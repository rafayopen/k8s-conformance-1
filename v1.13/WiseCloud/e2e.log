I1209 20:15:53.305378      15 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-028914468
I1209 20:15:53.305630      15 e2e.go:224] Starting e2e run "3a3019ef-fbef-11e8-8725-0a580af4034b" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1544386552 - Will randomize all specs
Will run 201 of 1946 specs

Dec  9 20:15:53.487: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
Dec  9 20:15:53.489: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Dec  9 20:15:53.508: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Dec  9 20:15:53.544: INFO: 20 / 20 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Dec  9 20:15:53.544: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Dec  9 20:15:53.544: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Dec  9 20:15:53.555: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds' (0 seconds elapsed)
Dec  9 20:15:53.555: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Dec  9 20:15:53.555: INFO: e2e test version: v1.13.0
Dec  9 20:15:53.557: INFO: kube-apiserver version: v1.13.0
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:15:53.557: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename containers
Dec  9 20:15:53.646: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Dec  9 20:15:53.660: INFO: Waiting up to 5m0s for pod "client-containers-3ac3fb90-fbef-11e8-8725-0a580af4034b" in namespace "e2e-tests-containers-2mgwv" to be "success or failure"
Dec  9 20:15:53.670: INFO: Pod "client-containers-3ac3fb90-fbef-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.473005ms
Dec  9 20:15:55.675: INFO: Pod "client-containers-3ac3fb90-fbef-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014815607s
STEP: Saw pod success
Dec  9 20:15:55.675: INFO: Pod "client-containers-3ac3fb90-fbef-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 20:15:55.679: INFO: Trying to get logs from node k8s04 pod client-containers-3ac3fb90-fbef-11e8-8725-0a580af4034b container test-container: <nil>
STEP: delete the pod
Dec  9 20:15:55.704: INFO: Waiting for pod client-containers-3ac3fb90-fbef-11e8-8725-0a580af4034b to disappear
Dec  9 20:15:55.709: INFO: Pod client-containers-3ac3fb90-fbef-11e8-8725-0a580af4034b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:15:55.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-2mgwv" for this suite.
Dec  9 20:16:01.740: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:16:01.874: INFO: namespace: e2e-tests-containers-2mgwv, resource: bindings, ignored listing per whitelist
Dec  9 20:16:01.890: INFO: namespace e2e-tests-containers-2mgwv deletion completed in 6.172823037s

• [SLOW TEST:8.334 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:16:01.890: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Dec  9 20:16:01.989: INFO: Waiting up to 5m0s for pod "var-expansion-3fbafc4a-fbef-11e8-8725-0a580af4034b" in namespace "e2e-tests-var-expansion-942w9" to be "success or failure"
Dec  9 20:16:01.995: INFO: Pod "var-expansion-3fbafc4a-fbef-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.041895ms
Dec  9 20:16:04.006: INFO: Pod "var-expansion-3fbafc4a-fbef-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017295678s
STEP: Saw pod success
Dec  9 20:16:04.006: INFO: Pod "var-expansion-3fbafc4a-fbef-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 20:16:04.010: INFO: Trying to get logs from node k8s04 pod var-expansion-3fbafc4a-fbef-11e8-8725-0a580af4034b container dapi-container: <nil>
STEP: delete the pod
Dec  9 20:16:04.033: INFO: Waiting for pod var-expansion-3fbafc4a-fbef-11e8-8725-0a580af4034b to disappear
Dec  9 20:16:04.037: INFO: Pod var-expansion-3fbafc4a-fbef-11e8-8725-0a580af4034b no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:16:04.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-942w9" for this suite.
Dec  9 20:16:10.069: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:16:10.086: INFO: namespace: e2e-tests-var-expansion-942w9, resource: bindings, ignored listing per whitelist
Dec  9 20:16:10.216: INFO: namespace e2e-tests-var-expansion-942w9 deletion completed in 6.166204472s

• [SLOW TEST:8.326 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:16:10.216: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Dec  9 20:16:12.362: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-44b46ed3-fbef-11e8-8725-0a580af4034b", GenerateName:"", Namespace:"e2e-tests-pods-252hg", SelfLink:"/api/v1/namespaces/e2e-tests-pods-252hg/pods/pod-submit-remove-44b46ed3-fbef-11e8-8725-0a580af4034b", UID:"44b5ec80-fbef-11e8-925a-000c296b480b", ResourceVersion:"36204", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63679983370, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"323121739"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-tsv5w", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0008f4180), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-tsv5w", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc000ab16b8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"k8s04", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001a7c060), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000ab1700)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000ab1930)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc000ab1938), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc000ab193c)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679983370, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679983371, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679983371, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679983370, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.9.14", PodIP:"10.244.3.78", StartTime:(*v1.Time)(0xc000e1cde0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc000e1ce00), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6", ContainerID:"docker://68f884c3f4b4e033eab44371b48cb3b9fcf45422e387fcc182cac5485c5f1520"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:16:20.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-252hg" for this suite.
Dec  9 20:16:26.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:16:26.744: INFO: namespace: e2e-tests-pods-252hg, resource: bindings, ignored listing per whitelist
Dec  9 20:16:26.895: INFO: namespace e2e-tests-pods-252hg deletion completed in 6.191695347s

• [SLOW TEST:16.678 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:16:26.895: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W1209 20:16:28.078291      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  9 20:16:28.083: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:16:28.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-wf4l7" for this suite.
Dec  9 20:16:34.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:16:34.220: INFO: namespace: e2e-tests-gc-wf4l7, resource: bindings, ignored listing per whitelist
Dec  9 20:16:34.272: INFO: namespace e2e-tests-gc-wf4l7 deletion completed in 6.182661498s

• [SLOW TEST:7.378 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:16:34.272: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-530fc4ad-fbef-11e8-8725-0a580af4034b
STEP: Creating a pod to test consume configMaps
Dec  9 20:16:34.437: INFO: Waiting up to 5m0s for pod "pod-configmaps-5311a404-fbef-11e8-8725-0a580af4034b" in namespace "e2e-tests-configmap-2644d" to be "success or failure"
Dec  9 20:16:34.447: INFO: Pod "pod-configmaps-5311a404-fbef-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.323109ms
Dec  9 20:16:36.452: INFO: Pod "pod-configmaps-5311a404-fbef-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01455854s
STEP: Saw pod success
Dec  9 20:16:36.452: INFO: Pod "pod-configmaps-5311a404-fbef-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 20:16:36.456: INFO: Trying to get logs from node k8s04 pod pod-configmaps-5311a404-fbef-11e8-8725-0a580af4034b container configmap-volume-test: <nil>
STEP: delete the pod
Dec  9 20:16:36.491: INFO: Waiting for pod pod-configmaps-5311a404-fbef-11e8-8725-0a580af4034b to disappear
Dec  9 20:16:36.495: INFO: Pod pod-configmaps-5311a404-fbef-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:16:36.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-2644d" for this suite.
Dec  9 20:16:42.531: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:16:42.669: INFO: namespace: e2e-tests-configmap-2644d, resource: bindings, ignored listing per whitelist
Dec  9 20:16:42.694: INFO: namespace e2e-tests-configmap-2644d deletion completed in 6.190423891s

• [SLOW TEST:8.422 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:16:42.695: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Dec  9 20:16:42.795: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Dec  9 20:16:42.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 create -f - --namespace=e2e-tests-kubectl-wt2zz'
Dec  9 20:16:43.374: INFO: stderr: ""
Dec  9 20:16:43.374: INFO: stdout: "service/redis-slave created\n"
Dec  9 20:16:43.375: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Dec  9 20:16:43.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 create -f - --namespace=e2e-tests-kubectl-wt2zz'
Dec  9 20:16:43.678: INFO: stderr: ""
Dec  9 20:16:43.678: INFO: stdout: "service/redis-master created\n"
Dec  9 20:16:43.678: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Dec  9 20:16:43.678: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 create -f - --namespace=e2e-tests-kubectl-wt2zz'
Dec  9 20:16:43.930: INFO: stderr: ""
Dec  9 20:16:43.930: INFO: stdout: "service/frontend created\n"
Dec  9 20:16:43.930: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Dec  9 20:16:43.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 create -f - --namespace=e2e-tests-kubectl-wt2zz'
Dec  9 20:16:44.161: INFO: stderr: ""
Dec  9 20:16:44.161: INFO: stdout: "deployment.extensions/frontend created\n"
Dec  9 20:16:44.161: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec  9 20:16:44.161: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 create -f - --namespace=e2e-tests-kubectl-wt2zz'
Dec  9 20:16:44.376: INFO: stderr: ""
Dec  9 20:16:44.376: INFO: stdout: "deployment.extensions/redis-master created\n"
Dec  9 20:16:44.376: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Dec  9 20:16:44.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 create -f - --namespace=e2e-tests-kubectl-wt2zz'
Dec  9 20:16:44.560: INFO: stderr: ""
Dec  9 20:16:44.560: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Dec  9 20:16:44.560: INFO: Waiting for all frontend pods to be Running.
Dec  9 20:16:49.611: INFO: Waiting for frontend to serve content.
Dec  9 20:16:49.645: INFO: Trying to add a new entry to the guestbook.
Dec  9 20:16:49.671: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Dec  9 20:16:49.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-wt2zz'
Dec  9 20:16:49.814: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  9 20:16:49.814: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Dec  9 20:16:49.814: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-wt2zz'
Dec  9 20:16:50.010: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  9 20:16:50.010: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec  9 20:16:50.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-wt2zz'
Dec  9 20:16:50.168: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  9 20:16:50.168: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec  9 20:16:50.168: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-wt2zz'
Dec  9 20:16:50.320: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  9 20:16:50.320: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec  9 20:16:50.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-wt2zz'
Dec  9 20:16:50.480: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  9 20:16:50.481: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec  9 20:16:50.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-wt2zz'
Dec  9 20:16:50.621: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  9 20:16:50.621: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:16:50.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wt2zz" for this suite.
Dec  9 20:17:30.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:17:30.798: INFO: namespace: e2e-tests-kubectl-wt2zz, resource: bindings, ignored listing per whitelist
Dec  9 20:17:30.820: INFO: namespace e2e-tests-kubectl-wt2zz deletion completed in 40.182802722s

• [SLOW TEST:48.125 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:17:30.820: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-74bf5381-fbef-11e8-8725-0a580af4034b
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-74bf5381-fbef-11e8-8725-0a580af4034b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:17:35.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xhsbn" for this suite.
Dec  9 20:17:57.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:17:57.124: INFO: namespace: e2e-tests-projected-xhsbn, resource: bindings, ignored listing per whitelist
Dec  9 20:17:57.222: INFO: namespace e2e-tests-projected-xhsbn deletion completed in 22.194052614s

• [SLOW TEST:26.402 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:17:57.223: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec  9 20:18:01.406: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  9 20:18:01.411: INFO: Pod pod-with-poststart-http-hook still exists
Dec  9 20:18:03.412: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  9 20:18:03.417: INFO: Pod pod-with-poststart-http-hook still exists
Dec  9 20:18:05.411: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  9 20:18:05.416: INFO: Pod pod-with-poststart-http-hook still exists
Dec  9 20:18:07.411: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  9 20:18:07.426: INFO: Pod pod-with-poststart-http-hook still exists
Dec  9 20:18:09.411: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  9 20:18:09.416: INFO: Pod pod-with-poststart-http-hook still exists
Dec  9 20:18:11.412: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  9 20:18:11.416: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:18:11.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-8bwjm" for this suite.
Dec  9 20:18:33.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:18:33.580: INFO: namespace: e2e-tests-container-lifecycle-hook-8bwjm, resource: bindings, ignored listing per whitelist
Dec  9 20:18:33.597: INFO: namespace e2e-tests-container-lifecycle-hook-8bwjm deletion completed in 22.173723042s

• [SLOW TEST:36.375 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:18:33.597: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec  9 20:18:33.723: INFO: Waiting up to 5m0s for pod "pod-9a29d8fc-fbef-11e8-8725-0a580af4034b" in namespace "e2e-tests-emptydir-p5gf6" to be "success or failure"
Dec  9 20:18:33.732: INFO: Pod "pod-9a29d8fc-fbef-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.432103ms
Dec  9 20:18:35.737: INFO: Pod "pod-9a29d8fc-fbef-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014291454s
STEP: Saw pod success
Dec  9 20:18:35.737: INFO: Pod "pod-9a29d8fc-fbef-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 20:18:35.742: INFO: Trying to get logs from node k8s04 pod pod-9a29d8fc-fbef-11e8-8725-0a580af4034b container test-container: <nil>
STEP: delete the pod
Dec  9 20:18:35.775: INFO: Waiting for pod pod-9a29d8fc-fbef-11e8-8725-0a580af4034b to disappear
Dec  9 20:18:35.780: INFO: Pod pod-9a29d8fc-fbef-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:18:35.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-p5gf6" for this suite.
Dec  9 20:18:41.809: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:18:41.908: INFO: namespace: e2e-tests-emptydir-p5gf6, resource: bindings, ignored listing per whitelist
Dec  9 20:18:41.973: INFO: namespace e2e-tests-emptydir-p5gf6 deletion completed in 6.185546166s

• [SLOW TEST:8.376 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:18:41.973: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  9 20:18:42.090: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9f2735b9-fbef-11e8-8725-0a580af4034b" in namespace "e2e-tests-projected-qs62j" to be "success or failure"
Dec  9 20:18:42.098: INFO: Pod "downwardapi-volume-9f2735b9-fbef-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.124702ms
Dec  9 20:18:44.103: INFO: Pod "downwardapi-volume-9f2735b9-fbef-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01305322s
STEP: Saw pod success
Dec  9 20:18:44.103: INFO: Pod "downwardapi-volume-9f2735b9-fbef-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 20:18:44.108: INFO: Trying to get logs from node k8s04 pod downwardapi-volume-9f2735b9-fbef-11e8-8725-0a580af4034b container client-container: <nil>
STEP: delete the pod
Dec  9 20:18:44.140: INFO: Waiting for pod downwardapi-volume-9f2735b9-fbef-11e8-8725-0a580af4034b to disappear
Dec  9 20:18:44.145: INFO: Pod downwardapi-volume-9f2735b9-fbef-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:18:44.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qs62j" for this suite.
Dec  9 20:18:50.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:18:50.253: INFO: namespace: e2e-tests-projected-qs62j, resource: bindings, ignored listing per whitelist
Dec  9 20:18:50.342: INFO: namespace e2e-tests-projected-qs62j deletion completed in 6.184955485s

• [SLOW TEST:8.369 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:18:50.342: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1209 20:18:56.494522      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  9 20:18:56.494: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:18:56.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-l5nv6" for this suite.
Dec  9 20:19:04.521: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:19:04.572: INFO: namespace: e2e-tests-gc-l5nv6, resource: bindings, ignored listing per whitelist
Dec  9 20:19:04.669: INFO: namespace e2e-tests-gc-l5nv6 deletion completed in 8.169497546s

• [SLOW TEST:14.327 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:19:04.669: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec  9 20:19:07.339: INFO: Successfully updated pod "pod-update-acafddb4-fbef-11e8-8725-0a580af4034b"
STEP: verifying the updated pod is in kubernetes
Dec  9 20:19:07.350: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:19:07.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-xsnmv" for this suite.
Dec  9 20:19:29.377: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:19:29.459: INFO: namespace: e2e-tests-pods-xsnmv, resource: bindings, ignored listing per whitelist
Dec  9 20:19:29.522: INFO: namespace e2e-tests-pods-xsnmv deletion completed in 22.165272995s

• [SLOW TEST:24.852 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:19:29.522: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-bb7e6fa9-fbef-11e8-8725-0a580af4034b
STEP: Creating a pod to test consume configMaps
Dec  9 20:19:29.649: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-bb80cf41-fbef-11e8-8725-0a580af4034b" in namespace "e2e-tests-projected-xzxmg" to be "success or failure"
Dec  9 20:19:29.657: INFO: Pod "pod-projected-configmaps-bb80cf41-fbef-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.189015ms
Dec  9 20:19:31.661: INFO: Pod "pod-projected-configmaps-bb80cf41-fbef-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012824981s
STEP: Saw pod success
Dec  9 20:19:31.661: INFO: Pod "pod-projected-configmaps-bb80cf41-fbef-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 20:19:31.666: INFO: Trying to get logs from node k8s04 pod pod-projected-configmaps-bb80cf41-fbef-11e8-8725-0a580af4034b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  9 20:19:31.708: INFO: Waiting for pod pod-projected-configmaps-bb80cf41-fbef-11e8-8725-0a580af4034b to disappear
Dec  9 20:19:31.715: INFO: Pod pod-projected-configmaps-bb80cf41-fbef-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:19:31.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xzxmg" for this suite.
Dec  9 20:19:37.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:19:37.847: INFO: namespace: e2e-tests-projected-xzxmg, resource: bindings, ignored listing per whitelist
Dec  9 20:19:37.896: INFO: namespace e2e-tests-projected-xzxmg deletion completed in 6.17223601s

• [SLOW TEST:8.374 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:19:37.896: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-prbt
STEP: Creating a pod to test atomic-volume-subpath
Dec  9 20:19:38.040: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-prbt" in namespace "e2e-tests-subpath-5n258" to be "success or failure"
Dec  9 20:19:38.049: INFO: Pod "pod-subpath-test-downwardapi-prbt": Phase="Pending", Reason="", readiness=false. Elapsed: 9.047828ms
Dec  9 20:19:40.054: INFO: Pod "pod-subpath-test-downwardapi-prbt": Phase="Running", Reason="", readiness=false. Elapsed: 2.013326898s
Dec  9 20:19:42.058: INFO: Pod "pod-subpath-test-downwardapi-prbt": Phase="Running", Reason="", readiness=false. Elapsed: 4.01769959s
Dec  9 20:19:44.072: INFO: Pod "pod-subpath-test-downwardapi-prbt": Phase="Running", Reason="", readiness=false. Elapsed: 6.031530636s
Dec  9 20:19:46.077: INFO: Pod "pod-subpath-test-downwardapi-prbt": Phase="Running", Reason="", readiness=false. Elapsed: 8.036565838s
Dec  9 20:19:48.082: INFO: Pod "pod-subpath-test-downwardapi-prbt": Phase="Running", Reason="", readiness=false. Elapsed: 10.041383935s
Dec  9 20:19:50.086: INFO: Pod "pod-subpath-test-downwardapi-prbt": Phase="Running", Reason="", readiness=false. Elapsed: 12.046152165s
Dec  9 20:19:52.091: INFO: Pod "pod-subpath-test-downwardapi-prbt": Phase="Running", Reason="", readiness=false. Elapsed: 14.051015192s
Dec  9 20:19:54.103: INFO: Pod "pod-subpath-test-downwardapi-prbt": Phase="Running", Reason="", readiness=false. Elapsed: 16.062871286s
Dec  9 20:19:56.108: INFO: Pod "pod-subpath-test-downwardapi-prbt": Phase="Running", Reason="", readiness=false. Elapsed: 18.068163655s
Dec  9 20:19:58.114: INFO: Pod "pod-subpath-test-downwardapi-prbt": Phase="Running", Reason="", readiness=false. Elapsed: 20.073361015s
Dec  9 20:20:00.118: INFO: Pod "pod-subpath-test-downwardapi-prbt": Phase="Running", Reason="", readiness=false. Elapsed: 22.077275131s
Dec  9 20:20:02.122: INFO: Pod "pod-subpath-test-downwardapi-prbt": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.082255471s
STEP: Saw pod success
Dec  9 20:20:02.123: INFO: Pod "pod-subpath-test-downwardapi-prbt" satisfied condition "success or failure"
Dec  9 20:20:02.127: INFO: Trying to get logs from node k8s04 pod pod-subpath-test-downwardapi-prbt container test-container-subpath-downwardapi-prbt: <nil>
STEP: delete the pod
Dec  9 20:20:02.162: INFO: Waiting for pod pod-subpath-test-downwardapi-prbt to disappear
Dec  9 20:20:02.166: INFO: Pod pod-subpath-test-downwardapi-prbt no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-prbt
Dec  9 20:20:02.166: INFO: Deleting pod "pod-subpath-test-downwardapi-prbt" in namespace "e2e-tests-subpath-5n258"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:20:02.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-5n258" for this suite.
Dec  9 20:20:08.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:20:08.224: INFO: namespace: e2e-tests-subpath-5n258, resource: bindings, ignored listing per whitelist
Dec  9 20:20:08.368: INFO: namespace e2e-tests-subpath-5n258 deletion completed in 6.188731735s

• [SLOW TEST:30.473 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:20:08.369: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-d2a5fd69-fbef-11e8-8725-0a580af4034b
STEP: Creating a pod to test consume configMaps
Dec  9 20:20:08.490: INFO: Waiting up to 5m0s for pod "pod-configmaps-d2a79efd-fbef-11e8-8725-0a580af4034b" in namespace "e2e-tests-configmap-866dh" to be "success or failure"
Dec  9 20:20:08.498: INFO: Pod "pod-configmaps-d2a79efd-fbef-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.98943ms
Dec  9 20:20:10.503: INFO: Pod "pod-configmaps-d2a79efd-fbef-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012466017s
STEP: Saw pod success
Dec  9 20:20:10.503: INFO: Pod "pod-configmaps-d2a79efd-fbef-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 20:20:10.507: INFO: Trying to get logs from node k8s04 pod pod-configmaps-d2a79efd-fbef-11e8-8725-0a580af4034b container configmap-volume-test: <nil>
STEP: delete the pod
Dec  9 20:20:10.541: INFO: Waiting for pod pod-configmaps-d2a79efd-fbef-11e8-8725-0a580af4034b to disappear
Dec  9 20:20:10.547: INFO: Pod pod-configmaps-d2a79efd-fbef-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:20:10.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-866dh" for this suite.
Dec  9 20:20:16.575: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:20:16.645: INFO: namespace: e2e-tests-configmap-866dh, resource: bindings, ignored listing per whitelist
Dec  9 20:20:16.722: INFO: namespace e2e-tests-configmap-866dh deletion completed in 6.168627194s

• [SLOW TEST:8.353 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:20:16.722: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-d7a14c68-fbef-11e8-8725-0a580af4034b
STEP: Creating a pod to test consume secrets
Dec  9 20:20:16.905: INFO: Waiting up to 5m0s for pod "pod-secrets-d7ac12ff-fbef-11e8-8725-0a580af4034b" in namespace "e2e-tests-secrets-5ljgr" to be "success or failure"
Dec  9 20:20:16.910: INFO: Pod "pod-secrets-d7ac12ff-fbef-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.051424ms
Dec  9 20:20:18.916: INFO: Pod "pod-secrets-d7ac12ff-fbef-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010399445s
STEP: Saw pod success
Dec  9 20:20:18.916: INFO: Pod "pod-secrets-d7ac12ff-fbef-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 20:20:18.920: INFO: Trying to get logs from node k8s04 pod pod-secrets-d7ac12ff-fbef-11e8-8725-0a580af4034b container secret-volume-test: <nil>
STEP: delete the pod
Dec  9 20:20:18.953: INFO: Waiting for pod pod-secrets-d7ac12ff-fbef-11e8-8725-0a580af4034b to disappear
Dec  9 20:20:18.960: INFO: Pod pod-secrets-d7ac12ff-fbef-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:20:18.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-5ljgr" for this suite.
Dec  9 20:20:24.997: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:20:25.022: INFO: namespace: e2e-tests-secrets-5ljgr, resource: bindings, ignored listing per whitelist
Dec  9 20:20:25.146: INFO: namespace e2e-tests-secrets-5ljgr deletion completed in 6.178297347s
STEP: Destroying namespace "e2e-tests-secret-namespace-2vbbx" for this suite.
Dec  9 20:20:31.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:20:31.298: INFO: namespace: e2e-tests-secret-namespace-2vbbx, resource: bindings, ignored listing per whitelist
Dec  9 20:20:31.327: INFO: namespace e2e-tests-secret-namespace-2vbbx deletion completed in 6.180210157s

• [SLOW TEST:14.604 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:20:31.327: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec  9 20:20:31.437: INFO: Waiting up to 5m0s for pod "pod-e054a196-fbef-11e8-8725-0a580af4034b" in namespace "e2e-tests-emptydir-5vj6z" to be "success or failure"
Dec  9 20:20:31.443: INFO: Pod "pod-e054a196-fbef-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.044993ms
Dec  9 20:20:33.448: INFO: Pod "pod-e054a196-fbef-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011606309s
STEP: Saw pod success
Dec  9 20:20:33.448: INFO: Pod "pod-e054a196-fbef-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 20:20:33.453: INFO: Trying to get logs from node k8s04 pod pod-e054a196-fbef-11e8-8725-0a580af4034b container test-container: <nil>
STEP: delete the pod
Dec  9 20:20:33.527: INFO: Waiting for pod pod-e054a196-fbef-11e8-8725-0a580af4034b to disappear
Dec  9 20:20:33.532: INFO: Pod pod-e054a196-fbef-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:20:33.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5vj6z" for this suite.
Dec  9 20:20:39.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:20:39.649: INFO: namespace: e2e-tests-emptydir-5vj6z, resource: bindings, ignored listing per whitelist
Dec  9 20:20:39.699: INFO: namespace e2e-tests-emptydir-5vj6z deletion completed in 6.159433459s

• [SLOW TEST:8.373 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:20:39.700: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:20:39.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-x5g5f" for this suite.
Dec  9 20:20:45.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:20:45.966: INFO: namespace: e2e-tests-kubelet-test-x5g5f, resource: bindings, ignored listing per whitelist
Dec  9 20:20:46.030: INFO: namespace e2e-tests-kubelet-test-x5g5f deletion completed in 6.179781537s

• [SLOW TEST:6.330 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:20:46.030: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Dec  9 20:20:46.125: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  9 20:20:46.137: INFO: Waiting for terminating namespaces to be deleted...
Dec  9 20:20:46.145: INFO: 
Logging pods the kubelet thinks is on node k8s04 before test
Dec  9 20:20:46.156: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-09 20:15:29 +0000 UTC (1 container statuses recorded)
Dec  9 20:20:46.156: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec  9 20:20:46.156: INFO: sonobuoy-e2e-job-0d4a7a7233874536 from heptio-sonobuoy started at 2018-12-09 20:15:42 +0000 UTC (2 container statuses recorded)
Dec  9 20:20:46.156: INFO: 	Container e2e ready: true, restart count 0
Dec  9 20:20:46.156: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  9 20:20:46.156: INFO: kube-proxy-jp2gj from kube-system started at 2018-12-09 16:17:56 +0000 UTC (1 container statuses recorded)
Dec  9 20:20:46.156: INFO: 	Container kube-proxy ready: true, restart count 1
Dec  9 20:20:46.156: INFO: kube-flannel-ds-zh4m6 from kube-system started at 2018-12-09 16:17:56 +0000 UTC (1 container statuses recorded)
Dec  9 20:20:46.156: INFO: 	Container kube-flannel ready: true, restart count 2
Dec  9 20:20:46.156: INFO: sonobuoy-systemd-logs-daemon-set-1cb03de6217e447d-crnlb from heptio-sonobuoy started at 2018-12-09 20:15:42 +0000 UTC (2 container statuses recorded)
Dec  9 20:20:46.156: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Dec  9 20:20:46.156: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.156ec3a7731337cf], Reason = [FailedScheduling], Message = [0/4 nodes are available: 4 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:20:47.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-2lvjl" for this suite.
Dec  9 20:20:53.223: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:20:53.265: INFO: namespace: e2e-tests-sched-pred-2lvjl, resource: bindings, ignored listing per whitelist
Dec  9 20:20:53.384: INFO: namespace e2e-tests-sched-pred-2lvjl deletion completed in 6.18157232s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.354 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:20:53.384: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-sgjcl
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-sgjcl
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-sgjcl
Dec  9 20:20:53.522: INFO: Found 0 stateful pods, waiting for 1
Dec  9 20:21:03.534: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Dec  9 20:21:03.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 exec --namespace=e2e-tests-statefulset-sgjcl ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  9 20:21:03.748: INFO: stderr: ""
Dec  9 20:21:03.748: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  9 20:21:03.748: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  9 20:21:03.753: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec  9 20:21:13.766: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  9 20:21:13.766: INFO: Waiting for statefulset status.replicas updated to 0
Dec  9 20:21:13.792: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999442s
Dec  9 20:21:14.797: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.994669815s
Dec  9 20:21:15.803: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.988890972s
Dec  9 20:21:16.808: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.983835684s
Dec  9 20:21:17.814: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.978570186s
Dec  9 20:21:18.819: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.972800607s
Dec  9 20:21:19.823: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.968073924s
Dec  9 20:21:20.828: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.9637109s
Dec  9 20:21:21.833: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.958529361s
Dec  9 20:21:22.839: INFO: Verifying statefulset ss doesn't scale past 1 for another 952.858919ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-sgjcl
Dec  9 20:21:23.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 exec --namespace=e2e-tests-statefulset-sgjcl ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  9 20:21:24.046: INFO: stderr: ""
Dec  9 20:21:24.046: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  9 20:21:24.046: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  9 20:21:24.050: INFO: Found 1 stateful pods, waiting for 3
Dec  9 20:21:34.063: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  9 20:21:34.063: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  9 20:21:34.063: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Dec  9 20:21:34.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 exec --namespace=e2e-tests-statefulset-sgjcl ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  9 20:21:34.269: INFO: stderr: ""
Dec  9 20:21:34.269: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  9 20:21:34.269: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  9 20:21:34.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 exec --namespace=e2e-tests-statefulset-sgjcl ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  9 20:21:34.486: INFO: stderr: ""
Dec  9 20:21:34.486: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  9 20:21:34.486: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  9 20:21:34.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 exec --namespace=e2e-tests-statefulset-sgjcl ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  9 20:21:34.748: INFO: stderr: ""
Dec  9 20:21:34.748: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  9 20:21:34.748: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  9 20:21:34.748: INFO: Waiting for statefulset status.replicas updated to 0
Dec  9 20:21:34.759: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Dec  9 20:21:44.777: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  9 20:21:44.777: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec  9 20:21:44.777: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec  9 20:21:44.798: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999149s
Dec  9 20:21:45.803: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.993952537s
Dec  9 20:21:46.808: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.988234679s
Dec  9 20:21:47.814: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.982704182s
Dec  9 20:21:48.819: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.977208324s
Dec  9 20:21:49.824: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.972357407s
Dec  9 20:21:50.829: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.967662242s
Dec  9 20:21:51.835: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.961904768s
Dec  9 20:21:52.840: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.956336478s
Dec  9 20:21:53.846: INFO: Verifying statefulset ss doesn't scale past 3 for another 950.910913ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-sgjcl
Dec  9 20:21:54.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 exec --namespace=e2e-tests-statefulset-sgjcl ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  9 20:21:55.066: INFO: stderr: ""
Dec  9 20:21:55.066: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  9 20:21:55.066: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  9 20:21:55.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 exec --namespace=e2e-tests-statefulset-sgjcl ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  9 20:21:55.264: INFO: stderr: ""
Dec  9 20:21:55.264: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  9 20:21:55.264: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  9 20:21:55.264: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 exec --namespace=e2e-tests-statefulset-sgjcl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  9 20:21:55.465: INFO: stderr: ""
Dec  9 20:21:55.465: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  9 20:21:55.465: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  9 20:21:55.465: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  9 20:22:15.488: INFO: Deleting all statefulset in ns e2e-tests-statefulset-sgjcl
Dec  9 20:22:15.495: INFO: Scaling statefulset ss to 0
Dec  9 20:22:15.525: INFO: Waiting for statefulset status.replicas updated to 0
Dec  9 20:22:15.532: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:22:15.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-sgjcl" for this suite.
Dec  9 20:22:21.594: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:22:21.615: INFO: namespace: e2e-tests-statefulset-sgjcl, resource: bindings, ignored listing per whitelist
Dec  9 20:22:21.753: INFO: namespace e2e-tests-statefulset-sgjcl deletion completed in 6.183059734s

• [SLOW TEST:88.369 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:22:21.753: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Dec  9 20:22:21.907: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-ckthl,SelfLink:/api/v1/namespaces/e2e-tests-watch-ckthl/configmaps/e2e-watch-test-resource-version,UID:2227f043-fbf0-11e8-925a-000c296b480b,ResourceVersion:37802,Generation:0,CreationTimestamp:2018-12-09 20:22:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  9 20:22:21.907: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-ckthl,SelfLink:/api/v1/namespaces/e2e-tests-watch-ckthl/configmaps/e2e-watch-test-resource-version,UID:2227f043-fbf0-11e8-925a-000c296b480b,ResourceVersion:37803,Generation:0,CreationTimestamp:2018-12-09 20:22:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:22:21.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-ckthl" for this suite.
Dec  9 20:22:27.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:22:27.956: INFO: namespace: e2e-tests-watch-ckthl, resource: bindings, ignored listing per whitelist
Dec  9 20:22:28.088: INFO: namespace e2e-tests-watch-ckthl deletion completed in 6.172459775s

• [SLOW TEST:6.335 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:22:28.088: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Dec  9 20:22:28.214: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-jkbfs,SelfLink:/api/v1/namespaces/e2e-tests-watch-jkbfs/configmaps/e2e-watch-test-watch-closed,UID:25edad3c-fbf0-11e8-925a-000c296b480b,ResourceVersion:37826,Generation:0,CreationTimestamp:2018-12-09 20:22:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  9 20:22:28.214: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-jkbfs,SelfLink:/api/v1/namespaces/e2e-tests-watch-jkbfs/configmaps/e2e-watch-test-watch-closed,UID:25edad3c-fbf0-11e8-925a-000c296b480b,ResourceVersion:37827,Generation:0,CreationTimestamp:2018-12-09 20:22:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Dec  9 20:22:28.244: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-jkbfs,SelfLink:/api/v1/namespaces/e2e-tests-watch-jkbfs/configmaps/e2e-watch-test-watch-closed,UID:25edad3c-fbf0-11e8-925a-000c296b480b,ResourceVersion:37828,Generation:0,CreationTimestamp:2018-12-09 20:22:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  9 20:22:28.245: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-jkbfs,SelfLink:/api/v1/namespaces/e2e-tests-watch-jkbfs/configmaps/e2e-watch-test-watch-closed,UID:25edad3c-fbf0-11e8-925a-000c296b480b,ResourceVersion:37829,Generation:0,CreationTimestamp:2018-12-09 20:22:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:22:28.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-jkbfs" for this suite.
Dec  9 20:22:34.273: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:22:34.389: INFO: namespace: e2e-tests-watch-jkbfs, resource: bindings, ignored listing per whitelist
Dec  9 20:22:34.416: INFO: namespace e2e-tests-watch-jkbfs deletion completed in 6.163976029s

• [SLOW TEST:6.327 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:22:34.416: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  9 20:22:34.536: INFO: Waiting up to 5m0s for pod "downwardapi-volume-29b3a1f5-fbf0-11e8-8725-0a580af4034b" in namespace "e2e-tests-projected-98vjk" to be "success or failure"
Dec  9 20:22:34.542: INFO: Pod "downwardapi-volume-29b3a1f5-fbf0-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.105688ms
Dec  9 20:22:36.553: INFO: Pod "downwardapi-volume-29b3a1f5-fbf0-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016269677s
STEP: Saw pod success
Dec  9 20:22:36.553: INFO: Pod "downwardapi-volume-29b3a1f5-fbf0-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 20:22:36.557: INFO: Trying to get logs from node k8s04 pod downwardapi-volume-29b3a1f5-fbf0-11e8-8725-0a580af4034b container client-container: <nil>
STEP: delete the pod
Dec  9 20:22:36.594: INFO: Waiting for pod downwardapi-volume-29b3a1f5-fbf0-11e8-8725-0a580af4034b to disappear
Dec  9 20:22:36.599: INFO: Pod downwardapi-volume-29b3a1f5-fbf0-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:22:36.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-98vjk" for this suite.
Dec  9 20:22:42.632: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:22:42.698: INFO: namespace: e2e-tests-projected-98vjk, resource: bindings, ignored listing per whitelist
Dec  9 20:22:42.790: INFO: namespace e2e-tests-projected-98vjk deletion completed in 6.178667861s

• [SLOW TEST:8.374 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:22:42.791: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W1209 20:23:22.942047      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  9 20:23:22.942: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:23:22.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-8pwkd" for this suite.
Dec  9 20:23:30.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:23:30.990: INFO: namespace: e2e-tests-gc-8pwkd, resource: bindings, ignored listing per whitelist
Dec  9 20:23:31.137: INFO: namespace e2e-tests-gc-8pwkd deletion completed in 8.186195974s

• [SLOW TEST:48.347 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:23:31.137: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-2p2jl
Dec  9 20:23:33.274: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-2p2jl
STEP: checking the pod's current state and verifying that restartCount is present
Dec  9 20:23:33.278: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:27:34.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-2p2jl" for this suite.
Dec  9 20:27:40.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:27:40.157: INFO: namespace: e2e-tests-container-probe-2p2jl, resource: bindings, ignored listing per whitelist
Dec  9 20:27:40.242: INFO: namespace e2e-tests-container-probe-2p2jl deletion completed in 6.163403229s

• [SLOW TEST:249.105 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:27:40.242: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Dec  9 20:27:40.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 cluster-info'
Dec  9 20:27:40.483: INFO: stderr: ""
Dec  9 20:27:40.483: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:27:40.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kgx9t" for this suite.
Dec  9 20:27:46.507: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:27:46.551: INFO: namespace: e2e-tests-kubectl-kgx9t, resource: bindings, ignored listing per whitelist
Dec  9 20:27:46.663: INFO: namespace e2e-tests-kubectl-kgx9t deletion completed in 6.175250826s

• [SLOW TEST:6.421 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:27:46.664: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:27:48.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-vh6br" for this suite.
Dec  9 20:28:32.834: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:28:32.858: INFO: namespace: e2e-tests-kubelet-test-vh6br, resource: bindings, ignored listing per whitelist
Dec  9 20:28:33.003: INFO: namespace e2e-tests-kubelet-test-vh6br deletion completed in 44.193011245s

• [SLOW TEST:46.340 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:28:33.003: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Dec  9 20:28:33.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 create -f - --namespace=e2e-tests-kubectl-mwj5s'
Dec  9 20:28:33.254: INFO: stderr: ""
Dec  9 20:28:33.254: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  9 20:28:33.254: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-mwj5s'
Dec  9 20:28:33.374: INFO: stderr: ""
Dec  9 20:28:33.374: INFO: stdout: "update-demo-nautilus-dr47k update-demo-nautilus-lqh6j "
Dec  9 20:28:33.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods update-demo-nautilus-dr47k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mwj5s'
Dec  9 20:28:33.451: INFO: stderr: ""
Dec  9 20:28:33.451: INFO: stdout: ""
Dec  9 20:28:33.451: INFO: update-demo-nautilus-dr47k is created but not running
Dec  9 20:28:38.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-mwj5s'
Dec  9 20:28:38.532: INFO: stderr: ""
Dec  9 20:28:38.532: INFO: stdout: "update-demo-nautilus-dr47k update-demo-nautilus-lqh6j "
Dec  9 20:28:38.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods update-demo-nautilus-dr47k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mwj5s'
Dec  9 20:28:38.611: INFO: stderr: ""
Dec  9 20:28:38.612: INFO: stdout: "true"
Dec  9 20:28:38.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods update-demo-nautilus-dr47k -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mwj5s'
Dec  9 20:28:38.693: INFO: stderr: ""
Dec  9 20:28:38.693: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  9 20:28:38.693: INFO: validating pod update-demo-nautilus-dr47k
Dec  9 20:28:38.699: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  9 20:28:38.700: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  9 20:28:38.700: INFO: update-demo-nautilus-dr47k is verified up and running
Dec  9 20:28:38.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods update-demo-nautilus-lqh6j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mwj5s'
Dec  9 20:28:38.781: INFO: stderr: ""
Dec  9 20:28:38.781: INFO: stdout: "true"
Dec  9 20:28:38.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods update-demo-nautilus-lqh6j -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mwj5s'
Dec  9 20:28:38.854: INFO: stderr: ""
Dec  9 20:28:38.854: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  9 20:28:38.854: INFO: validating pod update-demo-nautilus-lqh6j
Dec  9 20:28:38.860: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  9 20:28:38.860: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  9 20:28:38.860: INFO: update-demo-nautilus-lqh6j is verified up and running
STEP: scaling down the replication controller
Dec  9 20:28:38.863: INFO: scanned /root for discovery docs: <nil>
Dec  9 20:28:38.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-mwj5s'
Dec  9 20:28:40.002: INFO: stderr: ""
Dec  9 20:28:40.002: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  9 20:28:40.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-mwj5s'
Dec  9 20:28:40.094: INFO: stderr: ""
Dec  9 20:28:40.094: INFO: stdout: "update-demo-nautilus-dr47k update-demo-nautilus-lqh6j "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec  9 20:28:45.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-mwj5s'
Dec  9 20:28:45.180: INFO: stderr: ""
Dec  9 20:28:45.180: INFO: stdout: "update-demo-nautilus-dr47k update-demo-nautilus-lqh6j "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec  9 20:28:50.181: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-mwj5s'
Dec  9 20:28:50.265: INFO: stderr: ""
Dec  9 20:28:50.265: INFO: stdout: "update-demo-nautilus-dr47k update-demo-nautilus-lqh6j "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec  9 20:28:55.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-mwj5s'
Dec  9 20:28:55.360: INFO: stderr: ""
Dec  9 20:28:55.360: INFO: stdout: "update-demo-nautilus-dr47k "
Dec  9 20:28:55.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods update-demo-nautilus-dr47k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mwj5s'
Dec  9 20:28:55.447: INFO: stderr: ""
Dec  9 20:28:55.447: INFO: stdout: "true"
Dec  9 20:28:55.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods update-demo-nautilus-dr47k -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mwj5s'
Dec  9 20:28:55.522: INFO: stderr: ""
Dec  9 20:28:55.523: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  9 20:28:55.523: INFO: validating pod update-demo-nautilus-dr47k
Dec  9 20:28:55.529: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  9 20:28:55.529: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  9 20:28:55.529: INFO: update-demo-nautilus-dr47k is verified up and running
STEP: scaling up the replication controller
Dec  9 20:28:55.531: INFO: scanned /root for discovery docs: <nil>
Dec  9 20:28:55.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-mwj5s'
Dec  9 20:28:56.647: INFO: stderr: ""
Dec  9 20:28:56.647: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  9 20:28:56.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-mwj5s'
Dec  9 20:28:56.732: INFO: stderr: ""
Dec  9 20:28:56.732: INFO: stdout: "update-demo-nautilus-dr47k update-demo-nautilus-ppzsz "
Dec  9 20:28:56.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods update-demo-nautilus-dr47k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mwj5s'
Dec  9 20:28:56.807: INFO: stderr: ""
Dec  9 20:28:56.807: INFO: stdout: "true"
Dec  9 20:28:56.807: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods update-demo-nautilus-dr47k -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mwj5s'
Dec  9 20:28:56.884: INFO: stderr: ""
Dec  9 20:28:56.884: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  9 20:28:56.884: INFO: validating pod update-demo-nautilus-dr47k
Dec  9 20:28:56.890: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  9 20:28:56.890: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  9 20:28:56.890: INFO: update-demo-nautilus-dr47k is verified up and running
Dec  9 20:28:56.890: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods update-demo-nautilus-ppzsz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mwj5s'
Dec  9 20:28:56.966: INFO: stderr: ""
Dec  9 20:28:56.966: INFO: stdout: "true"
Dec  9 20:28:56.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods update-demo-nautilus-ppzsz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mwj5s'
Dec  9 20:28:57.040: INFO: stderr: ""
Dec  9 20:28:57.040: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  9 20:28:57.040: INFO: validating pod update-demo-nautilus-ppzsz
Dec  9 20:28:57.048: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  9 20:28:57.048: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  9 20:28:57.048: INFO: update-demo-nautilus-ppzsz is verified up and running
STEP: using delete to clean up resources
Dec  9 20:28:57.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-mwj5s'
Dec  9 20:28:57.136: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  9 20:28:57.136: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec  9 20:28:57.136: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-mwj5s'
Dec  9 20:28:57.253: INFO: stderr: "No resources found.\n"
Dec  9 20:28:57.254: INFO: stdout: ""
Dec  9 20:28:57.254: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods -l name=update-demo --namespace=e2e-tests-kubectl-mwj5s -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  9 20:28:57.342: INFO: stderr: ""
Dec  9 20:28:57.342: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:28:57.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mwj5s" for this suite.
Dec  9 20:29:19.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:29:19.398: INFO: namespace: e2e-tests-kubectl-mwj5s, resource: bindings, ignored listing per whitelist
Dec  9 20:29:19.516: INFO: namespace e2e-tests-kubectl-mwj5s deletion completed in 22.167573622s

• [SLOW TEST:46.513 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:29:19.517: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:29:21.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-jmq4z" for this suite.
Dec  9 20:29:27.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:29:27.832: INFO: namespace: e2e-tests-emptydir-wrapper-jmq4z, resource: bindings, ignored listing per whitelist
Dec  9 20:29:27.903: INFO: namespace e2e-tests-emptydir-wrapper-jmq4z deletion completed in 6.178946627s

• [SLOW TEST:8.386 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:29:27.903: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-2028769d-fbf1-11e8-8725-0a580af4034b
STEP: Creating a pod to test consume configMaps
Dec  9 20:29:28.027: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-202a4c73-fbf1-11e8-8725-0a580af4034b" in namespace "e2e-tests-projected-h8944" to be "success or failure"
Dec  9 20:29:28.034: INFO: Pod "pod-projected-configmaps-202a4c73-fbf1-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.684781ms
Dec  9 20:29:30.040: INFO: Pod "pod-projected-configmaps-202a4c73-fbf1-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012309764s
STEP: Saw pod success
Dec  9 20:29:30.040: INFO: Pod "pod-projected-configmaps-202a4c73-fbf1-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 20:29:30.044: INFO: Trying to get logs from node k8s04 pod pod-projected-configmaps-202a4c73-fbf1-11e8-8725-0a580af4034b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  9 20:29:30.076: INFO: Waiting for pod pod-projected-configmaps-202a4c73-fbf1-11e8-8725-0a580af4034b to disappear
Dec  9 20:29:30.082: INFO: Pod pod-projected-configmaps-202a4c73-fbf1-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:29:30.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-h8944" for this suite.
Dec  9 20:29:36.109: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:29:36.143: INFO: namespace: e2e-tests-projected-h8944, resource: bindings, ignored listing per whitelist
Dec  9 20:29:36.265: INFO: namespace e2e-tests-projected-h8944 deletion completed in 6.176296009s

• [SLOW TEST:8.362 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:29:36.265: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-6smfc/secret-test-2524e14b-fbf1-11e8-8725-0a580af4034b
STEP: Creating a pod to test consume secrets
Dec  9 20:29:36.396: INFO: Waiting up to 5m0s for pod "pod-configmaps-25274e23-fbf1-11e8-8725-0a580af4034b" in namespace "e2e-tests-secrets-6smfc" to be "success or failure"
Dec  9 20:29:36.404: INFO: Pod "pod-configmaps-25274e23-fbf1-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.211267ms
Dec  9 20:29:38.417: INFO: Pod "pod-configmaps-25274e23-fbf1-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020192909s
STEP: Saw pod success
Dec  9 20:29:38.417: INFO: Pod "pod-configmaps-25274e23-fbf1-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 20:29:38.421: INFO: Trying to get logs from node k8s04 pod pod-configmaps-25274e23-fbf1-11e8-8725-0a580af4034b container env-test: <nil>
STEP: delete the pod
Dec  9 20:29:38.457: INFO: Waiting for pod pod-configmaps-25274e23-fbf1-11e8-8725-0a580af4034b to disappear
Dec  9 20:29:38.461: INFO: Pod pod-configmaps-25274e23-fbf1-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:29:38.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-6smfc" for this suite.
Dec  9 20:29:44.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:29:44.592: INFO: namespace: e2e-tests-secrets-6smfc, resource: bindings, ignored listing per whitelist
Dec  9 20:29:44.646: INFO: namespace e2e-tests-secrets-6smfc deletion completed in 6.175682731s

• [SLOW TEST:8.381 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:29:44.646: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  9 20:29:44.760: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2a2297d1-fbf1-11e8-8725-0a580af4034b" in namespace "e2e-tests-projected-l8798" to be "success or failure"
Dec  9 20:29:44.769: INFO: Pod "downwardapi-volume-2a2297d1-fbf1-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.225835ms
Dec  9 20:29:46.775: INFO: Pod "downwardapi-volume-2a2297d1-fbf1-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015017837s
STEP: Saw pod success
Dec  9 20:29:46.775: INFO: Pod "downwardapi-volume-2a2297d1-fbf1-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 20:29:46.780: INFO: Trying to get logs from node k8s04 pod downwardapi-volume-2a2297d1-fbf1-11e8-8725-0a580af4034b container client-container: <nil>
STEP: delete the pod
Dec  9 20:29:46.819: INFO: Waiting for pod downwardapi-volume-2a2297d1-fbf1-11e8-8725-0a580af4034b to disappear
Dec  9 20:29:46.825: INFO: Pod downwardapi-volume-2a2297d1-fbf1-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:29:46.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-l8798" for this suite.
Dec  9 20:29:52.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:29:52.987: INFO: namespace: e2e-tests-projected-l8798, resource: bindings, ignored listing per whitelist
Dec  9 20:29:53.015: INFO: namespace e2e-tests-projected-l8798 deletion completed in 6.176089109s

• [SLOW TEST:8.369 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:29:53.015: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-8qb9k
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-8qb9k
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-8qb9k
Dec  9 20:29:53.159: INFO: Found 0 stateful pods, waiting for 1
Dec  9 20:30:03.171: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Dec  9 20:30:03.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 exec --namespace=e2e-tests-statefulset-8qb9k ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  9 20:30:03.398: INFO: stderr: ""
Dec  9 20:30:03.398: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  9 20:30:03.398: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  9 20:30:03.402: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec  9 20:30:13.413: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  9 20:30:13.413: INFO: Waiting for statefulset status.replicas updated to 0
Dec  9 20:30:13.437: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Dec  9 20:30:13.437: INFO: ss-0  k8s04  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:29:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:30:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:30:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:29:53 +0000 UTC  }]
Dec  9 20:30:13.437: INFO: 
Dec  9 20:30:13.437: INFO: StatefulSet ss has not reached scale 3, at 1
Dec  9 20:30:14.447: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.993648253s
Dec  9 20:30:15.453: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.984095351s
Dec  9 20:30:16.457: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.978465071s
Dec  9 20:30:17.462: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.974401168s
Dec  9 20:30:18.467: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.969329324s
Dec  9 20:30:19.473: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.964318866s
Dec  9 20:30:20.478: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.958515361s
Dec  9 20:30:21.484: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.953551823s
Dec  9 20:30:22.490: INFO: Verifying statefulset ss doesn't scale past 3 for another 947.979039ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-8qb9k
Dec  9 20:30:23.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 exec --namespace=e2e-tests-statefulset-8qb9k ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  9 20:30:23.709: INFO: stderr: ""
Dec  9 20:30:23.709: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  9 20:30:23.709: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  9 20:30:23.709: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 exec --namespace=e2e-tests-statefulset-8qb9k ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  9 20:30:23.909: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Dec  9 20:30:23.909: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  9 20:30:23.909: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  9 20:30:23.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 exec --namespace=e2e-tests-statefulset-8qb9k ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  9 20:30:24.154: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Dec  9 20:30:24.154: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  9 20:30:24.154: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  9 20:30:24.158: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  9 20:30:24.158: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  9 20:30:24.158: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Dec  9 20:30:24.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 exec --namespace=e2e-tests-statefulset-8qb9k ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  9 20:30:24.358: INFO: stderr: ""
Dec  9 20:30:24.358: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  9 20:30:24.358: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  9 20:30:24.358: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 exec --namespace=e2e-tests-statefulset-8qb9k ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  9 20:30:24.567: INFO: stderr: ""
Dec  9 20:30:24.567: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  9 20:30:24.567: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  9 20:30:24.567: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 exec --namespace=e2e-tests-statefulset-8qb9k ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  9 20:30:24.792: INFO: stderr: ""
Dec  9 20:30:24.792: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  9 20:30:24.792: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  9 20:30:24.792: INFO: Waiting for statefulset status.replicas updated to 0
Dec  9 20:30:24.796: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Dec  9 20:30:34.813: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  9 20:30:34.813: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec  9 20:30:34.813: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec  9 20:30:34.833: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Dec  9 20:30:34.833: INFO: ss-0  k8s04  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:29:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:30:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:30:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:29:53 +0000 UTC  }]
Dec  9 20:30:34.833: INFO: ss-1  k8s04  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:30:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:30:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:30:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:30:13 +0000 UTC  }]
Dec  9 20:30:34.833: INFO: ss-2  k8s04  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:30:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:30:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:30:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:30:13 +0000 UTC  }]
Dec  9 20:30:34.833: INFO: 
Dec  9 20:30:34.833: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  9 20:30:35.838: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Dec  9 20:30:35.838: INFO: ss-0  k8s04  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:29:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:30:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:30:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:29:53 +0000 UTC  }]
Dec  9 20:30:35.838: INFO: ss-1  k8s04  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:30:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:30:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:30:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:30:13 +0000 UTC  }]
Dec  9 20:30:35.838: INFO: ss-2  k8s04  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:30:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:30:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:30:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:30:13 +0000 UTC  }]
Dec  9 20:30:35.838: INFO: 
Dec  9 20:30:35.838: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  9 20:30:36.844: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Dec  9 20:30:36.844: INFO: ss-1  k8s04  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:30:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:30:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:30:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:30:13 +0000 UTC  }]
Dec  9 20:30:36.844: INFO: 
Dec  9 20:30:36.844: INFO: StatefulSet ss has not reached scale 0, at 1
Dec  9 20:30:37.849: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Dec  9 20:30:37.849: INFO: ss-1  k8s04  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:30:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:30:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:30:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:30:13 +0000 UTC  }]
Dec  9 20:30:37.849: INFO: 
Dec  9 20:30:37.849: INFO: StatefulSet ss has not reached scale 0, at 1
Dec  9 20:30:38.855: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Dec  9 20:30:38.855: INFO: ss-1  k8s04  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:30:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:30:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:30:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:30:13 +0000 UTC  }]
Dec  9 20:30:38.855: INFO: 
Dec  9 20:30:38.855: INFO: StatefulSet ss has not reached scale 0, at 1
Dec  9 20:30:39.860: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Dec  9 20:30:39.860: INFO: ss-1  k8s04  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:30:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:30:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:30:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:30:13 +0000 UTC  }]
Dec  9 20:30:39.860: INFO: 
Dec  9 20:30:39.860: INFO: StatefulSet ss has not reached scale 0, at 1
Dec  9 20:30:40.865: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.967122195s
Dec  9 20:30:41.869: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.962217778s
Dec  9 20:30:42.875: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.957266916s
Dec  9 20:30:43.879: INFO: Verifying statefulset ss doesn't scale past 0 for another 952.571729ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-8qb9k
Dec  9 20:30:44.895: INFO: Scaling statefulset ss to 0
Dec  9 20:30:44.914: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  9 20:30:44.922: INFO: Deleting all statefulset in ns e2e-tests-statefulset-8qb9k
Dec  9 20:30:44.930: INFO: Scaling statefulset ss to 0
Dec  9 20:30:44.951: INFO: Waiting for statefulset status.replicas updated to 0
Dec  9 20:30:44.959: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:30:44.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-8qb9k" for this suite.
Dec  9 20:30:51.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:30:51.082: INFO: namespace: e2e-tests-statefulset-8qb9k, resource: bindings, ignored listing per whitelist
Dec  9 20:30:51.169: INFO: namespace e2e-tests-statefulset-8qb9k deletion completed in 6.170462303s

• [SLOW TEST:58.154 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:30:51.169: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:30:51.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-b9jqm" for this suite.
Dec  9 20:30:57.300: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:30:57.372: INFO: namespace: e2e-tests-services-b9jqm, resource: bindings, ignored listing per whitelist
Dec  9 20:30:57.452: INFO: namespace e2e-tests-services-b9jqm deletion completed in 6.173023061s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:6.283 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:30:57.452: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Dec  9 20:30:57.565: INFO: Pod name pod-release: Found 0 pods out of 1
Dec  9 20:31:02.571: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:31:03.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-8lrff" for this suite.
Dec  9 20:31:09.624: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:31:09.768: INFO: namespace: e2e-tests-replication-controller-8lrff, resource: bindings, ignored listing per whitelist
Dec  9 20:31:09.778: INFO: namespace e2e-tests-replication-controller-8lrff deletion completed in 6.176961415s

• [SLOW TEST:12.327 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:31:09.779: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec  9 20:31:09.897: INFO: Waiting up to 5m0s for pod "pod-5ce1f57f-fbf1-11e8-8725-0a580af4034b" in namespace "e2e-tests-emptydir-wcnbd" to be "success or failure"
Dec  9 20:31:09.904: INFO: Pod "pod-5ce1f57f-fbf1-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.087395ms
Dec  9 20:31:11.909: INFO: Pod "pod-5ce1f57f-fbf1-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01203459s
STEP: Saw pod success
Dec  9 20:31:11.910: INFO: Pod "pod-5ce1f57f-fbf1-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 20:31:11.914: INFO: Trying to get logs from node k8s04 pod pod-5ce1f57f-fbf1-11e8-8725-0a580af4034b container test-container: <nil>
STEP: delete the pod
Dec  9 20:31:11.950: INFO: Waiting for pod pod-5ce1f57f-fbf1-11e8-8725-0a580af4034b to disappear
Dec  9 20:31:11.955: INFO: Pod pod-5ce1f57f-fbf1-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:31:11.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wcnbd" for this suite.
Dec  9 20:31:17.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:31:18.152: INFO: namespace: e2e-tests-emptydir-wcnbd, resource: bindings, ignored listing per whitelist
Dec  9 20:31:18.173: INFO: namespace e2e-tests-emptydir-wcnbd deletion completed in 6.209642468s

• [SLOW TEST:8.395 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:31:18.174: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-vn5x6/configmap-test-61e9f187-fbf1-11e8-8725-0a580af4034b
STEP: Creating a pod to test consume configMaps
Dec  9 20:31:18.347: INFO: Waiting up to 5m0s for pod "pod-configmaps-61eba511-fbf1-11e8-8725-0a580af4034b" in namespace "e2e-tests-configmap-vn5x6" to be "success or failure"
Dec  9 20:31:18.353: INFO: Pod "pod-configmaps-61eba511-fbf1-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.420478ms
Dec  9 20:31:20.359: INFO: Pod "pod-configmaps-61eba511-fbf1-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012027251s
STEP: Saw pod success
Dec  9 20:31:20.359: INFO: Pod "pod-configmaps-61eba511-fbf1-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 20:31:20.362: INFO: Trying to get logs from node k8s04 pod pod-configmaps-61eba511-fbf1-11e8-8725-0a580af4034b container env-test: <nil>
STEP: delete the pod
Dec  9 20:31:20.395: INFO: Waiting for pod pod-configmaps-61eba511-fbf1-11e8-8725-0a580af4034b to disappear
Dec  9 20:31:20.400: INFO: Pod pod-configmaps-61eba511-fbf1-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:31:20.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-vn5x6" for this suite.
Dec  9 20:31:26.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:31:26.473: INFO: namespace: e2e-tests-configmap-vn5x6, resource: bindings, ignored listing per whitelist
Dec  9 20:31:26.590: INFO: namespace e2e-tests-configmap-vn5x6 deletion completed in 6.181757145s

• [SLOW TEST:8.416 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:31:26.590: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec  9 20:31:26.707: INFO: Waiting up to 5m0s for pod "pod-66e6b2bf-fbf1-11e8-8725-0a580af4034b" in namespace "e2e-tests-emptydir-lqwbc" to be "success or failure"
Dec  9 20:31:26.715: INFO: Pod "pod-66e6b2bf-fbf1-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.990267ms
Dec  9 20:31:28.720: INFO: Pod "pod-66e6b2bf-fbf1-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01295932s
STEP: Saw pod success
Dec  9 20:31:28.720: INFO: Pod "pod-66e6b2bf-fbf1-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 20:31:28.724: INFO: Trying to get logs from node k8s04 pod pod-66e6b2bf-fbf1-11e8-8725-0a580af4034b container test-container: <nil>
STEP: delete the pod
Dec  9 20:31:28.760: INFO: Waiting for pod pod-66e6b2bf-fbf1-11e8-8725-0a580af4034b to disappear
Dec  9 20:31:28.765: INFO: Pod pod-66e6b2bf-fbf1-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:31:28.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-lqwbc" for this suite.
Dec  9 20:31:34.794: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:31:34.809: INFO: namespace: e2e-tests-emptydir-lqwbc, resource: bindings, ignored listing per whitelist
Dec  9 20:31:34.944: INFO: namespace e2e-tests-emptydir-lqwbc deletion completed in 6.170332087s

• [SLOW TEST:8.354 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:31:34.944: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  9 20:31:35.049: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6bdf789a-fbf1-11e8-8725-0a580af4034b" in namespace "e2e-tests-projected-45bg8" to be "success or failure"
Dec  9 20:31:35.055: INFO: Pod "downwardapi-volume-6bdf789a-fbf1-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.009018ms
Dec  9 20:31:37.068: INFO: Pod "downwardapi-volume-6bdf789a-fbf1-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01886216s
STEP: Saw pod success
Dec  9 20:31:37.068: INFO: Pod "downwardapi-volume-6bdf789a-fbf1-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 20:31:37.072: INFO: Trying to get logs from node k8s04 pod downwardapi-volume-6bdf789a-fbf1-11e8-8725-0a580af4034b container client-container: <nil>
STEP: delete the pod
Dec  9 20:31:37.107: INFO: Waiting for pod downwardapi-volume-6bdf789a-fbf1-11e8-8725-0a580af4034b to disappear
Dec  9 20:31:37.112: INFO: Pod downwardapi-volume-6bdf789a-fbf1-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:31:37.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-45bg8" for this suite.
Dec  9 20:31:43.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:31:43.216: INFO: namespace: e2e-tests-projected-45bg8, resource: bindings, ignored listing per whitelist
Dec  9 20:31:43.297: INFO: namespace e2e-tests-projected-45bg8 deletion completed in 6.177255674s

• [SLOW TEST:8.353 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:31:43.298: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec  9 20:31:43.412: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:31:45.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-msfm9" for this suite.
Dec  9 20:31:51.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:31:51.620: INFO: namespace: e2e-tests-init-container-msfm9, resource: bindings, ignored listing per whitelist
Dec  9 20:31:51.719: INFO: namespace e2e-tests-init-container-msfm9 deletion completed in 6.176691768s

• [SLOW TEST:8.421 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:31:51.719: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1209 20:32:01.908043      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  9 20:32:01.908: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:32:01.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-b69z6" for this suite.
Dec  9 20:32:09.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:32:10.075: INFO: namespace: e2e-tests-gc-b69z6, resource: bindings, ignored listing per whitelist
Dec  9 20:32:10.091: INFO: namespace e2e-tests-gc-b69z6 deletion completed in 8.169621925s

• [SLOW TEST:18.372 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:32:10.092: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Dec  9 20:32:14.261: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-kwrf7 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  9 20:32:14.261: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
Dec  9 20:32:14.385: INFO: Exec stderr: ""
Dec  9 20:32:14.385: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-kwrf7 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  9 20:32:14.385: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
Dec  9 20:32:14.503: INFO: Exec stderr: ""
Dec  9 20:32:14.503: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-kwrf7 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  9 20:32:14.503: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
Dec  9 20:32:14.627: INFO: Exec stderr: ""
Dec  9 20:32:14.627: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-kwrf7 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  9 20:32:14.627: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
Dec  9 20:32:14.751: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Dec  9 20:32:14.751: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-kwrf7 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  9 20:32:14.751: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
Dec  9 20:32:14.866: INFO: Exec stderr: ""
Dec  9 20:32:14.866: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-kwrf7 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  9 20:32:14.866: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
Dec  9 20:32:14.971: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Dec  9 20:32:14.971: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-kwrf7 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  9 20:32:14.971: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
Dec  9 20:32:15.076: INFO: Exec stderr: ""
Dec  9 20:32:15.076: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-kwrf7 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  9 20:32:15.076: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
Dec  9 20:32:15.189: INFO: Exec stderr: ""
Dec  9 20:32:15.189: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-kwrf7 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  9 20:32:15.189: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
Dec  9 20:32:15.299: INFO: Exec stderr: ""
Dec  9 20:32:15.299: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-kwrf7 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  9 20:32:15.299: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
Dec  9 20:32:15.421: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:32:15.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-kwrf7" for this suite.
Dec  9 20:33:01.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:33:01.503: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-kwrf7, resource: bindings, ignored listing per whitelist
Dec  9 20:33:01.597: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-kwrf7 deletion completed in 46.171470244s

• [SLOW TEST:51.505 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:33:01.597: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W1209 20:33:32.303822      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  9 20:33:32.303: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:33:32.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-kbkw5" for this suite.
Dec  9 20:33:38.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:33:38.390: INFO: namespace: e2e-tests-gc-kbkw5, resource: bindings, ignored listing per whitelist
Dec  9 20:33:38.484: INFO: namespace e2e-tests-gc-kbkw5 deletion completed in 6.171525326s

• [SLOW TEST:36.887 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:33:38.484: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-b5844055-fbf1-11e8-8725-0a580af4034b
STEP: Creating a pod to test consume configMaps
Dec  9 20:33:38.610: INFO: Waiting up to 5m0s for pod "pod-configmaps-b586308b-fbf1-11e8-8725-0a580af4034b" in namespace "e2e-tests-configmap-vvrkf" to be "success or failure"
Dec  9 20:33:38.617: INFO: Pod "pod-configmaps-b586308b-fbf1-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.747764ms
Dec  9 20:33:40.622: INFO: Pod "pod-configmaps-b586308b-fbf1-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011428917s
STEP: Saw pod success
Dec  9 20:33:40.622: INFO: Pod "pod-configmaps-b586308b-fbf1-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 20:33:40.626: INFO: Trying to get logs from node k8s04 pod pod-configmaps-b586308b-fbf1-11e8-8725-0a580af4034b container configmap-volume-test: <nil>
STEP: delete the pod
Dec  9 20:33:40.661: INFO: Waiting for pod pod-configmaps-b586308b-fbf1-11e8-8725-0a580af4034b to disappear
Dec  9 20:33:40.670: INFO: Pod pod-configmaps-b586308b-fbf1-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:33:40.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-vvrkf" for this suite.
Dec  9 20:33:46.739: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:33:46.890: INFO: namespace: e2e-tests-configmap-vvrkf, resource: bindings, ignored listing per whitelist
Dec  9 20:33:46.895: INFO: namespace e2e-tests-configmap-vvrkf deletion completed in 6.217930931s

• [SLOW TEST:8.411 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:33:46.895: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  9 20:33:46.994: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:33:49.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-ztvwx" for this suite.
Dec  9 20:34:33.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:34:33.241: INFO: namespace: e2e-tests-pods-ztvwx, resource: bindings, ignored listing per whitelist
Dec  9 20:34:33.314: INFO: namespace e2e-tests-pods-ztvwx deletion completed in 44.169762779s

• [SLOW TEST:46.418 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:34:33.314: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-d632524e-fbf1-11e8-8725-0a580af4034b
STEP: Creating a pod to test consume secrets
Dec  9 20:34:33.442: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d63435b2-fbf1-11e8-8725-0a580af4034b" in namespace "e2e-tests-projected-rbbqg" to be "success or failure"
Dec  9 20:34:33.449: INFO: Pod "pod-projected-secrets-d63435b2-fbf1-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.082114ms
Dec  9 20:34:35.454: INFO: Pod "pod-projected-secrets-d63435b2-fbf1-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012433974s
STEP: Saw pod success
Dec  9 20:34:35.454: INFO: Pod "pod-projected-secrets-d63435b2-fbf1-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 20:34:35.459: INFO: Trying to get logs from node k8s04 pod pod-projected-secrets-d63435b2-fbf1-11e8-8725-0a580af4034b container secret-volume-test: <nil>
STEP: delete the pod
Dec  9 20:34:35.494: INFO: Waiting for pod pod-projected-secrets-d63435b2-fbf1-11e8-8725-0a580af4034b to disappear
Dec  9 20:34:35.499: INFO: Pod pod-projected-secrets-d63435b2-fbf1-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:34:35.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rbbqg" for this suite.
Dec  9 20:34:41.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:34:41.595: INFO: namespace: e2e-tests-projected-rbbqg, resource: bindings, ignored listing per whitelist
Dec  9 20:34:41.677: INFO: namespace e2e-tests-projected-rbbqg deletion completed in 6.172084994s

• [SLOW TEST:8.363 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:34:41.677: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec  9 20:34:44.326: INFO: Successfully updated pod "labelsupdatedb2e17e7-fbf1-11e8-8725-0a580af4034b"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:34:48.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-h2j4h" for this suite.
Dec  9 20:35:10.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:35:10.504: INFO: namespace: e2e-tests-projected-h2j4h, resource: bindings, ignored listing per whitelist
Dec  9 20:35:10.544: INFO: namespace e2e-tests-projected-h2j4h deletion completed in 22.177664458s

• [SLOW TEST:28.867 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:35:10.544: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec  9 20:35:14.715: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  9 20:35:14.719: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  9 20:35:16.720: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  9 20:35:16.724: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  9 20:35:18.720: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  9 20:35:18.724: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  9 20:35:20.720: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  9 20:35:20.724: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  9 20:35:22.720: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  9 20:35:22.733: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  9 20:35:24.720: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  9 20:35:24.725: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  9 20:35:26.720: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  9 20:35:26.724: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  9 20:35:28.720: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  9 20:35:28.725: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  9 20:35:30.720: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  9 20:35:30.724: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  9 20:35:32.720: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  9 20:35:32.725: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  9 20:35:34.720: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  9 20:35:34.737: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:35:34.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-x4z5b" for this suite.
Dec  9 20:35:56.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:35:56.947: INFO: namespace: e2e-tests-container-lifecycle-hook-x4z5b, resource: bindings, ignored listing per whitelist
Dec  9 20:35:56.951: INFO: namespace e2e-tests-container-lifecycle-hook-x4z5b deletion completed in 22.19459064s

• [SLOW TEST:46.407 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:35:56.952: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  9 20:35:57.054: INFO: Creating ReplicaSet my-hostname-basic-080d4a2f-fbf2-11e8-8725-0a580af4034b
Dec  9 20:35:57.074: INFO: Pod name my-hostname-basic-080d4a2f-fbf2-11e8-8725-0a580af4034b: Found 0 pods out of 1
Dec  9 20:36:02.080: INFO: Pod name my-hostname-basic-080d4a2f-fbf2-11e8-8725-0a580af4034b: Found 1 pods out of 1
Dec  9 20:36:02.080: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-080d4a2f-fbf2-11e8-8725-0a580af4034b" is running
Dec  9 20:36:02.084: INFO: Pod "my-hostname-basic-080d4a2f-fbf2-11e8-8725-0a580af4034b-pd546" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-09 20:35:57 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-09 20:35:58 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-09 20:35:58 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-09 20:35:57 +0000 UTC Reason: Message:}])
Dec  9 20:36:02.084: INFO: Trying to dial the pod
Dec  9 20:36:07.106: INFO: Controller my-hostname-basic-080d4a2f-fbf2-11e8-8725-0a580af4034b: Got expected result from replica 1 [my-hostname-basic-080d4a2f-fbf2-11e8-8725-0a580af4034b-pd546]: "my-hostname-basic-080d4a2f-fbf2-11e8-8725-0a580af4034b-pd546", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:36:07.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-lcqdj" for this suite.
Dec  9 20:36:13.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:36:13.211: INFO: namespace: e2e-tests-replicaset-lcqdj, resource: bindings, ignored listing per whitelist
Dec  9 20:36:13.280: INFO: namespace e2e-tests-replicaset-lcqdj deletion completed in 6.166311598s

• [SLOW TEST:16.328 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:36:13.280: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  9 20:36:13.378: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-x77p6'
Dec  9 20:36:13.496: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  9 20:36:13.496: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Dec  9 20:36:13.513: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-8p888]
Dec  9 20:36:13.513: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-8p888" in namespace "e2e-tests-kubectl-x77p6" to be "running and ready"
Dec  9 20:36:13.519: INFO: Pod "e2e-test-nginx-rc-8p888": Phase="Pending", Reason="", readiness=false. Elapsed: 6.890116ms
Dec  9 20:36:15.528: INFO: Pod "e2e-test-nginx-rc-8p888": Phase="Running", Reason="", readiness=true. Elapsed: 2.01554378s
Dec  9 20:36:15.528: INFO: Pod "e2e-test-nginx-rc-8p888" satisfied condition "running and ready"
Dec  9 20:36:15.528: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-8p888]
Dec  9 20:36:15.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-x77p6'
Dec  9 20:36:15.645: INFO: stderr: ""
Dec  9 20:36:15.645: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Dec  9 20:36:15.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-x77p6'
Dec  9 20:36:15.732: INFO: stderr: ""
Dec  9 20:36:15.732: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:36:15.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-x77p6" for this suite.
Dec  9 20:36:21.760: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:36:21.843: INFO: namespace: e2e-tests-kubectl-x77p6, resource: bindings, ignored listing per whitelist
Dec  9 20:36:21.915: INFO: namespace e2e-tests-kubectl-x77p6 deletion completed in 6.176399521s

• [SLOW TEST:8.635 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:36:21.915: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec  9 20:36:24.552: INFO: Successfully updated pod "pod-update-activedeadlineseconds-16ebaf91-fbf2-11e8-8725-0a580af4034b"
Dec  9 20:36:24.552: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-16ebaf91-fbf2-11e8-8725-0a580af4034b" in namespace "e2e-tests-pods-7lmkk" to be "terminated due to deadline exceeded"
Dec  9 20:36:24.557: INFO: Pod "pod-update-activedeadlineseconds-16ebaf91-fbf2-11e8-8725-0a580af4034b": Phase="Running", Reason="", readiness=true. Elapsed: 4.379864ms
Dec  9 20:36:26.562: INFO: Pod "pod-update-activedeadlineseconds-16ebaf91-fbf2-11e8-8725-0a580af4034b": Phase="Running", Reason="", readiness=true. Elapsed: 2.009893413s
Dec  9 20:36:28.577: INFO: Pod "pod-update-activedeadlineseconds-16ebaf91-fbf2-11e8-8725-0a580af4034b": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.024150491s
Dec  9 20:36:28.577: INFO: Pod "pod-update-activedeadlineseconds-16ebaf91-fbf2-11e8-8725-0a580af4034b" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:36:28.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-7lmkk" for this suite.
Dec  9 20:36:34.598: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:36:34.676: INFO: namespace: e2e-tests-pods-7lmkk, resource: bindings, ignored listing per whitelist
Dec  9 20:36:34.763: INFO: namespace e2e-tests-pods-7lmkk deletion completed in 6.180843915s

• [SLOW TEST:12.848 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:36:34.763: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-1e95d223-fbf2-11e8-8725-0a580af4034b
STEP: Creating a pod to test consume secrets
Dec  9 20:36:34.904: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1e99a956-fbf2-11e8-8725-0a580af4034b" in namespace "e2e-tests-projected-w4rkj" to be "success or failure"
Dec  9 20:36:34.914: INFO: Pod "pod-projected-secrets-1e99a956-fbf2-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.341233ms
Dec  9 20:36:36.919: INFO: Pod "pod-projected-secrets-1e99a956-fbf2-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014498375s
STEP: Saw pod success
Dec  9 20:36:36.919: INFO: Pod "pod-projected-secrets-1e99a956-fbf2-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 20:36:36.923: INFO: Trying to get logs from node k8s04 pod pod-projected-secrets-1e99a956-fbf2-11e8-8725-0a580af4034b container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  9 20:36:36.951: INFO: Waiting for pod pod-projected-secrets-1e99a956-fbf2-11e8-8725-0a580af4034b to disappear
Dec  9 20:36:36.958: INFO: Pod pod-projected-secrets-1e99a956-fbf2-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:36:36.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-w4rkj" for this suite.
Dec  9 20:36:42.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:36:43.122: INFO: namespace: e2e-tests-projected-w4rkj, resource: bindings, ignored listing per whitelist
Dec  9 20:36:43.140: INFO: namespace e2e-tests-projected-w4rkj deletion completed in 6.16927442s

• [SLOW TEST:8.377 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:36:43.140: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-2394ac90-fbf2-11e8-8725-0a580af4034b
STEP: Creating configMap with name cm-test-opt-upd-2394acd2-fbf2-11e8-8725-0a580af4034b
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-2394ac90-fbf2-11e8-8725-0a580af4034b
STEP: Updating configmap cm-test-opt-upd-2394acd2-fbf2-11e8-8725-0a580af4034b
STEP: Creating configMap with name cm-test-opt-create-2394ace9-fbf2-11e8-8725-0a580af4034b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:36:47.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9nmhl" for this suite.
Dec  9 20:37:09.404: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:37:09.515: INFO: namespace: e2e-tests-projected-9nmhl, resource: bindings, ignored listing per whitelist
Dec  9 20:37:09.558: INFO: namespace e2e-tests-projected-9nmhl deletion completed in 22.170300867s

• [SLOW TEST:26.418 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:37:09.558: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-335287d8-fbf2-11e8-8725-0a580af4034b
STEP: Creating a pod to test consume configMaps
Dec  9 20:37:09.676: INFO: Waiting up to 5m0s for pod "pod-configmaps-33544ca5-fbf2-11e8-8725-0a580af4034b" in namespace "e2e-tests-configmap-qzgzw" to be "success or failure"
Dec  9 20:37:09.684: INFO: Pod "pod-configmaps-33544ca5-fbf2-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.306785ms
Dec  9 20:37:11.697: INFO: Pod "pod-configmaps-33544ca5-fbf2-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020548929s
STEP: Saw pod success
Dec  9 20:37:11.697: INFO: Pod "pod-configmaps-33544ca5-fbf2-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 20:37:11.702: INFO: Trying to get logs from node k8s04 pod pod-configmaps-33544ca5-fbf2-11e8-8725-0a580af4034b container configmap-volume-test: <nil>
STEP: delete the pod
Dec  9 20:37:11.727: INFO: Waiting for pod pod-configmaps-33544ca5-fbf2-11e8-8725-0a580af4034b to disappear
Dec  9 20:37:11.735: INFO: Pod pod-configmaps-33544ca5-fbf2-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:37:11.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-qzgzw" for this suite.
Dec  9 20:37:17.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:37:17.841: INFO: namespace: e2e-tests-configmap-qzgzw, resource: bindings, ignored listing per whitelist
Dec  9 20:37:17.937: INFO: namespace e2e-tests-configmap-qzgzw deletion completed in 6.192747878s

• [SLOW TEST:8.379 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:37:17.937: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  9 20:37:18.048: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Dec  9 20:37:18.067: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:18.067: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:18.067: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:18.073: INFO: Number of nodes with available pods: 0
Dec  9 20:37:18.073: INFO: Node k8s04 is running more than one daemon pod
Dec  9 20:37:19.080: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:19.080: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:19.080: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:19.086: INFO: Number of nodes with available pods: 0
Dec  9 20:37:19.086: INFO: Node k8s04 is running more than one daemon pod
Dec  9 20:37:20.079: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:20.080: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:20.080: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:20.083: INFO: Number of nodes with available pods: 1
Dec  9 20:37:20.083: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Dec  9 20:37:20.120: INFO: Wrong image for pod: daemon-set-d6qrz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  9 20:37:20.127: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:20.127: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:20.127: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:21.132: INFO: Wrong image for pod: daemon-set-d6qrz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  9 20:37:21.137: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:21.138: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:21.138: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:22.138: INFO: Wrong image for pod: daemon-set-d6qrz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  9 20:37:22.144: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:22.144: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:22.144: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:23.132: INFO: Wrong image for pod: daemon-set-d6qrz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  9 20:37:23.137: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:23.137: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:23.137: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:24.132: INFO: Wrong image for pod: daemon-set-d6qrz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  9 20:37:24.137: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:24.137: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:24.137: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:25.131: INFO: Wrong image for pod: daemon-set-d6qrz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  9 20:37:25.136: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:25.136: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:25.136: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:26.133: INFO: Wrong image for pod: daemon-set-d6qrz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  9 20:37:26.139: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:26.139: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:26.139: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:27.132: INFO: Wrong image for pod: daemon-set-d6qrz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  9 20:37:27.137: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:27.137: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:27.137: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:28.132: INFO: Wrong image for pod: daemon-set-d6qrz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  9 20:37:28.138: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:28.138: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:28.138: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:29.132: INFO: Wrong image for pod: daemon-set-d6qrz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  9 20:37:29.137: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:29.137: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:29.137: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:30.131: INFO: Wrong image for pod: daemon-set-d6qrz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  9 20:37:30.137: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:30.137: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:30.137: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:31.131: INFO: Wrong image for pod: daemon-set-d6qrz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  9 20:37:31.136: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:31.136: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:31.136: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:32.132: INFO: Wrong image for pod: daemon-set-d6qrz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  9 20:37:32.137: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:32.137: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:32.137: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:33.138: INFO: Wrong image for pod: daemon-set-d6qrz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  9 20:37:33.143: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:33.143: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:33.143: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:34.132: INFO: Wrong image for pod: daemon-set-d6qrz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  9 20:37:34.138: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:34.138: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:34.138: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:35.132: INFO: Wrong image for pod: daemon-set-d6qrz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  9 20:37:35.137: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:35.137: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:35.137: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:36.132: INFO: Wrong image for pod: daemon-set-d6qrz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  9 20:37:36.137: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:36.137: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:36.137: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:37.131: INFO: Wrong image for pod: daemon-set-d6qrz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  9 20:37:37.137: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:37.137: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:37.137: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:38.132: INFO: Wrong image for pod: daemon-set-d6qrz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  9 20:37:38.138: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:38.138: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:38.138: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:39.132: INFO: Wrong image for pod: daemon-set-d6qrz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  9 20:37:39.138: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:39.138: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:39.138: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:40.131: INFO: Wrong image for pod: daemon-set-d6qrz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  9 20:37:40.137: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:40.137: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:40.137: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:41.132: INFO: Wrong image for pod: daemon-set-d6qrz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  9 20:37:41.138: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:41.138: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:41.138: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:42.132: INFO: Wrong image for pod: daemon-set-d6qrz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  9 20:37:42.136: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:42.136: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:42.137: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:43.131: INFO: Wrong image for pod: daemon-set-d6qrz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  9 20:37:43.136: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:43.136: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:43.136: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:44.139: INFO: Wrong image for pod: daemon-set-d6qrz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  9 20:37:44.144: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:44.144: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:44.144: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:45.132: INFO: Wrong image for pod: daemon-set-d6qrz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  9 20:37:45.137: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:45.137: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:45.137: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:46.132: INFO: Wrong image for pod: daemon-set-d6qrz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  9 20:37:46.137: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:46.137: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:46.137: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:47.132: INFO: Wrong image for pod: daemon-set-d6qrz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  9 20:37:47.137: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:47.137: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:47.137: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:48.132: INFO: Wrong image for pod: daemon-set-d6qrz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  9 20:37:48.137: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:48.137: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:48.137: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:49.132: INFO: Wrong image for pod: daemon-set-d6qrz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  9 20:37:49.137: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:49.137: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:49.137: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:50.132: INFO: Wrong image for pod: daemon-set-d6qrz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  9 20:37:50.136: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:50.136: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:50.136: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:51.131: INFO: Wrong image for pod: daemon-set-d6qrz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  9 20:37:51.138: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:51.138: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:51.138: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:52.132: INFO: Wrong image for pod: daemon-set-d6qrz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  9 20:37:52.137: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:52.137: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:52.137: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:53.131: INFO: Wrong image for pod: daemon-set-d6qrz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  9 20:37:53.131: INFO: Pod daemon-set-d6qrz is not available
Dec  9 20:37:53.138: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:53.138: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:53.138: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:54.132: INFO: Wrong image for pod: daemon-set-d6qrz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  9 20:37:54.132: INFO: Pod daemon-set-d6qrz is not available
Dec  9 20:37:54.137: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:54.137: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:54.137: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:55.140: INFO: Wrong image for pod: daemon-set-d6qrz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  9 20:37:55.140: INFO: Pod daemon-set-d6qrz is not available
Dec  9 20:37:55.146: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:55.146: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:55.146: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:56.132: INFO: Wrong image for pod: daemon-set-d6qrz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  9 20:37:56.132: INFO: Pod daemon-set-d6qrz is not available
Dec  9 20:37:56.137: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:56.137: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:56.137: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:57.131: INFO: Wrong image for pod: daemon-set-d6qrz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  9 20:37:57.132: INFO: Pod daemon-set-d6qrz is not available
Dec  9 20:37:57.137: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:57.137: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:57.137: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:58.131: INFO: Wrong image for pod: daemon-set-d6qrz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  9 20:37:58.131: INFO: Pod daemon-set-d6qrz is not available
Dec  9 20:37:58.136: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:58.136: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:58.136: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:59.132: INFO: Wrong image for pod: daemon-set-d6qrz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  9 20:37:59.132: INFO: Pod daemon-set-d6qrz is not available
Dec  9 20:37:59.137: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:59.137: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:37:59.137: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:38:00.132: INFO: Wrong image for pod: daemon-set-d6qrz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  9 20:38:00.132: INFO: Pod daemon-set-d6qrz is not available
Dec  9 20:38:00.137: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:38:00.137: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:38:00.137: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:38:01.133: INFO: Pod daemon-set-zjswq is not available
Dec  9 20:38:01.138: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:38:01.138: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:38:01.138: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Dec  9 20:38:01.144: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:38:01.145: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:38:01.145: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:38:01.150: INFO: Number of nodes with available pods: 0
Dec  9 20:38:01.150: INFO: Node k8s04 is running more than one daemon pod
Dec  9 20:38:02.156: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:38:02.156: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:38:02.156: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:38:02.161: INFO: Number of nodes with available pods: 1
Dec  9 20:38:02.161: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-ftxsd, will wait for the garbage collector to delete the pods
Dec  9 20:38:02.253: INFO: Deleting DaemonSet.extensions daemon-set took: 13.107619ms
Dec  9 20:38:02.695: INFO: Terminating DaemonSet.extensions daemon-set pods took: 442.136097ms
Dec  9 20:38:10.706: INFO: Number of nodes with available pods: 0
Dec  9 20:38:10.706: INFO: Number of running nodes: 0, number of available pods: 0
Dec  9 20:38:10.709: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-ftxsd/daemonsets","resourceVersion":"40954"},"items":null}

Dec  9 20:38:10.717: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-ftxsd/pods","resourceVersion":"40954"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:38:10.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-ftxsd" for this suite.
Dec  9 20:38:16.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:38:16.775: INFO: namespace: e2e-tests-daemonsets-ftxsd, resource: bindings, ignored listing per whitelist
Dec  9 20:38:16.916: INFO: namespace e2e-tests-daemonsets-ftxsd deletion completed in 6.179237706s

• [SLOW TEST:58.978 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:38:16.916: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec  9 20:38:17.037: INFO: Waiting up to 5m0s for pod "pod-5b7a21a0-fbf2-11e8-8725-0a580af4034b" in namespace "e2e-tests-emptydir-msxgq" to be "success or failure"
Dec  9 20:38:17.044: INFO: Pod "pod-5b7a21a0-fbf2-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.464489ms
Dec  9 20:38:19.049: INFO: Pod "pod-5b7a21a0-fbf2-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011457617s
STEP: Saw pod success
Dec  9 20:38:19.049: INFO: Pod "pod-5b7a21a0-fbf2-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 20:38:19.053: INFO: Trying to get logs from node k8s04 pod pod-5b7a21a0-fbf2-11e8-8725-0a580af4034b container test-container: <nil>
STEP: delete the pod
Dec  9 20:38:19.087: INFO: Waiting for pod pod-5b7a21a0-fbf2-11e8-8725-0a580af4034b to disappear
Dec  9 20:38:19.101: INFO: Pod pod-5b7a21a0-fbf2-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:38:19.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-msxgq" for this suite.
Dec  9 20:38:25.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:38:25.223: INFO: namespace: e2e-tests-emptydir-msxgq, resource: bindings, ignored listing per whitelist
Dec  9 20:38:25.282: INFO: namespace e2e-tests-emptydir-msxgq deletion completed in 6.172345314s

• [SLOW TEST:8.366 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:38:25.282: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  9 20:38:25.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-t9jnx'
Dec  9 20:38:25.602: INFO: stderr: ""
Dec  9 20:38:25.602: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Dec  9 20:38:25.608: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-t9jnx'
Dec  9 20:38:30.693: INFO: stderr: ""
Dec  9 20:38:30.693: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:38:30.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-t9jnx" for this suite.
Dec  9 20:38:36.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:38:36.858: INFO: namespace: e2e-tests-kubectl-t9jnx, resource: bindings, ignored listing per whitelist
Dec  9 20:38:36.878: INFO: namespace e2e-tests-kubectl-t9jnx deletion completed in 6.178150234s

• [SLOW TEST:11.596 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:38:36.878: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Dec  9 20:38:36.998: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-rzp7p" to be "success or failure"
Dec  9 20:38:37.005: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 7.122606ms
Dec  9 20:38:39.012: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013738214s
STEP: Saw pod success
Dec  9 20:38:39.012: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Dec  9 20:38:39.017: INFO: Trying to get logs from node k8s04 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Dec  9 20:38:39.054: INFO: Waiting for pod pod-host-path-test to disappear
Dec  9 20:38:39.060: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:38:39.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-rzp7p" for this suite.
Dec  9 20:38:45.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:38:45.153: INFO: namespace: e2e-tests-hostpath-rzp7p, resource: bindings, ignored listing per whitelist
Dec  9 20:38:45.242: INFO: namespace e2e-tests-hostpath-rzp7p deletion completed in 6.172158211s

• [SLOW TEST:8.364 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:38:45.242: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  9 20:38:45.362: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6c5b8231-fbf2-11e8-8725-0a580af4034b" in namespace "e2e-tests-downward-api-nd6tz" to be "success or failure"
Dec  9 20:38:45.371: INFO: Pod "downwardapi-volume-6c5b8231-fbf2-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.672885ms
Dec  9 20:38:47.376: INFO: Pod "downwardapi-volume-6c5b8231-fbf2-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013600227s
STEP: Saw pod success
Dec  9 20:38:47.376: INFO: Pod "downwardapi-volume-6c5b8231-fbf2-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 20:38:47.380: INFO: Trying to get logs from node k8s04 pod downwardapi-volume-6c5b8231-fbf2-11e8-8725-0a580af4034b container client-container: <nil>
STEP: delete the pod
Dec  9 20:38:47.415: INFO: Waiting for pod downwardapi-volume-6c5b8231-fbf2-11e8-8725-0a580af4034b to disappear
Dec  9 20:38:47.422: INFO: Pod downwardapi-volume-6c5b8231-fbf2-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:38:47.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-nd6tz" for this suite.
Dec  9 20:38:53.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:38:53.473: INFO: namespace: e2e-tests-downward-api-nd6tz, resource: bindings, ignored listing per whitelist
Dec  9 20:38:53.614: INFO: namespace e2e-tests-downward-api-nd6tz deletion completed in 6.183522355s

• [SLOW TEST:8.372 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:38:53.614: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec  9 20:38:53.709: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:38:57.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-cjnxs" for this suite.
Dec  9 20:39:19.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:39:19.494: INFO: namespace: e2e-tests-init-container-cjnxs, resource: bindings, ignored listing per whitelist
Dec  9 20:39:19.613: INFO: namespace e2e-tests-init-container-cjnxs deletion completed in 22.170339417s

• [SLOW TEST:25.999 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:39:19.614: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-80da8c0e-fbf2-11e8-8725-0a580af4034b
STEP: Creating secret with name s-test-opt-upd-80da8c54-fbf2-11e8-8725-0a580af4034b
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-80da8c0e-fbf2-11e8-8725-0a580af4034b
STEP: Updating secret s-test-opt-upd-80da8c54-fbf2-11e8-8725-0a580af4034b
STEP: Creating secret with name s-test-opt-create-80da8c64-fbf2-11e8-8725-0a580af4034b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:40:52.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-k9dnq" for this suite.
Dec  9 20:41:14.510: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:41:14.625: INFO: namespace: e2e-tests-projected-k9dnq, resource: bindings, ignored listing per whitelist
Dec  9 20:41:14.660: INFO: namespace e2e-tests-projected-k9dnq deletion completed in 22.171436858s

• [SLOW TEST:115.046 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:41:14.660: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-v9zl
STEP: Creating a pod to test atomic-volume-subpath
Dec  9 20:41:14.811: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-v9zl" in namespace "e2e-tests-subpath-qftfl" to be "success or failure"
Dec  9 20:41:14.820: INFO: Pod "pod-subpath-test-configmap-v9zl": Phase="Pending", Reason="", readiness=false. Elapsed: 8.705211ms
Dec  9 20:41:16.826: INFO: Pod "pod-subpath-test-configmap-v9zl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014572422s
Dec  9 20:41:18.837: INFO: Pod "pod-subpath-test-configmap-v9zl": Phase="Running", Reason="", readiness=false. Elapsed: 4.025333463s
Dec  9 20:41:20.842: INFO: Pod "pod-subpath-test-configmap-v9zl": Phase="Running", Reason="", readiness=false. Elapsed: 6.030555613s
Dec  9 20:41:22.847: INFO: Pod "pod-subpath-test-configmap-v9zl": Phase="Running", Reason="", readiness=false. Elapsed: 8.035342769s
Dec  9 20:41:24.852: INFO: Pod "pod-subpath-test-configmap-v9zl": Phase="Running", Reason="", readiness=false. Elapsed: 10.040132611s
Dec  9 20:41:26.857: INFO: Pod "pod-subpath-test-configmap-v9zl": Phase="Running", Reason="", readiness=false. Elapsed: 12.04513096s
Dec  9 20:41:28.868: INFO: Pod "pod-subpath-test-configmap-v9zl": Phase="Running", Reason="", readiness=false. Elapsed: 14.056970912s
Dec  9 20:41:30.873: INFO: Pod "pod-subpath-test-configmap-v9zl": Phase="Running", Reason="", readiness=false. Elapsed: 16.061952322s
Dec  9 20:41:32.878: INFO: Pod "pod-subpath-test-configmap-v9zl": Phase="Running", Reason="", readiness=false. Elapsed: 18.066816302s
Dec  9 20:41:34.884: INFO: Pod "pod-subpath-test-configmap-v9zl": Phase="Running", Reason="", readiness=false. Elapsed: 20.072791016s
Dec  9 20:41:36.889: INFO: Pod "pod-subpath-test-configmap-v9zl": Phase="Running", Reason="", readiness=false. Elapsed: 22.077160595s
Dec  9 20:41:38.900: INFO: Pod "pod-subpath-test-configmap-v9zl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.088832844s
STEP: Saw pod success
Dec  9 20:41:38.900: INFO: Pod "pod-subpath-test-configmap-v9zl" satisfied condition "success or failure"
Dec  9 20:41:38.905: INFO: Trying to get logs from node k8s04 pod pod-subpath-test-configmap-v9zl container test-container-subpath-configmap-v9zl: <nil>
STEP: delete the pod
Dec  9 20:41:38.942: INFO: Waiting for pod pod-subpath-test-configmap-v9zl to disappear
Dec  9 20:41:38.948: INFO: Pod pod-subpath-test-configmap-v9zl no longer exists
STEP: Deleting pod pod-subpath-test-configmap-v9zl
Dec  9 20:41:38.948: INFO: Deleting pod "pod-subpath-test-configmap-v9zl" in namespace "e2e-tests-subpath-qftfl"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:41:38.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-qftfl" for this suite.
Dec  9 20:41:44.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:41:45.008: INFO: namespace: e2e-tests-subpath-qftfl, resource: bindings, ignored listing per whitelist
Dec  9 20:41:45.161: INFO: namespace e2e-tests-subpath-qftfl deletion completed in 6.193960925s

• [SLOW TEST:30.501 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:41:45.161: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-4k2c8
Dec  9 20:41:47.284: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-4k2c8
STEP: checking the pod's current state and verifying that restartCount is present
Dec  9 20:41:47.289: INFO: Initial restart count of pod liveness-http is 0
Dec  9 20:42:05.364: INFO: Restart count of pod e2e-tests-container-probe-4k2c8/liveness-http is now 1 (18.075123346s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:42:05.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-4k2c8" for this suite.
Dec  9 20:42:11.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:42:11.511: INFO: namespace: e2e-tests-container-probe-4k2c8, resource: bindings, ignored listing per whitelist
Dec  9 20:42:11.559: INFO: namespace e2e-tests-container-probe-4k2c8 deletion completed in 6.172292312s

• [SLOW TEST:26.398 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:42:11.559: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  9 20:42:11.676: INFO: (0) /api/v1/nodes/k8s04/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 12.197075ms)
Dec  9 20:42:11.685: INFO: (1) /api/v1/nodes/k8s04/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.62098ms)
Dec  9 20:42:11.694: INFO: (2) /api/v1/nodes/k8s04/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.503917ms)
Dec  9 20:42:11.703: INFO: (3) /api/v1/nodes/k8s04/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.269962ms)
Dec  9 20:42:11.711: INFO: (4) /api/v1/nodes/k8s04/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.999818ms)
Dec  9 20:42:11.719: INFO: (5) /api/v1/nodes/k8s04/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.184753ms)
Dec  9 20:42:11.727: INFO: (6) /api/v1/nodes/k8s04/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.880954ms)
Dec  9 20:42:11.733: INFO: (7) /api/v1/nodes/k8s04/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.312261ms)
Dec  9 20:42:11.741: INFO: (8) /api/v1/nodes/k8s04/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.410372ms)
Dec  9 20:42:11.750: INFO: (9) /api/v1/nodes/k8s04/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.811336ms)
Dec  9 20:42:11.757: INFO: (10) /api/v1/nodes/k8s04/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.854483ms)
Dec  9 20:42:11.765: INFO: (11) /api/v1/nodes/k8s04/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.737291ms)
Dec  9 20:42:11.772: INFO: (12) /api/v1/nodes/k8s04/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.538565ms)
Dec  9 20:42:11.779: INFO: (13) /api/v1/nodes/k8s04/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.137492ms)
Dec  9 20:42:11.787: INFO: (14) /api/v1/nodes/k8s04/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.349574ms)
Dec  9 20:42:11.794: INFO: (15) /api/v1/nodes/k8s04/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.615052ms)
Dec  9 20:42:11.804: INFO: (16) /api/v1/nodes/k8s04/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.841028ms)
Dec  9 20:42:11.813: INFO: (17) /api/v1/nodes/k8s04/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.709803ms)
Dec  9 20:42:11.820: INFO: (18) /api/v1/nodes/k8s04/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.979412ms)
Dec  9 20:42:11.830: INFO: (19) /api/v1/nodes/k8s04/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 10.159762ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:42:11.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-vtjkr" for this suite.
Dec  9 20:42:17.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:42:17.996: INFO: namespace: e2e-tests-proxy-vtjkr, resource: bindings, ignored listing per whitelist
Dec  9 20:42:18.010: INFO: namespace e2e-tests-proxy-vtjkr deletion completed in 6.173693153s

• [SLOW TEST:6.451 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:42:18.010: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Dec  9 20:42:18.105: INFO: namespace e2e-tests-kubectl-z5xpv
Dec  9 20:42:18.105: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 create -f - --namespace=e2e-tests-kubectl-z5xpv'
Dec  9 20:42:18.448: INFO: stderr: ""
Dec  9 20:42:18.448: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  9 20:42:19.462: INFO: Selector matched 1 pods for map[app:redis]
Dec  9 20:42:19.462: INFO: Found 0 / 1
Dec  9 20:42:20.453: INFO: Selector matched 1 pods for map[app:redis]
Dec  9 20:42:20.453: INFO: Found 1 / 1
Dec  9 20:42:20.453: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  9 20:42:20.458: INFO: Selector matched 1 pods for map[app:redis]
Dec  9 20:42:20.458: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  9 20:42:20.458: INFO: wait on redis-master startup in e2e-tests-kubectl-z5xpv 
Dec  9 20:42:20.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 logs redis-master-p84qb redis-master --namespace=e2e-tests-kubectl-z5xpv'
Dec  9 20:42:20.557: INFO: stderr: ""
Dec  9 20:42:20.557: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 09 Dec 20:42:19.240 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 09 Dec 20:42:19.240 # Server started, Redis version 3.2.12\n1:M 09 Dec 20:42:19.240 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 09 Dec 20:42:19.240 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Dec  9 20:42:20.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-z5xpv'
Dec  9 20:42:20.673: INFO: stderr: ""
Dec  9 20:42:20.673: INFO: stdout: "service/rm2 exposed\n"
Dec  9 20:42:20.684: INFO: Service rm2 in namespace e2e-tests-kubectl-z5xpv found.
STEP: exposing service
Dec  9 20:42:22.693: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-z5xpv'
Dec  9 20:42:22.804: INFO: stderr: ""
Dec  9 20:42:22.804: INFO: stdout: "service/rm3 exposed\n"
Dec  9 20:42:22.811: INFO: Service rm3 in namespace e2e-tests-kubectl-z5xpv found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:42:24.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-z5xpv" for this suite.
Dec  9 20:42:46.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:42:46.946: INFO: namespace: e2e-tests-kubectl-z5xpv, resource: bindings, ignored listing per whitelist
Dec  9 20:42:47.009: INFO: namespace e2e-tests-kubectl-z5xpv deletion completed in 22.178742303s

• [SLOW TEST:28.998 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:42:47.009: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec  9 20:42:47.154: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:42:47.154: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:42:47.154: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:42:47.160: INFO: Number of nodes with available pods: 0
Dec  9 20:42:47.160: INFO: Node k8s04 is running more than one daemon pod
Dec  9 20:42:48.165: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:42:48.165: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:42:48.165: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:42:48.170: INFO: Number of nodes with available pods: 0
Dec  9 20:42:48.170: INFO: Node k8s04 is running more than one daemon pod
Dec  9 20:42:49.166: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:42:49.166: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:42:49.166: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:42:49.170: INFO: Number of nodes with available pods: 1
Dec  9 20:42:49.170: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Stop a daemon pod, check that the daemon pod is revived.
Dec  9 20:42:49.200: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:42:49.200: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:42:49.200: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:42:49.205: INFO: Number of nodes with available pods: 0
Dec  9 20:42:49.205: INFO: Node k8s04 is running more than one daemon pod
Dec  9 20:42:50.211: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:42:50.211: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:42:50.211: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:42:50.216: INFO: Number of nodes with available pods: 0
Dec  9 20:42:50.216: INFO: Node k8s04 is running more than one daemon pod
Dec  9 20:42:51.211: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:42:51.211: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:42:51.211: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:42:51.215: INFO: Number of nodes with available pods: 0
Dec  9 20:42:51.215: INFO: Node k8s04 is running more than one daemon pod
Dec  9 20:42:52.211: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:42:52.211: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:42:52.211: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:42:52.216: INFO: Number of nodes with available pods: 0
Dec  9 20:42:52.216: INFO: Node k8s04 is running more than one daemon pod
Dec  9 20:42:53.221: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:42:53.221: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:42:53.221: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:42:53.225: INFO: Number of nodes with available pods: 0
Dec  9 20:42:53.225: INFO: Node k8s04 is running more than one daemon pod
Dec  9 20:42:54.210: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:42:54.210: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:42:54.210: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:42:54.215: INFO: Number of nodes with available pods: 0
Dec  9 20:42:54.215: INFO: Node k8s04 is running more than one daemon pod
Dec  9 20:42:55.211: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:42:55.211: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:42:55.211: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:42:55.215: INFO: Number of nodes with available pods: 0
Dec  9 20:42:55.215: INFO: Node k8s04 is running more than one daemon pod
Dec  9 20:42:56.211: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:42:56.211: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:42:56.211: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:42:56.215: INFO: Number of nodes with available pods: 0
Dec  9 20:42:56.215: INFO: Node k8s04 is running more than one daemon pod
Dec  9 20:42:57.211: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:42:57.211: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:42:57.211: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:42:57.215: INFO: Number of nodes with available pods: 0
Dec  9 20:42:57.215: INFO: Node k8s04 is running more than one daemon pod
Dec  9 20:42:58.211: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:42:58.211: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:42:58.211: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:42:58.216: INFO: Number of nodes with available pods: 0
Dec  9 20:42:58.216: INFO: Node k8s04 is running more than one daemon pod
Dec  9 20:42:59.211: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:42:59.211: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:42:59.211: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:42:59.215: INFO: Number of nodes with available pods: 0
Dec  9 20:42:59.215: INFO: Node k8s04 is running more than one daemon pod
Dec  9 20:43:00.211: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:00.211: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:00.211: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:00.215: INFO: Number of nodes with available pods: 0
Dec  9 20:43:00.215: INFO: Node k8s04 is running more than one daemon pod
Dec  9 20:43:01.211: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:01.211: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:01.211: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:01.215: INFO: Number of nodes with available pods: 0
Dec  9 20:43:01.215: INFO: Node k8s04 is running more than one daemon pod
Dec  9 20:43:02.211: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:02.211: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:02.211: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:02.215: INFO: Number of nodes with available pods: 0
Dec  9 20:43:02.215: INFO: Node k8s04 is running more than one daemon pod
Dec  9 20:43:03.210: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:03.210: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:03.210: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:03.215: INFO: Number of nodes with available pods: 0
Dec  9 20:43:03.215: INFO: Node k8s04 is running more than one daemon pod
Dec  9 20:43:04.218: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:04.218: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:04.218: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:04.222: INFO: Number of nodes with available pods: 0
Dec  9 20:43:04.222: INFO: Node k8s04 is running more than one daemon pod
Dec  9 20:43:05.211: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:05.211: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:05.211: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:05.215: INFO: Number of nodes with available pods: 0
Dec  9 20:43:05.215: INFO: Node k8s04 is running more than one daemon pod
Dec  9 20:43:06.211: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:06.211: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:06.211: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:06.215: INFO: Number of nodes with available pods: 0
Dec  9 20:43:06.215: INFO: Node k8s04 is running more than one daemon pod
Dec  9 20:43:07.210: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:07.210: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:07.211: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:07.215: INFO: Number of nodes with available pods: 0
Dec  9 20:43:07.215: INFO: Node k8s04 is running more than one daemon pod
Dec  9 20:43:08.210: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:08.210: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:08.210: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:08.214: INFO: Number of nodes with available pods: 0
Dec  9 20:43:08.214: INFO: Node k8s04 is running more than one daemon pod
Dec  9 20:43:09.211: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:09.211: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:09.211: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:09.215: INFO: Number of nodes with available pods: 0
Dec  9 20:43:09.215: INFO: Node k8s04 is running more than one daemon pod
Dec  9 20:43:10.212: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:10.212: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:10.212: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:10.216: INFO: Number of nodes with available pods: 0
Dec  9 20:43:10.216: INFO: Node k8s04 is running more than one daemon pod
Dec  9 20:43:11.211: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:11.211: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:11.211: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:11.215: INFO: Number of nodes with available pods: 0
Dec  9 20:43:11.215: INFO: Node k8s04 is running more than one daemon pod
Dec  9 20:43:12.211: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:12.211: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:12.211: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:12.215: INFO: Number of nodes with available pods: 0
Dec  9 20:43:12.215: INFO: Node k8s04 is running more than one daemon pod
Dec  9 20:43:13.211: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:13.211: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:13.211: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:13.215: INFO: Number of nodes with available pods: 0
Dec  9 20:43:13.215: INFO: Node k8s04 is running more than one daemon pod
Dec  9 20:43:14.211: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:14.211: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:14.211: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:14.215: INFO: Number of nodes with available pods: 0
Dec  9 20:43:14.215: INFO: Node k8s04 is running more than one daemon pod
Dec  9 20:43:15.219: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:15.219: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:15.219: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:15.223: INFO: Number of nodes with available pods: 0
Dec  9 20:43:15.223: INFO: Node k8s04 is running more than one daemon pod
Dec  9 20:43:16.211: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:16.211: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:16.211: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:16.215: INFO: Number of nodes with available pods: 0
Dec  9 20:43:16.215: INFO: Node k8s04 is running more than one daemon pod
Dec  9 20:43:17.211: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:17.211: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:17.211: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:17.215: INFO: Number of nodes with available pods: 0
Dec  9 20:43:17.215: INFO: Node k8s04 is running more than one daemon pod
Dec  9 20:43:18.210: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:18.210: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:18.210: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:18.215: INFO: Number of nodes with available pods: 0
Dec  9 20:43:18.215: INFO: Node k8s04 is running more than one daemon pod
Dec  9 20:43:19.210: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:19.210: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:19.210: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:19.215: INFO: Number of nodes with available pods: 0
Dec  9 20:43:19.215: INFO: Node k8s04 is running more than one daemon pod
Dec  9 20:43:20.212: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:20.212: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:20.212: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:20.216: INFO: Number of nodes with available pods: 0
Dec  9 20:43:20.216: INFO: Node k8s04 is running more than one daemon pod
Dec  9 20:43:21.211: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:21.211: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:21.211: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:21.215: INFO: Number of nodes with available pods: 0
Dec  9 20:43:21.215: INFO: Node k8s04 is running more than one daemon pod
Dec  9 20:43:22.211: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:22.211: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:22.211: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:22.215: INFO: Number of nodes with available pods: 0
Dec  9 20:43:22.215: INFO: Node k8s04 is running more than one daemon pod
Dec  9 20:43:23.214: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:23.214: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:23.214: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:23.219: INFO: Number of nodes with available pods: 0
Dec  9 20:43:23.219: INFO: Node k8s04 is running more than one daemon pod
Dec  9 20:43:24.212: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:24.212: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:24.212: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:43:24.215: INFO: Number of nodes with available pods: 1
Dec  9 20:43:24.215: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-c8bv9, will wait for the garbage collector to delete the pods
Dec  9 20:43:24.293: INFO: Deleting DaemonSet.extensions daemon-set took: 13.135692ms
Dec  9 20:43:24.394: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.844257ms
Dec  9 20:44:00.705: INFO: Number of nodes with available pods: 0
Dec  9 20:44:00.705: INFO: Number of running nodes: 0, number of available pods: 0
Dec  9 20:44:00.710: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-c8bv9/daemonsets","resourceVersion":"41914"},"items":null}

Dec  9 20:44:00.715: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-c8bv9/pods","resourceVersion":"41914"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:44:00.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-c8bv9" for this suite.
Dec  9 20:44:06.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:44:06.818: INFO: namespace: e2e-tests-daemonsets-c8bv9, resource: bindings, ignored listing per whitelist
Dec  9 20:44:06.911: INFO: namespace e2e-tests-daemonsets-c8bv9 deletion completed in 6.176419996s

• [SLOW TEST:79.902 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:44:06.911: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-2c1547db-fbf3-11e8-8725-0a580af4034b
STEP: Creating a pod to test consume secrets
Dec  9 20:44:07.027: INFO: Waiting up to 5m0s for pod "pod-secrets-2c172dd5-fbf3-11e8-8725-0a580af4034b" in namespace "e2e-tests-secrets-lq7h4" to be "success or failure"
Dec  9 20:44:07.032: INFO: Pod "pod-secrets-2c172dd5-fbf3-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.652173ms
Dec  9 20:44:09.037: INFO: Pod "pod-secrets-2c172dd5-fbf3-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009838319s
STEP: Saw pod success
Dec  9 20:44:09.037: INFO: Pod "pod-secrets-2c172dd5-fbf3-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 20:44:09.041: INFO: Trying to get logs from node k8s04 pod pod-secrets-2c172dd5-fbf3-11e8-8725-0a580af4034b container secret-env-test: <nil>
STEP: delete the pod
Dec  9 20:44:09.078: INFO: Waiting for pod pod-secrets-2c172dd5-fbf3-11e8-8725-0a580af4034b to disappear
Dec  9 20:44:09.085: INFO: Pod pod-secrets-2c172dd5-fbf3-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:44:09.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-lq7h4" for this suite.
Dec  9 20:44:15.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:44:15.180: INFO: namespace: e2e-tests-secrets-lq7h4, resource: bindings, ignored listing per whitelist
Dec  9 20:44:15.270: INFO: namespace e2e-tests-secrets-lq7h4 deletion completed in 6.172732451s

• [SLOW TEST:8.359 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:44:15.270: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Dec  9 20:44:15.414: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 create -f - --namespace=e2e-tests-kubectl-znfqh'
Dec  9 20:44:15.633: INFO: stderr: ""
Dec  9 20:44:15.633: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Dec  9 20:44:16.637: INFO: Selector matched 1 pods for map[app:redis]
Dec  9 20:44:16.637: INFO: Found 0 / 1
Dec  9 20:44:17.638: INFO: Selector matched 1 pods for map[app:redis]
Dec  9 20:44:17.638: INFO: Found 1 / 1
Dec  9 20:44:17.638: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  9 20:44:17.642: INFO: Selector matched 1 pods for map[app:redis]
Dec  9 20:44:17.642: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Dec  9 20:44:17.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 logs redis-master-bb58m redis-master --namespace=e2e-tests-kubectl-znfqh'
Dec  9 20:44:17.734: INFO: stderr: ""
Dec  9 20:44:17.734: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 09 Dec 20:44:16.447 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 09 Dec 20:44:16.447 # Server started, Redis version 3.2.12\n1:M 09 Dec 20:44:16.447 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 09 Dec 20:44:16.447 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Dec  9 20:44:17.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 log redis-master-bb58m redis-master --namespace=e2e-tests-kubectl-znfqh --tail=1'
Dec  9 20:44:17.827: INFO: stderr: ""
Dec  9 20:44:17.827: INFO: stdout: "1:M 09 Dec 20:44:16.447 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Dec  9 20:44:17.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 log redis-master-bb58m redis-master --namespace=e2e-tests-kubectl-znfqh --limit-bytes=1'
Dec  9 20:44:17.916: INFO: stderr: ""
Dec  9 20:44:17.916: INFO: stdout: " "
STEP: exposing timestamps
Dec  9 20:44:17.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 log redis-master-bb58m redis-master --namespace=e2e-tests-kubectl-znfqh --tail=1 --timestamps'
Dec  9 20:44:18.006: INFO: stderr: ""
Dec  9 20:44:18.006: INFO: stdout: "2018-12-09T20:44:16.450071363Z 1:M 09 Dec 20:44:16.447 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Dec  9 20:44:20.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 log redis-master-bb58m redis-master --namespace=e2e-tests-kubectl-znfqh --since=1s'
Dec  9 20:44:20.596: INFO: stderr: ""
Dec  9 20:44:20.596: INFO: stdout: ""
Dec  9 20:44:20.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 log redis-master-bb58m redis-master --namespace=e2e-tests-kubectl-znfqh --since=24h'
Dec  9 20:44:20.694: INFO: stderr: ""
Dec  9 20:44:20.694: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 09 Dec 20:44:16.447 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 09 Dec 20:44:16.447 # Server started, Redis version 3.2.12\n1:M 09 Dec 20:44:16.447 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 09 Dec 20:44:16.447 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Dec  9 20:44:20.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-znfqh'
Dec  9 20:44:20.797: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  9 20:44:20.797: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Dec  9 20:44:20.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-znfqh'
Dec  9 20:44:20.888: INFO: stderr: "No resources found.\n"
Dec  9 20:44:20.888: INFO: stdout: ""
Dec  9 20:44:20.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods -l name=nginx --namespace=e2e-tests-kubectl-znfqh -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  9 20:44:20.983: INFO: stderr: ""
Dec  9 20:44:20.983: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:44:20.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-znfqh" for this suite.
Dec  9 20:44:43.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:44:43.126: INFO: namespace: e2e-tests-kubectl-znfqh, resource: bindings, ignored listing per whitelist
Dec  9 20:44:43.157: INFO: namespace e2e-tests-kubectl-znfqh deletion completed in 22.168930849s

• [SLOW TEST:27.887 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:44:43.157: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  9 20:44:43.286: INFO: (0) /api/v1/nodes/k8s04:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.093633ms)
Dec  9 20:44:43.294: INFO: (1) /api/v1/nodes/k8s04:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.810121ms)
Dec  9 20:44:43.304: INFO: (2) /api/v1/nodes/k8s04:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 10.105952ms)
Dec  9 20:44:43.312: INFO: (3) /api/v1/nodes/k8s04:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.971136ms)
Dec  9 20:44:43.322: INFO: (4) /api/v1/nodes/k8s04:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.913159ms)
Dec  9 20:44:43.329: INFO: (5) /api/v1/nodes/k8s04:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.339453ms)
Dec  9 20:44:43.338: INFO: (6) /api/v1/nodes/k8s04:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.050936ms)
Dec  9 20:44:43.345: INFO: (7) /api/v1/nodes/k8s04:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.139479ms)
Dec  9 20:44:43.361: INFO: (8) /api/v1/nodes/k8s04:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 15.40694ms)
Dec  9 20:44:43.368: INFO: (9) /api/v1/nodes/k8s04:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.931645ms)
Dec  9 20:44:43.374: INFO: (10) /api/v1/nodes/k8s04:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.349567ms)
Dec  9 20:44:43.383: INFO: (11) /api/v1/nodes/k8s04:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.985608ms)
Dec  9 20:44:43.392: INFO: (12) /api/v1/nodes/k8s04:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.012975ms)
Dec  9 20:44:43.399: INFO: (13) /api/v1/nodes/k8s04:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.026142ms)
Dec  9 20:44:43.406: INFO: (14) /api/v1/nodes/k8s04:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.848783ms)
Dec  9 20:44:43.417: INFO: (15) /api/v1/nodes/k8s04:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 10.638996ms)
Dec  9 20:44:43.430: INFO: (16) /api/v1/nodes/k8s04:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 12.933008ms)
Dec  9 20:44:43.450: INFO: (17) /api/v1/nodes/k8s04:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 19.566723ms)
Dec  9 20:44:43.455: INFO: (18) /api/v1/nodes/k8s04:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.427144ms)
Dec  9 20:44:43.464: INFO: (19) /api/v1/nodes/k8s04:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.901377ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:44:43.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-j726r" for this suite.
Dec  9 20:44:49.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:44:49.526: INFO: namespace: e2e-tests-proxy-j726r, resource: bindings, ignored listing per whitelist
Dec  9 20:44:49.667: INFO: namespace e2e-tests-proxy-j726r deletion completed in 6.1948808s

• [SLOW TEST:6.510 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:44:49.667: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  9 20:44:49.774: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4590e0cf-fbf3-11e8-8725-0a580af4034b" in namespace "e2e-tests-downward-api-bbhvm" to be "success or failure"
Dec  9 20:44:49.780: INFO: Pod "downwardapi-volume-4590e0cf-fbf3-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.949278ms
Dec  9 20:44:51.785: INFO: Pod "downwardapi-volume-4590e0cf-fbf3-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010305225s
STEP: Saw pod success
Dec  9 20:44:51.785: INFO: Pod "downwardapi-volume-4590e0cf-fbf3-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 20:44:51.789: INFO: Trying to get logs from node k8s04 pod downwardapi-volume-4590e0cf-fbf3-11e8-8725-0a580af4034b container client-container: <nil>
STEP: delete the pod
Dec  9 20:44:51.824: INFO: Waiting for pod downwardapi-volume-4590e0cf-fbf3-11e8-8725-0a580af4034b to disappear
Dec  9 20:44:51.827: INFO: Pod downwardapi-volume-4590e0cf-fbf3-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:44:51.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-bbhvm" for this suite.
Dec  9 20:44:57.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:44:57.876: INFO: namespace: e2e-tests-downward-api-bbhvm, resource: bindings, ignored listing per whitelist
Dec  9 20:44:58.007: INFO: namespace e2e-tests-downward-api-bbhvm deletion completed in 6.17303833s

• [SLOW TEST:8.340 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:44:58.007: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  9 20:44:58.125: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4a8b51f0-fbf3-11e8-8725-0a580af4034b" in namespace "e2e-tests-projected-5pmnh" to be "success or failure"
Dec  9 20:44:58.133: INFO: Pod "downwardapi-volume-4a8b51f0-fbf3-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.715788ms
Dec  9 20:45:00.138: INFO: Pod "downwardapi-volume-4a8b51f0-fbf3-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012556687s
STEP: Saw pod success
Dec  9 20:45:00.138: INFO: Pod "downwardapi-volume-4a8b51f0-fbf3-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 20:45:00.142: INFO: Trying to get logs from node k8s04 pod downwardapi-volume-4a8b51f0-fbf3-11e8-8725-0a580af4034b container client-container: <nil>
STEP: delete the pod
Dec  9 20:45:00.178: INFO: Waiting for pod downwardapi-volume-4a8b51f0-fbf3-11e8-8725-0a580af4034b to disappear
Dec  9 20:45:00.185: INFO: Pod downwardapi-volume-4a8b51f0-fbf3-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:45:00.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5pmnh" for this suite.
Dec  9 20:45:06.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:45:06.315: INFO: namespace: e2e-tests-projected-5pmnh, resource: bindings, ignored listing per whitelist
Dec  9 20:45:06.376: INFO: namespace e2e-tests-projected-5pmnh deletion completed in 6.181767593s

• [SLOW TEST:8.368 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:45:06.376: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Dec  9 20:45:06.480: INFO: Waiting up to 5m0s for pod "client-containers-4f86242b-fbf3-11e8-8725-0a580af4034b" in namespace "e2e-tests-containers-226zt" to be "success or failure"
Dec  9 20:45:06.486: INFO: Pod "client-containers-4f86242b-fbf3-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.241235ms
Dec  9 20:45:08.492: INFO: Pod "client-containers-4f86242b-fbf3-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01186882s
STEP: Saw pod success
Dec  9 20:45:08.492: INFO: Pod "client-containers-4f86242b-fbf3-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 20:45:08.496: INFO: Trying to get logs from node k8s04 pod client-containers-4f86242b-fbf3-11e8-8725-0a580af4034b container test-container: <nil>
STEP: delete the pod
Dec  9 20:45:08.530: INFO: Waiting for pod client-containers-4f86242b-fbf3-11e8-8725-0a580af4034b to disappear
Dec  9 20:45:08.536: INFO: Pod client-containers-4f86242b-fbf3-11e8-8725-0a580af4034b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:45:08.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-226zt" for this suite.
Dec  9 20:45:14.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:45:14.667: INFO: namespace: e2e-tests-containers-226zt, resource: bindings, ignored listing per whitelist
Dec  9 20:45:14.725: INFO: namespace e2e-tests-containers-226zt deletion completed in 6.184131655s

• [SLOW TEST:8.350 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:45:14.725: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  9 20:45:14.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-6z6j7'
Dec  9 20:45:14.919: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  9 20:45:14.919: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Dec  9 20:45:14.929: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-6z6j7'
Dec  9 20:45:15.039: INFO: stderr: ""
Dec  9 20:45:15.040: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:45:15.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6z6j7" for this suite.
Dec  9 20:45:37.072: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:45:37.189: INFO: namespace: e2e-tests-kubectl-6z6j7, resource: bindings, ignored listing per whitelist
Dec  9 20:45:37.219: INFO: namespace e2e-tests-kubectl-6z6j7 deletion completed in 22.171862007s

• [SLOW TEST:22.493 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:45:37.219: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-jwr9x
I1209 20:45:37.336401      15 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-jwr9x, replica count: 1
I1209 20:45:38.387773      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1209 20:45:39.388315      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  9 20:45:39.507: INFO: Created: latency-svc-gdhr5
Dec  9 20:45:39.534: INFO: Got endpoints: latency-svc-gdhr5 [45.759934ms]
Dec  9 20:45:39.572: INFO: Created: latency-svc-qsh4t
Dec  9 20:45:39.580: INFO: Got endpoints: latency-svc-qsh4t [45.307601ms]
Dec  9 20:45:39.598: INFO: Created: latency-svc-94fxz
Dec  9 20:45:39.612: INFO: Got endpoints: latency-svc-94fxz [76.392318ms]
Dec  9 20:45:39.615: INFO: Created: latency-svc-5qhbw
Dec  9 20:45:39.636: INFO: Got endpoints: latency-svc-5qhbw [100.453704ms]
Dec  9 20:45:39.641: INFO: Created: latency-svc-w2pn9
Dec  9 20:45:39.661: INFO: Got endpoints: latency-svc-w2pn9 [124.264813ms]
Dec  9 20:45:39.672: INFO: Created: latency-svc-26nc5
Dec  9 20:45:39.696: INFO: Got endpoints: latency-svc-26nc5 [157.101233ms]
Dec  9 20:45:39.712: INFO: Created: latency-svc-nd78f
Dec  9 20:45:39.730: INFO: Got endpoints: latency-svc-nd78f [191.19836ms]
Dec  9 20:45:39.763: INFO: Created: latency-svc-7gknc
Dec  9 20:45:39.772: INFO: Got endpoints: latency-svc-7gknc [235.196414ms]
Dec  9 20:45:39.789: INFO: Created: latency-svc-j75vb
Dec  9 20:45:39.804: INFO: Got endpoints: latency-svc-j75vb [266.592313ms]
Dec  9 20:45:39.810: INFO: Created: latency-svc-k2hc6
Dec  9 20:45:39.819: INFO: Got endpoints: latency-svc-k2hc6 [280.908585ms]
Dec  9 20:45:39.845: INFO: Created: latency-svc-klcmq
Dec  9 20:45:39.855: INFO: Got endpoints: latency-svc-klcmq [316.420192ms]
Dec  9 20:45:39.889: INFO: Created: latency-svc-fdplq
Dec  9 20:45:39.889: INFO: Got endpoints: latency-svc-fdplq [350.376195ms]
Dec  9 20:45:39.907: INFO: Created: latency-svc-vcvp7
Dec  9 20:45:39.926: INFO: Got endpoints: latency-svc-vcvp7 [387.358845ms]
Dec  9 20:45:39.945: INFO: Created: latency-svc-bfdmq
Dec  9 20:45:39.965: INFO: Got endpoints: latency-svc-bfdmq [426.932902ms]
Dec  9 20:45:39.986: INFO: Created: latency-svc-r98rb
Dec  9 20:45:39.993: INFO: Got endpoints: latency-svc-r98rb [454.296504ms]
Dec  9 20:45:40.019: INFO: Created: latency-svc-bfsdl
Dec  9 20:45:40.031: INFO: Got endpoints: latency-svc-bfsdl [494.507073ms]
Dec  9 20:45:40.069: INFO: Created: latency-svc-c2ccl
Dec  9 20:45:40.085: INFO: Got endpoints: latency-svc-c2ccl [505.182449ms]
Dec  9 20:45:40.113: INFO: Created: latency-svc-29j2n
Dec  9 20:45:40.131: INFO: Got endpoints: latency-svc-29j2n [518.914788ms]
Dec  9 20:45:40.166: INFO: Created: latency-svc-ts9c4
Dec  9 20:45:40.186: INFO: Got endpoints: latency-svc-ts9c4 [549.630778ms]
Dec  9 20:45:40.221: INFO: Created: latency-svc-lfm97
Dec  9 20:45:40.230: INFO: Got endpoints: latency-svc-lfm97 [569.41814ms]
Dec  9 20:45:40.264: INFO: Created: latency-svc-247hm
Dec  9 20:45:40.282: INFO: Got endpoints: latency-svc-247hm [586.335691ms]
Dec  9 20:45:40.315: INFO: Created: latency-svc-92b6n
Dec  9 20:45:40.317: INFO: Got endpoints: latency-svc-92b6n [587.046152ms]
Dec  9 20:45:40.356: INFO: Created: latency-svc-hcl4x
Dec  9 20:45:40.363: INFO: Got endpoints: latency-svc-hcl4x [590.323037ms]
Dec  9 20:45:40.395: INFO: Created: latency-svc-djfq7
Dec  9 20:45:40.401: INFO: Got endpoints: latency-svc-djfq7 [597.024386ms]
Dec  9 20:45:40.437: INFO: Created: latency-svc-2qj9x
Dec  9 20:45:40.457: INFO: Got endpoints: latency-svc-2qj9x [637.936664ms]
Dec  9 20:45:40.485: INFO: Created: latency-svc-kfzx7
Dec  9 20:45:40.495: INFO: Got endpoints: latency-svc-kfzx7 [640.323824ms]
Dec  9 20:45:40.534: INFO: Created: latency-svc-txjms
Dec  9 20:45:40.548: INFO: Got endpoints: latency-svc-txjms [658.844372ms]
Dec  9 20:45:40.575: INFO: Created: latency-svc-j9s28
Dec  9 20:45:40.591: INFO: Got endpoints: latency-svc-j9s28 [664.800789ms]
Dec  9 20:45:40.624: INFO: Created: latency-svc-xrrsv
Dec  9 20:45:40.624: INFO: Got endpoints: latency-svc-xrrsv [658.312968ms]
Dec  9 20:45:40.650: INFO: Created: latency-svc-t6q9x
Dec  9 20:45:40.671: INFO: Got endpoints: latency-svc-t6q9x [678.010346ms]
Dec  9 20:45:40.708: INFO: Created: latency-svc-s92k9
Dec  9 20:45:40.729: INFO: Got endpoints: latency-svc-s92k9 [697.345853ms]
Dec  9 20:45:40.748: INFO: Created: latency-svc-r5ccg
Dec  9 20:45:40.753: INFO: Got endpoints: latency-svc-r5ccg [667.699126ms]
Dec  9 20:45:40.799: INFO: Created: latency-svc-cbtvx
Dec  9 20:45:40.812: INFO: Got endpoints: latency-svc-cbtvx [680.819769ms]
Dec  9 20:45:40.852: INFO: Created: latency-svc-8m9ls
Dec  9 20:45:40.852: INFO: Got endpoints: latency-svc-8m9ls [665.639191ms]
Dec  9 20:45:40.883: INFO: Created: latency-svc-wkwcf
Dec  9 20:45:40.890: INFO: Got endpoints: latency-svc-wkwcf [660.287229ms]
Dec  9 20:45:40.923: INFO: Created: latency-svc-ph6t4
Dec  9 20:45:40.934: INFO: Got endpoints: latency-svc-ph6t4 [652.322112ms]
Dec  9 20:45:40.967: INFO: Created: latency-svc-r82lc
Dec  9 20:45:40.983: INFO: Got endpoints: latency-svc-r82lc [666.653055ms]
Dec  9 20:45:41.012: INFO: Created: latency-svc-t4m82
Dec  9 20:45:41.033: INFO: Got endpoints: latency-svc-t4m82 [669.916879ms]
Dec  9 20:45:41.061: INFO: Created: latency-svc-jnbhg
Dec  9 20:45:41.083: INFO: Got endpoints: latency-svc-jnbhg [681.226995ms]
Dec  9 20:45:41.109: INFO: Created: latency-svc-295hc
Dec  9 20:45:41.124: INFO: Got endpoints: latency-svc-295hc [666.761604ms]
Dec  9 20:45:41.138: INFO: Created: latency-svc-jtfvk
Dec  9 20:45:41.153: INFO: Got endpoints: latency-svc-jtfvk [657.48429ms]
Dec  9 20:45:41.187: INFO: Created: latency-svc-7blt4
Dec  9 20:45:41.187: INFO: Got endpoints: latency-svc-7blt4 [639.342878ms]
Dec  9 20:45:41.216: INFO: Created: latency-svc-q594z
Dec  9 20:45:41.231: INFO: Got endpoints: latency-svc-q594z [640.047065ms]
Dec  9 20:45:41.267: INFO: Created: latency-svc-v7vkj
Dec  9 20:45:41.271: INFO: Got endpoints: latency-svc-v7vkj [647.830466ms]
Dec  9 20:45:41.354: INFO: Created: latency-svc-pnrdp
Dec  9 20:45:41.354: INFO: Got endpoints: latency-svc-pnrdp [683.217022ms]
Dec  9 20:45:41.374: INFO: Created: latency-svc-g826t
Dec  9 20:45:41.391: INFO: Got endpoints: latency-svc-g826t [662.465531ms]
Dec  9 20:45:41.411: INFO: Created: latency-svc-nr9v2
Dec  9 20:45:41.426: INFO: Got endpoints: latency-svc-nr9v2 [672.802958ms]
Dec  9 20:45:41.444: INFO: Created: latency-svc-wlxm5
Dec  9 20:45:41.451: INFO: Got endpoints: latency-svc-wlxm5 [639.557904ms]
Dec  9 20:45:41.491: INFO: Created: latency-svc-wxlzc
Dec  9 20:45:41.505: INFO: Got endpoints: latency-svc-wxlzc [652.886565ms]
Dec  9 20:45:41.531: INFO: Created: latency-svc-vmnvv
Dec  9 20:45:41.537: INFO: Got endpoints: latency-svc-vmnvv [646.798211ms]
Dec  9 20:45:41.578: INFO: Created: latency-svc-jrjt8
Dec  9 20:45:41.579: INFO: Got endpoints: latency-svc-jrjt8 [643.961702ms]
Dec  9 20:45:41.646: INFO: Created: latency-svc-7jznv
Dec  9 20:45:41.646: INFO: Created: latency-svc-6td6m
Dec  9 20:45:41.646: INFO: Got endpoints: latency-svc-6td6m [662.493634ms]
Dec  9 20:45:41.651: INFO: Got endpoints: latency-svc-7jznv [618.552422ms]
Dec  9 20:45:41.728: INFO: Created: latency-svc-fwc54
Dec  9 20:45:41.733: INFO: Got endpoints: latency-svc-fwc54 [650.673617ms]
Dec  9 20:45:41.772: INFO: Created: latency-svc-v5wb4
Dec  9 20:45:41.788: INFO: Got endpoints: latency-svc-v5wb4 [663.978284ms]
Dec  9 20:45:41.829: INFO: Created: latency-svc-8ngks
Dec  9 20:45:41.854: INFO: Got endpoints: latency-svc-8ngks [700.88074ms]
Dec  9 20:45:41.882: INFO: Created: latency-svc-z427j
Dec  9 20:45:41.904: INFO: Got endpoints: latency-svc-z427j [716.922626ms]
Dec  9 20:45:41.920: INFO: Created: latency-svc-lf5jw
Dec  9 20:45:41.938: INFO: Got endpoints: latency-svc-lf5jw [706.89356ms]
Dec  9 20:45:41.975: INFO: Created: latency-svc-l2ccj
Dec  9 20:45:41.981: INFO: Got endpoints: latency-svc-l2ccj [709.711228ms]
Dec  9 20:45:42.049: INFO: Created: latency-svc-d67zm
Dec  9 20:45:42.049: INFO: Got endpoints: latency-svc-d67zm [694.646368ms]
Dec  9 20:45:42.091: INFO: Created: latency-svc-vw48h
Dec  9 20:45:42.101: INFO: Got endpoints: latency-svc-vw48h [709.587786ms]
Dec  9 20:45:42.136: INFO: Created: latency-svc-h27fj
Dec  9 20:45:42.161: INFO: Got endpoints: latency-svc-h27fj [735.529611ms]
Dec  9 20:45:42.209: INFO: Created: latency-svc-htzb4
Dec  9 20:45:42.211: INFO: Got endpoints: latency-svc-htzb4 [760.01877ms]
Dec  9 20:45:42.297: INFO: Created: latency-svc-49gw7
Dec  9 20:45:42.298: INFO: Got endpoints: latency-svc-49gw7 [791.691244ms]
Dec  9 20:45:42.368: INFO: Created: latency-svc-fqm8x
Dec  9 20:45:42.373: INFO: Got endpoints: latency-svc-fqm8x [835.294989ms]
Dec  9 20:45:42.434: INFO: Created: latency-svc-qrcdr
Dec  9 20:45:42.434: INFO: Got endpoints: latency-svc-qrcdr [855.07848ms]
Dec  9 20:45:42.459: INFO: Created: latency-svc-ff2xg
Dec  9 20:45:42.475: INFO: Got endpoints: latency-svc-ff2xg [828.811553ms]
Dec  9 20:45:42.508: INFO: Created: latency-svc-mqjmq
Dec  9 20:45:42.525: INFO: Got endpoints: latency-svc-mqjmq [873.082709ms]
Dec  9 20:45:42.556: INFO: Created: latency-svc-hhsc6
Dec  9 20:45:42.580: INFO: Got endpoints: latency-svc-hhsc6 [846.36785ms]
Dec  9 20:45:42.599: INFO: Created: latency-svc-vdd9g
Dec  9 20:45:42.625: INFO: Got endpoints: latency-svc-vdd9g [837.729367ms]
Dec  9 20:45:42.631: INFO: Created: latency-svc-hp9k9
Dec  9 20:45:42.644: INFO: Got endpoints: latency-svc-hp9k9 [790.074901ms]
Dec  9 20:45:42.732: INFO: Created: latency-svc-lsdpb
Dec  9 20:45:42.733: INFO: Got endpoints: latency-svc-lsdpb [829.410366ms]
Dec  9 20:45:42.769: INFO: Created: latency-svc-ktth9
Dec  9 20:45:42.786: INFO: Got endpoints: latency-svc-ktth9 [848.793703ms]
Dec  9 20:45:42.820: INFO: Created: latency-svc-vf9lm
Dec  9 20:45:42.856: INFO: Got endpoints: latency-svc-vf9lm [874.327365ms]
Dec  9 20:45:42.927: INFO: Created: latency-svc-tkpmc
Dec  9 20:45:42.945: INFO: Got endpoints: latency-svc-tkpmc [896.042772ms]
Dec  9 20:45:42.999: INFO: Created: latency-svc-f8tqx
Dec  9 20:45:42.999: INFO: Got endpoints: latency-svc-f8tqx [898.133529ms]
Dec  9 20:45:43.016: INFO: Created: latency-svc-qr4zr
Dec  9 20:45:43.042: INFO: Got endpoints: latency-svc-qr4zr [880.665046ms]
Dec  9 20:45:43.102: INFO: Created: latency-svc-786x8
Dec  9 20:45:43.106: INFO: Got endpoints: latency-svc-786x8 [894.589748ms]
Dec  9 20:45:43.136: INFO: Created: latency-svc-5wm4v
Dec  9 20:45:43.151: INFO: Got endpoints: latency-svc-5wm4v [852.437502ms]
Dec  9 20:45:43.187: INFO: Created: latency-svc-xxhdp
Dec  9 20:45:43.222: INFO: Got endpoints: latency-svc-xxhdp [849.484347ms]
Dec  9 20:45:43.248: INFO: Created: latency-svc-55wnw
Dec  9 20:45:43.248: INFO: Got endpoints: latency-svc-55wnw [814.407522ms]
Dec  9 20:45:43.285: INFO: Created: latency-svc-p64vb
Dec  9 20:45:43.303: INFO: Got endpoints: latency-svc-p64vb [828.698645ms]
Dec  9 20:45:43.318: INFO: Created: latency-svc-bg4nk
Dec  9 20:45:43.367: INFO: Got endpoints: latency-svc-bg4nk [842.568941ms]
Dec  9 20:45:43.369: INFO: Created: latency-svc-r6s9n
Dec  9 20:45:43.402: INFO: Got endpoints: latency-svc-r6s9n [821.736702ms]
Dec  9 20:45:43.418: INFO: Created: latency-svc-fd7z4
Dec  9 20:45:43.446: INFO: Got endpoints: latency-svc-fd7z4 [820.907867ms]
Dec  9 20:45:43.464: INFO: Created: latency-svc-fk4wm
Dec  9 20:45:43.488: INFO: Got endpoints: latency-svc-fk4wm [844.675825ms]
Dec  9 20:45:43.526: INFO: Created: latency-svc-24cnm
Dec  9 20:45:43.538: INFO: Created: latency-svc-gnpzc
Dec  9 20:45:43.551: INFO: Got endpoints: latency-svc-24cnm [817.870899ms]
Dec  9 20:45:43.562: INFO: Got endpoints: latency-svc-gnpzc [775.934389ms]
Dec  9 20:45:43.611: INFO: Created: latency-svc-fh48p
Dec  9 20:45:43.627: INFO: Got endpoints: latency-svc-fh48p [771.110337ms]
Dec  9 20:45:43.646: INFO: Created: latency-svc-l9tcq
Dec  9 20:45:43.658: INFO: Got endpoints: latency-svc-l9tcq [712.934034ms]
Dec  9 20:45:43.710: INFO: Created: latency-svc-47kth
Dec  9 20:45:43.730: INFO: Got endpoints: latency-svc-47kth [103.672585ms]
Dec  9 20:45:44.036: INFO: Created: latency-svc-ctxqm
Dec  9 20:45:44.042: INFO: Got endpoints: latency-svc-ctxqm [1.043438369s]
Dec  9 20:45:44.062: INFO: Created: latency-svc-8t4hf
Dec  9 20:45:44.081: INFO: Got endpoints: latency-svc-8t4hf [1.03877167s]
Dec  9 20:45:44.092: INFO: Created: latency-svc-hrpz7
Dec  9 20:45:44.113: INFO: Got endpoints: latency-svc-hrpz7 [1.006915323s]
Dec  9 20:45:44.158: INFO: Created: latency-svc-kgtmp
Dec  9 20:45:44.158: INFO: Got endpoints: latency-svc-kgtmp [1.007211505s]
Dec  9 20:45:44.189: INFO: Created: latency-svc-vd2lr
Dec  9 20:45:44.193: INFO: Got endpoints: latency-svc-vd2lr [971.330833ms]
Dec  9 20:45:44.220: INFO: Created: latency-svc-j8cnl
Dec  9 20:45:44.220: INFO: Got endpoints: latency-svc-j8cnl [971.591555ms]
Dec  9 20:45:44.239: INFO: Created: latency-svc-fvkdz
Dec  9 20:45:44.261: INFO: Got endpoints: latency-svc-fvkdz [957.3973ms]
Dec  9 20:45:44.263: INFO: Created: latency-svc-hxg28
Dec  9 20:45:44.270: INFO: Created: latency-svc-pfwbm
Dec  9 20:45:44.286: INFO: Got endpoints: latency-svc-hxg28 [918.371488ms]
Dec  9 20:45:44.308: INFO: Got endpoints: latency-svc-pfwbm [906.677028ms]
Dec  9 20:45:44.311: INFO: Created: latency-svc-f4hz2
Dec  9 20:45:44.346: INFO: Created: latency-svc-h8csp
Dec  9 20:45:44.352: INFO: Got endpoints: latency-svc-f4hz2 [905.305791ms]
Dec  9 20:45:44.363: INFO: Got endpoints: latency-svc-h8csp [874.327238ms]
Dec  9 20:45:44.396: INFO: Created: latency-svc-976n8
Dec  9 20:45:44.406: INFO: Created: latency-svc-4zdqb
Dec  9 20:45:44.411: INFO: Got endpoints: latency-svc-976n8 [859.162215ms]
Dec  9 20:45:44.419: INFO: Got endpoints: latency-svc-4zdqb [856.205672ms]
Dec  9 20:45:44.435: INFO: Created: latency-svc-cwrcq
Dec  9 20:45:44.473: INFO: Created: latency-svc-f4v8q
Dec  9 20:45:44.474: INFO: Got endpoints: latency-svc-cwrcq [816.233075ms]
Dec  9 20:45:44.490: INFO: Got endpoints: latency-svc-f4v8q [759.689571ms]
Dec  9 20:45:44.500: INFO: Created: latency-svc-cbsc8
Dec  9 20:45:44.516: INFO: Got endpoints: latency-svc-cbsc8 [473.57439ms]
Dec  9 20:45:44.520: INFO: Created: latency-svc-z9qgs
Dec  9 20:45:44.546: INFO: Got endpoints: latency-svc-z9qgs [465.224146ms]
Dec  9 20:45:44.561: INFO: Created: latency-svc-lpvp4
Dec  9 20:45:44.581: INFO: Got endpoints: latency-svc-lpvp4 [467.699837ms]
Dec  9 20:45:44.596: INFO: Created: latency-svc-mkthq
Dec  9 20:45:44.607: INFO: Got endpoints: latency-svc-mkthq [449.366981ms]
Dec  9 20:45:44.640: INFO: Created: latency-svc-jdmh2
Dec  9 20:45:44.663: INFO: Created: latency-svc-n9lxr
Dec  9 20:45:44.673: INFO: Got endpoints: latency-svc-jdmh2 [479.997247ms]
Dec  9 20:45:44.707: INFO: Created: latency-svc-g6pv7
Dec  9 20:45:44.707: INFO: Got endpoints: latency-svc-n9lxr [487.798776ms]
Dec  9 20:45:44.728: INFO: Got endpoints: latency-svc-g6pv7 [467.017228ms]
Dec  9 20:45:44.752: INFO: Created: latency-svc-wvkxd
Dec  9 20:45:44.780: INFO: Got endpoints: latency-svc-wvkxd [494.13979ms]
Dec  9 20:45:44.781: INFO: Created: latency-svc-htsc5
Dec  9 20:45:44.799: INFO: Got endpoints: latency-svc-htsc5 [490.809095ms]
Dec  9 20:45:44.830: INFO: Created: latency-svc-lbtgf
Dec  9 20:45:44.830: INFO: Got endpoints: latency-svc-lbtgf [478.55573ms]
Dec  9 20:45:44.850: INFO: Created: latency-svc-676nr
Dec  9 20:45:44.860: INFO: Created: latency-svc-wn8gg
Dec  9 20:45:44.868: INFO: Got endpoints: latency-svc-676nr [504.800879ms]
Dec  9 20:45:44.888: INFO: Got endpoints: latency-svc-wn8gg [476.94532ms]
Dec  9 20:45:44.897: INFO: Created: latency-svc-5v7bw
Dec  9 20:45:44.916: INFO: Got endpoints: latency-svc-5v7bw [497.359946ms]
Dec  9 20:45:44.924: INFO: Created: latency-svc-54x9r
Dec  9 20:45:44.942: INFO: Got endpoints: latency-svc-54x9r [468.290875ms]
Dec  9 20:45:44.950: INFO: Created: latency-svc-tz4mr
Dec  9 20:45:44.981: INFO: Created: latency-svc-pm85v
Dec  9 20:45:44.985: INFO: Got endpoints: latency-svc-tz4mr [494.750607ms]
Dec  9 20:45:45.005: INFO: Got endpoints: latency-svc-pm85v [488.620793ms]
Dec  9 20:45:45.011: INFO: Created: latency-svc-lzfn8
Dec  9 20:45:45.034: INFO: Got endpoints: latency-svc-lzfn8 [487.888319ms]
Dec  9 20:45:45.044: INFO: Created: latency-svc-954r4
Dec  9 20:45:45.068: INFO: Got endpoints: latency-svc-954r4 [487.019577ms]
Dec  9 20:45:45.089: INFO: Created: latency-svc-rkxp5
Dec  9 20:45:45.112: INFO: Got endpoints: latency-svc-rkxp5 [504.115668ms]
Dec  9 20:45:45.123: INFO: Created: latency-svc-jvfsq
Dec  9 20:45:45.146: INFO: Created: latency-svc-qjk86
Dec  9 20:45:45.153: INFO: Got endpoints: latency-svc-jvfsq [479.027703ms]
Dec  9 20:45:45.169: INFO: Got endpoints: latency-svc-qjk86 [461.183912ms]
Dec  9 20:45:45.180: INFO: Created: latency-svc-vs6x2
Dec  9 20:45:45.214: INFO: Got endpoints: latency-svc-vs6x2 [486.263505ms]
Dec  9 20:45:45.219: INFO: Created: latency-svc-zb22d
Dec  9 20:45:45.249: INFO: Got endpoints: latency-svc-zb22d [469.001369ms]
Dec  9 20:45:45.260: INFO: Created: latency-svc-vqrcn
Dec  9 20:45:45.272: INFO: Got endpoints: latency-svc-vqrcn [473.142078ms]
Dec  9 20:45:45.279: INFO: Created: latency-svc-jm4lw
Dec  9 20:45:45.290: INFO: Got endpoints: latency-svc-jm4lw [460.046735ms]
Dec  9 20:45:45.300: INFO: Created: latency-svc-t96hb
Dec  9 20:45:45.312: INFO: Got endpoints: latency-svc-t96hb [444.072326ms]
Dec  9 20:45:45.351: INFO: Created: latency-svc-mm9rs
Dec  9 20:45:45.366: INFO: Got endpoints: latency-svc-mm9rs [477.913231ms]
Dec  9 20:45:45.397: INFO: Created: latency-svc-xj2xh
Dec  9 20:45:45.412: INFO: Got endpoints: latency-svc-xj2xh [495.828749ms]
Dec  9 20:45:45.456: INFO: Created: latency-svc-txvdn
Dec  9 20:45:45.470: INFO: Got endpoints: latency-svc-txvdn [527.184453ms]
Dec  9 20:45:45.500: INFO: Created: latency-svc-rlq89
Dec  9 20:45:45.512: INFO: Got endpoints: latency-svc-rlq89 [526.670911ms]
Dec  9 20:45:45.534: INFO: Created: latency-svc-9qsn2
Dec  9 20:45:45.551: INFO: Got endpoints: latency-svc-9qsn2 [546.532851ms]
Dec  9 20:45:45.588: INFO: Created: latency-svc-xx5w7
Dec  9 20:45:45.606: INFO: Got endpoints: latency-svc-xx5w7 [571.200672ms]
Dec  9 20:45:45.636: INFO: Created: latency-svc-ghhxq
Dec  9 20:45:45.654: INFO: Created: latency-svc-dz5n7
Dec  9 20:45:45.661: INFO: Got endpoints: latency-svc-ghhxq [593.482924ms]
Dec  9 20:45:45.683: INFO: Got endpoints: latency-svc-dz5n7 [571.906004ms]
Dec  9 20:45:45.724: INFO: Created: latency-svc-8gpvx
Dec  9 20:45:45.742: INFO: Got endpoints: latency-svc-8gpvx [589.600072ms]
Dec  9 20:45:45.780: INFO: Created: latency-svc-5l8zv
Dec  9 20:45:45.788: INFO: Got endpoints: latency-svc-5l8zv [619.139994ms]
Dec  9 20:45:45.846: INFO: Created: latency-svc-5v89h
Dec  9 20:45:45.846: INFO: Got endpoints: latency-svc-5v89h [631.057652ms]
Dec  9 20:45:45.875: INFO: Created: latency-svc-frd7z
Dec  9 20:45:45.877: INFO: Got endpoints: latency-svc-frd7z [628.14799ms]
Dec  9 20:45:45.925: INFO: Created: latency-svc-wztwl
Dec  9 20:45:45.933: INFO: Got endpoints: latency-svc-wztwl [660.131522ms]
Dec  9 20:45:45.976: INFO: Created: latency-svc-vdjlz
Dec  9 20:45:45.977: INFO: Got endpoints: latency-svc-vdjlz [686.783229ms]
Dec  9 20:45:46.024: INFO: Created: latency-svc-nhrnw
Dec  9 20:45:46.064: INFO: Created: latency-svc-mhtpf
Dec  9 20:45:46.064: INFO: Got endpoints: latency-svc-mhtpf [698.239474ms]
Dec  9 20:45:46.064: INFO: Got endpoints: latency-svc-nhrnw [752.647721ms]
Dec  9 20:45:46.088: INFO: Created: latency-svc-zxn4p
Dec  9 20:45:46.105: INFO: Got endpoints: latency-svc-zxn4p [693.362826ms]
Dec  9 20:45:46.112: INFO: Created: latency-svc-spwsx
Dec  9 20:45:46.128: INFO: Got endpoints: latency-svc-spwsx [658.298988ms]
Dec  9 20:45:46.168: INFO: Created: latency-svc-2m5j9
Dec  9 20:45:46.191: INFO: Created: latency-svc-5d8c8
Dec  9 20:45:46.202: INFO: Got endpoints: latency-svc-2m5j9 [689.730297ms]
Dec  9 20:45:46.209: INFO: Got endpoints: latency-svc-5d8c8 [658.05832ms]
Dec  9 20:45:46.242: INFO: Created: latency-svc-hb9p5
Dec  9 20:45:46.253: INFO: Got endpoints: latency-svc-hb9p5 [647.438558ms]
Dec  9 20:45:46.274: INFO: Created: latency-svc-h2fhg
Dec  9 20:45:46.279: INFO: Got endpoints: latency-svc-h2fhg [617.594271ms]
Dec  9 20:45:46.291: INFO: Created: latency-svc-lxxbj
Dec  9 20:45:46.313: INFO: Got endpoints: latency-svc-lxxbj [629.16186ms]
Dec  9 20:45:46.333: INFO: Created: latency-svc-vts2w
Dec  9 20:45:46.339: INFO: Got endpoints: latency-svc-vts2w [596.956714ms]
Dec  9 20:45:46.358: INFO: Created: latency-svc-l96cp
Dec  9 20:45:46.372: INFO: Got endpoints: latency-svc-l96cp [584.56064ms]
Dec  9 20:45:46.407: INFO: Created: latency-svc-288lh
Dec  9 20:45:46.430: INFO: Got endpoints: latency-svc-288lh [583.858467ms]
Dec  9 20:45:46.450: INFO: Created: latency-svc-v5jlh
Dec  9 20:45:46.472: INFO: Got endpoints: latency-svc-v5jlh [595.30774ms]
Dec  9 20:45:46.497: INFO: Created: latency-svc-sp2fp
Dec  9 20:45:46.539: INFO: Got endpoints: latency-svc-sp2fp [606.292963ms]
Dec  9 20:45:46.549: INFO: Created: latency-svc-n2mx2
Dec  9 20:45:46.579: INFO: Got endpoints: latency-svc-n2mx2 [601.760779ms]
Dec  9 20:45:46.618: INFO: Created: latency-svc-wbpkg
Dec  9 20:45:46.646: INFO: Got endpoints: latency-svc-wbpkg [581.754109ms]
Dec  9 20:45:46.661: INFO: Created: latency-svc-kwhx6
Dec  9 20:45:46.677: INFO: Got endpoints: latency-svc-kwhx6 [612.10806ms]
Dec  9 20:45:46.721: INFO: Created: latency-svc-tlz79
Dec  9 20:45:46.756: INFO: Got endpoints: latency-svc-tlz79 [651.021485ms]
Dec  9 20:45:46.760: INFO: Created: latency-svc-l68qm
Dec  9 20:45:46.786: INFO: Got endpoints: latency-svc-l68qm [657.319244ms]
Dec  9 20:45:46.807: INFO: Created: latency-svc-swjgq
Dec  9 20:45:46.836: INFO: Got endpoints: latency-svc-swjgq [634.511773ms]
Dec  9 20:45:46.851: INFO: Created: latency-svc-tm6lh
Dec  9 20:45:46.882: INFO: Got endpoints: latency-svc-tm6lh [672.758531ms]
Dec  9 20:45:46.900: INFO: Created: latency-svc-6fsnc
Dec  9 20:45:46.921: INFO: Got endpoints: latency-svc-6fsnc [668.252588ms]
Dec  9 20:45:46.943: INFO: Created: latency-svc-g9qxv
Dec  9 20:45:46.966: INFO: Got endpoints: latency-svc-g9qxv [687.548826ms]
Dec  9 20:45:46.974: INFO: Created: latency-svc-f7pk9
Dec  9 20:45:47.004: INFO: Created: latency-svc-wzm2d
Dec  9 20:45:47.004: INFO: Got endpoints: latency-svc-f7pk9 [691.308048ms]
Dec  9 20:45:47.019: INFO: Got endpoints: latency-svc-wzm2d [679.269768ms]
Dec  9 20:45:47.034: INFO: Created: latency-svc-24k6g
Dec  9 20:45:47.056: INFO: Got endpoints: latency-svc-24k6g [683.42771ms]
Dec  9 20:45:47.070: INFO: Created: latency-svc-h2mxz
Dec  9 20:45:47.078: INFO: Got endpoints: latency-svc-h2mxz [648.116293ms]
Dec  9 20:45:47.103: INFO: Created: latency-svc-f54qj
Dec  9 20:45:47.108: INFO: Got endpoints: latency-svc-f54qj [635.979461ms]
Dec  9 20:45:47.128: INFO: Created: latency-svc-2wkms
Dec  9 20:45:47.139: INFO: Got endpoints: latency-svc-2wkms [599.919481ms]
Dec  9 20:45:47.159: INFO: Created: latency-svc-qswgg
Dec  9 20:45:47.180: INFO: Created: latency-svc-5j5rp
Dec  9 20:45:47.192: INFO: Got endpoints: latency-svc-qswgg [612.486806ms]
Dec  9 20:45:47.211: INFO: Got endpoints: latency-svc-5j5rp [565.402154ms]
Dec  9 20:45:47.227: INFO: Created: latency-svc-dgwjd
Dec  9 20:45:47.248: INFO: Created: latency-svc-szv2v
Dec  9 20:45:47.266: INFO: Got endpoints: latency-svc-dgwjd [589.322206ms]
Dec  9 20:45:47.273: INFO: Created: latency-svc-4j9mx
Dec  9 20:45:47.281: INFO: Got endpoints: latency-svc-szv2v [523.93712ms]
Dec  9 20:45:47.301: INFO: Created: latency-svc-spv7t
Dec  9 20:45:47.301: INFO: Got endpoints: latency-svc-4j9mx [515.29431ms]
Dec  9 20:45:47.334: INFO: Got endpoints: latency-svc-spv7t [497.981678ms]
Dec  9 20:45:47.348: INFO: Created: latency-svc-q5ckf
Dec  9 20:45:47.357: INFO: Got endpoints: latency-svc-q5ckf [474.219163ms]
Dec  9 20:45:47.359: INFO: Created: latency-svc-dpjkt
Dec  9 20:45:47.379: INFO: Got endpoints: latency-svc-dpjkt [457.241209ms]
Dec  9 20:45:47.412: INFO: Created: latency-svc-ngwgt
Dec  9 20:45:47.412: INFO: Got endpoints: latency-svc-ngwgt [445.794554ms]
Dec  9 20:45:47.470: INFO: Created: latency-svc-v8js9
Dec  9 20:45:47.501: INFO: Got endpoints: latency-svc-v8js9 [496.621631ms]
Dec  9 20:45:47.521: INFO: Created: latency-svc-bl44q
Dec  9 20:45:47.541: INFO: Got endpoints: latency-svc-bl44q [522.128472ms]
Dec  9 20:45:47.567: INFO: Created: latency-svc-kw26p
Dec  9 20:45:47.585: INFO: Got endpoints: latency-svc-kw26p [528.701654ms]
Dec  9 20:45:47.630: INFO: Created: latency-svc-jmbpq
Dec  9 20:45:47.630: INFO: Got endpoints: latency-svc-jmbpq [552.101825ms]
Dec  9 20:45:47.689: INFO: Created: latency-svc-5zmqt
Dec  9 20:45:47.689: INFO: Got endpoints: latency-svc-5zmqt [581.025555ms]
Dec  9 20:45:47.713: INFO: Created: latency-svc-stn7g
Dec  9 20:45:47.724: INFO: Got endpoints: latency-svc-stn7g [584.991767ms]
Dec  9 20:45:47.756: INFO: Created: latency-svc-6dt6m
Dec  9 20:45:47.772: INFO: Got endpoints: latency-svc-6dt6m [580.640911ms]
Dec  9 20:45:47.815: INFO: Created: latency-svc-sxch2
Dec  9 20:45:47.815: INFO: Got endpoints: latency-svc-sxch2 [603.70625ms]
Dec  9 20:45:47.846: INFO: Created: latency-svc-s6zkg
Dec  9 20:45:47.846: INFO: Got endpoints: latency-svc-s6zkg [579.890144ms]
Dec  9 20:45:47.884: INFO: Created: latency-svc-d5mk6
Dec  9 20:45:47.900: INFO: Got endpoints: latency-svc-d5mk6 [619.082793ms]
Dec  9 20:45:47.941: INFO: Created: latency-svc-nh6fr
Dec  9 20:45:47.948: INFO: Got endpoints: latency-svc-nh6fr [647.444591ms]
Dec  9 20:45:47.992: INFO: Created: latency-svc-g6qm7
Dec  9 20:45:48.011: INFO: Got endpoints: latency-svc-g6qm7 [676.675977ms]
Dec  9 20:45:48.124: INFO: Created: latency-svc-kd4d8
Dec  9 20:45:48.125: INFO: Got endpoints: latency-svc-kd4d8 [767.927727ms]
Dec  9 20:45:48.158: INFO: Created: latency-svc-mkmnp
Dec  9 20:45:48.179: INFO: Got endpoints: latency-svc-mkmnp [800.593791ms]
Dec  9 20:45:48.203: INFO: Created: latency-svc-6xpd9
Dec  9 20:45:48.233: INFO: Got endpoints: latency-svc-6xpd9 [820.295248ms]
Dec  9 20:45:48.255: INFO: Created: latency-svc-f6hbs
Dec  9 20:45:48.257: INFO: Got endpoints: latency-svc-f6hbs [756.78133ms]
Dec  9 20:45:48.346: INFO: Created: latency-svc-hgfkb
Dec  9 20:45:48.360: INFO: Got endpoints: latency-svc-hgfkb [819.258935ms]
Dec  9 20:45:48.360: INFO: Latencies: [45.307601ms 76.392318ms 100.453704ms 103.672585ms 124.264813ms 157.101233ms 191.19836ms 235.196414ms 266.592313ms 280.908585ms 316.420192ms 350.376195ms 387.358845ms 426.932902ms 444.072326ms 445.794554ms 449.366981ms 454.296504ms 457.241209ms 460.046735ms 461.183912ms 465.224146ms 467.017228ms 467.699837ms 468.290875ms 469.001369ms 473.142078ms 473.57439ms 474.219163ms 476.94532ms 477.913231ms 478.55573ms 479.027703ms 479.997247ms 486.263505ms 487.019577ms 487.798776ms 487.888319ms 488.620793ms 490.809095ms 494.13979ms 494.507073ms 494.750607ms 495.828749ms 496.621631ms 497.359946ms 497.981678ms 504.115668ms 504.800879ms 505.182449ms 515.29431ms 518.914788ms 522.128472ms 523.93712ms 526.670911ms 527.184453ms 528.701654ms 546.532851ms 549.630778ms 552.101825ms 565.402154ms 569.41814ms 571.200672ms 571.906004ms 579.890144ms 580.640911ms 581.025555ms 581.754109ms 583.858467ms 584.56064ms 584.991767ms 586.335691ms 587.046152ms 589.322206ms 589.600072ms 590.323037ms 593.482924ms 595.30774ms 596.956714ms 597.024386ms 599.919481ms 601.760779ms 603.70625ms 606.292963ms 612.10806ms 612.486806ms 617.594271ms 618.552422ms 619.082793ms 619.139994ms 628.14799ms 629.16186ms 631.057652ms 634.511773ms 635.979461ms 637.936664ms 639.342878ms 639.557904ms 640.047065ms 640.323824ms 643.961702ms 646.798211ms 647.438558ms 647.444591ms 647.830466ms 648.116293ms 650.673617ms 651.021485ms 652.322112ms 652.886565ms 657.319244ms 657.48429ms 658.05832ms 658.298988ms 658.312968ms 658.844372ms 660.131522ms 660.287229ms 662.465531ms 662.493634ms 663.978284ms 664.800789ms 665.639191ms 666.653055ms 666.761604ms 667.699126ms 668.252588ms 669.916879ms 672.758531ms 672.802958ms 676.675977ms 678.010346ms 679.269768ms 680.819769ms 681.226995ms 683.217022ms 683.42771ms 686.783229ms 687.548826ms 689.730297ms 691.308048ms 693.362826ms 694.646368ms 697.345853ms 698.239474ms 700.88074ms 706.89356ms 709.587786ms 709.711228ms 712.934034ms 716.922626ms 735.529611ms 752.647721ms 756.78133ms 759.689571ms 760.01877ms 767.927727ms 771.110337ms 775.934389ms 790.074901ms 791.691244ms 800.593791ms 814.407522ms 816.233075ms 817.870899ms 819.258935ms 820.295248ms 820.907867ms 821.736702ms 828.698645ms 828.811553ms 829.410366ms 835.294989ms 837.729367ms 842.568941ms 844.675825ms 846.36785ms 848.793703ms 849.484347ms 852.437502ms 855.07848ms 856.205672ms 859.162215ms 873.082709ms 874.327238ms 874.327365ms 880.665046ms 894.589748ms 896.042772ms 898.133529ms 905.305791ms 906.677028ms 918.371488ms 957.3973ms 971.330833ms 971.591555ms 1.006915323s 1.007211505s 1.03877167s 1.043438369s]
Dec  9 20:45:48.360: INFO: 50 %ile: 643.961702ms
Dec  9 20:45:48.360: INFO: 90 %ile: 855.07848ms
Dec  9 20:45:48.360: INFO: 99 %ile: 1.03877167s
Dec  9 20:45:48.360: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:45:48.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-jwr9x" for this suite.
Dec  9 20:46:08.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:46:08.420: INFO: namespace: e2e-tests-svc-latency-jwr9x, resource: bindings, ignored listing per whitelist
Dec  9 20:46:08.543: INFO: namespace e2e-tests-svc-latency-jwr9x deletion completed in 20.175020183s

• [SLOW TEST:31.324 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:46:08.543: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-74977245-fbf3-11e8-8725-0a580af4034b
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-74977245-fbf3-11e8-8725-0a580af4034b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:46:12.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-7mg25" for this suite.
Dec  9 20:46:34.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:46:34.844: INFO: namespace: e2e-tests-configmap-7mg25, resource: bindings, ignored listing per whitelist
Dec  9 20:46:34.930: INFO: namespace e2e-tests-configmap-7mg25 deletion completed in 22.179928248s

• [SLOW TEST:26.387 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:46:34.930: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-84503ac4-fbf3-11e8-8725-0a580af4034b
STEP: Creating a pod to test consume secrets
Dec  9 20:46:35.055: INFO: Waiting up to 5m0s for pod "pod-secrets-84522c26-fbf3-11e8-8725-0a580af4034b" in namespace "e2e-tests-secrets-qxmtc" to be "success or failure"
Dec  9 20:46:35.064: INFO: Pod "pod-secrets-84522c26-fbf3-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.646912ms
Dec  9 20:46:37.069: INFO: Pod "pod-secrets-84522c26-fbf3-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013970687s
STEP: Saw pod success
Dec  9 20:46:37.069: INFO: Pod "pod-secrets-84522c26-fbf3-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 20:46:37.075: INFO: Trying to get logs from node k8s04 pod pod-secrets-84522c26-fbf3-11e8-8725-0a580af4034b container secret-volume-test: <nil>
STEP: delete the pod
Dec  9 20:46:37.122: INFO: Waiting for pod pod-secrets-84522c26-fbf3-11e8-8725-0a580af4034b to disappear
Dec  9 20:46:37.128: INFO: Pod pod-secrets-84522c26-fbf3-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:46:37.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-qxmtc" for this suite.
Dec  9 20:46:43.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:46:43.307: INFO: namespace: e2e-tests-secrets-qxmtc, resource: bindings, ignored listing per whitelist
Dec  9 20:46:43.319: INFO: namespace e2e-tests-secrets-qxmtc deletion completed in 6.181354268s

• [SLOW TEST:8.389 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:46:43.319: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-894faabf-fbf3-11e8-8725-0a580af4034b
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:46:45.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-6jc7h" for this suite.
Dec  9 20:47:07.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:47:07.606: INFO: namespace: e2e-tests-configmap-6jc7h, resource: bindings, ignored listing per whitelist
Dec  9 20:47:07.689: INFO: namespace e2e-tests-configmap-6jc7h deletion completed in 22.185993654s

• [SLOW TEST:24.370 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:47:07.690: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec  9 20:47:07.809: INFO: Waiting up to 5m0s for pod "pod-97d6b077-fbf3-11e8-8725-0a580af4034b" in namespace "e2e-tests-emptydir-zp6bx" to be "success or failure"
Dec  9 20:47:07.816: INFO: Pod "pod-97d6b077-fbf3-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.049412ms
Dec  9 20:47:09.821: INFO: Pod "pod-97d6b077-fbf3-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011528873s
STEP: Saw pod success
Dec  9 20:47:09.821: INFO: Pod "pod-97d6b077-fbf3-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 20:47:09.827: INFO: Trying to get logs from node k8s04 pod pod-97d6b077-fbf3-11e8-8725-0a580af4034b container test-container: <nil>
STEP: delete the pod
Dec  9 20:47:09.858: INFO: Waiting for pod pod-97d6b077-fbf3-11e8-8725-0a580af4034b to disappear
Dec  9 20:47:09.862: INFO: Pod pod-97d6b077-fbf3-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:47:09.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-zp6bx" for this suite.
Dec  9 20:47:15.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:47:16.000: INFO: namespace: e2e-tests-emptydir-zp6bx, resource: bindings, ignored listing per whitelist
Dec  9 20:47:16.072: INFO: namespace e2e-tests-emptydir-zp6bx deletion completed in 6.201456823s

• [SLOW TEST:8.382 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:47:16.072: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:47:40.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-9qqcc" for this suite.
Dec  9 20:47:46.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:47:46.657: INFO: namespace: e2e-tests-container-runtime-9qqcc, resource: bindings, ignored listing per whitelist
Dec  9 20:47:46.671: INFO: namespace e2e-tests-container-runtime-9qqcc deletion completed in 6.172877372s

• [SLOW TEST:30.600 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:47:46.672: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:47:57.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-6x678" for this suite.
Dec  9 20:48:19.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:48:19.971: INFO: namespace: e2e-tests-replication-controller-6x678, resource: bindings, ignored listing per whitelist
Dec  9 20:48:20.281: INFO: namespace e2e-tests-replication-controller-6x678 deletion completed in 22.429803965s

• [SLOW TEST:33.609 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:48:20.281: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec  9 20:48:20.381: INFO: PodSpec: initContainers in spec.initContainers
Dec  9 20:49:05.182: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-c31bf10e-fbf3-11e8-8725-0a580af4034b", GenerateName:"", Namespace:"e2e-tests-init-container-q62qd", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-q62qd/pods/pod-init-c31bf10e-fbf3-11e8-8725-0a580af4034b", UID:"c31cdae0-fbf3-11e8-925a-000c296b480b", ResourceVersion:"44259", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63679985300, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"381318390"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-5954c", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001dea240), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-5954c", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-5954c", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-5954c", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0016629f8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"k8s04", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00116c840), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001662af0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001662b10)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001662b18), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001662b1c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679985300, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679985300, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679985300, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679985300, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.9.14", PodIP:"10.244.3.195", StartTime:(*v1.Time)(0xc0013a8120), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001941340)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001941420)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:2a03a6059f21e150ae84b0973863609494aad70f0a80eaeb64bddd8d92465812", ContainerID:"docker://ee4c3a025b7b0633bec7a2b9b1e1b0fc5c41b8836f3d63c8009226b003f55049"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0013a81a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0013a8160), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:49:05.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-q62qd" for this suite.
Dec  9 20:49:27.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:49:27.255: INFO: namespace: e2e-tests-init-container-q62qd, resource: bindings, ignored listing per whitelist
Dec  9 20:49:27.383: INFO: namespace e2e-tests-init-container-q62qd deletion completed in 22.183721449s

• [SLOW TEST:67.102 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:49:27.383: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-eb1b40e2-fbf3-11e8-8725-0a580af4034b
STEP: Creating a pod to test consume configMaps
Dec  9 20:49:27.513: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-eb1d0fcd-fbf3-11e8-8725-0a580af4034b" in namespace "e2e-tests-projected-6vvzj" to be "success or failure"
Dec  9 20:49:27.524: INFO: Pod "pod-projected-configmaps-eb1d0fcd-fbf3-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.825765ms
Dec  9 20:49:29.529: INFO: Pod "pod-projected-configmaps-eb1d0fcd-fbf3-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01605983s
STEP: Saw pod success
Dec  9 20:49:29.529: INFO: Pod "pod-projected-configmaps-eb1d0fcd-fbf3-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 20:49:29.532: INFO: Trying to get logs from node k8s04 pod pod-projected-configmaps-eb1d0fcd-fbf3-11e8-8725-0a580af4034b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  9 20:49:29.576: INFO: Waiting for pod pod-projected-configmaps-eb1d0fcd-fbf3-11e8-8725-0a580af4034b to disappear
Dec  9 20:49:29.583: INFO: Pod pod-projected-configmaps-eb1d0fcd-fbf3-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:49:29.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6vvzj" for this suite.
Dec  9 20:49:35.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:49:35.713: INFO: namespace: e2e-tests-projected-6vvzj, resource: bindings, ignored listing per whitelist
Dec  9 20:49:35.767: INFO: namespace e2e-tests-projected-6vvzj deletion completed in 6.17580078s

• [SLOW TEST:8.384 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:49:35.767: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Dec  9 20:49:35.885: INFO: Waiting up to 5m0s for pod "var-expansion-f01a37dd-fbf3-11e8-8725-0a580af4034b" in namespace "e2e-tests-var-expansion-xp6pb" to be "success or failure"
Dec  9 20:49:35.895: INFO: Pod "var-expansion-f01a37dd-fbf3-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.927323ms
Dec  9 20:49:37.909: INFO: Pod "var-expansion-f01a37dd-fbf3-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023110385s
STEP: Saw pod success
Dec  9 20:49:37.909: INFO: Pod "var-expansion-f01a37dd-fbf3-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 20:49:37.913: INFO: Trying to get logs from node k8s04 pod var-expansion-f01a37dd-fbf3-11e8-8725-0a580af4034b container dapi-container: <nil>
STEP: delete the pod
Dec  9 20:49:37.948: INFO: Waiting for pod var-expansion-f01a37dd-fbf3-11e8-8725-0a580af4034b to disappear
Dec  9 20:49:37.953: INFO: Pod var-expansion-f01a37dd-fbf3-11e8-8725-0a580af4034b no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:49:37.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-xp6pb" for this suite.
Dec  9 20:49:43.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:49:44.131: INFO: namespace: e2e-tests-var-expansion-xp6pb, resource: bindings, ignored listing per whitelist
Dec  9 20:49:44.151: INFO: namespace e2e-tests-var-expansion-xp6pb deletion completed in 6.189163076s

• [SLOW TEST:8.384 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:49:44.151: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Dec  9 20:49:44.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 create -f - --namespace=e2e-tests-kubectl-bgrfs'
Dec  9 20:49:44.540: INFO: stderr: ""
Dec  9 20:49:44.540: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  9 20:49:44.540: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bgrfs'
Dec  9 20:49:44.661: INFO: stderr: ""
Dec  9 20:49:44.661: INFO: stdout: "update-demo-nautilus-5jkrm update-demo-nautilus-nrrws "
Dec  9 20:49:44.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods update-demo-nautilus-5jkrm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bgrfs'
Dec  9 20:49:44.757: INFO: stderr: ""
Dec  9 20:49:44.757: INFO: stdout: ""
Dec  9 20:49:44.757: INFO: update-demo-nautilus-5jkrm is created but not running
Dec  9 20:49:49.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bgrfs'
Dec  9 20:49:49.864: INFO: stderr: ""
Dec  9 20:49:49.864: INFO: stdout: "update-demo-nautilus-5jkrm update-demo-nautilus-nrrws "
Dec  9 20:49:49.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods update-demo-nautilus-5jkrm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bgrfs'
Dec  9 20:49:49.960: INFO: stderr: ""
Dec  9 20:49:49.960: INFO: stdout: "true"
Dec  9 20:49:49.960: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods update-demo-nautilus-5jkrm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bgrfs'
Dec  9 20:49:50.061: INFO: stderr: ""
Dec  9 20:49:50.061: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  9 20:49:50.061: INFO: validating pod update-demo-nautilus-5jkrm
Dec  9 20:49:50.070: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  9 20:49:50.070: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  9 20:49:50.070: INFO: update-demo-nautilus-5jkrm is verified up and running
Dec  9 20:49:50.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods update-demo-nautilus-nrrws -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bgrfs'
Dec  9 20:49:50.172: INFO: stderr: ""
Dec  9 20:49:50.172: INFO: stdout: "true"
Dec  9 20:49:50.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods update-demo-nautilus-nrrws -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bgrfs'
Dec  9 20:49:50.261: INFO: stderr: ""
Dec  9 20:49:50.262: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  9 20:49:50.262: INFO: validating pod update-demo-nautilus-nrrws
Dec  9 20:49:50.269: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  9 20:49:50.269: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  9 20:49:50.269: INFO: update-demo-nautilus-nrrws is verified up and running
STEP: rolling-update to new replication controller
Dec  9 20:49:50.272: INFO: scanned /root for discovery docs: <nil>
Dec  9 20:49:50.272: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-bgrfs'
Dec  9 20:50:12.718: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec  9 20:50:12.718: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  9 20:50:12.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bgrfs'
Dec  9 20:50:12.824: INFO: stderr: ""
Dec  9 20:50:12.824: INFO: stdout: "update-demo-kitten-dkfz2 update-demo-kitten-g66kd "
Dec  9 20:50:12.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods update-demo-kitten-dkfz2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bgrfs'
Dec  9 20:50:12.918: INFO: stderr: ""
Dec  9 20:50:12.918: INFO: stdout: "true"
Dec  9 20:50:12.918: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods update-demo-kitten-dkfz2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bgrfs'
Dec  9 20:50:13.005: INFO: stderr: ""
Dec  9 20:50:13.005: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec  9 20:50:13.005: INFO: validating pod update-demo-kitten-dkfz2
Dec  9 20:50:13.014: INFO: got data: {
  "image": "kitten.jpg"
}

Dec  9 20:50:13.014: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec  9 20:50:13.014: INFO: update-demo-kitten-dkfz2 is verified up and running
Dec  9 20:50:13.014: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods update-demo-kitten-g66kd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bgrfs'
Dec  9 20:50:13.107: INFO: stderr: ""
Dec  9 20:50:13.107: INFO: stdout: "true"
Dec  9 20:50:13.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods update-demo-kitten-g66kd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bgrfs'
Dec  9 20:50:13.197: INFO: stderr: ""
Dec  9 20:50:13.197: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec  9 20:50:13.198: INFO: validating pod update-demo-kitten-g66kd
Dec  9 20:50:13.204: INFO: got data: {
  "image": "kitten.jpg"
}

Dec  9 20:50:13.204: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec  9 20:50:13.204: INFO: update-demo-kitten-g66kd is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:50:13.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bgrfs" for this suite.
Dec  9 20:50:35.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:50:35.337: INFO: namespace: e2e-tests-kubectl-bgrfs, resource: bindings, ignored listing per whitelist
Dec  9 20:50:35.394: INFO: namespace e2e-tests-kubectl-bgrfs deletion completed in 22.182186861s

• [SLOW TEST:51.243 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:50:35.394: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  9 20:50:35.529: INFO: Waiting up to 5m0s for pod "downward-api-13a6f35e-fbf4-11e8-8725-0a580af4034b" in namespace "e2e-tests-downward-api-xcj7l" to be "success or failure"
Dec  9 20:50:35.537: INFO: Pod "downward-api-13a6f35e-fbf4-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.712915ms
Dec  9 20:50:37.542: INFO: Pod "downward-api-13a6f35e-fbf4-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012579176s
STEP: Saw pod success
Dec  9 20:50:37.542: INFO: Pod "downward-api-13a6f35e-fbf4-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 20:50:37.546: INFO: Trying to get logs from node k8s04 pod downward-api-13a6f35e-fbf4-11e8-8725-0a580af4034b container dapi-container: <nil>
STEP: delete the pod
Dec  9 20:50:37.582: INFO: Waiting for pod downward-api-13a6f35e-fbf4-11e8-8725-0a580af4034b to disappear
Dec  9 20:50:37.586: INFO: Pod downward-api-13a6f35e-fbf4-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:50:37.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xcj7l" for this suite.
Dec  9 20:50:43.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:50:43.709: INFO: namespace: e2e-tests-downward-api-xcj7l, resource: bindings, ignored listing per whitelist
Dec  9 20:50:43.772: INFO: namespace e2e-tests-downward-api-xcj7l deletion completed in 6.177640247s

• [SLOW TEST:8.379 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:50:43.772: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Dec  9 20:51:00.966: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:51:01.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-ghn59" for this suite.
Dec  9 20:51:24.019: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:51:24.075: INFO: namespace: e2e-tests-replicaset-ghn59, resource: bindings, ignored listing per whitelist
Dec  9 20:51:24.177: INFO: namespace e2e-tests-replicaset-ghn59 deletion completed in 22.177908184s

• [SLOW TEST:40.405 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:51:24.177: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec  9 20:51:24.333: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:51:24.333: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:51:24.333: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:51:24.343: INFO: Number of nodes with available pods: 0
Dec  9 20:51:24.343: INFO: Node k8s04 is running more than one daemon pod
Dec  9 20:51:25.350: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:51:25.350: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:51:25.350: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:51:25.354: INFO: Number of nodes with available pods: 0
Dec  9 20:51:25.354: INFO: Node k8s04 is running more than one daemon pod
Dec  9 20:51:26.349: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:51:26.349: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:51:26.349: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:51:26.353: INFO: Number of nodes with available pods: 1
Dec  9 20:51:26.353: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Dec  9 20:51:26.377: INFO: DaemonSet pods can't tolerate node k8s01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:51:26.377: INFO: DaemonSet pods can't tolerate node k8s02 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:51:26.377: INFO: DaemonSet pods can't tolerate node k8s03 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  9 20:51:26.386: INFO: Number of nodes with available pods: 1
Dec  9 20:51:26.386: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-zb6r8, will wait for the garbage collector to delete the pods
Dec  9 20:51:27.473: INFO: Deleting DaemonSet.extensions daemon-set took: 12.437924ms
Dec  9 20:51:27.574: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.069758ms
Dec  9 20:53:20.787: INFO: Number of nodes with available pods: 0
Dec  9 20:53:20.787: INFO: Number of running nodes: 0, number of available pods: 0
Dec  9 20:53:20.791: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-zb6r8/daemonsets","resourceVersion":"44983"},"items":null}

Dec  9 20:53:20.796: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-zb6r8/pods","resourceVersion":"44983"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:53:20.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-zb6r8" for this suite.
Dec  9 20:53:26.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:53:26.898: INFO: namespace: e2e-tests-daemonsets-zb6r8, resource: bindings, ignored listing per whitelist
Dec  9 20:53:26.990: INFO: namespace e2e-tests-daemonsets-zb6r8 deletion completed in 6.178887801s

• [SLOW TEST:122.813 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:53:26.990: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-79ece8e4-fbf4-11e8-8725-0a580af4034b
STEP: Creating a pod to test consume secrets
Dec  9 20:53:27.123: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-79ef2a81-fbf4-11e8-8725-0a580af4034b" in namespace "e2e-tests-projected-8f8lc" to be "success or failure"
Dec  9 20:53:27.129: INFO: Pod "pod-projected-secrets-79ef2a81-fbf4-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.183344ms
Dec  9 20:53:29.134: INFO: Pod "pod-projected-secrets-79ef2a81-fbf4-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011217548s
STEP: Saw pod success
Dec  9 20:53:29.134: INFO: Pod "pod-projected-secrets-79ef2a81-fbf4-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 20:53:29.138: INFO: Trying to get logs from node k8s04 pod pod-projected-secrets-79ef2a81-fbf4-11e8-8725-0a580af4034b container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  9 20:53:29.163: INFO: Waiting for pod pod-projected-secrets-79ef2a81-fbf4-11e8-8725-0a580af4034b to disappear
Dec  9 20:53:29.169: INFO: Pod pod-projected-secrets-79ef2a81-fbf4-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:53:29.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8f8lc" for this suite.
Dec  9 20:53:35.205: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:53:35.347: INFO: namespace: e2e-tests-projected-8f8lc, resource: bindings, ignored listing per whitelist
Dec  9 20:53:35.360: INFO: namespace e2e-tests-projected-8f8lc deletion completed in 6.183438099s

• [SLOW TEST:8.370 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:53:35.361: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-7ee8bb84-fbf4-11e8-8725-0a580af4034b
STEP: Creating a pod to test consume configMaps
Dec  9 20:53:35.479: INFO: Waiting up to 5m0s for pod "pod-configmaps-7eea29df-fbf4-11e8-8725-0a580af4034b" in namespace "e2e-tests-configmap-8gfkq" to be "success or failure"
Dec  9 20:53:35.491: INFO: Pod "pod-configmaps-7eea29df-fbf4-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.548625ms
Dec  9 20:53:37.496: INFO: Pod "pod-configmaps-7eea29df-fbf4-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016887893s
STEP: Saw pod success
Dec  9 20:53:37.496: INFO: Pod "pod-configmaps-7eea29df-fbf4-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 20:53:37.500: INFO: Trying to get logs from node k8s04 pod pod-configmaps-7eea29df-fbf4-11e8-8725-0a580af4034b container configmap-volume-test: <nil>
STEP: delete the pod
Dec  9 20:53:37.529: INFO: Waiting for pod pod-configmaps-7eea29df-fbf4-11e8-8725-0a580af4034b to disappear
Dec  9 20:53:37.533: INFO: Pod pod-configmaps-7eea29df-fbf4-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:53:37.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-8gfkq" for this suite.
Dec  9 20:53:43.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:53:43.629: INFO: namespace: e2e-tests-configmap-8gfkq, resource: bindings, ignored listing per whitelist
Dec  9 20:53:43.734: INFO: namespace e2e-tests-configmap-8gfkq deletion completed in 6.184628527s

• [SLOW TEST:8.374 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:53:43.735: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Dec  9 20:53:45.866: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-83e63bce-fbf4-11e8-8725-0a580af4034b,GenerateName:,Namespace:e2e-tests-events-w6kv4,SelfLink:/api/v1/namespaces/e2e-tests-events-w6kv4/pods/send-events-83e63bce-fbf4-11e8-8725-0a580af4034b,UID:83e7456b-fbf4-11e8-925a-000c296b480b,ResourceVersion:45111,Generation:0,CreationTimestamp:2018-12-09 20:53:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 829627605,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vskqt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vskqt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-vskqt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s04,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00185f0e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00185f100}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:53:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:53:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:53:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:53:43 +0000 UTC  }],Message:,Reason:,HostIP:192.168.9.14,PodIP:10.244.3.209,StartTime:2018-12-09 20:53:43 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2018-12-09 20:53:44 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://0abc8f02854949a9ae7536fc1d72467f17ecdac8631cb2498caf8563291f9ffc}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Dec  9 20:53:47.874: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Dec  9 20:53:49.881: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:53:49.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-w6kv4" for this suite.
Dec  9 20:54:31.913: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:54:32.048: INFO: namespace: e2e-tests-events-w6kv4, resource: bindings, ignored listing per whitelist
Dec  9 20:54:32.076: INFO: namespace e2e-tests-events-w6kv4 deletion completed in 42.179188067s

• [SLOW TEST:48.342 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:54:32.076: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:54:38.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-hwghg" for this suite.
Dec  9 20:54:44.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:54:44.463: INFO: namespace: e2e-tests-namespaces-hwghg, resource: bindings, ignored listing per whitelist
Dec  9 20:54:44.512: INFO: namespace e2e-tests-namespaces-hwghg deletion completed in 6.182057438s
STEP: Destroying namespace "e2e-tests-nsdeletetest-hlklc" for this suite.
Dec  9 20:54:44.516: INFO: Namespace e2e-tests-nsdeletetest-hlklc was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-h74dv" for this suite.
Dec  9 20:54:50.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:54:50.672: INFO: namespace: e2e-tests-nsdeletetest-h74dv, resource: bindings, ignored listing per whitelist
Dec  9 20:54:50.693: INFO: namespace e2e-tests-nsdeletetest-h74dv deletion completed in 6.176900348s

• [SLOW TEST:18.616 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:54:50.693: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:54:52.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-tt6sv" for this suite.
Dec  9 20:55:44.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:55:44.939: INFO: namespace: e2e-tests-kubelet-test-tt6sv, resource: bindings, ignored listing per whitelist
Dec  9 20:55:45.061: INFO: namespace e2e-tests-kubelet-test-tt6sv deletion completed in 52.22064159s

• [SLOW TEST:54.368 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:55:45.061: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec  9 20:55:45.170: INFO: Waiting up to 5m0s for pod "pod-cc3772ca-fbf4-11e8-8725-0a580af4034b" in namespace "e2e-tests-emptydir-t4849" to be "success or failure"
Dec  9 20:55:45.179: INFO: Pod "pod-cc3772ca-fbf4-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.262422ms
Dec  9 20:55:47.183: INFO: Pod "pod-cc3772ca-fbf4-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012228099s
STEP: Saw pod success
Dec  9 20:55:47.183: INFO: Pod "pod-cc3772ca-fbf4-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 20:55:47.187: INFO: Trying to get logs from node k8s04 pod pod-cc3772ca-fbf4-11e8-8725-0a580af4034b container test-container: <nil>
STEP: delete the pod
Dec  9 20:55:47.208: INFO: Waiting for pod pod-cc3772ca-fbf4-11e8-8725-0a580af4034b to disappear
Dec  9 20:55:47.215: INFO: Pod pod-cc3772ca-fbf4-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:55:47.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-t4849" for this suite.
Dec  9 20:55:53.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:55:53.358: INFO: namespace: e2e-tests-emptydir-t4849, resource: bindings, ignored listing per whitelist
Dec  9 20:55:53.401: INFO: namespace e2e-tests-emptydir-t4849 deletion completed in 6.177796801s

• [SLOW TEST:8.340 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:55:53.401: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Dec  9 20:55:53.498: INFO: Waiting up to 5m0s for pod "pod-d12e53a7-fbf4-11e8-8725-0a580af4034b" in namespace "e2e-tests-emptydir-w9kfh" to be "success or failure"
Dec  9 20:55:53.510: INFO: Pod "pod-d12e53a7-fbf4-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.845753ms
Dec  9 20:55:55.522: INFO: Pod "pod-d12e53a7-fbf4-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023942581s
STEP: Saw pod success
Dec  9 20:55:55.523: INFO: Pod "pod-d12e53a7-fbf4-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 20:55:55.527: INFO: Trying to get logs from node k8s04 pod pod-d12e53a7-fbf4-11e8-8725-0a580af4034b container test-container: <nil>
STEP: delete the pod
Dec  9 20:55:55.551: INFO: Waiting for pod pod-d12e53a7-fbf4-11e8-8725-0a580af4034b to disappear
Dec  9 20:55:55.556: INFO: Pod pod-d12e53a7-fbf4-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:55:55.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-w9kfh" for this suite.
Dec  9 20:56:01.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:56:01.732: INFO: namespace: e2e-tests-emptydir-w9kfh, resource: bindings, ignored listing per whitelist
Dec  9 20:56:01.743: INFO: namespace e2e-tests-emptydir-w9kfh deletion completed in 6.179011122s

• [SLOW TEST:8.341 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:56:01.743: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec  9 20:56:01.840: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:56:05.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-fks2r" for this suite.
Dec  9 20:56:11.809: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:56:11.829: INFO: namespace: e2e-tests-init-container-fks2r, resource: bindings, ignored listing per whitelist
Dec  9 20:56:11.965: INFO: namespace e2e-tests-init-container-fks2r deletion completed in 6.172707589s

• [SLOW TEST:10.223 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:56:11.966: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Dec  9 20:56:12.059: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-028914468 proxy --unix-socket=/tmp/kubectl-proxy-unix134234163/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:56:12.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-w2g5s" for this suite.
Dec  9 20:56:18.174: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:56:18.300: INFO: namespace: e2e-tests-kubectl-w2g5s, resource: bindings, ignored listing per whitelist
Dec  9 20:56:18.335: INFO: namespace e2e-tests-kubectl-w2g5s deletion completed in 6.181763869s

• [SLOW TEST:6.370 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:56:18.335: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Dec  9 20:56:18.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 api-versions'
Dec  9 20:56:18.515: INFO: stderr: ""
Dec  9 20:56:18.515: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:56:18.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zj6pz" for this suite.
Dec  9 20:56:24.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:56:24.658: INFO: namespace: e2e-tests-kubectl-zj6pz, resource: bindings, ignored listing per whitelist
Dec  9 20:56:24.695: INFO: namespace e2e-tests-kubectl-zj6pz deletion completed in 6.173158169s

• [SLOW TEST:6.360 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:56:24.695: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Dec  9 20:56:24.822: INFO: Waiting up to 5m0s for pod "client-containers-e3d95799-fbf4-11e8-8725-0a580af4034b" in namespace "e2e-tests-containers-6t92p" to be "success or failure"
Dec  9 20:56:24.828: INFO: Pod "client-containers-e3d95799-fbf4-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.470086ms
Dec  9 20:56:26.841: INFO: Pod "client-containers-e3d95799-fbf4-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019382992s
STEP: Saw pod success
Dec  9 20:56:26.841: INFO: Pod "client-containers-e3d95799-fbf4-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 20:56:26.845: INFO: Trying to get logs from node k8s04 pod client-containers-e3d95799-fbf4-11e8-8725-0a580af4034b container test-container: <nil>
STEP: delete the pod
Dec  9 20:56:26.871: INFO: Waiting for pod client-containers-e3d95799-fbf4-11e8-8725-0a580af4034b to disappear
Dec  9 20:56:26.878: INFO: Pod client-containers-e3d95799-fbf4-11e8-8725-0a580af4034b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:56:26.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-6t92p" for this suite.
Dec  9 20:56:32.914: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:56:33.044: INFO: namespace: e2e-tests-containers-6t92p, resource: bindings, ignored listing per whitelist
Dec  9 20:56:33.075: INFO: namespace e2e-tests-containers-6t92p deletion completed in 6.188996839s

• [SLOW TEST:8.380 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:56:33.075: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-e8d49b0e-fbf4-11e8-8725-0a580af4034b
STEP: Creating a pod to test consume configMaps
Dec  9 20:56:33.187: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e8d5c266-fbf4-11e8-8725-0a580af4034b" in namespace "e2e-tests-projected-wn8q6" to be "success or failure"
Dec  9 20:56:33.198: INFO: Pod "pod-projected-configmaps-e8d5c266-fbf4-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.432275ms
Dec  9 20:56:35.204: INFO: Pod "pod-projected-configmaps-e8d5c266-fbf4-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016908457s
STEP: Saw pod success
Dec  9 20:56:35.204: INFO: Pod "pod-projected-configmaps-e8d5c266-fbf4-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 20:56:35.208: INFO: Trying to get logs from node k8s04 pod pod-projected-configmaps-e8d5c266-fbf4-11e8-8725-0a580af4034b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  9 20:56:35.246: INFO: Waiting for pod pod-projected-configmaps-e8d5c266-fbf4-11e8-8725-0a580af4034b to disappear
Dec  9 20:56:35.252: INFO: Pod pod-projected-configmaps-e8d5c266-fbf4-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:56:35.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wn8q6" for this suite.
Dec  9 20:56:41.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:56:41.349: INFO: namespace: e2e-tests-projected-wn8q6, resource: bindings, ignored listing per whitelist
Dec  9 20:56:41.458: INFO: namespace e2e-tests-projected-wn8q6 deletion completed in 6.195501706s

• [SLOW TEST:8.383 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:56:41.458: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  9 20:56:41.588: INFO: Creating deployment "test-recreate-deployment"
Dec  9 20:56:41.597: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Dec  9 20:56:41.615: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Dec  9 20:56:43.627: INFO: Waiting deployment "test-recreate-deployment" to complete
Dec  9 20:56:43.632: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Dec  9 20:56:43.645: INFO: Updating deployment test-recreate-deployment
Dec  9 20:56:43.645: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  9 20:56:43.775: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-vqj74,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-vqj74/deployments/test-recreate-deployment,UID:edda3b6e-fbf4-11e8-925a-000c296b480b,ResourceVersion:45685,Generation:2,CreationTimestamp:2018-12-09 20:56:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2018-12-09 20:56:43 +0000 UTC 2018-12-09 20:56:43 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2018-12-09 20:56:43 +0000 UTC 2018-12-09 20:56:41 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Dec  9 20:56:43.788: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-vqj74,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-vqj74/replicasets/test-recreate-deployment-697fbf54bf,UID:ef1c8370-fbf4-11e8-925a-000c296b480b,ResourceVersion:45684,Generation:1,CreationTimestamp:2018-12-09 20:56:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment edda3b6e-fbf4-11e8-925a-000c296b480b 0xc001f3f487 0xc001f3f488}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  9 20:56:43.788: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Dec  9 20:56:43.789: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-vqj74,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-vqj74/replicasets/test-recreate-deployment-5dfdcc846d,UID:eddecc74-fbf4-11e8-925a-000c296b480b,ResourceVersion:45673,Generation:2,CreationTimestamp:2018-12-09 20:56:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment edda3b6e-fbf4-11e8-925a-000c296b480b 0xc001f3f3c7 0xc001f3f3c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  9 20:56:43.801: INFO: Pod "test-recreate-deployment-697fbf54bf-294jz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-294jz,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-vqj74,SelfLink:/api/v1/namespaces/e2e-tests-deployment-vqj74/pods/test-recreate-deployment-697fbf54bf-294jz,UID:ef1da717-fbf4-11e8-925a-000c296b480b,ResourceVersion:45683,Generation:0,CreationTimestamp:2018-12-09 20:56:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf ef1c8370-fbf4-11e8-925a-000c296b480b 0xc001977e17 0xc001977e18}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9twgf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9twgf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9twgf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s04,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001977e90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001977eb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:56:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:56:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:56:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 20:56:43 +0000 UTC  }],Message:,Reason:,HostIP:192.168.9.14,PodIP:,StartTime:2018-12-09 20:56:43 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:56:43.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-vqj74" for this suite.
Dec  9 20:56:49.828: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:56:49.961: INFO: namespace: e2e-tests-deployment-vqj74, resource: bindings, ignored listing per whitelist
Dec  9 20:56:49.976: INFO: namespace e2e-tests-deployment-vqj74 deletion completed in 6.168493571s

• [SLOW TEST:8.518 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:56:49.977: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec  9 20:56:50.086: INFO: Waiting up to 5m0s for pod "pod-f2e89463-fbf4-11e8-8725-0a580af4034b" in namespace "e2e-tests-emptydir-dlw4p" to be "success or failure"
Dec  9 20:56:50.094: INFO: Pod "pod-f2e89463-fbf4-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.09028ms
Dec  9 20:56:52.098: INFO: Pod "pod-f2e89463-fbf4-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012399636s
STEP: Saw pod success
Dec  9 20:56:52.098: INFO: Pod "pod-f2e89463-fbf4-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 20:56:52.102: INFO: Trying to get logs from node k8s04 pod pod-f2e89463-fbf4-11e8-8725-0a580af4034b container test-container: <nil>
STEP: delete the pod
Dec  9 20:56:52.126: INFO: Waiting for pod pod-f2e89463-fbf4-11e8-8725-0a580af4034b to disappear
Dec  9 20:56:52.134: INFO: Pod pod-f2e89463-fbf4-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:56:52.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-dlw4p" for this suite.
Dec  9 20:56:58.176: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:56:58.293: INFO: namespace: e2e-tests-emptydir-dlw4p, resource: bindings, ignored listing per whitelist
Dec  9 20:56:58.324: INFO: namespace e2e-tests-emptydir-dlw4p deletion completed in 6.181130999s

• [SLOW TEST:8.348 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:56:58.325: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:57:00.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-kzgxn" for this suite.
Dec  9 20:57:42.478: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:57:42.598: INFO: namespace: e2e-tests-kubelet-test-kzgxn, resource: bindings, ignored listing per whitelist
Dec  9 20:57:42.670: INFO: namespace e2e-tests-kubelet-test-kzgxn deletion completed in 42.207548405s

• [SLOW TEST:44.346 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:57:42.670: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  9 20:57:42.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-j62ck'
Dec  9 20:57:42.880: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  9 20:57:42.880: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Dec  9 20:57:42.887: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Dec  9 20:57:42.906: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Dec  9 20:57:42.922: INFO: scanned /root for discovery docs: <nil>
Dec  9 20:57:42.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-j62ck'
Dec  9 20:57:58.810: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec  9 20:57:58.810: INFO: stdout: "Created e2e-test-nginx-rc-920559aaec045f5375f7b83c4546f7a2\nScaling up e2e-test-nginx-rc-920559aaec045f5375f7b83c4546f7a2 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-920559aaec045f5375f7b83c4546f7a2 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-920559aaec045f5375f7b83c4546f7a2 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Dec  9 20:57:58.810: INFO: stdout: "Created e2e-test-nginx-rc-920559aaec045f5375f7b83c4546f7a2\nScaling up e2e-test-nginx-rc-920559aaec045f5375f7b83c4546f7a2 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-920559aaec045f5375f7b83c4546f7a2 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-920559aaec045f5375f7b83c4546f7a2 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Dec  9 20:57:58.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-j62ck'
Dec  9 20:57:58.907: INFO: stderr: ""
Dec  9 20:57:58.907: INFO: stdout: "e2e-test-nginx-rc-920559aaec045f5375f7b83c4546f7a2-tsmsk e2e-test-nginx-rc-nzhbt "
STEP: Replicas for run=e2e-test-nginx-rc: expected=1 actual=2
Dec  9 20:58:03.908: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-j62ck'
Dec  9 20:58:03.994: INFO: stderr: ""
Dec  9 20:58:03.994: INFO: stdout: "e2e-test-nginx-rc-920559aaec045f5375f7b83c4546f7a2-tsmsk "
Dec  9 20:58:03.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods e2e-test-nginx-rc-920559aaec045f5375f7b83c4546f7a2-tsmsk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-j62ck'
Dec  9 20:58:04.075: INFO: stderr: ""
Dec  9 20:58:04.075: INFO: stdout: "true"
Dec  9 20:58:04.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods e2e-test-nginx-rc-920559aaec045f5375f7b83c4546f7a2-tsmsk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-j62ck'
Dec  9 20:58:04.151: INFO: stderr: ""
Dec  9 20:58:04.151: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Dec  9 20:58:04.151: INFO: e2e-test-nginx-rc-920559aaec045f5375f7b83c4546f7a2-tsmsk is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Dec  9 20:58:04.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-j62ck'
Dec  9 20:58:04.251: INFO: stderr: ""
Dec  9 20:58:04.251: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:58:04.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-j62ck" for this suite.
Dec  9 20:58:26.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:58:26.357: INFO: namespace: e2e-tests-kubectl-j62ck, resource: bindings, ignored listing per whitelist
Dec  9 20:58:26.483: INFO: namespace e2e-tests-kubectl-j62ck deletion completed in 22.224409072s

• [SLOW TEST:43.813 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:58:26.483: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  9 20:58:26.589: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2c6e27c1-fbf5-11e8-8725-0a580af4034b" in namespace "e2e-tests-downward-api-tg9kb" to be "success or failure"
Dec  9 20:58:26.600: INFO: Pod "downwardapi-volume-2c6e27c1-fbf5-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.172979ms
Dec  9 20:58:28.605: INFO: Pod "downwardapi-volume-2c6e27c1-fbf5-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016446356s
STEP: Saw pod success
Dec  9 20:58:28.605: INFO: Pod "downwardapi-volume-2c6e27c1-fbf5-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 20:58:28.609: INFO: Trying to get logs from node k8s04 pod downwardapi-volume-2c6e27c1-fbf5-11e8-8725-0a580af4034b container client-container: <nil>
STEP: delete the pod
Dec  9 20:58:28.632: INFO: Waiting for pod downwardapi-volume-2c6e27c1-fbf5-11e8-8725-0a580af4034b to disappear
Dec  9 20:58:28.640: INFO: Pod downwardapi-volume-2c6e27c1-fbf5-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:58:28.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-tg9kb" for this suite.
Dec  9 20:58:34.672: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:58:34.718: INFO: namespace: e2e-tests-downward-api-tg9kb, resource: bindings, ignored listing per whitelist
Dec  9 20:58:34.825: INFO: namespace e2e-tests-downward-api-tg9kb deletion completed in 6.176795053s

• [SLOW TEST:8.342 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:58:34.825: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Dec  9 20:58:34.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 create -f - --namespace=e2e-tests-kubectl-7ncxl'
Dec  9 20:58:35.299: INFO: stderr: ""
Dec  9 20:58:35.299: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  9 20:58:35.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-7ncxl'
Dec  9 20:58:35.421: INFO: stderr: ""
Dec  9 20:58:35.421: INFO: stdout: "update-demo-nautilus-4fhhv update-demo-nautilus-sgzsb "
Dec  9 20:58:35.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods update-demo-nautilus-4fhhv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7ncxl'
Dec  9 20:58:35.496: INFO: stderr: ""
Dec  9 20:58:35.496: INFO: stdout: ""
Dec  9 20:58:35.496: INFO: update-demo-nautilus-4fhhv is created but not running
Dec  9 20:58:40.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-7ncxl'
Dec  9 20:58:40.584: INFO: stderr: ""
Dec  9 20:58:40.584: INFO: stdout: "update-demo-nautilus-4fhhv update-demo-nautilus-sgzsb "
Dec  9 20:58:40.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods update-demo-nautilus-4fhhv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7ncxl'
Dec  9 20:58:40.670: INFO: stderr: ""
Dec  9 20:58:40.670: INFO: stdout: "true"
Dec  9 20:58:40.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods update-demo-nautilus-4fhhv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7ncxl'
Dec  9 20:58:40.748: INFO: stderr: ""
Dec  9 20:58:40.748: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  9 20:58:40.748: INFO: validating pod update-demo-nautilus-4fhhv
Dec  9 20:58:40.760: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  9 20:58:40.760: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  9 20:58:40.760: INFO: update-demo-nautilus-4fhhv is verified up and running
Dec  9 20:58:40.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods update-demo-nautilus-sgzsb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7ncxl'
Dec  9 20:58:40.843: INFO: stderr: ""
Dec  9 20:58:40.843: INFO: stdout: "true"
Dec  9 20:58:40.843: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods update-demo-nautilus-sgzsb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7ncxl'
Dec  9 20:58:40.913: INFO: stderr: ""
Dec  9 20:58:40.913: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  9 20:58:40.913: INFO: validating pod update-demo-nautilus-sgzsb
Dec  9 20:58:40.919: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  9 20:58:40.919: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  9 20:58:40.919: INFO: update-demo-nautilus-sgzsb is verified up and running
STEP: using delete to clean up resources
Dec  9 20:58:40.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-7ncxl'
Dec  9 20:58:41.025: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  9 20:58:41.025: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec  9 20:58:41.025: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-7ncxl'
Dec  9 20:58:41.166: INFO: stderr: "No resources found.\n"
Dec  9 20:58:41.166: INFO: stdout: ""
Dec  9 20:58:41.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods -l name=update-demo --namespace=e2e-tests-kubectl-7ncxl -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  9 20:58:41.261: INFO: stderr: ""
Dec  9 20:58:41.261: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:58:41.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7ncxl" for this suite.
Dec  9 20:59:03.296: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:59:03.427: INFO: namespace: e2e-tests-kubectl-7ncxl, resource: bindings, ignored listing per whitelist
Dec  9 20:59:03.458: INFO: namespace e2e-tests-kubectl-7ncxl deletion completed in 22.190021702s

• [SLOW TEST:28.633 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:59:03.458: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec  9 20:59:06.102: INFO: Successfully updated pod "annotationupdate4276e270-fbf5-11e8-8725-0a580af4034b"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:59:10.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5lr9s" for this suite.
Dec  9 20:59:32.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:59:32.227: INFO: namespace: e2e-tests-downward-api-5lr9s, resource: bindings, ignored listing per whitelist
Dec  9 20:59:32.315: INFO: namespace e2e-tests-downward-api-5lr9s deletion completed in 22.173323179s

• [SLOW TEST:28.857 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:59:32.316: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Dec  9 20:59:32.414: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 create -f - --namespace=e2e-tests-kubectl-cd52l'
Dec  9 20:59:32.614: INFO: stderr: ""
Dec  9 20:59:32.614: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  9 20:59:33.620: INFO: Selector matched 1 pods for map[app:redis]
Dec  9 20:59:33.620: INFO: Found 0 / 1
Dec  9 20:59:34.619: INFO: Selector matched 1 pods for map[app:redis]
Dec  9 20:59:34.619: INFO: Found 1 / 1
Dec  9 20:59:34.619: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Dec  9 20:59:34.623: INFO: Selector matched 1 pods for map[app:redis]
Dec  9 20:59:34.623: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  9 20:59:34.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 patch pod redis-master-hmj6f --namespace=e2e-tests-kubectl-cd52l -p {"metadata":{"annotations":{"x":"y"}}}'
Dec  9 20:59:34.715: INFO: stderr: ""
Dec  9 20:59:34.715: INFO: stdout: "pod/redis-master-hmj6f patched\n"
STEP: checking annotations
Dec  9 20:59:34.720: INFO: Selector matched 1 pods for map[app:redis]
Dec  9 20:59:34.720: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 20:59:34.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-cd52l" for this suite.
Dec  9 20:59:56.742: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 20:59:56.845: INFO: namespace: e2e-tests-kubectl-cd52l, resource: bindings, ignored listing per whitelist
Dec  9 20:59:56.889: INFO: namespace e2e-tests-kubectl-cd52l deletion completed in 22.163218149s

• [SLOW TEST:24.573 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 20:59:56.889: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  9 21:00:17.022: INFO: Container started at 2018-12-09 20:59:57 +0000 UTC, pod became ready at 2018-12-09 21:00:15 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:00:17.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-qsbfc" for this suite.
Dec  9 21:00:39.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:00:39.127: INFO: namespace: e2e-tests-container-probe-qsbfc, resource: bindings, ignored listing per whitelist
Dec  9 21:00:39.205: INFO: namespace e2e-tests-container-probe-qsbfc deletion completed in 22.178184258s

• [SLOW TEST:42.317 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:00:39.206: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-7b8bfafb-fbf5-11e8-8725-0a580af4034b
STEP: Creating a pod to test consume configMaps
Dec  9 21:00:39.338: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7b8ddc56-fbf5-11e8-8725-0a580af4034b" in namespace "e2e-tests-projected-tqs45" to be "success or failure"
Dec  9 21:00:39.348: INFO: Pod "pod-projected-configmaps-7b8ddc56-fbf5-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.469629ms
Dec  9 21:00:41.354: INFO: Pod "pod-projected-configmaps-7b8ddc56-fbf5-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015303049s
STEP: Saw pod success
Dec  9 21:00:41.354: INFO: Pod "pod-projected-configmaps-7b8ddc56-fbf5-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 21:00:41.358: INFO: Trying to get logs from node k8s04 pod pod-projected-configmaps-7b8ddc56-fbf5-11e8-8725-0a580af4034b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  9 21:00:41.642: INFO: Waiting for pod pod-projected-configmaps-7b8ddc56-fbf5-11e8-8725-0a580af4034b to disappear
Dec  9 21:00:41.646: INFO: Pod pod-projected-configmaps-7b8ddc56-fbf5-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:00:41.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tqs45" for this suite.
Dec  9 21:00:47.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:00:47.938: INFO: namespace: e2e-tests-projected-tqs45, resource: bindings, ignored listing per whitelist
Dec  9 21:00:48.088: INFO: namespace e2e-tests-projected-tqs45 deletion completed in 6.431353021s

• [SLOW TEST:8.883 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:00:48.088: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-80d535e1-fbf5-11e8-8725-0a580af4034b
STEP: Creating configMap with name cm-test-opt-upd-80d5362a-fbf5-11e8-8725-0a580af4034b
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-80d535e1-fbf5-11e8-8725-0a580af4034b
STEP: Updating configmap cm-test-opt-upd-80d5362a-fbf5-11e8-8725-0a580af4034b
STEP: Creating configMap with name cm-test-opt-create-80d53649-fbf5-11e8-8725-0a580af4034b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:00:52.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-ml2qn" for this suite.
Dec  9 21:01:14.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:01:14.446: INFO: namespace: e2e-tests-configmap-ml2qn, resource: bindings, ignored listing per whitelist
Dec  9 21:01:14.528: INFO: namespace e2e-tests-configmap-ml2qn deletion completed in 22.174307428s

• [SLOW TEST:26.440 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:01:14.528: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  9 21:01:14.637: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9097c447-fbf5-11e8-8725-0a580af4034b" in namespace "e2e-tests-projected-xzjp4" to be "success or failure"
Dec  9 21:01:14.644: INFO: Pod "downwardapi-volume-9097c447-fbf5-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.727193ms
Dec  9 21:01:16.656: INFO: Pod "downwardapi-volume-9097c447-fbf5-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019072491s
STEP: Saw pod success
Dec  9 21:01:16.656: INFO: Pod "downwardapi-volume-9097c447-fbf5-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 21:01:16.660: INFO: Trying to get logs from node k8s04 pod downwardapi-volume-9097c447-fbf5-11e8-8725-0a580af4034b container client-container: <nil>
STEP: delete the pod
Dec  9 21:01:16.702: INFO: Waiting for pod downwardapi-volume-9097c447-fbf5-11e8-8725-0a580af4034b to disappear
Dec  9 21:01:16.707: INFO: Pod downwardapi-volume-9097c447-fbf5-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:01:16.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xzjp4" for this suite.
Dec  9 21:01:22.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:01:22.885: INFO: namespace: e2e-tests-projected-xzjp4, resource: bindings, ignored listing per whitelist
Dec  9 21:01:22.890: INFO: namespace e2e-tests-projected-xzjp4 deletion completed in 6.174150957s

• [SLOW TEST:8.361 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:01:22.890: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-hg7hz in namespace e2e-tests-proxy-zb6k6
I1209 21:01:23.024511      15 runners.go:184] Created replication controller with name: proxy-service-hg7hz, namespace: e2e-tests-proxy-zb6k6, replica count: 1
I1209 21:01:24.075883      15 runners.go:184] proxy-service-hg7hz Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1209 21:01:25.076465      15 runners.go:184] proxy-service-hg7hz Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1209 21:01:26.077075      15 runners.go:184] proxy-service-hg7hz Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1209 21:01:27.077433      15 runners.go:184] proxy-service-hg7hz Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1209 21:01:28.078157      15 runners.go:184] proxy-service-hg7hz Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1209 21:01:29.078749      15 runners.go:184] proxy-service-hg7hz Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  9 21:01:29.091: INFO: setup took 6.108628716s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Dec  9 21:01:29.104: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:160/proxy/: foo (200; 12.195751ms)
Dec  9 21:01:29.109: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25/proxy/rewriteme"... (200; 16.431293ms)
Dec  9 21:01:29.109: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:162/proxy/: bar (200; 16.206808ms)
Dec  9 21:01:29.111: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:160/proxy/: foo (200; 20.031128ms)
Dec  9 21:01:29.112: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:162/proxy/: bar (200; 18.116049ms)
Dec  9 21:01:29.112: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:1080/proxy/rewri... (200; 18.107153ms)
Dec  9 21:01:29.112: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/http:proxy-service-hg7hz:portname1/proxy/: foo (200; 18.90482ms)
Dec  9 21:01:29.116: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/http:proxy-service-hg7hz:portname2/proxy/: bar (200; 23.08653ms)
Dec  9 21:01:29.116: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/proxy-service-hg7hz:portname1/proxy/: foo (200; 23.639401ms)
Dec  9 21:01:29.116: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/proxy-service-hg7hz:portname2/proxy/: bar (200; 23.335025ms)
Dec  9 21:01:29.123: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:443/proxy/... (200; 30.404312ms)
Dec  9 21:01:29.123: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:460/proxy/: tls baz (200; 30.327888ms)
Dec  9 21:01:29.123: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:1080/proxy/... (200; 29.575638ms)
Dec  9 21:01:29.124: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/https:proxy-service-hg7hz:tlsportname2/proxy/: tls qux (200; 30.696078ms)
Dec  9 21:01:29.125: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/https:proxy-service-hg7hz:tlsportname1/proxy/: tls baz (200; 33.249903ms)
Dec  9 21:01:29.132: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:462/proxy/: tls qux (200; 38.400733ms)
Dec  9 21:01:29.151: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:462/proxy/: tls qux (200; 18.945647ms)
Dec  9 21:01:29.152: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:162/proxy/: bar (200; 18.614533ms)
Dec  9 21:01:29.152: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:160/proxy/: foo (200; 19.044959ms)
Dec  9 21:01:29.154: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:160/proxy/: foo (200; 21.81961ms)
Dec  9 21:01:29.154: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:1080/proxy/rewri... (200; 22.047048ms)
Dec  9 21:01:29.155: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:443/proxy/... (200; 21.247095ms)
Dec  9 21:01:29.155: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25/proxy/rewriteme"... (200; 21.481286ms)
Dec  9 21:01:29.159: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/http:proxy-service-hg7hz:portname1/proxy/: foo (200; 25.245296ms)
Dec  9 21:01:29.159: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/https:proxy-service-hg7hz:tlsportname1/proxy/: tls baz (200; 26.427211ms)
Dec  9 21:01:29.159: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:460/proxy/: tls baz (200; 25.788693ms)
Dec  9 21:01:29.159: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/proxy-service-hg7hz:portname2/proxy/: bar (200; 25.156445ms)
Dec  9 21:01:29.159: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:1080/proxy/... (200; 24.539862ms)
Dec  9 21:01:29.159: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/proxy-service-hg7hz:portname1/proxy/: foo (200; 25.7283ms)
Dec  9 21:01:29.163: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/http:proxy-service-hg7hz:portname2/proxy/: bar (200; 28.970395ms)
Dec  9 21:01:29.165: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/https:proxy-service-hg7hz:tlsportname2/proxy/: tls qux (200; 30.044577ms)
Dec  9 21:01:29.165: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:162/proxy/: bar (200; 30.534083ms)
Dec  9 21:01:29.175: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:460/proxy/: tls baz (200; 9.477156ms)
Dec  9 21:01:29.182: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:1080/proxy/... (200; 16.371772ms)
Dec  9 21:01:29.182: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:162/proxy/: bar (200; 14.924048ms)
Dec  9 21:01:29.182: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:162/proxy/: bar (200; 16.27533ms)
Dec  9 21:01:29.186: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/http:proxy-service-hg7hz:portname2/proxy/: bar (200; 18.814536ms)
Dec  9 21:01:29.186: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25/proxy/rewriteme"... (200; 18.805389ms)
Dec  9 21:01:29.186: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:443/proxy/... (200; 18.831846ms)
Dec  9 21:01:29.186: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:462/proxy/: tls qux (200; 19.533855ms)
Dec  9 21:01:29.186: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:1080/proxy/rewri... (200; 19.361809ms)
Dec  9 21:01:29.186: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:160/proxy/: foo (200; 19.120113ms)
Dec  9 21:01:29.186: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:160/proxy/: foo (200; 19.19506ms)
Dec  9 21:01:29.190: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/https:proxy-service-hg7hz:tlsportname1/proxy/: tls baz (200; 22.400905ms)
Dec  9 21:01:29.191: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/https:proxy-service-hg7hz:tlsportname2/proxy/: tls qux (200; 24.203561ms)
Dec  9 21:01:29.191: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/proxy-service-hg7hz:portname2/proxy/: bar (200; 24.378159ms)
Dec  9 21:01:29.191: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/proxy-service-hg7hz:portname1/proxy/: foo (200; 24.451648ms)
Dec  9 21:01:29.191: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/http:proxy-service-hg7hz:portname1/proxy/: foo (200; 24.432501ms)
Dec  9 21:01:29.201: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:162/proxy/: bar (200; 9.052656ms)
Dec  9 21:01:29.204: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:160/proxy/: foo (200; 12.960306ms)
Dec  9 21:01:29.204: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:462/proxy/: tls qux (200; 12.036222ms)
Dec  9 21:01:29.204: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:160/proxy/: foo (200; 12.643972ms)
Dec  9 21:01:29.206: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:460/proxy/: tls baz (200; 13.339272ms)
Dec  9 21:01:29.206: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25/proxy/rewriteme"... (200; 13.798845ms)
Dec  9 21:01:29.206: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:443/proxy/... (200; 13.535975ms)
Dec  9 21:01:29.208: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/https:proxy-service-hg7hz:tlsportname1/proxy/: tls baz (200; 16.09311ms)
Dec  9 21:01:29.210: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/proxy-service-hg7hz:portname2/proxy/: bar (200; 16.937242ms)
Dec  9 21:01:29.213: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:1080/proxy/rewri... (200; 20.433592ms)
Dec  9 21:01:29.213: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/proxy-service-hg7hz:portname1/proxy/: foo (200; 20.84697ms)
Dec  9 21:01:29.213: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:162/proxy/: bar (200; 20.534329ms)
Dec  9 21:01:29.213: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/http:proxy-service-hg7hz:portname1/proxy/: foo (200; 20.787977ms)
Dec  9 21:01:29.215: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:1080/proxy/... (200; 22.575627ms)
Dec  9 21:01:29.218: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/https:proxy-service-hg7hz:tlsportname2/proxy/: tls qux (200; 24.761976ms)
Dec  9 21:01:29.218: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/http:proxy-service-hg7hz:portname2/proxy/: bar (200; 24.861352ms)
Dec  9 21:01:29.227: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:460/proxy/: tls baz (200; 9.248811ms)
Dec  9 21:01:29.233: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:443/proxy/... (200; 13.197973ms)
Dec  9 21:01:29.233: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/proxy-service-hg7hz:portname2/proxy/: bar (200; 14.68785ms)
Dec  9 21:01:29.233: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:162/proxy/: bar (200; 14.280202ms)
Dec  9 21:01:29.233: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:160/proxy/: foo (200; 14.336663ms)
Dec  9 21:01:29.235: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:462/proxy/: tls qux (200; 16.253329ms)
Dec  9 21:01:29.235: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:162/proxy/: bar (200; 15.841879ms)
Dec  9 21:01:29.236: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25/proxy/rewriteme"... (200; 16.359576ms)
Dec  9 21:01:29.236: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:1080/proxy/rewri... (200; 17.068217ms)
Dec  9 21:01:29.236: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/http:proxy-service-hg7hz:portname1/proxy/: foo (200; 17.931072ms)
Dec  9 21:01:29.236: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/http:proxy-service-hg7hz:portname2/proxy/: bar (200; 17.806024ms)
Dec  9 21:01:29.236: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:1080/proxy/... (200; 17.568974ms)
Dec  9 21:01:29.236: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/https:proxy-service-hg7hz:tlsportname2/proxy/: tls qux (200; 17.71683ms)
Dec  9 21:01:29.236: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/proxy-service-hg7hz:portname1/proxy/: foo (200; 18.424381ms)
Dec  9 21:01:29.236: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:160/proxy/: foo (200; 17.001331ms)
Dec  9 21:01:29.246: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/https:proxy-service-hg7hz:tlsportname1/proxy/: tls baz (200; 26.650371ms)
Dec  9 21:01:29.262: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:443/proxy/... (200; 16.349788ms)
Dec  9 21:01:29.263: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:462/proxy/: tls qux (200; 13.988999ms)
Dec  9 21:01:29.263: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:162/proxy/: bar (200; 14.248347ms)
Dec  9 21:01:29.264: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:1080/proxy/... (200; 15.907776ms)
Dec  9 21:01:29.266: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:1080/proxy/rewri... (200; 15.985884ms)
Dec  9 21:01:29.266: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:160/proxy/: foo (200; 16.285724ms)
Dec  9 21:01:29.266: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25/proxy/rewriteme"... (200; 15.335965ms)
Dec  9 21:01:29.266: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:460/proxy/: tls baz (200; 15.474331ms)
Dec  9 21:01:29.269: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:160/proxy/: foo (200; 19.038756ms)
Dec  9 21:01:29.269: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:162/proxy/: bar (200; 18.405497ms)
Dec  9 21:01:29.269: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/http:proxy-service-hg7hz:portname1/proxy/: foo (200; 20.268166ms)
Dec  9 21:01:29.269: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/https:proxy-service-hg7hz:tlsportname2/proxy/: tls qux (200; 21.36439ms)
Dec  9 21:01:29.270: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/http:proxy-service-hg7hz:portname2/proxy/: bar (200; 23.648173ms)
Dec  9 21:01:29.270: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/proxy-service-hg7hz:portname1/proxy/: foo (200; 20.723239ms)
Dec  9 21:01:29.272: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/proxy-service-hg7hz:portname2/proxy/: bar (200; 22.655869ms)
Dec  9 21:01:29.275: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/https:proxy-service-hg7hz:tlsportname1/proxy/: tls baz (200; 24.862394ms)
Dec  9 21:01:29.288: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:162/proxy/: bar (200; 13.207086ms)
Dec  9 21:01:29.290: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:462/proxy/: tls qux (200; 14.564863ms)
Dec  9 21:01:29.290: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:160/proxy/: foo (200; 13.619528ms)
Dec  9 21:01:29.290: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:460/proxy/: tls baz (200; 15.382075ms)
Dec  9 21:01:29.290: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:443/proxy/... (200; 13.758141ms)
Dec  9 21:01:29.300: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:162/proxy/: bar (200; 23.410118ms)
Dec  9 21:01:29.301: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:1080/proxy/... (200; 24.444784ms)
Dec  9 21:01:29.301: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/https:proxy-service-hg7hz:tlsportname1/proxy/: tls baz (200; 24.661766ms)
Dec  9 21:01:29.301: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/proxy-service-hg7hz:portname1/proxy/: foo (200; 25.681441ms)
Dec  9 21:01:29.301: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/https:proxy-service-hg7hz:tlsportname2/proxy/: tls qux (200; 25.162912ms)
Dec  9 21:01:29.302: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/proxy-service-hg7hz:portname2/proxy/: bar (200; 25.580354ms)
Dec  9 21:01:29.302: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:1080/proxy/rewri... (200; 25.393324ms)
Dec  9 21:01:29.302: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/http:proxy-service-hg7hz:portname1/proxy/: foo (200; 25.891652ms)
Dec  9 21:01:29.303: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25/proxy/rewriteme"... (200; 26.785371ms)
Dec  9 21:01:29.305: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:160/proxy/: foo (200; 28.188681ms)
Dec  9 21:01:29.308: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/http:proxy-service-hg7hz:portname2/proxy/: bar (200; 31.761559ms)
Dec  9 21:01:29.322: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:160/proxy/: foo (200; 14.057491ms)
Dec  9 21:01:29.330: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/https:proxy-service-hg7hz:tlsportname1/proxy/: tls baz (200; 21.706826ms)
Dec  9 21:01:29.330: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:160/proxy/: foo (200; 21.71703ms)
Dec  9 21:01:29.330: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:1080/proxy/rewri... (200; 20.755587ms)
Dec  9 21:01:29.330: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:162/proxy/: bar (200; 21.281749ms)
Dec  9 21:01:29.330: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:460/proxy/: tls baz (200; 21.826939ms)
Dec  9 21:01:29.332: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:462/proxy/: tls qux (200; 23.354537ms)
Dec  9 21:01:29.332: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:162/proxy/: bar (200; 23.930968ms)
Dec  9 21:01:29.332: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:1080/proxy/... (200; 23.610749ms)
Dec  9 21:01:29.332: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:443/proxy/... (200; 23.793323ms)
Dec  9 21:01:29.334: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/https:proxy-service-hg7hz:tlsportname2/proxy/: tls qux (200; 26.20457ms)
Dec  9 21:01:29.334: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/proxy-service-hg7hz:portname1/proxy/: foo (200; 25.850086ms)
Dec  9 21:01:29.334: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/http:proxy-service-hg7hz:portname1/proxy/: foo (200; 25.265279ms)
Dec  9 21:01:29.334: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/http:proxy-service-hg7hz:portname2/proxy/: bar (200; 25.929176ms)
Dec  9 21:01:29.334: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25/proxy/rewriteme"... (200; 26.199884ms)
Dec  9 21:01:29.335: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/proxy-service-hg7hz:portname2/proxy/: bar (200; 26.03795ms)
Dec  9 21:01:29.348: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:1080/proxy/... (200; 11.889283ms)
Dec  9 21:01:29.348: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:462/proxy/: tls qux (200; 12.280883ms)
Dec  9 21:01:29.350: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:460/proxy/: tls baz (200; 14.525701ms)
Dec  9 21:01:29.355: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:160/proxy/: foo (200; 18.43092ms)
Dec  9 21:01:29.355: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/https:proxy-service-hg7hz:tlsportname2/proxy/: tls qux (200; 19.911535ms)
Dec  9 21:01:29.356: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:162/proxy/: bar (200; 18.513204ms)
Dec  9 21:01:29.356: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:1080/proxy/rewri... (200; 18.971885ms)
Dec  9 21:01:29.358: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25/proxy/rewriteme"... (200; 20.555982ms)
Dec  9 21:01:29.358: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:443/proxy/... (200; 20.306284ms)
Dec  9 21:01:29.358: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:162/proxy/: bar (200; 22.002698ms)
Dec  9 21:01:29.360: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/proxy-service-hg7hz:portname1/proxy/: foo (200; 23.418236ms)
Dec  9 21:01:29.360: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:160/proxy/: foo (200; 22.596566ms)
Dec  9 21:01:29.363: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/http:proxy-service-hg7hz:portname2/proxy/: bar (200; 26.054796ms)
Dec  9 21:01:29.365: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/https:proxy-service-hg7hz:tlsportname1/proxy/: tls baz (200; 28.396696ms)
Dec  9 21:01:29.366: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/http:proxy-service-hg7hz:portname1/proxy/: foo (200; 29.350363ms)
Dec  9 21:01:29.366: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/proxy-service-hg7hz:portname2/proxy/: bar (200; 29.250185ms)
Dec  9 21:01:29.388: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:462/proxy/: tls qux (200; 21.25656ms)
Dec  9 21:01:29.388: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:162/proxy/: bar (200; 21.373658ms)
Dec  9 21:01:29.388: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:460/proxy/: tls baz (200; 21.849509ms)
Dec  9 21:01:29.388: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:1080/proxy/... (200; 22.211013ms)
Dec  9 21:01:29.394: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:160/proxy/: foo (200; 26.264913ms)
Dec  9 21:01:29.394: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:1080/proxy/rewri... (200; 26.484898ms)
Dec  9 21:01:29.394: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/proxy-service-hg7hz:portname1/proxy/: foo (200; 27.685786ms)
Dec  9 21:01:29.394: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/https:proxy-service-hg7hz:tlsportname2/proxy/: tls qux (200; 26.747184ms)
Dec  9 21:01:29.401: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/proxy-service-hg7hz:portname2/proxy/: bar (200; 34.052326ms)
Dec  9 21:01:29.401: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25/proxy/rewriteme"... (200; 32.988974ms)
Dec  9 21:01:29.402: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/http:proxy-service-hg7hz:portname2/proxy/: bar (200; 35.010113ms)
Dec  9 21:01:29.405: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:443/proxy/... (200; 36.838238ms)
Dec  9 21:01:29.405: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/http:proxy-service-hg7hz:portname1/proxy/: foo (200; 38.341603ms)
Dec  9 21:01:29.405: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:160/proxy/: foo (200; 37.209098ms)
Dec  9 21:01:29.405: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:162/proxy/: bar (200; 37.082547ms)
Dec  9 21:01:29.408: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/https:proxy-service-hg7hz:tlsportname1/proxy/: tls baz (200; 40.379089ms)
Dec  9 21:01:29.426: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:462/proxy/: tls qux (200; 17.458525ms)
Dec  9 21:01:29.433: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:460/proxy/: tls baz (200; 24.715241ms)
Dec  9 21:01:29.439: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/proxy-service-hg7hz:portname2/proxy/: bar (200; 29.269774ms)
Dec  9 21:01:29.440: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25/proxy/rewriteme"... (200; 30.530654ms)
Dec  9 21:01:29.441: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/proxy-service-hg7hz:portname1/proxy/: foo (200; 31.573263ms)
Dec  9 21:01:29.441: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/http:proxy-service-hg7hz:portname1/proxy/: foo (200; 31.387009ms)
Dec  9 21:01:29.444: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:443/proxy/... (200; 33.594847ms)
Dec  9 21:01:29.445: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:162/proxy/: bar (200; 35.429274ms)
Dec  9 21:01:29.445: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/https:proxy-service-hg7hz:tlsportname2/proxy/: tls qux (200; 35.58588ms)
Dec  9 21:01:29.445: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:162/proxy/: bar (200; 35.139554ms)
Dec  9 21:01:29.448: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:1080/proxy/rewri... (200; 38.160187ms)
Dec  9 21:01:29.448: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/http:proxy-service-hg7hz:portname2/proxy/: bar (200; 38.469755ms)
Dec  9 21:01:29.448: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/https:proxy-service-hg7hz:tlsportname1/proxy/: tls baz (200; 38.166615ms)
Dec  9 21:01:29.448: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:1080/proxy/... (200; 38.42149ms)
Dec  9 21:01:29.448: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:160/proxy/: foo (200; 38.293981ms)
Dec  9 21:01:29.449: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:160/proxy/: foo (200; 38.976916ms)
Dec  9 21:01:29.464: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:1080/proxy/rewri... (200; 14.175479ms)
Dec  9 21:01:29.464: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:462/proxy/: tls qux (200; 14.98991ms)
Dec  9 21:01:29.467: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:162/proxy/: bar (200; 15.956188ms)
Dec  9 21:01:29.470: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25/proxy/rewriteme"... (200; 18.983431ms)
Dec  9 21:01:29.470: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:160/proxy/: foo (200; 19.301775ms)
Dec  9 21:01:29.470: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:160/proxy/: foo (200; 20.256704ms)
Dec  9 21:01:29.478: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/https:proxy-service-hg7hz:tlsportname1/proxy/: tls baz (200; 27.669402ms)
Dec  9 21:01:29.478: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:162/proxy/: bar (200; 25.169158ms)
Dec  9 21:01:29.478: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:443/proxy/... (200; 27.205493ms)
Dec  9 21:01:29.479: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:460/proxy/: tls baz (200; 27.218225ms)
Dec  9 21:01:29.479: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:1080/proxy/... (200; 26.801305ms)
Dec  9 21:01:29.485: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/proxy-service-hg7hz:portname2/proxy/: bar (200; 33.846025ms)
Dec  9 21:01:29.485: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/http:proxy-service-hg7hz:portname2/proxy/: bar (200; 33.818128ms)
Dec  9 21:01:29.485: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/https:proxy-service-hg7hz:tlsportname2/proxy/: tls qux (200; 33.767919ms)
Dec  9 21:01:29.485: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/http:proxy-service-hg7hz:portname1/proxy/: foo (200; 33.967298ms)
Dec  9 21:01:29.485: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/proxy-service-hg7hz:portname1/proxy/: foo (200; 34.117444ms)
Dec  9 21:01:29.498: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:462/proxy/: tls qux (200; 11.59366ms)
Dec  9 21:01:29.501: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:162/proxy/: bar (200; 14.869725ms)
Dec  9 21:01:29.501: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:1080/proxy/... (200; 15.111728ms)
Dec  9 21:01:29.501: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:460/proxy/: tls baz (200; 15.308783ms)
Dec  9 21:01:29.509: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:160/proxy/: foo (200; 19.814767ms)
Dec  9 21:01:29.509: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:1080/proxy/rewri... (200; 21.238974ms)
Dec  9 21:01:29.509: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:160/proxy/: foo (200; 21.202462ms)
Dec  9 21:01:29.509: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:162/proxy/: bar (200; 19.792624ms)
Dec  9 21:01:29.513: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:443/proxy/... (200; 23.770328ms)
Dec  9 21:01:29.513: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/proxy-service-hg7hz:portname2/proxy/: bar (200; 25.741752ms)
Dec  9 21:01:29.513: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/http:proxy-service-hg7hz:portname2/proxy/: bar (200; 25.592288ms)
Dec  9 21:01:29.513: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/http:proxy-service-hg7hz:portname1/proxy/: foo (200; 26.052453ms)
Dec  9 21:01:29.513: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/https:proxy-service-hg7hz:tlsportname2/proxy/: tls qux (200; 25.643844ms)
Dec  9 21:01:29.518: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/https:proxy-service-hg7hz:tlsportname1/proxy/: tls baz (200; 29.688242ms)
Dec  9 21:01:29.518: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25/proxy/rewriteme"... (200; 28.853489ms)
Dec  9 21:01:29.518: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/proxy-service-hg7hz:portname1/proxy/: foo (200; 31.556671ms)
Dec  9 21:01:29.528: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25/proxy/rewriteme"... (200; 10.082911ms)
Dec  9 21:01:29.528: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:443/proxy/... (200; 10.045691ms)
Dec  9 21:01:29.528: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:160/proxy/: foo (200; 10.649952ms)
Dec  9 21:01:29.529: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:460/proxy/: tls baz (200; 10.132343ms)
Dec  9 21:01:29.529: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:162/proxy/: bar (200; 10.8245ms)
Dec  9 21:01:29.532: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:1080/proxy/... (200; 13.782072ms)
Dec  9 21:01:29.535: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:1080/proxy/rewri... (200; 15.879304ms)
Dec  9 21:01:29.543: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:162/proxy/: bar (200; 23.626912ms)
Dec  9 21:01:29.543: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:160/proxy/: foo (200; 23.241401ms)
Dec  9 21:01:29.543: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/proxy-service-hg7hz:portname2/proxy/: bar (200; 23.45757ms)
Dec  9 21:01:29.543: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/http:proxy-service-hg7hz:portname2/proxy/: bar (200; 23.453879ms)
Dec  9 21:01:29.543: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/proxy-service-hg7hz:portname1/proxy/: foo (200; 23.700941ms)
Dec  9 21:01:29.543: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/http:proxy-service-hg7hz:portname1/proxy/: foo (200; 23.644275ms)
Dec  9 21:01:29.543: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/https:proxy-service-hg7hz:tlsportname2/proxy/: tls qux (200; 23.483478ms)
Dec  9 21:01:29.543: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:462/proxy/: tls qux (200; 23.945099ms)
Dec  9 21:01:29.545: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/https:proxy-service-hg7hz:tlsportname1/proxy/: tls baz (200; 25.6586ms)
Dec  9 21:01:29.555: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:160/proxy/: foo (200; 8.990113ms)
Dec  9 21:01:29.559: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:160/proxy/: foo (200; 13.178013ms)
Dec  9 21:01:29.559: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/https:proxy-service-hg7hz:tlsportname1/proxy/: tls baz (200; 13.603737ms)
Dec  9 21:01:29.559: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:1080/proxy/rewri... (200; 13.982954ms)
Dec  9 21:01:29.560: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:460/proxy/: tls baz (200; 13.715321ms)
Dec  9 21:01:29.560: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25/proxy/rewriteme"... (200; 13.752062ms)
Dec  9 21:01:29.566: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:443/proxy/... (200; 19.819728ms)
Dec  9 21:01:29.566: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:162/proxy/: bar (200; 19.952789ms)
Dec  9 21:01:29.566: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/proxy-service-hg7hz:portname2/proxy/: bar (200; 20.569551ms)
Dec  9 21:01:29.568: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:1080/proxy/... (200; 22.08918ms)
Dec  9 21:01:29.568: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:462/proxy/: tls qux (200; 22.073094ms)
Dec  9 21:01:29.568: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:162/proxy/: bar (200; 22.219836ms)
Dec  9 21:01:29.568: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/http:proxy-service-hg7hz:portname2/proxy/: bar (200; 22.340164ms)
Dec  9 21:01:29.574: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/proxy-service-hg7hz:portname1/proxy/: foo (200; 27.547287ms)
Dec  9 21:01:29.574: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/https:proxy-service-hg7hz:tlsportname2/proxy/: tls qux (200; 27.827392ms)
Dec  9 21:01:29.574: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/http:proxy-service-hg7hz:portname1/proxy/: foo (200; 27.583928ms)
Dec  9 21:01:29.591: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:162/proxy/: bar (200; 14.9345ms)
Dec  9 21:01:29.597: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:443/proxy/... (200; 20.929431ms)
Dec  9 21:01:29.597: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:1080/proxy/... (200; 21.609257ms)
Dec  9 21:01:29.598: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:162/proxy/: bar (200; 23.623862ms)
Dec  9 21:01:29.598: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:462/proxy/: tls qux (200; 23.472599ms)
Dec  9 21:01:29.598: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25/proxy/rewriteme"... (200; 21.524276ms)
Dec  9 21:01:29.598: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:160/proxy/: foo (200; 21.764994ms)
Dec  9 21:01:29.598: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:160/proxy/: foo (200; 21.673087ms)
Dec  9 21:01:29.598: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:1080/proxy/rewri... (200; 22.002755ms)
Dec  9 21:01:29.602: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/https:proxy-service-hg7hz:tlsportname1/proxy/: tls baz (200; 26.155044ms)
Dec  9 21:01:29.604: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/https:proxy-service-hg7hz:tlsportname2/proxy/: tls qux (200; 28.689419ms)
Dec  9 21:01:29.604: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:460/proxy/: tls baz (200; 30.469811ms)
Dec  9 21:01:29.604: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/proxy-service-hg7hz:portname1/proxy/: foo (200; 29.702751ms)
Dec  9 21:01:29.604: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/http:proxy-service-hg7hz:portname2/proxy/: bar (200; 28.900782ms)
Dec  9 21:01:29.604: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/proxy-service-hg7hz:portname2/proxy/: bar (200; 28.98633ms)
Dec  9 21:01:29.604: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/http:proxy-service-hg7hz:portname1/proxy/: foo (200; 29.176627ms)
Dec  9 21:01:29.617: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25/proxy/rewriteme"... (200; 11.334949ms)
Dec  9 21:01:29.619: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:460/proxy/: tls baz (200; 13.110682ms)
Dec  9 21:01:29.621: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:160/proxy/: foo (200; 16.876113ms)
Dec  9 21:01:29.621: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:162/proxy/: bar (200; 15.213793ms)
Dec  9 21:01:29.622: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/https:proxy-service-hg7hz:tlsportname1/proxy/: tls baz (200; 16.825162ms)
Dec  9 21:01:29.622: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:443/proxy/... (200; 16.219007ms)
Dec  9 21:01:29.622: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:162/proxy/: bar (200; 16.456321ms)
Dec  9 21:01:29.622: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:160/proxy/: foo (200; 16.909868ms)
Dec  9 21:01:29.622: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:462/proxy/: tls qux (200; 15.757697ms)
Dec  9 21:01:29.627: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:1080/proxy/... (200; 19.305531ms)
Dec  9 21:01:29.627: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:1080/proxy/rewri... (200; 19.22381ms)
Dec  9 21:01:29.630: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/proxy-service-hg7hz:portname1/proxy/: foo (200; 23.462595ms)
Dec  9 21:01:29.630: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/proxy-service-hg7hz:portname2/proxy/: bar (200; 23.273642ms)
Dec  9 21:01:29.630: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/https:proxy-service-hg7hz:tlsportname2/proxy/: tls qux (200; 23.057831ms)
Dec  9 21:01:29.630: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/http:proxy-service-hg7hz:portname1/proxy/: foo (200; 23.440634ms)
Dec  9 21:01:29.634: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/http:proxy-service-hg7hz:portname2/proxy/: bar (200; 26.850695ms)
Dec  9 21:01:29.644: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:162/proxy/: bar (200; 10.477785ms)
Dec  9 21:01:29.649: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:1080/proxy/rewri... (200; 14.743278ms)
Dec  9 21:01:29.652: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:160/proxy/: foo (200; 17.719075ms)
Dec  9 21:01:29.653: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25/proxy/rewriteme"... (200; 17.636393ms)
Dec  9 21:01:29.655: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:1080/proxy/... (200; 17.988216ms)
Dec  9 21:01:29.655: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:460/proxy/: tls baz (200; 19.740713ms)
Dec  9 21:01:29.655: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:162/proxy/: bar (200; 20.382907ms)
Dec  9 21:01:29.655: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:160/proxy/: foo (200; 21.002727ms)
Dec  9 21:01:29.655: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/https:proxy-service-hg7hz:tlsportname1/proxy/: tls baz (200; 20.874915ms)
Dec  9 21:01:29.657: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:443/proxy/... (200; 21.555703ms)
Dec  9 21:01:29.657: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:462/proxy/: tls qux (200; 21.488327ms)
Dec  9 21:01:29.664: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/proxy-service-hg7hz:portname1/proxy/: foo (200; 27.677399ms)
Dec  9 21:01:29.666: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/http:proxy-service-hg7hz:portname2/proxy/: bar (200; 30.026544ms)
Dec  9 21:01:29.666: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/proxy-service-hg7hz:portname2/proxy/: bar (200; 30.150225ms)
Dec  9 21:01:29.669: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/http:proxy-service-hg7hz:portname1/proxy/: foo (200; 32.799137ms)
Dec  9 21:01:29.672: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/https:proxy-service-hg7hz:tlsportname2/proxy/: tls qux (200; 35.037976ms)
Dec  9 21:01:29.684: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:160/proxy/: foo (200; 12.707474ms)
Dec  9 21:01:29.687: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:460/proxy/: tls baz (200; 14.431245ms)
Dec  9 21:01:29.687: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25/proxy/rewriteme"... (200; 14.295633ms)
Dec  9 21:01:29.689: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:160/proxy/: foo (200; 16.251938ms)
Dec  9 21:01:29.689: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:162/proxy/: bar (200; 15.399952ms)
Dec  9 21:01:29.693: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:443/proxy/... (200; 19.716602ms)
Dec  9 21:01:29.693: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:462/proxy/: tls qux (200; 19.435513ms)
Dec  9 21:01:29.693: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:1080/proxy/rewri... (200; 19.264397ms)
Dec  9 21:01:29.693: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:162/proxy/: bar (200; 19.969237ms)
Dec  9 21:01:29.695: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/proxy-service-hg7hz:portname1/proxy/: foo (200; 21.708083ms)
Dec  9 21:01:29.695: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/proxy-service-hg7hz:portname2/proxy/: bar (200; 21.747154ms)
Dec  9 21:01:29.695: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:1080/proxy/... (200; 22.202701ms)
Dec  9 21:01:29.698: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/http:proxy-service-hg7hz:portname1/proxy/: foo (200; 24.858001ms)
Dec  9 21:01:29.698: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/https:proxy-service-hg7hz:tlsportname1/proxy/: tls baz (200; 26.37646ms)
Dec  9 21:01:29.698: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/http:proxy-service-hg7hz:portname2/proxy/: bar (200; 25.399342ms)
Dec  9 21:01:29.699: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/https:proxy-service-hg7hz:tlsportname2/proxy/: tls qux (200; 26.196603ms)
Dec  9 21:01:29.715: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:462/proxy/: tls qux (200; 14.972258ms)
Dec  9 21:01:29.715: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:460/proxy/: tls baz (200; 16.051861ms)
Dec  9 21:01:29.715: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:162/proxy/: bar (200; 15.432672ms)
Dec  9 21:01:29.715: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:1080/proxy/... (200; 15.791762ms)
Dec  9 21:01:29.717: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:162/proxy/: bar (200; 15.428641ms)
Dec  9 21:01:29.720: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/http:proxy-service-hg7hz-8xn25:160/proxy/: foo (200; 18.506814ms)
Dec  9 21:01:29.720: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25/proxy/rewriteme"... (200; 18.601097ms)
Dec  9 21:01:29.720: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/https:proxy-service-hg7hz:tlsportname2/proxy/: tls qux (200; 19.481247ms)
Dec  9 21:01:29.722: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/https:proxy-service-hg7hz-8xn25:443/proxy/... (200; 20.447885ms)
Dec  9 21:01:29.722: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:160/proxy/: foo (200; 20.737495ms)
Dec  9 21:01:29.722: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/http:proxy-service-hg7hz:portname1/proxy/: foo (200; 21.661257ms)
Dec  9 21:01:29.722: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zb6k6/pods/proxy-service-hg7hz-8xn25:1080/proxy/rewri... (200; 21.447138ms)
Dec  9 21:01:29.722: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/http:proxy-service-hg7hz:portname2/proxy/: bar (200; 21.586675ms)
Dec  9 21:01:29.723: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/proxy-service-hg7hz:portname2/proxy/: bar (200; 21.842405ms)
Dec  9 21:01:29.723: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/proxy-service-hg7hz:portname1/proxy/: foo (200; 22.195013ms)
Dec  9 21:01:29.723: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zb6k6/services/https:proxy-service-hg7hz:tlsportname1/proxy/: tls baz (200; 21.489455ms)
STEP: deleting ReplicationController proxy-service-hg7hz in namespace e2e-tests-proxy-zb6k6, will wait for the garbage collector to delete the pods
Dec  9 21:01:29.794: INFO: Deleting ReplicationController proxy-service-hg7hz took: 11.200989ms
Dec  9 21:01:29.894: INFO: Terminating ReplicationController proxy-service-hg7hz pods took: 100.230535ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:01:31.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-zb6k6" for this suite.
Dec  9 21:01:37.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:01:37.598: INFO: namespace: e2e-tests-proxy-zb6k6, resource: bindings, ignored listing per whitelist
Dec  9 21:01:37.668: INFO: namespace e2e-tests-proxy-zb6k6 deletion completed in 6.167454271s

• [SLOW TEST:14.778 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:01:37.668: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-l8m5
STEP: Creating a pod to test atomic-volume-subpath
Dec  9 21:01:37.818: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-l8m5" in namespace "e2e-tests-subpath-ft9dw" to be "success or failure"
Dec  9 21:01:37.824: INFO: Pod "pod-subpath-test-configmap-l8m5": Phase="Pending", Reason="", readiness=false. Elapsed: 5.388377ms
Dec  9 21:01:39.836: INFO: Pod "pod-subpath-test-configmap-l8m5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017974844s
Dec  9 21:01:41.841: INFO: Pod "pod-subpath-test-configmap-l8m5": Phase="Running", Reason="", readiness=false. Elapsed: 4.022754625s
Dec  9 21:01:43.845: INFO: Pod "pod-subpath-test-configmap-l8m5": Phase="Running", Reason="", readiness=false. Elapsed: 6.027058481s
Dec  9 21:01:45.850: INFO: Pod "pod-subpath-test-configmap-l8m5": Phase="Running", Reason="", readiness=false. Elapsed: 8.031946176s
Dec  9 21:01:47.856: INFO: Pod "pod-subpath-test-configmap-l8m5": Phase="Running", Reason="", readiness=false. Elapsed: 10.037998131s
Dec  9 21:01:49.867: INFO: Pod "pod-subpath-test-configmap-l8m5": Phase="Running", Reason="", readiness=false. Elapsed: 12.049100071s
Dec  9 21:01:51.873: INFO: Pod "pod-subpath-test-configmap-l8m5": Phase="Running", Reason="", readiness=false. Elapsed: 14.054735381s
Dec  9 21:01:53.879: INFO: Pod "pod-subpath-test-configmap-l8m5": Phase="Running", Reason="", readiness=false. Elapsed: 16.060487626s
Dec  9 21:01:55.884: INFO: Pod "pod-subpath-test-configmap-l8m5": Phase="Running", Reason="", readiness=false. Elapsed: 18.065302262s
Dec  9 21:01:57.889: INFO: Pod "pod-subpath-test-configmap-l8m5": Phase="Running", Reason="", readiness=false. Elapsed: 20.070322583s
Dec  9 21:01:59.903: INFO: Pod "pod-subpath-test-configmap-l8m5": Phase="Running", Reason="", readiness=false. Elapsed: 22.084334612s
Dec  9 21:02:01.908: INFO: Pod "pod-subpath-test-configmap-l8m5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.089373745s
STEP: Saw pod success
Dec  9 21:02:01.908: INFO: Pod "pod-subpath-test-configmap-l8m5" satisfied condition "success or failure"
Dec  9 21:02:01.912: INFO: Trying to get logs from node k8s04 pod pod-subpath-test-configmap-l8m5 container test-container-subpath-configmap-l8m5: <nil>
STEP: delete the pod
Dec  9 21:02:01.948: INFO: Waiting for pod pod-subpath-test-configmap-l8m5 to disappear
Dec  9 21:02:01.954: INFO: Pod pod-subpath-test-configmap-l8m5 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-l8m5
Dec  9 21:02:01.954: INFO: Deleting pod "pod-subpath-test-configmap-l8m5" in namespace "e2e-tests-subpath-ft9dw"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:02:01.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-ft9dw" for this suite.
Dec  9 21:02:08.000: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:02:08.112: INFO: namespace: e2e-tests-subpath-ft9dw, resource: bindings, ignored listing per whitelist
Dec  9 21:02:08.145: INFO: namespace e2e-tests-subpath-ft9dw deletion completed in 6.174356765s

• [SLOW TEST:30.478 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:02:08.146: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W1209 21:02:18.315565      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  9 21:02:18.315: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:02:18.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-97n6z" for this suite.
Dec  9 21:02:24.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:02:24.397: INFO: namespace: e2e-tests-gc-97n6z, resource: bindings, ignored listing per whitelist
Dec  9 21:02:24.512: INFO: namespace e2e-tests-gc-97n6z deletion completed in 6.187318298s

• [SLOW TEST:16.366 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:02:24.512: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  9 21:02:24.636: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Dec  9 21:02:29.641: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  9 21:02:29.641: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  9 21:02:29.680: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-4xwd8,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4xwd8/deployments/test-cleanup-deployment,UID:bd4ffd92-fbf5-11e8-925a-000c296b480b,ResourceVersion:46843,Generation:1,CreationTimestamp:2018-12-09 21:02:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Dec  9 21:02:29.687: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:02:29.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-4xwd8" for this suite.
Dec  9 21:02:35.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:02:35.804: INFO: namespace: e2e-tests-deployment-4xwd8, resource: bindings, ignored listing per whitelist
Dec  9 21:02:35.888: INFO: namespace e2e-tests-deployment-4xwd8 deletion completed in 6.186015807s

• [SLOW TEST:11.376 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:02:35.888: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-c118d7e4-fbf5-11e8-8725-0a580af4034b
STEP: Creating a pod to test consume secrets
Dec  9 21:02:36.027: INFO: Waiting up to 5m0s for pod "pod-secrets-c11a21a7-fbf5-11e8-8725-0a580af4034b" in namespace "e2e-tests-secrets-xdchh" to be "success or failure"
Dec  9 21:02:36.038: INFO: Pod "pod-secrets-c11a21a7-fbf5-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.75086ms
Dec  9 21:02:38.043: INFO: Pod "pod-secrets-c11a21a7-fbf5-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015443006s
STEP: Saw pod success
Dec  9 21:02:38.043: INFO: Pod "pod-secrets-c11a21a7-fbf5-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 21:02:38.047: INFO: Trying to get logs from node k8s04 pod pod-secrets-c11a21a7-fbf5-11e8-8725-0a580af4034b container secret-volume-test: <nil>
STEP: delete the pod
Dec  9 21:02:38.078: INFO: Waiting for pod pod-secrets-c11a21a7-fbf5-11e8-8725-0a580af4034b to disappear
Dec  9 21:02:38.084: INFO: Pod pod-secrets-c11a21a7-fbf5-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:02:38.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-xdchh" for this suite.
Dec  9 21:02:44.113: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:02:44.228: INFO: namespace: e2e-tests-secrets-xdchh, resource: bindings, ignored listing per whitelist
Dec  9 21:02:44.267: INFO: namespace e2e-tests-secrets-xdchh deletion completed in 6.174280514s

• [SLOW TEST:8.378 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:02:44.267: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  9 21:02:44.359: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Dec  9 21:02:44.374: INFO: Pod name sample-pod: Found 0 pods out of 1
Dec  9 21:02:49.386: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  9 21:02:49.386: INFO: Creating deployment "test-rolling-update-deployment"
Dec  9 21:02:49.396: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Dec  9 21:02:49.410: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Dec  9 21:02:51.420: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Dec  9 21:02:51.425: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  9 21:02:51.449: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-6r2jr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-6r2jr/deployments/test-rolling-update-deployment,UID:c913b833-fbf5-11e8-925a-000c296b480b,ResourceVersion:46972,Generation:1,CreationTimestamp:2018-12-09 21:02:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-12-09 21:02:49 +0000 UTC 2018-12-09 21:02:49 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-12-09 21:02:50 +0000 UTC 2018-12-09 21:02:49 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec  9 21:02:51.457: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-6r2jr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-6r2jr/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:c9196b08-fbf5-11e8-925a-000c296b480b,ResourceVersion:46962,Generation:1,CreationTimestamp:2018-12-09 21:02:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment c913b833-fbf5-11e8-925a-000c296b480b 0xc0021ba607 0xc0021ba608}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec  9 21:02:51.457: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Dec  9 21:02:51.457: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-6r2jr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-6r2jr/replicasets/test-rolling-update-controller,UID:c614b986-fbf5-11e8-925a-000c296b480b,ResourceVersion:46971,Generation:2,CreationTimestamp:2018-12-09 21:02:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment c913b833-fbf5-11e8-925a-000c296b480b 0xc0021ba547 0xc0021ba548}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  9 21:02:51.463: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-btfbx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-btfbx,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-6r2jr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6r2jr/pods/test-rolling-update-deployment-68b55d7bc6-btfbx,UID:c91ab4df-fbf5-11e8-925a-000c296b480b,ResourceVersion:46961,Generation:0,CreationTimestamp:2018-12-09 21:02:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 c9196b08-fbf5-11e8-925a-000c296b480b 0xc002193337 0xc002193338}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7w446 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7w446,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-7w446 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s04,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021933b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021933d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:02:49 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:02:50 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:02:50 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:02:49 +0000 UTC  }],Message:,Reason:,HostIP:192.168.9.14,PodIP:10.244.3.239,StartTime:2018-12-09 21:02:49 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-12-09 21:02:50 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://153e477f779e088fa10774a46fb4c7e89b20691d6cab57f06ac376d1b1b200be}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:02:51.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-6r2jr" for this suite.
Dec  9 21:02:57.495: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:02:57.559: INFO: namespace: e2e-tests-deployment-6r2jr, resource: bindings, ignored listing per whitelist
Dec  9 21:02:57.661: INFO: namespace e2e-tests-deployment-6r2jr deletion completed in 6.187717928s

• [SLOW TEST:13.394 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:02:57.661: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Dec  9 21:02:57.771: INFO: Waiting up to 5m0s for pod "pod-ce10d7e0-fbf5-11e8-8725-0a580af4034b" in namespace "e2e-tests-emptydir-dv9m8" to be "success or failure"
Dec  9 21:02:57.779: INFO: Pod "pod-ce10d7e0-fbf5-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.631223ms
Dec  9 21:02:59.791: INFO: Pod "pod-ce10d7e0-fbf5-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019585546s
STEP: Saw pod success
Dec  9 21:02:59.791: INFO: Pod "pod-ce10d7e0-fbf5-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 21:02:59.795: INFO: Trying to get logs from node k8s04 pod pod-ce10d7e0-fbf5-11e8-8725-0a580af4034b container test-container: <nil>
STEP: delete the pod
Dec  9 21:02:59.830: INFO: Waiting for pod pod-ce10d7e0-fbf5-11e8-8725-0a580af4034b to disappear
Dec  9 21:02:59.836: INFO: Pod pod-ce10d7e0-fbf5-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:02:59.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-dv9m8" for this suite.
Dec  9 21:03:05.866: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:03:05.910: INFO: namespace: e2e-tests-emptydir-dv9m8, resource: bindings, ignored listing per whitelist
Dec  9 21:03:06.028: INFO: namespace e2e-tests-emptydir-dv9m8 deletion completed in 6.183261799s

• [SLOW TEST:8.367 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:03:06.028: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-d311aa3d-fbf5-11e8-8725-0a580af4034b
STEP: Creating a pod to test consume configMaps
Dec  9 21:03:06.184: INFO: Waiting up to 5m0s for pod "pod-configmaps-d312f6ce-fbf5-11e8-8725-0a580af4034b" in namespace "e2e-tests-configmap-4dqdj" to be "success or failure"
Dec  9 21:03:06.195: INFO: Pod "pod-configmaps-d312f6ce-fbf5-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.526678ms
Dec  9 21:03:08.199: INFO: Pod "pod-configmaps-d312f6ce-fbf5-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014338289s
STEP: Saw pod success
Dec  9 21:03:08.199: INFO: Pod "pod-configmaps-d312f6ce-fbf5-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 21:03:08.205: INFO: Trying to get logs from node k8s04 pod pod-configmaps-d312f6ce-fbf5-11e8-8725-0a580af4034b container configmap-volume-test: <nil>
STEP: delete the pod
Dec  9 21:03:08.237: INFO: Waiting for pod pod-configmaps-d312f6ce-fbf5-11e8-8725-0a580af4034b to disappear
Dec  9 21:03:08.244: INFO: Pod pod-configmaps-d312f6ce-fbf5-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:03:08.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-4dqdj" for this suite.
Dec  9 21:03:14.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:03:14.357: INFO: namespace: e2e-tests-configmap-4dqdj, resource: bindings, ignored listing per whitelist
Dec  9 21:03:14.432: INFO: namespace e2e-tests-configmap-4dqdj deletion completed in 6.181451027s

• [SLOW TEST:8.404 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:03:14.433: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  9 21:03:14.540: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d80fb81b-fbf5-11e8-8725-0a580af4034b" in namespace "e2e-tests-projected-q2vx8" to be "success or failure"
Dec  9 21:03:14.547: INFO: Pod "downwardapi-volume-d80fb81b-fbf5-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.987681ms
Dec  9 21:03:16.551: INFO: Pod "downwardapi-volume-d80fb81b-fbf5-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010493343s
STEP: Saw pod success
Dec  9 21:03:16.551: INFO: Pod "downwardapi-volume-d80fb81b-fbf5-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 21:03:16.556: INFO: Trying to get logs from node k8s04 pod downwardapi-volume-d80fb81b-fbf5-11e8-8725-0a580af4034b container client-container: <nil>
STEP: delete the pod
Dec  9 21:03:16.591: INFO: Waiting for pod downwardapi-volume-d80fb81b-fbf5-11e8-8725-0a580af4034b to disappear
Dec  9 21:03:16.596: INFO: Pod downwardapi-volume-d80fb81b-fbf5-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:03:16.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-q2vx8" for this suite.
Dec  9 21:03:22.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:03:22.724: INFO: namespace: e2e-tests-projected-q2vx8, resource: bindings, ignored listing per whitelist
Dec  9 21:03:22.815: INFO: namespace e2e-tests-projected-q2vx8 deletion completed in 6.211291712s

• [SLOW TEST:8.382 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:03:22.815: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  9 21:03:22.921: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dd0dab90-fbf5-11e8-8725-0a580af4034b" in namespace "e2e-tests-downward-api-nxjt5" to be "success or failure"
Dec  9 21:03:22.927: INFO: Pod "downwardapi-volume-dd0dab90-fbf5-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.671442ms
Dec  9 21:03:24.931: INFO: Pod "downwardapi-volume-dd0dab90-fbf5-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010312128s
STEP: Saw pod success
Dec  9 21:03:24.931: INFO: Pod "downwardapi-volume-dd0dab90-fbf5-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 21:03:24.935: INFO: Trying to get logs from node k8s04 pod downwardapi-volume-dd0dab90-fbf5-11e8-8725-0a580af4034b container client-container: <nil>
STEP: delete the pod
Dec  9 21:03:24.969: INFO: Waiting for pod downwardapi-volume-dd0dab90-fbf5-11e8-8725-0a580af4034b to disappear
Dec  9 21:03:24.978: INFO: Pod downwardapi-volume-dd0dab90-fbf5-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:03:24.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-nxjt5" for this suite.
Dec  9 21:03:31.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:03:31.099: INFO: namespace: e2e-tests-downward-api-nxjt5, resource: bindings, ignored listing per whitelist
Dec  9 21:03:31.165: INFO: namespace e2e-tests-downward-api-nxjt5 deletion completed in 6.179937051s

• [SLOW TEST:8.350 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:03:31.165: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  9 21:03:31.278: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e2099c0f-fbf5-11e8-8725-0a580af4034b" in namespace "e2e-tests-downward-api-9ntqp" to be "success or failure"
Dec  9 21:03:31.285: INFO: Pod "downwardapi-volume-e2099c0f-fbf5-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.111476ms
Dec  9 21:03:33.290: INFO: Pod "downwardapi-volume-e2099c0f-fbf5-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012396743s
STEP: Saw pod success
Dec  9 21:03:33.290: INFO: Pod "downwardapi-volume-e2099c0f-fbf5-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 21:03:33.295: INFO: Trying to get logs from node k8s04 pod downwardapi-volume-e2099c0f-fbf5-11e8-8725-0a580af4034b container client-container: <nil>
STEP: delete the pod
Dec  9 21:03:33.331: INFO: Waiting for pod downwardapi-volume-e2099c0f-fbf5-11e8-8725-0a580af4034b to disappear
Dec  9 21:03:33.337: INFO: Pod downwardapi-volume-e2099c0f-fbf5-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:03:33.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9ntqp" for this suite.
Dec  9 21:03:39.372: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:03:39.423: INFO: namespace: e2e-tests-downward-api-9ntqp, resource: bindings, ignored listing per whitelist
Dec  9 21:03:39.548: INFO: namespace e2e-tests-downward-api-9ntqp deletion completed in 6.200978638s

• [SLOW TEST:8.382 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:03:39.548: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-llrh9
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  9 21:03:39.642: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  9 21:04:01.742: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.3.245:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-llrh9 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  9 21:04:01.742: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
Dec  9 21:04:01.899: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:04:01.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-llrh9" for this suite.
Dec  9 21:04:23.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:04:23.969: INFO: namespace: e2e-tests-pod-network-test-llrh9, resource: bindings, ignored listing per whitelist
Dec  9 21:04:24.071: INFO: namespace e2e-tests-pod-network-test-llrh9 deletion completed in 22.165657513s

• [SLOW TEST:44.523 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:04:24.071: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-019201a1-fbf6-11e8-8725-0a580af4034b
STEP: Creating a pod to test consume secrets
Dec  9 21:04:24.191: INFO: Waiting up to 5m0s for pod "pod-secrets-019367d3-fbf6-11e8-8725-0a580af4034b" in namespace "e2e-tests-secrets-d8f2d" to be "success or failure"
Dec  9 21:04:24.202: INFO: Pod "pod-secrets-019367d3-fbf6-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.803396ms
Dec  9 21:04:26.213: INFO: Pod "pod-secrets-019367d3-fbf6-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022200257s
STEP: Saw pod success
Dec  9 21:04:26.213: INFO: Pod "pod-secrets-019367d3-fbf6-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 21:04:26.217: INFO: Trying to get logs from node k8s04 pod pod-secrets-019367d3-fbf6-11e8-8725-0a580af4034b container secret-volume-test: <nil>
STEP: delete the pod
Dec  9 21:04:26.251: INFO: Waiting for pod pod-secrets-019367d3-fbf6-11e8-8725-0a580af4034b to disappear
Dec  9 21:04:26.257: INFO: Pod pod-secrets-019367d3-fbf6-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:04:26.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-d8f2d" for this suite.
Dec  9 21:04:32.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:04:32.316: INFO: namespace: e2e-tests-secrets-d8f2d, resource: bindings, ignored listing per whitelist
Dec  9 21:04:32.446: INFO: namespace e2e-tests-secrets-d8f2d deletion completed in 6.181564866s

• [SLOW TEST:8.375 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:04:32.446: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  9 21:04:32.564: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0690f195-fbf6-11e8-8725-0a580af4034b" in namespace "e2e-tests-projected-vm9rb" to be "success or failure"
Dec  9 21:04:32.572: INFO: Pod "downwardapi-volume-0690f195-fbf6-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.106213ms
Dec  9 21:04:34.577: INFO: Pod "downwardapi-volume-0690f195-fbf6-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013171487s
STEP: Saw pod success
Dec  9 21:04:34.577: INFO: Pod "downwardapi-volume-0690f195-fbf6-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 21:04:34.582: INFO: Trying to get logs from node k8s04 pod downwardapi-volume-0690f195-fbf6-11e8-8725-0a580af4034b container client-container: <nil>
STEP: delete the pod
Dec  9 21:04:34.614: INFO: Waiting for pod downwardapi-volume-0690f195-fbf6-11e8-8725-0a580af4034b to disappear
Dec  9 21:04:34.620: INFO: Pod downwardapi-volume-0690f195-fbf6-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:04:34.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vm9rb" for this suite.
Dec  9 21:04:40.648: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:04:40.787: INFO: namespace: e2e-tests-projected-vm9rb, resource: bindings, ignored listing per whitelist
Dec  9 21:04:40.801: INFO: namespace e2e-tests-projected-vm9rb deletion completed in 6.17331935s

• [SLOW TEST:8.355 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:04:40.801: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec  9 21:04:43.448: INFO: Successfully updated pod "annotationupdate0b8a49cc-fbf6-11e8-8725-0a580af4034b"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:04:47.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9wqp2" for this suite.
Dec  9 21:05:09.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:05:09.616: INFO: namespace: e2e-tests-projected-9wqp2, resource: bindings, ignored listing per whitelist
Dec  9 21:05:09.665: INFO: namespace e2e-tests-projected-9wqp2 deletion completed in 22.169394553s

• [SLOW TEST:28.864 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:05:09.665: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  9 21:05:11.792: INFO: Waiting up to 5m0s for pod "client-envvars-1df3bbb9-fbf6-11e8-8725-0a580af4034b" in namespace "e2e-tests-pods-f86s7" to be "success or failure"
Dec  9 21:05:11.803: INFO: Pod "client-envvars-1df3bbb9-fbf6-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.171364ms
Dec  9 21:05:13.808: INFO: Pod "client-envvars-1df3bbb9-fbf6-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015838622s
STEP: Saw pod success
Dec  9 21:05:13.808: INFO: Pod "client-envvars-1df3bbb9-fbf6-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 21:05:13.812: INFO: Trying to get logs from node k8s04 pod client-envvars-1df3bbb9-fbf6-11e8-8725-0a580af4034b container env3cont: <nil>
STEP: delete the pod
Dec  9 21:05:13.845: INFO: Waiting for pod client-envvars-1df3bbb9-fbf6-11e8-8725-0a580af4034b to disappear
Dec  9 21:05:13.852: INFO: Pod client-envvars-1df3bbb9-fbf6-11e8-8725-0a580af4034b no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:05:13.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-f86s7" for this suite.
Dec  9 21:05:51.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:05:51.931: INFO: namespace: e2e-tests-pods-f86s7, resource: bindings, ignored listing per whitelist
Dec  9 21:05:52.049: INFO: namespace e2e-tests-pods-f86s7 deletion completed in 38.189177575s

• [SLOW TEST:42.384 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:05:52.050: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  9 21:05:52.165: INFO: Waiting up to 5m0s for pod "downwardapi-volume-36031275-fbf6-11e8-8725-0a580af4034b" in namespace "e2e-tests-downward-api-hblfm" to be "success or failure"
Dec  9 21:05:52.171: INFO: Pod "downwardapi-volume-36031275-fbf6-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.797035ms
Dec  9 21:05:54.183: INFO: Pod "downwardapi-volume-36031275-fbf6-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017973947s
STEP: Saw pod success
Dec  9 21:05:54.183: INFO: Pod "downwardapi-volume-36031275-fbf6-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 21:05:54.187: INFO: Trying to get logs from node k8s04 pod downwardapi-volume-36031275-fbf6-11e8-8725-0a580af4034b container client-container: <nil>
STEP: delete the pod
Dec  9 21:05:54.226: INFO: Waiting for pod downwardapi-volume-36031275-fbf6-11e8-8725-0a580af4034b to disappear
Dec  9 21:05:54.231: INFO: Pod downwardapi-volume-36031275-fbf6-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:05:54.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-hblfm" for this suite.
Dec  9 21:06:00.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:06:00.390: INFO: namespace: e2e-tests-downward-api-hblfm, resource: bindings, ignored listing per whitelist
Dec  9 21:06:00.434: INFO: namespace e2e-tests-downward-api-hblfm deletion completed in 6.193041751s

• [SLOW TEST:8.385 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:06:00.435: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-gfdxv
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Dec  9 21:06:00.560: INFO: Found 0 stateful pods, waiting for 3
Dec  9 21:06:10.573: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  9 21:06:10.573: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  9 21:06:10.573: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Dec  9 21:06:10.613: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Dec  9 21:06:20.664: INFO: Updating stateful set ss2
Dec  9 21:06:20.677: INFO: Waiting for Pod e2e-tests-statefulset-gfdxv/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Dec  9 21:06:30.744: INFO: Found 1 stateful pods, waiting for 3
Dec  9 21:06:40.757: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  9 21:06:40.757: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  9 21:06:40.757: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Dec  9 21:06:40.797: INFO: Updating stateful set ss2
Dec  9 21:06:40.811: INFO: Waiting for Pod e2e-tests-statefulset-gfdxv/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec  9 21:06:50.848: INFO: Updating stateful set ss2
Dec  9 21:06:50.861: INFO: Waiting for StatefulSet e2e-tests-statefulset-gfdxv/ss2 to complete update
Dec  9 21:06:50.861: INFO: Waiting for Pod e2e-tests-statefulset-gfdxv/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec  9 21:07:00.876: INFO: Waiting for StatefulSet e2e-tests-statefulset-gfdxv/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  9 21:07:10.871: INFO: Deleting all statefulset in ns e2e-tests-statefulset-gfdxv
Dec  9 21:07:10.888: INFO: Scaling statefulset ss2 to 0
Dec  9 21:07:30.915: INFO: Waiting for statefulset status.replicas updated to 0
Dec  9 21:07:30.919: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:07:30.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-gfdxv" for this suite.
Dec  9 21:07:36.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:07:37.006: INFO: namespace: e2e-tests-statefulset-gfdxv, resource: bindings, ignored listing per whitelist
Dec  9 21:07:37.146: INFO: namespace e2e-tests-statefulset-gfdxv deletion completed in 6.185412836s

• [SLOW TEST:96.711 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:07:37.146: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  9 21:07:37.265: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Dec  9 21:07:37.280: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-cz9lr/daemonsets","resourceVersion":"48060"},"items":null}

Dec  9 21:07:37.287: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-cz9lr/pods","resourceVersion":"48060"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:07:37.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-cz9lr" for this suite.
Dec  9 21:07:43.326: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:07:43.397: INFO: namespace: e2e-tests-daemonsets-cz9lr, resource: bindings, ignored listing per whitelist
Dec  9 21:07:43.476: INFO: namespace e2e-tests-daemonsets-cz9lr deletion completed in 6.16947587s

S [SKIPPING] [6.331 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Dec  9 21:07:37.265: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:07:43.477: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Dec  9 21:07:43.616: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-gzkzt,SelfLink:/api/v1/namespaces/e2e-tests-watch-gzkzt/configmaps/e2e-watch-test-label-changed,UID:786d7aa3-fbf6-11e8-925a-000c296b480b,ResourceVersion:48083,Generation:0,CreationTimestamp:2018-12-09 21:07:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  9 21:07:43.617: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-gzkzt,SelfLink:/api/v1/namespaces/e2e-tests-watch-gzkzt/configmaps/e2e-watch-test-label-changed,UID:786d7aa3-fbf6-11e8-925a-000c296b480b,ResourceVersion:48084,Generation:0,CreationTimestamp:2018-12-09 21:07:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec  9 21:07:43.617: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-gzkzt,SelfLink:/api/v1/namespaces/e2e-tests-watch-gzkzt/configmaps/e2e-watch-test-label-changed,UID:786d7aa3-fbf6-11e8-925a-000c296b480b,ResourceVersion:48085,Generation:0,CreationTimestamp:2018-12-09 21:07:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Dec  9 21:07:53.689: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-gzkzt,SelfLink:/api/v1/namespaces/e2e-tests-watch-gzkzt/configmaps/e2e-watch-test-label-changed,UID:786d7aa3-fbf6-11e8-925a-000c296b480b,ResourceVersion:48104,Generation:0,CreationTimestamp:2018-12-09 21:07:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  9 21:07:53.689: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-gzkzt,SelfLink:/api/v1/namespaces/e2e-tests-watch-gzkzt/configmaps/e2e-watch-test-label-changed,UID:786d7aa3-fbf6-11e8-925a-000c296b480b,ResourceVersion:48105,Generation:0,CreationTimestamp:2018-12-09 21:07:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Dec  9 21:07:53.690: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-gzkzt,SelfLink:/api/v1/namespaces/e2e-tests-watch-gzkzt/configmaps/e2e-watch-test-label-changed,UID:786d7aa3-fbf6-11e8-925a-000c296b480b,ResourceVersion:48106,Generation:0,CreationTimestamp:2018-12-09 21:07:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:07:53.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-gzkzt" for this suite.
Dec  9 21:07:59.718: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:07:59.766: INFO: namespace: e2e-tests-watch-gzkzt, resource: bindings, ignored listing per whitelist
Dec  9 21:07:59.871: INFO: namespace e2e-tests-watch-gzkzt deletion completed in 6.174953835s

• [SLOW TEST:16.394 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:07:59.871: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Dec  9 21:07:59.965: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-028914468 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:08:00.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pb967" for this suite.
Dec  9 21:08:06.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:08:06.136: INFO: namespace: e2e-tests-kubectl-pb967, resource: bindings, ignored listing per whitelist
Dec  9 21:08:06.233: INFO: namespace e2e-tests-kubectl-pb967 deletion completed in 6.181180715s

• [SLOW TEST:6.362 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:08:06.234: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-bcsfn
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  9 21:08:06.328: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  9 21:08:26.422: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.244.3.8 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-bcsfn PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  9 21:08:26.422: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
Dec  9 21:08:27.534: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:08:27.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-bcsfn" for this suite.
Dec  9 21:08:49.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:08:49.579: INFO: namespace: e2e-tests-pod-network-test-bcsfn, resource: bindings, ignored listing per whitelist
Dec  9 21:08:49.717: INFO: namespace e2e-tests-pod-network-test-bcsfn deletion completed in 22.176906042s

• [SLOW TEST:43.484 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:08:49.718: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-9fe88f14-fbf6-11e8-8725-0a580af4034b
STEP: Creating secret with name secret-projected-all-test-volume-9fe88f03-fbf6-11e8-8725-0a580af4034b
STEP: Creating a pod to test Check all projections for projected volume plugin
Dec  9 21:08:49.850: INFO: Waiting up to 5m0s for pod "projected-volume-9fe88ecd-fbf6-11e8-8725-0a580af4034b" in namespace "e2e-tests-projected-7gjj9" to be "success or failure"
Dec  9 21:08:49.857: INFO: Pod "projected-volume-9fe88ecd-fbf6-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.291456ms
Dec  9 21:08:51.861: INFO: Pod "projected-volume-9fe88ecd-fbf6-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010647875s
STEP: Saw pod success
Dec  9 21:08:51.861: INFO: Pod "projected-volume-9fe88ecd-fbf6-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 21:08:51.865: INFO: Trying to get logs from node k8s04 pod projected-volume-9fe88ecd-fbf6-11e8-8725-0a580af4034b container projected-all-volume-test: <nil>
STEP: delete the pod
Dec  9 21:08:51.895: INFO: Waiting for pod projected-volume-9fe88ecd-fbf6-11e8-8725-0a580af4034b to disappear
Dec  9 21:08:51.902: INFO: Pod projected-volume-9fe88ecd-fbf6-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:08:51.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7gjj9" for this suite.
Dec  9 21:08:57.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:08:57.984: INFO: namespace: e2e-tests-projected-7gjj9, resource: bindings, ignored listing per whitelist
Dec  9 21:08:58.087: INFO: namespace e2e-tests-projected-7gjj9 deletion completed in 6.174521054s

• [SLOW TEST:8.369 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:08:58.087: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-a4e3ba53-fbf6-11e8-8725-0a580af4034b
STEP: Creating a pod to test consume secrets
Dec  9 21:08:58.193: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a4e4f7ed-fbf6-11e8-8725-0a580af4034b" in namespace "e2e-tests-projected-vbhrb" to be "success or failure"
Dec  9 21:08:58.200: INFO: Pod "pod-projected-secrets-a4e4f7ed-fbf6-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.427261ms
Dec  9 21:09:00.206: INFO: Pod "pod-projected-secrets-a4e4f7ed-fbf6-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012493289s
STEP: Saw pod success
Dec  9 21:09:00.206: INFO: Pod "pod-projected-secrets-a4e4f7ed-fbf6-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 21:09:00.210: INFO: Trying to get logs from node k8s04 pod pod-projected-secrets-a4e4f7ed-fbf6-11e8-8725-0a580af4034b container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  9 21:09:00.243: INFO: Waiting for pod pod-projected-secrets-a4e4f7ed-fbf6-11e8-8725-0a580af4034b to disappear
Dec  9 21:09:00.249: INFO: Pod pod-projected-secrets-a4e4f7ed-fbf6-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:09:00.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vbhrb" for this suite.
Dec  9 21:09:06.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:09:06.380: INFO: namespace: e2e-tests-projected-vbhrb, resource: bindings, ignored listing per whitelist
Dec  9 21:09:06.422: INFO: namespace e2e-tests-projected-vbhrb deletion completed in 6.165979958s

• [SLOW TEST:8.335 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:09:06.423: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  9 21:09:06.524: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:09:12.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-twdx7" for this suite.
Dec  9 21:09:18.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:09:18.777: INFO: namespace: e2e-tests-custom-resource-definition-twdx7, resource: bindings, ignored listing per whitelist
Dec  9 21:09:18.777: INFO: namespace e2e-tests-custom-resource-definition-twdx7 deletion completed in 6.1876331s

• [SLOW TEST:12.354 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:09:18.777: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-b13c5027-fbf6-11e8-8725-0a580af4034b
STEP: Creating a pod to test consume configMaps
Dec  9 21:09:18.907: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b13d7106-fbf6-11e8-8725-0a580af4034b" in namespace "e2e-tests-projected-txg9t" to be "success or failure"
Dec  9 21:09:18.914: INFO: Pod "pod-projected-configmaps-b13d7106-fbf6-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.225881ms
Dec  9 21:09:20.919: INFO: Pod "pod-projected-configmaps-b13d7106-fbf6-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011836421s
STEP: Saw pod success
Dec  9 21:09:20.919: INFO: Pod "pod-projected-configmaps-b13d7106-fbf6-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 21:09:20.924: INFO: Trying to get logs from node k8s04 pod pod-projected-configmaps-b13d7106-fbf6-11e8-8725-0a580af4034b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  9 21:09:20.964: INFO: Waiting for pod pod-projected-configmaps-b13d7106-fbf6-11e8-8725-0a580af4034b to disappear
Dec  9 21:09:20.969: INFO: Pod pod-projected-configmaps-b13d7106-fbf6-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:09:20.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-txg9t" for this suite.
Dec  9 21:09:27.000: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:09:27.124: INFO: namespace: e2e-tests-projected-txg9t, resource: bindings, ignored listing per whitelist
Dec  9 21:09:27.166: INFO: namespace e2e-tests-projected-txg9t deletion completed in 6.187784459s

• [SLOW TEST:8.389 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:09:27.166: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-7jxlw
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-7jxlw
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-7jxlw
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-7jxlw
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-7jxlw
Dec  9 21:09:31.314: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-7jxlw, name: ss-0, uid: b886dad7-fbf6-11e8-925a-000c296b480b, status phase: Pending. Waiting for statefulset controller to delete.
Dec  9 21:09:31.701: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-7jxlw, name: ss-0, uid: b886dad7-fbf6-11e8-925a-000c296b480b, status phase: Failed. Waiting for statefulset controller to delete.
Dec  9 21:09:31.711: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-7jxlw, name: ss-0, uid: b886dad7-fbf6-11e8-925a-000c296b480b, status phase: Failed. Waiting for statefulset controller to delete.
Dec  9 21:09:31.720: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-7jxlw
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-7jxlw
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-7jxlw and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  9 21:09:35.763: INFO: Deleting all statefulset in ns e2e-tests-statefulset-7jxlw
Dec  9 21:09:35.768: INFO: Scaling statefulset ss to 0
Dec  9 21:09:45.804: INFO: Waiting for statefulset status.replicas updated to 0
Dec  9 21:09:45.808: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:09:45.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-7jxlw" for this suite.
Dec  9 21:09:51.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:09:51.891: INFO: namespace: e2e-tests-statefulset-7jxlw, resource: bindings, ignored listing per whitelist
Dec  9 21:09:52.017: INFO: namespace e2e-tests-statefulset-7jxlw deletion completed in 6.175212383s

• [SLOW TEST:24.852 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:09:52.017: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-spsc6 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-spsc6;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-spsc6 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-spsc6;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-spsc6.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-spsc6.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-spsc6.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-spsc6.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-spsc6.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-spsc6.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-spsc6.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-spsc6.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-spsc6.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-spsc6.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-spsc6.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-spsc6.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-spsc6.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 190.100.104.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.104.100.190_udp@PTR;check="$$(dig +tcp +noall +answer +search 190.100.104.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.104.100.190_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-spsc6 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-spsc6;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-spsc6 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-spsc6;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-spsc6.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-spsc6.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-spsc6.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-spsc6.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-spsc6.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-spsc6.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-spsc6.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-spsc6.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-spsc6.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-spsc6.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-spsc6.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-spsc6.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-spsc6.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 190.100.104.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.104.100.190_udp@PTR;check="$$(dig +tcp +noall +answer +search 190.100.104.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.104.100.190_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  9 21:09:54.213: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-spsc6/dns-test-c5116491-fbf6-11e8-8725-0a580af4034b: the server could not find the requested resource (get pods dns-test-c5116491-fbf6-11e8-8725-0a580af4034b)
Dec  9 21:09:54.217: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-spsc6/dns-test-c5116491-fbf6-11e8-8725-0a580af4034b: the server could not find the requested resource (get pods dns-test-c5116491-fbf6-11e8-8725-0a580af4034b)
Dec  9 21:09:54.223: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-spsc6 from pod e2e-tests-dns-spsc6/dns-test-c5116491-fbf6-11e8-8725-0a580af4034b: the server could not find the requested resource (get pods dns-test-c5116491-fbf6-11e8-8725-0a580af4034b)
Dec  9 21:09:54.231: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-spsc6 from pod e2e-tests-dns-spsc6/dns-test-c5116491-fbf6-11e8-8725-0a580af4034b: the server could not find the requested resource (get pods dns-test-c5116491-fbf6-11e8-8725-0a580af4034b)
Dec  9 21:09:54.238: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-spsc6.svc from pod e2e-tests-dns-spsc6/dns-test-c5116491-fbf6-11e8-8725-0a580af4034b: the server could not find the requested resource (get pods dns-test-c5116491-fbf6-11e8-8725-0a580af4034b)
Dec  9 21:09:54.245: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-spsc6.svc from pod e2e-tests-dns-spsc6/dns-test-c5116491-fbf6-11e8-8725-0a580af4034b: the server could not find the requested resource (get pods dns-test-c5116491-fbf6-11e8-8725-0a580af4034b)
Dec  9 21:09:54.253: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-spsc6.svc from pod e2e-tests-dns-spsc6/dns-test-c5116491-fbf6-11e8-8725-0a580af4034b: the server could not find the requested resource (get pods dns-test-c5116491-fbf6-11e8-8725-0a580af4034b)
Dec  9 21:09:54.259: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-spsc6.svc from pod e2e-tests-dns-spsc6/dns-test-c5116491-fbf6-11e8-8725-0a580af4034b: the server could not find the requested resource (get pods dns-test-c5116491-fbf6-11e8-8725-0a580af4034b)
Dec  9 21:09:54.267: INFO: Unable to read wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-spsc6.svc from pod e2e-tests-dns-spsc6/dns-test-c5116491-fbf6-11e8-8725-0a580af4034b: the server could not find the requested resource (get pods dns-test-c5116491-fbf6-11e8-8725-0a580af4034b)
Dec  9 21:09:54.275: INFO: Unable to read wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-spsc6.svc from pod e2e-tests-dns-spsc6/dns-test-c5116491-fbf6-11e8-8725-0a580af4034b: the server could not find the requested resource (get pods dns-test-c5116491-fbf6-11e8-8725-0a580af4034b)
Dec  9 21:09:54.283: INFO: Unable to read wheezy_udp@PodARecord from pod e2e-tests-dns-spsc6/dns-test-c5116491-fbf6-11e8-8725-0a580af4034b: the server could not find the requested resource (get pods dns-test-c5116491-fbf6-11e8-8725-0a580af4034b)
Dec  9 21:09:54.290: INFO: Unable to read wheezy_tcp@PodARecord from pod e2e-tests-dns-spsc6/dns-test-c5116491-fbf6-11e8-8725-0a580af4034b: the server could not find the requested resource (get pods dns-test-c5116491-fbf6-11e8-8725-0a580af4034b)
Dec  9 21:09:54.298: INFO: Unable to read 10.104.100.190_udp@PTR from pod e2e-tests-dns-spsc6/dns-test-c5116491-fbf6-11e8-8725-0a580af4034b: the server could not find the requested resource (get pods dns-test-c5116491-fbf6-11e8-8725-0a580af4034b)
Dec  9 21:09:54.304: INFO: Unable to read 10.104.100.190_tcp@PTR from pod e2e-tests-dns-spsc6/dns-test-c5116491-fbf6-11e8-8725-0a580af4034b: the server could not find the requested resource (get pods dns-test-c5116491-fbf6-11e8-8725-0a580af4034b)
Dec  9 21:09:54.311: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-spsc6/dns-test-c5116491-fbf6-11e8-8725-0a580af4034b: the server could not find the requested resource (get pods dns-test-c5116491-fbf6-11e8-8725-0a580af4034b)
Dec  9 21:09:54.318: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-spsc6/dns-test-c5116491-fbf6-11e8-8725-0a580af4034b: the server could not find the requested resource (get pods dns-test-c5116491-fbf6-11e8-8725-0a580af4034b)
Dec  9 21:09:54.325: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-spsc6 from pod e2e-tests-dns-spsc6/dns-test-c5116491-fbf6-11e8-8725-0a580af4034b: the server could not find the requested resource (get pods dns-test-c5116491-fbf6-11e8-8725-0a580af4034b)
Dec  9 21:09:54.333: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-spsc6 from pod e2e-tests-dns-spsc6/dns-test-c5116491-fbf6-11e8-8725-0a580af4034b: the server could not find the requested resource (get pods dns-test-c5116491-fbf6-11e8-8725-0a580af4034b)
Dec  9 21:09:54.339: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-spsc6.svc from pod e2e-tests-dns-spsc6/dns-test-c5116491-fbf6-11e8-8725-0a580af4034b: the server could not find the requested resource (get pods dns-test-c5116491-fbf6-11e8-8725-0a580af4034b)
Dec  9 21:09:54.347: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-spsc6.svc from pod e2e-tests-dns-spsc6/dns-test-c5116491-fbf6-11e8-8725-0a580af4034b: the server could not find the requested resource (get pods dns-test-c5116491-fbf6-11e8-8725-0a580af4034b)
Dec  9 21:09:54.353: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-spsc6.svc from pod e2e-tests-dns-spsc6/dns-test-c5116491-fbf6-11e8-8725-0a580af4034b: the server could not find the requested resource (get pods dns-test-c5116491-fbf6-11e8-8725-0a580af4034b)
Dec  9 21:09:54.360: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-spsc6.svc from pod e2e-tests-dns-spsc6/dns-test-c5116491-fbf6-11e8-8725-0a580af4034b: the server could not find the requested resource (get pods dns-test-c5116491-fbf6-11e8-8725-0a580af4034b)
Dec  9 21:09:54.367: INFO: Unable to read jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-spsc6.svc from pod e2e-tests-dns-spsc6/dns-test-c5116491-fbf6-11e8-8725-0a580af4034b: the server could not find the requested resource (get pods dns-test-c5116491-fbf6-11e8-8725-0a580af4034b)
Dec  9 21:09:54.374: INFO: Unable to read jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-spsc6.svc from pod e2e-tests-dns-spsc6/dns-test-c5116491-fbf6-11e8-8725-0a580af4034b: the server could not find the requested resource (get pods dns-test-c5116491-fbf6-11e8-8725-0a580af4034b)
Dec  9 21:09:54.381: INFO: Unable to read jessie_udp@PodARecord from pod e2e-tests-dns-spsc6/dns-test-c5116491-fbf6-11e8-8725-0a580af4034b: the server could not find the requested resource (get pods dns-test-c5116491-fbf6-11e8-8725-0a580af4034b)
Dec  9 21:09:54.387: INFO: Unable to read jessie_tcp@PodARecord from pod e2e-tests-dns-spsc6/dns-test-c5116491-fbf6-11e8-8725-0a580af4034b: the server could not find the requested resource (get pods dns-test-c5116491-fbf6-11e8-8725-0a580af4034b)
Dec  9 21:09:54.392: INFO: Unable to read 10.104.100.190_udp@PTR from pod e2e-tests-dns-spsc6/dns-test-c5116491-fbf6-11e8-8725-0a580af4034b: the server could not find the requested resource (get pods dns-test-c5116491-fbf6-11e8-8725-0a580af4034b)
Dec  9 21:09:54.399: INFO: Unable to read 10.104.100.190_tcp@PTR from pod e2e-tests-dns-spsc6/dns-test-c5116491-fbf6-11e8-8725-0a580af4034b: the server could not find the requested resource (get pods dns-test-c5116491-fbf6-11e8-8725-0a580af4034b)
Dec  9 21:09:54.399: INFO: Lookups using e2e-tests-dns-spsc6/dns-test-c5116491-fbf6-11e8-8725-0a580af4034b failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-spsc6 wheezy_tcp@dns-test-service.e2e-tests-dns-spsc6 wheezy_udp@dns-test-service.e2e-tests-dns-spsc6.svc wheezy_tcp@dns-test-service.e2e-tests-dns-spsc6.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-spsc6.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-spsc6.svc wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-spsc6.svc wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-spsc6.svc wheezy_udp@PodARecord wheezy_tcp@PodARecord 10.104.100.190_udp@PTR 10.104.100.190_tcp@PTR jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-spsc6 jessie_tcp@dns-test-service.e2e-tests-dns-spsc6 jessie_udp@dns-test-service.e2e-tests-dns-spsc6.svc jessie_tcp@dns-test-service.e2e-tests-dns-spsc6.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-spsc6.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-spsc6.svc jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-spsc6.svc jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-spsc6.svc jessie_udp@PodARecord jessie_tcp@PodARecord 10.104.100.190_udp@PTR 10.104.100.190_tcp@PTR]

Dec  9 21:09:59.411: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-spsc6/dns-test-c5116491-fbf6-11e8-8725-0a580af4034b: the server could not find the requested resource (get pods dns-test-c5116491-fbf6-11e8-8725-0a580af4034b)
Dec  9 21:09:59.459: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-spsc6.svc from pod e2e-tests-dns-spsc6/dns-test-c5116491-fbf6-11e8-8725-0a580af4034b: the server could not find the requested resource (get pods dns-test-c5116491-fbf6-11e8-8725-0a580af4034b)
Dec  9 21:09:59.528: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-spsc6/dns-test-c5116491-fbf6-11e8-8725-0a580af4034b: the server could not find the requested resource (get pods dns-test-c5116491-fbf6-11e8-8725-0a580af4034b)
Dec  9 21:09:59.534: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-spsc6/dns-test-c5116491-fbf6-11e8-8725-0a580af4034b: the server could not find the requested resource (get pods dns-test-c5116491-fbf6-11e8-8725-0a580af4034b)
Dec  9 21:09:59.616: INFO: Lookups using e2e-tests-dns-spsc6/dns-test-c5116491-fbf6-11e8-8725-0a580af4034b failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-spsc6.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service]

Dec  9 21:10:04.430: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-spsc6.svc from pod e2e-tests-dns-spsc6/dns-test-c5116491-fbf6-11e8-8725-0a580af4034b: the server could not find the requested resource (get pods dns-test-c5116491-fbf6-11e8-8725-0a580af4034b)
Dec  9 21:10:04.557: INFO: Lookups using e2e-tests-dns-spsc6/dns-test-c5116491-fbf6-11e8-8725-0a580af4034b failed for: [wheezy_tcp@dns-test-service.e2e-tests-dns-spsc6.svc]

Dec  9 21:10:09.441: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-spsc6.svc from pod e2e-tests-dns-spsc6/dns-test-c5116491-fbf6-11e8-8725-0a580af4034b: the server could not find the requested resource (get pods dns-test-c5116491-fbf6-11e8-8725-0a580af4034b)
Dec  9 21:10:09.568: INFO: Lookups using e2e-tests-dns-spsc6/dns-test-c5116491-fbf6-11e8-8725-0a580af4034b failed for: [wheezy_tcp@dns-test-service.e2e-tests-dns-spsc6.svc]

Dec  9 21:10:14.547: INFO: DNS probes using e2e-tests-dns-spsc6/dns-test-c5116491-fbf6-11e8-8725-0a580af4034b succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:10:14.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-spsc6" for this suite.
Dec  9 21:10:20.697: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:10:20.735: INFO: namespace: e2e-tests-dns-spsc6, resource: bindings, ignored listing per whitelist
Dec  9 21:10:20.863: INFO: namespace e2e-tests-dns-spsc6 deletion completed in 6.199138087s

• [SLOW TEST:28.846 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:10:20.863: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  9 21:10:20.972: INFO: Waiting up to 5m0s for pod "downward-api-d63bf0b1-fbf6-11e8-8725-0a580af4034b" in namespace "e2e-tests-downward-api-6mfd6" to be "success or failure"
Dec  9 21:10:20.978: INFO: Pod "downward-api-d63bf0b1-fbf6-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.071749ms
Dec  9 21:10:22.984: INFO: Pod "downward-api-d63bf0b1-fbf6-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011972494s
STEP: Saw pod success
Dec  9 21:10:22.984: INFO: Pod "downward-api-d63bf0b1-fbf6-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 21:10:22.990: INFO: Trying to get logs from node k8s04 pod downward-api-d63bf0b1-fbf6-11e8-8725-0a580af4034b container dapi-container: <nil>
STEP: delete the pod
Dec  9 21:10:23.030: INFO: Waiting for pod downward-api-d63bf0b1-fbf6-11e8-8725-0a580af4034b to disappear
Dec  9 21:10:23.038: INFO: Pod downward-api-d63bf0b1-fbf6-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:10:23.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-6mfd6" for this suite.
Dec  9 21:10:29.070: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:10:29.226: INFO: namespace: e2e-tests-downward-api-6mfd6, resource: bindings, ignored listing per whitelist
Dec  9 21:10:29.232: INFO: namespace e2e-tests-downward-api-6mfd6 deletion completed in 6.187605783s

• [SLOW TEST:8.369 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:10:29.232: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-bbmk8
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Dec  9 21:10:29.429: INFO: Found 0 stateful pods, waiting for 3
Dec  9 21:10:39.440: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  9 21:10:39.440: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  9 21:10:39.440: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Dec  9 21:10:39.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 exec --namespace=e2e-tests-statefulset-bbmk8 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  9 21:10:39.678: INFO: stderr: ""
Dec  9 21:10:39.678: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  9 21:10:39.678: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Dec  9 21:10:49.729: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Dec  9 21:10:59.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 exec --namespace=e2e-tests-statefulset-bbmk8 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  9 21:10:59.981: INFO: stderr: ""
Dec  9 21:10:59.981: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  9 21:10:59.981: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  9 21:11:10.015: INFO: Waiting for StatefulSet e2e-tests-statefulset-bbmk8/ss2 to complete update
Dec  9 21:11:10.015: INFO: Waiting for Pod e2e-tests-statefulset-bbmk8/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec  9 21:11:10.015: INFO: Waiting for Pod e2e-tests-statefulset-bbmk8/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec  9 21:11:10.015: INFO: Waiting for Pod e2e-tests-statefulset-bbmk8/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec  9 21:11:20.031: INFO: Waiting for StatefulSet e2e-tests-statefulset-bbmk8/ss2 to complete update
Dec  9 21:11:20.032: INFO: Waiting for Pod e2e-tests-statefulset-bbmk8/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec  9 21:11:20.032: INFO: Waiting for Pod e2e-tests-statefulset-bbmk8/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Dec  9 21:11:30.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 exec --namespace=e2e-tests-statefulset-bbmk8 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  9 21:11:30.230: INFO: stderr: ""
Dec  9 21:11:30.230: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  9 21:11:30.230: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  9 21:11:40.279: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Dec  9 21:11:50.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 exec --namespace=e2e-tests-statefulset-bbmk8 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  9 21:11:50.501: INFO: stderr: ""
Dec  9 21:11:50.501: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  9 21:11:50.501: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  9 21:12:10.535: INFO: Deleting all statefulset in ns e2e-tests-statefulset-bbmk8
Dec  9 21:12:10.540: INFO: Scaling statefulset ss2 to 0
Dec  9 21:12:50.566: INFO: Waiting for statefulset status.replicas updated to 0
Dec  9 21:12:50.571: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:12:50.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-bbmk8" for this suite.
Dec  9 21:12:56.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:12:56.669: INFO: namespace: e2e-tests-statefulset-bbmk8, resource: bindings, ignored listing per whitelist
Dec  9 21:12:56.789: INFO: namespace e2e-tests-statefulset-bbmk8 deletion completed in 6.175311848s

• [SLOW TEST:147.557 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:12:56.789: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  9 21:12:56.906: INFO: Waiting up to 5m0s for pod "downwardapi-volume-332d91d4-fbf7-11e8-8725-0a580af4034b" in namespace "e2e-tests-projected-982q5" to be "success or failure"
Dec  9 21:12:56.916: INFO: Pod "downwardapi-volume-332d91d4-fbf7-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.716165ms
Dec  9 21:12:58.921: INFO: Pod "downwardapi-volume-332d91d4-fbf7-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014846391s
STEP: Saw pod success
Dec  9 21:12:58.921: INFO: Pod "downwardapi-volume-332d91d4-fbf7-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 21:12:58.925: INFO: Trying to get logs from node k8s04 pod downwardapi-volume-332d91d4-fbf7-11e8-8725-0a580af4034b container client-container: <nil>
STEP: delete the pod
Dec  9 21:12:58.962: INFO: Waiting for pod downwardapi-volume-332d91d4-fbf7-11e8-8725-0a580af4034b to disappear
Dec  9 21:12:58.966: INFO: Pod downwardapi-volume-332d91d4-fbf7-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:12:58.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-982q5" for this suite.
Dec  9 21:13:04.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:13:05.100: INFO: namespace: e2e-tests-projected-982q5, resource: bindings, ignored listing per whitelist
Dec  9 21:13:05.142: INFO: namespace e2e-tests-projected-982q5 deletion completed in 6.166842309s

• [SLOW TEST:8.353 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:13:05.142: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-38270e02-fbf7-11e8-8725-0a580af4034b
STEP: Creating secret with name s-test-opt-upd-38270efd-fbf7-11e8-8725-0a580af4034b
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-38270e02-fbf7-11e8-8725-0a580af4034b
STEP: Updating secret s-test-opt-upd-38270efd-fbf7-11e8-8725-0a580af4034b
STEP: Creating secret with name s-test-opt-create-38270f11-fbf7-11e8-8725-0a580af4034b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:13:11.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-w4tgt" for this suite.
Dec  9 21:13:33.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:13:33.597: INFO: namespace: e2e-tests-secrets-w4tgt, resource: bindings, ignored listing per whitelist
Dec  9 21:13:33.614: INFO: namespace e2e-tests-secrets-w4tgt deletion completed in 22.190848137s

• [SLOW TEST:28.472 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:13:33.614: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-lfhsw/configmap-test-491fee4d-fbf7-11e8-8725-0a580af4034b
STEP: Creating a pod to test consume configMaps
Dec  9 21:13:33.733: INFO: Waiting up to 5m0s for pod "pod-configmaps-492117e6-fbf7-11e8-8725-0a580af4034b" in namespace "e2e-tests-configmap-lfhsw" to be "success or failure"
Dec  9 21:13:33.742: INFO: Pod "pod-configmaps-492117e6-fbf7-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.999517ms
Dec  9 21:13:35.747: INFO: Pod "pod-configmaps-492117e6-fbf7-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013882379s
STEP: Saw pod success
Dec  9 21:13:35.747: INFO: Pod "pod-configmaps-492117e6-fbf7-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 21:13:35.750: INFO: Trying to get logs from node k8s04 pod pod-configmaps-492117e6-fbf7-11e8-8725-0a580af4034b container env-test: <nil>
STEP: delete the pod
Dec  9 21:13:35.786: INFO: Waiting for pod pod-configmaps-492117e6-fbf7-11e8-8725-0a580af4034b to disappear
Dec  9 21:13:35.790: INFO: Pod pod-configmaps-492117e6-fbf7-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:13:35.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-lfhsw" for this suite.
Dec  9 21:13:41.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:13:41.892: INFO: namespace: e2e-tests-configmap-lfhsw, resource: bindings, ignored listing per whitelist
Dec  9 21:13:41.968: INFO: namespace e2e-tests-configmap-lfhsw deletion completed in 6.170059726s

• [SLOW TEST:8.354 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:13:41.968: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec  9 21:13:42.080: INFO: Waiting up to 5m0s for pod "pod-4e1a978a-fbf7-11e8-8725-0a580af4034b" in namespace "e2e-tests-emptydir-s6lvb" to be "success or failure"
Dec  9 21:13:42.087: INFO: Pod "pod-4e1a978a-fbf7-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.459267ms
Dec  9 21:13:44.101: INFO: Pod "pod-4e1a978a-fbf7-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021541312s
STEP: Saw pod success
Dec  9 21:13:44.101: INFO: Pod "pod-4e1a978a-fbf7-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 21:13:44.105: INFO: Trying to get logs from node k8s04 pod pod-4e1a978a-fbf7-11e8-8725-0a580af4034b container test-container: <nil>
STEP: delete the pod
Dec  9 21:13:44.139: INFO: Waiting for pod pod-4e1a978a-fbf7-11e8-8725-0a580af4034b to disappear
Dec  9 21:13:44.144: INFO: Pod pod-4e1a978a-fbf7-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:13:44.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-s6lvb" for this suite.
Dec  9 21:13:50.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:13:50.308: INFO: namespace: e2e-tests-emptydir-s6lvb, resource: bindings, ignored listing per whitelist
Dec  9 21:13:50.336: INFO: namespace e2e-tests-emptydir-s6lvb deletion completed in 6.181349315s

• [SLOW TEST:8.368 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:13:50.337: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  9 21:13:50.453: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5318384d-fbf7-11e8-8725-0a580af4034b" in namespace "e2e-tests-downward-api-c9f9f" to be "success or failure"
Dec  9 21:13:50.460: INFO: Pod "downwardapi-volume-5318384d-fbf7-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.296946ms
Dec  9 21:13:52.465: INFO: Pod "downwardapi-volume-5318384d-fbf7-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012281195s
STEP: Saw pod success
Dec  9 21:13:52.465: INFO: Pod "downwardapi-volume-5318384d-fbf7-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 21:13:52.470: INFO: Trying to get logs from node k8s04 pod downwardapi-volume-5318384d-fbf7-11e8-8725-0a580af4034b container client-container: <nil>
STEP: delete the pod
Dec  9 21:13:52.505: INFO: Waiting for pod downwardapi-volume-5318384d-fbf7-11e8-8725-0a580af4034b to disappear
Dec  9 21:13:52.510: INFO: Pod downwardapi-volume-5318384d-fbf7-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:13:52.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-c9f9f" for this suite.
Dec  9 21:13:58.539: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:13:58.607: INFO: namespace: e2e-tests-downward-api-c9f9f, resource: bindings, ignored listing per whitelist
Dec  9 21:13:58.688: INFO: namespace e2e-tests-downward-api-c9f9f deletion completed in 6.171003012s

• [SLOW TEST:8.351 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:13:58.688: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-58132636-fbf7-11e8-8725-0a580af4034b
STEP: Creating a pod to test consume secrets
Dec  9 21:13:58.824: INFO: Waiting up to 5m0s for pod "pod-secrets-58144e3d-fbf7-11e8-8725-0a580af4034b" in namespace "e2e-tests-secrets-g6lsj" to be "success or failure"
Dec  9 21:13:58.833: INFO: Pod "pod-secrets-58144e3d-fbf7-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.540424ms
Dec  9 21:14:00.838: INFO: Pod "pod-secrets-58144e3d-fbf7-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011999581s
STEP: Saw pod success
Dec  9 21:14:00.838: INFO: Pod "pod-secrets-58144e3d-fbf7-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 21:14:00.842: INFO: Trying to get logs from node k8s04 pod pod-secrets-58144e3d-fbf7-11e8-8725-0a580af4034b container secret-volume-test: <nil>
STEP: delete the pod
Dec  9 21:14:00.879: INFO: Waiting for pod pod-secrets-58144e3d-fbf7-11e8-8725-0a580af4034b to disappear
Dec  9 21:14:00.885: INFO: Pod pod-secrets-58144e3d-fbf7-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:14:00.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-g6lsj" for this suite.
Dec  9 21:14:06.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:14:07.035: INFO: namespace: e2e-tests-secrets-g6lsj, resource: bindings, ignored listing per whitelist
Dec  9 21:14:07.067: INFO: namespace e2e-tests-secrets-g6lsj deletion completed in 6.175583179s

• [SLOW TEST:8.380 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:14:07.067: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-5hwdw
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  9 21:14:07.184: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  9 21:14:29.268: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.3.33:8080/dial?request=hostName&protocol=udp&host=10.244.3.32&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-5hwdw PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  9 21:14:29.268: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
Dec  9 21:14:29.408: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:14:29.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-5hwdw" for this suite.
Dec  9 21:14:51.432: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:14:51.543: INFO: namespace: e2e-tests-pod-network-test-5hwdw, resource: bindings, ignored listing per whitelist
Dec  9 21:14:51.584: INFO: namespace e2e-tests-pod-network-test-5hwdw deletion completed in 22.17135793s

• [SLOW TEST:44.517 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:14:51.585: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Dec  9 21:14:51.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 --namespace=e2e-tests-kubectl-mxnsx run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Dec  9 21:14:53.698: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Dec  9 21:14:53.698: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:14:55.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mxnsx" for this suite.
Dec  9 21:15:01.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:15:01.817: INFO: namespace: e2e-tests-kubectl-mxnsx, resource: bindings, ignored listing per whitelist
Dec  9 21:15:01.883: INFO: namespace e2e-tests-kubectl-mxnsx deletion completed in 6.168128445s

• [SLOW TEST:10.299 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:15:01.883: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-4tfh2
Dec  9 21:15:04.015: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-4tfh2
STEP: checking the pod's current state and verifying that restartCount is present
Dec  9 21:15:04.019: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:19:04.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-4tfh2" for this suite.
Dec  9 21:19:10.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:19:10.972: INFO: namespace: e2e-tests-container-probe-4tfh2, resource: bindings, ignored listing per whitelist
Dec  9 21:19:11.013: INFO: namespace e2e-tests-container-probe-4tfh2 deletion completed in 6.184335101s

• [SLOW TEST:249.130 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:19:11.014: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-123c56e4-fbf8-11e8-8725-0a580af4034b
STEP: Creating a pod to test consume secrets
Dec  9 21:19:11.144: INFO: Waiting up to 5m0s for pod "pod-secrets-123d85b3-fbf8-11e8-8725-0a580af4034b" in namespace "e2e-tests-secrets-n4czj" to be "success or failure"
Dec  9 21:19:11.151: INFO: Pod "pod-secrets-123d85b3-fbf8-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.790078ms
Dec  9 21:19:13.157: INFO: Pod "pod-secrets-123d85b3-fbf8-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013300111s
STEP: Saw pod success
Dec  9 21:19:13.157: INFO: Pod "pod-secrets-123d85b3-fbf8-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 21:19:13.161: INFO: Trying to get logs from node k8s04 pod pod-secrets-123d85b3-fbf8-11e8-8725-0a580af4034b container secret-volume-test: <nil>
STEP: delete the pod
Dec  9 21:19:13.204: INFO: Waiting for pod pod-secrets-123d85b3-fbf8-11e8-8725-0a580af4034b to disappear
Dec  9 21:19:13.210: INFO: Pod pod-secrets-123d85b3-fbf8-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:19:13.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-n4czj" for this suite.
Dec  9 21:19:19.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:19:19.346: INFO: namespace: e2e-tests-secrets-n4czj, resource: bindings, ignored listing per whitelist
Dec  9 21:19:19.403: INFO: namespace e2e-tests-secrets-n4czj deletion completed in 6.183710098s

• [SLOW TEST:8.389 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:19:19.403: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  9 21:19:19.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 version --client'
Dec  9 21:19:19.564: INFO: stderr: ""
Dec  9 21:19:19.564: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Dec  9 21:19:19.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 create -f - --namespace=e2e-tests-kubectl-hrdgj'
Dec  9 21:19:19.742: INFO: stderr: ""
Dec  9 21:19:19.742: INFO: stdout: "replicationcontroller/redis-master created\n"
Dec  9 21:19:19.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 create -f - --namespace=e2e-tests-kubectl-hrdgj'
Dec  9 21:19:19.958: INFO: stderr: ""
Dec  9 21:19:19.958: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  9 21:19:20.973: INFO: Selector matched 1 pods for map[app:redis]
Dec  9 21:19:20.973: INFO: Found 0 / 1
Dec  9 21:19:21.963: INFO: Selector matched 1 pods for map[app:redis]
Dec  9 21:19:21.963: INFO: Found 1 / 1
Dec  9 21:19:21.963: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  9 21:19:21.968: INFO: Selector matched 1 pods for map[app:redis]
Dec  9 21:19:21.968: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  9 21:19:21.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 describe pod redis-master-99gnd --namespace=e2e-tests-kubectl-hrdgj'
Dec  9 21:19:22.077: INFO: stderr: ""
Dec  9 21:19:22.077: INFO: stdout: "Name:               redis-master-99gnd\nNamespace:          e2e-tests-kubectl-hrdgj\nPriority:           0\nPriorityClassName:  <none>\nNode:               k8s04/192.168.9.14\nStart Time:         Sun, 09 Dec 2018 21:19:19 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.244.3.37\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://160813f726a65841da682d801bb023c6fd365a571f3180556c41c740f8d03b74\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sun, 09 Dec 2018 21:19:20 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-7v6mg (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-7v6mg:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-7v6mg\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  3s    default-scheduler  Successfully assigned e2e-tests-kubectl-hrdgj/redis-master-99gnd to k8s04\n  Normal  Pulled     2s    kubelet, k8s04     Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, k8s04     Created container\n  Normal  Started    2s    kubelet, k8s04     Started container\n"
Dec  9 21:19:22.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 describe rc redis-master --namespace=e2e-tests-kubectl-hrdgj'
Dec  9 21:19:22.184: INFO: stderr: ""
Dec  9 21:19:22.184: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-hrdgj\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-99gnd\n"
Dec  9 21:19:22.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 describe service redis-master --namespace=e2e-tests-kubectl-hrdgj'
Dec  9 21:19:22.278: INFO: stderr: ""
Dec  9 21:19:22.278: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-hrdgj\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.99.172.51\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.244.3.37:6379\nSession Affinity:  None\nEvents:            <none>\n"
Dec  9 21:19:22.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 describe node k8s01'
Dec  9 21:19:22.392: INFO: stderr: ""
Dec  9 21:19:22.392: INFO: stdout: "Name:               k8s01\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/hostname=k8s01\n                    node-role.kubernetes.io/master=\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"2a:43:7b:0d:14:8b\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 192.168.9.11\n                    kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Sun, 09 Dec 2018 16:17:35 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Sun, 09 Dec 2018 21:19:19 +0000   Sun, 09 Dec 2018 16:17:28 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Sun, 09 Dec 2018 21:19:19 +0000   Sun, 09 Dec 2018 16:17:28 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Sun, 09 Dec 2018 21:19:19 +0000   Sun, 09 Dec 2018 16:17:28 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Sun, 09 Dec 2018 21:19:19 +0000   Sun, 09 Dec 2018 16:17:55 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  192.168.9.11\n  Hostname:    k8s01\nCapacity:\n cpu:                2\n ephemeral-storage:  99688900Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             3861512Ki\n pods:               110\nAllocatable:\n cpu:                2\n ephemeral-storage:  91873290088\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             3759112Ki\n pods:               110\nSystem Info:\n Machine ID:                 a8e78ff250274bc7bd50871834e3e9a6\n System UUID:                A2B64D56-4E35-55B5-65FC-2149D8086E66\n Boot ID:                    3c88092b-4f5b-48b2-a1d9-64023a920c7d\n Kernel Version:             3.10.0-957.el7.x86_64\n OS Image:                   CentOS Linux 7 (Core)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.1\n Kubelet Version:            v1.13.0\n Kube-Proxy Version:         v1.13.0\nPodCIDR:                     10.244.0.0/24\nNon-terminated Pods:         (9 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-1cb03de6217e447d-79r6s    0 (0%)        0 (0%)      0 (0%)           0 (0%)         63m\n  kube-system                coredns-9dbbc75f6-cggdl                                    100m (5%)     0 (0%)      70Mi (1%)        170Mi (4%)     5h1m\n  kube-system                coredns-9dbbc75f6-w6spc                                    100m (5%)     0 (0%)      70Mi (1%)        170Mi (4%)     5h1m\n  kube-system                kube-apiserver-k8s01                                       250m (12%)    0 (0%)      0 (0%)           0 (0%)         5h\n  kube-system                kube-controller-manager-k8s01                              200m (10%)    0 (0%)      0 (0%)           0 (0%)         5h\n  kube-system                kube-flannel-ds-jx66c                                      100m (5%)     100m (5%)   50Mi (1%)        50Mi (1%)      5h1m\n  kube-system                kube-proxy-gss7l                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         5h1m\n  kube-system                kube-scheduler-k8s01                                       100m (5%)     0 (0%)      0 (0%)           0 (0%)         5h\n  kube-system                kubernetes-dashboard-844ddc9487-bwb5h                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         5h1m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                850m (42%)  100m (5%)\n  memory             190Mi (5%)  390Mi (10%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:              <none>\n"
Dec  9 21:19:22.392: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 describe namespace e2e-tests-kubectl-hrdgj'
Dec  9 21:19:22.503: INFO: stderr: ""
Dec  9 21:19:22.503: INFO: stdout: "Name:         e2e-tests-kubectl-hrdgj\nLabels:       e2e-framework=kubectl\n              e2e-run=3a3019ef-fbef-11e8-8725-0a580af4034b\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:19:22.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hrdgj" for this suite.
Dec  9 21:19:44.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:19:44.645: INFO: namespace: e2e-tests-kubectl-hrdgj, resource: bindings, ignored listing per whitelist
Dec  9 21:19:44.693: INFO: namespace e2e-tests-kubectl-hrdgj deletion completed in 22.184845842s

• [SLOW TEST:25.290 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:19:44.693: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-pgd2
STEP: Creating a pod to test atomic-volume-subpath
Dec  9 21:19:44.836: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-pgd2" in namespace "e2e-tests-subpath-bp9nv" to be "success or failure"
Dec  9 21:19:44.846: INFO: Pod "pod-subpath-test-secret-pgd2": Phase="Pending", Reason="", readiness=false. Elapsed: 9.326449ms
Dec  9 21:19:46.851: INFO: Pod "pod-subpath-test-secret-pgd2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014444645s
Dec  9 21:19:48.856: INFO: Pod "pod-subpath-test-secret-pgd2": Phase="Running", Reason="", readiness=false. Elapsed: 4.019169738s
Dec  9 21:19:50.861: INFO: Pod "pod-subpath-test-secret-pgd2": Phase="Running", Reason="", readiness=false. Elapsed: 6.024422806s
Dec  9 21:19:52.865: INFO: Pod "pod-subpath-test-secret-pgd2": Phase="Running", Reason="", readiness=false. Elapsed: 8.028754084s
Dec  9 21:19:54.876: INFO: Pod "pod-subpath-test-secret-pgd2": Phase="Running", Reason="", readiness=false. Elapsed: 10.039932938s
Dec  9 21:19:56.880: INFO: Pod "pod-subpath-test-secret-pgd2": Phase="Running", Reason="", readiness=false. Elapsed: 12.043926726s
Dec  9 21:19:58.885: INFO: Pod "pod-subpath-test-secret-pgd2": Phase="Running", Reason="", readiness=false. Elapsed: 14.048631396s
Dec  9 21:20:00.891: INFO: Pod "pod-subpath-test-secret-pgd2": Phase="Running", Reason="", readiness=false. Elapsed: 16.054686923s
Dec  9 21:20:02.896: INFO: Pod "pod-subpath-test-secret-pgd2": Phase="Running", Reason="", readiness=false. Elapsed: 18.060085201s
Dec  9 21:20:04.910: INFO: Pod "pod-subpath-test-secret-pgd2": Phase="Running", Reason="", readiness=false. Elapsed: 20.073369111s
Dec  9 21:20:06.916: INFO: Pod "pod-subpath-test-secret-pgd2": Phase="Running", Reason="", readiness=false. Elapsed: 22.079122014s
Dec  9 21:20:08.921: INFO: Pod "pod-subpath-test-secret-pgd2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.084550383s
STEP: Saw pod success
Dec  9 21:20:08.921: INFO: Pod "pod-subpath-test-secret-pgd2" satisfied condition "success or failure"
Dec  9 21:20:08.925: INFO: Trying to get logs from node k8s04 pod pod-subpath-test-secret-pgd2 container test-container-subpath-secret-pgd2: <nil>
STEP: delete the pod
Dec  9 21:20:08.964: INFO: Waiting for pod pod-subpath-test-secret-pgd2 to disappear
Dec  9 21:20:08.970: INFO: Pod pod-subpath-test-secret-pgd2 no longer exists
STEP: Deleting pod pod-subpath-test-secret-pgd2
Dec  9 21:20:08.971: INFO: Deleting pod "pod-subpath-test-secret-pgd2" in namespace "e2e-tests-subpath-bp9nv"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:20:08.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-bp9nv" for this suite.
Dec  9 21:20:15.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:20:15.132: INFO: namespace: e2e-tests-subpath-bp9nv, resource: bindings, ignored listing per whitelist
Dec  9 21:20:15.200: INFO: namespace e2e-tests-subpath-bp9nv deletion completed in 6.210156914s

• [SLOW TEST:30.507 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:20:15.200: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec  9 21:20:17.862: INFO: Successfully updated pod "labelsupdate387e932a-fbf8-11e8-8725-0a580af4034b"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:20:21.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-tgkrt" for this suite.
Dec  9 21:20:43.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:20:43.979: INFO: namespace: e2e-tests-downward-api-tgkrt, resource: bindings, ignored listing per whitelist
Dec  9 21:20:44.073: INFO: namespace e2e-tests-downward-api-tgkrt deletion completed in 22.1717843s

• [SLOW TEST:28.873 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:20:44.073: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  9 21:20:44.186: INFO: Waiting up to 5m0s for pod "downward-api-49b2e26f-fbf8-11e8-8725-0a580af4034b" in namespace "e2e-tests-downward-api-2749n" to be "success or failure"
Dec  9 21:20:44.202: INFO: Pod "downward-api-49b2e26f-fbf8-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 16.051187ms
Dec  9 21:20:46.206: INFO: Pod "downward-api-49b2e26f-fbf8-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020546213s
STEP: Saw pod success
Dec  9 21:20:46.207: INFO: Pod "downward-api-49b2e26f-fbf8-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 21:20:46.211: INFO: Trying to get logs from node k8s04 pod downward-api-49b2e26f-fbf8-11e8-8725-0a580af4034b container dapi-container: <nil>
STEP: delete the pod
Dec  9 21:20:46.250: INFO: Waiting for pod downward-api-49b2e26f-fbf8-11e8-8725-0a580af4034b to disappear
Dec  9 21:20:46.256: INFO: Pod downward-api-49b2e26f-fbf8-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:20:46.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2749n" for this suite.
Dec  9 21:20:52.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:20:52.348: INFO: namespace: e2e-tests-downward-api-2749n, resource: bindings, ignored listing per whitelist
Dec  9 21:20:52.439: INFO: namespace e2e-tests-downward-api-2749n deletion completed in 6.176549075s

• [SLOW TEST:8.366 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:20:52.439: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  9 21:20:52.554: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Dec  9 21:20:52.570: INFO: Number of nodes with available pods: 0
Dec  9 21:20:52.570: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Dec  9 21:20:52.611: INFO: Number of nodes with available pods: 0
Dec  9 21:20:52.611: INFO: Node k8s04 is running more than one daemon pod
Dec  9 21:20:53.621: INFO: Number of nodes with available pods: 1
Dec  9 21:20:53.621: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Dec  9 21:20:53.650: INFO: Number of nodes with available pods: 1
Dec  9 21:20:53.650: INFO: Number of running nodes: 0, number of available pods: 1
Dec  9 21:20:54.655: INFO: Number of nodes with available pods: 0
Dec  9 21:20:54.655: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Dec  9 21:20:54.672: INFO: Number of nodes with available pods: 0
Dec  9 21:20:54.672: INFO: Node k8s04 is running more than one daemon pod
Dec  9 21:20:55.678: INFO: Number of nodes with available pods: 0
Dec  9 21:20:55.678: INFO: Node k8s04 is running more than one daemon pod
Dec  9 21:20:56.677: INFO: Number of nodes with available pods: 0
Dec  9 21:20:56.677: INFO: Node k8s04 is running more than one daemon pod
Dec  9 21:20:57.677: INFO: Number of nodes with available pods: 0
Dec  9 21:20:57.677: INFO: Node k8s04 is running more than one daemon pod
Dec  9 21:20:58.686: INFO: Number of nodes with available pods: 0
Dec  9 21:20:58.686: INFO: Node k8s04 is running more than one daemon pod
Dec  9 21:20:59.678: INFO: Number of nodes with available pods: 0
Dec  9 21:20:59.678: INFO: Node k8s04 is running more than one daemon pod
Dec  9 21:21:00.678: INFO: Number of nodes with available pods: 0
Dec  9 21:21:00.678: INFO: Node k8s04 is running more than one daemon pod
Dec  9 21:21:01.678: INFO: Number of nodes with available pods: 0
Dec  9 21:21:01.678: INFO: Node k8s04 is running more than one daemon pod
Dec  9 21:21:02.678: INFO: Number of nodes with available pods: 0
Dec  9 21:21:02.678: INFO: Node k8s04 is running more than one daemon pod
Dec  9 21:21:03.678: INFO: Number of nodes with available pods: 0
Dec  9 21:21:03.678: INFO: Node k8s04 is running more than one daemon pod
Dec  9 21:21:04.678: INFO: Number of nodes with available pods: 0
Dec  9 21:21:04.678: INFO: Node k8s04 is running more than one daemon pod
Dec  9 21:21:05.677: INFO: Number of nodes with available pods: 0
Dec  9 21:21:05.677: INFO: Node k8s04 is running more than one daemon pod
Dec  9 21:21:06.678: INFO: Number of nodes with available pods: 0
Dec  9 21:21:06.678: INFO: Node k8s04 is running more than one daemon pod
Dec  9 21:21:07.677: INFO: Number of nodes with available pods: 0
Dec  9 21:21:07.677: INFO: Node k8s04 is running more than one daemon pod
Dec  9 21:21:08.678: INFO: Number of nodes with available pods: 0
Dec  9 21:21:08.678: INFO: Node k8s04 is running more than one daemon pod
Dec  9 21:21:09.684: INFO: Number of nodes with available pods: 0
Dec  9 21:21:09.684: INFO: Node k8s04 is running more than one daemon pod
Dec  9 21:21:10.678: INFO: Number of nodes with available pods: 0
Dec  9 21:21:10.678: INFO: Node k8s04 is running more than one daemon pod
Dec  9 21:21:11.678: INFO: Number of nodes with available pods: 0
Dec  9 21:21:11.678: INFO: Node k8s04 is running more than one daemon pod
Dec  9 21:21:12.677: INFO: Number of nodes with available pods: 0
Dec  9 21:21:12.677: INFO: Node k8s04 is running more than one daemon pod
Dec  9 21:21:13.678: INFO: Number of nodes with available pods: 0
Dec  9 21:21:13.678: INFO: Node k8s04 is running more than one daemon pod
Dec  9 21:21:14.679: INFO: Number of nodes with available pods: 0
Dec  9 21:21:14.679: INFO: Node k8s04 is running more than one daemon pod
Dec  9 21:21:15.678: INFO: Number of nodes with available pods: 0
Dec  9 21:21:15.678: INFO: Node k8s04 is running more than one daemon pod
Dec  9 21:21:16.677: INFO: Number of nodes with available pods: 0
Dec  9 21:21:16.677: INFO: Node k8s04 is running more than one daemon pod
Dec  9 21:21:17.678: INFO: Number of nodes with available pods: 0
Dec  9 21:21:17.678: INFO: Node k8s04 is running more than one daemon pod
Dec  9 21:21:18.678: INFO: Number of nodes with available pods: 0
Dec  9 21:21:18.678: INFO: Node k8s04 is running more than one daemon pod
Dec  9 21:21:19.678: INFO: Number of nodes with available pods: 0
Dec  9 21:21:19.678: INFO: Node k8s04 is running more than one daemon pod
Dec  9 21:21:20.685: INFO: Number of nodes with available pods: 0
Dec  9 21:21:20.685: INFO: Node k8s04 is running more than one daemon pod
Dec  9 21:21:21.678: INFO: Number of nodes with available pods: 0
Dec  9 21:21:21.678: INFO: Node k8s04 is running more than one daemon pod
Dec  9 21:21:22.678: INFO: Number of nodes with available pods: 0
Dec  9 21:21:22.678: INFO: Node k8s04 is running more than one daemon pod
Dec  9 21:21:23.677: INFO: Number of nodes with available pods: 0
Dec  9 21:21:23.677: INFO: Node k8s04 is running more than one daemon pod
Dec  9 21:21:24.677: INFO: Number of nodes with available pods: 0
Dec  9 21:21:24.677: INFO: Node k8s04 is running more than one daemon pod
Dec  9 21:21:25.678: INFO: Number of nodes with available pods: 0
Dec  9 21:21:25.678: INFO: Node k8s04 is running more than one daemon pod
Dec  9 21:21:26.677: INFO: Number of nodes with available pods: 0
Dec  9 21:21:26.677: INFO: Node k8s04 is running more than one daemon pod
Dec  9 21:21:27.677: INFO: Number of nodes with available pods: 0
Dec  9 21:21:27.677: INFO: Node k8s04 is running more than one daemon pod
Dec  9 21:21:28.677: INFO: Number of nodes with available pods: 0
Dec  9 21:21:28.678: INFO: Node k8s04 is running more than one daemon pod
Dec  9 21:21:29.678: INFO: Number of nodes with available pods: 0
Dec  9 21:21:29.678: INFO: Node k8s04 is running more than one daemon pod
Dec  9 21:21:30.677: INFO: Number of nodes with available pods: 0
Dec  9 21:21:30.678: INFO: Node k8s04 is running more than one daemon pod
Dec  9 21:21:31.685: INFO: Number of nodes with available pods: 0
Dec  9 21:21:31.685: INFO: Node k8s04 is running more than one daemon pod
Dec  9 21:21:32.677: INFO: Number of nodes with available pods: 1
Dec  9 21:21:32.677: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-dsnfs, will wait for the garbage collector to delete the pods
Dec  9 21:21:32.755: INFO: Deleting DaemonSet.extensions daemon-set took: 12.354486ms
Dec  9 21:21:32.856: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.690204ms
Dec  9 21:22:10.767: INFO: Number of nodes with available pods: 0
Dec  9 21:22:10.768: INFO: Number of running nodes: 0, number of available pods: 0
Dec  9 21:22:10.771: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-dsnfs/daemonsets","resourceVersion":"50827"},"items":null}

Dec  9 21:22:10.777: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-dsnfs/pods","resourceVersion":"50827"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:22:10.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-dsnfs" for this suite.
Dec  9 21:22:16.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:22:16.852: INFO: namespace: e2e-tests-daemonsets-dsnfs, resource: bindings, ignored listing per whitelist
Dec  9 21:22:16.988: INFO: namespace e2e-tests-daemonsets-dsnfs deletion completed in 6.177519105s

• [SLOW TEST:84.549 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:22:16.988: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  9 21:22:17.100: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8114a923-fbf8-11e8-8725-0a580af4034b" in namespace "e2e-tests-downward-api-nxdcr" to be "success or failure"
Dec  9 21:22:17.107: INFO: Pod "downwardapi-volume-8114a923-fbf8-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.451966ms
Dec  9 21:22:19.112: INFO: Pod "downwardapi-volume-8114a923-fbf8-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011494366s
Dec  9 21:22:21.124: INFO: Pod "downwardapi-volume-8114a923-fbf8-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023261585s
STEP: Saw pod success
Dec  9 21:22:21.124: INFO: Pod "downwardapi-volume-8114a923-fbf8-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 21:22:21.128: INFO: Trying to get logs from node k8s04 pod downwardapi-volume-8114a923-fbf8-11e8-8725-0a580af4034b container client-container: <nil>
STEP: delete the pod
Dec  9 21:22:21.164: INFO: Waiting for pod downwardapi-volume-8114a923-fbf8-11e8-8725-0a580af4034b to disappear
Dec  9 21:22:21.168: INFO: Pod downwardapi-volume-8114a923-fbf8-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:22:21.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-nxdcr" for this suite.
Dec  9 21:22:27.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:22:27.287: INFO: namespace: e2e-tests-downward-api-nxdcr, resource: bindings, ignored listing per whitelist
Dec  9 21:22:27.341: INFO: namespace e2e-tests-downward-api-nxdcr deletion completed in 6.165359548s

• [SLOW TEST:10.352 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:22:27.341: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  9 21:22:27.450: INFO: Waiting up to 5m0s for pod "downward-api-873fb01e-fbf8-11e8-8725-0a580af4034b" in namespace "e2e-tests-downward-api-sqtqc" to be "success or failure"
Dec  9 21:22:27.457: INFO: Pod "downward-api-873fb01e-fbf8-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.455696ms
Dec  9 21:22:29.462: INFO: Pod "downward-api-873fb01e-fbf8-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011690242s
STEP: Saw pod success
Dec  9 21:22:29.462: INFO: Pod "downward-api-873fb01e-fbf8-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 21:22:29.467: INFO: Trying to get logs from node k8s04 pod downward-api-873fb01e-fbf8-11e8-8725-0a580af4034b container dapi-container: <nil>
STEP: delete the pod
Dec  9 21:22:29.503: INFO: Waiting for pod downward-api-873fb01e-fbf8-11e8-8725-0a580af4034b to disappear
Dec  9 21:22:29.512: INFO: Pod downward-api-873fb01e-fbf8-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:22:29.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-sqtqc" for this suite.
Dec  9 21:22:35.539: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:22:35.646: INFO: namespace: e2e-tests-downward-api-sqtqc, resource: bindings, ignored listing per whitelist
Dec  9 21:22:35.685: INFO: namespace e2e-tests-downward-api-sqtqc deletion completed in 6.166644238s

• [SLOW TEST:8.345 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:22:35.685: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-8c38e84c-fbf8-11e8-8725-0a580af4034b
STEP: Creating a pod to test consume configMaps
Dec  9 21:22:35.804: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8c3a363d-fbf8-11e8-8725-0a580af4034b" in namespace "e2e-tests-projected-w4q5b" to be "success or failure"
Dec  9 21:22:35.816: INFO: Pod "pod-projected-configmaps-8c3a363d-fbf8-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.622417ms
Dec  9 21:22:37.820: INFO: Pod "pod-projected-configmaps-8c3a363d-fbf8-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016284476s
STEP: Saw pod success
Dec  9 21:22:37.820: INFO: Pod "pod-projected-configmaps-8c3a363d-fbf8-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 21:22:37.825: INFO: Trying to get logs from node k8s04 pod pod-projected-configmaps-8c3a363d-fbf8-11e8-8725-0a580af4034b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  9 21:22:37.859: INFO: Waiting for pod pod-projected-configmaps-8c3a363d-fbf8-11e8-8725-0a580af4034b to disappear
Dec  9 21:22:37.864: INFO: Pod pod-projected-configmaps-8c3a363d-fbf8-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:22:37.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-w4q5b" for this suite.
Dec  9 21:22:43.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:22:44.053: INFO: namespace: e2e-tests-projected-w4q5b, resource: bindings, ignored listing per whitelist
Dec  9 21:22:44.053: INFO: namespace e2e-tests-projected-w4q5b deletion completed in 6.181056838s

• [SLOW TEST:8.368 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:22:44.053: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  9 21:22:44.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-d4bmj'
Dec  9 21:22:44.261: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  9 21:22:44.261: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Dec  9 21:22:48.284: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-d4bmj'
Dec  9 21:22:48.378: INFO: stderr: ""
Dec  9 21:22:48.378: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:22:48.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-d4bmj" for this suite.
Dec  9 21:23:10.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:23:10.514: INFO: namespace: e2e-tests-kubectl-d4bmj, resource: bindings, ignored listing per whitelist
Dec  9 21:23:10.559: INFO: namespace e2e-tests-kubectl-d4bmj deletion completed in 22.172775961s

• [SLOW TEST:26.506 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:23:10.559: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec  9 21:23:14.728: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  9 21:23:14.734: INFO: Pod pod-with-prestop-http-hook still exists
Dec  9 21:23:16.734: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  9 21:23:16.739: INFO: Pod pod-with-prestop-http-hook still exists
Dec  9 21:23:18.734: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  9 21:23:18.739: INFO: Pod pod-with-prestop-http-hook still exists
Dec  9 21:23:20.734: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  9 21:23:20.739: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:23:20.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-q49ds" for this suite.
Dec  9 21:23:42.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:23:42.871: INFO: namespace: e2e-tests-container-lifecycle-hook-q49ds, resource: bindings, ignored listing per whitelist
Dec  9 21:23:42.925: INFO: namespace e2e-tests-container-lifecycle-hook-q49ds deletion completed in 22.16355178s

• [SLOW TEST:32.366 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:23:42.925: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  9 21:23:43.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-4p5vp'
Dec  9 21:23:43.124: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  9 21:23:43.124: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Dec  9 21:23:45.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-4p5vp'
Dec  9 21:23:45.242: INFO: stderr: ""
Dec  9 21:23:45.242: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:23:45.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4p5vp" for this suite.
Dec  9 21:24:07.274: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:24:07.325: INFO: namespace: e2e-tests-kubectl-4p5vp, resource: bindings, ignored listing per whitelist
Dec  9 21:24:07.436: INFO: namespace e2e-tests-kubectl-4p5vp deletion completed in 22.187078342s

• [SLOW TEST:24.511 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:24:07.436: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-c2e9dd11-fbf8-11e8-8725-0a580af4034b
STEP: Creating a pod to test consume configMaps
Dec  9 21:24:07.559: INFO: Waiting up to 5m0s for pod "pod-configmaps-c2eb0f09-fbf8-11e8-8725-0a580af4034b" in namespace "e2e-tests-configmap-ckx22" to be "success or failure"
Dec  9 21:24:07.567: INFO: Pod "pod-configmaps-c2eb0f09-fbf8-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.784752ms
Dec  9 21:24:09.581: INFO: Pod "pod-configmaps-c2eb0f09-fbf8-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022560687s
STEP: Saw pod success
Dec  9 21:24:09.581: INFO: Pod "pod-configmaps-c2eb0f09-fbf8-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 21:24:09.586: INFO: Trying to get logs from node k8s04 pod pod-configmaps-c2eb0f09-fbf8-11e8-8725-0a580af4034b container configmap-volume-test: <nil>
STEP: delete the pod
Dec  9 21:24:09.635: INFO: Waiting for pod pod-configmaps-c2eb0f09-fbf8-11e8-8725-0a580af4034b to disappear
Dec  9 21:24:09.640: INFO: Pod pod-configmaps-c2eb0f09-fbf8-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:24:09.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-ckx22" for this suite.
Dec  9 21:24:15.668: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:24:15.748: INFO: namespace: e2e-tests-configmap-ckx22, resource: bindings, ignored listing per whitelist
Dec  9 21:24:15.836: INFO: namespace e2e-tests-configmap-ckx22 deletion completed in 6.18838719s

• [SLOW TEST:8.400 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:24:15.836: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  9 21:24:15.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 version'
Dec  9 21:24:16.011: INFO: stderr: ""
Dec  9 21:24:16.011: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T20:56:12Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:24:16.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ks88k" for this suite.
Dec  9 21:24:22.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:24:22.050: INFO: namespace: e2e-tests-kubectl-ks88k, resource: bindings, ignored listing per whitelist
Dec  9 21:24:22.187: INFO: namespace e2e-tests-kubectl-ks88k deletion completed in 6.170177592s

• [SLOW TEST:6.351 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:24:22.187: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-n92vt
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  9 21:24:22.285: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  9 21:24:36.367: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.3.52:8080/dial?request=hostName&protocol=http&host=10.244.3.51&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-n92vt PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  9 21:24:36.367: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
Dec  9 21:24:36.503: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:24:36.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-n92vt" for this suite.
Dec  9 21:24:58.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:24:58.647: INFO: namespace: e2e-tests-pod-network-test-n92vt, resource: bindings, ignored listing per whitelist
Dec  9 21:24:58.681: INFO: namespace e2e-tests-pod-network-test-n92vt deletion completed in 22.171334635s

• [SLOW TEST:36.494 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:24:58.681: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Dec  9 21:25:00.914: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:25:24.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-n8spt" for this suite.
Dec  9 21:25:31.019: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:25:31.075: INFO: namespace: e2e-tests-namespaces-n8spt, resource: bindings, ignored listing per whitelist
Dec  9 21:25:31.167: INFO: namespace e2e-tests-namespaces-n8spt deletion completed in 6.170047532s
STEP: Destroying namespace "e2e-tests-nsdeletetest-8jd4l" for this suite.
Dec  9 21:25:31.171: INFO: Namespace e2e-tests-nsdeletetest-8jd4l was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-wppvw" for this suite.
Dec  9 21:25:37.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:25:37.239: INFO: namespace: e2e-tests-nsdeletetest-wppvw, resource: bindings, ignored listing per whitelist
Dec  9 21:25:37.349: INFO: namespace e2e-tests-nsdeletetest-wppvw deletion completed in 6.178604546s

• [SLOW TEST:38.668 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:25:37.350: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Dec  9 21:25:37.817: INFO: Pod name wrapped-volume-race-f8b684d5-fbf8-11e8-8725-0a580af4034b: Found 0 pods out of 5
Dec  9 21:25:42.824: INFO: Pod name wrapped-volume-race-f8b684d5-fbf8-11e8-8725-0a580af4034b: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-f8b684d5-fbf8-11e8-8725-0a580af4034b in namespace e2e-tests-emptydir-wrapper-4k52c, will wait for the garbage collector to delete the pods
Dec  9 21:25:52.934: INFO: Deleting ReplicationController wrapped-volume-race-f8b684d5-fbf8-11e8-8725-0a580af4034b took: 17.535706ms
Dec  9 21:25:53.035: INFO: Terminating ReplicationController wrapped-volume-race-f8b684d5-fbf8-11e8-8725-0a580af4034b pods took: 100.531811ms
STEP: Creating RC which spawns configmap-volume pods
Dec  9 21:26:28.774: INFO: Pod name wrapped-volume-race-1713282b-fbf9-11e8-8725-0a580af4034b: Found 0 pods out of 5
Dec  9 21:26:33.783: INFO: Pod name wrapped-volume-race-1713282b-fbf9-11e8-8725-0a580af4034b: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-1713282b-fbf9-11e8-8725-0a580af4034b in namespace e2e-tests-emptydir-wrapper-4k52c, will wait for the garbage collector to delete the pods
Dec  9 21:26:45.876: INFO: Deleting ReplicationController wrapped-volume-race-1713282b-fbf9-11e8-8725-0a580af4034b took: 10.743313ms
Dec  9 21:26:45.977: INFO: Terminating ReplicationController wrapped-volume-race-1713282b-fbf9-11e8-8725-0a580af4034b pods took: 100.333935ms
STEP: Creating RC which spawns configmap-volume pods
Dec  9 21:27:31.210: INFO: Pod name wrapped-volume-race-3c4b02cb-fbf9-11e8-8725-0a580af4034b: Found 0 pods out of 5
Dec  9 21:27:36.218: INFO: Pod name wrapped-volume-race-3c4b02cb-fbf9-11e8-8725-0a580af4034b: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-3c4b02cb-fbf9-11e8-8725-0a580af4034b in namespace e2e-tests-emptydir-wrapper-4k52c, will wait for the garbage collector to delete the pods
Dec  9 21:27:46.328: INFO: Deleting ReplicationController wrapped-volume-race-3c4b02cb-fbf9-11e8-8725-0a580af4034b took: 13.332154ms
Dec  9 21:27:46.428: INFO: Terminating ReplicationController wrapped-volume-race-3c4b02cb-fbf9-11e8-8725-0a580af4034b pods took: 100.415918ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:28:32.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-4k52c" for this suite.
Dec  9 21:28:40.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:28:40.557: INFO: namespace: e2e-tests-emptydir-wrapper-4k52c, resource: bindings, ignored listing per whitelist
Dec  9 21:28:40.567: INFO: namespace e2e-tests-emptydir-wrapper-4k52c deletion completed in 8.168078103s

• [SLOW TEST:183.217 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:28:40.567: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec  9 21:28:40.689: INFO: Waiting up to 5m0s for pod "pod-65b803b5-fbf9-11e8-8725-0a580af4034b" in namespace "e2e-tests-emptydir-jdr86" to be "success or failure"
Dec  9 21:28:40.695: INFO: Pod "pod-65b803b5-fbf9-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.498614ms
Dec  9 21:28:42.707: INFO: Pod "pod-65b803b5-fbf9-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017608752s
STEP: Saw pod success
Dec  9 21:28:42.707: INFO: Pod "pod-65b803b5-fbf9-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 21:28:42.711: INFO: Trying to get logs from node k8s04 pod pod-65b803b5-fbf9-11e8-8725-0a580af4034b container test-container: <nil>
STEP: delete the pod
Dec  9 21:28:42.745: INFO: Waiting for pod pod-65b803b5-fbf9-11e8-8725-0a580af4034b to disappear
Dec  9 21:28:42.758: INFO: Pod pod-65b803b5-fbf9-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:28:42.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jdr86" for this suite.
Dec  9 21:28:48.788: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:28:48.878: INFO: namespace: e2e-tests-emptydir-jdr86, resource: bindings, ignored listing per whitelist
Dec  9 21:28:48.947: INFO: namespace e2e-tests-emptydir-jdr86 deletion completed in 6.180419989s

• [SLOW TEST:8.380 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:28:48.948: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Dec  9 21:28:49.563: INFO: Waiting up to 5m0s for pod "pod-service-account-6b01a360-fbf9-11e8-8725-0a580af4034b-vfkvp" in namespace "e2e-tests-svcaccounts-2khrt" to be "success or failure"
Dec  9 21:28:49.571: INFO: Pod "pod-service-account-6b01a360-fbf9-11e8-8725-0a580af4034b-vfkvp": Phase="Pending", Reason="", readiness=false. Elapsed: 7.427093ms
Dec  9 21:28:51.576: INFO: Pod "pod-service-account-6b01a360-fbf9-11e8-8725-0a580af4034b-vfkvp": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012370453s
Dec  9 21:28:53.588: INFO: Pod "pod-service-account-6b01a360-fbf9-11e8-8725-0a580af4034b-vfkvp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024827616s
STEP: Saw pod success
Dec  9 21:28:53.588: INFO: Pod "pod-service-account-6b01a360-fbf9-11e8-8725-0a580af4034b-vfkvp" satisfied condition "success or failure"
Dec  9 21:28:53.594: INFO: Trying to get logs from node k8s04 pod pod-service-account-6b01a360-fbf9-11e8-8725-0a580af4034b-vfkvp container token-test: <nil>
STEP: delete the pod
Dec  9 21:28:53.627: INFO: Waiting for pod pod-service-account-6b01a360-fbf9-11e8-8725-0a580af4034b-vfkvp to disappear
Dec  9 21:28:53.633: INFO: Pod pod-service-account-6b01a360-fbf9-11e8-8725-0a580af4034b-vfkvp no longer exists
STEP: Creating a pod to test consume service account root CA
Dec  9 21:28:53.642: INFO: Waiting up to 5m0s for pod "pod-service-account-6b01a360-fbf9-11e8-8725-0a580af4034b-26c5l" in namespace "e2e-tests-svcaccounts-2khrt" to be "success or failure"
Dec  9 21:28:53.652: INFO: Pod "pod-service-account-6b01a360-fbf9-11e8-8725-0a580af4034b-26c5l": Phase="Pending", Reason="", readiness=false. Elapsed: 9.841594ms
Dec  9 21:28:55.657: INFO: Pod "pod-service-account-6b01a360-fbf9-11e8-8725-0a580af4034b-26c5l": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014851914s
Dec  9 21:28:57.662: INFO: Pod "pod-service-account-6b01a360-fbf9-11e8-8725-0a580af4034b-26c5l": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019963342s
STEP: Saw pod success
Dec  9 21:28:57.663: INFO: Pod "pod-service-account-6b01a360-fbf9-11e8-8725-0a580af4034b-26c5l" satisfied condition "success or failure"
Dec  9 21:28:57.667: INFO: Trying to get logs from node k8s04 pod pod-service-account-6b01a360-fbf9-11e8-8725-0a580af4034b-26c5l container root-ca-test: <nil>
STEP: delete the pod
Dec  9 21:28:57.701: INFO: Waiting for pod pod-service-account-6b01a360-fbf9-11e8-8725-0a580af4034b-26c5l to disappear
Dec  9 21:28:57.707: INFO: Pod pod-service-account-6b01a360-fbf9-11e8-8725-0a580af4034b-26c5l no longer exists
STEP: Creating a pod to test consume service account namespace
Dec  9 21:28:57.720: INFO: Waiting up to 5m0s for pod "pod-service-account-6b01a360-fbf9-11e8-8725-0a580af4034b-2xvxj" in namespace "e2e-tests-svcaccounts-2khrt" to be "success or failure"
Dec  9 21:28:57.729: INFO: Pod "pod-service-account-6b01a360-fbf9-11e8-8725-0a580af4034b-2xvxj": Phase="Pending", Reason="", readiness=false. Elapsed: 8.607958ms
Dec  9 21:28:59.733: INFO: Pod "pod-service-account-6b01a360-fbf9-11e8-8725-0a580af4034b-2xvxj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013119605s
Dec  9 21:29:01.738: INFO: Pod "pod-service-account-6b01a360-fbf9-11e8-8725-0a580af4034b-2xvxj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017873251s
STEP: Saw pod success
Dec  9 21:29:01.738: INFO: Pod "pod-service-account-6b01a360-fbf9-11e8-8725-0a580af4034b-2xvxj" satisfied condition "success or failure"
Dec  9 21:29:01.742: INFO: Trying to get logs from node k8s04 pod pod-service-account-6b01a360-fbf9-11e8-8725-0a580af4034b-2xvxj container namespace-test: <nil>
STEP: delete the pod
Dec  9 21:29:01.778: INFO: Waiting for pod pod-service-account-6b01a360-fbf9-11e8-8725-0a580af4034b-2xvxj to disappear
Dec  9 21:29:01.782: INFO: Pod pod-service-account-6b01a360-fbf9-11e8-8725-0a580af4034b-2xvxj no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:29:01.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-2khrt" for this suite.
Dec  9 21:29:07.813: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:29:07.827: INFO: namespace: e2e-tests-svcaccounts-2khrt, resource: bindings, ignored listing per whitelist
Dec  9 21:29:07.969: INFO: namespace e2e-tests-svcaccounts-2khrt deletion completed in 6.17885013s

• [SLOW TEST:19.021 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:29:07.969: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Dec  9 21:29:08.092: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-5h7c2,SelfLink:/api/v1/namespaces/e2e-tests-watch-5h7c2/configmaps/e2e-watch-test-configmap-a,UID:760d4876-fbf9-11e8-925a-000c296b480b,ResourceVersion:52861,Generation:0,CreationTimestamp:2018-12-09 21:29:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  9 21:29:08.092: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-5h7c2,SelfLink:/api/v1/namespaces/e2e-tests-watch-5h7c2/configmaps/e2e-watch-test-configmap-a,UID:760d4876-fbf9-11e8-925a-000c296b480b,ResourceVersion:52861,Generation:0,CreationTimestamp:2018-12-09 21:29:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Dec  9 21:29:18.116: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-5h7c2,SelfLink:/api/v1/namespaces/e2e-tests-watch-5h7c2/configmaps/e2e-watch-test-configmap-a,UID:760d4876-fbf9-11e8-925a-000c296b480b,ResourceVersion:52879,Generation:0,CreationTimestamp:2018-12-09 21:29:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec  9 21:29:18.117: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-5h7c2,SelfLink:/api/v1/namespaces/e2e-tests-watch-5h7c2/configmaps/e2e-watch-test-configmap-a,UID:760d4876-fbf9-11e8-925a-000c296b480b,ResourceVersion:52879,Generation:0,CreationTimestamp:2018-12-09 21:29:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Dec  9 21:29:28.140: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-5h7c2,SelfLink:/api/v1/namespaces/e2e-tests-watch-5h7c2/configmaps/e2e-watch-test-configmap-a,UID:760d4876-fbf9-11e8-925a-000c296b480b,ResourceVersion:52897,Generation:0,CreationTimestamp:2018-12-09 21:29:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  9 21:29:28.140: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-5h7c2,SelfLink:/api/v1/namespaces/e2e-tests-watch-5h7c2/configmaps/e2e-watch-test-configmap-a,UID:760d4876-fbf9-11e8-925a-000c296b480b,ResourceVersion:52897,Generation:0,CreationTimestamp:2018-12-09 21:29:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Dec  9 21:29:38.164: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-5h7c2,SelfLink:/api/v1/namespaces/e2e-tests-watch-5h7c2/configmaps/e2e-watch-test-configmap-a,UID:760d4876-fbf9-11e8-925a-000c296b480b,ResourceVersion:52915,Generation:0,CreationTimestamp:2018-12-09 21:29:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  9 21:29:38.164: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-5h7c2,SelfLink:/api/v1/namespaces/e2e-tests-watch-5h7c2/configmaps/e2e-watch-test-configmap-a,UID:760d4876-fbf9-11e8-925a-000c296b480b,ResourceVersion:52915,Generation:0,CreationTimestamp:2018-12-09 21:29:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Dec  9 21:29:48.188: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-5h7c2,SelfLink:/api/v1/namespaces/e2e-tests-watch-5h7c2/configmaps/e2e-watch-test-configmap-b,UID:8df38a11-fbf9-11e8-925a-000c296b480b,ResourceVersion:52933,Generation:0,CreationTimestamp:2018-12-09 21:29:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  9 21:29:48.188: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-5h7c2,SelfLink:/api/v1/namespaces/e2e-tests-watch-5h7c2/configmaps/e2e-watch-test-configmap-b,UID:8df38a11-fbf9-11e8-925a-000c296b480b,ResourceVersion:52933,Generation:0,CreationTimestamp:2018-12-09 21:29:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Dec  9 21:29:58.215: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-5h7c2,SelfLink:/api/v1/namespaces/e2e-tests-watch-5h7c2/configmaps/e2e-watch-test-configmap-b,UID:8df38a11-fbf9-11e8-925a-000c296b480b,ResourceVersion:52951,Generation:0,CreationTimestamp:2018-12-09 21:29:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  9 21:29:58.215: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-5h7c2,SelfLink:/api/v1/namespaces/e2e-tests-watch-5h7c2/configmaps/e2e-watch-test-configmap-b,UID:8df38a11-fbf9-11e8-925a-000c296b480b,ResourceVersion:52951,Generation:0,CreationTimestamp:2018-12-09 21:29:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:30:08.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-5h7c2" for this suite.
Dec  9 21:30:14.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:30:14.382: INFO: namespace: e2e-tests-watch-5h7c2, resource: bindings, ignored listing per whitelist
Dec  9 21:30:14.406: INFO: namespace e2e-tests-watch-5h7c2 deletion completed in 6.175304356s

• [SLOW TEST:66.438 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:30:14.407: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-jrsr4
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-jrsr4
STEP: Deleting pre-stop pod
Dec  9 21:30:23.636: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:30:23.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-jrsr4" for this suite.
Dec  9 21:31:01.682: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:31:01.789: INFO: namespace: e2e-tests-prestop-jrsr4, resource: bindings, ignored listing per whitelist
Dec  9 21:31:01.844: INFO: namespace e2e-tests-prestop-jrsr4 deletion completed in 38.187852892s

• [SLOW TEST:47.437 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:31:01.844: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Dec  9 21:31:03.983: INFO: Pod pod-hostip-b9eb764d-fbf9-11e8-8725-0a580af4034b has hostIP: 192.168.9.14
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:31:03.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-74nwn" for this suite.
Dec  9 21:31:26.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:31:26.137: INFO: namespace: e2e-tests-pods-74nwn, resource: bindings, ignored listing per whitelist
Dec  9 21:31:26.160: INFO: namespace e2e-tests-pods-74nwn deletion completed in 22.169976374s

• [SLOW TEST:24.317 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:31:26.161: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  9 21:31:26.286: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c86b7669-fbf9-11e8-8725-0a580af4034b" in namespace "e2e-tests-downward-api-g2ll8" to be "success or failure"
Dec  9 21:31:26.293: INFO: Pod "downwardapi-volume-c86b7669-fbf9-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.65184ms
Dec  9 21:31:28.298: INFO: Pod "downwardapi-volume-c86b7669-fbf9-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012041117s
STEP: Saw pod success
Dec  9 21:31:28.298: INFO: Pod "downwardapi-volume-c86b7669-fbf9-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 21:31:28.304: INFO: Trying to get logs from node k8s04 pod downwardapi-volume-c86b7669-fbf9-11e8-8725-0a580af4034b container client-container: <nil>
STEP: delete the pod
Dec  9 21:31:28.338: INFO: Waiting for pod downwardapi-volume-c86b7669-fbf9-11e8-8725-0a580af4034b to disappear
Dec  9 21:31:28.345: INFO: Pod downwardapi-volume-c86b7669-fbf9-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:31:28.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-g2ll8" for this suite.
Dec  9 21:31:34.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:31:34.502: INFO: namespace: e2e-tests-downward-api-g2ll8, resource: bindings, ignored listing per whitelist
Dec  9 21:31:34.528: INFO: namespace e2e-tests-downward-api-g2ll8 deletion completed in 6.173877773s

• [SLOW TEST:8.367 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:31:34.528: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-jgnlf
Dec  9 21:31:36.665: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-jgnlf
STEP: checking the pod's current state and verifying that restartCount is present
Dec  9 21:31:36.670: INFO: Initial restart count of pod liveness-exec is 0
Dec  9 21:32:30.845: INFO: Restart count of pod e2e-tests-container-probe-jgnlf/liveness-exec is now 1 (54.174456604s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:32:30.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-jgnlf" for this suite.
Dec  9 21:32:36.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:32:36.940: INFO: namespace: e2e-tests-container-probe-jgnlf, resource: bindings, ignored listing per whitelist
Dec  9 21:32:37.056: INFO: namespace e2e-tests-container-probe-jgnlf deletion completed in 6.187128231s

• [SLOW TEST:62.528 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:32:37.056: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  9 21:32:37.153: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:32:39.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-6gvlj" for this suite.
Dec  9 21:33:23.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:33:23.390: INFO: namespace: e2e-tests-pods-6gvlj, resource: bindings, ignored listing per whitelist
Dec  9 21:33:23.423: INFO: namespace e2e-tests-pods-6gvlj deletion completed in 44.211524406s

• [SLOW TEST:46.367 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:33:23.423: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  9 21:33:23.539: INFO: Pod name rollover-pod: Found 0 pods out of 1
Dec  9 21:33:28.544: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  9 21:33:28.544: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Dec  9 21:33:30.550: INFO: Creating deployment "test-rollover-deployment"
Dec  9 21:33:30.567: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Dec  9 21:33:32.580: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Dec  9 21:33:32.591: INFO: Ensure that both replica sets have 1 created replica
Dec  9 21:33:32.605: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Dec  9 21:33:32.624: INFO: Updating deployment test-rollover-deployment
Dec  9 21:33:32.624: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Dec  9 21:33:34.643: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Dec  9 21:33:34.656: INFO: Make sure deployment "test-rollover-deployment" is complete
Dec  9 21:33:34.670: INFO: all replica sets need to contain the pod-template-hash label
Dec  9 21:33:34.670: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679988010, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679988010, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679988014, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679988010, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  9 21:33:36.684: INFO: all replica sets need to contain the pod-template-hash label
Dec  9 21:33:36.684: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679988010, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679988010, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679988014, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679988010, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  9 21:33:38.682: INFO: all replica sets need to contain the pod-template-hash label
Dec  9 21:33:38.682: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679988010, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679988010, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679988014, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679988010, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  9 21:33:40.681: INFO: all replica sets need to contain the pod-template-hash label
Dec  9 21:33:40.681: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679988010, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679988010, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679988014, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679988010, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  9 21:33:42.682: INFO: all replica sets need to contain the pod-template-hash label
Dec  9 21:33:42.683: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679988010, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679988010, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679988014, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679988010, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  9 21:33:44.686: INFO: 
Dec  9 21:33:44.686: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  9 21:33:44.704: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-c274w,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-c274w/deployments/test-rollover-deployment,UID:127f2629-fbfa-11e8-925a-000c296b480b,ResourceVersion:53561,Generation:2,CreationTimestamp:2018-12-09 21:33:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-12-09 21:33:30 +0000 UTC 2018-12-09 21:33:30 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-12-09 21:33:44 +0000 UTC 2018-12-09 21:33:30 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec  9 21:33:44.709: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-c274w,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-c274w/replicasets/test-rollover-deployment-6b7f9d6597,UID:13bb6d10-fbfa-11e8-925a-000c296b480b,ResourceVersion:53552,Generation:2,CreationTimestamp:2018-12-09 21:33:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 127f2629-fbfa-11e8-925a-000c296b480b 0xc001976107 0xc001976108}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec  9 21:33:44.709: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Dec  9 21:33:44.709: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-c274w,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-c274w/replicasets/test-rollover-controller,UID:0e4f341c-fbfa-11e8-925a-000c296b480b,ResourceVersion:53560,Generation:2,CreationTimestamp:2018-12-09 21:33:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 127f2629-fbfa-11e8-925a-000c296b480b 0xc001dafe47 0xc001dafe48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  9 21:33:44.710: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-c274w,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-c274w/replicasets/test-rollover-deployment-6586df867b,UID:128574b4-fbfa-11e8-925a-000c296b480b,ResourceVersion:53520,Generation:2,CreationTimestamp:2018-12-09 21:33:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 127f2629-fbfa-11e8-925a-000c296b480b 0xc001daff07 0xc001daff08}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  9 21:33:44.716: INFO: Pod "test-rollover-deployment-6b7f9d6597-8rwgj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-8rwgj,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-c274w,SelfLink:/api/v1/namespaces/e2e-tests-deployment-c274w/pods/test-rollover-deployment-6b7f9d6597-8rwgj,UID:13c2510d-fbfa-11e8-925a-000c296b480b,ResourceVersion:53532,Generation:0,CreationTimestamp:2018-12-09 21:33:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 13bb6d10-fbfa-11e8-925a-000c296b480b 0xc001f3faf7 0xc001f3faf8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rszs5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rszs5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-rszs5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s04,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f3fb70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f3fb90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:33:32 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:33:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:33:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:33:32 +0000 UTC  }],Message:,Reason:,HostIP:192.168.9.14,PodIP:10.244.3.84,StartTime:2018-12-09 21:33:32 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-12-09 21:33:33 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://9c38d2749d4c155a946696f535abedcb354ceddc0fc2e370329d9decb75117cb}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:33:44.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-c274w" for this suite.
Dec  9 21:33:50.742: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:33:50.809: INFO: namespace: e2e-tests-deployment-c274w, resource: bindings, ignored listing per whitelist
Dec  9 21:33:50.897: INFO: namespace e2e-tests-deployment-c274w deletion completed in 6.173993795s

• [SLOW TEST:27.473 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:33:50.897: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Dec  9 21:33:50.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 create -f - --namespace=e2e-tests-kubectl-g59gl'
Dec  9 21:33:51.346: INFO: stderr: ""
Dec  9 21:33:51.346: INFO: stdout: "pod/pause created\n"
Dec  9 21:33:51.346: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Dec  9 21:33:51.346: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-g59gl" to be "running and ready"
Dec  9 21:33:51.356: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 10.257788ms
Dec  9 21:33:53.361: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.014448169s
Dec  9 21:33:53.361: INFO: Pod "pause" satisfied condition "running and ready"
Dec  9 21:33:53.361: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Dec  9 21:33:53.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-g59gl'
Dec  9 21:33:53.457: INFO: stderr: ""
Dec  9 21:33:53.457: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Dec  9 21:33:53.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pod pause -L testing-label --namespace=e2e-tests-kubectl-g59gl'
Dec  9 21:33:53.546: INFO: stderr: ""
Dec  9 21:33:53.546: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Dec  9 21:33:53.546: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 label pods pause testing-label- --namespace=e2e-tests-kubectl-g59gl'
Dec  9 21:33:53.633: INFO: stderr: ""
Dec  9 21:33:53.633: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Dec  9 21:33:53.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pod pause -L testing-label --namespace=e2e-tests-kubectl-g59gl'
Dec  9 21:33:53.709: INFO: stderr: ""
Dec  9 21:33:53.709: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Dec  9 21:33:53.709: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-g59gl'
Dec  9 21:33:53.800: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  9 21:33:53.800: INFO: stdout: "pod \"pause\" force deleted\n"
Dec  9 21:33:53.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-g59gl'
Dec  9 21:33:53.904: INFO: stderr: "No resources found.\n"
Dec  9 21:33:53.904: INFO: stdout: ""
Dec  9 21:33:53.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pods -l name=pause --namespace=e2e-tests-kubectl-g59gl -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  9 21:33:54.001: INFO: stderr: ""
Dec  9 21:33:54.001: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:33:54.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-g59gl" for this suite.
Dec  9 21:34:00.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:34:00.053: INFO: namespace: e2e-tests-kubectl-g59gl, resource: bindings, ignored listing per whitelist
Dec  9 21:34:00.187: INFO: namespace e2e-tests-kubectl-g59gl deletion completed in 6.179843528s

• [SLOW TEST:9.290 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:34:00.187: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:34:00.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-txtml" for this suite.
Dec  9 21:34:22.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:34:22.441: INFO: namespace: e2e-tests-pods-txtml, resource: bindings, ignored listing per whitelist
Dec  9 21:34:22.501: INFO: namespace e2e-tests-pods-txtml deletion completed in 22.188975063s

• [SLOW TEST:22.315 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:34:22.501: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  9 21:34:22.597: INFO: Creating deployment "nginx-deployment"
Dec  9 21:34:22.607: INFO: Waiting for observed generation 1
Dec  9 21:34:24.624: INFO: Waiting for all required pods to come up
Dec  9 21:34:24.630: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Dec  9 21:34:30.653: INFO: Waiting for deployment "nginx-deployment" to complete
Dec  9 21:34:30.668: INFO: Updating deployment "nginx-deployment" with a non-existent image
Dec  9 21:34:30.690: INFO: Updating deployment nginx-deployment
Dec  9 21:34:30.690: INFO: Waiting for observed generation 2
Dec  9 21:34:32.709: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Dec  9 21:34:32.716: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Dec  9 21:34:32.725: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Dec  9 21:34:32.753: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Dec  9 21:34:32.753: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Dec  9 21:34:32.760: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Dec  9 21:34:32.774: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Dec  9 21:34:32.774: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Dec  9 21:34:32.794: INFO: Updating deployment nginx-deployment
Dec  9 21:34:32.794: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Dec  9 21:34:32.806: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Dec  9 21:34:34.827: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  9 21:34:34.838: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-gq7kc,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-gq7kc/deployments/nginx-deployment,UID:3184efcd-fbfa-11e8-925a-000c296b480b,ResourceVersion:53975,Generation:3,CreationTimestamp:2018-12-09 21:34:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2018-12-09 21:34:32 +0000 UTC 2018-12-09 21:34:32 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2018-12-09 21:34:32 +0000 UTC 2018-12-09 21:34:22 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Dec  9 21:34:34.845: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-gq7kc,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-gq7kc/replicasets/nginx-deployment-65bbdb5f8,UID:3657aeab-fbfa-11e8-925a-000c296b480b,ResourceVersion:53971,Generation:3,CreationTimestamp:2018-12-09 21:34:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 3184efcd-fbfa-11e8-925a-000c296b480b 0xc001538b17 0xc001538b18}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  9 21:34:34.845: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Dec  9 21:34:34.845: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-gq7kc,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-gq7kc/replicasets/nginx-deployment-555b55d965,UID:31887598-fbfa-11e8-925a-000c296b480b,ResourceVersion:53969,Generation:3,CreationTimestamp:2018-12-09 21:34:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 3184efcd-fbfa-11e8-925a-000c296b480b 0xc0015388d7 0xc0015388d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Dec  9 21:34:34.854: INFO: Pod "nginx-deployment-555b55d965-54fts" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-54fts,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-gq7kc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gq7kc/pods/nginx-deployment-555b55d965-54fts,UID:37a6864b-fbfa-11e8-925a-000c296b480b,ResourceVersion:53941,Generation:0,CreationTimestamp:2018-12-09 21:34:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 31887598-fbfa-11e8-925a-000c296b480b 0xc001316167 0xc001316168}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2q8vs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2q8vs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-2q8vs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s04,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001316330} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001316350}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  9 21:34:34.854: INFO: Pod "nginx-deployment-555b55d965-6jdwn" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-6jdwn,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-gq7kc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gq7kc/pods/nginx-deployment-555b55d965-6jdwn,UID:31902d38-fbfa-11e8-925a-000c296b480b,ResourceVersion:53842,Generation:0,CreationTimestamp:2018-12-09 21:34:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 31887598-fbfa-11e8-925a-000c296b480b 0xc0013163c0 0xc0013163c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2q8vs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2q8vs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-2q8vs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s04,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0013165d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0013165f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:22 +0000 UTC  }],Message:,Reason:,HostIP:192.168.9.14,PodIP:10.244.3.93,StartTime:2018-12-09 21:34:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-09 21:34:26 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://6023680723e67c75b73c851f0fd0da51fa9b9d11b369c4577fa649a84440357c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  9 21:34:34.854: INFO: Pod "nginx-deployment-555b55d965-6jvjf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-6jvjf,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-gq7kc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gq7kc/pods/nginx-deployment-555b55d965-6jvjf,UID:37a9c714-fbfa-11e8-925a-000c296b480b,ResourceVersion:53959,Generation:0,CreationTimestamp:2018-12-09 21:34:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 31887598-fbfa-11e8-925a-000c296b480b 0xc0013166b0 0xc0013166b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2q8vs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2q8vs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-2q8vs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s04,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0013167a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0013167c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  9 21:34:34.855: INFO: Pod "nginx-deployment-555b55d965-78pwc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-78pwc,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-gq7kc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gq7kc/pods/nginx-deployment-555b55d965-78pwc,UID:37a0d72a-fbfa-11e8-925a-000c296b480b,ResourceVersion:53998,Generation:0,CreationTimestamp:2018-12-09 21:34:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 31887598-fbfa-11e8-925a-000c296b480b 0xc001316840 0xc001316841}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2q8vs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2q8vs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-2q8vs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s04,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0013168e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001316ae0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC  }],Message:,Reason:,HostIP:192.168.9.14,PodIP:,StartTime:2018-12-09 21:34:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  9 21:34:34.855: INFO: Pod "nginx-deployment-555b55d965-8lk5q" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-8lk5q,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-gq7kc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gq7kc/pods/nginx-deployment-555b55d965-8lk5q,UID:37a4a292-fbfa-11e8-925a-000c296b480b,ResourceVersion:54007,Generation:0,CreationTimestamp:2018-12-09 21:34:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 31887598-fbfa-11e8-925a-000c296b480b 0xc001316d77 0xc001316d78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2q8vs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2q8vs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-2q8vs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s04,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001316df0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001316e10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC  }],Message:,Reason:,HostIP:192.168.9.14,PodIP:,StartTime:2018-12-09 21:34:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  9 21:34:34.855: INFO: Pod "nginx-deployment-555b55d965-bwzh6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-bwzh6,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-gq7kc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gq7kc/pods/nginx-deployment-555b55d965-bwzh6,UID:318f9fee-fbfa-11e8-925a-000c296b480b,ResourceVersion:53813,Generation:0,CreationTimestamp:2018-12-09 21:34:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 31887598-fbfa-11e8-925a-000c296b480b 0xc0013175e7 0xc0013175e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2q8vs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2q8vs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-2q8vs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s04,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001317690} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0013176b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:26 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:26 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:22 +0000 UTC  }],Message:,Reason:,HostIP:192.168.9.14,PodIP:10.244.3.90,StartTime:2018-12-09 21:34:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-09 21:34:26 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://18c74f2915bf9065c141e23d6d3d1669003bf11f7efefc815d606cca6cc214d7}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  9 21:34:34.855: INFO: Pod "nginx-deployment-555b55d965-c5lhf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-c5lhf,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-gq7kc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gq7kc/pods/nginx-deployment-555b55d965-c5lhf,UID:379e2fac-fbfa-11e8-925a-000c296b480b,ResourceVersion:53933,Generation:0,CreationTimestamp:2018-12-09 21:34:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 31887598-fbfa-11e8-925a-000c296b480b 0xc001317b20 0xc001317b21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2q8vs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2q8vs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-2q8vs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s04,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001317cf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001317d40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC  }],Message:,Reason:,HostIP:192.168.9.14,PodIP:,StartTime:2018-12-09 21:34:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  9 21:34:34.855: INFO: Pod "nginx-deployment-555b55d965-dc7jb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-dc7jb,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-gq7kc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gq7kc/pods/nginx-deployment-555b55d965-dc7jb,UID:37a9adea-fbfa-11e8-925a-000c296b480b,ResourceVersion:53960,Generation:0,CreationTimestamp:2018-12-09 21:34:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 31887598-fbfa-11e8-925a-000c296b480b 0xc001317e57 0xc001317e58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2q8vs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2q8vs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-2q8vs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s04,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000d5c200} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000d5c220}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  9 21:34:34.856: INFO: Pod "nginx-deployment-555b55d965-hqj6p" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-hqj6p,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-gq7kc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gq7kc/pods/nginx-deployment-555b55d965-hqj6p,UID:37a06e7e-fbfa-11e8-925a-000c296b480b,ResourceVersion:53963,Generation:0,CreationTimestamp:2018-12-09 21:34:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 31887598-fbfa-11e8-925a-000c296b480b 0xc000d5c290 0xc000d5c291}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2q8vs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2q8vs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-2q8vs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s04,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000d5c300} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000d5c320}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC  }],Message:,Reason:,HostIP:192.168.9.14,PodIP:,StartTime:2018-12-09 21:34:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  9 21:34:34.856: INFO: Pod "nginx-deployment-555b55d965-j5nwg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-j5nwg,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-gq7kc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gq7kc/pods/nginx-deployment-555b55d965-j5nwg,UID:3192bc2e-fbfa-11e8-925a-000c296b480b,ResourceVersion:53810,Generation:0,CreationTimestamp:2018-12-09 21:34:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 31887598-fbfa-11e8-925a-000c296b480b 0xc000d5c507 0xc000d5c508}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2q8vs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2q8vs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-2q8vs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s04,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000d5c580} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000d5c5a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:26 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:26 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:22 +0000 UTC  }],Message:,Reason:,HostIP:192.168.9.14,PodIP:10.244.3.95,StartTime:2018-12-09 21:34:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-09 21:34:26 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://9aeb8ed6c1bbf94d368efd01593e9aa0e7937786bab053354ce1c774766024fe}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  9 21:34:34.856: INFO: Pod "nginx-deployment-555b55d965-j5rds" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-j5rds,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-gq7kc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gq7kc/pods/nginx-deployment-555b55d965-j5rds,UID:31932075-fbfa-11e8-925a-000c296b480b,ResourceVersion:53820,Generation:0,CreationTimestamp:2018-12-09 21:34:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 31887598-fbfa-11e8-925a-000c296b480b 0xc000d5c740 0xc000d5c741}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2q8vs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2q8vs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-2q8vs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s04,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000d5c7e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000d5c800}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:22 +0000 UTC  }],Message:,Reason:,HostIP:192.168.9.14,PodIP:10.244.3.92,StartTime:2018-12-09 21:34:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-09 21:34:26 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://09056acd00d4bf03beb7550db43949b8538b3259501d6cfcd770ee9f3dd9a5d8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  9 21:34:34.856: INFO: Pod "nginx-deployment-555b55d965-kmvjb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-kmvjb,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-gq7kc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gq7kc/pods/nginx-deployment-555b55d965-kmvjb,UID:37a6593b-fbfa-11e8-925a-000c296b480b,ResourceVersion:53945,Generation:0,CreationTimestamp:2018-12-09 21:34:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 31887598-fbfa-11e8-925a-000c296b480b 0xc000d5c950 0xc000d5c951}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2q8vs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2q8vs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-2q8vs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s04,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000d5caf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000d5cb10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  9 21:34:34.856: INFO: Pod "nginx-deployment-555b55d965-lgzgb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-lgzgb,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-gq7kc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gq7kc/pods/nginx-deployment-555b55d965-lgzgb,UID:37a93931-fbfa-11e8-925a-000c296b480b,ResourceVersion:53961,Generation:0,CreationTimestamp:2018-12-09 21:34:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 31887598-fbfa-11e8-925a-000c296b480b 0xc000d5cbd0 0xc000d5cbd1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2q8vs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2q8vs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-2q8vs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s04,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000d5cd30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000d5cd50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  9 21:34:34.856: INFO: Pod "nginx-deployment-555b55d965-lv87k" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-lv87k,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-gq7kc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gq7kc/pods/nginx-deployment-555b55d965-lv87k,UID:37a9da30-fbfa-11e8-925a-000c296b480b,ResourceVersion:53956,Generation:0,CreationTimestamp:2018-12-09 21:34:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 31887598-fbfa-11e8-925a-000c296b480b 0xc000d5ce30 0xc000d5ce31}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2q8vs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2q8vs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-2q8vs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s04,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000d5cf10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000d5cfc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  9 21:34:34.857: INFO: Pod "nginx-deployment-555b55d965-n4t8c" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-n4t8c,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-gq7kc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gq7kc/pods/nginx-deployment-555b55d965-n4t8c,UID:318ff9db-fbfa-11e8-925a-000c296b480b,ResourceVersion:53836,Generation:0,CreationTimestamp:2018-12-09 21:34:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 31887598-fbfa-11e8-925a-000c296b480b 0xc000d5d030 0xc000d5d031}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2q8vs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2q8vs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-2q8vs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s04,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000d5d190} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000d5d210}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:22 +0000 UTC  }],Message:,Reason:,HostIP:192.168.9.14,PodIP:10.244.3.97,StartTime:2018-12-09 21:34:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-09 21:34:27 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://d0809b70e601ebcc201f8501d1da629e18b724e4a5c5d46c5f14f4368ac710ee}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  9 21:34:34.857: INFO: Pod "nginx-deployment-555b55d965-trdhh" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-trdhh,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-gq7kc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gq7kc/pods/nginx-deployment-555b55d965-trdhh,UID:318d8dc3-fbfa-11e8-925a-000c296b480b,ResourceVersion:53803,Generation:0,CreationTimestamp:2018-12-09 21:34:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 31887598-fbfa-11e8-925a-000c296b480b 0xc000d5d2d0 0xc000d5d2d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2q8vs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2q8vs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-2q8vs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s04,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000d5d340} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000d5d410}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:26 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:26 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:22 +0000 UTC  }],Message:,Reason:,HostIP:192.168.9.14,PodIP:10.244.3.89,StartTime:2018-12-09 21:34:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-09 21:34:25 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://c7b7338a9dfb84df484d5459c24a915e676fb775af4096610cb25cd2d62b2599}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  9 21:34:34.857: INFO: Pod "nginx-deployment-555b55d965-vxqtd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-vxqtd,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-gq7kc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gq7kc/pods/nginx-deployment-555b55d965-vxqtd,UID:318ca44b-fbfa-11e8-925a-000c296b480b,ResourceVersion:53800,Generation:0,CreationTimestamp:2018-12-09 21:34:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 31887598-fbfa-11e8-925a-000c296b480b 0xc000d5d4d0 0xc000d5d4d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2q8vs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2q8vs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-2q8vs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s04,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000d5d600} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000d5d620}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:26 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:26 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:22 +0000 UTC  }],Message:,Reason:,HostIP:192.168.9.14,PodIP:10.244.3.88,StartTime:2018-12-09 21:34:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-09 21:34:25 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://39a0295f2172fd4955ef2455ed07050884bd7b743fa880eaf47398e102ab55a1}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  9 21:34:34.858: INFO: Pod "nginx-deployment-555b55d965-xlwpv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-xlwpv,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-gq7kc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gq7kc/pods/nginx-deployment-555b55d965-xlwpv,UID:31903e92-fbfa-11e8-925a-000c296b480b,ResourceVersion:53806,Generation:0,CreationTimestamp:2018-12-09 21:34:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 31887598-fbfa-11e8-925a-000c296b480b 0xc000d5d760 0xc000d5d761}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2q8vs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2q8vs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-2q8vs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s04,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000d5d7d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000d5d7f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:26 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:26 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:22 +0000 UTC  }],Message:,Reason:,HostIP:192.168.9.14,PodIP:10.244.3.91,StartTime:2018-12-09 21:34:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-09 21:34:26 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://24218af815cf438c0b2a656e50fc163bc8ee334e3f33dc56b664376adfcfec63}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  9 21:34:34.858: INFO: Pod "nginx-deployment-555b55d965-zbjwm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-zbjwm,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-gq7kc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gq7kc/pods/nginx-deployment-555b55d965-zbjwm,UID:37a9d121-fbfa-11e8-925a-000c296b480b,ResourceVersion:53962,Generation:0,CreationTimestamp:2018-12-09 21:34:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 31887598-fbfa-11e8-925a-000c296b480b 0xc000d5d9f0 0xc000d5d9f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2q8vs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2q8vs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-2q8vs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s04,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000d5da60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000d5da80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  9 21:34:34.859: INFO: Pod "nginx-deployment-555b55d965-zdfpc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-zdfpc,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-gq7kc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gq7kc/pods/nginx-deployment-555b55d965-zdfpc,UID:37a4f99d-fbfa-11e8-925a-000c296b480b,ResourceVersion:54009,Generation:0,CreationTimestamp:2018-12-09 21:34:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 31887598-fbfa-11e8-925a-000c296b480b 0xc000d5daf0 0xc000d5daf1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2q8vs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2q8vs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-2q8vs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s04,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000d5dc40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000d5dc60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC  }],Message:,Reason:,HostIP:192.168.9.14,PodIP:,StartTime:2018-12-09 21:34:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  9 21:34:34.859: INFO: Pod "nginx-deployment-65bbdb5f8-2lvhc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-2lvhc,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-gq7kc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gq7kc/pods/nginx-deployment-65bbdb5f8-2lvhc,UID:366a5126-fbfa-11e8-925a-000c296b480b,ResourceVersion:53896,Generation:0,CreationTimestamp:2018-12-09 21:34:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 3657aeab-fbfa-11e8-925a-000c296b480b 0xc000d5dd17 0xc000d5dd18}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2q8vs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2q8vs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-2q8vs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s04,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000d5dd90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000d5ddb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:30 +0000 UTC  }],Message:,Reason:,HostIP:192.168.9.14,PodIP:,StartTime:2018-12-09 21:34:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  9 21:34:34.859: INFO: Pod "nginx-deployment-65bbdb5f8-4s7sb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-4s7sb,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-gq7kc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gq7kc/pods/nginx-deployment-65bbdb5f8-4s7sb,UID:365c82b5-fbfa-11e8-925a-000c296b480b,ResourceVersion:53885,Generation:0,CreationTimestamp:2018-12-09 21:34:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 3657aeab-fbfa-11e8-925a-000c296b480b 0xc000d5dee0 0xc000d5dee1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2q8vs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2q8vs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-2q8vs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s04,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000d5df90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000d5dfb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:30 +0000 UTC  }],Message:,Reason:,HostIP:192.168.9.14,PodIP:,StartTime:2018-12-09 21:34:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  9 21:34:34.859: INFO: Pod "nginx-deployment-65bbdb5f8-6jgc7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-6jgc7,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-gq7kc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gq7kc/pods/nginx-deployment-65bbdb5f8-6jgc7,UID:37a4d590-fbfa-11e8-925a-000c296b480b,ResourceVersion:54011,Generation:0,CreationTimestamp:2018-12-09 21:34:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 3657aeab-fbfa-11e8-925a-000c296b480b 0xc0014ae2a0 0xc0014ae2a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2q8vs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2q8vs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-2q8vs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s04,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0014ae320} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0014ae380}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC  }],Message:,Reason:,HostIP:192.168.9.14,PodIP:,StartTime:2018-12-09 21:34:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  9 21:34:34.859: INFO: Pod "nginx-deployment-65bbdb5f8-6vlxj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-6vlxj,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-gq7kc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gq7kc/pods/nginx-deployment-65bbdb5f8-6vlxj,UID:37a80447-fbfa-11e8-925a-000c296b480b,ResourceVersion:53952,Generation:0,CreationTimestamp:2018-12-09 21:34:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 3657aeab-fbfa-11e8-925a-000c296b480b 0xc0014ae8c0 0xc0014ae8c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2q8vs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2q8vs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-2q8vs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s04,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0014ae940} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0014ae960}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  9 21:34:34.859: INFO: Pod "nginx-deployment-65bbdb5f8-gr5rw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-gr5rw,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-gq7kc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gq7kc/pods/nginx-deployment-65bbdb5f8-gr5rw,UID:37a1a549-fbfa-11e8-925a-000c296b480b,ResourceVersion:53977,Generation:0,CreationTimestamp:2018-12-09 21:34:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 3657aeab-fbfa-11e8-925a-000c296b480b 0xc0014aea80 0xc0014aea81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2q8vs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2q8vs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-2q8vs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s04,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0014aeb10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0014af010}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC  }],Message:,Reason:,HostIP:192.168.9.14,PodIP:,StartTime:2018-12-09 21:34:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  9 21:34:34.860: INFO: Pod "nginx-deployment-65bbdb5f8-j6v5k" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-j6v5k,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-gq7kc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gq7kc/pods/nginx-deployment-65bbdb5f8-j6v5k,UID:365a3074-fbfa-11e8-925a-000c296b480b,ResourceVersion:53869,Generation:0,CreationTimestamp:2018-12-09 21:34:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 3657aeab-fbfa-11e8-925a-000c296b480b 0xc0014af280 0xc0014af281}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2q8vs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2q8vs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-2q8vs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s04,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0014af300} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0014af320}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:30 +0000 UTC  }],Message:,Reason:,HostIP:192.168.9.14,PodIP:,StartTime:2018-12-09 21:34:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  9 21:34:34.860: INFO: Pod "nginx-deployment-65bbdb5f8-jhf45" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-jhf45,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-gq7kc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gq7kc/pods/nginx-deployment-65bbdb5f8-jhf45,UID:37a43a5b-fbfa-11e8-925a-000c296b480b,ResourceVersion:53986,Generation:0,CreationTimestamp:2018-12-09 21:34:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 3657aeab-fbfa-11e8-925a-000c296b480b 0xc0014af760 0xc0014af761}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2q8vs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2q8vs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-2q8vs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s04,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0014af7e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0014af800}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC  }],Message:,Reason:,HostIP:192.168.9.14,PodIP:,StartTime:2018-12-09 21:34:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  9 21:34:34.860: INFO: Pod "nginx-deployment-65bbdb5f8-klrtn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-klrtn,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-gq7kc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gq7kc/pods/nginx-deployment-65bbdb5f8-klrtn,UID:365c40e6-fbfa-11e8-925a-000c296b480b,ResourceVersion:53881,Generation:0,CreationTimestamp:2018-12-09 21:34:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 3657aeab-fbfa-11e8-925a-000c296b480b 0xc0014afa40 0xc0014afa41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2q8vs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2q8vs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-2q8vs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s04,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0014afac0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0014afae0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:30 +0000 UTC  }],Message:,Reason:,HostIP:192.168.9.14,PodIP:,StartTime:2018-12-09 21:34:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  9 21:34:34.860: INFO: Pod "nginx-deployment-65bbdb5f8-n2jxp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-n2jxp,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-gq7kc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gq7kc/pods/nginx-deployment-65bbdb5f8-n2jxp,UID:37a823d4-fbfa-11e8-925a-000c296b480b,ResourceVersion:53958,Generation:0,CreationTimestamp:2018-12-09 21:34:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 3657aeab-fbfa-11e8-925a-000c296b480b 0xc0014afbe0 0xc0014afbe1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2q8vs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2q8vs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-2q8vs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s04,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0014afc60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0014afc80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  9 21:34:34.860: INFO: Pod "nginx-deployment-65bbdb5f8-t2f4q" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-t2f4q,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-gq7kc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gq7kc/pods/nginx-deployment-65bbdb5f8-t2f4q,UID:37a85610-fbfa-11e8-925a-000c296b480b,ResourceVersion:53957,Generation:0,CreationTimestamp:2018-12-09 21:34:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 3657aeab-fbfa-11e8-925a-000c296b480b 0xc0014afd20 0xc0014afd21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2q8vs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2q8vs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-2q8vs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s04,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0014afda0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0014afdc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  9 21:34:34.861: INFO: Pod "nginx-deployment-65bbdb5f8-w5hdl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-w5hdl,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-gq7kc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gq7kc/pods/nginx-deployment-65bbdb5f8-w5hdl,UID:366b8684-fbfa-11e8-925a-000c296b480b,ResourceVersion:53902,Generation:0,CreationTimestamp:2018-12-09 21:34:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 3657aeab-fbfa-11e8-925a-000c296b480b 0xc0014afeb0 0xc0014afeb1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2q8vs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2q8vs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-2q8vs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s04,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0014aff30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0014affc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:30 +0000 UTC  }],Message:,Reason:,HostIP:192.168.9.14,PodIP:,StartTime:2018-12-09 21:34:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  9 21:34:34.861: INFO: Pod "nginx-deployment-65bbdb5f8-x86p9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-x86p9,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-gq7kc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gq7kc/pods/nginx-deployment-65bbdb5f8-x86p9,UID:37a87382-fbfa-11e8-925a-000c296b480b,ResourceVersion:53953,Generation:0,CreationTimestamp:2018-12-09 21:34:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 3657aeab-fbfa-11e8-925a-000c296b480b 0xc000f30080 0xc000f30081}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2q8vs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2q8vs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-2q8vs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s04,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000f302f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000f30310}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  9 21:34:34.861: INFO: Pod "nginx-deployment-65bbdb5f8-xvksr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-xvksr,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-gq7kc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gq7kc/pods/nginx-deployment-65bbdb5f8-xvksr,UID:37aaf4b7-fbfa-11e8-925a-000c296b480b,ResourceVersion:53967,Generation:0,CreationTimestamp:2018-12-09 21:34:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 3657aeab-fbfa-11e8-925a-000c296b480b 0xc000f303a0 0xc000f303a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2q8vs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2q8vs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-2q8vs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s04,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000f30430} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000f30450}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-09 21:34:32 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:34:34.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-gq7kc" for this suite.
Dec  9 21:34:42.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:34:42.931: INFO: namespace: e2e-tests-deployment-gq7kc, resource: bindings, ignored listing per whitelist
Dec  9 21:34:43.081: INFO: namespace e2e-tests-deployment-gq7kc deletion completed in 8.209767755s

• [SLOW TEST:20.580 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:34:43.081: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec  9 21:34:43.205: INFO: Waiting up to 5m0s for pod "pod-3dcba2f5-fbfa-11e8-8725-0a580af4034b" in namespace "e2e-tests-emptydir-rsft6" to be "success or failure"
Dec  9 21:34:43.212: INFO: Pod "pod-3dcba2f5-fbfa-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.153566ms
Dec  9 21:34:45.217: INFO: Pod "pod-3dcba2f5-fbfa-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011459823s
Dec  9 21:34:47.221: INFO: Pod "pod-3dcba2f5-fbfa-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015342158s
Dec  9 21:34:49.233: INFO: Pod "pod-3dcba2f5-fbfa-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.027683333s
STEP: Saw pod success
Dec  9 21:34:49.233: INFO: Pod "pod-3dcba2f5-fbfa-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 21:34:49.237: INFO: Trying to get logs from node k8s04 pod pod-3dcba2f5-fbfa-11e8-8725-0a580af4034b container test-container: <nil>
STEP: delete the pod
Dec  9 21:34:49.280: INFO: Waiting for pod pod-3dcba2f5-fbfa-11e8-8725-0a580af4034b to disappear
Dec  9 21:34:49.284: INFO: Pod pod-3dcba2f5-fbfa-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:34:49.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-rsft6" for this suite.
Dec  9 21:34:55.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:34:55.428: INFO: namespace: e2e-tests-emptydir-rsft6, resource: bindings, ignored listing per whitelist
Dec  9 21:34:55.472: INFO: namespace e2e-tests-emptydir-rsft6 deletion completed in 6.178814158s

• [SLOW TEST:12.391 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:34:55.472: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Dec  9 21:34:55.579: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  9 21:34:55.593: INFO: Waiting for terminating namespaces to be deleted...
Dec  9 21:34:55.600: INFO: 
Logging pods the kubelet thinks is on node k8s04 before test
Dec  9 21:34:55.611: INFO: kube-proxy-jp2gj from kube-system started at 2018-12-09 16:17:56 +0000 UTC (1 container statuses recorded)
Dec  9 21:34:55.612: INFO: 	Container kube-proxy ready: true, restart count 1
Dec  9 21:34:55.612: INFO: kube-flannel-ds-zh4m6 from kube-system started at 2018-12-09 16:17:56 +0000 UTC (1 container statuses recorded)
Dec  9 21:34:55.612: INFO: 	Container kube-flannel ready: true, restart count 2
Dec  9 21:34:55.612: INFO: sonobuoy-systemd-logs-daemon-set-1cb03de6217e447d-crnlb from heptio-sonobuoy started at 2018-12-09 20:15:42 +0000 UTC (2 container statuses recorded)
Dec  9 21:34:55.612: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec  9 21:34:55.612: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec  9 21:34:55.612: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-09 20:15:29 +0000 UTC (1 container statuses recorded)
Dec  9 21:34:55.612: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec  9 21:34:55.612: INFO: sonobuoy-e2e-job-0d4a7a7233874536 from heptio-sonobuoy started at 2018-12-09 20:15:42 +0000 UTC (2 container statuses recorded)
Dec  9 21:34:55.612: INFO: 	Container e2e ready: true, restart count 0
Dec  9 21:34:55.612: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node k8s04
Dec  9 21:34:55.658: INFO: Pod sonobuoy requesting resource cpu=0m on Node k8s04
Dec  9 21:34:55.659: INFO: Pod sonobuoy-e2e-job-0d4a7a7233874536 requesting resource cpu=0m on Node k8s04
Dec  9 21:34:55.659: INFO: Pod sonobuoy-systemd-logs-daemon-set-1cb03de6217e447d-crnlb requesting resource cpu=0m on Node k8s04
Dec  9 21:34:55.659: INFO: Pod kube-flannel-ds-zh4m6 requesting resource cpu=100m on Node k8s04
Dec  9 21:34:55.659: INFO: Pod kube-proxy-jp2gj requesting resource cpu=0m on Node k8s04
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-45397906-fbfa-11e8-8725-0a580af4034b.156ec7b36d2019e1], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-5k77z/filler-pod-45397906-fbfa-11e8-8725-0a580af4034b to k8s04]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-45397906-fbfa-11e8-8725-0a580af4034b.156ec7b393bf08b7], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-45397906-fbfa-11e8-8725-0a580af4034b.156ec7b3954570ee], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-45397906-fbfa-11e8-8725-0a580af4034b.156ec7b39d5c9b05], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.156ec7b3e578b78e], Reason = [FailedScheduling], Message = [0/4 nodes are available: 1 Insufficient cpu, 3 node(s) had taints that the pod didn't tolerate.]
STEP: removing the label node off the node k8s04
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:34:58.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-5k77z" for this suite.
Dec  9 21:35:04.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:35:04.923: INFO: namespace: e2e-tests-sched-pred-5k77z, resource: bindings, ignored listing per whitelist
Dec  9 21:35:04.928: INFO: namespace e2e-tests-sched-pred-5k77z deletion completed in 6.18727793s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:9.456 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:35:04.929: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Dec  9 21:35:05.049: INFO: Waiting up to 5m0s for pod "var-expansion-4ad06c85-fbfa-11e8-8725-0a580af4034b" in namespace "e2e-tests-var-expansion-jps2s" to be "success or failure"
Dec  9 21:35:05.061: INFO: Pod "var-expansion-4ad06c85-fbfa-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.865451ms
Dec  9 21:35:07.067: INFO: Pod "var-expansion-4ad06c85-fbfa-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017334513s
STEP: Saw pod success
Dec  9 21:35:07.067: INFO: Pod "var-expansion-4ad06c85-fbfa-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 21:35:07.071: INFO: Trying to get logs from node k8s04 pod var-expansion-4ad06c85-fbfa-11e8-8725-0a580af4034b container dapi-container: <nil>
STEP: delete the pod
Dec  9 21:35:07.107: INFO: Waiting for pod var-expansion-4ad06c85-fbfa-11e8-8725-0a580af4034b to disappear
Dec  9 21:35:07.112: INFO: Pod var-expansion-4ad06c85-fbfa-11e8-8725-0a580af4034b no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:35:07.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-jps2s" for this suite.
Dec  9 21:35:13.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:35:13.186: INFO: namespace: e2e-tests-var-expansion-jps2s, resource: bindings, ignored listing per whitelist
Dec  9 21:35:13.301: INFO: namespace e2e-tests-var-expansion-jps2s deletion completed in 6.183111852s

• [SLOW TEST:8.373 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:35:13.301: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:35:17.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-7vs9d" for this suite.
Dec  9 21:35:23.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:35:23.543: INFO: namespace: e2e-tests-kubelet-test-7vs9d, resource: bindings, ignored listing per whitelist
Dec  9 21:35:23.608: INFO: namespace e2e-tests-kubelet-test-7vs9d deletion completed in 6.180083387s

• [SLOW TEST:10.306 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:35:23.608: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  9 21:35:23.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-q4wb6'
Dec  9 21:35:23.809: INFO: stderr: ""
Dec  9 21:35:23.809: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Dec  9 21:35:28.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-q4wb6 -o json'
Dec  9 21:35:28.940: INFO: stderr: ""
Dec  9 21:35:28.940: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2018-12-09T21:35:23Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-q4wb6\",\n        \"resourceVersion\": \"54405\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-q4wb6/pods/e2e-test-nginx-pod\",\n        \"uid\": \"55fe5833-fbfa-11e8-8106-000c29086e66\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-gpp8f\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"k8s04\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-gpp8f\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-gpp8f\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-09T21:35:23Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-09T21:35:25Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-09T21:35:25Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-09T21:35:23Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://6719cf0286973b90141c0f68f060b021563a2eb73991197c26bc078269fe1257\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2018-12-09T21:35:24Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.9.14\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.3.121\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2018-12-09T21:35:23Z\"\n    }\n}\n"
STEP: replace the image in the pod
Dec  9 21:35:28.941: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 replace -f - --namespace=e2e-tests-kubectl-q4wb6'
Dec  9 21:35:29.121: INFO: stderr: ""
Dec  9 21:35:29.121: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Dec  9 21:35:29.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-028914468 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-q4wb6'
Dec  9 21:35:31.250: INFO: stderr: ""
Dec  9 21:35:31.250: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:35:31.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-q4wb6" for this suite.
Dec  9 21:35:37.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:35:37.302: INFO: namespace: e2e-tests-kubectl-q4wb6, resource: bindings, ignored listing per whitelist
Dec  9 21:35:37.449: INFO: namespace e2e-tests-kubectl-q4wb6 deletion completed in 6.192597711s

• [SLOW TEST:13.841 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:35:37.449: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-5e31bf85-fbfa-11e8-8725-0a580af4034b
STEP: Creating a pod to test consume secrets
Dec  9 21:35:37.576: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5e331b42-fbfa-11e8-8725-0a580af4034b" in namespace "e2e-tests-projected-zz5jm" to be "success or failure"
Dec  9 21:35:37.591: INFO: Pod "pod-projected-secrets-5e331b42-fbfa-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 15.28629ms
Dec  9 21:35:39.596: INFO: Pod "pod-projected-secrets-5e331b42-fbfa-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020596353s
STEP: Saw pod success
Dec  9 21:35:39.596: INFO: Pod "pod-projected-secrets-5e331b42-fbfa-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 21:35:39.601: INFO: Trying to get logs from node k8s04 pod pod-projected-secrets-5e331b42-fbfa-11e8-8725-0a580af4034b container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  9 21:35:39.637: INFO: Waiting for pod pod-projected-secrets-5e331b42-fbfa-11e8-8725-0a580af4034b to disappear
Dec  9 21:35:39.642: INFO: Pod pod-projected-secrets-5e331b42-fbfa-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:35:39.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zz5jm" for this suite.
Dec  9 21:35:45.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:35:45.809: INFO: namespace: e2e-tests-projected-zz5jm, resource: bindings, ignored listing per whitelist
Dec  9 21:35:45.815: INFO: namespace e2e-tests-projected-zz5jm deletion completed in 6.165640831s

• [SLOW TEST:8.366 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:35:45.815: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-9ll4w
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-9ll4w to expose endpoints map[]
Dec  9 21:35:45.938: INFO: Get endpoints failed (9.07401ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Dec  9 21:35:46.943: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-9ll4w exposes endpoints map[] (1.013959443s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-9ll4w
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-9ll4w to expose endpoints map[pod1:[80]]
Dec  9 21:35:48.986: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-9ll4w exposes endpoints map[pod1:[80]] (2.030042531s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-9ll4w
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-9ll4w to expose endpoints map[pod1:[80] pod2:[80]]
Dec  9 21:35:51.042: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-9ll4w exposes endpoints map[pod1:[80] pod2:[80]] (2.048252603s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-9ll4w
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-9ll4w to expose endpoints map[pod2:[80]]
Dec  9 21:35:52.081: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-9ll4w exposes endpoints map[pod2:[80]] (1.02819485s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-9ll4w
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-9ll4w to expose endpoints map[]
Dec  9 21:35:53.106: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-9ll4w exposes endpoints map[] (1.013134483s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:35:53.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-9ll4w" for this suite.
Dec  9 21:35:59.180: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:35:59.212: INFO: namespace: e2e-tests-services-9ll4w, resource: bindings, ignored listing per whitelist
Dec  9 21:35:59.327: INFO: namespace e2e-tests-services-9ll4w deletion completed in 6.176165448s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:13.513 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:35:59.328: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-qjrnc
Dec  9 21:36:01.478: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-qjrnc
STEP: checking the pod's current state and verifying that restartCount is present
Dec  9 21:36:01.482: INFO: Initial restart count of pod liveness-http is 0
Dec  9 21:36:19.545: INFO: Restart count of pod e2e-tests-container-probe-qjrnc/liveness-http is now 1 (18.062258668s elapsed)
Dec  9 21:36:39.607: INFO: Restart count of pod e2e-tests-container-probe-qjrnc/liveness-http is now 2 (38.124331469s elapsed)
Dec  9 21:36:59.671: INFO: Restart count of pod e2e-tests-container-probe-qjrnc/liveness-http is now 3 (58.189194925s elapsed)
Dec  9 21:37:19.734: INFO: Restart count of pod e2e-tests-container-probe-qjrnc/liveness-http is now 4 (1m18.252072052s elapsed)
Dec  9 21:38:24.352: INFO: Restart count of pod e2e-tests-container-probe-qjrnc/liveness-http is now 5 (2m22.870216645s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:38:24.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-qjrnc" for this suite.
Dec  9 21:38:30.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:38:30.462: INFO: namespace: e2e-tests-container-probe-qjrnc, resource: bindings, ignored listing per whitelist
Dec  9 21:38:30.548: INFO: namespace e2e-tests-container-probe-qjrnc deletion completed in 6.171724169s

• [SLOW TEST:151.220 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:38:30.548: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Dec  9 21:38:31.193: INFO: created pod pod-service-account-defaultsa
Dec  9 21:38:31.193: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Dec  9 21:38:31.210: INFO: created pod pod-service-account-mountsa
Dec  9 21:38:31.210: INFO: pod pod-service-account-mountsa service account token volume mount: true
Dec  9 21:38:31.222: INFO: created pod pod-service-account-nomountsa
Dec  9 21:38:31.222: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Dec  9 21:38:31.229: INFO: created pod pod-service-account-defaultsa-mountspec
Dec  9 21:38:31.229: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Dec  9 21:38:31.246: INFO: created pod pod-service-account-mountsa-mountspec
Dec  9 21:38:31.246: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Dec  9 21:38:31.264: INFO: created pod pod-service-account-nomountsa-mountspec
Dec  9 21:38:31.264: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Dec  9 21:38:31.277: INFO: created pod pod-service-account-defaultsa-nomountspec
Dec  9 21:38:31.277: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Dec  9 21:38:31.293: INFO: created pod pod-service-account-mountsa-nomountspec
Dec  9 21:38:31.293: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Dec  9 21:38:31.312: INFO: created pod pod-service-account-nomountsa-nomountspec
Dec  9 21:38:31.312: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:38:31.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-svpk4" for this suite.
Dec  9 21:38:53.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:38:53.428: INFO: namespace: e2e-tests-svcaccounts-svpk4, resource: bindings, ignored listing per whitelist
Dec  9 21:38:53.515: INFO: namespace e2e-tests-svcaccounts-svpk4 deletion completed in 22.184661356s

• [SLOW TEST:22.967 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:38:53.515: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec  9 21:38:53.624: INFO: Waiting up to 5m0s for pod "pod-d30ddd97-fbfa-11e8-8725-0a580af4034b" in namespace "e2e-tests-emptydir-pd8dp" to be "success or failure"
Dec  9 21:38:53.633: INFO: Pod "pod-d30ddd97-fbfa-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.328264ms
Dec  9 21:38:55.637: INFO: Pod "pod-d30ddd97-fbfa-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012825096s
STEP: Saw pod success
Dec  9 21:38:55.637: INFO: Pod "pod-d30ddd97-fbfa-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 21:38:55.641: INFO: Trying to get logs from node k8s04 pod pod-d30ddd97-fbfa-11e8-8725-0a580af4034b container test-container: <nil>
STEP: delete the pod
Dec  9 21:38:55.676: INFO: Waiting for pod pod-d30ddd97-fbfa-11e8-8725-0a580af4034b to disappear
Dec  9 21:38:55.681: INFO: Pod pod-d30ddd97-fbfa-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:38:55.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-pd8dp" for this suite.
Dec  9 21:39:01.717: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:39:01.842: INFO: namespace: e2e-tests-emptydir-pd8dp, resource: bindings, ignored listing per whitelist
Dec  9 21:39:01.882: INFO: namespace e2e-tests-emptydir-pd8dp deletion completed in 6.192721561s

• [SLOW TEST:8.367 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:39:01.882: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-d80b9351-fbfa-11e8-8725-0a580af4034b
STEP: Creating a pod to test consume secrets
Dec  9 21:39:02.007: INFO: Waiting up to 5m0s for pod "pod-secrets-d80cf42c-fbfa-11e8-8725-0a580af4034b" in namespace "e2e-tests-secrets-8j6cp" to be "success or failure"
Dec  9 21:39:02.016: INFO: Pod "pod-secrets-d80cf42c-fbfa-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.297679ms
Dec  9 21:39:04.021: INFO: Pod "pod-secrets-d80cf42c-fbfa-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013605111s
STEP: Saw pod success
Dec  9 21:39:04.021: INFO: Pod "pod-secrets-d80cf42c-fbfa-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 21:39:04.024: INFO: Trying to get logs from node k8s04 pod pod-secrets-d80cf42c-fbfa-11e8-8725-0a580af4034b container secret-volume-test: <nil>
STEP: delete the pod
Dec  9 21:39:04.057: INFO: Waiting for pod pod-secrets-d80cf42c-fbfa-11e8-8725-0a580af4034b to disappear
Dec  9 21:39:04.064: INFO: Pod pod-secrets-d80cf42c-fbfa-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:39:04.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-8j6cp" for this suite.
Dec  9 21:39:10.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:39:10.202: INFO: namespace: e2e-tests-secrets-8j6cp, resource: bindings, ignored listing per whitelist
Dec  9 21:39:10.253: INFO: namespace e2e-tests-secrets-8j6cp deletion completed in 6.182408026s

• [SLOW TEST:8.371 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:39:10.253: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-tc5w
STEP: Creating a pod to test atomic-volume-subpath
Dec  9 21:39:10.386: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-tc5w" in namespace "e2e-tests-subpath-xzsm4" to be "success or failure"
Dec  9 21:39:10.395: INFO: Pod "pod-subpath-test-projected-tc5w": Phase="Pending", Reason="", readiness=false. Elapsed: 8.053207ms
Dec  9 21:39:12.401: INFO: Pod "pod-subpath-test-projected-tc5w": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014109373s
Dec  9 21:39:14.405: INFO: Pod "pod-subpath-test-projected-tc5w": Phase="Running", Reason="", readiness=false. Elapsed: 4.01830049s
Dec  9 21:39:16.410: INFO: Pod "pod-subpath-test-projected-tc5w": Phase="Running", Reason="", readiness=false. Elapsed: 6.023604575s
Dec  9 21:39:18.415: INFO: Pod "pod-subpath-test-projected-tc5w": Phase="Running", Reason="", readiness=false. Elapsed: 8.028387423s
Dec  9 21:39:20.427: INFO: Pod "pod-subpath-test-projected-tc5w": Phase="Running", Reason="", readiness=false. Elapsed: 10.040927397s
Dec  9 21:39:22.432: INFO: Pod "pod-subpath-test-projected-tc5w": Phase="Running", Reason="", readiness=false. Elapsed: 12.045403647s
Dec  9 21:39:24.437: INFO: Pod "pod-subpath-test-projected-tc5w": Phase="Running", Reason="", readiness=false. Elapsed: 14.05034981s
Dec  9 21:39:26.441: INFO: Pod "pod-subpath-test-projected-tc5w": Phase="Running", Reason="", readiness=false. Elapsed: 16.054659534s
Dec  9 21:39:28.446: INFO: Pod "pod-subpath-test-projected-tc5w": Phase="Running", Reason="", readiness=false. Elapsed: 18.059933327s
Dec  9 21:39:30.460: INFO: Pod "pod-subpath-test-projected-tc5w": Phase="Running", Reason="", readiness=false. Elapsed: 20.073115854s
Dec  9 21:39:32.464: INFO: Pod "pod-subpath-test-projected-tc5w": Phase="Running", Reason="", readiness=false. Elapsed: 22.077963265s
Dec  9 21:39:34.471: INFO: Pod "pod-subpath-test-projected-tc5w": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.084190455s
STEP: Saw pod success
Dec  9 21:39:34.471: INFO: Pod "pod-subpath-test-projected-tc5w" satisfied condition "success or failure"
Dec  9 21:39:34.475: INFO: Trying to get logs from node k8s04 pod pod-subpath-test-projected-tc5w container test-container-subpath-projected-tc5w: <nil>
STEP: delete the pod
Dec  9 21:39:34.510: INFO: Waiting for pod pod-subpath-test-projected-tc5w to disappear
Dec  9 21:39:34.516: INFO: Pod pod-subpath-test-projected-tc5w no longer exists
STEP: Deleting pod pod-subpath-test-projected-tc5w
Dec  9 21:39:34.516: INFO: Deleting pod "pod-subpath-test-projected-tc5w" in namespace "e2e-tests-subpath-xzsm4"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:39:34.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-xzsm4" for this suite.
Dec  9 21:39:40.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:39:40.692: INFO: namespace: e2e-tests-subpath-xzsm4, resource: bindings, ignored listing per whitelist
Dec  9 21:39:40.718: INFO: namespace e2e-tests-subpath-xzsm4 deletion completed in 6.180815557s

• [SLOW TEST:30.465 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:39:40.718: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-9wbfs
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-9wbfs to expose endpoints map[]
Dec  9 21:39:40.846: INFO: Get endpoints failed (7.204047ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Dec  9 21:39:41.850: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-9wbfs exposes endpoints map[] (1.011706705s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-9wbfs
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-9wbfs to expose endpoints map[pod1:[100]]
Dec  9 21:39:43.897: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-9wbfs exposes endpoints map[pod1:[100]] (2.034404045s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-9wbfs
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-9wbfs to expose endpoints map[pod1:[100] pod2:[101]]
Dec  9 21:39:45.954: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-9wbfs exposes endpoints map[pod1:[100] pod2:[101]] (2.049459117s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-9wbfs
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-9wbfs to expose endpoints map[pod2:[101]]
Dec  9 21:39:45.987: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-9wbfs exposes endpoints map[pod2:[101]] (22.25234ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-9wbfs
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-9wbfs to expose endpoints map[]
Dec  9 21:39:47.015: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-9wbfs exposes endpoints map[] (1.01252345s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:39:47.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-9wbfs" for this suite.
Dec  9 21:39:53.089: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:39:53.103: INFO: namespace: e2e-tests-services-9wbfs, resource: bindings, ignored listing per whitelist
Dec  9 21:39:53.239: INFO: namespace e2e-tests-services-9wbfs deletion completed in 6.173392438s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:12.521 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:39:53.240: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-f6a765bb-fbfa-11e8-8725-0a580af4034b
STEP: Creating a pod to test consume secrets
Dec  9 21:39:53.359: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f6a8c088-fbfa-11e8-8725-0a580af4034b" in namespace "e2e-tests-projected-rdjw7" to be "success or failure"
Dec  9 21:39:53.370: INFO: Pod "pod-projected-secrets-f6a8c088-fbfa-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.934435ms
Dec  9 21:39:55.374: INFO: Pod "pod-projected-secrets-f6a8c088-fbfa-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014735176s
STEP: Saw pod success
Dec  9 21:39:55.374: INFO: Pod "pod-projected-secrets-f6a8c088-fbfa-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 21:39:55.380: INFO: Trying to get logs from node k8s04 pod pod-projected-secrets-f6a8c088-fbfa-11e8-8725-0a580af4034b container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  9 21:39:55.416: INFO: Waiting for pod pod-projected-secrets-f6a8c088-fbfa-11e8-8725-0a580af4034b to disappear
Dec  9 21:39:55.422: INFO: Pod pod-projected-secrets-f6a8c088-fbfa-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:39:55.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rdjw7" for this suite.
Dec  9 21:40:01.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:40:01.571: INFO: namespace: e2e-tests-projected-rdjw7, resource: bindings, ignored listing per whitelist
Dec  9 21:40:01.610: INFO: namespace e2e-tests-projected-rdjw7 deletion completed in 6.180888801s

• [SLOW TEST:8.370 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:40:01.610: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Dec  9 21:40:01.704: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  9 21:40:01.713: INFO: Waiting for terminating namespaces to be deleted...
Dec  9 21:40:01.719: INFO: 
Logging pods the kubelet thinks is on node k8s04 before test
Dec  9 21:40:01.731: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-09 20:15:29 +0000 UTC (1 container statuses recorded)
Dec  9 21:40:01.731: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec  9 21:40:01.731: INFO: sonobuoy-e2e-job-0d4a7a7233874536 from heptio-sonobuoy started at 2018-12-09 20:15:42 +0000 UTC (2 container statuses recorded)
Dec  9 21:40:01.731: INFO: 	Container e2e ready: true, restart count 0
Dec  9 21:40:01.731: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  9 21:40:01.731: INFO: kube-proxy-jp2gj from kube-system started at 2018-12-09 16:17:56 +0000 UTC (1 container statuses recorded)
Dec  9 21:40:01.731: INFO: 	Container kube-proxy ready: true, restart count 1
Dec  9 21:40:01.731: INFO: kube-flannel-ds-zh4m6 from kube-system started at 2018-12-09 16:17:56 +0000 UTC (1 container statuses recorded)
Dec  9 21:40:01.731: INFO: 	Container kube-flannel ready: true, restart count 2
Dec  9 21:40:01.731: INFO: sonobuoy-systemd-logs-daemon-set-1cb03de6217e447d-crnlb from heptio-sonobuoy started at 2018-12-09 20:15:42 +0000 UTC (2 container statuses recorded)
Dec  9 21:40:01.731: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec  9 21:40:01.731: INFO: 	Container sonobuoy-worker ready: true, restart count 1
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-fce0dc22-fbfa-11e8-8725-0a580af4034b 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-fce0dc22-fbfa-11e8-8725-0a580af4034b off the node k8s04
STEP: verifying the node doesn't have the label kubernetes.io/e2e-fce0dc22-fbfa-11e8-8725-0a580af4034b
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:40:05.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-55zsn" for this suite.
Dec  9 21:40:13.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:40:13.933: INFO: namespace: e2e-tests-sched-pred-55zsn, resource: bindings, ignored listing per whitelist
Dec  9 21:40:14.028: INFO: namespace e2e-tests-sched-pred-55zsn deletion completed in 8.168930145s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:12.418 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:40:14.028: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Dec  9 21:40:14.140: INFO: Waiting up to 5m0s for pod "client-containers-030c1b0b-fbfb-11e8-8725-0a580af4034b" in namespace "e2e-tests-containers-mrpdr" to be "success or failure"
Dec  9 21:40:14.149: INFO: Pod "client-containers-030c1b0b-fbfb-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.372138ms
Dec  9 21:40:16.154: INFO: Pod "client-containers-030c1b0b-fbfb-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014021102s
STEP: Saw pod success
Dec  9 21:40:16.154: INFO: Pod "client-containers-030c1b0b-fbfb-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 21:40:16.158: INFO: Trying to get logs from node k8s04 pod client-containers-030c1b0b-fbfb-11e8-8725-0a580af4034b container test-container: <nil>
STEP: delete the pod
Dec  9 21:40:16.195: INFO: Waiting for pod client-containers-030c1b0b-fbfb-11e8-8725-0a580af4034b to disappear
Dec  9 21:40:16.204: INFO: Pod client-containers-030c1b0b-fbfb-11e8-8725-0a580af4034b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:40:16.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-mrpdr" for this suite.
Dec  9 21:40:22.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:40:22.283: INFO: namespace: e2e-tests-containers-mrpdr, resource: bindings, ignored listing per whitelist
Dec  9 21:40:22.413: INFO: namespace e2e-tests-containers-mrpdr deletion completed in 6.199442223s

• [SLOW TEST:8.385 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:40:22.413: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  9 21:40:22.525: INFO: Waiting up to 5m0s for pod "downward-api-080b1c79-fbfb-11e8-8725-0a580af4034b" in namespace "e2e-tests-downward-api-lb5tl" to be "success or failure"
Dec  9 21:40:22.533: INFO: Pod "downward-api-080b1c79-fbfb-11e8-8725-0a580af4034b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.84754ms
Dec  9 21:40:24.538: INFO: Pod "downward-api-080b1c79-fbfb-11e8-8725-0a580af4034b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013175341s
STEP: Saw pod success
Dec  9 21:40:24.538: INFO: Pod "downward-api-080b1c79-fbfb-11e8-8725-0a580af4034b" satisfied condition "success or failure"
Dec  9 21:40:24.543: INFO: Trying to get logs from node k8s04 pod downward-api-080b1c79-fbfb-11e8-8725-0a580af4034b container dapi-container: <nil>
STEP: delete the pod
Dec  9 21:40:24.580: INFO: Waiting for pod downward-api-080b1c79-fbfb-11e8-8725-0a580af4034b to disappear
Dec  9 21:40:24.584: INFO: Pod downward-api-080b1c79-fbfb-11e8-8725-0a580af4034b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:40:24.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-lb5tl" for this suite.
Dec  9 21:40:30.616: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:40:30.676: INFO: namespace: e2e-tests-downward-api-lb5tl, resource: bindings, ignored listing per whitelist
Dec  9 21:40:30.774: INFO: namespace e2e-tests-downward-api-lb5tl deletion completed in 6.180205582s

• [SLOW TEST:8.361 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:40:30.774: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  9 21:40:30.907: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"0d09c144-fbfb-11e8-925a-000c296b480b", Controller:(*bool)(0xc00215b7d2), BlockOwnerDeletion:(*bool)(0xc00215b7d3)}}
Dec  9 21:40:30.919: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"0d070732-fbfb-11e8-925a-000c296b480b", Controller:(*bool)(0xc0022e381e), BlockOwnerDeletion:(*bool)(0xc0022e381f)}}
Dec  9 21:40:30.934: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"0d083a56-fbfb-11e8-925a-000c296b480b", Controller:(*bool)(0xc00215b9ce), BlockOwnerDeletion:(*bool)(0xc00215b9cf)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:40:35.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-vg8zc" for this suite.
Dec  9 21:40:41.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:40:42.062: INFO: namespace: e2e-tests-gc-vg8zc, resource: bindings, ignored listing per whitelist
Dec  9 21:40:42.186: INFO: namespace e2e-tests-gc-vg8zc deletion completed in 6.22205536s

• [SLOW TEST:11.412 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:40:42.186: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-13d56a7f-fbfb-11e8-8725-0a580af4034b
Dec  9 21:40:42.307: INFO: Pod name my-hostname-basic-13d56a7f-fbfb-11e8-8725-0a580af4034b: Found 0 pods out of 1
Dec  9 21:40:47.320: INFO: Pod name my-hostname-basic-13d56a7f-fbfb-11e8-8725-0a580af4034b: Found 1 pods out of 1
Dec  9 21:40:47.320: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-13d56a7f-fbfb-11e8-8725-0a580af4034b" are running
Dec  9 21:40:47.325: INFO: Pod "my-hostname-basic-13d56a7f-fbfb-11e8-8725-0a580af4034b-ktlxh" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-09 21:40:42 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-09 21:40:43 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-09 21:40:43 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-09 21:40:42 +0000 UTC Reason: Message:}])
Dec  9 21:40:47.325: INFO: Trying to dial the pod
Dec  9 21:40:52.339: INFO: Controller my-hostname-basic-13d56a7f-fbfb-11e8-8725-0a580af4034b: Got expected result from replica 1 [my-hostname-basic-13d56a7f-fbfb-11e8-8725-0a580af4034b-ktlxh]: "my-hostname-basic-13d56a7f-fbfb-11e8-8725-0a580af4034b-ktlxh", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:40:52.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-87t92" for this suite.
Dec  9 21:40:58.372: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:40:58.405: INFO: namespace: e2e-tests-replication-controller-87t92, resource: bindings, ignored listing per whitelist
Dec  9 21:40:58.525: INFO: namespace e2e-tests-replication-controller-87t92 deletion completed in 6.180630239s

• [SLOW TEST:16.339 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:40:58.526: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:41:58.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-4xklp" for this suite.
Dec  9 21:42:20.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:42:20.818: INFO: namespace: e2e-tests-container-probe-4xklp, resource: bindings, ignored listing per whitelist
Dec  9 21:42:20.858: INFO: namespace e2e-tests-container-probe-4xklp deletion completed in 22.187460779s

• [SLOW TEST:82.333 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:42:20.859: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec  9 21:42:25.042: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  9 21:42:25.052: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  9 21:42:27.052: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  9 21:42:27.057: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  9 21:42:29.052: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  9 21:42:29.058: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  9 21:42:31.053: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  9 21:42:31.062: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  9 21:42:33.053: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  9 21:42:33.067: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  9 21:42:35.053: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  9 21:42:35.058: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  9 21:42:37.053: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  9 21:42:37.058: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  9 21:42:39.053: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  9 21:42:39.058: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  9 21:42:41.053: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  9 21:42:41.058: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  9 21:42:43.053: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  9 21:42:43.057: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  9 21:42:45.052: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  9 21:42:45.066: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:42:45.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-7p49k" for this suite.
Dec  9 21:43:07.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:43:07.160: INFO: namespace: e2e-tests-container-lifecycle-hook-7p49k, resource: bindings, ignored listing per whitelist
Dec  9 21:43:07.252: INFO: namespace e2e-tests-container-lifecycle-hook-7p49k deletion completed in 22.178507584s

• [SLOW TEST:46.394 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  9 21:43:07.252: INFO: >>> kubeConfig: /tmp/kubeconfig-028914468
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-hxwgk.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-hxwgk.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-hxwgk.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-hxwgk.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-hxwgk.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-hxwgk.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  9 21:43:11.492: INFO: DNS probes using e2e-tests-dns-hxwgk/dns-test-6a4b3f7e-fbfb-11e8-8725-0a580af4034b succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  9 21:43:11.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-hxwgk" for this suite.
Dec  9 21:43:17.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  9 21:43:17.616: INFO: namespace: e2e-tests-dns-hxwgk, resource: bindings, ignored listing per whitelist
Dec  9 21:43:17.706: INFO: namespace e2e-tests-dns-hxwgk deletion completed in 6.179367013s

• [SLOW TEST:10.454 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSDec  9 21:43:17.706: INFO: Running AfterSuite actions on all nodes
Dec  9 21:43:17.706: INFO: Running AfterSuite actions on node 1
Dec  9 21:43:17.706: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 5244.220 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h27m25.158914916s
Test Suite Passed
