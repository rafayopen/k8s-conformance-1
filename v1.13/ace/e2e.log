I1227 01:26:10.095745      18 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-574749520
I1227 01:26:10.095863      18 e2e.go:224] Starting e2e run "63c9e4d6-0976-11e9-a1bd-0a580a2100c6" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1545873969 - Will randomize all specs
Will run 201 of 1946 specs

Dec 27 01:26:10.202: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
Dec 27 01:26:10.204: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Dec 27 01:26:10.212: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Dec 27 01:26:10.235: INFO: 20 / 20 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Dec 27 01:26:10.235: INFO: expected 2 pod replicas in namespace 'kube-system', 2 are Running and Ready.
Dec 27 01:26:10.235: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Dec 27 01:26:10.241: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-flannel' (0 seconds elapsed)
Dec 27 01:26:10.241: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Dec 27 01:26:10.241: INFO: e2e test version: v1.13.0
Dec 27 01:26:10.241: INFO: kube-apiserver version: v1.13.1
S
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:26:10.242: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename downward-api
Dec 27 01:26:10.288: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec 27 01:26:12.828: INFO: Successfully updated pod "annotationupdate642bd410-0976-11e9-a1bd-0a580a2100c6"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:26:16.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-tnbng" for this suite.
Dec 27 01:26:38.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:26:38.895: INFO: namespace: e2e-tests-downward-api-tnbng, resource: bindings, ignored listing per whitelist
Dec 27 01:26:38.939: INFO: namespace e2e-tests-downward-api-tnbng deletion completed in 22.084155681s

• [SLOW TEST:28.697 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:26:38.939: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-7546f6f9-0976-11e9-a1bd-0a580a2100c6
STEP: Creating a pod to test consume configMaps
Dec 27 01:26:38.998: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7547b755-0976-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-projected-27pjn" to be "success or failure"
Dec 27 01:26:39.000: INFO: Pod "pod-projected-configmaps-7547b755-0976-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.735062ms
Dec 27 01:26:41.003: INFO: Pod "pod-projected-configmaps-7547b755-0976-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0043401s
STEP: Saw pod success
Dec 27 01:26:41.003: INFO: Pod "pod-projected-configmaps-7547b755-0976-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 01:26:41.004: INFO: Trying to get logs from node guojing-3 pod pod-projected-configmaps-7547b755-0976-11e9-a1bd-0a580a2100c6 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 27 01:26:41.028: INFO: Waiting for pod pod-projected-configmaps-7547b755-0976-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 01:26:41.030: INFO: Pod pod-projected-configmaps-7547b755-0976-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:26:41.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-27pjn" for this suite.
Dec 27 01:26:47.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:26:47.054: INFO: namespace: e2e-tests-projected-27pjn, resource: bindings, ignored listing per whitelist
Dec 27 01:26:47.102: INFO: namespace e2e-tests-projected-27pjn deletion completed in 6.069737107s

• [SLOW TEST:8.163 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:26:47.102: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Dec 27 01:26:47.156: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-4jjfb" to be "success or failure"
Dec 27 01:26:47.158: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 1.902534ms
Dec 27 01:26:49.160: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004452268s
STEP: Saw pod success
Dec 27 01:26:49.160: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Dec 27 01:26:49.162: INFO: Trying to get logs from node guojing-1 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Dec 27 01:26:49.186: INFO: Waiting for pod pod-host-path-test to disappear
Dec 27 01:26:49.188: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:26:49.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-4jjfb" for this suite.
Dec 27 01:26:55.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:26:55.237: INFO: namespace: e2e-tests-hostpath-4jjfb, resource: bindings, ignored listing per whitelist
Dec 27 01:26:55.254: INFO: namespace e2e-tests-hostpath-4jjfb deletion completed in 6.061895503s

• [SLOW TEST:8.152 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:26:55.254: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-7efff285-0976-11e9-a1bd-0a580a2100c6
STEP: Creating a pod to test consume configMaps
Dec 27 01:26:55.312: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7f00a628-0976-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-projected-zd5c4" to be "success or failure"
Dec 27 01:26:55.314: INFO: Pod "pod-projected-configmaps-7f00a628-0976-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.689862ms
Dec 27 01:26:57.317: INFO: Pod "pod-projected-configmaps-7f00a628-0976-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00437106s
STEP: Saw pod success
Dec 27 01:26:57.317: INFO: Pod "pod-projected-configmaps-7f00a628-0976-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 01:26:57.318: INFO: Trying to get logs from node guojing-2 pod pod-projected-configmaps-7f00a628-0976-11e9-a1bd-0a580a2100c6 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 27 01:26:57.344: INFO: Waiting for pod pod-projected-configmaps-7f00a628-0976-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 01:26:57.346: INFO: Pod pod-projected-configmaps-7f00a628-0976-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:26:57.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zd5c4" for this suite.
Dec 27 01:27:03.357: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:27:03.373: INFO: namespace: e2e-tests-projected-zd5c4, resource: bindings, ignored listing per whitelist
Dec 27 01:27:03.416: INFO: namespace e2e-tests-projected-zd5c4 deletion completed in 6.066736297s

• [SLOW TEST:8.162 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:27:03.416: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Dec 27 01:27:07.491: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-4d9w4 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 27 01:27:07.491: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
Dec 27 01:27:07.569: INFO: Exec stderr: ""
Dec 27 01:27:07.569: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-4d9w4 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 27 01:27:07.569: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
Dec 27 01:27:07.645: INFO: Exec stderr: ""
Dec 27 01:27:07.645: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-4d9w4 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 27 01:27:07.645: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
Dec 27 01:27:07.716: INFO: Exec stderr: ""
Dec 27 01:27:07.716: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-4d9w4 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 27 01:27:07.716: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
Dec 27 01:27:07.789: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Dec 27 01:27:07.789: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-4d9w4 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 27 01:27:07.789: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
Dec 27 01:27:07.861: INFO: Exec stderr: ""
Dec 27 01:27:07.861: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-4d9w4 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 27 01:27:07.861: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
Dec 27 01:27:07.934: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Dec 27 01:27:07.934: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-4d9w4 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 27 01:27:07.934: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
Dec 27 01:27:08.009: INFO: Exec stderr: ""
Dec 27 01:27:08.009: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-4d9w4 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 27 01:27:08.009: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
Dec 27 01:27:08.085: INFO: Exec stderr: ""
Dec 27 01:27:08.085: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-4d9w4 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 27 01:27:08.085: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
Dec 27 01:27:08.175: INFO: Exec stderr: ""
Dec 27 01:27:08.175: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-4d9w4 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 27 01:27:08.175: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
Dec 27 01:27:08.251: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:27:08.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-4d9w4" for this suite.
Dec 27 01:27:58.264: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:27:58.291: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-4d9w4, resource: bindings, ignored listing per whitelist
Dec 27 01:27:58.322: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-4d9w4 deletion completed in 50.066482791s

• [SLOW TEST:54.906 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:27:58.322: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-a49891f0-0976-11e9-a1bd-0a580a2100c6
STEP: Creating secret with name secret-projected-all-test-volume-a49891d3-0976-11e9-a1bd-0a580a2100c6
STEP: Creating a pod to test Check all projections for projected volume plugin
Dec 27 01:27:58.389: INFO: Waiting up to 5m0s for pod "projected-volume-a4989190-0976-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-projected-jzjj8" to be "success or failure"
Dec 27 01:27:58.391: INFO: Pod "projected-volume-a4989190-0976-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.855019ms
Dec 27 01:28:00.394: INFO: Pod "projected-volume-a4989190-0976-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00455605s
STEP: Saw pod success
Dec 27 01:28:00.394: INFO: Pod "projected-volume-a4989190-0976-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 01:28:00.396: INFO: Trying to get logs from node guojing-2 pod projected-volume-a4989190-0976-11e9-a1bd-0a580a2100c6 container projected-all-volume-test: <nil>
STEP: delete the pod
Dec 27 01:28:00.412: INFO: Waiting for pod projected-volume-a4989190-0976-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 01:28:00.414: INFO: Pod projected-volume-a4989190-0976-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:28:00.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jzjj8" for this suite.
Dec 27 01:28:06.425: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:28:06.460: INFO: namespace: e2e-tests-projected-jzjj8, resource: bindings, ignored listing per whitelist
Dec 27 01:28:06.481: INFO: namespace e2e-tests-projected-jzjj8 deletion completed in 6.064644396s

• [SLOW TEST:8.159 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:28:06.482: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Dec 27 01:28:06.543: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-xqjfw,SelfLink:/api/v1/namespaces/e2e-tests-watch-xqjfw/configmaps/e2e-watch-test-label-changed,UID:a973c771-0976-11e9-9853-debd8636412e,ResourceVersion:1466,Generation:0,CreationTimestamp:2018-12-27 01:28:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 27 01:28:06.543: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-xqjfw,SelfLink:/api/v1/namespaces/e2e-tests-watch-xqjfw/configmaps/e2e-watch-test-label-changed,UID:a973c771-0976-11e9-9853-debd8636412e,ResourceVersion:1467,Generation:0,CreationTimestamp:2018-12-27 01:28:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec 27 01:28:06.543: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-xqjfw,SelfLink:/api/v1/namespaces/e2e-tests-watch-xqjfw/configmaps/e2e-watch-test-label-changed,UID:a973c771-0976-11e9-9853-debd8636412e,ResourceVersion:1468,Generation:0,CreationTimestamp:2018-12-27 01:28:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Dec 27 01:28:16.565: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-xqjfw,SelfLink:/api/v1/namespaces/e2e-tests-watch-xqjfw/configmaps/e2e-watch-test-label-changed,UID:a973c771-0976-11e9-9853-debd8636412e,ResourceVersion:1486,Generation:0,CreationTimestamp:2018-12-27 01:28:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 27 01:28:16.565: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-xqjfw,SelfLink:/api/v1/namespaces/e2e-tests-watch-xqjfw/configmaps/e2e-watch-test-label-changed,UID:a973c771-0976-11e9-9853-debd8636412e,ResourceVersion:1487,Generation:0,CreationTimestamp:2018-12-27 01:28:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Dec 27 01:28:16.565: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-xqjfw,SelfLink:/api/v1/namespaces/e2e-tests-watch-xqjfw/configmaps/e2e-watch-test-label-changed,UID:a973c771-0976-11e9-9853-debd8636412e,ResourceVersion:1488,Generation:0,CreationTimestamp:2018-12-27 01:28:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:28:16.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-xqjfw" for this suite.
Dec 27 01:28:22.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:28:22.625: INFO: namespace: e2e-tests-watch-xqjfw, resource: bindings, ignored listing per whitelist
Dec 27 01:28:22.643: INFO: namespace e2e-tests-watch-xqjfw deletion completed in 6.074750015s

• [SLOW TEST:16.161 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:28:22.643: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec 27 01:28:26.719: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 27 01:28:26.721: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 27 01:28:28.721: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 27 01:28:28.724: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 27 01:28:30.721: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 27 01:28:30.724: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 27 01:28:32.721: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 27 01:28:32.724: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 27 01:28:34.721: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 27 01:28:34.724: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 27 01:28:36.721: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 27 01:28:36.724: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 27 01:28:38.721: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 27 01:28:38.725: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 27 01:28:40.721: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 27 01:28:40.724: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 27 01:28:42.721: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 27 01:28:42.724: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 27 01:28:44.721: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 27 01:28:44.724: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:28:44.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-6jrw9" for this suite.
Dec 27 01:29:06.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:29:06.758: INFO: namespace: e2e-tests-container-lifecycle-hook-6jrw9, resource: bindings, ignored listing per whitelist
Dec 27 01:29:06.797: INFO: namespace e2e-tests-container-lifecycle-hook-6jrw9 deletion completed in 22.064977663s

• [SLOW TEST:44.154 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:29:06.797: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec 27 01:29:06.849: INFO: Waiting up to 5m0s for pod "pod-cd67c65e-0976-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-emptydir-xd8c8" to be "success or failure"
Dec 27 01:29:06.855: INFO: Pod "pod-cd67c65e-0976-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 5.697367ms
Dec 27 01:29:08.858: INFO: Pod "pod-cd67c65e-0976-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008612765s
STEP: Saw pod success
Dec 27 01:29:08.858: INFO: Pod "pod-cd67c65e-0976-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 01:29:08.860: INFO: Trying to get logs from node guojing-2 pod pod-cd67c65e-0976-11e9-a1bd-0a580a2100c6 container test-container: <nil>
STEP: delete the pod
Dec 27 01:29:08.875: INFO: Waiting for pod pod-cd67c65e-0976-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 01:29:08.876: INFO: Pod pod-cd67c65e-0976-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:29:08.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-xd8c8" for this suite.
Dec 27 01:29:14.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:29:14.909: INFO: namespace: e2e-tests-emptydir-xd8c8, resource: bindings, ignored listing per whitelist
Dec 27 01:29:14.964: INFO: namespace e2e-tests-emptydir-xd8c8 deletion completed in 6.0851733s

• [SLOW TEST:8.167 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:29:14.964: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Dec 27 01:29:15.516: INFO: Waiting up to 5m0s for pod "pod-service-account-d2921e83-0976-11e9-a1bd-0a580a2100c6-wlfhx" in namespace "e2e-tests-svcaccounts-mxbwm" to be "success or failure"
Dec 27 01:29:15.518: INFO: Pod "pod-service-account-d2921e83-0976-11e9-a1bd-0a580a2100c6-wlfhx": Phase="Pending", Reason="", readiness=false. Elapsed: 1.927664ms
Dec 27 01:29:17.520: INFO: Pod "pod-service-account-d2921e83-0976-11e9-a1bd-0a580a2100c6-wlfhx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004735155s
Dec 27 01:29:19.523: INFO: Pod "pod-service-account-d2921e83-0976-11e9-a1bd-0a580a2100c6-wlfhx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007364498s
STEP: Saw pod success
Dec 27 01:29:19.523: INFO: Pod "pod-service-account-d2921e83-0976-11e9-a1bd-0a580a2100c6-wlfhx" satisfied condition "success or failure"
Dec 27 01:29:19.525: INFO: Trying to get logs from node guojing-3 pod pod-service-account-d2921e83-0976-11e9-a1bd-0a580a2100c6-wlfhx container token-test: <nil>
STEP: delete the pod
Dec 27 01:29:19.541: INFO: Waiting for pod pod-service-account-d2921e83-0976-11e9-a1bd-0a580a2100c6-wlfhx to disappear
Dec 27 01:29:19.543: INFO: Pod pod-service-account-d2921e83-0976-11e9-a1bd-0a580a2100c6-wlfhx no longer exists
STEP: Creating a pod to test consume service account root CA
Dec 27 01:29:19.546: INFO: Waiting up to 5m0s for pod "pod-service-account-d2921e83-0976-11e9-a1bd-0a580a2100c6-r4vkl" in namespace "e2e-tests-svcaccounts-mxbwm" to be "success or failure"
Dec 27 01:29:19.548: INFO: Pod "pod-service-account-d2921e83-0976-11e9-a1bd-0a580a2100c6-r4vkl": Phase="Pending", Reason="", readiness=false. Elapsed: 1.73532ms
Dec 27 01:29:21.550: INFO: Pod "pod-service-account-d2921e83-0976-11e9-a1bd-0a580a2100c6-r4vkl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004070287s
STEP: Saw pod success
Dec 27 01:29:21.550: INFO: Pod "pod-service-account-d2921e83-0976-11e9-a1bd-0a580a2100c6-r4vkl" satisfied condition "success or failure"
Dec 27 01:29:21.552: INFO: Trying to get logs from node guojing-2 pod pod-service-account-d2921e83-0976-11e9-a1bd-0a580a2100c6-r4vkl container root-ca-test: <nil>
STEP: delete the pod
Dec 27 01:29:21.572: INFO: Waiting for pod pod-service-account-d2921e83-0976-11e9-a1bd-0a580a2100c6-r4vkl to disappear
Dec 27 01:29:21.575: INFO: Pod pod-service-account-d2921e83-0976-11e9-a1bd-0a580a2100c6-r4vkl no longer exists
STEP: Creating a pod to test consume service account namespace
Dec 27 01:29:21.578: INFO: Waiting up to 5m0s for pod "pod-service-account-d2921e83-0976-11e9-a1bd-0a580a2100c6-rhnnx" in namespace "e2e-tests-svcaccounts-mxbwm" to be "success or failure"
Dec 27 01:29:21.580: INFO: Pod "pod-service-account-d2921e83-0976-11e9-a1bd-0a580a2100c6-rhnnx": Phase="Pending", Reason="", readiness=false. Elapsed: 1.636859ms
Dec 27 01:29:23.583: INFO: Pod "pod-service-account-d2921e83-0976-11e9-a1bd-0a580a2100c6-rhnnx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004179547s
STEP: Saw pod success
Dec 27 01:29:23.583: INFO: Pod "pod-service-account-d2921e83-0976-11e9-a1bd-0a580a2100c6-rhnnx" satisfied condition "success or failure"
Dec 27 01:29:23.584: INFO: Trying to get logs from node guojing-1 pod pod-service-account-d2921e83-0976-11e9-a1bd-0a580a2100c6-rhnnx container namespace-test: <nil>
STEP: delete the pod
Dec 27 01:29:23.601: INFO: Waiting for pod pod-service-account-d2921e83-0976-11e9-a1bd-0a580a2100c6-rhnnx to disappear
Dec 27 01:29:23.603: INFO: Pod pod-service-account-d2921e83-0976-11e9-a1bd-0a580a2100c6-rhnnx no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:29:23.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-mxbwm" for this suite.
Dec 27 01:29:29.615: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:29:29.665: INFO: namespace: e2e-tests-svcaccounts-mxbwm, resource: bindings, ignored listing per whitelist
Dec 27 01:29:29.673: INFO: namespace e2e-tests-svcaccounts-mxbwm deletion completed in 6.066990602s

• [SLOW TEST:14.709 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:29:29.673: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec 27 01:29:29.723: INFO: Waiting up to 5m0s for pod "pod-db0a1fb7-0976-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-emptydir-l5jpn" to be "success or failure"
Dec 27 01:29:29.725: INFO: Pod "pod-db0a1fb7-0976-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.927977ms
Dec 27 01:29:31.728: INFO: Pod "pod-db0a1fb7-0976-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004657836s
STEP: Saw pod success
Dec 27 01:29:31.728: INFO: Pod "pod-db0a1fb7-0976-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 01:29:31.730: INFO: Trying to get logs from node guojing-3 pod pod-db0a1fb7-0976-11e9-a1bd-0a580a2100c6 container test-container: <nil>
STEP: delete the pod
Dec 27 01:29:31.743: INFO: Waiting for pod pod-db0a1fb7-0976-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 01:29:31.745: INFO: Pod pod-db0a1fb7-0976-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:29:31.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-l5jpn" for this suite.
Dec 27 01:29:37.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:29:37.777: INFO: namespace: e2e-tests-emptydir-l5jpn, resource: bindings, ignored listing per whitelist
Dec 27 01:29:37.817: INFO: namespace e2e-tests-emptydir-l5jpn deletion completed in 6.067769148s

• [SLOW TEST:8.144 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:29:37.817: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 27 01:29:37.857: INFO: Creating ReplicaSet my-hostname-basic-dfe42e2d-0976-11e9-a1bd-0a580a2100c6
Dec 27 01:29:37.866: INFO: Pod name my-hostname-basic-dfe42e2d-0976-11e9-a1bd-0a580a2100c6: Found 0 pods out of 1
Dec 27 01:29:42.869: INFO: Pod name my-hostname-basic-dfe42e2d-0976-11e9-a1bd-0a580a2100c6: Found 1 pods out of 1
Dec 27 01:29:42.869: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-dfe42e2d-0976-11e9-a1bd-0a580a2100c6" is running
Dec 27 01:29:42.871: INFO: Pod "my-hostname-basic-dfe42e2d-0976-11e9-a1bd-0a580a2100c6-zsjbv" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-27 01:29:37 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-27 01:29:39 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-27 01:29:39 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-27 01:29:37 +0000 UTC Reason: Message:}])
Dec 27 01:29:42.871: INFO: Trying to dial the pod
Dec 27 01:29:47.878: INFO: Controller my-hostname-basic-dfe42e2d-0976-11e9-a1bd-0a580a2100c6: Got expected result from replica 1 [my-hostname-basic-dfe42e2d-0976-11e9-a1bd-0a580a2100c6-zsjbv]: "my-hostname-basic-dfe42e2d-0976-11e9-a1bd-0a580a2100c6-zsjbv", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:29:47.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-d85sm" for this suite.
Dec 27 01:29:53.890: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:29:53.932: INFO: namespace: e2e-tests-replicaset-d85sm, resource: bindings, ignored listing per whitelist
Dec 27 01:29:53.947: INFO: namespace e2e-tests-replicaset-d85sm deletion completed in 6.065223589s

• [SLOW TEST:16.130 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:29:53.947: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-m7lzz A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-m7lzz;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-m7lzz A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-m7lzz;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-m7lzz.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-m7lzz.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-m7lzz.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-m7lzz.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-m7lzz.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-m7lzz.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-m7lzz.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-m7lzz.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-m7lzz.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 114.117.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.117.114_udp@PTR;check="$$(dig +tcp +noall +answer +search 114.117.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.117.114_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-m7lzz A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-m7lzz;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-m7lzz A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-m7lzz;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-m7lzz.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-m7lzz.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-m7lzz.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-m7lzz.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-m7lzz.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-m7lzz.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-m7lzz.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-m7lzz.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-m7lzz.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 114.117.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.117.114_udp@PTR;check="$$(dig +tcp +noall +answer +search 114.117.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.117.114_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 27 01:29:56.062: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:29:56.075: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:29:56.092: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:29:56.094: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:29:56.096: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-m7lzz from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:29:56.098: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-m7lzz from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:29:56.101: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-m7lzz.svc from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:29:56.104: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-m7lzz.svc from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:29:56.106: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:29:56.108: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:29:56.121: INFO: Lookups using e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6 failed for: [wheezy_udp@dns-test-service wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-m7lzz jessie_tcp@dns-test-service.e2e-tests-dns-m7lzz jessie_udp@dns-test-service.e2e-tests-dns-m7lzz.svc jessie_tcp@dns-test-service.e2e-tests-dns-m7lzz.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc]

Dec 27 01:30:01.125: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:01.141: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:01.163: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:01.165: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:01.168: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-m7lzz from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:01.170: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-m7lzz from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:01.173: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-m7lzz.svc from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:01.175: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-m7lzz.svc from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:01.177: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:01.180: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:01.194: INFO: Lookups using e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6 failed for: [wheezy_udp@dns-test-service wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-m7lzz jessie_tcp@dns-test-service.e2e-tests-dns-m7lzz jessie_udp@dns-test-service.e2e-tests-dns-m7lzz.svc jessie_tcp@dns-test-service.e2e-tests-dns-m7lzz.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc]

Dec 27 01:30:06.125: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:06.138: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:06.154: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:06.156: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:06.159: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-m7lzz from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:06.162: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-m7lzz from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:06.164: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-m7lzz.svc from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:06.166: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-m7lzz.svc from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:06.168: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:06.170: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:06.182: INFO: Lookups using e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6 failed for: [wheezy_udp@dns-test-service wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-m7lzz jessie_tcp@dns-test-service.e2e-tests-dns-m7lzz jessie_udp@dns-test-service.e2e-tests-dns-m7lzz.svc jessie_tcp@dns-test-service.e2e-tests-dns-m7lzz.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc]

Dec 27 01:30:11.125: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:11.139: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:11.155: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:11.157: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:11.159: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-m7lzz from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:11.161: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-m7lzz from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:11.163: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-m7lzz.svc from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:11.166: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-m7lzz.svc from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:11.168: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:11.170: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:11.182: INFO: Lookups using e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6 failed for: [wheezy_udp@dns-test-service wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-m7lzz jessie_tcp@dns-test-service.e2e-tests-dns-m7lzz jessie_udp@dns-test-service.e2e-tests-dns-m7lzz.svc jessie_tcp@dns-test-service.e2e-tests-dns-m7lzz.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc]

Dec 27 01:30:16.125: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:16.137: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:16.153: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:16.155: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:16.157: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-m7lzz from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:16.159: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-m7lzz from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:16.161: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-m7lzz.svc from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:16.163: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-m7lzz.svc from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:16.165: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:16.167: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:16.178: INFO: Lookups using e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6 failed for: [wheezy_udp@dns-test-service wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-m7lzz jessie_tcp@dns-test-service.e2e-tests-dns-m7lzz jessie_udp@dns-test-service.e2e-tests-dns-m7lzz.svc jessie_tcp@dns-test-service.e2e-tests-dns-m7lzz.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc]

Dec 27 01:30:21.125: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:21.138: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:21.160: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:21.163: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:21.166: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-m7lzz from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:21.168: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-m7lzz from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:21.170: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-m7lzz.svc from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:21.172: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-m7lzz.svc from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:21.175: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:21.177: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc from pod e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6: the server could not find the requested resource (get pods dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6)
Dec 27 01:30:21.189: INFO: Lookups using e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6 failed for: [wheezy_udp@dns-test-service wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-m7lzz jessie_tcp@dns-test-service.e2e-tests-dns-m7lzz jessie_udp@dns-test-service.e2e-tests-dns-m7lzz.svc jessie_tcp@dns-test-service.e2e-tests-dns-m7lzz.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-m7lzz.svc]

Dec 27 01:30:26.191: INFO: DNS probes using e2e-tests-dns-m7lzz/dns-test-e985d6c9-0976-11e9-a1bd-0a580a2100c6 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:30:26.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-m7lzz" for this suite.
Dec 27 01:30:32.296: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:30:32.351: INFO: namespace: e2e-tests-dns-m7lzz, resource: bindings, ignored listing per whitelist
Dec 27 01:30:32.353: INFO: namespace e2e-tests-dns-m7lzz deletion completed in 6.069173965s

• [SLOW TEST:38.406 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:30:32.353: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 27 01:30:48.420: INFO: Container started at 2018-12-27 01:30:33 +0000 UTC, pod became ready at 2018-12-27 01:30:48 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:30:48.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-qj2xm" for this suite.
Dec 27 01:31:10.432: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:31:10.490: INFO: namespace: e2e-tests-container-probe-qj2xm, resource: bindings, ignored listing per whitelist
Dec 27 01:31:10.491: INFO: namespace e2e-tests-container-probe-qj2xm deletion completed in 22.068750207s

• [SLOW TEST:38.138 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:31:10.491: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:31:10.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-957c4" for this suite.
Dec 27 01:31:16.572: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:31:16.596: INFO: namespace: e2e-tests-kubelet-test-957c4, resource: bindings, ignored listing per whitelist
Dec 27 01:31:16.636: INFO: namespace e2e-tests-kubelet-test-957c4 deletion completed in 6.072684767s

• [SLOW TEST:6.145 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:31:16.637: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Dec 27 01:31:16.877: INFO: Pod name wrapped-volume-race-1ae7997c-0977-11e9-a1bd-0a580a2100c6: Found 0 pods out of 5
Dec 27 01:31:21.881: INFO: Pod name wrapped-volume-race-1ae7997c-0977-11e9-a1bd-0a580a2100c6: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-1ae7997c-0977-11e9-a1bd-0a580a2100c6 in namespace e2e-tests-emptydir-wrapper-nqtqr, will wait for the garbage collector to delete the pods
Dec 27 01:31:31.956: INFO: Deleting ReplicationController wrapped-volume-race-1ae7997c-0977-11e9-a1bd-0a580a2100c6 took: 8.577006ms
Dec 27 01:31:32.056: INFO: Terminating ReplicationController wrapped-volume-race-1ae7997c-0977-11e9-a1bd-0a580a2100c6 pods took: 100.184154ms
STEP: Creating RC which spawns configmap-volume pods
Dec 27 01:32:15.175: INFO: Pod name wrapped-volume-race-3da62489-0977-11e9-a1bd-0a580a2100c6: Found 0 pods out of 5
Dec 27 01:32:20.181: INFO: Pod name wrapped-volume-race-3da62489-0977-11e9-a1bd-0a580a2100c6: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-3da62489-0977-11e9-a1bd-0a580a2100c6 in namespace e2e-tests-emptydir-wrapper-nqtqr, will wait for the garbage collector to delete the pods
Dec 27 01:32:30.254: INFO: Deleting ReplicationController wrapped-volume-race-3da62489-0977-11e9-a1bd-0a580a2100c6 took: 7.981929ms
Dec 27 01:32:30.355: INFO: Terminating ReplicationController wrapped-volume-race-3da62489-0977-11e9-a1bd-0a580a2100c6 pods took: 100.169592ms
STEP: Creating RC which spawns configmap-volume pods
Dec 27 01:33:15.169: INFO: Pod name wrapped-volume-race-61692ee8-0977-11e9-a1bd-0a580a2100c6: Found 0 pods out of 5
Dec 27 01:33:20.174: INFO: Pod name wrapped-volume-race-61692ee8-0977-11e9-a1bd-0a580a2100c6: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-61692ee8-0977-11e9-a1bd-0a580a2100c6 in namespace e2e-tests-emptydir-wrapper-nqtqr, will wait for the garbage collector to delete the pods
Dec 27 01:33:30.247: INFO: Deleting ReplicationController wrapped-volume-race-61692ee8-0977-11e9-a1bd-0a580a2100c6 took: 8.437205ms
Dec 27 01:33:30.347: INFO: Terminating ReplicationController wrapped-volume-race-61692ee8-0977-11e9-a1bd-0a580a2100c6 pods took: 100.146671ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:34:05.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-nqtqr" for this suite.
Dec 27 01:34:11.532: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:34:11.586: INFO: namespace: e2e-tests-emptydir-wrapper-nqtqr, resource: bindings, ignored listing per whitelist
Dec 27 01:34:11.589: INFO: namespace e2e-tests-emptydir-wrapper-nqtqr deletion completed in 6.06439762s

• [SLOW TEST:174.952 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:34:11.589: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 27 01:34:11.637: INFO: Creating deployment "nginx-deployment"
Dec 27 01:34:11.645: INFO: Waiting for observed generation 1
Dec 27 01:34:13.649: INFO: Waiting for all required pods to come up
Dec 27 01:34:13.652: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Dec 27 01:34:13.652: INFO: Waiting for deployment "nginx-deployment" to complete
Dec 27 01:34:13.659: INFO: Updating deployment "nginx-deployment" with a non-existent image
Dec 27 01:34:13.665: INFO: Updating deployment nginx-deployment
Dec 27 01:34:13.665: INFO: Waiting for observed generation 2
Dec 27 01:34:15.670: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Dec 27 01:34:15.674: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Dec 27 01:34:15.676: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Dec 27 01:34:15.681: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Dec 27 01:34:15.681: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Dec 27 01:34:15.683: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Dec 27 01:34:15.686: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Dec 27 01:34:15.686: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Dec 27 01:34:15.693: INFO: Updating deployment nginx-deployment
Dec 27 01:34:15.693: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Dec 27 01:34:15.697: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Dec 27 01:34:15.700: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec 27 01:34:15.709: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-xfphn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-xfphn/deployments/nginx-deployment,UID:8313dafd-0977-11e9-9853-debd8636412e,ResourceVersion:3399,Generation:3,CreationTimestamp:2018-12-27 01:34:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[{Available True 2018-12-27 01:34:13 +0000 UTC 2018-12-27 01:34:13 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-12-27 01:34:13 +0000 UTC 2018-12-27 01:34:11 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Dec 27 01:34:15.723: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-xfphn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-xfphn/replicasets/nginx-deployment-65bbdb5f8,UID:84492d5f-0977-11e9-b34c-525400cd4ed0,ResourceVersion:3403,Generation:3,CreationTimestamp:2018-12-27 01:34:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 8313dafd-0977-11e9-9853-debd8636412e 0xc001f86067 0xc001f86068}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 27 01:34:15.723: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Dec 27 01:34:15.723: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-xfphn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-xfphn/replicasets/nginx-deployment-555b55d965,UID:83157cc8-0977-11e9-b34c-525400cd4ed0,ResourceVersion:3400,Generation:3,CreationTimestamp:2018-12-27 01:34:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 8313dafd-0977-11e9-9853-debd8636412e 0xc001f99e27 0xc001f99e28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Dec 27 01:34:15.738: INFO: Pod "nginx-deployment-555b55d965-2fjmn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-2fjmn,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xfphn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xfphn/pods/nginx-deployment-555b55d965-2fjmn,UID:8580a666-0977-11e9-b34c-525400cd4ed0,ResourceVersion:3420,Generation:0,CreationTimestamp:2018-12-27 01:34:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 83157cc8-0977-11e9-b34c-525400cd4ed0 0xc0010a8350 0xc0010a8351}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-kf7rq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kf7rq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kf7rq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:guojing-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0010a83c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0010a83e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:15 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 27 01:34:15.738: INFO: Pod "nginx-deployment-555b55d965-4cths" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-4cths,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xfphn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xfphn/pods/nginx-deployment-555b55d965-4cths,UID:831a07b4-0977-11e9-b34c-525400cd4ed0,ResourceVersion:3317,Generation:0,CreationTimestamp:2018-12-27 01:34:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 83157cc8-0977-11e9-b34c-525400cd4ed0 0xc0010a8450 0xc0010a8451}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-kf7rq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kf7rq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kf7rq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:guojing-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0010a84c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0010a84e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:12 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:12 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:11 +0000 UTC  }],Message:,Reason:,HostIP:172.19.16.27,PodIP:10.33.0.208,StartTime:2018-12-27 01:34:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-27 01:34:12 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://de5e9b2c5d7601aea5045041f4735d5ef96c86f429f82043e6c514245f3a9907}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 27 01:34:15.738: INFO: Pod "nginx-deployment-555b55d965-4kcpz" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-4kcpz,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xfphn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xfphn/pods/nginx-deployment-555b55d965-4kcpz,UID:831a07ff-0977-11e9-b34c-525400cd4ed0,ResourceVersion:3296,Generation:0,CreationTimestamp:2018-12-27 01:34:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 83157cc8-0977-11e9-b34c-525400cd4ed0 0xc0010a85a0 0xc0010a85a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-kf7rq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kf7rq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kf7rq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:guojing-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0010a8610} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0010a8630}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:12 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:12 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:11 +0000 UTC  }],Message:,Reason:,HostIP:172.19.16.36,PodIP:10.33.1.34,StartTime:2018-12-27 01:34:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-27 01:34:12 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://329eb4ca5e91d7252311da22865870c5d8e6e7c30099ce19573e96876d19a4e9}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 27 01:34:15.739: INFO: Pod "nginx-deployment-555b55d965-4kv85" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-4kv85,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xfphn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xfphn/pods/nginx-deployment-555b55d965-4kv85,UID:8582fcf7-0977-11e9-b34c-525400cd4ed0,ResourceVersion:3416,Generation:0,CreationTimestamp:2018-12-27 01:34:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 83157cc8-0977-11e9-b34c-525400cd4ed0 0xc0010a86f0 0xc0010a86f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-kf7rq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kf7rq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kf7rq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0010a8750} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0010a8770}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 27 01:34:15.739: INFO: Pod "nginx-deployment-555b55d965-7n84k" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-7n84k,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xfphn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xfphn/pods/nginx-deployment-555b55d965-7n84k,UID:857f5835-0977-11e9-b34c-525400cd4ed0,ResourceVersion:3405,Generation:0,CreationTimestamp:2018-12-27 01:34:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 83157cc8-0977-11e9-b34c-525400cd4ed0 0xc0010a87c7 0xc0010a87c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-kf7rq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kf7rq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kf7rq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:guojing-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0010a8850} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0010a8870}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:15 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 27 01:34:15.739: INFO: Pod "nginx-deployment-555b55d965-dgxw2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-dgxw2,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xfphn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xfphn/pods/nginx-deployment-555b55d965-dgxw2,UID:83184e44-0977-11e9-b34c-525400cd4ed0,ResourceVersion:3301,Generation:0,CreationTimestamp:2018-12-27 01:34:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 83157cc8-0977-11e9-b34c-525400cd4ed0 0xc0010a88e0 0xc0010a88e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-kf7rq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kf7rq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kf7rq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:guojing-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0010a8950} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0010a8970}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:12 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:12 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:11 +0000 UTC  }],Message:,Reason:,HostIP:172.19.16.18,PodIP:10.33.2.60,StartTime:2018-12-27 01:34:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-27 01:34:12 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://f8929a16bff8ee04b9bf8f61fab1ae931f46259a001dba9314b5fd1b1288ac13}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 27 01:34:15.739: INFO: Pod "nginx-deployment-555b55d965-gkv98" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-gkv98,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xfphn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xfphn/pods/nginx-deployment-555b55d965-gkv98,UID:831c1a03-0977-11e9-b34c-525400cd4ed0,ResourceVersion:3320,Generation:0,CreationTimestamp:2018-12-27 01:34:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 83157cc8-0977-11e9-b34c-525400cd4ed0 0xc0010a8a30 0xc0010a8a31}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-kf7rq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kf7rq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kf7rq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:guojing-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0010a8ad0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0010a8af0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:12 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:12 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:11 +0000 UTC  }],Message:,Reason:,HostIP:172.19.16.18,PodIP:10.33.2.63,StartTime:2018-12-27 01:34:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-27 01:34:12 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://cf3b4bcbebc7670954b175317cd35fda096e41e58c4246d8aac1485d1518ea13}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 27 01:34:15.739: INFO: Pod "nginx-deployment-555b55d965-kxq27" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-kxq27,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xfphn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xfphn/pods/nginx-deployment-555b55d965-kxq27,UID:85809ba3-0977-11e9-b34c-525400cd4ed0,ResourceVersion:3414,Generation:0,CreationTimestamp:2018-12-27 01:34:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 83157cc8-0977-11e9-b34c-525400cd4ed0 0xc0010a8bc0 0xc0010a8bc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-kf7rq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kf7rq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kf7rq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:guojing-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0010a8c30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0010a8c50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:15 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 27 01:34:15.740: INFO: Pod "nginx-deployment-555b55d965-lqt6t" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-lqt6t,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xfphn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xfphn/pods/nginx-deployment-555b55d965-lqt6t,UID:8319f9aa-0977-11e9-b34c-525400cd4ed0,ResourceVersion:3314,Generation:0,CreationTimestamp:2018-12-27 01:34:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 83157cc8-0977-11e9-b34c-525400cd4ed0 0xc0010a8cc0 0xc0010a8cc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-kf7rq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kf7rq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kf7rq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:guojing-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0010a8d30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0010a8d60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:12 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:12 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:11 +0000 UTC  }],Message:,Reason:,HostIP:172.19.16.27,PodIP:10.33.0.207,StartTime:2018-12-27 01:34:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-27 01:34:12 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://cb95e67e3627522e169054ba00af238fdb221698e9ef481ed284656cbad72c71}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 27 01:34:15.740: INFO: Pod "nginx-deployment-555b55d965-nt98j" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-nt98j,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xfphn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xfphn/pods/nginx-deployment-555b55d965-nt98j,UID:831c04e3-0977-11e9-b34c-525400cd4ed0,ResourceVersion:3303,Generation:0,CreationTimestamp:2018-12-27 01:34:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 83157cc8-0977-11e9-b34c-525400cd4ed0 0xc0010a8e60 0xc0010a8e61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-kf7rq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kf7rq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kf7rq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:guojing-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0010a8ed0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0010a8ef0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:12 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:12 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:11 +0000 UTC  }],Message:,Reason:,HostIP:172.19.16.18,PodIP:10.33.2.62,StartTime:2018-12-27 01:34:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-27 01:34:12 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://223cffc0bb30554d8a593a8dac460fa72f42585342d042b66018c4c35a7a2837}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 27 01:34:15.740: INFO: Pod "nginx-deployment-555b55d965-p8t84" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-p8t84,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xfphn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xfphn/pods/nginx-deployment-555b55d965-p8t84,UID:831a0340-0977-11e9-b34c-525400cd4ed0,ResourceVersion:3307,Generation:0,CreationTimestamp:2018-12-27 01:34:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 83157cc8-0977-11e9-b34c-525400cd4ed0 0xc0010a8fb0 0xc0010a8fb1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-kf7rq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kf7rq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kf7rq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:guojing-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0010a90a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0010a90c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:12 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:12 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:11 +0000 UTC  }],Message:,Reason:,HostIP:172.19.16.18,PodIP:10.33.2.61,StartTime:2018-12-27 01:34:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-27 01:34:12 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://eb011e3efeb41e9fbcde91dc8c05d64d4f1814535a0dd6807d91b8a46269917e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 27 01:34:15.740: INFO: Pod "nginx-deployment-555b55d965-pgbvk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-pgbvk,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xfphn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xfphn/pods/nginx-deployment-555b55d965-pgbvk,UID:85830a07-0977-11e9-b34c-525400cd4ed0,ResourceVersion:3419,Generation:0,CreationTimestamp:2018-12-27 01:34:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 83157cc8-0977-11e9-b34c-525400cd4ed0 0xc0010a9180 0xc0010a9181}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-kf7rq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kf7rq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kf7rq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0010a91e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0010a9200}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 27 01:34:15.740: INFO: Pod "nginx-deployment-555b55d965-tswrh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-tswrh,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xfphn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xfphn/pods/nginx-deployment-555b55d965-tswrh,UID:8582f14c-0977-11e9-b34c-525400cd4ed0,ResourceVersion:3417,Generation:0,CreationTimestamp:2018-12-27 01:34:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 83157cc8-0977-11e9-b34c-525400cd4ed0 0xc0010a9517 0xc0010a9518}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-kf7rq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kf7rq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kf7rq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0010a9580} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0010a95a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 27 01:34:15.740: INFO: Pod "nginx-deployment-555b55d965-x6622" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-x6622,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xfphn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xfphn/pods/nginx-deployment-555b55d965-x6622,UID:83172859-0977-11e9-b34c-525400cd4ed0,ResourceVersion:3311,Generation:0,CreationTimestamp:2018-12-27 01:34:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 83157cc8-0977-11e9-b34c-525400cd4ed0 0xc0010a95f7 0xc0010a95f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-kf7rq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kf7rq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kf7rq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:guojing-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0010a9680} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0010a9700}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:12 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:12 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:11 +0000 UTC  }],Message:,Reason:,HostIP:172.19.16.27,PodIP:10.33.0.206,StartTime:2018-12-27 01:34:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-27 01:34:12 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://80e77ab9aff3cb065c67f73685b14d55db9c9a354e0ba5789d6e1c5cb0f701e4}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 27 01:34:15.740: INFO: Pod "nginx-deployment-555b55d965-zwgg8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-zwgg8,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xfphn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xfphn/pods/nginx-deployment-555b55d965-zwgg8,UID:858300ab-0977-11e9-b34c-525400cd4ed0,ResourceVersion:3421,Generation:0,CreationTimestamp:2018-12-27 01:34:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 83157cc8-0977-11e9-b34c-525400cd4ed0 0xc0010a97c0 0xc0010a97c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-kf7rq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kf7rq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kf7rq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0010a9820} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0010a9840}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 27 01:34:15.741: INFO: Pod "nginx-deployment-65bbdb5f8-6624f" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-6624f,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-xfphn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xfphn/pods/nginx-deployment-65bbdb5f8-6624f,UID:844be617-0977-11e9-b34c-525400cd4ed0,ResourceVersion:3358,Generation:0,CreationTimestamp:2018-12-27 01:34:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 84492d5f-0977-11e9-b34c-525400cd4ed0 0xc0010a98d7 0xc0010a98d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-kf7rq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kf7rq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kf7rq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:guojing-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0010a9950} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0010a9970}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:13 +0000 UTC  }],Message:,Reason:,HostIP:172.19.16.18,PodIP:,StartTime:2018-12-27 01:34:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 27 01:34:15.741: INFO: Pod "nginx-deployment-65bbdb5f8-8v4xm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-8v4xm,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-xfphn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xfphn/pods/nginx-deployment-65bbdb5f8-8v4xm,UID:84542237-0977-11e9-b34c-525400cd4ed0,ResourceVersion:3375,Generation:0,CreationTimestamp:2018-12-27 01:34:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 84492d5f-0977-11e9-b34c-525400cd4ed0 0xc0010a9a30 0xc0010a9a31}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-kf7rq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kf7rq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kf7rq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:guojing-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0010a9ab0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0010a9ad0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:13 +0000 UTC  }],Message:,Reason:,HostIP:172.19.16.36,PodIP:,StartTime:2018-12-27 01:34:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 27 01:34:15.741: INFO: Pod "nginx-deployment-65bbdb5f8-c8f7b" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-c8f7b,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-xfphn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xfphn/pods/nginx-deployment-65bbdb5f8-c8f7b,UID:8583003a-0977-11e9-b34c-525400cd4ed0,ResourceVersion:3418,Generation:0,CreationTimestamp:2018-12-27 01:34:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 84492d5f-0977-11e9-b34c-525400cd4ed0 0xc0010a9b90 0xc0010a9b91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-kf7rq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kf7rq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kf7rq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0010a9c00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0010a9c20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 27 01:34:15.741: INFO: Pod "nginx-deployment-65bbdb5f8-ff2jp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-ff2jp,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-xfphn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xfphn/pods/nginx-deployment-65bbdb5f8-ff2jp,UID:8582fc1f-0977-11e9-b34c-525400cd4ed0,ResourceVersion:3415,Generation:0,CreationTimestamp:2018-12-27 01:34:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 84492d5f-0977-11e9-b34c-525400cd4ed0 0xc0010a9c77 0xc0010a9c78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-kf7rq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kf7rq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kf7rq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0010a9ce0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0010a9d00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 27 01:34:15.742: INFO: Pod "nginx-deployment-65bbdb5f8-fmqmx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-fmqmx,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-xfphn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xfphn/pods/nginx-deployment-65bbdb5f8-fmqmx,UID:8449d948-0977-11e9-b34c-525400cd4ed0,ResourceVersion:3354,Generation:0,CreationTimestamp:2018-12-27 01:34:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 84492d5f-0977-11e9-b34c-525400cd4ed0 0xc0010a9d57 0xc0010a9d58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-kf7rq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kf7rq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kf7rq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:guojing-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0010a9dd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0010a9df0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:13 +0000 UTC  }],Message:,Reason:,HostIP:172.19.16.36,PodIP:,StartTime:2018-12-27 01:34:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 27 01:34:15.742: INFO: Pod "nginx-deployment-65bbdb5f8-gkvhg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-gkvhg,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-xfphn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xfphn/pods/nginx-deployment-65bbdb5f8-gkvhg,UID:85807bcd-0977-11e9-b34c-525400cd4ed0,ResourceVersion:3410,Generation:0,CreationTimestamp:2018-12-27 01:34:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 84492d5f-0977-11e9-b34c-525400cd4ed0 0xc0010a9eb0 0xc0010a9eb1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-kf7rq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kf7rq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kf7rq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:guojing-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0010a9f30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0010a9f50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:15 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 27 01:34:15.742: INFO: Pod "nginx-deployment-65bbdb5f8-ph9lg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-ph9lg,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-xfphn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xfphn/pods/nginx-deployment-65bbdb5f8-ph9lg,UID:84534e0e-0977-11e9-b34c-525400cd4ed0,ResourceVersion:3380,Generation:0,CreationTimestamp:2018-12-27 01:34:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 84492d5f-0977-11e9-b34c-525400cd4ed0 0xc0010a9fc0 0xc0010a9fc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-kf7rq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kf7rq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kf7rq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:guojing-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f44040} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f44070}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:13 +0000 UTC  }],Message:,Reason:,HostIP:172.19.16.18,PodIP:,StartTime:2018-12-27 01:34:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 27 01:34:15.742: INFO: Pod "nginx-deployment-65bbdb5f8-zxxph" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-zxxph,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-xfphn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xfphn/pods/nginx-deployment-65bbdb5f8-zxxph,UID:844be3a7-0977-11e9-b34c-525400cd4ed0,ResourceVersion:3361,Generation:0,CreationTimestamp:2018-12-27 01:34:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 84492d5f-0977-11e9-b34c-525400cd4ed0 0xc001f44210 0xc001f44211}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-kf7rq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kf7rq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kf7rq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:guojing-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f44290} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f442c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:13 +0000 UTC  }],Message:,Reason:,HostIP:172.19.16.27,PodIP:,StartTime:2018-12-27 01:34:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:34:15.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-xfphn" for this suite.
Dec 27 01:34:21.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:34:21.836: INFO: namespace: e2e-tests-deployment-xfphn, resource: bindings, ignored listing per whitelist
Dec 27 01:34:21.871: INFO: namespace e2e-tests-deployment-xfphn deletion completed in 6.113194064s

• [SLOW TEST:10.282 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:34:21.871: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec 27 01:34:21.925: INFO: Waiting up to 5m0s for pod "pod-8934352f-0977-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-emptydir-n42p2" to be "success or failure"
Dec 27 01:34:21.927: INFO: Pod "pod-8934352f-0977-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.046487ms
Dec 27 01:34:23.930: INFO: Pod "pod-8934352f-0977-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004888269s
Dec 27 01:34:25.932: INFO: Pod "pod-8934352f-0977-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.00743203s
Dec 27 01:34:27.934: INFO: Pod "pod-8934352f-0977-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009876339s
STEP: Saw pod success
Dec 27 01:34:27.935: INFO: Pod "pod-8934352f-0977-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 01:34:27.936: INFO: Trying to get logs from node guojing-1 pod pod-8934352f-0977-11e9-a1bd-0a580a2100c6 container test-container: <nil>
STEP: delete the pod
Dec 27 01:34:27.954: INFO: Waiting for pod pod-8934352f-0977-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 01:34:27.956: INFO: Pod pod-8934352f-0977-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:34:27.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-n42p2" for this suite.
Dec 27 01:34:33.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:34:33.988: INFO: namespace: e2e-tests-emptydir-n42p2, resource: bindings, ignored listing per whitelist
Dec 27 01:34:34.033: INFO: namespace e2e-tests-emptydir-n42p2 deletion completed in 6.074030553s

• [SLOW TEST:12.162 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:34:34.033: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Dec 27 01:34:36.097: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-90748050-0977-11e9-a1bd-0a580a2100c6,GenerateName:,Namespace:e2e-tests-events-v56nw,SelfLink:/api/v1/namespaces/e2e-tests-events-v56nw/pods/send-events-90748050-0977-11e9-a1bd-0a580a2100c6,UID:9074ede2-0977-11e9-9853-debd8636412e,ResourceVersion:3763,Generation:0,CreationTimestamp:2018-12-27 01:34:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 82323207,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-b8q9w {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-b8q9w,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-b8q9w true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:guojing-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001829df0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001829e10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:34:34 +0000 UTC  }],Message:,Reason:,HostIP:172.19.16.27,PodIP:10.33.0.217,StartTime:2018-12-27 01:34:34 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2018-12-27 01:34:34 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://ab2e533144d044b5264e11c970228a62f3faf0cee2d131f7074c3339c0596523}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Dec 27 01:34:38.100: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Dec 27 01:34:40.103: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:34:40.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-v56nw" for this suite.
Dec 27 01:35:20.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:35:20.165: INFO: namespace: e2e-tests-events-v56nw, resource: bindings, ignored listing per whitelist
Dec 27 01:35:20.184: INFO: namespace e2e-tests-events-v56nw deletion completed in 40.066486265s

• [SLOW TEST:46.151 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:35:20.184: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Dec 27 01:35:20.250: INFO: Pod name pod-release: Found 0 pods out of 1
Dec 27 01:35:25.253: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:35:26.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-9n4wm" for this suite.
Dec 27 01:35:32.278: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:35:32.285: INFO: namespace: e2e-tests-replication-controller-9n4wm, resource: bindings, ignored listing per whitelist
Dec 27 01:35:32.334: INFO: namespace e2e-tests-replication-controller-9n4wm deletion completed in 6.065629458s

• [SLOW TEST:12.150 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:35:32.334: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-b33498ff-0977-11e9-a1bd-0a580a2100c6
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-b33498ff-0977-11e9-a1bd-0a580a2100c6
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:35:36.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-j4d46" for this suite.
Dec 27 01:35:58.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:35:58.473: INFO: namespace: e2e-tests-projected-j4d46, resource: bindings, ignored listing per whitelist
Dec 27 01:35:58.500: INFO: namespace e2e-tests-projected-j4d46 deletion completed in 22.071091309s

• [SLOW TEST:26.166 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:35:58.500: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec 27 01:35:58.549: INFO: PodSpec: initContainers in spec.initContainers
Dec 27 01:36:42.994: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-c2cd2d82-0977-11e9-a1bd-0a580a2100c6", GenerateName:"", Namespace:"e2e-tests-init-container-54x7c", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-54x7c/pods/pod-init-c2cd2d82-0977-11e9-a1bd-0a580a2100c6", UID:"c2cda8c5-0977-11e9-9853-debd8636412e", ResourceVersion:"4081", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63681471358, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"549549211"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-8l4r9", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001fc1c80), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-8l4r9", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-8l4r9", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-8l4r9", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001a08758), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"guojing-3", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc000c43d40), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001a087f0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001a08810)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001a08818), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001a0881c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681471358, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681471358, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681471358, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681471358, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.19.16.36", PodIP:"10.33.1.50", StartTime:(*v1.Time)(0xc001914e00), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0018f2f50)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0018f2fc0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:2a03a6059f21e150ae84b0973863609494aad70f0a80eaeb64bddd8d92465812", ContainerID:"docker://7d22713f9c2c5b98e6c6dfbbae4055e01747e500af48b521ffabec0cbc806213"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001914e40), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001914e20), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:36:42.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-54x7c" for this suite.
Dec 27 01:37:05.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:37:05.020: INFO: namespace: e2e-tests-init-container-54x7c, resource: bindings, ignored listing per whitelist
Dec 27 01:37:05.065: INFO: namespace e2e-tests-init-container-54x7c deletion completed in 22.066818776s

• [SLOW TEST:66.565 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:37:05.065: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 27 01:37:05.120: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ea7a008d-0977-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-downward-api-x6brm" to be "success or failure"
Dec 27 01:37:05.122: INFO: Pod "downwardapi-volume-ea7a008d-0977-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.839865ms
Dec 27 01:37:07.125: INFO: Pod "downwardapi-volume-ea7a008d-0977-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004464553s
STEP: Saw pod success
Dec 27 01:37:07.125: INFO: Pod "downwardapi-volume-ea7a008d-0977-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 01:37:07.127: INFO: Trying to get logs from node guojing-1 pod downwardapi-volume-ea7a008d-0977-11e9-a1bd-0a580a2100c6 container client-container: <nil>
STEP: delete the pod
Dec 27 01:37:07.141: INFO: Waiting for pod downwardapi-volume-ea7a008d-0977-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 01:37:07.143: INFO: Pod downwardapi-volume-ea7a008d-0977-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:37:07.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-x6brm" for this suite.
Dec 27 01:37:13.155: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:37:13.190: INFO: namespace: e2e-tests-downward-api-x6brm, resource: bindings, ignored listing per whitelist
Dec 27 01:37:13.211: INFO: namespace e2e-tests-downward-api-x6brm deletion completed in 6.065341338s

• [SLOW TEST:8.146 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:37:13.211: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 27 01:37:13.264: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ef54846b-0977-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-downward-api-dm784" to be "success or failure"
Dec 27 01:37:13.267: INFO: Pod "downwardapi-volume-ef54846b-0977-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.94075ms
Dec 27 01:37:15.269: INFO: Pod "downwardapi-volume-ef54846b-0977-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005645262s
STEP: Saw pod success
Dec 27 01:37:15.269: INFO: Pod "downwardapi-volume-ef54846b-0977-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 01:37:15.271: INFO: Trying to get logs from node guojing-2 pod downwardapi-volume-ef54846b-0977-11e9-a1bd-0a580a2100c6 container client-container: <nil>
STEP: delete the pod
Dec 27 01:37:15.286: INFO: Waiting for pod downwardapi-volume-ef54846b-0977-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 01:37:15.288: INFO: Pod downwardapi-volume-ef54846b-0977-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:37:15.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-dm784" for this suite.
Dec 27 01:37:21.300: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:37:21.313: INFO: namespace: e2e-tests-downward-api-dm784, resource: bindings, ignored listing per whitelist
Dec 27 01:37:21.358: INFO: namespace e2e-tests-downward-api-dm784 deletion completed in 6.066448111s

• [SLOW TEST:8.146 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:37:21.358: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec 27 01:37:21.413: INFO: Waiting up to 5m0s for pod "pod-f43037fe-0977-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-emptydir-5p2kk" to be "success or failure"
Dec 27 01:37:21.415: INFO: Pod "pod-f43037fe-0977-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.745161ms
Dec 27 01:37:23.418: INFO: Pod "pod-f43037fe-0977-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00443103s
STEP: Saw pod success
Dec 27 01:37:23.418: INFO: Pod "pod-f43037fe-0977-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 01:37:23.419: INFO: Trying to get logs from node guojing-3 pod pod-f43037fe-0977-11e9-a1bd-0a580a2100c6 container test-container: <nil>
STEP: delete the pod
Dec 27 01:37:23.436: INFO: Waiting for pod pod-f43037fe-0977-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 01:37:23.438: INFO: Pod pod-f43037fe-0977-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:37:23.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5p2kk" for this suite.
Dec 27 01:37:29.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:37:29.500: INFO: namespace: e2e-tests-emptydir-5p2kk, resource: bindings, ignored listing per whitelist
Dec 27 01:37:29.507: INFO: namespace e2e-tests-emptydir-5p2kk deletion completed in 6.066307253s

• [SLOW TEST:8.149 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:37:29.507: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W1227 01:37:39.575095      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 27 01:37:39.575: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:37:39.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-p7l5z" for this suite.
Dec 27 01:37:45.586: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:37:45.627: INFO: namespace: e2e-tests-gc-p7l5z, resource: bindings, ignored listing per whitelist
Dec 27 01:37:45.645: INFO: namespace e2e-tests-gc-p7l5z deletion completed in 6.067847692s

• [SLOW TEST:16.138 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:37:45.645: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Dec 27 01:37:45.702: INFO: Waiting up to 5m0s for pod "client-containers-02aa6463-0978-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-containers-gcnrp" to be "success or failure"
Dec 27 01:37:45.704: INFO: Pod "client-containers-02aa6463-0978-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.187566ms
Dec 27 01:37:47.707: INFO: Pod "client-containers-02aa6463-0978-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004896446s
STEP: Saw pod success
Dec 27 01:37:47.707: INFO: Pod "client-containers-02aa6463-0978-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 01:37:47.709: INFO: Trying to get logs from node guojing-3 pod client-containers-02aa6463-0978-11e9-a1bd-0a580a2100c6 container test-container: <nil>
STEP: delete the pod
Dec 27 01:37:47.725: INFO: Waiting for pod client-containers-02aa6463-0978-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 01:37:47.727: INFO: Pod client-containers-02aa6463-0978-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:37:47.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-gcnrp" for this suite.
Dec 27 01:37:53.738: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:37:53.791: INFO: namespace: e2e-tests-containers-gcnrp, resource: bindings, ignored listing per whitelist
Dec 27 01:37:53.796: INFO: namespace e2e-tests-containers-gcnrp deletion completed in 6.065694617s

• [SLOW TEST:8.151 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:37:53.796: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-rq8k9/secret-test-0785731e-0978-11e9-a1bd-0a580a2100c6
STEP: Creating a pod to test consume secrets
Dec 27 01:37:53.851: INFO: Waiting up to 5m0s for pod "pod-configmaps-07862f51-0978-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-secrets-rq8k9" to be "success or failure"
Dec 27 01:37:53.853: INFO: Pod "pod-configmaps-07862f51-0978-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.893964ms
Dec 27 01:37:55.856: INFO: Pod "pod-configmaps-07862f51-0978-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004269888s
STEP: Saw pod success
Dec 27 01:37:55.856: INFO: Pod "pod-configmaps-07862f51-0978-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 01:37:55.857: INFO: Trying to get logs from node guojing-2 pod pod-configmaps-07862f51-0978-11e9-a1bd-0a580a2100c6 container env-test: <nil>
STEP: delete the pod
Dec 27 01:37:55.873: INFO: Waiting for pod pod-configmaps-07862f51-0978-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 01:37:55.875: INFO: Pod pod-configmaps-07862f51-0978-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:37:55.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-rq8k9" for this suite.
Dec 27 01:38:01.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:38:01.904: INFO: namespace: e2e-tests-secrets-rq8k9, resource: bindings, ignored listing per whitelist
Dec 27 01:38:01.949: INFO: namespace e2e-tests-secrets-rq8k9 deletion completed in 6.071847661s

• [SLOW TEST:8.153 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:38:01.949: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 27 01:38:02.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-p5mvt'
Dec 27 01:38:06.360: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 27 01:38:06.360: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Dec 27 01:38:06.362: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-p5mvt'
Dec 27 01:38:06.431: INFO: stderr: ""
Dec 27 01:38:06.431: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:38:06.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-p5mvt" for this suite.
Dec 27 01:38:28.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:38:28.501: INFO: namespace: e2e-tests-kubectl-p5mvt, resource: bindings, ignored listing per whitelist
Dec 27 01:38:28.510: INFO: namespace e2e-tests-kubectl-p5mvt deletion completed in 22.073683052s

• [SLOW TEST:26.561 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:38:28.510: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:38:30.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-zv2tn" for this suite.
Dec 27 01:38:36.614: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:38:36.656: INFO: namespace: e2e-tests-emptydir-wrapper-zv2tn, resource: bindings, ignored listing per whitelist
Dec 27 01:38:36.671: INFO: namespace e2e-tests-emptydir-wrapper-zv2tn deletion completed in 6.064578308s

• [SLOW TEST:8.161 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:38:36.671: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-2114054c-0978-11e9-a1bd-0a580a2100c6
STEP: Creating a pod to test consume secrets
Dec 27 01:38:36.731: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2115243c-0978-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-projected-hl9c7" to be "success or failure"
Dec 27 01:38:36.733: INFO: Pod "pod-projected-secrets-2115243c-0978-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.941101ms
Dec 27 01:38:38.736: INFO: Pod "pod-projected-secrets-2115243c-0978-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004532009s
STEP: Saw pod success
Dec 27 01:38:38.736: INFO: Pod "pod-projected-secrets-2115243c-0978-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 01:38:38.738: INFO: Trying to get logs from node guojing-1 pod pod-projected-secrets-2115243c-0978-11e9-a1bd-0a580a2100c6 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 27 01:38:38.755: INFO: Waiting for pod pod-projected-secrets-2115243c-0978-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 01:38:38.757: INFO: Pod pod-projected-secrets-2115243c-0978-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:38:38.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hl9c7" for this suite.
Dec 27 01:38:44.769: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:38:44.816: INFO: namespace: e2e-tests-projected-hl9c7, resource: bindings, ignored listing per whitelist
Dec 27 01:38:44.827: INFO: namespace e2e-tests-projected-hl9c7 deletion completed in 6.066704491s

• [SLOW TEST:8.156 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:38:44.827: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Dec 27 01:38:44.884: INFO: Waiting up to 5m0s for pod "client-containers-25f0c45d-0978-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-containers-srkp9" to be "success or failure"
Dec 27 01:38:44.886: INFO: Pod "client-containers-25f0c45d-0978-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.945386ms
Dec 27 01:38:46.888: INFO: Pod "client-containers-25f0c45d-0978-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0045907s
STEP: Saw pod success
Dec 27 01:38:46.888: INFO: Pod "client-containers-25f0c45d-0978-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 01:38:46.890: INFO: Trying to get logs from node guojing-2 pod client-containers-25f0c45d-0978-11e9-a1bd-0a580a2100c6 container test-container: <nil>
STEP: delete the pod
Dec 27 01:38:46.907: INFO: Waiting for pod client-containers-25f0c45d-0978-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 01:38:46.909: INFO: Pod client-containers-25f0c45d-0978-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:38:46.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-srkp9" for this suite.
Dec 27 01:38:52.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:38:52.967: INFO: namespace: e2e-tests-containers-srkp9, resource: bindings, ignored listing per whitelist
Dec 27 01:38:52.979: INFO: namespace e2e-tests-containers-srkp9 deletion completed in 6.067387482s

• [SLOW TEST:8.152 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:38:52.979: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-j7b47
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 27 01:38:53.023: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 27 01:39:15.084: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.33.1.56:8080/dial?request=hostName&protocol=udp&host=10.33.1.55&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-j7b47 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 27 01:39:15.084: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
Dec 27 01:39:15.168: INFO: Waiting for endpoints: map[]
Dec 27 01:39:15.170: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.33.1.56:8080/dial?request=hostName&protocol=udp&host=10.33.0.223&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-j7b47 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 27 01:39:15.170: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
Dec 27 01:39:15.252: INFO: Waiting for endpoints: map[]
Dec 27 01:39:15.254: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.33.1.56:8080/dial?request=hostName&protocol=udp&host=10.33.2.75&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-j7b47 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 27 01:39:15.254: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
Dec 27 01:39:15.330: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:39:15.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-j7b47" for this suite.
Dec 27 01:39:37.342: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:39:37.376: INFO: namespace: e2e-tests-pod-network-test-j7b47, resource: bindings, ignored listing per whitelist
Dec 27 01:39:37.405: INFO: namespace e2e-tests-pod-network-test-j7b47 deletion completed in 22.0714322s

• [SLOW TEST:44.425 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:39:37.405: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-4cdg
STEP: Creating a pod to test atomic-volume-subpath
Dec 27 01:39:37.467: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-4cdg" in namespace "e2e-tests-subpath-2zrbd" to be "success or failure"
Dec 27 01:39:37.469: INFO: Pod "pod-subpath-test-configmap-4cdg": Phase="Pending", Reason="", readiness=false. Elapsed: 1.834766ms
Dec 27 01:39:39.472: INFO: Pod "pod-subpath-test-configmap-4cdg": Phase="Running", Reason="", readiness=false. Elapsed: 2.004546807s
Dec 27 01:39:41.475: INFO: Pod "pod-subpath-test-configmap-4cdg": Phase="Running", Reason="", readiness=false. Elapsed: 4.007057554s
Dec 27 01:39:43.477: INFO: Pod "pod-subpath-test-configmap-4cdg": Phase="Running", Reason="", readiness=false. Elapsed: 6.009672614s
Dec 27 01:39:45.480: INFO: Pod "pod-subpath-test-configmap-4cdg": Phase="Running", Reason="", readiness=false. Elapsed: 8.012491463s
Dec 27 01:39:47.483: INFO: Pod "pod-subpath-test-configmap-4cdg": Phase="Running", Reason="", readiness=false. Elapsed: 10.015044674s
Dec 27 01:39:49.485: INFO: Pod "pod-subpath-test-configmap-4cdg": Phase="Running", Reason="", readiness=false. Elapsed: 12.017556388s
Dec 27 01:39:51.488: INFO: Pod "pod-subpath-test-configmap-4cdg": Phase="Running", Reason="", readiness=false. Elapsed: 14.020635558s
Dec 27 01:39:53.491: INFO: Pod "pod-subpath-test-configmap-4cdg": Phase="Running", Reason="", readiness=false. Elapsed: 16.023406959s
Dec 27 01:39:55.494: INFO: Pod "pod-subpath-test-configmap-4cdg": Phase="Running", Reason="", readiness=false. Elapsed: 18.026612128s
Dec 27 01:39:57.497: INFO: Pod "pod-subpath-test-configmap-4cdg": Phase="Running", Reason="", readiness=false. Elapsed: 20.029440756s
Dec 27 01:39:59.500: INFO: Pod "pod-subpath-test-configmap-4cdg": Phase="Running", Reason="", readiness=false. Elapsed: 22.032148843s
Dec 27 01:40:01.503: INFO: Pod "pod-subpath-test-configmap-4cdg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.035359384s
STEP: Saw pod success
Dec 27 01:40:01.503: INFO: Pod "pod-subpath-test-configmap-4cdg" satisfied condition "success or failure"
Dec 27 01:40:01.505: INFO: Trying to get logs from node guojing-2 pod pod-subpath-test-configmap-4cdg container test-container-subpath-configmap-4cdg: <nil>
STEP: delete the pod
Dec 27 01:40:01.523: INFO: Waiting for pod pod-subpath-test-configmap-4cdg to disappear
Dec 27 01:40:01.526: INFO: Pod pod-subpath-test-configmap-4cdg no longer exists
STEP: Deleting pod pod-subpath-test-configmap-4cdg
Dec 27 01:40:01.526: INFO: Deleting pod "pod-subpath-test-configmap-4cdg" in namespace "e2e-tests-subpath-2zrbd"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:40:01.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-2zrbd" for this suite.
Dec 27 01:40:07.542: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:40:07.568: INFO: namespace: e2e-tests-subpath-2zrbd, resource: bindings, ignored listing per whitelist
Dec 27 01:40:07.600: INFO: namespace e2e-tests-subpath-2zrbd deletion completed in 6.067826729s

• [SLOW TEST:30.196 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:40:07.601: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Dec 27 01:40:07.656: INFO: Waiting up to 5m0s for pod "pod-5746eaeb-0978-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-emptydir-lp87l" to be "success or failure"
Dec 27 01:40:07.659: INFO: Pod "pod-5746eaeb-0978-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.291866ms
Dec 27 01:40:09.662: INFO: Pod "pod-5746eaeb-0978-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005096538s
STEP: Saw pod success
Dec 27 01:40:09.662: INFO: Pod "pod-5746eaeb-0978-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 01:40:09.663: INFO: Trying to get logs from node guojing-3 pod pod-5746eaeb-0978-11e9-a1bd-0a580a2100c6 container test-container: <nil>
STEP: delete the pod
Dec 27 01:40:09.687: INFO: Waiting for pod pod-5746eaeb-0978-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 01:40:09.689: INFO: Pod pod-5746eaeb-0978-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:40:09.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-lp87l" for this suite.
Dec 27 01:40:15.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:40:15.735: INFO: namespace: e2e-tests-emptydir-lp87l, resource: bindings, ignored listing per whitelist
Dec 27 01:40:15.764: INFO: namespace e2e-tests-emptydir-lp87l deletion completed in 6.072750809s

• [SLOW TEST:8.164 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:40:15.765: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-nqkqv in namespace e2e-tests-proxy-j5xmj
I1227 01:40:15.836749      18 runners.go:184] Created replication controller with name: proxy-service-nqkqv, namespace: e2e-tests-proxy-j5xmj, replica count: 1
I1227 01:40:16.887104      18 runners.go:184] proxy-service-nqkqv Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1227 01:40:17.887302      18 runners.go:184] proxy-service-nqkqv Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1227 01:40:18.887475      18 runners.go:184] proxy-service-nqkqv Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1227 01:40:19.887654      18 runners.go:184] proxy-service-nqkqv Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1227 01:40:20.887826      18 runners.go:184] proxy-service-nqkqv Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1227 01:40:21.888037      18 runners.go:184] proxy-service-nqkqv Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1227 01:40:22.888231      18 runners.go:184] proxy-service-nqkqv Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 27 01:40:22.890: INFO: setup took 7.080563251s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Dec 27 01:40:22.894: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:160/proxy/: foo (200; 4.153309ms)
Dec 27 01:40:22.894: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/proxy-service-nqkqv:portname1/proxy/: foo (200; 4.360989ms)
Dec 27 01:40:22.895: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:1080/proxy/rewri... (200; 4.486165ms)
Dec 27 01:40:22.895: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:162/proxy/: bar (200; 5.168439ms)
Dec 27 01:40:22.895: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:162/proxy/: bar (200; 5.198872ms)
Dec 27 01:40:22.895: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk/proxy/rewriteme"... (200; 5.316872ms)
Dec 27 01:40:22.896: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/http:proxy-service-nqkqv:portname1/proxy/: foo (200; 5.438937ms)
Dec 27 01:40:22.896: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:160/proxy/: foo (200; 5.489081ms)
Dec 27 01:40:22.896: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/proxy-service-nqkqv:portname2/proxy/: bar (200; 5.442456ms)
Dec 27 01:40:22.896: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:1080/proxy/... (200; 5.69139ms)
Dec 27 01:40:22.896: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/http:proxy-service-nqkqv:portname2/proxy/: bar (200; 5.641861ms)
Dec 27 01:40:22.900: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:460/proxy/: tls baz (200; 9.865884ms)
Dec 27 01:40:22.902: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/https:proxy-service-nqkqv:tlsportname2/proxy/: tls qux (200; 11.618123ms)
Dec 27 01:40:22.902: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:462/proxy/: tls qux (200; 12.17309ms)
Dec 27 01:40:22.903: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:443/proxy/... (200; 12.522016ms)
Dec 27 01:40:22.905: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/https:proxy-service-nqkqv:tlsportname1/proxy/: tls baz (200; 14.316984ms)
Dec 27 01:40:22.907: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:460/proxy/: tls baz (200; 2.44818ms)
Dec 27 01:40:22.907: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:160/proxy/: foo (200; 2.592212ms)
Dec 27 01:40:22.907: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:1080/proxy/... (200; 2.658224ms)
Dec 27 01:40:22.908: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:160/proxy/: foo (200; 3.605333ms)
Dec 27 01:40:22.908: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk/proxy/rewriteme"... (200; 3.67333ms)
Dec 27 01:40:22.909: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:162/proxy/: bar (200; 3.957594ms)
Dec 27 01:40:22.909: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:443/proxy/... (200; 3.912061ms)
Dec 27 01:40:22.909: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/proxy-service-nqkqv:portname2/proxy/: bar (200; 3.870412ms)
Dec 27 01:40:22.909: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:462/proxy/: tls qux (200; 4.099747ms)
Dec 27 01:40:22.909: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/proxy-service-nqkqv:portname1/proxy/: foo (200; 4.187431ms)
Dec 27 01:40:22.909: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:1080/proxy/rewri... (200; 4.108337ms)
Dec 27 01:40:22.909: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/http:proxy-service-nqkqv:portname1/proxy/: foo (200; 4.283123ms)
Dec 27 01:40:22.909: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:162/proxy/: bar (200; 4.209592ms)
Dec 27 01:40:22.909: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/https:proxy-service-nqkqv:tlsportname1/proxy/: tls baz (200; 4.766989ms)
Dec 27 01:40:22.910: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/https:proxy-service-nqkqv:tlsportname2/proxy/: tls qux (200; 5.059033ms)
Dec 27 01:40:22.910: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/http:proxy-service-nqkqv:portname2/proxy/: bar (200; 5.292023ms)
Dec 27 01:40:22.912: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:160/proxy/: foo (200; 2.085204ms)
Dec 27 01:40:22.913: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:462/proxy/: tls qux (200; 2.538794ms)
Dec 27 01:40:22.913: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:160/proxy/: foo (200; 2.836048ms)
Dec 27 01:40:22.913: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:460/proxy/: tls baz (200; 2.810787ms)
Dec 27 01:40:22.913: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk/proxy/rewriteme"... (200; 3.094485ms)
Dec 27 01:40:22.913: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:1080/proxy/rewri... (200; 2.794956ms)
Dec 27 01:40:22.915: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:162/proxy/: bar (200; 4.152236ms)
Dec 27 01:40:22.915: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:162/proxy/: bar (200; 4.050726ms)
Dec 27 01:40:22.915: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/https:proxy-service-nqkqv:tlsportname1/proxy/: tls baz (200; 4.832555ms)
Dec 27 01:40:22.915: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/proxy-service-nqkqv:portname2/proxy/: bar (200; 4.56721ms)
Dec 27 01:40:22.915: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:443/proxy/... (200; 4.206441ms)
Dec 27 01:40:22.915: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/proxy-service-nqkqv:portname1/proxy/: foo (200; 4.823165ms)
Dec 27 01:40:22.915: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:1080/proxy/... (200; 4.547991ms)
Dec 27 01:40:22.915: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/http:proxy-service-nqkqv:portname2/proxy/: bar (200; 5.153398ms)
Dec 27 01:40:22.916: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/http:proxy-service-nqkqv:portname1/proxy/: foo (200; 4.584711ms)
Dec 27 01:40:22.916: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/https:proxy-service-nqkqv:tlsportname2/proxy/: tls qux (200; 4.696419ms)
Dec 27 01:40:22.919: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:160/proxy/: foo (200; 3.257923ms)
Dec 27 01:40:22.919: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:443/proxy/... (200; 3.501096ms)
Dec 27 01:40:22.920: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:162/proxy/: bar (200; 3.68985ms)
Dec 27 01:40:22.920: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:162/proxy/: bar (200; 3.53938ms)
Dec 27 01:40:22.922: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:462/proxy/: tls qux (200; 5.442882ms)
Dec 27 01:40:22.922: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:460/proxy/: tls baz (200; 5.209122ms)
Dec 27 01:40:22.923: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/http:proxy-service-nqkqv:portname2/proxy/: bar (200; 6.445609ms)
Dec 27 01:40:22.923: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:1080/proxy/... (200; 5.852415ms)
Dec 27 01:40:22.923: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/http:proxy-service-nqkqv:portname1/proxy/: foo (200; 6.762001ms)
Dec 27 01:40:22.923: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:160/proxy/: foo (200; 6.340124ms)
Dec 27 01:40:22.923: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/https:proxy-service-nqkqv:tlsportname2/proxy/: tls qux (200; 6.734557ms)
Dec 27 01:40:22.923: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk/proxy/rewriteme"... (200; 6.424536ms)
Dec 27 01:40:22.923: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/https:proxy-service-nqkqv:tlsportname1/proxy/: tls baz (200; 6.585184ms)
Dec 27 01:40:22.923: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/proxy-service-nqkqv:portname1/proxy/: foo (200; 6.497379ms)
Dec 27 01:40:22.923: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/proxy-service-nqkqv:portname2/proxy/: bar (200; 6.445176ms)
Dec 27 01:40:22.923: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:1080/proxy/rewri... (200; 6.634625ms)
Dec 27 01:40:22.926: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:1080/proxy/... (200; 2.793415ms)
Dec 27 01:40:22.926: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:460/proxy/: tls baz (200; 2.932725ms)
Dec 27 01:40:22.926: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk/proxy/rewriteme"... (200; 2.858566ms)
Dec 27 01:40:22.928: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:162/proxy/: bar (200; 4.412421ms)
Dec 27 01:40:22.928: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:462/proxy/: tls qux (200; 4.832064ms)
Dec 27 01:40:22.928: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:160/proxy/: foo (200; 4.834738ms)
Dec 27 01:40:22.928: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:1080/proxy/rewri... (200; 4.782864ms)
Dec 27 01:40:22.928: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:160/proxy/: foo (200; 4.94199ms)
Dec 27 01:40:22.928: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/http:proxy-service-nqkqv:portname1/proxy/: foo (200; 4.985072ms)
Dec 27 01:40:22.929: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:162/proxy/: bar (200; 5.139203ms)
Dec 27 01:40:22.929: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:443/proxy/... (200; 5.283213ms)
Dec 27 01:40:22.930: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/https:proxy-service-nqkqv:tlsportname2/proxy/: tls qux (200; 6.360568ms)
Dec 27 01:40:22.930: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/proxy-service-nqkqv:portname1/proxy/: foo (200; 6.622406ms)
Dec 27 01:40:22.930: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/proxy-service-nqkqv:portname2/proxy/: bar (200; 6.723392ms)
Dec 27 01:40:22.930: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/http:proxy-service-nqkqv:portname2/proxy/: bar (200; 7.010732ms)
Dec 27 01:40:22.930: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/https:proxy-service-nqkqv:tlsportname1/proxy/: tls baz (200; 7.047414ms)
Dec 27 01:40:22.935: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:162/proxy/: bar (200; 4.454129ms)
Dec 27 01:40:22.936: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:462/proxy/: tls qux (200; 4.888222ms)
Dec 27 01:40:22.936: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:160/proxy/: foo (200; 5.340418ms)
Dec 27 01:40:22.936: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:160/proxy/: foo (200; 5.011521ms)
Dec 27 01:40:22.936: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:162/proxy/: bar (200; 5.311188ms)
Dec 27 01:40:22.936: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk/proxy/rewriteme"... (200; 5.107866ms)
Dec 27 01:40:22.936: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/https:proxy-service-nqkqv:tlsportname2/proxy/: tls qux (200; 5.241703ms)
Dec 27 01:40:22.937: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:1080/proxy/... (200; 4.990612ms)
Dec 27 01:40:22.937: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:443/proxy/... (200; 5.083757ms)
Dec 27 01:40:22.937: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:460/proxy/: tls baz (200; 5.363426ms)
Dec 27 01:40:22.937: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/http:proxy-service-nqkqv:portname1/proxy/: foo (200; 5.94575ms)
Dec 27 01:40:22.937: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:1080/proxy/rewri... (200; 5.479582ms)
Dec 27 01:40:22.938: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/http:proxy-service-nqkqv:portname2/proxy/: bar (200; 6.519395ms)
Dec 27 01:40:22.938: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/proxy-service-nqkqv:portname1/proxy/: foo (200; 6.847307ms)
Dec 27 01:40:22.938: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/proxy-service-nqkqv:portname2/proxy/: bar (200; 6.787668ms)
Dec 27 01:40:22.938: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/https:proxy-service-nqkqv:tlsportname1/proxy/: tls baz (200; 7.274334ms)
Dec 27 01:40:22.942: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:162/proxy/: bar (200; 3.512207ms)
Dec 27 01:40:22.942: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:462/proxy/: tls qux (200; 3.699323ms)
Dec 27 01:40:22.943: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk/proxy/rewriteme"... (200; 3.853204ms)
Dec 27 01:40:22.943: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:160/proxy/: foo (200; 3.867358ms)
Dec 27 01:40:22.944: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:1080/proxy/rewri... (200; 5.356634ms)
Dec 27 01:40:22.945: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/http:proxy-service-nqkqv:portname2/proxy/: bar (200; 5.996899ms)
Dec 27 01:40:22.945: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:1080/proxy/... (200; 5.423504ms)
Dec 27 01:40:22.945: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:460/proxy/: tls baz (200; 5.490322ms)
Dec 27 01:40:22.945: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:160/proxy/: foo (200; 5.134839ms)
Dec 27 01:40:22.945: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/https:proxy-service-nqkqv:tlsportname1/proxy/: tls baz (200; 5.979981ms)
Dec 27 01:40:22.945: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:443/proxy/... (200; 5.34337ms)
Dec 27 01:40:22.945: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:162/proxy/: bar (200; 5.415945ms)
Dec 27 01:40:22.945: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/proxy-service-nqkqv:portname1/proxy/: foo (200; 5.73536ms)
Dec 27 01:40:22.945: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/https:proxy-service-nqkqv:tlsportname2/proxy/: tls qux (200; 5.416136ms)
Dec 27 01:40:22.945: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/http:proxy-service-nqkqv:portname1/proxy/: foo (200; 5.879687ms)
Dec 27 01:40:22.945: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/proxy-service-nqkqv:portname2/proxy/: bar (200; 6.323168ms)
Dec 27 01:40:22.949: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:460/proxy/: tls baz (200; 3.565707ms)
Dec 27 01:40:22.949: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:443/proxy/... (200; 3.840205ms)
Dec 27 01:40:22.949: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:1080/proxy/... (200; 4.003854ms)
Dec 27 01:40:22.949: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:162/proxy/: bar (200; 3.950638ms)
Dec 27 01:40:22.951: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:160/proxy/: foo (200; 4.772275ms)
Dec 27 01:40:22.951: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:160/proxy/: foo (200; 5.296358ms)
Dec 27 01:40:22.951: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk/proxy/rewriteme"... (200; 5.106198ms)
Dec 27 01:40:22.951: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:162/proxy/: bar (200; 5.601996ms)
Dec 27 01:40:22.952: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/https:proxy-service-nqkqv:tlsportname1/proxy/: tls baz (200; 5.622389ms)
Dec 27 01:40:22.952: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/https:proxy-service-nqkqv:tlsportname2/proxy/: tls qux (200; 6.000179ms)
Dec 27 01:40:22.952: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/http:proxy-service-nqkqv:portname2/proxy/: bar (200; 5.79893ms)
Dec 27 01:40:22.952: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/proxy-service-nqkqv:portname1/proxy/: foo (200; 5.443128ms)
Dec 27 01:40:22.952: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:462/proxy/: tls qux (200; 5.585978ms)
Dec 27 01:40:22.952: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:1080/proxy/rewri... (200; 5.41614ms)
Dec 27 01:40:22.952: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/http:proxy-service-nqkqv:portname1/proxy/: foo (200; 6.240779ms)
Dec 27 01:40:22.957: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/proxy-service-nqkqv:portname2/proxy/: bar (200; 10.839977ms)
Dec 27 01:40:22.959: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:462/proxy/: tls qux (200; 2.175369ms)
Dec 27 01:40:22.960: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:443/proxy/... (200; 2.935471ms)
Dec 27 01:40:22.961: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:1080/proxy/rewri... (200; 3.517211ms)
Dec 27 01:40:22.961: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:162/proxy/: bar (200; 3.723838ms)
Dec 27 01:40:22.963: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:162/proxy/: bar (200; 5.563129ms)
Dec 27 01:40:22.963: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:1080/proxy/... (200; 5.406456ms)
Dec 27 01:40:22.963: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk/proxy/rewriteme"... (200; 5.535014ms)
Dec 27 01:40:22.963: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:460/proxy/: tls baz (200; 5.452002ms)
Dec 27 01:40:22.963: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:160/proxy/: foo (200; 5.563147ms)
Dec 27 01:40:22.963: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:160/proxy/: foo (200; 5.786176ms)
Dec 27 01:40:22.963: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/http:proxy-service-nqkqv:portname2/proxy/: bar (200; 6.213471ms)
Dec 27 01:40:22.964: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/https:proxy-service-nqkqv:tlsportname2/proxy/: tls qux (200; 6.703568ms)
Dec 27 01:40:22.964: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/proxy-service-nqkqv:portname1/proxy/: foo (200; 6.830272ms)
Dec 27 01:40:22.964: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/https:proxy-service-nqkqv:tlsportname1/proxy/: tls baz (200; 6.952262ms)
Dec 27 01:40:22.964: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/proxy-service-nqkqv:portname2/proxy/: bar (200; 6.842641ms)
Dec 27 01:40:22.964: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/http:proxy-service-nqkqv:portname1/proxy/: foo (200; 6.972223ms)
Dec 27 01:40:22.966: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:462/proxy/: tls qux (200; 2.029393ms)
Dec 27 01:40:22.969: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/http:proxy-service-nqkqv:portname1/proxy/: foo (200; 4.423947ms)
Dec 27 01:40:22.969: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:443/proxy/... (200; 4.326412ms)
Dec 27 01:40:22.969: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:162/proxy/: bar (200; 4.832576ms)
Dec 27 01:40:22.970: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:1080/proxy/rewri... (200; 5.172518ms)
Dec 27 01:40:22.970: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:160/proxy/: foo (200; 5.106819ms)
Dec 27 01:40:22.970: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:1080/proxy/... (200; 5.231891ms)
Dec 27 01:40:22.970: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/http:proxy-service-nqkqv:portname2/proxy/: bar (200; 5.570561ms)
Dec 27 01:40:22.970: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:162/proxy/: bar (200; 5.503998ms)
Dec 27 01:40:22.970: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk/proxy/rewriteme"... (200; 5.482459ms)
Dec 27 01:40:22.970: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:160/proxy/: foo (200; 5.55761ms)
Dec 27 01:40:22.970: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/proxy-service-nqkqv:portname2/proxy/: bar (200; 5.665166ms)
Dec 27 01:40:22.970: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:460/proxy/: tls baz (200; 5.627462ms)
Dec 27 01:40:22.971: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/proxy-service-nqkqv:portname1/proxy/: foo (200; 6.236138ms)
Dec 27 01:40:22.971: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/https:proxy-service-nqkqv:tlsportname2/proxy/: tls qux (200; 6.2634ms)
Dec 27 01:40:22.971: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/https:proxy-service-nqkqv:tlsportname1/proxy/: tls baz (200; 6.330322ms)
Dec 27 01:40:22.973: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:162/proxy/: bar (200; 2.38078ms)
Dec 27 01:40:22.975: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:462/proxy/: tls qux (200; 4.160786ms)
Dec 27 01:40:22.975: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:160/proxy/: foo (200; 4.270647ms)
Dec 27 01:40:22.976: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk/proxy/rewriteme"... (200; 4.472435ms)
Dec 27 01:40:22.976: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:443/proxy/... (200; 4.287041ms)
Dec 27 01:40:22.976: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/http:proxy-service-nqkqv:portname2/proxy/: bar (200; 5.363135ms)
Dec 27 01:40:22.976: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:160/proxy/: foo (200; 4.378102ms)
Dec 27 01:40:22.976: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:1080/proxy/rewri... (200; 4.905942ms)
Dec 27 01:40:22.976: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:162/proxy/: bar (200; 4.719108ms)
Dec 27 01:40:22.976: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:1080/proxy/... (200; 4.793908ms)
Dec 27 01:40:22.976: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/https:proxy-service-nqkqv:tlsportname2/proxy/: tls qux (200; 4.511247ms)
Dec 27 01:40:22.976: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:460/proxy/: tls baz (200; 4.874224ms)
Dec 27 01:40:22.977: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/https:proxy-service-nqkqv:tlsportname1/proxy/: tls baz (200; 5.761149ms)
Dec 27 01:40:22.977: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/proxy-service-nqkqv:portname1/proxy/: foo (200; 5.661763ms)
Dec 27 01:40:22.978: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/http:proxy-service-nqkqv:portname1/proxy/: foo (200; 6.085547ms)
Dec 27 01:40:22.978: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/proxy-service-nqkqv:portname2/proxy/: bar (200; 6.552142ms)
Dec 27 01:40:22.981: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:443/proxy/... (200; 3.312282ms)
Dec 27 01:40:22.982: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:462/proxy/: tls qux (200; 3.99134ms)
Dec 27 01:40:22.982: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:160/proxy/: foo (200; 4.104123ms)
Dec 27 01:40:22.982: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:460/proxy/: tls baz (200; 4.000752ms)
Dec 27 01:40:22.982: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:1080/proxy/rewri... (200; 4.106691ms)
Dec 27 01:40:22.983: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:162/proxy/: bar (200; 4.449542ms)
Dec 27 01:40:22.984: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/http:proxy-service-nqkqv:portname2/proxy/: bar (200; 5.559076ms)
Dec 27 01:40:22.984: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:1080/proxy/... (200; 5.541357ms)
Dec 27 01:40:22.984: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/proxy-service-nqkqv:portname2/proxy/: bar (200; 5.782117ms)
Dec 27 01:40:22.984: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/proxy-service-nqkqv:portname1/proxy/: foo (200; 5.864156ms)
Dec 27 01:40:22.984: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/https:proxy-service-nqkqv:tlsportname2/proxy/: tls qux (200; 5.858346ms)
Dec 27 01:40:22.984: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk/proxy/rewriteme"... (200; 5.890445ms)
Dec 27 01:40:22.984: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:162/proxy/: bar (200; 5.898772ms)
Dec 27 01:40:22.984: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:160/proxy/: foo (200; 5.973765ms)
Dec 27 01:40:22.986: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/http:proxy-service-nqkqv:portname1/proxy/: foo (200; 7.507503ms)
Dec 27 01:40:22.986: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/https:proxy-service-nqkqv:tlsportname1/proxy/: tls baz (200; 7.787972ms)
Dec 27 01:40:22.990: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:443/proxy/... (200; 4.013598ms)
Dec 27 01:40:22.990: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:462/proxy/: tls qux (200; 4.234342ms)
Dec 27 01:40:22.990: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:162/proxy/: bar (200; 4.168307ms)
Dec 27 01:40:22.991: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:1080/proxy/... (200; 4.425155ms)
Dec 27 01:40:22.991: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:160/proxy/: foo (200; 4.711288ms)
Dec 27 01:40:22.991: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:160/proxy/: foo (200; 4.757623ms)
Dec 27 01:40:22.991: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:1080/proxy/rewri... (200; 4.767168ms)
Dec 27 01:40:22.991: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk/proxy/rewriteme"... (200; 4.87059ms)
Dec 27 01:40:22.991: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:162/proxy/: bar (200; 4.946809ms)
Dec 27 01:40:22.991: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:460/proxy/: tls baz (200; 4.883424ms)
Dec 27 01:40:22.992: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/proxy-service-nqkqv:portname2/proxy/: bar (200; 5.5126ms)
Dec 27 01:40:22.992: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/https:proxy-service-nqkqv:tlsportname1/proxy/: tls baz (200; 6.171408ms)
Dec 27 01:40:22.992: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/http:proxy-service-nqkqv:portname1/proxy/: foo (200; 6.291932ms)
Dec 27 01:40:22.992: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/https:proxy-service-nqkqv:tlsportname2/proxy/: tls qux (200; 6.34652ms)
Dec 27 01:40:22.992: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/proxy-service-nqkqv:portname1/proxy/: foo (200; 6.237792ms)
Dec 27 01:40:22.993: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/http:proxy-service-nqkqv:portname2/proxy/: bar (200; 6.461881ms)
Dec 27 01:40:22.995: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:443/proxy/... (200; 2.036479ms)
Dec 27 01:40:22.995: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:462/proxy/: tls qux (200; 2.133973ms)
Dec 27 01:40:22.995: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:1080/proxy/rewri... (200; 2.360525ms)
Dec 27 01:40:22.995: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:162/proxy/: bar (200; 2.446553ms)
Dec 27 01:40:22.995: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:162/proxy/: bar (200; 2.412422ms)
Dec 27 01:40:22.996: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk/proxy/rewriteme"... (200; 3.019339ms)
Dec 27 01:40:22.996: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:1080/proxy/... (200; 3.097123ms)
Dec 27 01:40:22.996: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:460/proxy/: tls baz (200; 3.125451ms)
Dec 27 01:40:22.996: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:160/proxy/: foo (200; 3.276085ms)
Dec 27 01:40:22.996: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:160/proxy/: foo (200; 3.459239ms)
Dec 27 01:40:22.996: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/http:proxy-service-nqkqv:portname1/proxy/: foo (200; 3.667614ms)
Dec 27 01:40:22.997: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/proxy-service-nqkqv:portname2/proxy/: bar (200; 4.388468ms)
Dec 27 01:40:22.997: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/https:proxy-service-nqkqv:tlsportname1/proxy/: tls baz (200; 4.529996ms)
Dec 27 01:40:22.998: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/proxy-service-nqkqv:portname1/proxy/: foo (200; 4.659695ms)
Dec 27 01:40:22.998: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/https:proxy-service-nqkqv:tlsportname2/proxy/: tls qux (200; 4.934525ms)
Dec 27 01:40:22.998: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/http:proxy-service-nqkqv:portname2/proxy/: bar (200; 5.133641ms)
Dec 27 01:40:23.001: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:162/proxy/: bar (200; 2.621967ms)
Dec 27 01:40:23.001: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:160/proxy/: foo (200; 2.646168ms)
Dec 27 01:40:23.001: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:160/proxy/: foo (200; 2.610111ms)
Dec 27 01:40:23.001: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:162/proxy/: bar (200; 3.069294ms)
Dec 27 01:40:23.002: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:462/proxy/: tls qux (200; 3.124044ms)
Dec 27 01:40:23.002: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk/proxy/rewriteme"... (200; 3.315851ms)
Dec 27 01:40:23.002: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:460/proxy/: tls baz (200; 2.925715ms)
Dec 27 01:40:23.003: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/http:proxy-service-nqkqv:portname1/proxy/: foo (200; 4.722753ms)
Dec 27 01:40:23.003: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/https:proxy-service-nqkqv:tlsportname2/proxy/: tls qux (200; 4.660766ms)
Dec 27 01:40:23.003: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:1080/proxy/... (200; 4.042907ms)
Dec 27 01:40:23.003: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:443/proxy/... (200; 4.11673ms)
Dec 27 01:40:23.003: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:1080/proxy/rewri... (200; 4.422266ms)
Dec 27 01:40:23.004: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/http:proxy-service-nqkqv:portname2/proxy/: bar (200; 5.183474ms)
Dec 27 01:40:23.005: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/proxy-service-nqkqv:portname2/proxy/: bar (200; 5.509782ms)
Dec 27 01:40:23.005: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/proxy-service-nqkqv:portname1/proxy/: foo (200; 5.606321ms)
Dec 27 01:40:23.005: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/https:proxy-service-nqkqv:tlsportname1/proxy/: tls baz (200; 5.912034ms)
Dec 27 01:40:23.009: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:162/proxy/: bar (200; 3.944383ms)
Dec 27 01:40:23.009: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:1080/proxy/... (200; 3.863928ms)
Dec 27 01:40:23.009: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/proxy-service-nqkqv:portname1/proxy/: foo (200; 4.066237ms)
Dec 27 01:40:23.009: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:1080/proxy/rewri... (200; 4.222657ms)
Dec 27 01:40:23.009: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/http:proxy-service-nqkqv:portname2/proxy/: bar (200; 4.430683ms)
Dec 27 01:40:23.009: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:460/proxy/: tls baz (200; 4.185543ms)
Dec 27 01:40:23.009: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:443/proxy/... (200; 4.0108ms)
Dec 27 01:40:23.009: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:160/proxy/: foo (200; 3.812727ms)
Dec 27 01:40:23.009: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:462/proxy/: tls qux (200; 3.611744ms)
Dec 27 01:40:23.009: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/proxy-service-nqkqv:portname2/proxy/: bar (200; 4.677661ms)
Dec 27 01:40:23.010: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:162/proxy/: bar (200; 4.198517ms)
Dec 27 01:40:23.010: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:160/proxy/: foo (200; 3.942588ms)
Dec 27 01:40:23.010: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk/proxy/rewriteme"... (200; 4.043264ms)
Dec 27 01:40:23.010: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/http:proxy-service-nqkqv:portname1/proxy/: foo (200; 4.723977ms)
Dec 27 01:40:23.011: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/https:proxy-service-nqkqv:tlsportname1/proxy/: tls baz (200; 5.118285ms)
Dec 27 01:40:23.011: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/https:proxy-service-nqkqv:tlsportname2/proxy/: tls qux (200; 5.482541ms)
Dec 27 01:40:23.013: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:460/proxy/: tls baz (200; 2.652471ms)
Dec 27 01:40:23.014: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:1080/proxy/... (200; 2.78592ms)
Dec 27 01:40:23.014: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:162/proxy/: bar (200; 2.862957ms)
Dec 27 01:40:23.014: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:443/proxy/... (200; 3.280331ms)
Dec 27 01:40:23.015: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:162/proxy/: bar (200; 3.202707ms)
Dec 27 01:40:23.016: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk/proxy/rewriteme"... (200; 4.150058ms)
Dec 27 01:40:23.016: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:160/proxy/: foo (200; 4.492679ms)
Dec 27 01:40:23.016: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:1080/proxy/rewri... (200; 3.822366ms)
Dec 27 01:40:23.016: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:462/proxy/: tls qux (200; 4.090032ms)
Dec 27 01:40:23.016: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:160/proxy/: foo (200; 4.179457ms)
Dec 27 01:40:23.016: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/http:proxy-service-nqkqv:portname1/proxy/: foo (200; 4.790088ms)
Dec 27 01:40:23.017: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/proxy-service-nqkqv:portname1/proxy/: foo (200; 4.674491ms)
Dec 27 01:40:23.017: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/proxy-service-nqkqv:portname2/proxy/: bar (200; 5.334442ms)
Dec 27 01:40:23.017: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/http:proxy-service-nqkqv:portname2/proxy/: bar (200; 5.926609ms)
Dec 27 01:40:23.018: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/https:proxy-service-nqkqv:tlsportname2/proxy/: tls qux (200; 6.317554ms)
Dec 27 01:40:23.018: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/https:proxy-service-nqkqv:tlsportname1/proxy/: tls baz (200; 6.034213ms)
Dec 27 01:40:23.020: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk/proxy/rewriteme"... (200; 2.409062ms)
Dec 27 01:40:23.020: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:460/proxy/: tls baz (200; 2.589696ms)
Dec 27 01:40:23.020: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:1080/proxy/... (200; 2.423975ms)
Dec 27 01:40:23.021: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:443/proxy/... (200; 2.65431ms)
Dec 27 01:40:23.021: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:162/proxy/: bar (200; 2.748267ms)
Dec 27 01:40:23.021: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:160/proxy/: foo (200; 2.551736ms)
Dec 27 01:40:23.021: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:162/proxy/: bar (200; 2.848912ms)
Dec 27 01:40:23.021: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:1080/proxy/rewri... (200; 3.126277ms)
Dec 27 01:40:23.021: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:462/proxy/: tls qux (200; 2.606481ms)
Dec 27 01:40:23.021: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:160/proxy/: foo (200; 2.783665ms)
Dec 27 01:40:23.022: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/proxy-service-nqkqv:portname1/proxy/: foo (200; 4.141423ms)
Dec 27 01:40:23.022: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/http:proxy-service-nqkqv:portname1/proxy/: foo (200; 4.136346ms)
Dec 27 01:40:23.023: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/http:proxy-service-nqkqv:portname2/proxy/: bar (200; 3.996153ms)
Dec 27 01:40:23.023: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/https:proxy-service-nqkqv:tlsportname1/proxy/: tls baz (200; 4.003703ms)
Dec 27 01:40:23.023: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/proxy-service-nqkqv:portname2/proxy/: bar (200; 4.783349ms)
Dec 27 01:40:23.023: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/https:proxy-service-nqkqv:tlsportname2/proxy/: tls qux (200; 4.337029ms)
Dec 27 01:40:23.025: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:462/proxy/: tls qux (200; 2.386057ms)
Dec 27 01:40:23.025: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:460/proxy/: tls baz (200; 2.179361ms)
Dec 27 01:40:23.025: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk/proxy/rewriteme"... (200; 2.691065ms)
Dec 27 01:40:23.025: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:160/proxy/: foo (200; 2.609912ms)
Dec 27 01:40:23.026: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:1080/proxy/... (200; 2.3496ms)
Dec 27 01:40:23.026: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:162/proxy/: bar (200; 2.329911ms)
Dec 27 01:40:23.026: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:443/proxy/... (200; 2.465293ms)
Dec 27 01:40:23.026: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:1080/proxy/rewri... (200; 2.757621ms)
Dec 27 01:40:23.027: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:162/proxy/: bar (200; 2.944268ms)
Dec 27 01:40:23.027: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/https:proxy-service-nqkqv:tlsportname2/proxy/: tls qux (200; 3.965301ms)
Dec 27 01:40:23.027: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:160/proxy/: foo (200; 3.127507ms)
Dec 27 01:40:23.027: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/http:proxy-service-nqkqv:portname2/proxy/: bar (200; 3.99066ms)
Dec 27 01:40:23.027: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/https:proxy-service-nqkqv:tlsportname1/proxy/: tls baz (200; 3.922812ms)
Dec 27 01:40:23.027: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/proxy-service-nqkqv:portname1/proxy/: foo (200; 4.014541ms)
Dec 27 01:40:23.027: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/http:proxy-service-nqkqv:portname1/proxy/: foo (200; 3.593205ms)
Dec 27 01:40:23.027: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/proxy-service-nqkqv:portname2/proxy/: bar (200; 4.106162ms)
Dec 27 01:40:23.031: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk/proxy/rewriteme"... (200; 3.173311ms)
Dec 27 01:40:23.031: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:160/proxy/: foo (200; 3.590506ms)
Dec 27 01:40:23.032: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:160/proxy/: foo (200; 4.647815ms)
Dec 27 01:40:23.033: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:460/proxy/: tls baz (200; 4.973437ms)
Dec 27 01:40:23.033: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/proxy-service-nqkqv:portname2/proxy/: bar (200; 5.151627ms)
Dec 27 01:40:23.033: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:1080/proxy/... (200; 5.081571ms)
Dec 27 01:40:23.033: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:462/proxy/: tls qux (200; 5.083099ms)
Dec 27 01:40:23.033: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/https:proxy-service-nqkqv-8tqtk:443/proxy/... (200; 5.147483ms)
Dec 27 01:40:23.033: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:1080/proxy/rewri... (200; 5.049117ms)
Dec 27 01:40:23.033: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/proxy-service-nqkqv-8tqtk:162/proxy/: bar (200; 5.070503ms)
Dec 27 01:40:23.033: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/http:proxy-service-nqkqv:portname2/proxy/: bar (200; 5.292059ms)
Dec 27 01:40:23.033: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5xmj/pods/http:proxy-service-nqkqv-8tqtk:162/proxy/: bar (200; 5.331158ms)
Dec 27 01:40:23.034: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/https:proxy-service-nqkqv:tlsportname2/proxy/: tls qux (200; 6.031907ms)
Dec 27 01:40:23.034: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/http:proxy-service-nqkqv:portname1/proxy/: foo (200; 6.076266ms)
Dec 27 01:40:23.034: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/https:proxy-service-nqkqv:tlsportname1/proxy/: tls baz (200; 6.250997ms)
Dec 27 01:40:23.034: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5xmj/services/proxy-service-nqkqv:portname1/proxy/: foo (200; 6.147391ms)
STEP: deleting ReplicationController proxy-service-nqkqv in namespace e2e-tests-proxy-j5xmj, will wait for the garbage collector to delete the pods
Dec 27 01:40:23.092: INFO: Deleting ReplicationController proxy-service-nqkqv took: 6.755984ms
Dec 27 01:40:23.193: INFO: Terminating ReplicationController proxy-service-nqkqv pods took: 100.177661ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:40:34.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-j5xmj" for this suite.
Dec 27 01:40:40.111: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:40:40.115: INFO: namespace: e2e-tests-proxy-j5xmj, resource: bindings, ignored listing per whitelist
Dec 27 01:40:40.169: INFO: namespace e2e-tests-proxy-j5xmj deletion completed in 6.072191534s

• [SLOW TEST:24.404 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:40:40.169: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-6ab05625-0978-11e9-a1bd-0a580a2100c6
STEP: Creating a pod to test consume configMaps
Dec 27 01:40:40.227: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6ab1181f-0978-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-projected-b7dz5" to be "success or failure"
Dec 27 01:40:40.233: INFO: Pod "pod-projected-configmaps-6ab1181f-0978-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 5.359867ms
Dec 27 01:40:42.235: INFO: Pod "pod-projected-configmaps-6ab1181f-0978-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008190102s
STEP: Saw pod success
Dec 27 01:40:42.235: INFO: Pod "pod-projected-configmaps-6ab1181f-0978-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 01:40:42.237: INFO: Trying to get logs from node guojing-2 pod pod-projected-configmaps-6ab1181f-0978-11e9-a1bd-0a580a2100c6 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 27 01:40:42.257: INFO: Waiting for pod pod-projected-configmaps-6ab1181f-0978-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 01:40:42.259: INFO: Pod pod-projected-configmaps-6ab1181f-0978-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:40:42.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-b7dz5" for this suite.
Dec 27 01:40:48.270: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:40:48.320: INFO: namespace: e2e-tests-projected-b7dz5, resource: bindings, ignored listing per whitelist
Dec 27 01:40:48.329: INFO: namespace e2e-tests-projected-b7dz5 deletion completed in 6.066757042s

• [SLOW TEST:8.160 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:40:48.329: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec 27 01:40:48.391: INFO: Waiting up to 5m0s for pod "pod-6f8d9c97-0978-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-emptydir-h6kcq" to be "success or failure"
Dec 27 01:40:48.393: INFO: Pod "pod-6f8d9c97-0978-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.956672ms
Dec 27 01:40:50.399: INFO: Pod "pod-6f8d9c97-0978-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007779709s
STEP: Saw pod success
Dec 27 01:40:50.399: INFO: Pod "pod-6f8d9c97-0978-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 01:40:50.401: INFO: Trying to get logs from node guojing-3 pod pod-6f8d9c97-0978-11e9-a1bd-0a580a2100c6 container test-container: <nil>
STEP: delete the pod
Dec 27 01:40:50.416: INFO: Waiting for pod pod-6f8d9c97-0978-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 01:40:50.418: INFO: Pod pod-6f8d9c97-0978-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:40:50.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-h6kcq" for this suite.
Dec 27 01:40:56.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:40:56.469: INFO: namespace: e2e-tests-emptydir-h6kcq, resource: bindings, ignored listing per whitelist
Dec 27 01:40:56.485: INFO: namespace e2e-tests-emptydir-h6kcq deletion completed in 6.064004522s

• [SLOW TEST:8.156 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:40:56.485: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Dec 27 01:40:56.537: INFO: Waiting up to 5m0s for pod "var-expansion-7469876c-0978-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-var-expansion-bjs9g" to be "success or failure"
Dec 27 01:40:56.539: INFO: Pod "var-expansion-7469876c-0978-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.85372ms
Dec 27 01:40:58.541: INFO: Pod "var-expansion-7469876c-0978-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004479188s
STEP: Saw pod success
Dec 27 01:40:58.541: INFO: Pod "var-expansion-7469876c-0978-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 01:40:58.543: INFO: Trying to get logs from node guojing-2 pod var-expansion-7469876c-0978-11e9-a1bd-0a580a2100c6 container dapi-container: <nil>
STEP: delete the pod
Dec 27 01:40:58.567: INFO: Waiting for pod var-expansion-7469876c-0978-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 01:40:58.571: INFO: Pod var-expansion-7469876c-0978-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:40:58.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-bjs9g" for this suite.
Dec 27 01:41:04.585: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:41:04.619: INFO: namespace: e2e-tests-var-expansion-bjs9g, resource: bindings, ignored listing per whitelist
Dec 27 01:41:04.641: INFO: namespace e2e-tests-var-expansion-bjs9g deletion completed in 6.065955084s

• [SLOW TEST:8.156 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:41:04.641: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 27 01:41:04.711: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"79476579-0978-11e9-9853-debd8636412e", Controller:(*bool)(0xc001cadb6e), BlockOwnerDeletion:(*bool)(0xc001cadb6f)}}
Dec 27 01:41:04.719: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"7945ba07-0978-11e9-9853-debd8636412e", Controller:(*bool)(0xc00094ff66), BlockOwnerDeletion:(*bool)(0xc00094ff67)}}
Dec 27 01:41:04.726: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"79468f7b-0978-11e9-9853-debd8636412e", Controller:(*bool)(0xc001caddda), BlockOwnerDeletion:(*bool)(0xc001cadddb)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:41:09.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-zcs9b" for this suite.
Dec 27 01:41:15.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:41:15.757: INFO: namespace: e2e-tests-gc-zcs9b, resource: bindings, ignored listing per whitelist
Dec 27 01:41:15.802: INFO: namespace e2e-tests-gc-zcs9b deletion completed in 6.064334929s

• [SLOW TEST:11.161 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:41:15.802: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-cjhvv
Dec 27 01:41:17.860: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-cjhvv
STEP: checking the pod's current state and verifying that restartCount is present
Dec 27 01:41:17.862: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:45:18.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-cjhvv" for this suite.
Dec 27 01:45:24.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:45:24.317: INFO: namespace: e2e-tests-container-probe-cjhvv, resource: bindings, ignored listing per whitelist
Dec 27 01:45:24.346: INFO: namespace e2e-tests-container-probe-cjhvv deletion completed in 6.064809668s

• [SLOW TEST:248.544 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:45:24.346: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-141238e0-0979-11e9-a1bd-0a580a2100c6
STEP: Creating a pod to test consume secrets
Dec 27 01:45:24.429: INFO: Waiting up to 5m0s for pod "pod-secrets-1416c56d-0979-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-secrets-x58h7" to be "success or failure"
Dec 27 01:45:24.430: INFO: Pod "pod-secrets-1416c56d-0979-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.737493ms
Dec 27 01:45:26.433: INFO: Pod "pod-secrets-1416c56d-0979-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004428666s
STEP: Saw pod success
Dec 27 01:45:26.433: INFO: Pod "pod-secrets-1416c56d-0979-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 01:45:26.435: INFO: Trying to get logs from node guojing-3 pod pod-secrets-1416c56d-0979-11e9-a1bd-0a580a2100c6 container secret-volume-test: <nil>
STEP: delete the pod
Dec 27 01:45:26.451: INFO: Waiting for pod pod-secrets-1416c56d-0979-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 01:45:26.452: INFO: Pod pod-secrets-1416c56d-0979-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:45:26.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-x58h7" for this suite.
Dec 27 01:45:32.466: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:45:32.501: INFO: namespace: e2e-tests-secrets-x58h7, resource: bindings, ignored listing per whitelist
Dec 27 01:45:32.527: INFO: namespace e2e-tests-secrets-x58h7 deletion completed in 6.071937833s
STEP: Destroying namespace "e2e-tests-secret-namespace-xj95n" for this suite.
Dec 27 01:45:38.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:45:38.562: INFO: namespace: e2e-tests-secret-namespace-xj95n, resource: bindings, ignored listing per whitelist
Dec 27 01:45:38.591: INFO: namespace e2e-tests-secret-namespace-xj95n deletion completed in 6.063818731s

• [SLOW TEST:14.245 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:45:38.591: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Dec 27 01:45:38.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 create -f - --namespace=e2e-tests-kubectl-68g8f'
Dec 27 01:45:38.856: INFO: stderr: ""
Dec 27 01:45:38.856: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 27 01:45:39.859: INFO: Selector matched 1 pods for map[app:redis]
Dec 27 01:45:39.859: INFO: Found 0 / 1
Dec 27 01:45:40.859: INFO: Selector matched 1 pods for map[app:redis]
Dec 27 01:45:40.859: INFO: Found 1 / 1
Dec 27 01:45:40.859: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Dec 27 01:45:40.861: INFO: Selector matched 1 pods for map[app:redis]
Dec 27 01:45:40.861: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 27 01:45:40.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 patch pod redis-master-489z4 --namespace=e2e-tests-kubectl-68g8f -p {"metadata":{"annotations":{"x":"y"}}}'
Dec 27 01:45:40.940: INFO: stderr: ""
Dec 27 01:45:40.940: INFO: stdout: "pod/redis-master-489z4 patched\n"
STEP: checking annotations
Dec 27 01:45:40.943: INFO: Selector matched 1 pods for map[app:redis]
Dec 27 01:45:40.943: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:45:40.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-68g8f" for this suite.
Dec 27 01:46:02.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:46:02.999: INFO: namespace: e2e-tests-kubectl-68g8f, resource: bindings, ignored listing per whitelist
Dec 27 01:46:03.015: INFO: namespace e2e-tests-kubectl-68g8f deletion completed in 22.069005414s

• [SLOW TEST:24.423 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:46:03.015: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 27 01:46:03.071: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2b1ee920-0979-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-projected-srl5g" to be "success or failure"
Dec 27 01:46:03.073: INFO: Pod "downwardapi-volume-2b1ee920-0979-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.712919ms
Dec 27 01:46:05.079: INFO: Pod "downwardapi-volume-2b1ee920-0979-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007675012s
STEP: Saw pod success
Dec 27 01:46:05.079: INFO: Pod "downwardapi-volume-2b1ee920-0979-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 01:46:05.081: INFO: Trying to get logs from node guojing-2 pod downwardapi-volume-2b1ee920-0979-11e9-a1bd-0a580a2100c6 container client-container: <nil>
STEP: delete the pod
Dec 27 01:46:05.096: INFO: Waiting for pod downwardapi-volume-2b1ee920-0979-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 01:46:05.098: INFO: Pod downwardapi-volume-2b1ee920-0979-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:46:05.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-srl5g" for this suite.
Dec 27 01:46:11.113: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:46:11.163: INFO: namespace: e2e-tests-projected-srl5g, resource: bindings, ignored listing per whitelist
Dec 27 01:46:11.175: INFO: namespace e2e-tests-projected-srl5g deletion completed in 6.074140478s

• [SLOW TEST:8.161 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:46:11.176: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 27 01:46:11.235: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Dec 27 01:46:11.245: INFO: Number of nodes with available pods: 0
Dec 27 01:46:11.245: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 01:46:12.251: INFO: Number of nodes with available pods: 0
Dec 27 01:46:12.251: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 01:46:13.251: INFO: Number of nodes with available pods: 3
Dec 27 01:46:13.251: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Dec 27 01:46:13.273: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:13.273: INFO: Wrong image for pod: daemon-set-cp28c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:13.273: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:14.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:14.279: INFO: Wrong image for pod: daemon-set-cp28c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:14.279: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:15.283: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:15.283: INFO: Wrong image for pod: daemon-set-cp28c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:15.283: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:16.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:16.279: INFO: Wrong image for pod: daemon-set-cp28c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:16.279: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:17.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:17.279: INFO: Wrong image for pod: daemon-set-cp28c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:17.279: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:18.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:18.279: INFO: Wrong image for pod: daemon-set-cp28c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:18.279: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:19.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:19.279: INFO: Wrong image for pod: daemon-set-cp28c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:19.279: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:20.281: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:20.281: INFO: Wrong image for pod: daemon-set-cp28c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:20.281: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:21.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:21.280: INFO: Wrong image for pod: daemon-set-cp28c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:21.280: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:22.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:22.280: INFO: Wrong image for pod: daemon-set-cp28c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:22.280: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:23.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:23.280: INFO: Wrong image for pod: daemon-set-cp28c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:23.280: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:24.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:24.279: INFO: Wrong image for pod: daemon-set-cp28c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:24.279: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:25.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:25.280: INFO: Wrong image for pod: daemon-set-cp28c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:25.280: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:26.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:26.279: INFO: Wrong image for pod: daemon-set-cp28c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:26.279: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:27.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:27.280: INFO: Wrong image for pod: daemon-set-cp28c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:27.280: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:28.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:28.280: INFO: Wrong image for pod: daemon-set-cp28c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:28.280: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:29.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:29.279: INFO: Wrong image for pod: daemon-set-cp28c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:29.279: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:30.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:30.279: INFO: Wrong image for pod: daemon-set-cp28c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:30.279: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:31.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:31.279: INFO: Wrong image for pod: daemon-set-cp28c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:31.279: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:32.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:32.280: INFO: Wrong image for pod: daemon-set-cp28c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:32.280: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:33.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:33.280: INFO: Wrong image for pod: daemon-set-cp28c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:33.280: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:34.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:34.279: INFO: Wrong image for pod: daemon-set-cp28c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:34.279: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:35.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:35.279: INFO: Wrong image for pod: daemon-set-cp28c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:35.279: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:36.283: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:36.283: INFO: Wrong image for pod: daemon-set-cp28c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:36.283: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:37.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:37.279: INFO: Wrong image for pod: daemon-set-cp28c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:37.279: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:38.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:38.279: INFO: Wrong image for pod: daemon-set-cp28c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:38.279: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:39.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:39.279: INFO: Wrong image for pod: daemon-set-cp28c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:39.279: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:40.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:40.280: INFO: Wrong image for pod: daemon-set-cp28c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:40.280: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:41.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:41.279: INFO: Wrong image for pod: daemon-set-cp28c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:41.279: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:42.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:42.280: INFO: Wrong image for pod: daemon-set-cp28c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:42.280: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:43.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:43.279: INFO: Wrong image for pod: daemon-set-cp28c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:43.279: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:44.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:44.280: INFO: Wrong image for pod: daemon-set-cp28c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:44.280: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:45.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:45.279: INFO: Wrong image for pod: daemon-set-cp28c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:45.279: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:46.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:46.279: INFO: Wrong image for pod: daemon-set-cp28c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:46.279: INFO: Pod daemon-set-cp28c is not available
Dec 27 01:46:46.279: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:47.282: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:47.282: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:47.282: INFO: Pod daemon-set-wdwjr is not available
Dec 27 01:46:48.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:48.279: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:49.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:49.280: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:50.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:50.280: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:51.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:51.280: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:52.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:52.279: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:53.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:53.280: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:54.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:54.280: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:55.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:55.279: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:56.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:56.280: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:57.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:57.280: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:58.283: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:58.283: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:59.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:46:59.279: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:00.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:00.280: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:01.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:01.280: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:02.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:02.280: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:03.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:03.280: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:04.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:04.279: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:05.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:05.280: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:06.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:06.280: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:07.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:07.279: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:08.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:08.279: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:09.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:09.279: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:10.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:10.280: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:11.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:11.279: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:12.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:12.279: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:13.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:13.279: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:14.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:14.280: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:15.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:15.280: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:16.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:16.279: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:17.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:17.280: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:18.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:18.279: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:19.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:19.280: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:19.280: INFO: Pod daemon-set-s6lrc is not available
Dec 27 01:47:20.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:20.280: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:20.280: INFO: Pod daemon-set-s6lrc is not available
Dec 27 01:47:21.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:21.279: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:21.279: INFO: Pod daemon-set-s6lrc is not available
Dec 27 01:47:22.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:22.279: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:22.279: INFO: Pod daemon-set-s6lrc is not available
Dec 27 01:47:23.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:23.280: INFO: Wrong image for pod: daemon-set-s6lrc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:23.280: INFO: Pod daemon-set-s6lrc is not available
Dec 27 01:47:24.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:24.279: INFO: Pod daemon-set-vgqgn is not available
Dec 27 01:47:25.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:26.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:27.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:28.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:29.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:30.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:31.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:32.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:33.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:34.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:35.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:36.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:37.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:38.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:39.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:40.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:41.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:42.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:43.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:44.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:45.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:46.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:47.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:48.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:49.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:50.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:51.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:52.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:53.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:54.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:55.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:56.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:56.279: INFO: Pod daemon-set-7nx9s is not available
Dec 27 01:47:57.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:57.279: INFO: Pod daemon-set-7nx9s is not available
Dec 27 01:47:58.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:58.280: INFO: Pod daemon-set-7nx9s is not available
Dec 27 01:47:59.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:47:59.280: INFO: Pod daemon-set-7nx9s is not available
Dec 27 01:48:00.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:48:00.279: INFO: Pod daemon-set-7nx9s is not available
Dec 27 01:48:01.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:48:01.280: INFO: Pod daemon-set-7nx9s is not available
Dec 27 01:48:02.280: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:48:02.280: INFO: Pod daemon-set-7nx9s is not available
Dec 27 01:48:03.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:48:03.279: INFO: Pod daemon-set-7nx9s is not available
Dec 27 01:48:04.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:48:04.279: INFO: Pod daemon-set-7nx9s is not available
Dec 27 01:48:05.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:48:05.280: INFO: Pod daemon-set-7nx9s is not available
Dec 27 01:48:06.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:48:06.279: INFO: Pod daemon-set-7nx9s is not available
Dec 27 01:48:07.279: INFO: Wrong image for pod: daemon-set-7nx9s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 27 01:48:07.279: INFO: Pod daemon-set-7nx9s is not available
Dec 27 01:48:08.280: INFO: Pod daemon-set-j7zgt is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Dec 27 01:48:08.288: INFO: Number of nodes with available pods: 2
Dec 27 01:48:08.288: INFO: Node guojing-2 is running more than one daemon pod
Dec 27 01:48:09.294: INFO: Number of nodes with available pods: 3
Dec 27 01:48:09.294: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-d7nqc, will wait for the garbage collector to delete the pods
Dec 27 01:48:09.362: INFO: Deleting DaemonSet.extensions daemon-set took: 6.430524ms
Dec 27 01:48:09.462: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.165858ms
Dec 27 01:48:18.165: INFO: Number of nodes with available pods: 0
Dec 27 01:48:18.165: INFO: Number of running nodes: 0, number of available pods: 0
Dec 27 01:48:18.167: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-d7nqc/daemonsets","resourceVersion":"6016"},"items":null}

Dec 27 01:48:18.168: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-d7nqc/pods","resourceVersion":"6016"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:48:18.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-d7nqc" for this suite.
Dec 27 01:48:24.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:48:24.245: INFO: namespace: e2e-tests-daemonsets-d7nqc, resource: bindings, ignored listing per whitelist
Dec 27 01:48:24.247: INFO: namespace e2e-tests-daemonsets-d7nqc deletion completed in 6.067880101s

• [SLOW TEST:133.071 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:48:24.247: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 27 01:48:24.298: INFO: Creating deployment "test-recreate-deployment"
Dec 27 01:48:24.304: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Dec 27 01:48:24.309: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Dec 27 01:48:26.314: INFO: Waiting deployment "test-recreate-deployment" to complete
Dec 27 01:48:26.316: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Dec 27 01:48:26.323: INFO: Updating deployment test-recreate-deployment
Dec 27 01:48:26.323: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec 27 01:48:26.399: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-bx67d,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bx67d/deployments/test-recreate-deployment,UID:7f4d53f7-0979-11e9-9853-debd8636412e,ResourceVersion:6117,Generation:2,CreationTimestamp:2018-12-27 01:48:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2018-12-27 01:48:26 +0000 UTC 2018-12-27 01:48:26 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2018-12-27 01:48:26 +0000 UTC 2018-12-27 01:48:24 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Dec 27 01:48:26.401: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-bx67d,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bx67d/replicasets/test-recreate-deployment-697fbf54bf,UID:8086fc86-0979-11e9-b34c-525400cd4ed0,ResourceVersion:6115,Generation:1,CreationTimestamp:2018-12-27 01:48:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 7f4d53f7-0979-11e9-9853-debd8636412e 0xc0024499f7 0xc0024499f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 27 01:48:26.401: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Dec 27 01:48:26.402: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-bx67d,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bx67d/replicasets/test-recreate-deployment-5dfdcc846d,UID:7f4f0d65-0979-11e9-b34c-525400cd4ed0,ResourceVersion:6105,Generation:2,CreationTimestamp:2018-12-27 01:48:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 7f4d53f7-0979-11e9-9853-debd8636412e 0xc002449947 0xc002449948}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 27 01:48:26.404: INFO: Pod "test-recreate-deployment-697fbf54bf-t7wh4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-t7wh4,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-bx67d,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bx67d/pods/test-recreate-deployment-697fbf54bf-t7wh4,UID:8087a190-0979-11e9-b34c-525400cd4ed0,ResourceVersion:6116,Generation:0,CreationTimestamp:2018-12-27 01:48:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf 8086fc86-0979-11e9-b34c-525400cd4ed0 0xc001c14347 0xc001c14348}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-m4lnz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-m4lnz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-m4lnz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:guojing-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c143c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c143e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:48:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:48:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:48:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 01:48:26 +0000 UTC  }],Message:,Reason:,HostIP:172.19.16.18,PodIP:,StartTime:2018-12-27 01:48:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:48:26.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-bx67d" for this suite.
Dec 27 01:48:32.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:48:32.436: INFO: namespace: e2e-tests-deployment-bx67d, resource: bindings, ignored listing per whitelist
Dec 27 01:48:32.474: INFO: namespace e2e-tests-deployment-bx67d deletion completed in 6.067890077s

• [SLOW TEST:8.227 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:48:32.475: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 27 01:48:32.526: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8433930c-0979-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-projected-fdkpv" to be "success or failure"
Dec 27 01:48:32.528: INFO: Pod "downwardapi-volume-8433930c-0979-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.88199ms
Dec 27 01:48:34.530: INFO: Pod "downwardapi-volume-8433930c-0979-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004809613s
STEP: Saw pod success
Dec 27 01:48:34.530: INFO: Pod "downwardapi-volume-8433930c-0979-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 01:48:34.532: INFO: Trying to get logs from node guojing-2 pod downwardapi-volume-8433930c-0979-11e9-a1bd-0a580a2100c6 container client-container: <nil>
STEP: delete the pod
Dec 27 01:48:34.550: INFO: Waiting for pod downwardapi-volume-8433930c-0979-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 01:48:34.551: INFO: Pod downwardapi-volume-8433930c-0979-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:48:34.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fdkpv" for this suite.
Dec 27 01:48:40.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:48:40.598: INFO: namespace: e2e-tests-projected-fdkpv, resource: bindings, ignored listing per whitelist
Dec 27 01:48:40.620: INFO: namespace e2e-tests-projected-fdkpv deletion completed in 6.066052616s

• [SLOW TEST:8.146 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:48:40.620: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-890f75e6-0979-11e9-a1bd-0a580a2100c6
STEP: Creating a pod to test consume secrets
Dec 27 01:48:40.679: INFO: Waiting up to 5m0s for pod "pod-secrets-891032fe-0979-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-secrets-jzwzp" to be "success or failure"
Dec 27 01:48:40.681: INFO: Pod "pod-secrets-891032fe-0979-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.798431ms
Dec 27 01:48:42.683: INFO: Pod "pod-secrets-891032fe-0979-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004254739s
STEP: Saw pod success
Dec 27 01:48:42.683: INFO: Pod "pod-secrets-891032fe-0979-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 01:48:42.685: INFO: Trying to get logs from node guojing-3 pod pod-secrets-891032fe-0979-11e9-a1bd-0a580a2100c6 container secret-env-test: <nil>
STEP: delete the pod
Dec 27 01:48:42.698: INFO: Waiting for pod pod-secrets-891032fe-0979-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 01:48:42.700: INFO: Pod pod-secrets-891032fe-0979-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:48:42.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-jzwzp" for this suite.
Dec 27 01:48:48.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:48:48.741: INFO: namespace: e2e-tests-secrets-jzwzp, resource: bindings, ignored listing per whitelist
Dec 27 01:48:48.780: INFO: namespace e2e-tests-secrets-jzwzp deletion completed in 6.076738291s

• [SLOW TEST:8.159 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:48:48.780: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-shvl8
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 27 01:48:48.827: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 27 01:49:10.889: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.33.0.232 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-shvl8 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 27 01:49:10.889: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
Dec 27 01:49:11.976: INFO: Found all expected endpoints: [netserver-0]
Dec 27 01:49:11.979: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.33.2.81 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-shvl8 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 27 01:49:11.979: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
Dec 27 01:49:13.063: INFO: Found all expected endpoints: [netserver-1]
Dec 27 01:49:13.066: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.33.1.64 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-shvl8 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 27 01:49:13.066: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
Dec 27 01:49:14.146: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:49:14.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-shvl8" for this suite.
Dec 27 01:49:36.161: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:49:36.178: INFO: namespace: e2e-tests-pod-network-test-shvl8, resource: bindings, ignored listing per whitelist
Dec 27 01:49:36.224: INFO: namespace e2e-tests-pod-network-test-shvl8 deletion completed in 22.074859141s

• [SLOW TEST:47.444 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:49:36.224: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Dec 27 01:49:36.279: INFO: Waiting up to 5m0s for pod "pod-aa33c77c-0979-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-emptydir-4lklc" to be "success or failure"
Dec 27 01:49:36.281: INFO: Pod "pod-aa33c77c-0979-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.819122ms
Dec 27 01:49:38.283: INFO: Pod "pod-aa33c77c-0979-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00452309s
STEP: Saw pod success
Dec 27 01:49:38.283: INFO: Pod "pod-aa33c77c-0979-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 01:49:38.285: INFO: Trying to get logs from node guojing-3 pod pod-aa33c77c-0979-11e9-a1bd-0a580a2100c6 container test-container: <nil>
STEP: delete the pod
Dec 27 01:49:38.300: INFO: Waiting for pod pod-aa33c77c-0979-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 01:49:38.302: INFO: Pod pod-aa33c77c-0979-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:49:38.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-4lklc" for this suite.
Dec 27 01:49:44.312: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:49:44.327: INFO: namespace: e2e-tests-emptydir-4lklc, resource: bindings, ignored listing per whitelist
Dec 27 01:49:44.368: INFO: namespace e2e-tests-emptydir-4lklc deletion completed in 6.063478387s

• [SLOW TEST:8.144 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:49:44.368: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 27 01:49:44.414: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 version --client'
Dec 27 01:49:44.465: INFO: stderr: ""
Dec 27 01:49:44.465: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Dec 27 01:49:44.466: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 create -f - --namespace=e2e-tests-kubectl-g5rpw'
Dec 27 01:49:44.888: INFO: stderr: ""
Dec 27 01:49:44.888: INFO: stdout: "replicationcontroller/redis-master created\n"
Dec 27 01:49:44.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 create -f - --namespace=e2e-tests-kubectl-g5rpw'
Dec 27 01:49:45.063: INFO: stderr: ""
Dec 27 01:49:45.063: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 27 01:49:46.066: INFO: Selector matched 1 pods for map[app:redis]
Dec 27 01:49:46.066: INFO: Found 1 / 1
Dec 27 01:49:46.066: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 27 01:49:46.070: INFO: Selector matched 1 pods for map[app:redis]
Dec 27 01:49:46.070: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 27 01:49:46.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 describe pod redis-master-vgw4w --namespace=e2e-tests-kubectl-g5rpw'
Dec 27 01:49:46.146: INFO: stderr: ""
Dec 27 01:49:46.146: INFO: stdout: "Name:               redis-master-vgw4w\nNamespace:          e2e-tests-kubectl-g5rpw\nPriority:           0\nPriorityClassName:  <none>\nNode:               guojing-1/172.19.16.18\nStart Time:         Thu, 27 Dec 2018 01:49:44 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.33.2.83\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://ea8655b06d8c4604aa952a22516493429039d2ea5be1f76a334a8c20d4e0784b\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Thu, 27 Dec 2018 01:49:45 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-2mwb4 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-2mwb4:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-2mwb4\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                Message\n  ----    ------     ----  ----                -------\n  Normal  Scheduled  2s    default-scheduler   Successfully assigned e2e-tests-kubectl-g5rpw/redis-master-vgw4w to guojing-1\n  Normal  Pulled     1s    kubelet, guojing-1  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, guojing-1  Created container\n  Normal  Started    1s    kubelet, guojing-1  Started container\n"
Dec 27 01:49:46.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 describe rc redis-master --namespace=e2e-tests-kubectl-g5rpw'
Dec 27 01:49:46.221: INFO: stderr: ""
Dec 27 01:49:46.221: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-g5rpw\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-vgw4w\n"
Dec 27 01:49:46.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 describe service redis-master --namespace=e2e-tests-kubectl-g5rpw'
Dec 27 01:49:46.293: INFO: stderr: ""
Dec 27 01:49:46.293: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-g5rpw\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.102.124.133\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.33.2.83:6379\nSession Affinity:  None\nEvents:            <none>\n"
Dec 27 01:49:46.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 describe node guojing-1'
Dec 27 01:49:46.379: INFO: stderr: ""
Dec 27 01:49:46.379: INFO: stdout: "Name:               guojing-1\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/hostname=guojing-1\n                    node-role.kubernetes.io/master=\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"de:bd:86:36:41:2e\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 172.19.16.18\n                    kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Thu, 27 Dec 2018 01:21:44 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Thu, 27 Dec 2018 01:49:37 +0000   Thu, 27 Dec 2018 01:21:44 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Thu, 27 Dec 2018 01:49:37 +0000   Thu, 27 Dec 2018 01:21:44 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Thu, 27 Dec 2018 01:49:37 +0000   Thu, 27 Dec 2018 01:21:44 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Thu, 27 Dec 2018 01:49:37 +0000   Thu, 27 Dec 2018 01:22:24 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  172.19.16.18\n  Hostname:    guojing-1\nCapacity:\n cpu:                8\n ephemeral-storage:  51473888Ki\n hugepages-2Mi:      0\n memory:             16266496Ki\n pods:               110\nAllocatable:\n cpu:                8\n ephemeral-storage:  47438335103\n hugepages-2Mi:      0\n memory:             16164096Ki\n pods:               110\nSystem Info:\n Machine ID:                 c28d40cbc8e3adcb4e32d9779a77b39e\n System UUID:                9D55F51E-4643-4302-B670-8E3DD9970C06\n Boot ID:                    d4eabe38-d665-46fd-8c96-81d8689c5523\n Kernel Version:             3.10.0-862.el7.x86_64\n OS Image:                   CentOS Linux 7 (Core)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.1\n Kubelet Version:            v1.13.1\n Kube-Proxy Version:         v1.13.1\nPodCIDR:                     10.33.2.0/24\nNon-terminated Pods:         (7 in total)\n  Namespace                  Name                                 CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                 ------------  ----------  ---------------  -------------  ---\n  e2e-tests-kubectl-g5rpw    redis-master-vgw4w                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         2s\n  kube-system                etcd-guojing-1                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         26m\n  kube-system                kube-apiserver-guojing-1             250m (3%)     0 (0%)      0 (0%)           0 (0%)         28m\n  kube-system                kube-controller-manager-guojing-1    200m (2%)     0 (0%)      0 (0%)           0 (0%)         28m\n  kube-system                kube-flannel-cpmvg                   50m (0%)      300m (3%)   64M (0%)         500M (3%)      27m\n  kube-system                kube-proxy-4mfwt                     0 (0%)        0 (0%)      0 (0%)           0 (0%)         28m\n  kube-system                kube-scheduler-guojing-1             100m (1%)     0 (0%)      0 (0%)           0 (0%)         28m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests   Limits\n  --------           --------   ------\n  cpu                600m (7%)  300m (3%)\n  memory             64M (0%)   500M (3%)\n  ephemeral-storage  0 (0%)     0 (0%)\nEvents:\n  Type    Reason                   Age                From                   Message\n  ----    ------                   ----               ----                   -------\n  Normal  Starting                 28m                kubelet, guojing-1     Starting kubelet.\n  Normal  NodeHasSufficientMemory  28m (x7 over 28m)  kubelet, guojing-1     Node guojing-1 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    28m (x7 over 28m)  kubelet, guojing-1     Node guojing-1 status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     28m (x7 over 28m)  kubelet, guojing-1     Node guojing-1 status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced  28m                kubelet, guojing-1     Updated Node Allocatable limit across pods\n  Normal  Starting                 28m                kube-proxy, guojing-1  Starting kube-proxy.\n  Normal  NodeReady                27m                kubelet, guojing-1     Node guojing-1 status is now: NodeReady\n"
Dec 27 01:49:46.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 describe namespace e2e-tests-kubectl-g5rpw'
Dec 27 01:49:46.446: INFO: stderr: ""
Dec 27 01:49:46.446: INFO: stdout: "Name:         e2e-tests-kubectl-g5rpw\nLabels:       e2e-framework=kubectl\n              e2e-run=63c9e4d6-0976-11e9-a1bd-0a580a2100c6\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:49:46.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-g5rpw" for this suite.
Dec 27 01:50:08.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:50:08.506: INFO: namespace: e2e-tests-kubectl-g5rpw, resource: bindings, ignored listing per whitelist
Dec 27 01:50:08.517: INFO: namespace e2e-tests-kubectl-g5rpw deletion completed in 22.068088598s

• [SLOW TEST:24.149 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:50:08.517: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-bd73f59a-0979-11e9-a1bd-0a580a2100c6
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-bd73f59a-0979-11e9-a1bd-0a580a2100c6
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:50:12.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-f9mvd" for this suite.
Dec 27 01:50:34.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:50:34.674: INFO: namespace: e2e-tests-configmap-f9mvd, resource: bindings, ignored listing per whitelist
Dec 27 01:50:34.679: INFO: namespace e2e-tests-configmap-f9mvd deletion completed in 22.070025423s

• [SLOW TEST:26.162 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:50:34.680: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec 27 01:50:34.734: INFO: Waiting up to 5m0s for pod "pod-cd0b087b-0979-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-emptydir-vzqwp" to be "success or failure"
Dec 27 01:50:34.736: INFO: Pod "pod-cd0b087b-0979-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.739797ms
Dec 27 01:50:36.738: INFO: Pod "pod-cd0b087b-0979-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004295097s
STEP: Saw pod success
Dec 27 01:50:36.738: INFO: Pod "pod-cd0b087b-0979-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 01:50:36.740: INFO: Trying to get logs from node guojing-3 pod pod-cd0b087b-0979-11e9-a1bd-0a580a2100c6 container test-container: <nil>
STEP: delete the pod
Dec 27 01:50:36.758: INFO: Waiting for pod pod-cd0b087b-0979-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 01:50:36.760: INFO: Pod pod-cd0b087b-0979-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:50:36.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-vzqwp" for this suite.
Dec 27 01:50:42.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:50:42.808: INFO: namespace: e2e-tests-emptydir-vzqwp, resource: bindings, ignored listing per whitelist
Dec 27 01:50:42.831: INFO: namespace e2e-tests-emptydir-vzqwp deletion completed in 6.068403485s

• [SLOW TEST:8.152 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:50:42.831: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Dec 27 01:50:42.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 create -f - --namespace=e2e-tests-kubectl-54tk8'
Dec 27 01:50:43.026: INFO: stderr: ""
Dec 27 01:50:43.026: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 27 01:50:43.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-54tk8'
Dec 27 01:50:43.101: INFO: stderr: ""
Dec 27 01:50:43.101: INFO: stdout: "update-demo-nautilus-9qtzc update-demo-nautilus-pnpn9 "
Dec 27 01:50:43.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods update-demo-nautilus-9qtzc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-54tk8'
Dec 27 01:50:43.163: INFO: stderr: ""
Dec 27 01:50:43.163: INFO: stdout: ""
Dec 27 01:50:43.163: INFO: update-demo-nautilus-9qtzc is created but not running
Dec 27 01:50:48.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-54tk8'
Dec 27 01:50:48.229: INFO: stderr: ""
Dec 27 01:50:48.229: INFO: stdout: "update-demo-nautilus-9qtzc update-demo-nautilus-pnpn9 "
Dec 27 01:50:48.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods update-demo-nautilus-9qtzc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-54tk8'
Dec 27 01:50:48.295: INFO: stderr: ""
Dec 27 01:50:48.295: INFO: stdout: "true"
Dec 27 01:50:48.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods update-demo-nautilus-9qtzc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-54tk8'
Dec 27 01:50:48.364: INFO: stderr: ""
Dec 27 01:50:48.364: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 27 01:50:48.364: INFO: validating pod update-demo-nautilus-9qtzc
Dec 27 01:50:48.367: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 27 01:50:48.367: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 27 01:50:48.367: INFO: update-demo-nautilus-9qtzc is verified up and running
Dec 27 01:50:48.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods update-demo-nautilus-pnpn9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-54tk8'
Dec 27 01:50:48.426: INFO: stderr: ""
Dec 27 01:50:48.426: INFO: stdout: "true"
Dec 27 01:50:48.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods update-demo-nautilus-pnpn9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-54tk8'
Dec 27 01:50:48.488: INFO: stderr: ""
Dec 27 01:50:48.488: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 27 01:50:48.488: INFO: validating pod update-demo-nautilus-pnpn9
Dec 27 01:50:48.491: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 27 01:50:48.491: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 27 01:50:48.491: INFO: update-demo-nautilus-pnpn9 is verified up and running
STEP: using delete to clean up resources
Dec 27 01:50:48.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-54tk8'
Dec 27 01:50:48.556: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 27 01:50:48.556: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec 27 01:50:48.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-54tk8'
Dec 27 01:50:48.622: INFO: stderr: "No resources found.\n"
Dec 27 01:50:48.622: INFO: stdout: ""
Dec 27 01:50:48.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods -l name=update-demo --namespace=e2e-tests-kubectl-54tk8 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 27 01:50:48.685: INFO: stderr: ""
Dec 27 01:50:48.685: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:50:48.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-54tk8" for this suite.
Dec 27 01:50:54.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:50:54.714: INFO: namespace: e2e-tests-kubectl-54tk8, resource: bindings, ignored listing per whitelist
Dec 27 01:50:54.758: INFO: namespace e2e-tests-kubectl-54tk8 deletion completed in 6.069001624s

• [SLOW TEST:11.926 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:50:54.758: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec 27 01:50:54.813: INFO: Waiting up to 5m0s for pod "pod-d9034f91-0979-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-emptydir-jrvw2" to be "success or failure"
Dec 27 01:50:54.815: INFO: Pod "pod-d9034f91-0979-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.675197ms
Dec 27 01:50:56.818: INFO: Pod "pod-d9034f91-0979-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004297869s
STEP: Saw pod success
Dec 27 01:50:56.818: INFO: Pod "pod-d9034f91-0979-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 01:50:56.820: INFO: Trying to get logs from node guojing-3 pod pod-d9034f91-0979-11e9-a1bd-0a580a2100c6 container test-container: <nil>
STEP: delete the pod
Dec 27 01:50:56.834: INFO: Waiting for pod pod-d9034f91-0979-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 01:50:56.836: INFO: Pod pod-d9034f91-0979-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:50:56.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jrvw2" for this suite.
Dec 27 01:51:02.847: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:51:02.879: INFO: namespace: e2e-tests-emptydir-jrvw2, resource: bindings, ignored listing per whitelist
Dec 27 01:51:02.910: INFO: namespace e2e-tests-emptydir-jrvw2 deletion completed in 6.071467779s

• [SLOW TEST:8.153 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:51:02.910: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-2n49t
Dec 27 01:51:04.968: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-2n49t
STEP: checking the pod's current state and verifying that restartCount is present
Dec 27 01:51:04.970: INFO: Initial restart count of pod liveness-exec is 0
Dec 27 01:51:53.034: INFO: Restart count of pod e2e-tests-container-probe-2n49t/liveness-exec is now 1 (48.064227189s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:51:53.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-2n49t" for this suite.
Dec 27 01:51:59.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:51:59.105: INFO: namespace: e2e-tests-container-probe-2n49t, resource: bindings, ignored listing per whitelist
Dec 27 01:51:59.116: INFO: namespace e2e-tests-container-probe-2n49t deletion completed in 6.067879092s

• [SLOW TEST:56.206 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:51:59.116: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-ff5f7b76-0979-11e9-a1bd-0a580a2100c6
STEP: Creating a pod to test consume secrets
Dec 27 01:51:59.176: INFO: Waiting up to 5m0s for pod "pod-secrets-ff603025-0979-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-secrets-8fpth" to be "success or failure"
Dec 27 01:51:59.178: INFO: Pod "pod-secrets-ff603025-0979-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.873728ms
Dec 27 01:52:01.181: INFO: Pod "pod-secrets-ff603025-0979-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005523618s
STEP: Saw pod success
Dec 27 01:52:01.182: INFO: Pod "pod-secrets-ff603025-0979-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 01:52:01.183: INFO: Trying to get logs from node guojing-2 pod pod-secrets-ff603025-0979-11e9-a1bd-0a580a2100c6 container secret-volume-test: <nil>
STEP: delete the pod
Dec 27 01:52:01.209: INFO: Waiting for pod pod-secrets-ff603025-0979-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 01:52:01.211: INFO: Pod pod-secrets-ff603025-0979-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:52:01.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-8fpth" for this suite.
Dec 27 01:52:07.225: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:52:07.260: INFO: namespace: e2e-tests-secrets-8fpth, resource: bindings, ignored listing per whitelist
Dec 27 01:52:07.297: INFO: namespace e2e-tests-secrets-8fpth deletion completed in 6.082309616s

• [SLOW TEST:8.181 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:52:07.297: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W1227 01:52:08.372803      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 27 01:52:08.372: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:52:08.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-nq2bx" for this suite.
Dec 27 01:52:14.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:52:14.400: INFO: namespace: e2e-tests-gc-nq2bx, resource: bindings, ignored listing per whitelist
Dec 27 01:52:14.440: INFO: namespace e2e-tests-gc-nq2bx deletion completed in 6.065441935s

• [SLOW TEST:7.143 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:52:14.441: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1227 01:52:20.513222      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 27 01:52:20.513: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:52:20.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-9292t" for this suite.
Dec 27 01:52:26.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:52:26.558: INFO: namespace: e2e-tests-gc-9292t, resource: bindings, ignored listing per whitelist
Dec 27 01:52:26.580: INFO: namespace e2e-tests-gc-9292t deletion completed in 6.06446157s

• [SLOW TEST:12.139 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:52:26.580: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 27 01:52:26.631: INFO: (0) /api/v1/nodes/guojing-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.866773ms)
Dec 27 01:52:26.634: INFO: (1) /api/v1/nodes/guojing-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.191048ms)
Dec 27 01:52:26.636: INFO: (2) /api/v1/nodes/guojing-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.177684ms)
Dec 27 01:52:26.638: INFO: (3) /api/v1/nodes/guojing-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.256372ms)
Dec 27 01:52:26.640: INFO: (4) /api/v1/nodes/guojing-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.22081ms)
Dec 27 01:52:26.643: INFO: (5) /api/v1/nodes/guojing-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.343879ms)
Dec 27 01:52:26.645: INFO: (6) /api/v1/nodes/guojing-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.088093ms)
Dec 27 01:52:26.647: INFO: (7) /api/v1/nodes/guojing-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.178789ms)
Dec 27 01:52:26.649: INFO: (8) /api/v1/nodes/guojing-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.114628ms)
Dec 27 01:52:26.651: INFO: (9) /api/v1/nodes/guojing-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.107406ms)
Dec 27 01:52:26.653: INFO: (10) /api/v1/nodes/guojing-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.076614ms)
Dec 27 01:52:26.656: INFO: (11) /api/v1/nodes/guojing-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.169642ms)
Dec 27 01:52:26.658: INFO: (12) /api/v1/nodes/guojing-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.121388ms)
Dec 27 01:52:26.660: INFO: (13) /api/v1/nodes/guojing-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.278011ms)
Dec 27 01:52:26.662: INFO: (14) /api/v1/nodes/guojing-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.12618ms)
Dec 27 01:52:26.664: INFO: (15) /api/v1/nodes/guojing-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.170498ms)
Dec 27 01:52:26.666: INFO: (16) /api/v1/nodes/guojing-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.005841ms)
Dec 27 01:52:26.668: INFO: (17) /api/v1/nodes/guojing-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.012187ms)
Dec 27 01:52:26.670: INFO: (18) /api/v1/nodes/guojing-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.006365ms)
Dec 27 01:52:26.673: INFO: (19) /api/v1/nodes/guojing-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.10946ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:52:26.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-g2br7" for this suite.
Dec 27 01:52:32.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:52:32.703: INFO: namespace: e2e-tests-proxy-g2br7, resource: bindings, ignored listing per whitelist
Dec 27 01:52:32.743: INFO: namespace e2e-tests-proxy-g2br7 deletion completed in 6.068458787s

• [SLOW TEST:6.163 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:52:32.744: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-1369febe-097a-11e9-a1bd-0a580a2100c6
STEP: Creating a pod to test consume secrets
Dec 27 01:52:32.798: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-136ab6ea-097a-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-projected-9gszn" to be "success or failure"
Dec 27 01:52:32.800: INFO: Pod "pod-projected-secrets-136ab6ea-097a-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.760502ms
Dec 27 01:52:34.802: INFO: Pod "pod-projected-secrets-136ab6ea-097a-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004302515s
STEP: Saw pod success
Dec 27 01:52:34.802: INFO: Pod "pod-projected-secrets-136ab6ea-097a-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 01:52:34.804: INFO: Trying to get logs from node guojing-3 pod pod-projected-secrets-136ab6ea-097a-11e9-a1bd-0a580a2100c6 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 27 01:52:34.819: INFO: Waiting for pod pod-projected-secrets-136ab6ea-097a-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 01:52:34.821: INFO: Pod pod-projected-secrets-136ab6ea-097a-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:52:34.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9gszn" for this suite.
Dec 27 01:52:40.833: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:52:40.890: INFO: namespace: e2e-tests-projected-9gszn, resource: bindings, ignored listing per whitelist
Dec 27 01:52:40.894: INFO: namespace e2e-tests-projected-9gszn deletion completed in 6.069839227s

• [SLOW TEST:8.150 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:52:40.894: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 27 01:52:40.958: INFO: Waiting up to 5m0s for pod "downwardapi-volume-18479b8f-097a-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-projected-7sg2v" to be "success or failure"
Dec 27 01:52:40.960: INFO: Pod "downwardapi-volume-18479b8f-097a-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.943723ms
Dec 27 01:52:42.963: INFO: Pod "downwardapi-volume-18479b8f-097a-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004699742s
STEP: Saw pod success
Dec 27 01:52:42.963: INFO: Pod "downwardapi-volume-18479b8f-097a-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 01:52:42.964: INFO: Trying to get logs from node guojing-1 pod downwardapi-volume-18479b8f-097a-11e9-a1bd-0a580a2100c6 container client-container: <nil>
STEP: delete the pod
Dec 27 01:52:42.981: INFO: Waiting for pod downwardapi-volume-18479b8f-097a-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 01:52:42.983: INFO: Pod downwardapi-volume-18479b8f-097a-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:52:42.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7sg2v" for this suite.
Dec 27 01:52:48.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:52:49.034: INFO: namespace: e2e-tests-projected-7sg2v, resource: bindings, ignored listing per whitelist
Dec 27 01:52:49.053: INFO: namespace e2e-tests-projected-7sg2v deletion completed in 6.066713322s

• [SLOW TEST:8.159 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:52:49.053: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 27 01:52:49.101: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:52:58.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-xt7r8" for this suite.
Dec 27 01:53:04.155: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:53:04.208: INFO: namespace: e2e-tests-custom-resource-definition-xt7r8, resource: bindings, ignored listing per whitelist
Dec 27 01:53:04.213: INFO: namespace e2e-tests-custom-resource-definition-xt7r8 deletion completed in 6.066507979s

• [SLOW TEST:15.160 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:53:04.213: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-k4sc
STEP: Creating a pod to test atomic-volume-subpath
Dec 27 01:53:04.279: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-k4sc" in namespace "e2e-tests-subpath-v6v7c" to be "success or failure"
Dec 27 01:53:04.281: INFO: Pod "pod-subpath-test-downwardapi-k4sc": Phase="Pending", Reason="", readiness=false. Elapsed: 1.970476ms
Dec 27 01:53:06.283: INFO: Pod "pod-subpath-test-downwardapi-k4sc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00469235s
Dec 27 01:53:08.286: INFO: Pod "pod-subpath-test-downwardapi-k4sc": Phase="Running", Reason="", readiness=false. Elapsed: 4.007422065s
Dec 27 01:53:10.289: INFO: Pod "pod-subpath-test-downwardapi-k4sc": Phase="Running", Reason="", readiness=false. Elapsed: 6.010098044s
Dec 27 01:53:12.292: INFO: Pod "pod-subpath-test-downwardapi-k4sc": Phase="Running", Reason="", readiness=false. Elapsed: 8.012745255s
Dec 27 01:53:14.294: INFO: Pod "pod-subpath-test-downwardapi-k4sc": Phase="Running", Reason="", readiness=false. Elapsed: 10.015508598s
Dec 27 01:53:16.297: INFO: Pod "pod-subpath-test-downwardapi-k4sc": Phase="Running", Reason="", readiness=false. Elapsed: 12.018258149s
Dec 27 01:53:18.300: INFO: Pod "pod-subpath-test-downwardapi-k4sc": Phase="Running", Reason="", readiness=false. Elapsed: 14.020887947s
Dec 27 01:53:20.302: INFO: Pod "pod-subpath-test-downwardapi-k4sc": Phase="Running", Reason="", readiness=false. Elapsed: 16.023661522s
Dec 27 01:53:22.305: INFO: Pod "pod-subpath-test-downwardapi-k4sc": Phase="Running", Reason="", readiness=false. Elapsed: 18.026293196s
Dec 27 01:53:24.308: INFO: Pod "pod-subpath-test-downwardapi-k4sc": Phase="Running", Reason="", readiness=false. Elapsed: 20.029093981s
Dec 27 01:53:26.310: INFO: Pod "pod-subpath-test-downwardapi-k4sc": Phase="Running", Reason="", readiness=false. Elapsed: 22.031706932s
Dec 27 01:53:28.313: INFO: Pod "pod-subpath-test-downwardapi-k4sc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.034588345s
STEP: Saw pod success
Dec 27 01:53:28.313: INFO: Pod "pod-subpath-test-downwardapi-k4sc" satisfied condition "success or failure"
Dec 27 01:53:28.315: INFO: Trying to get logs from node guojing-2 pod pod-subpath-test-downwardapi-k4sc container test-container-subpath-downwardapi-k4sc: <nil>
STEP: delete the pod
Dec 27 01:53:28.333: INFO: Waiting for pod pod-subpath-test-downwardapi-k4sc to disappear
Dec 27 01:53:28.335: INFO: Pod pod-subpath-test-downwardapi-k4sc no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-k4sc
Dec 27 01:53:28.335: INFO: Deleting pod "pod-subpath-test-downwardapi-k4sc" in namespace "e2e-tests-subpath-v6v7c"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:53:28.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-v6v7c" for this suite.
Dec 27 01:53:34.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:53:34.385: INFO: namespace: e2e-tests-subpath-v6v7c, resource: bindings, ignored listing per whitelist
Dec 27 01:53:34.407: INFO: namespace e2e-tests-subpath-v6v7c deletion completed in 6.066633161s

• [SLOW TEST:30.193 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:53:34.407: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-382b4691-097a-11e9-a1bd-0a580a2100c6
STEP: Creating a pod to test consume secrets
Dec 27 01:53:34.465: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-382c494c-097a-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-projected-stlxn" to be "success or failure"
Dec 27 01:53:34.466: INFO: Pod "pod-projected-secrets-382c494c-097a-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.701107ms
Dec 27 01:53:36.469: INFO: Pod "pod-projected-secrets-382c494c-097a-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004238485s
STEP: Saw pod success
Dec 27 01:53:36.469: INFO: Pod "pod-projected-secrets-382c494c-097a-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 01:53:36.471: INFO: Trying to get logs from node guojing-3 pod pod-projected-secrets-382c494c-097a-11e9-a1bd-0a580a2100c6 container secret-volume-test: <nil>
STEP: delete the pod
Dec 27 01:53:36.485: INFO: Waiting for pod pod-projected-secrets-382c494c-097a-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 01:53:36.487: INFO: Pod pod-projected-secrets-382c494c-097a-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:53:36.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-stlxn" for this suite.
Dec 27 01:53:42.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:53:42.515: INFO: namespace: e2e-tests-projected-stlxn, resource: bindings, ignored listing per whitelist
Dec 27 01:53:42.557: INFO: namespace e2e-tests-projected-stlxn deletion completed in 6.067605199s

• [SLOW TEST:8.150 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:53:42.557: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 27 01:53:42.620: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Dec 27 01:53:42.627: INFO: Number of nodes with available pods: 0
Dec 27 01:53:42.627: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Dec 27 01:53:42.648: INFO: Number of nodes with available pods: 0
Dec 27 01:53:42.648: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 01:53:43.650: INFO: Number of nodes with available pods: 0
Dec 27 01:53:43.650: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 01:53:44.650: INFO: Number of nodes with available pods: 1
Dec 27 01:53:44.650: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Dec 27 01:53:44.664: INFO: Number of nodes with available pods: 1
Dec 27 01:53:44.664: INFO: Number of running nodes: 0, number of available pods: 1
Dec 27 01:53:45.667: INFO: Number of nodes with available pods: 0
Dec 27 01:53:45.667: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Dec 27 01:53:45.674: INFO: Number of nodes with available pods: 0
Dec 27 01:53:45.674: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 01:53:46.676: INFO: Number of nodes with available pods: 0
Dec 27 01:53:46.676: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 01:53:47.677: INFO: Number of nodes with available pods: 0
Dec 27 01:53:47.677: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 01:53:48.676: INFO: Number of nodes with available pods: 0
Dec 27 01:53:48.676: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 01:53:49.677: INFO: Number of nodes with available pods: 0
Dec 27 01:53:49.677: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 01:53:50.676: INFO: Number of nodes with available pods: 0
Dec 27 01:53:50.677: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 01:53:51.677: INFO: Number of nodes with available pods: 0
Dec 27 01:53:51.677: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 01:53:52.677: INFO: Number of nodes with available pods: 0
Dec 27 01:53:52.677: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 01:53:53.676: INFO: Number of nodes with available pods: 0
Dec 27 01:53:53.676: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 01:53:54.677: INFO: Number of nodes with available pods: 0
Dec 27 01:53:54.677: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 01:53:55.677: INFO: Number of nodes with available pods: 0
Dec 27 01:53:55.677: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 01:53:56.677: INFO: Number of nodes with available pods: 0
Dec 27 01:53:56.677: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 01:53:57.676: INFO: Number of nodes with available pods: 0
Dec 27 01:53:57.676: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 01:53:58.676: INFO: Number of nodes with available pods: 0
Dec 27 01:53:58.676: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 01:53:59.677: INFO: Number of nodes with available pods: 0
Dec 27 01:53:59.677: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 01:54:00.677: INFO: Number of nodes with available pods: 0
Dec 27 01:54:00.677: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 01:54:01.677: INFO: Number of nodes with available pods: 0
Dec 27 01:54:01.677: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 01:54:02.676: INFO: Number of nodes with available pods: 0
Dec 27 01:54:02.676: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 01:54:03.676: INFO: Number of nodes with available pods: 0
Dec 27 01:54:03.676: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 01:54:04.677: INFO: Number of nodes with available pods: 0
Dec 27 01:54:04.677: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 01:54:05.677: INFO: Number of nodes with available pods: 0
Dec 27 01:54:05.677: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 01:54:06.676: INFO: Number of nodes with available pods: 0
Dec 27 01:54:06.676: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 01:54:07.676: INFO: Number of nodes with available pods: 0
Dec 27 01:54:07.676: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 01:54:08.677: INFO: Number of nodes with available pods: 0
Dec 27 01:54:08.677: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 01:54:09.677: INFO: Number of nodes with available pods: 0
Dec 27 01:54:09.677: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 01:54:10.677: INFO: Number of nodes with available pods: 0
Dec 27 01:54:10.677: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 01:54:11.677: INFO: Number of nodes with available pods: 0
Dec 27 01:54:11.677: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 01:54:12.676: INFO: Number of nodes with available pods: 0
Dec 27 01:54:12.676: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 01:54:13.676: INFO: Number of nodes with available pods: 0
Dec 27 01:54:13.676: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 01:54:14.676: INFO: Number of nodes with available pods: 0
Dec 27 01:54:14.676: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 01:54:15.677: INFO: Number of nodes with available pods: 0
Dec 27 01:54:15.677: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 01:54:16.676: INFO: Number of nodes with available pods: 0
Dec 27 01:54:16.676: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 01:54:17.677: INFO: Number of nodes with available pods: 0
Dec 27 01:54:17.677: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 01:54:18.677: INFO: Number of nodes with available pods: 0
Dec 27 01:54:18.677: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 01:54:19.677: INFO: Number of nodes with available pods: 1
Dec 27 01:54:19.677: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-s884z, will wait for the garbage collector to delete the pods
Dec 27 01:54:19.740: INFO: Deleting DaemonSet.extensions daemon-set took: 8.217663ms
Dec 27 01:54:19.840: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.144311ms
Dec 27 01:55:04.143: INFO: Number of nodes with available pods: 0
Dec 27 01:55:04.143: INFO: Number of running nodes: 0, number of available pods: 0
Dec 27 01:55:04.144: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-s884z/daemonsets","resourceVersion":"7629"},"items":null}

Dec 27 01:55:04.146: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-s884z/pods","resourceVersion":"7629"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:55:04.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-s884z" for this suite.
Dec 27 01:55:10.174: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:55:10.183: INFO: namespace: e2e-tests-daemonsets-s884z, resource: bindings, ignored listing per whitelist
Dec 27 01:55:10.231: INFO: namespace e2e-tests-daemonsets-s884z deletion completed in 6.06589826s

• [SLOW TEST:87.674 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:55:10.231: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 27 01:55:10.287: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7149089b-097a-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-projected-qv77t" to be "success or failure"
Dec 27 01:55:10.289: INFO: Pod "downwardapi-volume-7149089b-097a-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.87065ms
Dec 27 01:55:12.291: INFO: Pod "downwardapi-volume-7149089b-097a-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00449529s
STEP: Saw pod success
Dec 27 01:55:12.292: INFO: Pod "downwardapi-volume-7149089b-097a-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 01:55:12.293: INFO: Trying to get logs from node guojing-2 pod downwardapi-volume-7149089b-097a-11e9-a1bd-0a580a2100c6 container client-container: <nil>
STEP: delete the pod
Dec 27 01:55:12.317: INFO: Waiting for pod downwardapi-volume-7149089b-097a-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 01:55:12.318: INFO: Pod downwardapi-volume-7149089b-097a-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:55:12.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qv77t" for this suite.
Dec 27 01:55:18.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:55:18.380: INFO: namespace: e2e-tests-projected-qv77t, resource: bindings, ignored listing per whitelist
Dec 27 01:55:18.391: INFO: namespace e2e-tests-projected-qv77t deletion completed in 6.064879168s

• [SLOW TEST:8.160 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:55:18.391: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Dec 27 01:55:18.436: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-574749520 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:55:18.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bdgms" for this suite.
Dec 27 01:55:24.501: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:55:24.532: INFO: namespace: e2e-tests-kubectl-bdgms, resource: bindings, ignored listing per whitelist
Dec 27 01:55:24.558: INFO: namespace e2e-tests-kubectl-bdgms deletion completed in 6.065234975s

• [SLOW TEST:6.167 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:55:24.558: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:55:26.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-r9zzh" for this suite.
Dec 27 01:56:10.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:56:10.648: INFO: namespace: e2e-tests-kubelet-test-r9zzh, resource: bindings, ignored listing per whitelist
Dec 27 01:56:10.695: INFO: namespace e2e-tests-kubelet-test-r9zzh deletion completed in 44.065022995s

• [SLOW TEST:46.137 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:56:10.695: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-9552f320-097a-11e9-a1bd-0a580a2100c6
STEP: Creating a pod to test consume secrets
Dec 27 01:56:10.753: INFO: Waiting up to 5m0s for pod "pod-secrets-9553e2a7-097a-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-secrets-lwjcd" to be "success or failure"
Dec 27 01:56:10.758: INFO: Pod "pod-secrets-9553e2a7-097a-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 5.023122ms
Dec 27 01:56:12.761: INFO: Pod "pod-secrets-9553e2a7-097a-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008413803s
STEP: Saw pod success
Dec 27 01:56:12.761: INFO: Pod "pod-secrets-9553e2a7-097a-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 01:56:12.764: INFO: Trying to get logs from node guojing-3 pod pod-secrets-9553e2a7-097a-11e9-a1bd-0a580a2100c6 container secret-volume-test: <nil>
STEP: delete the pod
Dec 27 01:56:12.779: INFO: Waiting for pod pod-secrets-9553e2a7-097a-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 01:56:12.781: INFO: Pod pod-secrets-9553e2a7-097a-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:56:12.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-lwjcd" for this suite.
Dec 27 01:56:18.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:56:18.812: INFO: namespace: e2e-tests-secrets-lwjcd, resource: bindings, ignored listing per whitelist
Dec 27 01:56:18.848: INFO: namespace e2e-tests-secrets-lwjcd deletion completed in 6.064607092s

• [SLOW TEST:8.153 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:56:18.849: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 27 01:56:18.903: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9a2f4a02-097a-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-downward-api-2m499" to be "success or failure"
Dec 27 01:56:18.908: INFO: Pod "downwardapi-volume-9a2f4a02-097a-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 5.175822ms
Dec 27 01:56:20.910: INFO: Pod "downwardapi-volume-9a2f4a02-097a-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00774008s
STEP: Saw pod success
Dec 27 01:56:20.910: INFO: Pod "downwardapi-volume-9a2f4a02-097a-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 01:56:20.912: INFO: Trying to get logs from node guojing-1 pod downwardapi-volume-9a2f4a02-097a-11e9-a1bd-0a580a2100c6 container client-container: <nil>
STEP: delete the pod
Dec 27 01:56:20.928: INFO: Waiting for pod downwardapi-volume-9a2f4a02-097a-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 01:56:20.930: INFO: Pod downwardapi-volume-9a2f4a02-097a-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:56:20.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2m499" for this suite.
Dec 27 01:56:26.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:56:26.966: INFO: namespace: e2e-tests-downward-api-2m499, resource: bindings, ignored listing per whitelist
Dec 27 01:56:26.995: INFO: namespace e2e-tests-downward-api-2m499 deletion completed in 6.063136718s

• [SLOW TEST:8.147 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:56:26.996: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec 27 01:56:27.055: INFO: Waiting up to 5m0s for pod "pod-9f0b214a-097a-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-emptydir-nzggr" to be "success or failure"
Dec 27 01:56:27.057: INFO: Pod "pod-9f0b214a-097a-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.714913ms
Dec 27 01:56:29.060: INFO: Pod "pod-9f0b214a-097a-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004180881s
STEP: Saw pod success
Dec 27 01:56:29.060: INFO: Pod "pod-9f0b214a-097a-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 01:56:29.061: INFO: Trying to get logs from node guojing-2 pod pod-9f0b214a-097a-11e9-a1bd-0a580a2100c6 container test-container: <nil>
STEP: delete the pod
Dec 27 01:56:29.075: INFO: Waiting for pod pod-9f0b214a-097a-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 01:56:29.080: INFO: Pod pod-9f0b214a-097a-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:56:29.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-nzggr" for this suite.
Dec 27 01:56:35.094: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:56:35.114: INFO: namespace: e2e-tests-emptydir-nzggr, resource: bindings, ignored listing per whitelist
Dec 27 01:56:35.154: INFO: namespace e2e-tests-emptydir-nzggr deletion completed in 6.071202287s

• [SLOW TEST:8.158 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:56:35.154: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-a3e7b356-097a-11e9-a1bd-0a580a2100c6
Dec 27 01:56:35.211: INFO: Pod name my-hostname-basic-a3e7b356-097a-11e9-a1bd-0a580a2100c6: Found 0 pods out of 1
Dec 27 01:56:40.213: INFO: Pod name my-hostname-basic-a3e7b356-097a-11e9-a1bd-0a580a2100c6: Found 1 pods out of 1
Dec 27 01:56:40.213: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-a3e7b356-097a-11e9-a1bd-0a580a2100c6" are running
Dec 27 01:56:40.215: INFO: Pod "my-hostname-basic-a3e7b356-097a-11e9-a1bd-0a580a2100c6-zdkr6" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-27 01:56:35 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-27 01:56:36 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-27 01:56:36 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-27 01:56:35 +0000 UTC Reason: Message:}])
Dec 27 01:56:40.215: INFO: Trying to dial the pod
Dec 27 01:56:45.223: INFO: Controller my-hostname-basic-a3e7b356-097a-11e9-a1bd-0a580a2100c6: Got expected result from replica 1 [my-hostname-basic-a3e7b356-097a-11e9-a1bd-0a580a2100c6-zdkr6]: "my-hostname-basic-a3e7b356-097a-11e9-a1bd-0a580a2100c6-zdkr6", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:56:45.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-crcbf" for this suite.
Dec 27 01:56:51.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:56:51.271: INFO: namespace: e2e-tests-replication-controller-crcbf, resource: bindings, ignored listing per whitelist
Dec 27 01:56:51.299: INFO: namespace e2e-tests-replication-controller-crcbf deletion completed in 6.073053307s

• [SLOW TEST:16.145 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:56:51.299: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-d4247
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-d4247
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-d4247
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-d4247
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-d4247
Dec 27 01:56:53.371: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-d4247, name: ss-0, uid: ad94a8a2-097a-11e9-b34c-525400cd4ed0, status phase: Pending. Waiting for statefulset controller to delete.
Dec 27 01:56:54.050: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-d4247, name: ss-0, uid: ad94a8a2-097a-11e9-b34c-525400cd4ed0, status phase: Failed. Waiting for statefulset controller to delete.
Dec 27 01:56:54.056: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-d4247, name: ss-0, uid: ad94a8a2-097a-11e9-b34c-525400cd4ed0, status phase: Failed. Waiting for statefulset controller to delete.
Dec 27 01:56:54.065: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-d4247
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-d4247
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-d4247 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec 27 01:56:56.093: INFO: Deleting all statefulset in ns e2e-tests-statefulset-d4247
Dec 27 01:56:56.095: INFO: Scaling statefulset ss to 0
Dec 27 01:57:06.108: INFO: Waiting for statefulset status.replicas updated to 0
Dec 27 01:57:06.110: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:57:06.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-d4247" for this suite.
Dec 27 01:57:12.134: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:57:12.141: INFO: namespace: e2e-tests-statefulset-d4247, resource: bindings, ignored listing per whitelist
Dec 27 01:57:12.191: INFO: namespace e2e-tests-statefulset-d4247 deletion completed in 6.069323176s

• [SLOW TEST:20.892 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:57:12.191: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec 27 01:57:14.767: INFO: Successfully updated pod "pod-update-b9faddaa-097a-11e9-a1bd-0a580a2100c6"
STEP: verifying the updated pod is in kubernetes
Dec 27 01:57:14.770: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:57:14.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-4w68g" for this suite.
Dec 27 01:57:36.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:57:36.830: INFO: namespace: e2e-tests-pods-4w68g, resource: bindings, ignored listing per whitelist
Dec 27 01:57:36.840: INFO: namespace e2e-tests-pods-4w68g deletion completed in 22.067007296s

• [SLOW TEST:24.649 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:57:36.840: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec 27 01:57:39.415: INFO: Successfully updated pod "pod-update-activedeadlineseconds-c8aca9de-097a-11e9-a1bd-0a580a2100c6"
Dec 27 01:57:39.415: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-c8aca9de-097a-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-pods-bfhjq" to be "terminated due to deadline exceeded"
Dec 27 01:57:39.417: INFO: Pod "pod-update-activedeadlineseconds-c8aca9de-097a-11e9-a1bd-0a580a2100c6": Phase="Running", Reason="", readiness=true. Elapsed: 1.831524ms
Dec 27 01:57:41.420: INFO: Pod "pod-update-activedeadlineseconds-c8aca9de-097a-11e9-a1bd-0a580a2100c6": Phase="Running", Reason="", readiness=true. Elapsed: 2.00460893s
Dec 27 01:57:43.422: INFO: Pod "pod-update-activedeadlineseconds-c8aca9de-097a-11e9-a1bd-0a580a2100c6": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.007171029s
Dec 27 01:57:43.422: INFO: Pod "pod-update-activedeadlineseconds-c8aca9de-097a-11e9-a1bd-0a580a2100c6" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:57:43.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-bfhjq" for this suite.
Dec 27 01:57:49.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:57:49.473: INFO: namespace: e2e-tests-pods-bfhjq, resource: bindings, ignored listing per whitelist
Dec 27 01:57:49.492: INFO: namespace e2e-tests-pods-bfhjq deletion completed in 6.066854375s

• [SLOW TEST:12.652 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:57:49.492: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-rh7pd/configmap-test-d03609ea-097a-11e9-a1bd-0a580a2100c6
STEP: Creating a pod to test consume configMaps
Dec 27 01:57:49.547: INFO: Waiting up to 5m0s for pod "pod-configmaps-d036c58b-097a-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-configmap-rh7pd" to be "success or failure"
Dec 27 01:57:49.548: INFO: Pod "pod-configmaps-d036c58b-097a-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.764517ms
Dec 27 01:57:51.551: INFO: Pod "pod-configmaps-d036c58b-097a-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0047686s
STEP: Saw pod success
Dec 27 01:57:51.551: INFO: Pod "pod-configmaps-d036c58b-097a-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 01:57:51.553: INFO: Trying to get logs from node guojing-3 pod pod-configmaps-d036c58b-097a-11e9-a1bd-0a580a2100c6 container env-test: <nil>
STEP: delete the pod
Dec 27 01:57:51.568: INFO: Waiting for pod pod-configmaps-d036c58b-097a-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 01:57:51.570: INFO: Pod pod-configmaps-d036c58b-097a-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:57:51.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-rh7pd" for this suite.
Dec 27 01:57:57.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:57:57.591: INFO: namespace: e2e-tests-configmap-rh7pd, resource: bindings, ignored listing per whitelist
Dec 27 01:57:57.644: INFO: namespace e2e-tests-configmap-rh7pd deletion completed in 6.071783245s

• [SLOW TEST:8.152 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:57:57.645: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Dec 27 01:57:57.698: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-dgrxd,SelfLink:/api/v1/namespaces/e2e-tests-watch-dgrxd/configmaps/e2e-watch-test-configmap-a,UID:d512d45b-097a-11e9-9853-debd8636412e,ResourceVersion:8276,Generation:0,CreationTimestamp:2018-12-27 01:57:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 27 01:57:57.698: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-dgrxd,SelfLink:/api/v1/namespaces/e2e-tests-watch-dgrxd/configmaps/e2e-watch-test-configmap-a,UID:d512d45b-097a-11e9-9853-debd8636412e,ResourceVersion:8276,Generation:0,CreationTimestamp:2018-12-27 01:57:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Dec 27 01:58:07.705: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-dgrxd,SelfLink:/api/v1/namespaces/e2e-tests-watch-dgrxd/configmaps/e2e-watch-test-configmap-a,UID:d512d45b-097a-11e9-9853-debd8636412e,ResourceVersion:8293,Generation:0,CreationTimestamp:2018-12-27 01:57:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec 27 01:58:07.705: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-dgrxd,SelfLink:/api/v1/namespaces/e2e-tests-watch-dgrxd/configmaps/e2e-watch-test-configmap-a,UID:d512d45b-097a-11e9-9853-debd8636412e,ResourceVersion:8293,Generation:0,CreationTimestamp:2018-12-27 01:57:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Dec 27 01:58:17.716: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-dgrxd,SelfLink:/api/v1/namespaces/e2e-tests-watch-dgrxd/configmaps/e2e-watch-test-configmap-a,UID:d512d45b-097a-11e9-9853-debd8636412e,ResourceVersion:8310,Generation:0,CreationTimestamp:2018-12-27 01:57:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 27 01:58:17.716: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-dgrxd,SelfLink:/api/v1/namespaces/e2e-tests-watch-dgrxd/configmaps/e2e-watch-test-configmap-a,UID:d512d45b-097a-11e9-9853-debd8636412e,ResourceVersion:8310,Generation:0,CreationTimestamp:2018-12-27 01:57:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Dec 27 01:58:27.722: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-dgrxd,SelfLink:/api/v1/namespaces/e2e-tests-watch-dgrxd/configmaps/e2e-watch-test-configmap-a,UID:d512d45b-097a-11e9-9853-debd8636412e,ResourceVersion:8327,Generation:0,CreationTimestamp:2018-12-27 01:57:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 27 01:58:27.722: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-dgrxd,SelfLink:/api/v1/namespaces/e2e-tests-watch-dgrxd/configmaps/e2e-watch-test-configmap-a,UID:d512d45b-097a-11e9-9853-debd8636412e,ResourceVersion:8327,Generation:0,CreationTimestamp:2018-12-27 01:57:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Dec 27 01:58:37.728: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-dgrxd,SelfLink:/api/v1/namespaces/e2e-tests-watch-dgrxd/configmaps/e2e-watch-test-configmap-b,UID:eceeea0b-097a-11e9-9853-debd8636412e,ResourceVersion:8344,Generation:0,CreationTimestamp:2018-12-27 01:58:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 27 01:58:37.728: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-dgrxd,SelfLink:/api/v1/namespaces/e2e-tests-watch-dgrxd/configmaps/e2e-watch-test-configmap-b,UID:eceeea0b-097a-11e9-9853-debd8636412e,ResourceVersion:8344,Generation:0,CreationTimestamp:2018-12-27 01:58:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Dec 27 01:58:47.734: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-dgrxd,SelfLink:/api/v1/namespaces/e2e-tests-watch-dgrxd/configmaps/e2e-watch-test-configmap-b,UID:eceeea0b-097a-11e9-9853-debd8636412e,ResourceVersion:8361,Generation:0,CreationTimestamp:2018-12-27 01:58:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 27 01:58:47.734: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-dgrxd,SelfLink:/api/v1/namespaces/e2e-tests-watch-dgrxd/configmaps/e2e-watch-test-configmap-b,UID:eceeea0b-097a-11e9-9853-debd8636412e,ResourceVersion:8361,Generation:0,CreationTimestamp:2018-12-27 01:58:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:58:57.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-dgrxd" for this suite.
Dec 27 01:59:03.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:59:03.783: INFO: namespace: e2e-tests-watch-dgrxd, resource: bindings, ignored listing per whitelist
Dec 27 01:59:03.803: INFO: namespace e2e-tests-watch-dgrxd deletion completed in 6.065247386s

• [SLOW TEST:66.159 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:59:03.803: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec 27 01:59:03.857: INFO: Waiting up to 5m0s for pod "pod-fc814909-097a-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-emptydir-rf9ng" to be "success or failure"
Dec 27 01:59:03.858: INFO: Pod "pod-fc814909-097a-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.797203ms
Dec 27 01:59:05.861: INFO: Pod "pod-fc814909-097a-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004183352s
STEP: Saw pod success
Dec 27 01:59:05.861: INFO: Pod "pod-fc814909-097a-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 01:59:05.863: INFO: Trying to get logs from node guojing-1 pod pod-fc814909-097a-11e9-a1bd-0a580a2100c6 container test-container: <nil>
STEP: delete the pod
Dec 27 01:59:05.880: INFO: Waiting for pod pod-fc814909-097a-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 01:59:05.882: INFO: Pod pod-fc814909-097a-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:59:05.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-rf9ng" for this suite.
Dec 27 01:59:11.894: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:59:11.908: INFO: namespace: e2e-tests-emptydir-rf9ng, resource: bindings, ignored listing per whitelist
Dec 27 01:59:11.952: INFO: namespace e2e-tests-emptydir-rf9ng deletion completed in 6.066760998s

• [SLOW TEST:8.148 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:59:11.952: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Dec 27 01:59:11.998: INFO: namespace e2e-tests-kubectl-xfr9m
Dec 27 01:59:11.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 create -f - --namespace=e2e-tests-kubectl-xfr9m'
Dec 27 01:59:12.163: INFO: stderr: ""
Dec 27 01:59:12.163: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 27 01:59:13.171: INFO: Selector matched 1 pods for map[app:redis]
Dec 27 01:59:13.171: INFO: Found 1 / 1
Dec 27 01:59:13.171: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 27 01:59:13.172: INFO: Selector matched 1 pods for map[app:redis]
Dec 27 01:59:13.172: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 27 01:59:13.172: INFO: wait on redis-master startup in e2e-tests-kubectl-xfr9m 
Dec 27 01:59:13.173: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 logs redis-master-vwqm2 redis-master --namespace=e2e-tests-kubectl-xfr9m'
Dec 27 01:59:13.261: INFO: stderr: ""
Dec 27 01:59:13.261: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 27 Dec 01:59:12.921 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 27 Dec 01:59:12.921 # Server started, Redis version 3.2.12\n1:M 27 Dec 01:59:12.921 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 27 Dec 01:59:12.921 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Dec 27 01:59:13.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-xfr9m'
Dec 27 01:59:13.353: INFO: stderr: ""
Dec 27 01:59:13.353: INFO: stdout: "service/rm2 exposed\n"
Dec 27 01:59:13.356: INFO: Service rm2 in namespace e2e-tests-kubectl-xfr9m found.
STEP: exposing service
Dec 27 01:59:15.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-xfr9m'
Dec 27 01:59:15.458: INFO: stderr: ""
Dec 27 01:59:15.458: INFO: stdout: "service/rm3 exposed\n"
Dec 27 01:59:15.462: INFO: Service rm3 in namespace e2e-tests-kubectl-xfr9m found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 01:59:17.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xfr9m" for this suite.
Dec 27 01:59:39.478: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 01:59:39.517: INFO: namespace: e2e-tests-kubectl-xfr9m, resource: bindings, ignored listing per whitelist
Dec 27 01:59:39.537: INFO: namespace e2e-tests-kubectl-xfr9m deletion completed in 22.067881866s

• [SLOW TEST:27.585 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 01:59:39.537: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-vs2k
STEP: Creating a pod to test atomic-volume-subpath
Dec 27 01:59:39.603: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-vs2k" in namespace "e2e-tests-subpath-59bwn" to be "success or failure"
Dec 27 01:59:39.605: INFO: Pod "pod-subpath-test-projected-vs2k": Phase="Pending", Reason="", readiness=false. Elapsed: 1.838457ms
Dec 27 01:59:41.607: INFO: Pod "pod-subpath-test-projected-vs2k": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004679959s
Dec 27 01:59:43.610: INFO: Pod "pod-subpath-test-projected-vs2k": Phase="Running", Reason="", readiness=false. Elapsed: 4.00754001s
Dec 27 01:59:45.613: INFO: Pod "pod-subpath-test-projected-vs2k": Phase="Running", Reason="", readiness=false. Elapsed: 6.010303875s
Dec 27 01:59:47.616: INFO: Pod "pod-subpath-test-projected-vs2k": Phase="Running", Reason="", readiness=false. Elapsed: 8.013243917s
Dec 27 01:59:49.619: INFO: Pod "pod-subpath-test-projected-vs2k": Phase="Running", Reason="", readiness=false. Elapsed: 10.016077335s
Dec 27 01:59:51.622: INFO: Pod "pod-subpath-test-projected-vs2k": Phase="Running", Reason="", readiness=false. Elapsed: 12.018754993s
Dec 27 01:59:53.624: INFO: Pod "pod-subpath-test-projected-vs2k": Phase="Running", Reason="", readiness=false. Elapsed: 14.021517158s
Dec 27 01:59:55.627: INFO: Pod "pod-subpath-test-projected-vs2k": Phase="Running", Reason="", readiness=false. Elapsed: 16.024213613s
Dec 27 01:59:57.630: INFO: Pod "pod-subpath-test-projected-vs2k": Phase="Running", Reason="", readiness=false. Elapsed: 18.027125331s
Dec 27 01:59:59.633: INFO: Pod "pod-subpath-test-projected-vs2k": Phase="Running", Reason="", readiness=false. Elapsed: 20.029801617s
Dec 27 02:00:01.636: INFO: Pod "pod-subpath-test-projected-vs2k": Phase="Running", Reason="", readiness=false. Elapsed: 22.032920008s
Dec 27 02:00:03.639: INFO: Pod "pod-subpath-test-projected-vs2k": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.036023794s
STEP: Saw pod success
Dec 27 02:00:03.639: INFO: Pod "pod-subpath-test-projected-vs2k" satisfied condition "success or failure"
Dec 27 02:00:03.641: INFO: Trying to get logs from node guojing-3 pod pod-subpath-test-projected-vs2k container test-container-subpath-projected-vs2k: <nil>
STEP: delete the pod
Dec 27 02:00:03.657: INFO: Waiting for pod pod-subpath-test-projected-vs2k to disappear
Dec 27 02:00:03.659: INFO: Pod pod-subpath-test-projected-vs2k no longer exists
STEP: Deleting pod pod-subpath-test-projected-vs2k
Dec 27 02:00:03.659: INFO: Deleting pod "pod-subpath-test-projected-vs2k" in namespace "e2e-tests-subpath-59bwn"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:00:03.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-59bwn" for this suite.
Dec 27 02:00:09.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:00:09.723: INFO: namespace: e2e-tests-subpath-59bwn, resource: bindings, ignored listing per whitelist
Dec 27 02:00:09.729: INFO: namespace e2e-tests-subpath-59bwn deletion completed in 6.066197855s

• [SLOW TEST:30.192 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:00:09.730: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Dec 27 02:00:09.782: INFO: Waiting up to 5m0s for pod "client-containers-23ccafdf-097b-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-containers-r6hw9" to be "success or failure"
Dec 27 02:00:09.785: INFO: Pod "client-containers-23ccafdf-097b-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.305762ms
Dec 27 02:00:11.788: INFO: Pod "client-containers-23ccafdf-097b-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0060593s
Dec 27 02:00:13.790: INFO: Pod "client-containers-23ccafdf-097b-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008363146s
STEP: Saw pod success
Dec 27 02:00:13.790: INFO: Pod "client-containers-23ccafdf-097b-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:00:13.792: INFO: Trying to get logs from node guojing-1 pod client-containers-23ccafdf-097b-11e9-a1bd-0a580a2100c6 container test-container: <nil>
STEP: delete the pod
Dec 27 02:00:13.813: INFO: Waiting for pod client-containers-23ccafdf-097b-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:00:13.815: INFO: Pod client-containers-23ccafdf-097b-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:00:13.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-r6hw9" for this suite.
Dec 27 02:00:19.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:00:19.857: INFO: namespace: e2e-tests-containers-r6hw9, resource: bindings, ignored listing per whitelist
Dec 27 02:00:19.886: INFO: namespace e2e-tests-containers-r6hw9 deletion completed in 6.068621999s

• [SLOW TEST:10.157 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:00:19.886: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec 27 02:00:19.963: INFO: Number of nodes with available pods: 0
Dec 27 02:00:19.963: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:00:20.970: INFO: Number of nodes with available pods: 0
Dec 27 02:00:20.970: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:00:21.968: INFO: Number of nodes with available pods: 3
Dec 27 02:00:21.968: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Dec 27 02:00:21.983: INFO: Number of nodes with available pods: 2
Dec 27 02:00:21.983: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:00:22.989: INFO: Number of nodes with available pods: 2
Dec 27 02:00:22.989: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:00:23.990: INFO: Number of nodes with available pods: 2
Dec 27 02:00:23.990: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:00:24.990: INFO: Number of nodes with available pods: 2
Dec 27 02:00:24.990: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:00:25.989: INFO: Number of nodes with available pods: 2
Dec 27 02:00:25.989: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:00:26.989: INFO: Number of nodes with available pods: 2
Dec 27 02:00:26.989: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:00:27.990: INFO: Number of nodes with available pods: 2
Dec 27 02:00:27.990: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:00:28.990: INFO: Number of nodes with available pods: 2
Dec 27 02:00:28.990: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:00:29.993: INFO: Number of nodes with available pods: 2
Dec 27 02:00:29.993: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:00:30.989: INFO: Number of nodes with available pods: 2
Dec 27 02:00:30.989: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:00:31.989: INFO: Number of nodes with available pods: 2
Dec 27 02:00:31.989: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:00:32.990: INFO: Number of nodes with available pods: 2
Dec 27 02:00:32.990: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:00:33.989: INFO: Number of nodes with available pods: 2
Dec 27 02:00:33.989: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:00:34.989: INFO: Number of nodes with available pods: 2
Dec 27 02:00:34.989: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:00:35.990: INFO: Number of nodes with available pods: 2
Dec 27 02:00:35.990: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:00:36.989: INFO: Number of nodes with available pods: 2
Dec 27 02:00:36.989: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:00:37.989: INFO: Number of nodes with available pods: 2
Dec 27 02:00:37.989: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:00:38.989: INFO: Number of nodes with available pods: 2
Dec 27 02:00:38.989: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:00:39.989: INFO: Number of nodes with available pods: 2
Dec 27 02:00:39.989: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:00:40.993: INFO: Number of nodes with available pods: 2
Dec 27 02:00:40.993: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:00:41.989: INFO: Number of nodes with available pods: 2
Dec 27 02:00:41.989: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:00:42.989: INFO: Number of nodes with available pods: 2
Dec 27 02:00:42.989: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:00:43.989: INFO: Number of nodes with available pods: 2
Dec 27 02:00:43.989: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:00:44.989: INFO: Number of nodes with available pods: 2
Dec 27 02:00:44.989: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:00:45.993: INFO: Number of nodes with available pods: 2
Dec 27 02:00:45.993: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:00:46.989: INFO: Number of nodes with available pods: 2
Dec 27 02:00:46.989: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:00:47.989: INFO: Number of nodes with available pods: 2
Dec 27 02:00:47.989: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:00:48.989: INFO: Number of nodes with available pods: 2
Dec 27 02:00:48.989: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:00:49.989: INFO: Number of nodes with available pods: 2
Dec 27 02:00:49.989: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:00:50.989: INFO: Number of nodes with available pods: 2
Dec 27 02:00:50.989: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:00:51.992: INFO: Number of nodes with available pods: 2
Dec 27 02:00:51.992: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:00:52.989: INFO: Number of nodes with available pods: 2
Dec 27 02:00:52.989: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:00:53.989: INFO: Number of nodes with available pods: 2
Dec 27 02:00:53.989: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:00:54.989: INFO: Number of nodes with available pods: 2
Dec 27 02:00:54.989: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:00:55.989: INFO: Number of nodes with available pods: 2
Dec 27 02:00:55.989: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:00:56.989: INFO: Number of nodes with available pods: 2
Dec 27 02:00:56.989: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:00:57.989: INFO: Number of nodes with available pods: 2
Dec 27 02:00:57.989: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:00:58.989: INFO: Number of nodes with available pods: 2
Dec 27 02:00:58.989: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:00:59.989: INFO: Number of nodes with available pods: 2
Dec 27 02:00:59.989: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:01:00.989: INFO: Number of nodes with available pods: 2
Dec 27 02:01:00.989: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:01:01.996: INFO: Number of nodes with available pods: 2
Dec 27 02:01:01.996: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:01:02.989: INFO: Number of nodes with available pods: 2
Dec 27 02:01:02.989: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:01:03.990: INFO: Number of nodes with available pods: 2
Dec 27 02:01:03.990: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:01:04.989: INFO: Number of nodes with available pods: 2
Dec 27 02:01:04.989: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:01:05.990: INFO: Number of nodes with available pods: 3
Dec 27 02:01:05.990: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-kdgt8, will wait for the garbage collector to delete the pods
Dec 27 02:01:06.052: INFO: Deleting DaemonSet.extensions daemon-set took: 5.725051ms
Dec 27 02:01:06.152: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.202004ms
Dec 27 02:01:48.154: INFO: Number of nodes with available pods: 0
Dec 27 02:01:48.154: INFO: Number of running nodes: 0, number of available pods: 0
Dec 27 02:01:48.156: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-kdgt8/daemonsets","resourceVersion":"8863"},"items":null}

Dec 27 02:01:48.158: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-kdgt8/pods","resourceVersion":"8863"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:01:48.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-kdgt8" for this suite.
Dec 27 02:01:54.179: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:01:54.237: INFO: namespace: e2e-tests-daemonsets-kdgt8, resource: bindings, ignored listing per whitelist
Dec 27 02:01:54.244: INFO: namespace e2e-tests-daemonsets-kdgt8 deletion completed in 6.074145901s

• [SLOW TEST:94.358 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:01:54.245: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Dec 27 02:01:54.310: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-8gqgv,SelfLink:/api/v1/namespaces/e2e-tests-watch-8gqgv/configmaps/e2e-watch-test-resource-version,UID:62180f2f-097b-11e9-9853-debd8636412e,ResourceVersion:8911,Generation:0,CreationTimestamp:2018-12-27 02:01:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 27 02:01:54.310: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-8gqgv,SelfLink:/api/v1/namespaces/e2e-tests-watch-8gqgv/configmaps/e2e-watch-test-resource-version,UID:62180f2f-097b-11e9-9853-debd8636412e,ResourceVersion:8912,Generation:0,CreationTimestamp:2018-12-27 02:01:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:01:54.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-8gqgv" for this suite.
Dec 27 02:02:00.321: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:02:00.374: INFO: namespace: e2e-tests-watch-8gqgv, resource: bindings, ignored listing per whitelist
Dec 27 02:02:00.381: INFO: namespace e2e-tests-watch-8gqgv deletion completed in 6.067893727s

• [SLOW TEST:6.136 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:02:00.381: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 27 02:02:00.441: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Dec 27 02:02:00.445: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-dcqwt/daemonsets","resourceVersion":"8932"},"items":null}

Dec 27 02:02:00.447: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-dcqwt/pods","resourceVersion":"8932"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:02:00.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-dcqwt" for this suite.
Dec 27 02:02:06.466: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:02:06.497: INFO: namespace: e2e-tests-daemonsets-dcqwt, resource: bindings, ignored listing per whitelist
Dec 27 02:02:06.526: INFO: namespace e2e-tests-daemonsets-dcqwt deletion completed in 6.069025147s

S [SKIPPING] [6.145 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Dec 27 02:02:00.441: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:02:06.526: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec 27 02:02:06.576: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:02:09.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-ssrtf" for this suite.
Dec 27 02:02:15.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:02:15.332: INFO: namespace: e2e-tests-init-container-ssrtf, resource: bindings, ignored listing per whitelist
Dec 27 02:02:15.378: INFO: namespace e2e-tests-init-container-ssrtf deletion completed in 6.072867422s

• [SLOW TEST:8.852 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:02:15.378: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-rsw4b
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 27 02:02:15.427: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 27 02:02:37.492: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.33.1.80:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-rsw4b PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 27 02:02:37.492: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
Dec 27 02:02:37.580: INFO: Found all expected endpoints: [netserver-0]
Dec 27 02:02:37.583: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.33.0.247:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-rsw4b PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 27 02:02:37.583: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
Dec 27 02:02:37.660: INFO: Found all expected endpoints: [netserver-1]
Dec 27 02:02:37.663: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.33.2.101:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-rsw4b PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 27 02:02:37.663: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
Dec 27 02:02:37.743: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:02:37.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-rsw4b" for this suite.
Dec 27 02:02:59.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:02:59.786: INFO: namespace: e2e-tests-pod-network-test-rsw4b, resource: bindings, ignored listing per whitelist
Dec 27 02:02:59.814: INFO: namespace e2e-tests-pod-network-test-rsw4b deletion completed in 22.067879854s

• [SLOW TEST:44.436 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:02:59.814: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec 27 02:02:59.874: INFO: Waiting up to 5m0s for pod "downward-api-892ea388-097b-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-downward-api-v8vsd" to be "success or failure"
Dec 27 02:02:59.875: INFO: Pod "downward-api-892ea388-097b-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.804443ms
Dec 27 02:03:01.879: INFO: Pod "downward-api-892ea388-097b-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005145034s
STEP: Saw pod success
Dec 27 02:03:01.879: INFO: Pod "downward-api-892ea388-097b-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:03:01.881: INFO: Trying to get logs from node guojing-1 pod downward-api-892ea388-097b-11e9-a1bd-0a580a2100c6 container dapi-container: <nil>
STEP: delete the pod
Dec 27 02:03:01.898: INFO: Waiting for pod downward-api-892ea388-097b-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:03:01.900: INFO: Pod downward-api-892ea388-097b-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:03:01.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-v8vsd" for this suite.
Dec 27 02:03:07.913: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:03:07.941: INFO: namespace: e2e-tests-downward-api-v8vsd, resource: bindings, ignored listing per whitelist
Dec 27 02:03:07.969: INFO: namespace e2e-tests-downward-api-v8vsd deletion completed in 6.065913544s

• [SLOW TEST:8.155 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:03:07.970: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-fqg2h
Dec 27 02:03:12.025: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-fqg2h
STEP: checking the pod's current state and verifying that restartCount is present
Dec 27 02:03:12.027: INFO: Initial restart count of pod liveness-http is 0
Dec 27 02:03:28.051: INFO: Restart count of pod e2e-tests-container-probe-fqg2h/liveness-http is now 1 (16.024224527s elapsed)
Dec 27 02:03:48.078: INFO: Restart count of pod e2e-tests-container-probe-fqg2h/liveness-http is now 2 (36.050908318s elapsed)
Dec 27 02:04:08.105: INFO: Restart count of pod e2e-tests-container-probe-fqg2h/liveness-http is now 3 (56.077972374s elapsed)
Dec 27 02:04:28.135: INFO: Restart count of pod e2e-tests-container-probe-fqg2h/liveness-http is now 4 (1m16.108486622s elapsed)
Dec 27 02:05:40.233: INFO: Restart count of pod e2e-tests-container-probe-fqg2h/liveness-http is now 5 (2m28.205880143s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:05:40.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-fqg2h" for this suite.
Dec 27 02:05:46.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:05:46.278: INFO: namespace: e2e-tests-container-probe-fqg2h, resource: bindings, ignored listing per whitelist
Dec 27 02:05:46.310: INFO: namespace e2e-tests-container-probe-fqg2h deletion completed in 6.065168262s

• [SLOW TEST:158.340 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:05:46.310: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-ec6b01a4-097b-11e9-a1bd-0a580a2100c6
STEP: Creating a pod to test consume secrets
Dec 27 02:05:46.367: INFO: Waiting up to 5m0s for pod "pod-secrets-ec6bbac6-097b-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-secrets-7gt8m" to be "success or failure"
Dec 27 02:05:46.372: INFO: Pod "pod-secrets-ec6bbac6-097b-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 5.213862ms
Dec 27 02:05:48.375: INFO: Pod "pod-secrets-ec6bbac6-097b-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007757235s
STEP: Saw pod success
Dec 27 02:05:48.375: INFO: Pod "pod-secrets-ec6bbac6-097b-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:05:48.377: INFO: Trying to get logs from node guojing-1 pod pod-secrets-ec6bbac6-097b-11e9-a1bd-0a580a2100c6 container secret-volume-test: <nil>
STEP: delete the pod
Dec 27 02:05:48.393: INFO: Waiting for pod pod-secrets-ec6bbac6-097b-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:05:48.395: INFO: Pod pod-secrets-ec6bbac6-097b-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:05:48.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-7gt8m" for this suite.
Dec 27 02:05:54.406: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:05:54.459: INFO: namespace: e2e-tests-secrets-7gt8m, resource: bindings, ignored listing per whitelist
Dec 27 02:05:54.463: INFO: namespace e2e-tests-secrets-7gt8m deletion completed in 6.06477531s

• [SLOW TEST:8.153 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:05:54.463: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:06:54.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-bdlz8" for this suite.
Dec 27 02:07:16.533: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:07:16.577: INFO: namespace: e2e-tests-container-probe-bdlz8, resource: bindings, ignored listing per whitelist
Dec 27 02:07:16.592: INFO: namespace e2e-tests-container-probe-bdlz8 deletion completed in 22.067668416s

• [SLOW TEST:82.129 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:07:16.592: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-xnhtb
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-xnhtb
STEP: Deleting pre-stop pod
Dec 27 02:07:25.673: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:07:25.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-xnhtb" for this suite.
Dec 27 02:08:05.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:08:05.710: INFO: namespace: e2e-tests-prestop-xnhtb, resource: bindings, ignored listing per whitelist
Dec 27 02:08:05.752: INFO: namespace e2e-tests-prestop-xnhtb deletion completed in 40.06827242s

• [SLOW TEST:49.160 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:08:05.752: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Dec 27 02:08:05.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 create -f - --namespace=e2e-tests-kubectl-skjqb'
Dec 27 02:08:06.211: INFO: stderr: ""
Dec 27 02:08:06.211: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 27 02:08:06.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-skjqb'
Dec 27 02:08:06.286: INFO: stderr: ""
Dec 27 02:08:06.286: INFO: stdout: "update-demo-nautilus-c6nwr update-demo-nautilus-n4k5r "
Dec 27 02:08:06.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods update-demo-nautilus-c6nwr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-skjqb'
Dec 27 02:08:06.350: INFO: stderr: ""
Dec 27 02:08:06.350: INFO: stdout: ""
Dec 27 02:08:06.350: INFO: update-demo-nautilus-c6nwr is created but not running
Dec 27 02:08:11.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-skjqb'
Dec 27 02:08:11.422: INFO: stderr: ""
Dec 27 02:08:11.422: INFO: stdout: "update-demo-nautilus-c6nwr update-demo-nautilus-n4k5r "
Dec 27 02:08:11.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods update-demo-nautilus-c6nwr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-skjqb'
Dec 27 02:08:11.484: INFO: stderr: ""
Dec 27 02:08:11.485: INFO: stdout: "true"
Dec 27 02:08:11.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods update-demo-nautilus-c6nwr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-skjqb'
Dec 27 02:08:11.547: INFO: stderr: ""
Dec 27 02:08:11.547: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 27 02:08:11.547: INFO: validating pod update-demo-nautilus-c6nwr
Dec 27 02:08:11.550: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 27 02:08:11.550: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 27 02:08:11.550: INFO: update-demo-nautilus-c6nwr is verified up and running
Dec 27 02:08:11.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods update-demo-nautilus-n4k5r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-skjqb'
Dec 27 02:08:11.613: INFO: stderr: ""
Dec 27 02:08:11.613: INFO: stdout: "true"
Dec 27 02:08:11.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods update-demo-nautilus-n4k5r -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-skjqb'
Dec 27 02:08:11.674: INFO: stderr: ""
Dec 27 02:08:11.674: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 27 02:08:11.674: INFO: validating pod update-demo-nautilus-n4k5r
Dec 27 02:08:11.677: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 27 02:08:11.677: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 27 02:08:11.677: INFO: update-demo-nautilus-n4k5r is verified up and running
STEP: rolling-update to new replication controller
Dec 27 02:08:11.679: INFO: scanned /root for discovery docs: <nil>
Dec 27 02:08:11.679: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-skjqb'
Dec 27 02:08:33.997: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec 27 02:08:33.997: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 27 02:08:33.997: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-skjqb'
Dec 27 02:08:34.071: INFO: stderr: ""
Dec 27 02:08:34.071: INFO: stdout: "update-demo-kitten-l2ndc update-demo-kitten-xvjbd "
Dec 27 02:08:34.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods update-demo-kitten-l2ndc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-skjqb'
Dec 27 02:08:34.135: INFO: stderr: ""
Dec 27 02:08:34.135: INFO: stdout: "true"
Dec 27 02:08:34.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods update-demo-kitten-l2ndc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-skjqb'
Dec 27 02:08:34.196: INFO: stderr: ""
Dec 27 02:08:34.196: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec 27 02:08:34.196: INFO: validating pod update-demo-kitten-l2ndc
Dec 27 02:08:34.199: INFO: got data: {
  "image": "kitten.jpg"
}

Dec 27 02:08:34.199: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec 27 02:08:34.199: INFO: update-demo-kitten-l2ndc is verified up and running
Dec 27 02:08:34.199: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods update-demo-kitten-xvjbd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-skjqb'
Dec 27 02:08:34.262: INFO: stderr: ""
Dec 27 02:08:34.262: INFO: stdout: "true"
Dec 27 02:08:34.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods update-demo-kitten-xvjbd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-skjqb'
Dec 27 02:08:34.327: INFO: stderr: ""
Dec 27 02:08:34.327: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec 27 02:08:34.327: INFO: validating pod update-demo-kitten-xvjbd
Dec 27 02:08:34.330: INFO: got data: {
  "image": "kitten.jpg"
}

Dec 27 02:08:34.330: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec 27 02:08:34.330: INFO: update-demo-kitten-xvjbd is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:08:34.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-skjqb" for this suite.
Dec 27 02:08:56.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:08:56.357: INFO: namespace: e2e-tests-kubectl-skjqb, resource: bindings, ignored listing per whitelist
Dec 27 02:08:56.398: INFO: namespace e2e-tests-kubectl-skjqb deletion completed in 22.065500144s

• [SLOW TEST:50.647 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:08:56.398: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Dec 27 02:08:56.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 --namespace=e2e-tests-kubectl-tntch run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Dec 27 02:08:57.623: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Dec 27 02:08:57.624: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:08:59.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tntch" for this suite.
Dec 27 02:09:05.641: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:09:05.654: INFO: namespace: e2e-tests-kubectl-tntch, resource: bindings, ignored listing per whitelist
Dec 27 02:09:05.698: INFO: namespace e2e-tests-kubectl-tntch deletion completed in 6.067342894s

• [SLOW TEST:9.300 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:09:05.698: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec 27 02:09:05.750: INFO: Waiting up to 5m0s for pod "pod-6342ecb1-097c-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-emptydir-mqldf" to be "success or failure"
Dec 27 02:09:05.752: INFO: Pod "pod-6342ecb1-097c-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.203915ms
Dec 27 02:09:07.754: INFO: Pod "pod-6342ecb1-097c-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004665629s
STEP: Saw pod success
Dec 27 02:09:07.754: INFO: Pod "pod-6342ecb1-097c-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:09:07.756: INFO: Trying to get logs from node guojing-1 pod pod-6342ecb1-097c-11e9-a1bd-0a580a2100c6 container test-container: <nil>
STEP: delete the pod
Dec 27 02:09:07.778: INFO: Waiting for pod pod-6342ecb1-097c-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:09:07.780: INFO: Pod pod-6342ecb1-097c-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:09:07.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-mqldf" for this suite.
Dec 27 02:09:13.794: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:09:13.843: INFO: namespace: e2e-tests-emptydir-mqldf, resource: bindings, ignored listing per whitelist
Dec 27 02:09:13.853: INFO: namespace e2e-tests-emptydir-mqldf deletion completed in 6.069189104s

• [SLOW TEST:8.155 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:09:13.853: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Dec 27 02:09:13.906: INFO: Waiting up to 5m0s for pod "var-expansion-681f5a4a-097c-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-var-expansion-mv8rp" to be "success or failure"
Dec 27 02:09:13.909: INFO: Pod "var-expansion-681f5a4a-097c-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.225935ms
Dec 27 02:09:15.911: INFO: Pod "var-expansion-681f5a4a-097c-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005690157s
STEP: Saw pod success
Dec 27 02:09:15.911: INFO: Pod "var-expansion-681f5a4a-097c-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:09:15.913: INFO: Trying to get logs from node guojing-2 pod var-expansion-681f5a4a-097c-11e9-a1bd-0a580a2100c6 container dapi-container: <nil>
STEP: delete the pod
Dec 27 02:09:15.932: INFO: Waiting for pod var-expansion-681f5a4a-097c-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:09:15.934: INFO: Pod var-expansion-681f5a4a-097c-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:09:15.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-mv8rp" for this suite.
Dec 27 02:09:21.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:09:21.971: INFO: namespace: e2e-tests-var-expansion-mv8rp, resource: bindings, ignored listing per whitelist
Dec 27 02:09:22.015: INFO: namespace e2e-tests-var-expansion-mv8rp deletion completed in 6.078726462s

• [SLOW TEST:8.163 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:09:22.016: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 27 02:09:22.068: INFO: Pod name rollover-pod: Found 0 pods out of 1
Dec 27 02:09:27.071: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 27 02:09:27.071: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Dec 27 02:09:29.073: INFO: Creating deployment "test-rollover-deployment"
Dec 27 02:09:29.080: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Dec 27 02:09:31.084: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Dec 27 02:09:31.088: INFO: Ensure that both replica sets have 1 created replica
Dec 27 02:09:31.092: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Dec 27 02:09:31.100: INFO: Updating deployment test-rollover-deployment
Dec 27 02:09:31.100: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Dec 27 02:09:33.104: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Dec 27 02:09:33.108: INFO: Make sure deployment "test-rollover-deployment" is complete
Dec 27 02:09:33.112: INFO: all replica sets need to contain the pod-template-hash label
Dec 27 02:09:33.112: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681473369, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681473369, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681473372, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681473369, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 27 02:09:35.123: INFO: all replica sets need to contain the pod-template-hash label
Dec 27 02:09:35.123: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681473369, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681473369, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681473372, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681473369, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 27 02:09:37.117: INFO: all replica sets need to contain the pod-template-hash label
Dec 27 02:09:37.117: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681473369, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681473369, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681473372, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681473369, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 27 02:09:39.117: INFO: all replica sets need to contain the pod-template-hash label
Dec 27 02:09:39.117: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681473369, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681473369, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681473372, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681473369, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 27 02:09:41.116: INFO: all replica sets need to contain the pod-template-hash label
Dec 27 02:09:41.116: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681473369, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681473369, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681473372, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681473369, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 27 02:09:43.117: INFO: 
Dec 27 02:09:43.117: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec 27 02:09:43.122: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-bz2pq,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bz2pq/deployments/test-rollover-deployment,UID:712ae7e3-097c-11e9-9853-debd8636412e,ResourceVersion:10255,Generation:2,CreationTimestamp:2018-12-27 02:09:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-12-27 02:09:29 +0000 UTC 2018-12-27 02:09:29 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-12-27 02:09:42 +0000 UTC 2018-12-27 02:09:29 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec 27 02:09:43.124: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-bz2pq,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bz2pq/replicasets/test-rollover-deployment-6b7f9d6597,UID:72604c4d-097c-11e9-b34c-525400cd4ed0,ResourceVersion:10246,Generation:2,CreationTimestamp:2018-12-27 02:09:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 712ae7e3-097c-11e9-9853-debd8636412e 0xc000f366b7 0xc000f366b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec 27 02:09:43.124: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Dec 27 02:09:43.124: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-bz2pq,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bz2pq/replicasets/test-rollover-controller,UID:6cfcd134-097c-11e9-9853-debd8636412e,ResourceVersion:10254,Generation:2,CreationTimestamp:2018-12-27 02:09:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 712ae7e3-097c-11e9-9853-debd8636412e 0xc000f36527 0xc000f36528}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 27 02:09:43.124: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-bz2pq,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bz2pq/replicasets/test-rollover-deployment-6586df867b,UID:712d6ed2-097c-11e9-b34c-525400cd4ed0,ResourceVersion:10214,Generation:2,CreationTimestamp:2018-12-27 02:09:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 712ae7e3-097c-11e9-9853-debd8636412e 0xc000f365e7 0xc000f365e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 27 02:09:43.126: INFO: Pod "test-rollover-deployment-6b7f9d6597-68c4x" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-68c4x,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-bz2pq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bz2pq/pods/test-rollover-deployment-6b7f9d6597-68c4x,UID:7263ee4d-097c-11e9-b34c-525400cd4ed0,ResourceVersion:10227,Generation:0,CreationTimestamp:2018-12-27 02:09:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 72604c4d-097c-11e9-b34c-525400cd4ed0 0xc000f371f7 0xc000f371f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7wf6m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7wf6m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-7wf6m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:guojing-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000f37270} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000f37290}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:09:31 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:09:32 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:09:32 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:09:31 +0000 UTC  }],Message:,Reason:,HostIP:172.19.16.27,PodIP:10.33.0.253,StartTime:2018-12-27 02:09:31 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-12-27 02:09:31 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://13e2ff775f33f5e5b951efb7944c8520362216cde73145c77420945cc608715e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:09:43.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-bz2pq" for this suite.
Dec 27 02:09:49.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:09:49.166: INFO: namespace: e2e-tests-deployment-bz2pq, resource: bindings, ignored listing per whitelist
Dec 27 02:09:49.200: INFO: namespace e2e-tests-deployment-bz2pq deletion completed in 6.070062318s

• [SLOW TEST:27.184 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:09:49.200: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Dec 27 02:09:49.250: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 27 02:09:49.255: INFO: Waiting for terminating namespaces to be deleted...
Dec 27 02:09:49.257: INFO: 
Logging pods the kubelet thinks is on node guojing-1 before test
Dec 27 02:09:49.261: INFO: kube-apiserver-guojing-1 from kube-system started at <nil> (0 container statuses recorded)
Dec 27 02:09:49.261: INFO: kube-scheduler-guojing-1 from kube-system started at <nil> (0 container statuses recorded)
Dec 27 02:09:49.261: INFO: kube-controller-manager-guojing-1 from kube-system started at <nil> (0 container statuses recorded)
Dec 27 02:09:49.261: INFO: etcd-guojing-1 from kube-system started at <nil> (0 container statuses recorded)
Dec 27 02:09:49.261: INFO: kube-proxy-4mfwt from kube-system started at 2018-12-27 01:21:44 +0000 UTC (1 container statuses recorded)
Dec 27 02:09:49.261: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 27 02:09:49.261: INFO: kube-flannel-cpmvg from kube-system started at 2018-12-27 01:22:14 +0000 UTC (2 container statuses recorded)
Dec 27 02:09:49.261: INFO: 	Container install-cni ready: true, restart count 0
Dec 27 02:09:49.261: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 27 02:09:49.261: INFO: 
Logging pods the kubelet thinks is on node guojing-2 before test
Dec 27 02:09:49.267: INFO: etcd-guojing-2 from kube-system started at <nil> (0 container statuses recorded)
Dec 27 02:09:49.267: INFO: coredns-585c7897d4-xl2hs from kube-system started at 2018-12-27 01:21:41 +0000 UTC (1 container statuses recorded)
Dec 27 02:09:49.267: INFO: 	Container coredns ready: true, restart count 0
Dec 27 02:09:49.267: INFO: kube-controller-manager-guojing-2 from kube-system started at <nil> (0 container statuses recorded)
Dec 27 02:09:49.267: INFO: kube-flannel-2cgd9 from kube-system started at 2018-12-27 01:22:14 +0000 UTC (2 container statuses recorded)
Dec 27 02:09:49.267: INFO: 	Container install-cni ready: true, restart count 0
Dec 27 02:09:49.267: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 27 02:09:49.267: INFO: coredns-585c7897d4-74jzl from kube-system started at 2018-12-27 01:21:41 +0000 UTC (1 container statuses recorded)
Dec 27 02:09:49.267: INFO: 	Container coredns ready: true, restart count 0
Dec 27 02:09:49.267: INFO: kube-proxy-sfcms from kube-system started at 2018-12-27 01:21:41 +0000 UTC (1 container statuses recorded)
Dec 27 02:09:49.267: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 27 02:09:49.267: INFO: kube-scheduler-guojing-2 from kube-system started at <nil> (0 container statuses recorded)
Dec 27 02:09:49.267: INFO: kube-apiserver-guojing-2 from kube-system started at <nil> (0 container statuses recorded)
Dec 27 02:09:49.267: INFO: sonobuoy-e2e-job-9a6d2b4903a24fc2 from heptio-sonobuoy started at 2018-12-27 01:26:08 +0000 UTC (2 container statuses recorded)
Dec 27 02:09:49.267: INFO: 	Container e2e ready: true, restart count 0
Dec 27 02:09:49.267: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 27 02:09:49.267: INFO: 
Logging pods the kubelet thinks is on node guojing-3 before test
Dec 27 02:09:49.275: INFO: kube-scheduler-guojing-3 from kube-system started at <nil> (0 container statuses recorded)
Dec 27 02:09:49.275: INFO: kube-proxy-bppf2 from kube-system started at 2018-12-27 01:21:44 +0000 UTC (1 container statuses recorded)
Dec 27 02:09:49.275: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 27 02:09:49.275: INFO: etcd-guojing-3 from kube-system started at <nil> (0 container statuses recorded)
Dec 27 02:09:49.275: INFO: kube-flannel-hjf2c from kube-system started at 2018-12-27 01:22:14 +0000 UTC (2 container statuses recorded)
Dec 27 02:09:49.275: INFO: 	Container install-cni ready: true, restart count 0
Dec 27 02:09:49.275: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 27 02:09:49.275: INFO: kube-apiserver-guojing-3 from kube-system started at <nil> (0 container statuses recorded)
Dec 27 02:09:49.275: INFO: kube-controller-manager-guojing-3 from kube-system started at <nil> (0 container statuses recorded)
Dec 27 02:09:49.275: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-27 01:26:05 +0000 UTC (3 container statuses recorded)
Dec 27 02:09:49.275: INFO: 	Container cleanup ready: true, restart count 0
Dec 27 02:09:49.275: INFO: 	Container forwarder ready: true, restart count 0
Dec 27 02:09:49.275: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node guojing-1
STEP: verifying the node has the label node guojing-2
STEP: verifying the node has the label node guojing-3
Dec 27 02:09:49.316: INFO: Pod sonobuoy requesting resource cpu=0m on Node guojing-3
Dec 27 02:09:49.316: INFO: Pod sonobuoy-e2e-job-9a6d2b4903a24fc2 requesting resource cpu=0m on Node guojing-2
Dec 27 02:09:49.316: INFO: Pod coredns-585c7897d4-74jzl requesting resource cpu=100m on Node guojing-2
Dec 27 02:09:49.316: INFO: Pod coredns-585c7897d4-xl2hs requesting resource cpu=100m on Node guojing-2
Dec 27 02:09:49.316: INFO: Pod etcd-guojing-1 requesting resource cpu=0m on Node guojing-1
Dec 27 02:09:49.316: INFO: Pod etcd-guojing-2 requesting resource cpu=0m on Node guojing-2
Dec 27 02:09:49.316: INFO: Pod etcd-guojing-3 requesting resource cpu=0m on Node guojing-3
Dec 27 02:09:49.316: INFO: Pod kube-apiserver-guojing-1 requesting resource cpu=250m on Node guojing-1
Dec 27 02:09:49.316: INFO: Pod kube-apiserver-guojing-2 requesting resource cpu=250m on Node guojing-2
Dec 27 02:09:49.316: INFO: Pod kube-apiserver-guojing-3 requesting resource cpu=250m on Node guojing-3
Dec 27 02:09:49.316: INFO: Pod kube-controller-manager-guojing-1 requesting resource cpu=200m on Node guojing-1
Dec 27 02:09:49.316: INFO: Pod kube-controller-manager-guojing-2 requesting resource cpu=200m on Node guojing-2
Dec 27 02:09:49.316: INFO: Pod kube-controller-manager-guojing-3 requesting resource cpu=200m on Node guojing-3
Dec 27 02:09:49.316: INFO: Pod kube-flannel-2cgd9 requesting resource cpu=50m on Node guojing-2
Dec 27 02:09:49.316: INFO: Pod kube-flannel-cpmvg requesting resource cpu=50m on Node guojing-1
Dec 27 02:09:49.316: INFO: Pod kube-flannel-hjf2c requesting resource cpu=50m on Node guojing-3
Dec 27 02:09:49.316: INFO: Pod kube-proxy-4mfwt requesting resource cpu=0m on Node guojing-1
Dec 27 02:09:49.316: INFO: Pod kube-proxy-bppf2 requesting resource cpu=0m on Node guojing-3
Dec 27 02:09:49.316: INFO: Pod kube-proxy-sfcms requesting resource cpu=0m on Node guojing-2
Dec 27 02:09:49.316: INFO: Pod kube-scheduler-guojing-1 requesting resource cpu=100m on Node guojing-1
Dec 27 02:09:49.316: INFO: Pod kube-scheduler-guojing-2 requesting resource cpu=100m on Node guojing-2
Dec 27 02:09:49.316: INFO: Pod kube-scheduler-guojing-3 requesting resource cpu=100m on Node guojing-3
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7d3b964c-097c-11e9-a1bd-0a580a2100c6.15740e914d9e056a], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-j8m46/filler-pod-7d3b964c-097c-11e9-a1bd-0a580a2100c6 to guojing-1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7d3b964c-097c-11e9-a1bd-0a580a2100c6.15740e917039f946], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7d3b964c-097c-11e9-a1bd-0a580a2100c6.15740e91735dee2d], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7d3b964c-097c-11e9-a1bd-0a580a2100c6.15740e9179320ecb], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7d3ca906-097c-11e9-a1bd-0a580a2100c6.15740e914e025048], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-j8m46/filler-pod-7d3ca906-097c-11e9-a1bd-0a580a2100c6 to guojing-2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7d3ca906-097c-11e9-a1bd-0a580a2100c6.15740e9170f9f5d5], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7d3ca906-097c-11e9-a1bd-0a580a2100c6.15740e91745c3a00], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7d3ca906-097c-11e9-a1bd-0a580a2100c6.15740e917b25938b], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7d3d72c1-097c-11e9-a1bd-0a580a2100c6.15740e914e1789c1], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-j8m46/filler-pod-7d3d72c1-097c-11e9-a1bd-0a580a2100c6 to guojing-3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7d3d72c1-097c-11e9-a1bd-0a580a2100c6.15740e91707b4bd0], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7d3d72c1-097c-11e9-a1bd-0a580a2100c6.15740e917371e1bb], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7d3d72c1-097c-11e9-a1bd-0a580a2100c6.15740e9179d6113c], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15740e91c623db30], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node guojing-3
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node guojing-1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node guojing-2
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:09:52.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-j8m46" for this suite.
Dec 27 02:09:58.406: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:09:58.413: INFO: namespace: e2e-tests-sched-pred-j8m46, resource: bindings, ignored listing per whitelist
Dec 27 02:09:58.464: INFO: namespace e2e-tests-sched-pred-j8m46 deletion completed in 6.066407306s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:9.264 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:09:58.464: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-82b74ac4-097c-11e9-a1bd-0a580a2100c6
STEP: Creating a pod to test consume secrets
Dec 27 02:09:58.527: INFO: Waiting up to 5m0s for pod "pod-secrets-82b854bd-097c-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-secrets-tks6c" to be "success or failure"
Dec 27 02:09:58.530: INFO: Pod "pod-secrets-82b854bd-097c-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.028163ms
Dec 27 02:10:00.533: INFO: Pod "pod-secrets-82b854bd-097c-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005626427s
STEP: Saw pod success
Dec 27 02:10:00.533: INFO: Pod "pod-secrets-82b854bd-097c-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:10:00.535: INFO: Trying to get logs from node guojing-3 pod pod-secrets-82b854bd-097c-11e9-a1bd-0a580a2100c6 container secret-volume-test: <nil>
STEP: delete the pod
Dec 27 02:10:00.553: INFO: Waiting for pod pod-secrets-82b854bd-097c-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:10:00.554: INFO: Pod pod-secrets-82b854bd-097c-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:10:00.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-tks6c" for this suite.
Dec 27 02:10:06.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:10:06.620: INFO: namespace: e2e-tests-secrets-tks6c, resource: bindings, ignored listing per whitelist
Dec 27 02:10:06.628: INFO: namespace e2e-tests-secrets-tks6c deletion completed in 6.071341814s

• [SLOW TEST:8.164 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:10:06.628: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Dec 27 02:10:06.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 api-versions'
Dec 27 02:10:06.744: INFO: stderr: ""
Dec 27 02:10:06.744: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:10:06.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-w5h7z" for this suite.
Dec 27 02:10:12.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:10:12.771: INFO: namespace: e2e-tests-kubectl-w5h7z, resource: bindings, ignored listing per whitelist
Dec 27 02:10:12.816: INFO: namespace e2e-tests-kubectl-w5h7z deletion completed in 6.068517844s

• [SLOW TEST:6.188 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:10:12.816: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 27 02:10:12.868: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8b43eb6b-097c-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-downward-api-s5f2c" to be "success or failure"
Dec 27 02:10:12.869: INFO: Pod "downwardapi-volume-8b43eb6b-097c-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.944515ms
Dec 27 02:10:14.872: INFO: Pod "downwardapi-volume-8b43eb6b-097c-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004341175s
STEP: Saw pod success
Dec 27 02:10:14.872: INFO: Pod "downwardapi-volume-8b43eb6b-097c-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:10:14.874: INFO: Trying to get logs from node guojing-1 pod downwardapi-volume-8b43eb6b-097c-11e9-a1bd-0a580a2100c6 container client-container: <nil>
STEP: delete the pod
Dec 27 02:10:14.888: INFO: Waiting for pod downwardapi-volume-8b43eb6b-097c-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:10:14.890: INFO: Pod downwardapi-volume-8b43eb6b-097c-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:10:14.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-s5f2c" for this suite.
Dec 27 02:10:20.901: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:10:20.921: INFO: namespace: e2e-tests-downward-api-s5f2c, resource: bindings, ignored listing per whitelist
Dec 27 02:10:20.959: INFO: namespace e2e-tests-downward-api-s5f2c deletion completed in 6.066612422s

• [SLOW TEST:8.143 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:10:20.959: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:10:23.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-snd7z" for this suite.
Dec 27 02:11:13.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:11:13.071: INFO: namespace: e2e-tests-kubelet-test-snd7z, resource: bindings, ignored listing per whitelist
Dec 27 02:11:13.096: INFO: namespace e2e-tests-kubelet-test-snd7z deletion completed in 50.068748297s

• [SLOW TEST:52.136 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:11:13.096: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-af341a8e-097c-11e9-a1bd-0a580a2100c6
STEP: Creating a pod to test consume secrets
Dec 27 02:11:13.163: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-af34deb9-097c-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-projected-7srdz" to be "success or failure"
Dec 27 02:11:13.165: INFO: Pod "pod-projected-secrets-af34deb9-097c-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.941843ms
Dec 27 02:11:15.167: INFO: Pod "pod-projected-secrets-af34deb9-097c-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00434739s
STEP: Saw pod success
Dec 27 02:11:15.167: INFO: Pod "pod-projected-secrets-af34deb9-097c-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:11:15.169: INFO: Trying to get logs from node guojing-3 pod pod-projected-secrets-af34deb9-097c-11e9-a1bd-0a580a2100c6 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 27 02:11:15.188: INFO: Waiting for pod pod-projected-secrets-af34deb9-097c-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:11:15.190: INFO: Pod pod-projected-secrets-af34deb9-097c-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:11:15.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7srdz" for this suite.
Dec 27 02:11:21.201: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:11:21.227: INFO: namespace: e2e-tests-projected-7srdz, resource: bindings, ignored listing per whitelist
Dec 27 02:11:21.257: INFO: namespace e2e-tests-projected-7srdz deletion completed in 6.064741799s

• [SLOW TEST:8.162 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:11:21.258: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-nz6k5
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-nz6k5 to expose endpoints map[]
Dec 27 02:11:21.325: INFO: Get endpoints failed (1.751775ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Dec 27 02:11:22.328: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-nz6k5 exposes endpoints map[] (1.004370742s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-nz6k5
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-nz6k5 to expose endpoints map[pod1:[80]]
Dec 27 02:11:24.350: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-nz6k5 exposes endpoints map[pod1:[80]] (2.016702856s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-nz6k5
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-nz6k5 to expose endpoints map[pod1:[80] pod2:[80]]
Dec 27 02:11:26.376: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-nz6k5 exposes endpoints map[pod2:[80] pod1:[80]] (2.021824102s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-nz6k5
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-nz6k5 to expose endpoints map[pod2:[80]]
Dec 27 02:11:27.391: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-nz6k5 exposes endpoints map[pod2:[80]] (1.009649028s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-nz6k5
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-nz6k5 to expose endpoints map[]
Dec 27 02:11:28.404: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-nz6k5 exposes endpoints map[] (1.006474418s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:11:28.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-nz6k5" for this suite.
Dec 27 02:11:48.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:11:48.456: INFO: namespace: e2e-tests-services-nz6k5, resource: bindings, ignored listing per whitelist
Dec 27 02:11:48.506: INFO: namespace e2e-tests-services-nz6k5 deletion completed in 20.067214043s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:27.249 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:11:48.506: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Dec 27 02:11:48.556: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-574749520 proxy --unix-socket=/tmp/kubectl-proxy-unix468334703/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:11:48.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-blzp7" for this suite.
Dec 27 02:11:54.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:11:54.652: INFO: namespace: e2e-tests-kubectl-blzp7, resource: bindings, ignored listing per whitelist
Dec 27 02:11:54.675: INFO: namespace e2e-tests-kubectl-blzp7 deletion completed in 6.068696061s

• [SLOW TEST:6.169 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:11:54.675: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:11:56.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-phmgt" for this suite.
Dec 27 02:12:46.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:12:46.808: INFO: namespace: e2e-tests-kubelet-test-phmgt, resource: bindings, ignored listing per whitelist
Dec 27 02:12:46.809: INFO: namespace e2e-tests-kubelet-test-phmgt deletion completed in 50.066195775s

• [SLOW TEST:52.134 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:12:46.809: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-n9wkd
Dec 27 02:12:48.871: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-n9wkd
STEP: checking the pod's current state and verifying that restartCount is present
Dec 27 02:12:48.873: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:16:49.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-n9wkd" for this suite.
Dec 27 02:16:55.228: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:16:55.242: INFO: namespace: e2e-tests-container-probe-n9wkd, resource: bindings, ignored listing per whitelist
Dec 27 02:16:55.289: INFO: namespace e2e-tests-container-probe-n9wkd deletion completed in 6.073179503s

• [SLOW TEST:248.480 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:16:55.289: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 27 02:16:55.345: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7b292f98-097d-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-projected-nsrjt" to be "success or failure"
Dec 27 02:16:55.348: INFO: Pod "downwardapi-volume-7b292f98-097d-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.169386ms
Dec 27 02:16:57.350: INFO: Pod "downwardapi-volume-7b292f98-097d-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00500982s
STEP: Saw pod success
Dec 27 02:16:57.350: INFO: Pod "downwardapi-volume-7b292f98-097d-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:16:57.352: INFO: Trying to get logs from node guojing-2 pod downwardapi-volume-7b292f98-097d-11e9-a1bd-0a580a2100c6 container client-container: <nil>
STEP: delete the pod
Dec 27 02:16:57.370: INFO: Waiting for pod downwardapi-volume-7b292f98-097d-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:16:57.372: INFO: Pod downwardapi-volume-7b292f98-097d-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:16:57.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nsrjt" for this suite.
Dec 27 02:17:03.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:17:03.428: INFO: namespace: e2e-tests-projected-nsrjt, resource: bindings, ignored listing per whitelist
Dec 27 02:17:03.441: INFO: namespace e2e-tests-projected-nsrjt deletion completed in 6.066454376s

• [SLOW TEST:8.152 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:17:03.441: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:17:09.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-5tv7l" for this suite.
Dec 27 02:17:15.585: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:17:15.626: INFO: namespace: e2e-tests-namespaces-5tv7l, resource: bindings, ignored listing per whitelist
Dec 27 02:17:15.643: INFO: namespace e2e-tests-namespaces-5tv7l deletion completed in 6.069883652s
STEP: Destroying namespace "e2e-tests-nsdeletetest-zbrq5" for this suite.
Dec 27 02:17:15.645: INFO: Namespace e2e-tests-nsdeletetest-zbrq5 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-mfgzg" for this suite.
Dec 27 02:17:21.655: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:17:21.671: INFO: namespace: e2e-tests-nsdeletetest-mfgzg, resource: bindings, ignored listing per whitelist
Dec 27 02:17:21.712: INFO: namespace e2e-tests-nsdeletetest-mfgzg deletion completed in 6.066987535s

• [SLOW TEST:18.270 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:17:21.712: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-8ae90687-097d-11e9-a1bd-0a580a2100c6
STEP: Creating a pod to test consume configMaps
Dec 27 02:17:21.771: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8ae9ba50-097d-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-projected-qmjnd" to be "success or failure"
Dec 27 02:17:21.773: INFO: Pod "pod-projected-configmaps-8ae9ba50-097d-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053221ms
Dec 27 02:17:23.776: INFO: Pod "pod-projected-configmaps-8ae9ba50-097d-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004757324s
STEP: Saw pod success
Dec 27 02:17:23.776: INFO: Pod "pod-projected-configmaps-8ae9ba50-097d-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:17:23.778: INFO: Trying to get logs from node guojing-3 pod pod-projected-configmaps-8ae9ba50-097d-11e9-a1bd-0a580a2100c6 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 27 02:17:23.796: INFO: Waiting for pod pod-projected-configmaps-8ae9ba50-097d-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:17:23.798: INFO: Pod pod-projected-configmaps-8ae9ba50-097d-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:17:23.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qmjnd" for this suite.
Dec 27 02:17:29.809: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:17:29.866: INFO: namespace: e2e-tests-projected-qmjnd, resource: bindings, ignored listing per whitelist
Dec 27 02:17:29.874: INFO: namespace e2e-tests-projected-qmjnd deletion completed in 6.072506441s

• [SLOW TEST:8.162 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:17:29.874: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec 27 02:17:29.947: INFO: Number of nodes with available pods: 0
Dec 27 02:17:29.947: INFO: Node guojing-1 is running more than one daemon pod
Dec 27 02:17:30.953: INFO: Number of nodes with available pods: 1
Dec 27 02:17:30.953: INFO: Node guojing-2 is running more than one daemon pod
Dec 27 02:17:31.953: INFO: Number of nodes with available pods: 3
Dec 27 02:17:31.953: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Dec 27 02:17:31.972: INFO: Number of nodes with available pods: 3
Dec 27 02:17:31.972: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-8vl55, will wait for the garbage collector to delete the pods
Dec 27 02:17:33.037: INFO: Deleting DaemonSet.extensions daemon-set took: 6.065731ms
Dec 27 02:17:33.137: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.148401ms
Dec 27 02:19:18.139: INFO: Number of nodes with available pods: 0
Dec 27 02:19:18.139: INFO: Number of running nodes: 0, number of available pods: 0
Dec 27 02:19:18.141: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-8vl55/daemonsets","resourceVersion":"11661"},"items":null}

Dec 27 02:19:18.143: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-8vl55/pods","resourceVersion":"11661"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:19:18.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-8vl55" for this suite.
Dec 27 02:19:24.163: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:19:24.192: INFO: namespace: e2e-tests-daemonsets-8vl55, resource: bindings, ignored listing per whitelist
Dec 27 02:19:24.221: INFO: namespace e2e-tests-daemonsets-8vl55 deletion completed in 6.06647592s

• [SLOW TEST:114.347 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:19:24.221: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Dec 27 02:19:24.276: INFO: Waiting up to 5m0s for pod "client-containers-d3ee4120-097d-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-containers-fpr7h" to be "success or failure"
Dec 27 02:19:24.278: INFO: Pod "client-containers-d3ee4120-097d-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008598ms
Dec 27 02:19:26.280: INFO: Pod "client-containers-d3ee4120-097d-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004780016s
STEP: Saw pod success
Dec 27 02:19:26.280: INFO: Pod "client-containers-d3ee4120-097d-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:19:26.282: INFO: Trying to get logs from node guojing-1 pod client-containers-d3ee4120-097d-11e9-a1bd-0a580a2100c6 container test-container: <nil>
STEP: delete the pod
Dec 27 02:19:26.302: INFO: Waiting for pod client-containers-d3ee4120-097d-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:19:26.304: INFO: Pod client-containers-d3ee4120-097d-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:19:26.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-fpr7h" for this suite.
Dec 27 02:19:32.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:19:32.373: INFO: namespace: e2e-tests-containers-fpr7h, resource: bindings, ignored listing per whitelist
Dec 27 02:19:32.373: INFO: namespace e2e-tests-containers-fpr7h deletion completed in 6.066220392s

• [SLOW TEST:8.153 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:19:32.373: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec 27 02:19:32.428: INFO: Waiting up to 5m0s for pod "downward-api-d8c9add1-097d-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-downward-api-ls6dw" to be "success or failure"
Dec 27 02:19:32.430: INFO: Pod "downward-api-d8c9add1-097d-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.11098ms
Dec 27 02:19:34.432: INFO: Pod "downward-api-d8c9add1-097d-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00458862s
STEP: Saw pod success
Dec 27 02:19:34.432: INFO: Pod "downward-api-d8c9add1-097d-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:19:34.435: INFO: Trying to get logs from node guojing-2 pod downward-api-d8c9add1-097d-11e9-a1bd-0a580a2100c6 container dapi-container: <nil>
STEP: delete the pod
Dec 27 02:19:34.450: INFO: Waiting for pod downward-api-d8c9add1-097d-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:19:34.452: INFO: Pod downward-api-d8c9add1-097d-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:19:34.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-ls6dw" for this suite.
Dec 27 02:19:40.466: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:19:40.501: INFO: namespace: e2e-tests-downward-api-ls6dw, resource: bindings, ignored listing per whitelist
Dec 27 02:19:40.525: INFO: namespace e2e-tests-downward-api-ls6dw deletion completed in 6.070484945s

• [SLOW TEST:8.152 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:19:40.525: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec 27 02:19:40.580: INFO: Waiting up to 5m0s for pod "downward-api-dda60d51-097d-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-downward-api-pxnww" to be "success or failure"
Dec 27 02:19:40.582: INFO: Pod "downward-api-dda60d51-097d-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.861698ms
Dec 27 02:19:42.584: INFO: Pod "downward-api-dda60d51-097d-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004489726s
STEP: Saw pod success
Dec 27 02:19:42.584: INFO: Pod "downward-api-dda60d51-097d-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:19:42.586: INFO: Trying to get logs from node guojing-3 pod downward-api-dda60d51-097d-11e9-a1bd-0a580a2100c6 container dapi-container: <nil>
STEP: delete the pod
Dec 27 02:19:42.602: INFO: Waiting for pod downward-api-dda60d51-097d-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:19:42.603: INFO: Pod downward-api-dda60d51-097d-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:19:42.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-pxnww" for this suite.
Dec 27 02:19:48.616: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:19:48.645: INFO: namespace: e2e-tests-downward-api-pxnww, resource: bindings, ignored listing per whitelist
Dec 27 02:19:48.674: INFO: namespace e2e-tests-downward-api-pxnww deletion completed in 6.067363415s

• [SLOW TEST:8.148 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:19:48.674: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-e2816db1-097d-11e9-a1bd-0a580a2100c6
STEP: Creating a pod to test consume configMaps
Dec 27 02:19:48.731: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e28230b1-097d-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-projected-56cs6" to be "success or failure"
Dec 27 02:19:48.741: INFO: Pod "pod-projected-configmaps-e28230b1-097d-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 9.674035ms
Dec 27 02:19:50.743: INFO: Pod "pod-projected-configmaps-e28230b1-097d-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012254001s
STEP: Saw pod success
Dec 27 02:19:50.743: INFO: Pod "pod-projected-configmaps-e28230b1-097d-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:19:50.745: INFO: Trying to get logs from node guojing-2 pod pod-projected-configmaps-e28230b1-097d-11e9-a1bd-0a580a2100c6 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 27 02:19:50.758: INFO: Waiting for pod pod-projected-configmaps-e28230b1-097d-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:19:50.760: INFO: Pod pod-projected-configmaps-e28230b1-097d-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:19:50.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-56cs6" for this suite.
Dec 27 02:19:56.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:19:56.818: INFO: namespace: e2e-tests-projected-56cs6, resource: bindings, ignored listing per whitelist
Dec 27 02:19:56.830: INFO: namespace e2e-tests-projected-56cs6 deletion completed in 6.067032231s

• [SLOW TEST:8.156 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:19:56.830: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 27 02:19:56.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-xvg9g'
Dec 27 02:19:57.181: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 27 02:19:57.181: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Dec 27 02:20:01.194: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-xvg9g'
Dec 27 02:20:01.272: INFO: stderr: ""
Dec 27 02:20:01.272: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:20:01.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xvg9g" for this suite.
Dec 27 02:20:07.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:20:07.295: INFO: namespace: e2e-tests-kubectl-xvg9g, resource: bindings, ignored listing per whitelist
Dec 27 02:20:07.348: INFO: namespace e2e-tests-kubectl-xvg9g deletion completed in 6.071525679s

• [SLOW TEST:10.518 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:20:07.349: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-eda3d9cb-097d-11e9-a1bd-0a580a2100c6
STEP: Creating a pod to test consume secrets
Dec 27 02:20:07.411: INFO: Waiting up to 5m0s for pod "pod-secrets-eda4a588-097d-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-secrets-2rfzq" to be "success or failure"
Dec 27 02:20:07.412: INFO: Pod "pod-secrets-eda4a588-097d-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.740602ms
Dec 27 02:20:09.415: INFO: Pod "pod-secrets-eda4a588-097d-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004346987s
STEP: Saw pod success
Dec 27 02:20:09.415: INFO: Pod "pod-secrets-eda4a588-097d-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:20:09.417: INFO: Trying to get logs from node guojing-3 pod pod-secrets-eda4a588-097d-11e9-a1bd-0a580a2100c6 container secret-volume-test: <nil>
STEP: delete the pod
Dec 27 02:20:09.432: INFO: Waiting for pod pod-secrets-eda4a588-097d-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:20:09.434: INFO: Pod pod-secrets-eda4a588-097d-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:20:09.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-2rfzq" for this suite.
Dec 27 02:20:15.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:20:15.453: INFO: namespace: e2e-tests-secrets-2rfzq, resource: bindings, ignored listing per whitelist
Dec 27 02:20:15.504: INFO: namespace e2e-tests-secrets-2rfzq deletion completed in 6.067103108s

• [SLOW TEST:8.156 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:20:15.504: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:20:15.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-djxd9" for this suite.
Dec 27 02:20:37.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:20:37.588: INFO: namespace: e2e-tests-pods-djxd9, resource: bindings, ignored listing per whitelist
Dec 27 02:20:37.638: INFO: namespace e2e-tests-pods-djxd9 deletion completed in 22.073968209s

• [SLOW TEST:22.134 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:20:37.638: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Dec 27 02:20:37.687: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 27 02:20:37.693: INFO: Waiting for terminating namespaces to be deleted...
Dec 27 02:20:37.695: INFO: 
Logging pods the kubelet thinks is on node guojing-1 before test
Dec 27 02:20:37.699: INFO: etcd-guojing-1 from kube-system started at <nil> (0 container statuses recorded)
Dec 27 02:20:37.699: INFO: kube-proxy-4mfwt from kube-system started at 2018-12-27 01:21:44 +0000 UTC (1 container statuses recorded)
Dec 27 02:20:37.699: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 27 02:20:37.699: INFO: kube-flannel-cpmvg from kube-system started at 2018-12-27 01:22:14 +0000 UTC (2 container statuses recorded)
Dec 27 02:20:37.699: INFO: 	Container install-cni ready: true, restart count 0
Dec 27 02:20:37.699: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 27 02:20:37.699: INFO: kube-apiserver-guojing-1 from kube-system started at <nil> (0 container statuses recorded)
Dec 27 02:20:37.699: INFO: kube-scheduler-guojing-1 from kube-system started at <nil> (0 container statuses recorded)
Dec 27 02:20:37.699: INFO: kube-controller-manager-guojing-1 from kube-system started at <nil> (0 container statuses recorded)
Dec 27 02:20:37.699: INFO: 
Logging pods the kubelet thinks is on node guojing-2 before test
Dec 27 02:20:37.703: INFO: coredns-585c7897d4-74jzl from kube-system started at 2018-12-27 01:21:41 +0000 UTC (1 container statuses recorded)
Dec 27 02:20:37.703: INFO: 	Container coredns ready: true, restart count 0
Dec 27 02:20:37.703: INFO: kube-proxy-sfcms from kube-system started at 2018-12-27 01:21:41 +0000 UTC (1 container statuses recorded)
Dec 27 02:20:37.703: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 27 02:20:37.703: INFO: kube-scheduler-guojing-2 from kube-system started at <nil> (0 container statuses recorded)
Dec 27 02:20:37.703: INFO: kube-apiserver-guojing-2 from kube-system started at <nil> (0 container statuses recorded)
Dec 27 02:20:37.703: INFO: sonobuoy-e2e-job-9a6d2b4903a24fc2 from heptio-sonobuoy started at 2018-12-27 01:26:08 +0000 UTC (2 container statuses recorded)
Dec 27 02:20:37.703: INFO: 	Container e2e ready: true, restart count 0
Dec 27 02:20:37.703: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 27 02:20:37.703: INFO: etcd-guojing-2 from kube-system started at <nil> (0 container statuses recorded)
Dec 27 02:20:37.703: INFO: coredns-585c7897d4-xl2hs from kube-system started at 2018-12-27 01:21:41 +0000 UTC (1 container statuses recorded)
Dec 27 02:20:37.703: INFO: 	Container coredns ready: true, restart count 0
Dec 27 02:20:37.703: INFO: kube-controller-manager-guojing-2 from kube-system started at <nil> (0 container statuses recorded)
Dec 27 02:20:37.703: INFO: kube-flannel-2cgd9 from kube-system started at 2018-12-27 01:22:14 +0000 UTC (2 container statuses recorded)
Dec 27 02:20:37.703: INFO: 	Container install-cni ready: true, restart count 0
Dec 27 02:20:37.703: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 27 02:20:37.703: INFO: 
Logging pods the kubelet thinks is on node guojing-3 before test
Dec 27 02:20:37.708: INFO: etcd-guojing-3 from kube-system started at <nil> (0 container statuses recorded)
Dec 27 02:20:37.708: INFO: kube-flannel-hjf2c from kube-system started at 2018-12-27 01:22:14 +0000 UTC (2 container statuses recorded)
Dec 27 02:20:37.708: INFO: 	Container install-cni ready: true, restart count 0
Dec 27 02:20:37.708: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 27 02:20:37.708: INFO: kube-apiserver-guojing-3 from kube-system started at <nil> (0 container statuses recorded)
Dec 27 02:20:37.708: INFO: kube-controller-manager-guojing-3 from kube-system started at <nil> (0 container statuses recorded)
Dec 27 02:20:37.708: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-27 01:26:05 +0000 UTC (3 container statuses recorded)
Dec 27 02:20:37.708: INFO: 	Container cleanup ready: true, restart count 0
Dec 27 02:20:37.708: INFO: 	Container forwarder ready: true, restart count 0
Dec 27 02:20:37.708: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 27 02:20:37.708: INFO: kube-scheduler-guojing-3 from kube-system started at <nil> (0 container statuses recorded)
Dec 27 02:20:37.708: INFO: kube-proxy-bppf2 from kube-system started at 2018-12-27 01:21:44 +0000 UTC (1 container statuses recorded)
Dec 27 02:20:37.708: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15740f2844dcab46], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:20:38.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-rjfl6" for this suite.
Dec 27 02:20:44.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:20:44.770: INFO: namespace: e2e-tests-sched-pred-rjfl6, resource: bindings, ignored listing per whitelist
Dec 27 02:20:44.790: INFO: namespace e2e-tests-sched-pred-rjfl6 deletion completed in 6.06241067s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.152 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:20:44.791: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec 27 02:20:44.834: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:20:48.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-sjqkp" for this suite.
Dec 27 02:21:10.143: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:21:10.154: INFO: namespace: e2e-tests-init-container-sjqkp, resource: bindings, ignored listing per whitelist
Dec 27 02:21:10.206: INFO: namespace e2e-tests-init-container-sjqkp deletion completed in 22.071385336s

• [SLOW TEST:25.415 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:21:10.206: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1227 02:21:20.310471      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 27 02:21:20.310: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:21:20.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-lgnrb" for this suite.
Dec 27 02:21:26.325: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:21:26.364: INFO: namespace: e2e-tests-gc-lgnrb, resource: bindings, ignored listing per whitelist
Dec 27 02:21:26.380: INFO: namespace e2e-tests-gc-lgnrb deletion completed in 6.067328361s

• [SLOW TEST:16.174 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:21:26.380: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 27 02:21:26.441: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1cbf73f8-097e-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-downward-api-9xh76" to be "success or failure"
Dec 27 02:21:26.448: INFO: Pod "downwardapi-volume-1cbf73f8-097e-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.599536ms
Dec 27 02:21:28.451: INFO: Pod "downwardapi-volume-1cbf73f8-097e-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009746955s
STEP: Saw pod success
Dec 27 02:21:28.451: INFO: Pod "downwardapi-volume-1cbf73f8-097e-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:21:28.453: INFO: Trying to get logs from node guojing-1 pod downwardapi-volume-1cbf73f8-097e-11e9-a1bd-0a580a2100c6 container client-container: <nil>
STEP: delete the pod
Dec 27 02:21:28.471: INFO: Waiting for pod downwardapi-volume-1cbf73f8-097e-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:21:28.473: INFO: Pod downwardapi-volume-1cbf73f8-097e-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:21:28.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9xh76" for this suite.
Dec 27 02:21:34.484: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:21:34.538: INFO: namespace: e2e-tests-downward-api-9xh76, resource: bindings, ignored listing per whitelist
Dec 27 02:21:34.542: INFO: namespace e2e-tests-downward-api-9xh76 deletion completed in 6.066437134s

• [SLOW TEST:8.162 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:21:34.542: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 27 02:21:34.593: INFO: Waiting up to 5m0s for pod "downwardapi-volume-219b61cd-097e-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-downward-api-62prz" to be "success or failure"
Dec 27 02:21:34.595: INFO: Pod "downwardapi-volume-219b61cd-097e-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025985ms
Dec 27 02:21:36.601: INFO: Pod "downwardapi-volume-219b61cd-097e-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007977687s
STEP: Saw pod success
Dec 27 02:21:36.601: INFO: Pod "downwardapi-volume-219b61cd-097e-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:21:36.603: INFO: Trying to get logs from node guojing-2 pod downwardapi-volume-219b61cd-097e-11e9-a1bd-0a580a2100c6 container client-container: <nil>
STEP: delete the pod
Dec 27 02:21:36.621: INFO: Waiting for pod downwardapi-volume-219b61cd-097e-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:21:36.623: INFO: Pod downwardapi-volume-219b61cd-097e-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:21:36.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-62prz" for this suite.
Dec 27 02:21:42.635: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:21:42.665: INFO: namespace: e2e-tests-downward-api-62prz, resource: bindings, ignored listing per whitelist
Dec 27 02:21:42.692: INFO: namespace e2e-tests-downward-api-62prz deletion completed in 6.06564124s

• [SLOW TEST:8.150 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:21:42.693: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:22:05.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-mb8vm" for this suite.
Dec 27 02:22:11.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:22:11.957: INFO: namespace: e2e-tests-container-runtime-mb8vm, resource: bindings, ignored listing per whitelist
Dec 27 02:22:11.960: INFO: namespace e2e-tests-container-runtime-mb8vm deletion completed in 6.062288444s

• [SLOW TEST:29.268 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:22:11.961: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec 27 02:22:16.046: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 27 02:22:16.048: INFO: Pod pod-with-poststart-http-hook still exists
Dec 27 02:22:18.048: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 27 02:22:18.054: INFO: Pod pod-with-poststart-http-hook still exists
Dec 27 02:22:20.048: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 27 02:22:20.051: INFO: Pod pod-with-poststart-http-hook still exists
Dec 27 02:22:22.048: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 27 02:22:22.050: INFO: Pod pod-with-poststart-http-hook still exists
Dec 27 02:22:24.048: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 27 02:22:24.050: INFO: Pod pod-with-poststart-http-hook still exists
Dec 27 02:22:26.048: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 27 02:22:26.050: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:22:26.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-trkpv" for this suite.
Dec 27 02:22:48.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:22:48.099: INFO: namespace: e2e-tests-container-lifecycle-hook-trkpv, resource: bindings, ignored listing per whitelist
Dec 27 02:22:48.120: INFO: namespace e2e-tests-container-lifecycle-hook-trkpv deletion completed in 22.066786927s

• [SLOW TEST:36.160 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:22:48.120: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-4d7816e3-097e-11e9-a1bd-0a580a2100c6
STEP: Creating secret with name s-test-opt-upd-4d781733-097e-11e9-a1bd-0a580a2100c6
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-4d7816e3-097e-11e9-a1bd-0a580a2100c6
STEP: Updating secret s-test-opt-upd-4d781733-097e-11e9-a1bd-0a580a2100c6
STEP: Creating secret with name s-test-opt-create-4d781758-097e-11e9-a1bd-0a580a2100c6
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:24:00.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fsh2r" for this suite.
Dec 27 02:24:22.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:24:22.521: INFO: namespace: e2e-tests-projected-fsh2r, resource: bindings, ignored listing per whitelist
Dec 27 02:24:22.571: INFO: namespace e2e-tests-projected-fsh2r deletion completed in 22.066105597s

• [SLOW TEST:94.451 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:24:22.572: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 27 02:24:22.617: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:24:24.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-gltjn" for this suite.
Dec 27 02:25:04.656: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:25:04.680: INFO: namespace: e2e-tests-pods-gltjn, resource: bindings, ignored listing per whitelist
Dec 27 02:25:04.715: INFO: namespace e2e-tests-pods-gltjn deletion completed in 40.069617079s

• [SLOW TEST:42.143 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:25:04.715: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-9ee15acb-097e-11e9-a1bd-0a580a2100c6
STEP: Creating a pod to test consume configMaps
Dec 27 02:25:04.771: INFO: Waiting up to 5m0s for pod "pod-configmaps-9ee21d6f-097e-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-configmap-cmjm8" to be "success or failure"
Dec 27 02:25:04.773: INFO: Pod "pod-configmaps-9ee21d6f-097e-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.862166ms
Dec 27 02:25:06.775: INFO: Pod "pod-configmaps-9ee21d6f-097e-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004358584s
STEP: Saw pod success
Dec 27 02:25:06.775: INFO: Pod "pod-configmaps-9ee21d6f-097e-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:25:06.777: INFO: Trying to get logs from node guojing-1 pod pod-configmaps-9ee21d6f-097e-11e9-a1bd-0a580a2100c6 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 27 02:25:06.795: INFO: Waiting for pod pod-configmaps-9ee21d6f-097e-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:25:06.797: INFO: Pod pod-configmaps-9ee21d6f-097e-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:25:06.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-cmjm8" for this suite.
Dec 27 02:25:12.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:25:12.842: INFO: namespace: e2e-tests-configmap-cmjm8, resource: bindings, ignored listing per whitelist
Dec 27 02:25:12.867: INFO: namespace e2e-tests-configmap-cmjm8 deletion completed in 6.06732935s

• [SLOW TEST:8.152 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:25:12.867: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-a3bce45d-097e-11e9-a1bd-0a580a2100c6
STEP: Creating a pod to test consume configMaps
Dec 27 02:25:12.921: INFO: Waiting up to 5m0s for pod "pod-configmaps-a3bd989c-097e-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-configmap-k4bgz" to be "success or failure"
Dec 27 02:25:12.923: INFO: Pod "pod-configmaps-a3bd989c-097e-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.830536ms
Dec 27 02:25:14.926: INFO: Pod "pod-configmaps-a3bd989c-097e-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004687078s
STEP: Saw pod success
Dec 27 02:25:14.926: INFO: Pod "pod-configmaps-a3bd989c-097e-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:25:14.928: INFO: Trying to get logs from node guojing-2 pod pod-configmaps-a3bd989c-097e-11e9-a1bd-0a580a2100c6 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 27 02:25:14.944: INFO: Waiting for pod pod-configmaps-a3bd989c-097e-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:25:14.947: INFO: Pod pod-configmaps-a3bd989c-097e-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:25:14.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-k4bgz" for this suite.
Dec 27 02:25:20.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:25:20.996: INFO: namespace: e2e-tests-configmap-k4bgz, resource: bindings, ignored listing per whitelist
Dec 27 02:25:21.025: INFO: namespace e2e-tests-configmap-k4bgz deletion completed in 6.074413066s

• [SLOW TEST:8.157 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:25:21.025: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 27 02:25:21.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-z6sn5'
Dec 27 02:25:21.155: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 27 02:25:21.155: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Dec 27 02:25:23.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-z6sn5'
Dec 27 02:25:23.237: INFO: stderr: ""
Dec 27 02:25:23.237: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:25:23.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-z6sn5" for this suite.
Dec 27 02:25:29.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:25:29.310: INFO: namespace: e2e-tests-kubectl-z6sn5, resource: bindings, ignored listing per whitelist
Dec 27 02:25:29.315: INFO: namespace e2e-tests-kubectl-z6sn5 deletion completed in 6.073787824s

• [SLOW TEST:8.290 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:25:29.315: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-ad8b0038-097e-11e9-a1bd-0a580a2100c6
STEP: Creating a pod to test consume configMaps
Dec 27 02:25:29.371: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ad8bcff1-097e-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-projected-z7vvg" to be "success or failure"
Dec 27 02:25:29.373: INFO: Pod "pod-projected-configmaps-ad8bcff1-097e-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.868699ms
Dec 27 02:25:31.375: INFO: Pod "pod-projected-configmaps-ad8bcff1-097e-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004505072s
STEP: Saw pod success
Dec 27 02:25:31.375: INFO: Pod "pod-projected-configmaps-ad8bcff1-097e-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:25:31.377: INFO: Trying to get logs from node guojing-1 pod pod-projected-configmaps-ad8bcff1-097e-11e9-a1bd-0a580a2100c6 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 27 02:25:31.395: INFO: Waiting for pod pod-projected-configmaps-ad8bcff1-097e-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:25:31.397: INFO: Pod pod-projected-configmaps-ad8bcff1-097e-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:25:31.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-z7vvg" for this suite.
Dec 27 02:25:37.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:25:37.422: INFO: namespace: e2e-tests-projected-z7vvg, resource: bindings, ignored listing per whitelist
Dec 27 02:25:37.474: INFO: namespace e2e-tests-projected-z7vvg deletion completed in 6.07463892s

• [SLOW TEST:8.159 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:25:37.474: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 27 02:25:37.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-k8mx8'
Dec 27 02:25:37.600: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 27 02:25:37.600: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Dec 27 02:25:37.609: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-q4p8j]
Dec 27 02:25:37.609: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-q4p8j" in namespace "e2e-tests-kubectl-k8mx8" to be "running and ready"
Dec 27 02:25:37.612: INFO: Pod "e2e-test-nginx-rc-q4p8j": Phase="Pending", Reason="", readiness=false. Elapsed: 2.923533ms
Dec 27 02:25:39.615: INFO: Pod "e2e-test-nginx-rc-q4p8j": Phase="Running", Reason="", readiness=true. Elapsed: 2.005490618s
Dec 27 02:25:39.615: INFO: Pod "e2e-test-nginx-rc-q4p8j" satisfied condition "running and ready"
Dec 27 02:25:39.615: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-q4p8j]
Dec 27 02:25:39.615: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-k8mx8'
Dec 27 02:25:39.708: INFO: stderr: ""
Dec 27 02:25:39.708: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Dec 27 02:25:39.708: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-k8mx8'
Dec 27 02:25:39.782: INFO: stderr: ""
Dec 27 02:25:39.782: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:25:39.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-k8mx8" for this suite.
Dec 27 02:26:01.801: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:26:01.833: INFO: namespace: e2e-tests-kubectl-k8mx8, resource: bindings, ignored listing per whitelist
Dec 27 02:26:01.867: INFO: namespace e2e-tests-kubectl-k8mx8 deletion completed in 22.08117776s

• [SLOW TEST:24.393 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:26:01.867: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 27 02:26:01.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-s5r5w'
Dec 27 02:26:02.009: INFO: stderr: ""
Dec 27 02:26:02.010: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Dec 27 02:26:07.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-s5r5w -o json'
Dec 27 02:26:07.127: INFO: stderr: ""
Dec 27 02:26:07.127: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2018-12-27T02:26:01Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-s5r5w\",\n        \"resourceVersion\": \"13191\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-s5r5w/pods/e2e-test-nginx-pod\",\n        \"uid\": \"c0fd9bf5-097e-11e9-9853-debd8636412e\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-x8zwc\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"guojing-3\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-x8zwc\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-x8zwc\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-27T02:26:02Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-27T02:26:02Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-27T02:26:02Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-27T02:26:02Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://f4bf78aff43c7233db6c8a2d09b28510066c342e3f36c4cacb749a95447f914d\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2018-12-27T02:26:02Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.19.16.36\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.33.1.101\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2018-12-27T02:26:02Z\"\n    }\n}\n"
STEP: replace the image in the pod
Dec 27 02:26:07.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 replace -f - --namespace=e2e-tests-kubectl-s5r5w'
Dec 27 02:26:07.345: INFO: stderr: ""
Dec 27 02:26:07.345: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Dec 27 02:26:07.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-s5r5w'
Dec 27 02:26:14.039: INFO: stderr: ""
Dec 27 02:26:14.039: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:26:14.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-s5r5w" for this suite.
Dec 27 02:26:20.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:26:20.061: INFO: namespace: e2e-tests-kubectl-s5r5w, resource: bindings, ignored listing per whitelist
Dec 27 02:26:20.123: INFO: namespace e2e-tests-kubectl-s5r5w deletion completed in 6.080211315s

• [SLOW TEST:18.256 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:26:20.123: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-qj65x
I1227 02:26:20.178716      18 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-qj65x, replica count: 1
I1227 02:26:21.229039      18 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 27 02:26:21.357: INFO: Created: latency-svc-8klsb
Dec 27 02:26:21.365: INFO: Got endpoints: latency-svc-8klsb [36.176855ms]
Dec 27 02:26:21.386: INFO: Created: latency-svc-7m59s
Dec 27 02:26:21.401: INFO: Got endpoints: latency-svc-7m59s [35.765402ms]
Dec 27 02:26:21.405: INFO: Created: latency-svc-66t44
Dec 27 02:26:21.408: INFO: Got endpoints: latency-svc-66t44 [42.972166ms]
Dec 27 02:26:21.430: INFO: Created: latency-svc-bm9qs
Dec 27 02:26:21.435: INFO: Got endpoints: latency-svc-bm9qs [33.530429ms]
Dec 27 02:26:21.450: INFO: Created: latency-svc-bxr8r
Dec 27 02:26:21.456: INFO: Got endpoints: latency-svc-bxr8r [90.788808ms]
Dec 27 02:26:21.473: INFO: Created: latency-svc-kk9sc
Dec 27 02:26:21.476: INFO: Got endpoints: latency-svc-kk9sc [110.023484ms]
Dec 27 02:26:21.491: INFO: Created: latency-svc-zl5cp
Dec 27 02:26:21.504: INFO: Got endpoints: latency-svc-zl5cp [137.891086ms]
Dec 27 02:26:21.509: INFO: Created: latency-svc-pf2bm
Dec 27 02:26:21.521: INFO: Got endpoints: latency-svc-pf2bm [154.710396ms]
Dec 27 02:26:21.552: INFO: Created: latency-svc-drvvx
Dec 27 02:26:21.566: INFO: Got endpoints: latency-svc-drvvx [199.440326ms]
Dec 27 02:26:21.572: INFO: Created: latency-svc-gds4m
Dec 27 02:26:21.586: INFO: Got endpoints: latency-svc-gds4m [219.880331ms]
Dec 27 02:26:21.589: INFO: Created: latency-svc-kgcrf
Dec 27 02:26:21.593: INFO: Got endpoints: latency-svc-kgcrf [226.348429ms]
Dec 27 02:26:21.608: INFO: Created: latency-svc-82twt
Dec 27 02:26:21.621: INFO: Got endpoints: latency-svc-82twt [253.936348ms]
Dec 27 02:26:21.625: INFO: Created: latency-svc-lmqx8
Dec 27 02:26:21.638: INFO: Got endpoints: latency-svc-lmqx8 [271.106885ms]
Dec 27 02:26:21.643: INFO: Created: latency-svc-hcjhl
Dec 27 02:26:21.674: INFO: Got endpoints: latency-svc-hcjhl [306.878443ms]
Dec 27 02:26:21.678: INFO: Created: latency-svc-5fccl
Dec 27 02:26:21.692: INFO: Got endpoints: latency-svc-5fccl [324.308261ms]
Dec 27 02:26:21.696: INFO: Created: latency-svc-zklh7
Dec 27 02:26:21.700: INFO: Got endpoints: latency-svc-zklh7 [332.644327ms]
Dec 27 02:26:21.714: INFO: Created: latency-svc-hshqc
Dec 27 02:26:21.718: INFO: Got endpoints: latency-svc-hshqc [349.903677ms]
Dec 27 02:26:21.731: INFO: Created: latency-svc-cl7gb
Dec 27 02:26:21.744: INFO: Got endpoints: latency-svc-cl7gb [335.545094ms]
Dec 27 02:26:21.748: INFO: Created: latency-svc-25kcc
Dec 27 02:26:21.754: INFO: Got endpoints: latency-svc-25kcc [319.799789ms]
Dec 27 02:26:21.768: INFO: Created: latency-svc-6c87w
Dec 27 02:26:21.797: INFO: Got endpoints: latency-svc-6c87w [340.524ms]
Dec 27 02:26:21.801: INFO: Created: latency-svc-wblcd
Dec 27 02:26:21.814: INFO: Got endpoints: latency-svc-wblcd [337.809766ms]
Dec 27 02:26:21.818: INFO: Created: latency-svc-gtxgl
Dec 27 02:26:21.823: INFO: Got endpoints: latency-svc-gtxgl [319.484085ms]
Dec 27 02:26:21.839: INFO: Created: latency-svc-4tn2r
Dec 27 02:26:21.852: INFO: Got endpoints: latency-svc-4tn2r [330.669084ms]
Dec 27 02:26:21.855: INFO: Created: latency-svc-pbsgs
Dec 27 02:26:21.860: INFO: Got endpoints: latency-svc-pbsgs [294.481708ms]
Dec 27 02:26:21.874: INFO: Created: latency-svc-cvtf4
Dec 27 02:26:21.888: INFO: Got endpoints: latency-svc-cvtf4 [301.512741ms]
Dec 27 02:26:21.892: INFO: Created: latency-svc-8khd6
Dec 27 02:26:21.916: INFO: Got endpoints: latency-svc-8khd6 [322.888171ms]
Dec 27 02:26:21.920: INFO: Created: latency-svc-2dwqc
Dec 27 02:26:21.934: INFO: Got endpoints: latency-svc-2dwqc [313.52503ms]
Dec 27 02:26:21.939: INFO: Created: latency-svc-jgtls
Dec 27 02:26:21.954: INFO: Got endpoints: latency-svc-jgtls [315.723651ms]
Dec 27 02:26:21.957: INFO: Created: latency-svc-vbg6l
Dec 27 02:26:21.964: INFO: Got endpoints: latency-svc-vbg6l [289.233118ms]
Dec 27 02:26:21.978: INFO: Created: latency-svc-nzgph
Dec 27 02:26:21.982: INFO: Got endpoints: latency-svc-nzgph [290.596353ms]
Dec 27 02:26:21.996: INFO: Created: latency-svc-t6sbv
Dec 27 02:26:22.010: INFO: Got endpoints: latency-svc-t6sbv [309.934292ms]
Dec 27 02:26:22.014: INFO: Created: latency-svc-s4k6v
Dec 27 02:26:22.036: INFO: Got endpoints: latency-svc-s4k6v [318.460704ms]
Dec 27 02:26:22.041: INFO: Created: latency-svc-l9z7f
Dec 27 02:26:22.057: INFO: Got endpoints: latency-svc-l9z7f [312.779617ms]
Dec 27 02:26:22.060: INFO: Created: latency-svc-rs2f5
Dec 27 02:26:22.066: INFO: Got endpoints: latency-svc-rs2f5 [311.857079ms]
Dec 27 02:26:22.082: INFO: Created: latency-svc-krrlk
Dec 27 02:26:22.088: INFO: Got endpoints: latency-svc-krrlk [290.813419ms]
Dec 27 02:26:22.103: INFO: Created: latency-svc-c98vq
Dec 27 02:26:22.111: INFO: Got endpoints: latency-svc-c98vq [297.186996ms]
Dec 27 02:26:22.127: INFO: Created: latency-svc-kcqh4
Dec 27 02:26:22.157: INFO: Got endpoints: latency-svc-kcqh4 [333.982207ms]
Dec 27 02:26:22.161: INFO: Created: latency-svc-xlhhq
Dec 27 02:26:22.175: INFO: Got endpoints: latency-svc-xlhhq [322.982611ms]
Dec 27 02:26:22.179: INFO: Created: latency-svc-f8zlx
Dec 27 02:26:22.192: INFO: Got endpoints: latency-svc-f8zlx [331.787011ms]
Dec 27 02:26:22.195: INFO: Created: latency-svc-bb6n6
Dec 27 02:26:22.201: INFO: Got endpoints: latency-svc-bb6n6 [312.491421ms]
Dec 27 02:26:22.213: INFO: Created: latency-svc-82hdq
Dec 27 02:26:22.227: INFO: Got endpoints: latency-svc-82hdq [311.125146ms]
Dec 27 02:26:22.231: INFO: Created: latency-svc-lwsns
Dec 27 02:26:22.244: INFO: Got endpoints: latency-svc-lwsns [309.752427ms]
Dec 27 02:26:22.248: INFO: Created: latency-svc-fpxj9
Dec 27 02:26:22.279: INFO: Got endpoints: latency-svc-fpxj9 [324.930328ms]
Dec 27 02:26:22.285: INFO: Created: latency-svc-25vsr
Dec 27 02:26:22.299: INFO: Got endpoints: latency-svc-25vsr [335.419836ms]
Dec 27 02:26:22.302: INFO: Created: latency-svc-jzhrk
Dec 27 02:26:22.308: INFO: Got endpoints: latency-svc-jzhrk [325.388748ms]
Dec 27 02:26:22.321: INFO: Created: latency-svc-5dvd6
Dec 27 02:26:22.325: INFO: Got endpoints: latency-svc-5dvd6 [314.526137ms]
Dec 27 02:26:22.339: INFO: Created: latency-svc-p56lb
Dec 27 02:26:22.353: INFO: Got endpoints: latency-svc-p56lb [316.252193ms]
Dec 27 02:26:22.355: INFO: Created: latency-svc-gtljx
Dec 27 02:26:22.359: INFO: Got endpoints: latency-svc-gtljx [301.995268ms]
Dec 27 02:26:22.379: INFO: Created: latency-svc-rkgnj
Dec 27 02:26:22.403: INFO: Got endpoints: latency-svc-rkgnj [336.602883ms]
Dec 27 02:26:22.406: INFO: Created: latency-svc-b4kz2
Dec 27 02:26:22.419: INFO: Got endpoints: latency-svc-b4kz2 [330.750912ms]
Dec 27 02:26:22.424: INFO: Created: latency-svc-fq7nn
Dec 27 02:26:22.428: INFO: Got endpoints: latency-svc-fq7nn [316.936503ms]
Dec 27 02:26:22.441: INFO: Created: latency-svc-n5c5d
Dec 27 02:26:22.459: INFO: Created: latency-svc-5wxhh
Dec 27 02:26:22.460: INFO: Got endpoints: latency-svc-n5c5d [303.027263ms]
Dec 27 02:26:22.477: INFO: Created: latency-svc-wmw2c
Dec 27 02:26:22.495: INFO: Created: latency-svc-9fj2n
Dec 27 02:26:22.527: INFO: Got endpoints: latency-svc-5wxhh [352.842986ms]
Dec 27 02:26:22.530: INFO: Created: latency-svc-gsv4k
Dec 27 02:26:22.550: INFO: Created: latency-svc-wjh6h
Dec 27 02:26:22.567: INFO: Got endpoints: latency-svc-wmw2c [375.078421ms]
Dec 27 02:26:22.571: INFO: Created: latency-svc-65n6j
Dec 27 02:26:22.588: INFO: Created: latency-svc-6qgzr
Dec 27 02:26:22.604: INFO: Created: latency-svc-hpczj
Dec 27 02:26:22.622: INFO: Got endpoints: latency-svc-9fj2n [421.548656ms]
Dec 27 02:26:22.623: INFO: Created: latency-svc-8q6jj
Dec 27 02:26:22.662: INFO: Created: latency-svc-mhlp6
Dec 27 02:26:22.662: INFO: Got endpoints: latency-svc-gsv4k [434.380464ms]
Dec 27 02:26:22.678: INFO: Created: latency-svc-qlfhs
Dec 27 02:26:22.695: INFO: Created: latency-svc-42nf9
Dec 27 02:26:22.712: INFO: Got endpoints: latency-svc-wjh6h [467.218633ms]
Dec 27 02:26:22.714: INFO: Created: latency-svc-wp9f4
Dec 27 02:26:22.730: INFO: Created: latency-svc-ngsr9
Dec 27 02:26:22.748: INFO: Created: latency-svc-k4fgn
Dec 27 02:26:22.774: INFO: Got endpoints: latency-svc-65n6j [494.640406ms]
Dec 27 02:26:22.777: INFO: Created: latency-svc-bwrg9
Dec 27 02:26:22.793: INFO: Created: latency-svc-llk95
Dec 27 02:26:22.812: INFO: Got endpoints: latency-svc-6qgzr [513.099868ms]
Dec 27 02:26:22.812: INFO: Created: latency-svc-qpqr5
Dec 27 02:26:22.832: INFO: Created: latency-svc-8kwhw
Dec 27 02:26:22.849: INFO: Created: latency-svc-rg7x4
Dec 27 02:26:22.863: INFO: Got endpoints: latency-svc-hpczj [555.487806ms]
Dec 27 02:26:22.866: INFO: Created: latency-svc-g9bzd
Dec 27 02:26:22.908: INFO: Created: latency-svc-7lljm
Dec 27 02:26:22.921: INFO: Got endpoints: latency-svc-8q6jj [596.438416ms]
Dec 27 02:26:22.924: INFO: Created: latency-svc-ntwz9
Dec 27 02:26:22.949: INFO: Created: latency-svc-t7rdb
Dec 27 02:26:22.961: INFO: Got endpoints: latency-svc-mhlp6 [608.674708ms]
Dec 27 02:26:22.984: INFO: Created: latency-svc-8khgb
Dec 27 02:26:23.016: INFO: Got endpoints: latency-svc-qlfhs [657.199877ms]
Dec 27 02:26:23.040: INFO: Created: latency-svc-mh7k8
Dec 27 02:26:23.061: INFO: Got endpoints: latency-svc-42nf9 [658.00006ms]
Dec 27 02:26:23.084: INFO: Created: latency-svc-jhc4s
Dec 27 02:26:23.111: INFO: Got endpoints: latency-svc-wp9f4 [692.227092ms]
Dec 27 02:26:23.135: INFO: Created: latency-svc-p4ql7
Dec 27 02:26:23.161: INFO: Got endpoints: latency-svc-ngsr9 [733.100024ms]
Dec 27 02:26:23.181: INFO: Created: latency-svc-6pbtm
Dec 27 02:26:23.211: INFO: Got endpoints: latency-svc-k4fgn [750.323602ms]
Dec 27 02:26:23.244: INFO: Created: latency-svc-l77bg
Dec 27 02:26:23.262: INFO: Got endpoints: latency-svc-bwrg9 [734.498906ms]
Dec 27 02:26:23.283: INFO: Created: latency-svc-l4lsc
Dec 27 02:26:23.311: INFO: Got endpoints: latency-svc-llk95 [743.563924ms]
Dec 27 02:26:23.332: INFO: Created: latency-svc-wmtkh
Dec 27 02:26:23.361: INFO: Got endpoints: latency-svc-qpqr5 [738.91848ms]
Dec 27 02:26:23.381: INFO: Created: latency-svc-sqkhw
Dec 27 02:26:23.413: INFO: Got endpoints: latency-svc-8kwhw [750.931979ms]
Dec 27 02:26:23.433: INFO: Created: latency-svc-f24v7
Dec 27 02:26:23.465: INFO: Got endpoints: latency-svc-rg7x4 [752.929434ms]
Dec 27 02:26:23.487: INFO: Created: latency-svc-x8jnq
Dec 27 02:26:23.511: INFO: Got endpoints: latency-svc-g9bzd [737.501186ms]
Dec 27 02:26:23.533: INFO: Created: latency-svc-q7lxp
Dec 27 02:26:23.561: INFO: Got endpoints: latency-svc-7lljm [748.833588ms]
Dec 27 02:26:23.583: INFO: Created: latency-svc-hlfbg
Dec 27 02:26:23.614: INFO: Got endpoints: latency-svc-ntwz9 [750.882863ms]
Dec 27 02:26:23.634: INFO: Created: latency-svc-6jb8t
Dec 27 02:26:23.661: INFO: Got endpoints: latency-svc-t7rdb [739.602127ms]
Dec 27 02:26:23.692: INFO: Created: latency-svc-zvlzz
Dec 27 02:26:23.711: INFO: Got endpoints: latency-svc-8khgb [749.344321ms]
Dec 27 02:26:23.733: INFO: Created: latency-svc-jlxtf
Dec 27 02:26:23.761: INFO: Got endpoints: latency-svc-mh7k8 [745.031039ms]
Dec 27 02:26:23.781: INFO: Created: latency-svc-csk27
Dec 27 02:26:23.811: INFO: Got endpoints: latency-svc-jhc4s [749.734817ms]
Dec 27 02:26:23.833: INFO: Created: latency-svc-d8vvn
Dec 27 02:26:23.861: INFO: Got endpoints: latency-svc-p4ql7 [750.527618ms]
Dec 27 02:26:23.882: INFO: Created: latency-svc-sg6jl
Dec 27 02:26:23.916: INFO: Got endpoints: latency-svc-6pbtm [754.579473ms]
Dec 27 02:26:23.938: INFO: Created: latency-svc-p9x87
Dec 27 02:26:23.963: INFO: Got endpoints: latency-svc-l77bg [752.529945ms]
Dec 27 02:26:23.986: INFO: Created: latency-svc-f4w4m
Dec 27 02:26:24.011: INFO: Got endpoints: latency-svc-l4lsc [748.833557ms]
Dec 27 02:26:24.031: INFO: Created: latency-svc-8ffbl
Dec 27 02:26:24.061: INFO: Got endpoints: latency-svc-wmtkh [750.128708ms]
Dec 27 02:26:24.083: INFO: Created: latency-svc-r9865
Dec 27 02:26:24.112: INFO: Got endpoints: latency-svc-sqkhw [750.56983ms]
Dec 27 02:26:24.141: INFO: Created: latency-svc-wjlxh
Dec 27 02:26:24.163: INFO: Got endpoints: latency-svc-f24v7 [750.792154ms]
Dec 27 02:26:24.185: INFO: Created: latency-svc-92gps
Dec 27 02:26:24.211: INFO: Got endpoints: latency-svc-x8jnq [746.336253ms]
Dec 27 02:26:24.231: INFO: Created: latency-svc-vhskf
Dec 27 02:26:24.261: INFO: Got endpoints: latency-svc-q7lxp [750.116447ms]
Dec 27 02:26:24.281: INFO: Created: latency-svc-6ldp8
Dec 27 02:26:24.311: INFO: Got endpoints: latency-svc-hlfbg [750.295337ms]
Dec 27 02:26:24.332: INFO: Created: latency-svc-9h48g
Dec 27 02:26:24.364: INFO: Got endpoints: latency-svc-6jb8t [749.535931ms]
Dec 27 02:26:24.384: INFO: Created: latency-svc-nhpmm
Dec 27 02:26:24.412: INFO: Got endpoints: latency-svc-zvlzz [750.788693ms]
Dec 27 02:26:24.432: INFO: Created: latency-svc-fdfjh
Dec 27 02:26:24.461: INFO: Got endpoints: latency-svc-jlxtf [750.440791ms]
Dec 27 02:26:24.483: INFO: Created: latency-svc-n85df
Dec 27 02:26:24.514: INFO: Got endpoints: latency-svc-csk27 [752.915475ms]
Dec 27 02:26:24.537: INFO: Created: latency-svc-b45zk
Dec 27 02:26:24.561: INFO: Got endpoints: latency-svc-d8vvn [750.636427ms]
Dec 27 02:26:24.595: INFO: Created: latency-svc-527vs
Dec 27 02:26:24.611: INFO: Got endpoints: latency-svc-sg6jl [749.014673ms]
Dec 27 02:26:24.629: INFO: Created: latency-svc-xg4cp
Dec 27 02:26:24.661: INFO: Got endpoints: latency-svc-p9x87 [745.651063ms]
Dec 27 02:26:24.681: INFO: Created: latency-svc-jnx65
Dec 27 02:26:24.711: INFO: Got endpoints: latency-svc-f4w4m [747.644759ms]
Dec 27 02:26:24.733: INFO: Created: latency-svc-xz59g
Dec 27 02:26:24.761: INFO: Got endpoints: latency-svc-8ffbl [749.794982ms]
Dec 27 02:26:24.780: INFO: Created: latency-svc-bqgmf
Dec 27 02:26:24.821: INFO: Got endpoints: latency-svc-r9865 [759.913715ms]
Dec 27 02:26:24.842: INFO: Created: latency-svc-5qjt9
Dec 27 02:26:24.864: INFO: Got endpoints: latency-svc-wjlxh [752.754284ms]
Dec 27 02:26:24.889: INFO: Created: latency-svc-8djct
Dec 27 02:26:24.912: INFO: Got endpoints: latency-svc-92gps [748.437462ms]
Dec 27 02:26:24.942: INFO: Created: latency-svc-22sgt
Dec 27 02:26:24.961: INFO: Got endpoints: latency-svc-vhskf [750.136101ms]
Dec 27 02:26:24.981: INFO: Created: latency-svc-rplnn
Dec 27 02:26:25.011: INFO: Got endpoints: latency-svc-6ldp8 [749.35019ms]
Dec 27 02:26:25.032: INFO: Created: latency-svc-kx2z5
Dec 27 02:26:25.061: INFO: Got endpoints: latency-svc-9h48g [749.356287ms]
Dec 27 02:26:25.081: INFO: Created: latency-svc-rdv7g
Dec 27 02:26:25.112: INFO: Got endpoints: latency-svc-nhpmm [747.598942ms]
Dec 27 02:26:25.131: INFO: Created: latency-svc-4hvtl
Dec 27 02:26:25.161: INFO: Got endpoints: latency-svc-fdfjh [749.295708ms]
Dec 27 02:26:25.181: INFO: Created: latency-svc-ghmxw
Dec 27 02:26:25.214: INFO: Got endpoints: latency-svc-n85df [752.406946ms]
Dec 27 02:26:25.235: INFO: Created: latency-svc-rthvc
Dec 27 02:26:25.270: INFO: Got endpoints: latency-svc-b45zk [756.054935ms]
Dec 27 02:26:25.290: INFO: Created: latency-svc-h2pwj
Dec 27 02:26:25.311: INFO: Got endpoints: latency-svc-527vs [749.454574ms]
Dec 27 02:26:25.330: INFO: Created: latency-svc-5mxth
Dec 27 02:26:25.361: INFO: Got endpoints: latency-svc-xg4cp [750.647393ms]
Dec 27 02:26:25.386: INFO: Created: latency-svc-ksfrn
Dec 27 02:26:25.411: INFO: Got endpoints: latency-svc-jnx65 [749.546364ms]
Dec 27 02:26:25.431: INFO: Created: latency-svc-qj66p
Dec 27 02:26:25.461: INFO: Got endpoints: latency-svc-xz59g [750.034055ms]
Dec 27 02:26:25.481: INFO: Created: latency-svc-s8vjn
Dec 27 02:26:25.511: INFO: Got endpoints: latency-svc-bqgmf [749.904802ms]
Dec 27 02:26:25.530: INFO: Created: latency-svc-8h54m
Dec 27 02:26:25.563: INFO: Got endpoints: latency-svc-5qjt9 [741.468401ms]
Dec 27 02:26:25.583: INFO: Created: latency-svc-c6hj9
Dec 27 02:26:25.612: INFO: Got endpoints: latency-svc-8djct [747.047116ms]
Dec 27 02:26:25.632: INFO: Created: latency-svc-snb42
Dec 27 02:26:25.661: INFO: Got endpoints: latency-svc-22sgt [749.102393ms]
Dec 27 02:26:25.680: INFO: Created: latency-svc-pmmgv
Dec 27 02:26:25.720: INFO: Got endpoints: latency-svc-rplnn [759.208185ms]
Dec 27 02:26:25.740: INFO: Created: latency-svc-hxgmz
Dec 27 02:26:25.760: INFO: Got endpoints: latency-svc-kx2z5 [749.445593ms]
Dec 27 02:26:25.779: INFO: Created: latency-svc-4txlw
Dec 27 02:26:25.812: INFO: Got endpoints: latency-svc-rdv7g [751.057087ms]
Dec 27 02:26:25.838: INFO: Created: latency-svc-2jvh5
Dec 27 02:26:25.861: INFO: Got endpoints: latency-svc-4hvtl [748.995799ms]
Dec 27 02:26:25.879: INFO: Created: latency-svc-dltx5
Dec 27 02:26:25.913: INFO: Got endpoints: latency-svc-ghmxw [751.759773ms]
Dec 27 02:26:25.949: INFO: Created: latency-svc-vxmpn
Dec 27 02:26:25.961: INFO: Got endpoints: latency-svc-rthvc [747.054815ms]
Dec 27 02:26:25.981: INFO: Created: latency-svc-k7cj5
Dec 27 02:26:26.012: INFO: Got endpoints: latency-svc-h2pwj [741.996485ms]
Dec 27 02:26:26.037: INFO: Created: latency-svc-kss5b
Dec 27 02:26:26.061: INFO: Got endpoints: latency-svc-5mxth [750.290634ms]
Dec 27 02:26:26.080: INFO: Created: latency-svc-59svs
Dec 27 02:26:26.111: INFO: Got endpoints: latency-svc-ksfrn [749.294643ms]
Dec 27 02:26:26.132: INFO: Created: latency-svc-pkvsq
Dec 27 02:26:26.170: INFO: Got endpoints: latency-svc-qj66p [758.435727ms]
Dec 27 02:26:26.190: INFO: Created: latency-svc-hb57m
Dec 27 02:26:26.210: INFO: Got endpoints: latency-svc-s8vjn [749.240051ms]
Dec 27 02:26:26.230: INFO: Created: latency-svc-npbg5
Dec 27 02:26:26.261: INFO: Got endpoints: latency-svc-8h54m [750.571127ms]
Dec 27 02:26:26.285: INFO: Created: latency-svc-v87xt
Dec 27 02:26:26.314: INFO: Got endpoints: latency-svc-c6hj9 [751.088066ms]
Dec 27 02:26:26.334: INFO: Created: latency-svc-6lkx7
Dec 27 02:26:26.361: INFO: Got endpoints: latency-svc-snb42 [749.368546ms]
Dec 27 02:26:26.395: INFO: Created: latency-svc-mrfhm
Dec 27 02:26:26.412: INFO: Got endpoints: latency-svc-pmmgv [750.577748ms]
Dec 27 02:26:26.432: INFO: Created: latency-svc-fhwbd
Dec 27 02:26:26.462: INFO: Got endpoints: latency-svc-hxgmz [741.022824ms]
Dec 27 02:26:26.482: INFO: Created: latency-svc-2gdrg
Dec 27 02:26:26.511: INFO: Got endpoints: latency-svc-4txlw [750.582025ms]
Dec 27 02:26:26.531: INFO: Created: latency-svc-vh6qq
Dec 27 02:26:26.562: INFO: Got endpoints: latency-svc-2jvh5 [749.71205ms]
Dec 27 02:26:26.584: INFO: Created: latency-svc-rwhlk
Dec 27 02:26:26.618: INFO: Got endpoints: latency-svc-dltx5 [757.167404ms]
Dec 27 02:26:26.638: INFO: Created: latency-svc-f8vlt
Dec 27 02:26:26.661: INFO: Got endpoints: latency-svc-vxmpn [748.366776ms]
Dec 27 02:26:26.682: INFO: Created: latency-svc-fbfxj
Dec 27 02:26:26.712: INFO: Got endpoints: latency-svc-k7cj5 [751.28813ms]
Dec 27 02:26:26.736: INFO: Created: latency-svc-x4zdj
Dec 27 02:26:26.761: INFO: Got endpoints: latency-svc-kss5b [748.588596ms]
Dec 27 02:26:26.782: INFO: Created: latency-svc-s8k2v
Dec 27 02:26:26.812: INFO: Got endpoints: latency-svc-59svs [750.294258ms]
Dec 27 02:26:26.832: INFO: Created: latency-svc-pb28v
Dec 27 02:26:26.864: INFO: Got endpoints: latency-svc-pkvsq [753.322019ms]
Dec 27 02:26:26.886: INFO: Created: latency-svc-xw72x
Dec 27 02:26:26.911: INFO: Got endpoints: latency-svc-hb57m [740.895938ms]
Dec 27 02:26:26.931: INFO: Created: latency-svc-qdd5p
Dec 27 02:26:26.961: INFO: Got endpoints: latency-svc-npbg5 [750.635667ms]
Dec 27 02:26:26.981: INFO: Created: latency-svc-g47v9
Dec 27 02:26:27.011: INFO: Got endpoints: latency-svc-v87xt [749.635768ms]
Dec 27 02:26:27.032: INFO: Created: latency-svc-tvkgh
Dec 27 02:26:27.069: INFO: Got endpoints: latency-svc-6lkx7 [755.569637ms]
Dec 27 02:26:27.096: INFO: Created: latency-svc-mv2s7
Dec 27 02:26:27.110: INFO: Got endpoints: latency-svc-mrfhm [749.291789ms]
Dec 27 02:26:27.130: INFO: Created: latency-svc-fjb82
Dec 27 02:26:27.161: INFO: Got endpoints: latency-svc-fhwbd [749.235461ms]
Dec 27 02:26:27.185: INFO: Created: latency-svc-nvzsq
Dec 27 02:26:27.211: INFO: Got endpoints: latency-svc-2gdrg [748.99629ms]
Dec 27 02:26:27.231: INFO: Created: latency-svc-787f5
Dec 27 02:26:27.261: INFO: Got endpoints: latency-svc-vh6qq [749.992187ms]
Dec 27 02:26:27.282: INFO: Created: latency-svc-d9fq5
Dec 27 02:26:27.311: INFO: Got endpoints: latency-svc-rwhlk [749.817146ms]
Dec 27 02:26:27.332: INFO: Created: latency-svc-2cc69
Dec 27 02:26:27.360: INFO: Got endpoints: latency-svc-f8vlt [742.636009ms]
Dec 27 02:26:27.379: INFO: Created: latency-svc-gl54q
Dec 27 02:26:27.412: INFO: Got endpoints: latency-svc-fbfxj [750.670563ms]
Dec 27 02:26:27.433: INFO: Created: latency-svc-jv7cm
Dec 27 02:26:27.462: INFO: Got endpoints: latency-svc-x4zdj [749.950545ms]
Dec 27 02:26:27.481: INFO: Created: latency-svc-24rqw
Dec 27 02:26:27.518: INFO: Got endpoints: latency-svc-s8k2v [756.910843ms]
Dec 27 02:26:27.540: INFO: Created: latency-svc-9p27b
Dec 27 02:26:27.561: INFO: Got endpoints: latency-svc-pb28v [749.135335ms]
Dec 27 02:26:27.581: INFO: Created: latency-svc-wq9rg
Dec 27 02:26:27.612: INFO: Got endpoints: latency-svc-xw72x [748.077136ms]
Dec 27 02:26:27.635: INFO: Created: latency-svc-p8xdl
Dec 27 02:26:27.661: INFO: Got endpoints: latency-svc-qdd5p [749.822158ms]
Dec 27 02:26:27.680: INFO: Created: latency-svc-hvhcp
Dec 27 02:26:27.711: INFO: Got endpoints: latency-svc-g47v9 [750.154558ms]
Dec 27 02:26:27.730: INFO: Created: latency-svc-v28bz
Dec 27 02:26:27.761: INFO: Got endpoints: latency-svc-tvkgh [749.878241ms]
Dec 27 02:26:27.781: INFO: Created: latency-svc-sv425
Dec 27 02:26:27.812: INFO: Got endpoints: latency-svc-mv2s7 [743.08228ms]
Dec 27 02:26:27.831: INFO: Created: latency-svc-nc95c
Dec 27 02:26:27.861: INFO: Got endpoints: latency-svc-fjb82 [750.467412ms]
Dec 27 02:26:27.880: INFO: Created: latency-svc-8k8zp
Dec 27 02:26:27.911: INFO: Got endpoints: latency-svc-nvzsq [750.252641ms]
Dec 27 02:26:27.930: INFO: Created: latency-svc-bhhfj
Dec 27 02:26:27.965: INFO: Got endpoints: latency-svc-787f5 [754.708597ms]
Dec 27 02:26:27.987: INFO: Created: latency-svc-8vt6g
Dec 27 02:26:28.012: INFO: Got endpoints: latency-svc-d9fq5 [750.944751ms]
Dec 27 02:26:28.033: INFO: Created: latency-svc-m7prq
Dec 27 02:26:28.061: INFO: Got endpoints: latency-svc-2cc69 [749.660771ms]
Dec 27 02:26:28.085: INFO: Created: latency-svc-wnzl5
Dec 27 02:26:28.111: INFO: Got endpoints: latency-svc-gl54q [750.841505ms]
Dec 27 02:26:28.138: INFO: Created: latency-svc-6z9pk
Dec 27 02:26:28.161: INFO: Got endpoints: latency-svc-jv7cm [748.852811ms]
Dec 27 02:26:28.194: INFO: Created: latency-svc-7p6wq
Dec 27 02:26:28.210: INFO: Got endpoints: latency-svc-24rqw [748.516882ms]
Dec 27 02:26:28.232: INFO: Created: latency-svc-zrf5z
Dec 27 02:26:28.263: INFO: Got endpoints: latency-svc-9p27b [744.874997ms]
Dec 27 02:26:28.286: INFO: Created: latency-svc-tkc9d
Dec 27 02:26:28.311: INFO: Got endpoints: latency-svc-wq9rg [750.266719ms]
Dec 27 02:26:28.330: INFO: Created: latency-svc-6k2tv
Dec 27 02:26:28.361: INFO: Got endpoints: latency-svc-p8xdl [748.779928ms]
Dec 27 02:26:28.381: INFO: Created: latency-svc-mrpw4
Dec 27 02:26:28.418: INFO: Got endpoints: latency-svc-hvhcp [757.515578ms]
Dec 27 02:26:28.440: INFO: Created: latency-svc-t94lq
Dec 27 02:26:28.461: INFO: Got endpoints: latency-svc-v28bz [749.188371ms]
Dec 27 02:26:28.480: INFO: Created: latency-svc-b764c
Dec 27 02:26:28.511: INFO: Got endpoints: latency-svc-sv425 [749.808567ms]
Dec 27 02:26:28.536: INFO: Created: latency-svc-p2r6v
Dec 27 02:26:28.561: INFO: Got endpoints: latency-svc-nc95c [748.811094ms]
Dec 27 02:26:28.582: INFO: Created: latency-svc-b4q2v
Dec 27 02:26:28.612: INFO: Got endpoints: latency-svc-8k8zp [751.497784ms]
Dec 27 02:26:28.649: INFO: Created: latency-svc-bzrxd
Dec 27 02:26:28.661: INFO: Got endpoints: latency-svc-bhhfj [749.244885ms]
Dec 27 02:26:28.680: INFO: Created: latency-svc-pz7v9
Dec 27 02:26:28.713: INFO: Got endpoints: latency-svc-8vt6g [747.843361ms]
Dec 27 02:26:28.733: INFO: Created: latency-svc-n67vv
Dec 27 02:26:28.761: INFO: Got endpoints: latency-svc-m7prq [749.438482ms]
Dec 27 02:26:28.783: INFO: Created: latency-svc-56vpd
Dec 27 02:26:28.814: INFO: Got endpoints: latency-svc-wnzl5 [752.352369ms]
Dec 27 02:26:28.833: INFO: Created: latency-svc-wnsm2
Dec 27 02:26:28.872: INFO: Got endpoints: latency-svc-6z9pk [760.864368ms]
Dec 27 02:26:28.892: INFO: Created: latency-svc-d9lvp
Dec 27 02:26:28.911: INFO: Got endpoints: latency-svc-7p6wq [749.368049ms]
Dec 27 02:26:28.929: INFO: Created: latency-svc-q4gjx
Dec 27 02:26:28.961: INFO: Got endpoints: latency-svc-zrf5z [750.014483ms]
Dec 27 02:26:28.994: INFO: Created: latency-svc-pkq6k
Dec 27 02:26:29.011: INFO: Got endpoints: latency-svc-tkc9d [747.858922ms]
Dec 27 02:26:29.031: INFO: Created: latency-svc-25hjd
Dec 27 02:26:29.061: INFO: Got endpoints: latency-svc-6k2tv [750.350038ms]
Dec 27 02:26:29.082: INFO: Created: latency-svc-5w6sb
Dec 27 02:26:29.111: INFO: Got endpoints: latency-svc-mrpw4 [749.815785ms]
Dec 27 02:26:29.131: INFO: Created: latency-svc-9w87c
Dec 27 02:26:29.162: INFO: Got endpoints: latency-svc-t94lq [744.14805ms]
Dec 27 02:26:29.182: INFO: Created: latency-svc-4mdmp
Dec 27 02:26:29.213: INFO: Got endpoints: latency-svc-b764c [752.393306ms]
Dec 27 02:26:29.262: INFO: Got endpoints: latency-svc-p2r6v [751.354723ms]
Dec 27 02:26:29.315: INFO: Got endpoints: latency-svc-b4q2v [753.977247ms]
Dec 27 02:26:29.361: INFO: Got endpoints: latency-svc-bzrxd [748.962715ms]
Dec 27 02:26:29.411: INFO: Got endpoints: latency-svc-pz7v9 [750.264766ms]
Dec 27 02:26:29.461: INFO: Got endpoints: latency-svc-n67vv [747.871893ms]
Dec 27 02:26:29.513: INFO: Got endpoints: latency-svc-56vpd [751.202743ms]
Dec 27 02:26:29.561: INFO: Got endpoints: latency-svc-wnsm2 [747.129917ms]
Dec 27 02:26:29.611: INFO: Got endpoints: latency-svc-d9lvp [739.12723ms]
Dec 27 02:26:29.661: INFO: Got endpoints: latency-svc-q4gjx [750.601741ms]
Dec 27 02:26:29.712: INFO: Got endpoints: latency-svc-pkq6k [751.670217ms]
Dec 27 02:26:29.761: INFO: Got endpoints: latency-svc-25hjd [750.102534ms]
Dec 27 02:26:29.811: INFO: Got endpoints: latency-svc-5w6sb [749.662283ms]
Dec 27 02:26:29.863: INFO: Got endpoints: latency-svc-9w87c [751.999404ms]
Dec 27 02:26:29.912: INFO: Got endpoints: latency-svc-4mdmp [749.302754ms]
Dec 27 02:26:29.912: INFO: Latencies: [33.530429ms 35.765402ms 42.972166ms 90.788808ms 110.023484ms 137.891086ms 154.710396ms 199.440326ms 219.880331ms 226.348429ms 253.936348ms 271.106885ms 289.233118ms 290.596353ms 290.813419ms 294.481708ms 297.186996ms 301.512741ms 301.995268ms 303.027263ms 306.878443ms 309.752427ms 309.934292ms 311.125146ms 311.857079ms 312.491421ms 312.779617ms 313.52503ms 314.526137ms 315.723651ms 316.252193ms 316.936503ms 318.460704ms 319.484085ms 319.799789ms 322.888171ms 322.982611ms 324.308261ms 324.930328ms 325.388748ms 330.669084ms 330.750912ms 331.787011ms 332.644327ms 333.982207ms 335.419836ms 335.545094ms 336.602883ms 337.809766ms 340.524ms 349.903677ms 352.842986ms 375.078421ms 421.548656ms 434.380464ms 467.218633ms 494.640406ms 513.099868ms 555.487806ms 596.438416ms 608.674708ms 657.199877ms 658.00006ms 692.227092ms 733.100024ms 734.498906ms 737.501186ms 738.91848ms 739.12723ms 739.602127ms 740.895938ms 741.022824ms 741.468401ms 741.996485ms 742.636009ms 743.08228ms 743.563924ms 744.14805ms 744.874997ms 745.031039ms 745.651063ms 746.336253ms 747.047116ms 747.054815ms 747.129917ms 747.598942ms 747.644759ms 747.843361ms 747.858922ms 747.871893ms 748.077136ms 748.366776ms 748.437462ms 748.516882ms 748.588596ms 748.779928ms 748.811094ms 748.833557ms 748.833588ms 748.852811ms 748.962715ms 748.995799ms 748.99629ms 749.014673ms 749.102393ms 749.135335ms 749.188371ms 749.235461ms 749.240051ms 749.244885ms 749.291789ms 749.294643ms 749.295708ms 749.302754ms 749.344321ms 749.35019ms 749.356287ms 749.368049ms 749.368546ms 749.438482ms 749.445593ms 749.454574ms 749.535931ms 749.546364ms 749.635768ms 749.660771ms 749.662283ms 749.71205ms 749.734817ms 749.794982ms 749.808567ms 749.815785ms 749.817146ms 749.822158ms 749.878241ms 749.904802ms 749.950545ms 749.992187ms 750.014483ms 750.034055ms 750.102534ms 750.116447ms 750.128708ms 750.136101ms 750.154558ms 750.252641ms 750.264766ms 750.266719ms 750.290634ms 750.294258ms 750.295337ms 750.323602ms 750.350038ms 750.440791ms 750.467412ms 750.527618ms 750.56983ms 750.571127ms 750.577748ms 750.582025ms 750.601741ms 750.635667ms 750.636427ms 750.647393ms 750.670563ms 750.788693ms 750.792154ms 750.841505ms 750.882863ms 750.931979ms 750.944751ms 751.057087ms 751.088066ms 751.202743ms 751.28813ms 751.354723ms 751.497784ms 751.670217ms 751.759773ms 751.999404ms 752.352369ms 752.393306ms 752.406946ms 752.529945ms 752.754284ms 752.915475ms 752.929434ms 753.322019ms 753.977247ms 754.579473ms 754.708597ms 755.569637ms 756.054935ms 756.910843ms 757.167404ms 757.515578ms 758.435727ms 759.208185ms 759.913715ms 760.864368ms]
Dec 27 02:26:29.912: INFO: 50 %ile: 748.962715ms
Dec 27 02:26:29.912: INFO: 90 %ile: 752.352369ms
Dec 27 02:26:29.912: INFO: 99 %ile: 759.913715ms
Dec 27 02:26:29.912: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:26:29.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-qj65x" for this suite.
Dec 27 02:26:45.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:26:45.937: INFO: namespace: e2e-tests-svc-latency-qj65x, resource: bindings, ignored listing per whitelist
Dec 27 02:26:45.984: INFO: namespace e2e-tests-svc-latency-qj65x deletion completed in 16.068678973s

• [SLOW TEST:25.861 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:26:45.984: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 27 02:26:46.047: INFO: (0) /api/v1/nodes/guojing-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.550255ms)
Dec 27 02:26:46.053: INFO: (1) /api/v1/nodes/guojing-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.389022ms)
Dec 27 02:26:46.056: INFO: (2) /api/v1/nodes/guojing-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.941402ms)
Dec 27 02:26:46.059: INFO: (3) /api/v1/nodes/guojing-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.874262ms)
Dec 27 02:26:46.062: INFO: (4) /api/v1/nodes/guojing-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.016076ms)
Dec 27 02:26:46.068: INFO: (5) /api/v1/nodes/guojing-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.343828ms)
Dec 27 02:26:46.070: INFO: (6) /api/v1/nodes/guojing-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.516969ms)
Dec 27 02:26:46.073: INFO: (7) /api/v1/nodes/guojing-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.393169ms)
Dec 27 02:26:46.076: INFO: (8) /api/v1/nodes/guojing-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.855148ms)
Dec 27 02:26:46.079: INFO: (9) /api/v1/nodes/guojing-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.875201ms)
Dec 27 02:26:46.082: INFO: (10) /api/v1/nodes/guojing-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.591069ms)
Dec 27 02:26:46.085: INFO: (11) /api/v1/nodes/guojing-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.542836ms)
Dec 27 02:26:46.087: INFO: (12) /api/v1/nodes/guojing-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.519157ms)
Dec 27 02:26:46.090: INFO: (13) /api/v1/nodes/guojing-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.311207ms)
Dec 27 02:26:46.092: INFO: (14) /api/v1/nodes/guojing-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.491594ms)
Dec 27 02:26:46.095: INFO: (15) /api/v1/nodes/guojing-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.02858ms)
Dec 27 02:26:46.098: INFO: (16) /api/v1/nodes/guojing-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.307986ms)
Dec 27 02:26:46.100: INFO: (17) /api/v1/nodes/guojing-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.22473ms)
Dec 27 02:26:46.102: INFO: (18) /api/v1/nodes/guojing-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.290579ms)
Dec 27 02:26:46.104: INFO: (19) /api/v1/nodes/guojing-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.185185ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:26:46.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-d6kdj" for this suite.
Dec 27 02:26:52.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:26:52.168: INFO: namespace: e2e-tests-proxy-d6kdj, resource: bindings, ignored listing per whitelist
Dec 27 02:26:52.176: INFO: namespace e2e-tests-proxy-d6kdj deletion completed in 6.068516605s

• [SLOW TEST:6.192 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:26:52.176: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Dec 27 02:26:52.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 cluster-info'
Dec 27 02:26:52.290: INFO: stderr: ""
Dec 27 02:26:52.290: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:26:52.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2cnvp" for this suite.
Dec 27 02:26:58.302: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:26:58.309: INFO: namespace: e2e-tests-kubectl-2cnvp, resource: bindings, ignored listing per whitelist
Dec 27 02:26:58.359: INFO: namespace e2e-tests-kubectl-2cnvp deletion completed in 6.066296628s

• [SLOW TEST:6.183 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:26:58.359: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Dec 27 02:26:58.406: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 create -f - --namespace=e2e-tests-kubectl-zvtf7'
Dec 27 02:26:58.612: INFO: stderr: ""
Dec 27 02:26:58.612: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Dec 27 02:26:59.615: INFO: Selector matched 1 pods for map[app:redis]
Dec 27 02:26:59.615: INFO: Found 0 / 1
Dec 27 02:27:00.614: INFO: Selector matched 1 pods for map[app:redis]
Dec 27 02:27:00.614: INFO: Found 1 / 1
Dec 27 02:27:00.614: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 27 02:27:00.616: INFO: Selector matched 1 pods for map[app:redis]
Dec 27 02:27:00.616: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Dec 27 02:27:00.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 logs redis-master-7f5cf redis-master --namespace=e2e-tests-kubectl-zvtf7'
Dec 27 02:27:00.695: INFO: stderr: ""
Dec 27 02:27:00.695: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 27 Dec 02:26:59.385 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 27 Dec 02:26:59.385 # Server started, Redis version 3.2.12\n1:M 27 Dec 02:26:59.385 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 27 Dec 02:26:59.385 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Dec 27 02:27:00.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 log redis-master-7f5cf redis-master --namespace=e2e-tests-kubectl-zvtf7 --tail=1'
Dec 27 02:27:00.765: INFO: stderr: ""
Dec 27 02:27:00.765: INFO: stdout: "1:M 27 Dec 02:26:59.385 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Dec 27 02:27:00.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 log redis-master-7f5cf redis-master --namespace=e2e-tests-kubectl-zvtf7 --limit-bytes=1'
Dec 27 02:27:00.841: INFO: stderr: ""
Dec 27 02:27:00.841: INFO: stdout: " "
STEP: exposing timestamps
Dec 27 02:27:00.841: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 log redis-master-7f5cf redis-master --namespace=e2e-tests-kubectl-zvtf7 --tail=1 --timestamps'
Dec 27 02:27:00.920: INFO: stderr: ""
Dec 27 02:27:00.920: INFO: stdout: "2018-12-27T02:26:59.385744464Z 1:M 27 Dec 02:26:59.385 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Dec 27 02:27:03.420: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 log redis-master-7f5cf redis-master --namespace=e2e-tests-kubectl-zvtf7 --since=1s'
Dec 27 02:27:03.507: INFO: stderr: ""
Dec 27 02:27:03.507: INFO: stdout: ""
Dec 27 02:27:03.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 log redis-master-7f5cf redis-master --namespace=e2e-tests-kubectl-zvtf7 --since=24h'
Dec 27 02:27:03.588: INFO: stderr: ""
Dec 27 02:27:03.588: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 27 Dec 02:26:59.385 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 27 Dec 02:26:59.385 # Server started, Redis version 3.2.12\n1:M 27 Dec 02:26:59.385 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 27 Dec 02:26:59.385 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Dec 27 02:27:03.588: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-zvtf7'
Dec 27 02:27:03.656: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 27 02:27:03.656: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Dec 27 02:27:03.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-zvtf7'
Dec 27 02:27:03.727: INFO: stderr: "No resources found.\n"
Dec 27 02:27:03.727: INFO: stdout: ""
Dec 27 02:27:03.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods -l name=nginx --namespace=e2e-tests-kubectl-zvtf7 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 27 02:27:03.797: INFO: stderr: ""
Dec 27 02:27:03.797: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:27:03.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zvtf7" for this suite.
Dec 27 02:27:09.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:27:09.865: INFO: namespace: e2e-tests-kubectl-zvtf7, resource: bindings, ignored listing per whitelist
Dec 27 02:27:09.869: INFO: namespace e2e-tests-kubectl-zvtf7 deletion completed in 6.067893887s

• [SLOW TEST:11.510 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:27:09.869: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Dec 27 02:27:16.946: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:27:17.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-t4hhp" for this suite.
Dec 27 02:27:39.971: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:27:40.020: INFO: namespace: e2e-tests-replicaset-t4hhp, resource: bindings, ignored listing per whitelist
Dec 27 02:27:40.034: INFO: namespace e2e-tests-replicaset-t4hhp deletion completed in 22.07171626s

• [SLOW TEST:30.165 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:27:40.034: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec 27 02:27:40.091: INFO: Waiting up to 5m0s for pod "pod-fb75ec8a-097e-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-emptydir-7rt5m" to be "success or failure"
Dec 27 02:27:40.093: INFO: Pod "pod-fb75ec8a-097e-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039535ms
Dec 27 02:27:42.096: INFO: Pod "pod-fb75ec8a-097e-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004934454s
STEP: Saw pod success
Dec 27 02:27:42.096: INFO: Pod "pod-fb75ec8a-097e-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:27:42.098: INFO: Trying to get logs from node guojing-2 pod pod-fb75ec8a-097e-11e9-a1bd-0a580a2100c6 container test-container: <nil>
STEP: delete the pod
Dec 27 02:27:42.117: INFO: Waiting for pod pod-fb75ec8a-097e-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:27:42.122: INFO: Pod pod-fb75ec8a-097e-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:27:42.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-7rt5m" for this suite.
Dec 27 02:27:48.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:27:48.144: INFO: namespace: e2e-tests-emptydir-7rt5m, resource: bindings, ignored listing per whitelist
Dec 27 02:27:48.191: INFO: namespace e2e-tests-emptydir-7rt5m deletion completed in 6.066021537s

• [SLOW TEST:8.157 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:27:48.191: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-86fdd
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 27 02:27:48.238: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 27 02:28:06.313: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.33.1.104:8080/dial?request=hostName&protocol=http&host=10.33.0.46&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-86fdd PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 27 02:28:06.313: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
Dec 27 02:28:06.399: INFO: Waiting for endpoints: map[]
Dec 27 02:28:06.402: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.33.1.104:8080/dial?request=hostName&protocol=http&host=10.33.2.128&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-86fdd PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 27 02:28:06.402: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
Dec 27 02:28:06.481: INFO: Waiting for endpoints: map[]
Dec 27 02:28:06.484: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.33.1.104:8080/dial?request=hostName&protocol=http&host=10.33.1.103&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-86fdd PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 27 02:28:06.484: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
Dec 27 02:28:06.563: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:28:06.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-86fdd" for this suite.
Dec 27 02:28:28.576: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:28:28.585: INFO: namespace: e2e-tests-pod-network-test-86fdd, resource: bindings, ignored listing per whitelist
Dec 27 02:28:28.641: INFO: namespace e2e-tests-pod-network-test-86fdd deletion completed in 22.074110708s

• [SLOW TEST:40.450 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:28:28.641: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec 27 02:28:28.699: INFO: Waiting up to 5m0s for pod "pod-186eda7b-097f-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-emptydir-t9h9z" to be "success or failure"
Dec 27 02:28:28.701: INFO: Pod "pod-186eda7b-097f-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.908768ms
Dec 27 02:28:30.703: INFO: Pod "pod-186eda7b-097f-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004373439s
STEP: Saw pod success
Dec 27 02:28:30.703: INFO: Pod "pod-186eda7b-097f-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:28:30.705: INFO: Trying to get logs from node guojing-2 pod pod-186eda7b-097f-11e9-a1bd-0a580a2100c6 container test-container: <nil>
STEP: delete the pod
Dec 27 02:28:30.722: INFO: Waiting for pod pod-186eda7b-097f-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:28:30.724: INFO: Pod pod-186eda7b-097f-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:28:30.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-t9h9z" for this suite.
Dec 27 02:28:36.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:28:36.787: INFO: namespace: e2e-tests-emptydir-t9h9z, resource: bindings, ignored listing per whitelist
Dec 27 02:28:36.800: INFO: namespace e2e-tests-emptydir-t9h9z deletion completed in 6.072401757s

• [SLOW TEST:8.159 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:28:36.800: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 27 02:28:36.855: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1d4b6cd7-097f-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-downward-api-mpf52" to be "success or failure"
Dec 27 02:28:36.858: INFO: Pod "downwardapi-volume-1d4b6cd7-097f-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.115433ms
Dec 27 02:28:38.861: INFO: Pod "downwardapi-volume-1d4b6cd7-097f-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005896573s
STEP: Saw pod success
Dec 27 02:28:38.861: INFO: Pod "downwardapi-volume-1d4b6cd7-097f-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:28:38.863: INFO: Trying to get logs from node guojing-3 pod downwardapi-volume-1d4b6cd7-097f-11e9-a1bd-0a580a2100c6 container client-container: <nil>
STEP: delete the pod
Dec 27 02:28:38.878: INFO: Waiting for pod downwardapi-volume-1d4b6cd7-097f-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:28:38.880: INFO: Pod downwardapi-volume-1d4b6cd7-097f-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:28:38.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-mpf52" for this suite.
Dec 27 02:28:44.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:28:44.946: INFO: namespace: e2e-tests-downward-api-mpf52, resource: bindings, ignored listing per whitelist
Dec 27 02:28:44.949: INFO: namespace e2e-tests-downward-api-mpf52 deletion completed in 6.065996799s

• [SLOW TEST:8.149 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:28:44.949: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-2226f766-097f-11e9-a1bd-0a580a2100c6
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:28:47.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-rjkvg" for this suite.
Dec 27 02:29:09.040: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:29:09.093: INFO: namespace: e2e-tests-configmap-rjkvg, resource: bindings, ignored listing per whitelist
Dec 27 02:29:09.099: INFO: namespace e2e-tests-configmap-rjkvg deletion completed in 22.067934669s

• [SLOW TEST:24.150 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:29:09.099: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-308ce3b1-097f-11e9-a1bd-0a580a2100c6
STEP: Creating secret with name s-test-opt-upd-308ce421-097f-11e9-a1bd-0a580a2100c6
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-308ce3b1-097f-11e9-a1bd-0a580a2100c6
STEP: Updating secret s-test-opt-upd-308ce421-097f-11e9-a1bd-0a580a2100c6
STEP: Creating secret with name s-test-opt-create-308ce451-097f-11e9-a1bd-0a580a2100c6
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:29:15.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-6fwsk" for this suite.
Dec 27 02:29:37.257: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:29:37.268: INFO: namespace: e2e-tests-secrets-6fwsk, resource: bindings, ignored listing per whitelist
Dec 27 02:29:37.319: INFO: namespace e2e-tests-secrets-6fwsk deletion completed in 22.071167249s

• [SLOW TEST:28.220 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:29:37.319: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-415e5e6b-097f-11e9-a1bd-0a580a2100c6
STEP: Creating a pod to test consume configMaps
Dec 27 02:29:37.381: INFO: Waiting up to 5m0s for pod "pod-configmaps-415f22eb-097f-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-configmap-z6fj7" to be "success or failure"
Dec 27 02:29:37.383: INFO: Pod "pod-configmaps-415f22eb-097f-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.866312ms
Dec 27 02:29:39.386: INFO: Pod "pod-configmaps-415f22eb-097f-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004506656s
STEP: Saw pod success
Dec 27 02:29:39.386: INFO: Pod "pod-configmaps-415f22eb-097f-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:29:39.388: INFO: Trying to get logs from node guojing-3 pod pod-configmaps-415f22eb-097f-11e9-a1bd-0a580a2100c6 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 27 02:29:39.404: INFO: Waiting for pod pod-configmaps-415f22eb-097f-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:29:39.406: INFO: Pod pod-configmaps-415f22eb-097f-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:29:39.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-z6fj7" for this suite.
Dec 27 02:29:45.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:29:45.445: INFO: namespace: e2e-tests-configmap-z6fj7, resource: bindings, ignored listing per whitelist
Dec 27 02:29:45.483: INFO: namespace e2e-tests-configmap-z6fj7 deletion completed in 6.074130447s

• [SLOW TEST:8.164 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:29:45.483: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 27 02:29:45.538: INFO: Waiting up to 5m0s for pod "downwardapi-volume-463b3d6e-097f-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-downward-api-fr48g" to be "success or failure"
Dec 27 02:29:45.540: INFO: Pod "downwardapi-volume-463b3d6e-097f-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.973051ms
Dec 27 02:29:47.543: INFO: Pod "downwardapi-volume-463b3d6e-097f-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004789615s
STEP: Saw pod success
Dec 27 02:29:47.543: INFO: Pod "downwardapi-volume-463b3d6e-097f-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:29:47.544: INFO: Trying to get logs from node guojing-1 pod downwardapi-volume-463b3d6e-097f-11e9-a1bd-0a580a2100c6 container client-container: <nil>
STEP: delete the pod
Dec 27 02:29:47.561: INFO: Waiting for pod downwardapi-volume-463b3d6e-097f-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:29:47.563: INFO: Pod downwardapi-volume-463b3d6e-097f-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:29:47.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-fr48g" for this suite.
Dec 27 02:29:53.574: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:29:53.625: INFO: namespace: e2e-tests-downward-api-fr48g, resource: bindings, ignored listing per whitelist
Dec 27 02:29:53.632: INFO: namespace e2e-tests-downward-api-fr48g deletion completed in 6.065943064s

• [SLOW TEST:8.149 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:29:53.632: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Dec 27 02:29:53.688: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-wvbs6,SelfLink:/api/v1/namespaces/e2e-tests-watch-wvbs6/configmaps/e2e-watch-test-watch-closed,UID:4b16e633-097f-11e9-9853-debd8636412e,ResourceVersion:15291,Generation:0,CreationTimestamp:2018-12-27 02:29:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 27 02:29:53.688: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-wvbs6,SelfLink:/api/v1/namespaces/e2e-tests-watch-wvbs6/configmaps/e2e-watch-test-watch-closed,UID:4b16e633-097f-11e9-9853-debd8636412e,ResourceVersion:15292,Generation:0,CreationTimestamp:2018-12-27 02:29:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Dec 27 02:29:53.699: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-wvbs6,SelfLink:/api/v1/namespaces/e2e-tests-watch-wvbs6/configmaps/e2e-watch-test-watch-closed,UID:4b16e633-097f-11e9-9853-debd8636412e,ResourceVersion:15293,Generation:0,CreationTimestamp:2018-12-27 02:29:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 27 02:29:53.699: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-wvbs6,SelfLink:/api/v1/namespaces/e2e-tests-watch-wvbs6/configmaps/e2e-watch-test-watch-closed,UID:4b16e633-097f-11e9-9853-debd8636412e,ResourceVersion:15294,Generation:0,CreationTimestamp:2018-12-27 02:29:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:29:53.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-wvbs6" for this suite.
Dec 27 02:29:59.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:29:59.750: INFO: namespace: e2e-tests-watch-wvbs6, resource: bindings, ignored listing per whitelist
Dec 27 02:29:59.768: INFO: namespace e2e-tests-watch-wvbs6 deletion completed in 6.066322204s

• [SLOW TEST:6.136 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:29:59.768: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-lkbpc.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-lkbpc.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-lkbpc.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-lkbpc.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-lkbpc.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-lkbpc.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 27 02:30:01.893: INFO: DNS probes using e2e-tests-dns-lkbpc/dns-test-4ec04a10-097f-11e9-a1bd-0a580a2100c6 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:30:01.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-lkbpc" for this suite.
Dec 27 02:30:07.925: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:30:07.964: INFO: namespace: e2e-tests-dns-lkbpc, resource: bindings, ignored listing per whitelist
Dec 27 02:30:07.983: INFO: namespace e2e-tests-dns-lkbpc deletion completed in 6.072997808s

• [SLOW TEST:8.215 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:30:07.983: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 27 02:30:08.041: INFO: Waiting up to 5m0s for pod "downwardapi-volume-53a4fb6c-097f-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-projected-xsk4n" to be "success or failure"
Dec 27 02:30:08.043: INFO: Pod "downwardapi-volume-53a4fb6c-097f-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026194ms
Dec 27 02:30:10.046: INFO: Pod "downwardapi-volume-53a4fb6c-097f-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00475088s
STEP: Saw pod success
Dec 27 02:30:10.046: INFO: Pod "downwardapi-volume-53a4fb6c-097f-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:30:10.048: INFO: Trying to get logs from node guojing-3 pod downwardapi-volume-53a4fb6c-097f-11e9-a1bd-0a580a2100c6 container client-container: <nil>
STEP: delete the pod
Dec 27 02:30:10.064: INFO: Waiting for pod downwardapi-volume-53a4fb6c-097f-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:30:10.067: INFO: Pod downwardapi-volume-53a4fb6c-097f-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:30:10.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xsk4n" for this suite.
Dec 27 02:30:16.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:30:16.097: INFO: namespace: e2e-tests-projected-xsk4n, resource: bindings, ignored listing per whitelist
Dec 27 02:30:16.141: INFO: namespace e2e-tests-projected-xsk4n deletion completed in 6.071646514s

• [SLOW TEST:8.158 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:30:16.141: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-29p2g
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-29p2g
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-29p2g
Dec 27 02:30:16.200: INFO: Found 0 stateful pods, waiting for 1
Dec 27 02:30:26.203: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Dec 27 02:30:26.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 exec --namespace=e2e-tests-statefulset-29p2g ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 27 02:30:26.354: INFO: stderr: ""
Dec 27 02:30:26.354: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 27 02:30:26.354: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 27 02:30:26.357: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec 27 02:30:36.360: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 27 02:30:36.360: INFO: Waiting for statefulset status.replicas updated to 0
Dec 27 02:30:36.371: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998502s
Dec 27 02:30:37.374: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.997844125s
Dec 27 02:30:38.377: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.994800497s
Dec 27 02:30:39.380: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.991833941s
Dec 27 02:30:40.382: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.988989288s
Dec 27 02:30:41.385: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.986124499s
Dec 27 02:30:42.388: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.983223674s
Dec 27 02:30:43.391: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.980377491s
Dec 27 02:30:44.394: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.977430222s
Dec 27 02:30:45.397: INFO: Verifying statefulset ss doesn't scale past 1 for another 974.363081ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-29p2g
Dec 27 02:30:46.400: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 exec --namespace=e2e-tests-statefulset-29p2g ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 27 02:30:46.548: INFO: stderr: ""
Dec 27 02:30:46.548: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 27 02:30:46.548: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 27 02:30:46.551: INFO: Found 1 stateful pods, waiting for 3
Dec 27 02:30:56.553: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 27 02:30:56.553: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 27 02:30:56.553: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Dec 27 02:30:56.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 exec --namespace=e2e-tests-statefulset-29p2g ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 27 02:30:56.699: INFO: stderr: ""
Dec 27 02:30:56.699: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 27 02:30:56.699: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 27 02:30:56.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 exec --namespace=e2e-tests-statefulset-29p2g ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 27 02:30:56.849: INFO: stderr: ""
Dec 27 02:30:56.849: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 27 02:30:56.850: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 27 02:30:56.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 exec --namespace=e2e-tests-statefulset-29p2g ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 27 02:30:56.996: INFO: stderr: ""
Dec 27 02:30:56.996: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 27 02:30:56.996: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 27 02:30:56.996: INFO: Waiting for statefulset status.replicas updated to 0
Dec 27 02:30:56.998: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Dec 27 02:31:07.004: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 27 02:31:07.004: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec 27 02:31:07.004: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec 27 02:31:07.012: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998881s
Dec 27 02:31:08.015: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997589251s
Dec 27 02:31:09.019: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.994550654s
Dec 27 02:31:10.023: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.989831537s
Dec 27 02:31:11.026: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.986485112s
Dec 27 02:31:12.030: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.983172722s
Dec 27 02:31:13.033: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.979008489s
Dec 27 02:31:14.037: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.975984586s
Dec 27 02:31:15.040: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.972469836s
Dec 27 02:31:16.044: INFO: Verifying statefulset ss doesn't scale past 3 for another 969.158678ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-29p2g
Dec 27 02:31:17.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 exec --namespace=e2e-tests-statefulset-29p2g ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 27 02:31:17.195: INFO: stderr: ""
Dec 27 02:31:17.195: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 27 02:31:17.195: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 27 02:31:17.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 exec --namespace=e2e-tests-statefulset-29p2g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 27 02:31:17.342: INFO: stderr: ""
Dec 27 02:31:17.342: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 27 02:31:17.342: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 27 02:31:17.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 exec --namespace=e2e-tests-statefulset-29p2g ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 27 02:31:17.483: INFO: stderr: ""
Dec 27 02:31:17.483: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 27 02:31:17.483: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 27 02:31:17.483: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec 27 02:31:37.494: INFO: Deleting all statefulset in ns e2e-tests-statefulset-29p2g
Dec 27 02:31:37.496: INFO: Scaling statefulset ss to 0
Dec 27 02:31:37.501: INFO: Waiting for statefulset status.replicas updated to 0
Dec 27 02:31:37.503: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:31:37.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-29p2g" for this suite.
Dec 27 02:31:43.526: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:31:43.538: INFO: namespace: e2e-tests-statefulset-29p2g, resource: bindings, ignored listing per whitelist
Dec 27 02:31:43.583: INFO: namespace e2e-tests-statefulset-29p2g deletion completed in 6.066266205s

• [SLOW TEST:87.442 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:31:43.583: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 27 02:31:43.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 version'
Dec 27 02:31:43.692: INFO: stderr: ""
Dec 27 02:31:43.692: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.1\", GitCommit:\"eec55b9ba98609a46fee712359c7b5b365bdd920\", GitTreeState:\"clean\", BuildDate:\"2018-12-13T10:31:33Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:31:43.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zhc7z" for this suite.
Dec 27 02:31:49.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:31:49.754: INFO: namespace: e2e-tests-kubectl-zhc7z, resource: bindings, ignored listing per whitelist
Dec 27 02:31:49.777: INFO: namespace e2e-tests-kubectl-zhc7z deletion completed in 6.082078381s

• [SLOW TEST:6.194 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:31:49.777: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 27 02:31:51.873: INFO: Waiting up to 5m0s for pod "client-envvars-9188e07d-097f-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-pods-67bzk" to be "success or failure"
Dec 27 02:31:51.875: INFO: Pod "client-envvars-9188e07d-097f-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.093143ms
Dec 27 02:31:53.878: INFO: Pod "client-envvars-9188e07d-097f-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005082442s
STEP: Saw pod success
Dec 27 02:31:53.878: INFO: Pod "client-envvars-9188e07d-097f-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:31:53.880: INFO: Trying to get logs from node guojing-2 pod client-envvars-9188e07d-097f-11e9-a1bd-0a580a2100c6 container env3cont: <nil>
STEP: delete the pod
Dec 27 02:31:53.900: INFO: Waiting for pod client-envvars-9188e07d-097f-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:31:53.902: INFO: Pod client-envvars-9188e07d-097f-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:31:53.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-67bzk" for this suite.
Dec 27 02:32:31.914: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:32:31.965: INFO: namespace: e2e-tests-pods-67bzk, resource: bindings, ignored listing per whitelist
Dec 27 02:32:31.974: INFO: namespace e2e-tests-pods-67bzk deletion completed in 38.068246054s

• [SLOW TEST:42.196 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:32:31.974: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W1227 02:33:12.059500      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 27 02:33:12.059: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:33:12.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-jbsvr" for this suite.
Dec 27 02:33:18.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:33:18.088: INFO: namespace: e2e-tests-gc-jbsvr, resource: bindings, ignored listing per whitelist
Dec 27 02:33:18.136: INFO: namespace e2e-tests-gc-jbsvr deletion completed in 6.074615124s

• [SLOW TEST:46.162 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:33:18.136: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-c4fc4efb-097f-11e9-a1bd-0a580a2100c6
STEP: Creating a pod to test consume configMaps
Dec 27 02:33:18.199: INFO: Waiting up to 5m0s for pod "pod-configmaps-c4fd1bfe-097f-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-configmap-58pdb" to be "success or failure"
Dec 27 02:33:18.201: INFO: Pod "pod-configmaps-c4fd1bfe-097f-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.870798ms
Dec 27 02:33:20.204: INFO: Pod "pod-configmaps-c4fd1bfe-097f-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00465214s
STEP: Saw pod success
Dec 27 02:33:20.204: INFO: Pod "pod-configmaps-c4fd1bfe-097f-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:33:20.206: INFO: Trying to get logs from node guojing-2 pod pod-configmaps-c4fd1bfe-097f-11e9-a1bd-0a580a2100c6 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 27 02:33:20.225: INFO: Waiting for pod pod-configmaps-c4fd1bfe-097f-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:33:20.227: INFO: Pod pod-configmaps-c4fd1bfe-097f-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:33:20.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-58pdb" for this suite.
Dec 27 02:33:26.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:33:26.288: INFO: namespace: e2e-tests-configmap-58pdb, resource: bindings, ignored listing per whitelist
Dec 27 02:33:26.298: INFO: namespace e2e-tests-configmap-58pdb deletion completed in 6.068157327s

• [SLOW TEST:8.162 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:33:26.299: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 27 02:33:26.353: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c9d90179-097f-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-downward-api-m778t" to be "success or failure"
Dec 27 02:33:26.355: INFO: Pod "downwardapi-volume-c9d90179-097f-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.122463ms
Dec 27 02:33:28.358: INFO: Pod "downwardapi-volume-c9d90179-097f-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005264951s
STEP: Saw pod success
Dec 27 02:33:28.358: INFO: Pod "downwardapi-volume-c9d90179-097f-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:33:28.360: INFO: Trying to get logs from node guojing-2 pod downwardapi-volume-c9d90179-097f-11e9-a1bd-0a580a2100c6 container client-container: <nil>
STEP: delete the pod
Dec 27 02:33:28.376: INFO: Waiting for pod downwardapi-volume-c9d90179-097f-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:33:28.378: INFO: Pod downwardapi-volume-c9d90179-097f-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:33:28.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-m778t" for this suite.
Dec 27 02:33:34.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:33:34.421: INFO: namespace: e2e-tests-downward-api-m778t, resource: bindings, ignored listing per whitelist
Dec 27 02:33:34.454: INFO: namespace e2e-tests-downward-api-m778t deletion completed in 6.071130758s

• [SLOW TEST:8.155 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:33:34.454: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Dec 27 02:33:34.507: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Dec 27 02:33:34.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 create -f - --namespace=e2e-tests-kubectl-h8tkz'
Dec 27 02:33:34.938: INFO: stderr: ""
Dec 27 02:33:34.938: INFO: stdout: "service/redis-slave created\n"
Dec 27 02:33:34.938: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Dec 27 02:33:34.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 create -f - --namespace=e2e-tests-kubectl-h8tkz'
Dec 27 02:33:35.126: INFO: stderr: ""
Dec 27 02:33:35.126: INFO: stdout: "service/redis-master created\n"
Dec 27 02:33:35.126: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Dec 27 02:33:35.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 create -f - --namespace=e2e-tests-kubectl-h8tkz'
Dec 27 02:33:35.309: INFO: stderr: ""
Dec 27 02:33:35.309: INFO: stdout: "service/frontend created\n"
Dec 27 02:33:35.309: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Dec 27 02:33:35.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 create -f - --namespace=e2e-tests-kubectl-h8tkz'
Dec 27 02:33:35.478: INFO: stderr: ""
Dec 27 02:33:35.478: INFO: stdout: "deployment.extensions/frontend created\n"
Dec 27 02:33:35.478: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec 27 02:33:35.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 create -f - --namespace=e2e-tests-kubectl-h8tkz'
Dec 27 02:33:35.659: INFO: stderr: ""
Dec 27 02:33:35.659: INFO: stdout: "deployment.extensions/redis-master created\n"
Dec 27 02:33:35.659: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Dec 27 02:33:35.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 create -f - --namespace=e2e-tests-kubectl-h8tkz'
Dec 27 02:33:35.831: INFO: stderr: ""
Dec 27 02:33:35.831: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Dec 27 02:33:35.831: INFO: Waiting for all frontend pods to be Running.
Dec 27 02:33:40.882: INFO: Waiting for frontend to serve content.
Dec 27 02:33:40.894: INFO: Trying to add a new entry to the guestbook.
Dec 27 02:33:40.903: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Dec 27 02:33:40.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-h8tkz'
Dec 27 02:33:41.010: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 27 02:33:41.010: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Dec 27 02:33:41.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-h8tkz'
Dec 27 02:33:41.110: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 27 02:33:41.110: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec 27 02:33:41.110: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-h8tkz'
Dec 27 02:33:41.197: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 27 02:33:41.197: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec 27 02:33:41.197: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-h8tkz'
Dec 27 02:33:41.264: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 27 02:33:41.265: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec 27 02:33:41.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-h8tkz'
Dec 27 02:33:41.346: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 27 02:33:41.346: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec 27 02:33:41.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-h8tkz'
Dec 27 02:33:41.423: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 27 02:33:41.423: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:33:41.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-h8tkz" for this suite.
Dec 27 02:34:25.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:34:25.486: INFO: namespace: e2e-tests-kubectl-h8tkz, resource: bindings, ignored listing per whitelist
Dec 27 02:34:25.504: INFO: namespace e2e-tests-kubectl-h8tkz deletion completed in 44.07605549s

• [SLOW TEST:51.050 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:34:25.505: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-ggb87
Dec 27 02:34:27.565: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-ggb87
STEP: checking the pod's current state and verifying that restartCount is present
Dec 27 02:34:27.567: INFO: Initial restart count of pod liveness-http is 0
Dec 27 02:34:43.591: INFO: Restart count of pod e2e-tests-container-probe-ggb87/liveness-http is now 1 (16.023352757s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:34:43.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-ggb87" for this suite.
Dec 27 02:34:49.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:34:49.643: INFO: namespace: e2e-tests-container-probe-ggb87, resource: bindings, ignored listing per whitelist
Dec 27 02:34:49.671: INFO: namespace e2e-tests-container-probe-ggb87 deletion completed in 6.066102193s

• [SLOW TEST:24.166 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:34:49.672: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Dec 27 02:34:49.721: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 27 02:34:49.727: INFO: Waiting for terminating namespaces to be deleted...
Dec 27 02:34:49.729: INFO: 
Logging pods the kubelet thinks is on node guojing-1 before test
Dec 27 02:34:49.734: INFO: kube-controller-manager-guojing-1 from kube-system started at <nil> (0 container statuses recorded)
Dec 27 02:34:49.734: INFO: kube-proxy-4mfwt from kube-system started at 2018-12-27 01:21:44 +0000 UTC (1 container statuses recorded)
Dec 27 02:34:49.734: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 27 02:34:49.734: INFO: kube-flannel-cpmvg from kube-system started at 2018-12-27 01:22:14 +0000 UTC (2 container statuses recorded)
Dec 27 02:34:49.734: INFO: 	Container install-cni ready: true, restart count 0
Dec 27 02:34:49.734: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 27 02:34:49.734: INFO: etcd-guojing-1 from kube-system started at <nil> (0 container statuses recorded)
Dec 27 02:34:49.734: INFO: kube-scheduler-guojing-1 from kube-system started at <nil> (0 container statuses recorded)
Dec 27 02:34:49.734: INFO: kube-apiserver-guojing-1 from kube-system started at <nil> (0 container statuses recorded)
Dec 27 02:34:49.734: INFO: 
Logging pods the kubelet thinks is on node guojing-2 before test
Dec 27 02:34:49.740: INFO: kube-controller-manager-guojing-2 from kube-system started at <nil> (0 container statuses recorded)
Dec 27 02:34:49.740: INFO: kube-flannel-2cgd9 from kube-system started at 2018-12-27 01:22:14 +0000 UTC (2 container statuses recorded)
Dec 27 02:34:49.740: INFO: 	Container install-cni ready: true, restart count 0
Dec 27 02:34:49.740: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 27 02:34:49.740: INFO: coredns-585c7897d4-74jzl from kube-system started at 2018-12-27 01:21:41 +0000 UTC (1 container statuses recorded)
Dec 27 02:34:49.740: INFO: 	Container coredns ready: true, restart count 0
Dec 27 02:34:49.740: INFO: kube-proxy-sfcms from kube-system started at 2018-12-27 01:21:41 +0000 UTC (1 container statuses recorded)
Dec 27 02:34:49.740: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 27 02:34:49.740: INFO: kube-scheduler-guojing-2 from kube-system started at <nil> (0 container statuses recorded)
Dec 27 02:34:49.740: INFO: kube-apiserver-guojing-2 from kube-system started at <nil> (0 container statuses recorded)
Dec 27 02:34:49.740: INFO: sonobuoy-e2e-job-9a6d2b4903a24fc2 from heptio-sonobuoy started at 2018-12-27 01:26:08 +0000 UTC (2 container statuses recorded)
Dec 27 02:34:49.740: INFO: 	Container e2e ready: true, restart count 0
Dec 27 02:34:49.740: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 27 02:34:49.740: INFO: etcd-guojing-2 from kube-system started at <nil> (0 container statuses recorded)
Dec 27 02:34:49.740: INFO: coredns-585c7897d4-xl2hs from kube-system started at 2018-12-27 01:21:41 +0000 UTC (1 container statuses recorded)
Dec 27 02:34:49.740: INFO: 	Container coredns ready: true, restart count 0
Dec 27 02:34:49.740: INFO: 
Logging pods the kubelet thinks is on node guojing-3 before test
Dec 27 02:34:49.746: INFO: kube-scheduler-guojing-3 from kube-system started at <nil> (0 container statuses recorded)
Dec 27 02:34:49.746: INFO: kube-proxy-bppf2 from kube-system started at 2018-12-27 01:21:44 +0000 UTC (1 container statuses recorded)
Dec 27 02:34:49.746: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 27 02:34:49.746: INFO: etcd-guojing-3 from kube-system started at <nil> (0 container statuses recorded)
Dec 27 02:34:49.746: INFO: kube-flannel-hjf2c from kube-system started at 2018-12-27 01:22:14 +0000 UTC (2 container statuses recorded)
Dec 27 02:34:49.746: INFO: 	Container install-cni ready: true, restart count 0
Dec 27 02:34:49.746: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 27 02:34:49.746: INFO: kube-apiserver-guojing-3 from kube-system started at <nil> (0 container statuses recorded)
Dec 27 02:34:49.746: INFO: kube-controller-manager-guojing-3 from kube-system started at <nil> (0 container statuses recorded)
Dec 27 02:34:49.746: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-27 01:26:05 +0000 UTC (3 container statuses recorded)
Dec 27 02:34:49.746: INFO: 	Container cleanup ready: true, restart count 0
Dec 27 02:34:49.746: INFO: 	Container forwarder ready: true, restart count 0
Dec 27 02:34:49.746: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-fcc42425-097f-11e9-a1bd-0a580a2100c6 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-fcc42425-097f-11e9-a1bd-0a580a2100c6 off the node guojing-1
STEP: verifying the node doesn't have the label kubernetes.io/e2e-fcc42425-097f-11e9-a1bd-0a580a2100c6
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:34:53.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-g9rxf" for this suite.
Dec 27 02:35:01.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:35:01.830: INFO: namespace: e2e-tests-sched-pred-g9rxf, resource: bindings, ignored listing per whitelist
Dec 27 02:35:01.879: INFO: namespace e2e-tests-sched-pred-g9rxf deletion completed in 8.070891217s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:12.207 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:35:01.879: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
Dec 27 02:35:11.039: INFO: error from create uninitialized namespace: Internal error occurred: object deleted while waiting for creation
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:35:28.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-rfqpn" for this suite.
Dec 27 02:35:34.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:35:34.071: INFO: namespace: e2e-tests-namespaces-rfqpn, resource: bindings, ignored listing per whitelist
Dec 27 02:35:34.090: INFO: namespace e2e-tests-namespaces-rfqpn deletion completed in 6.072774484s
STEP: Destroying namespace "e2e-tests-nsdeletetest-ms7mm" for this suite.
Dec 27 02:35:34.092: INFO: Namespace e2e-tests-nsdeletetest-ms7mm was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-pds47" for this suite.
Dec 27 02:35:40.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:35:40.114: INFO: namespace: e2e-tests-nsdeletetest-pds47, resource: bindings, ignored listing per whitelist
Dec 27 02:35:40.160: INFO: namespace e2e-tests-nsdeletetest-pds47 deletion completed in 6.067709463s

• [SLOW TEST:38.281 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:35:40.160: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-dwsc
STEP: Creating a pod to test atomic-volume-subpath
Dec 27 02:35:40.226: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-dwsc" in namespace "e2e-tests-subpath-r7jpc" to be "success or failure"
Dec 27 02:35:40.228: INFO: Pod "pod-subpath-test-configmap-dwsc": Phase="Pending", Reason="", readiness=false. Elapsed: 1.806966ms
Dec 27 02:35:42.231: INFO: Pod "pod-subpath-test-configmap-dwsc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004657348s
Dec 27 02:35:44.233: INFO: Pod "pod-subpath-test-configmap-dwsc": Phase="Running", Reason="", readiness=false. Elapsed: 4.007444018s
Dec 27 02:35:46.236: INFO: Pod "pod-subpath-test-configmap-dwsc": Phase="Running", Reason="", readiness=false. Elapsed: 6.010538943s
Dec 27 02:35:48.246: INFO: Pod "pod-subpath-test-configmap-dwsc": Phase="Running", Reason="", readiness=false. Elapsed: 8.020194498s
Dec 27 02:35:50.249: INFO: Pod "pod-subpath-test-configmap-dwsc": Phase="Running", Reason="", readiness=false. Elapsed: 10.02320252s
Dec 27 02:35:52.252: INFO: Pod "pod-subpath-test-configmap-dwsc": Phase="Running", Reason="", readiness=false. Elapsed: 12.026245043s
Dec 27 02:35:54.255: INFO: Pod "pod-subpath-test-configmap-dwsc": Phase="Running", Reason="", readiness=false. Elapsed: 14.029418752s
Dec 27 02:35:56.258: INFO: Pod "pod-subpath-test-configmap-dwsc": Phase="Running", Reason="", readiness=false. Elapsed: 16.032367266s
Dec 27 02:35:58.261: INFO: Pod "pod-subpath-test-configmap-dwsc": Phase="Running", Reason="", readiness=false. Elapsed: 18.034986708s
Dec 27 02:36:00.263: INFO: Pod "pod-subpath-test-configmap-dwsc": Phase="Running", Reason="", readiness=false. Elapsed: 20.037524778s
Dec 27 02:36:02.266: INFO: Pod "pod-subpath-test-configmap-dwsc": Phase="Running", Reason="", readiness=false. Elapsed: 22.040289207s
Dec 27 02:36:04.269: INFO: Pod "pod-subpath-test-configmap-dwsc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.043079182s
STEP: Saw pod success
Dec 27 02:36:04.269: INFO: Pod "pod-subpath-test-configmap-dwsc" satisfied condition "success or failure"
Dec 27 02:36:04.271: INFO: Trying to get logs from node guojing-3 pod pod-subpath-test-configmap-dwsc container test-container-subpath-configmap-dwsc: <nil>
STEP: delete the pod
Dec 27 02:36:04.290: INFO: Waiting for pod pod-subpath-test-configmap-dwsc to disappear
Dec 27 02:36:04.294: INFO: Pod pod-subpath-test-configmap-dwsc no longer exists
STEP: Deleting pod pod-subpath-test-configmap-dwsc
Dec 27 02:36:04.295: INFO: Deleting pod "pod-subpath-test-configmap-dwsc" in namespace "e2e-tests-subpath-r7jpc"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:36:04.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-r7jpc" for this suite.
Dec 27 02:36:10.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:36:10.361: INFO: namespace: e2e-tests-subpath-r7jpc, resource: bindings, ignored listing per whitelist
Dec 27 02:36:10.368: INFO: namespace e2e-tests-subpath-r7jpc deletion completed in 6.068818181s

• [SLOW TEST:30.208 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:36:10.369: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-2ba48094-0980-11e9-a1bd-0a580a2100c6
STEP: Creating a pod to test consume configMaps
Dec 27 02:36:10.442: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2ba66781-0980-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-projected-ss84t" to be "success or failure"
Dec 27 02:36:10.443: INFO: Pod "pod-projected-configmaps-2ba66781-0980-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.819042ms
Dec 27 02:36:12.446: INFO: Pod "pod-projected-configmaps-2ba66781-0980-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004635627s
STEP: Saw pod success
Dec 27 02:36:12.446: INFO: Pod "pod-projected-configmaps-2ba66781-0980-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:36:12.448: INFO: Trying to get logs from node guojing-1 pod pod-projected-configmaps-2ba66781-0980-11e9-a1bd-0a580a2100c6 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 27 02:36:12.465: INFO: Waiting for pod pod-projected-configmaps-2ba66781-0980-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:36:12.467: INFO: Pod pod-projected-configmaps-2ba66781-0980-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:36:12.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ss84t" for this suite.
Dec 27 02:36:18.478: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:36:18.519: INFO: namespace: e2e-tests-projected-ss84t, resource: bindings, ignored listing per whitelist
Dec 27 02:36:18.539: INFO: namespace e2e-tests-projected-ss84t deletion completed in 6.06944234s

• [SLOW TEST:8.170 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:36:18.539: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-qgxtt
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-qgxtt
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-qgxtt
Dec 27 02:36:18.601: INFO: Found 0 stateful pods, waiting for 1
Dec 27 02:36:28.603: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Dec 27 02:36:28.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 exec --namespace=e2e-tests-statefulset-qgxtt ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 27 02:36:28.774: INFO: stderr: ""
Dec 27 02:36:28.774: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 27 02:36:28.774: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 27 02:36:28.776: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec 27 02:36:38.780: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 27 02:36:38.780: INFO: Waiting for statefulset status.replicas updated to 0
Dec 27 02:36:38.790: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Dec 27 02:36:38.790: INFO: ss-0  guojing-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:18 +0000 UTC  }]
Dec 27 02:36:38.790: INFO: 
Dec 27 02:36:38.790: INFO: StatefulSet ss has not reached scale 3, at 1
Dec 27 02:36:39.793: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997513529s
Dec 27 02:36:40.796: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.994650952s
Dec 27 02:36:41.800: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.991550453s
Dec 27 02:36:42.803: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.988021375s
Dec 27 02:36:43.806: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.984962767s
Dec 27 02:36:44.809: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.981620613s
Dec 27 02:36:45.813: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.97860034s
Dec 27 02:36:46.816: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.975022044s
Dec 27 02:36:47.819: INFO: Verifying statefulset ss doesn't scale past 3 for another 972.036225ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-qgxtt
Dec 27 02:36:48.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 exec --namespace=e2e-tests-statefulset-qgxtt ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 27 02:36:48.976: INFO: stderr: ""
Dec 27 02:36:48.976: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 27 02:36:48.976: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 27 02:36:48.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 exec --namespace=e2e-tests-statefulset-qgxtt ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 27 02:36:49.112: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Dec 27 02:36:49.112: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 27 02:36:49.112: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 27 02:36:49.112: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 exec --namespace=e2e-tests-statefulset-qgxtt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 27 02:36:49.252: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Dec 27 02:36:49.252: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 27 02:36:49.252: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 27 02:36:49.255: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Dec 27 02:36:59.258: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 27 02:36:59.258: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 27 02:36:59.258: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Dec 27 02:36:59.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 exec --namespace=e2e-tests-statefulset-qgxtt ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 27 02:36:59.417: INFO: stderr: ""
Dec 27 02:36:59.417: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 27 02:36:59.417: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 27 02:36:59.417: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 exec --namespace=e2e-tests-statefulset-qgxtt ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 27 02:36:59.557: INFO: stderr: ""
Dec 27 02:36:59.557: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 27 02:36:59.557: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 27 02:36:59.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 exec --namespace=e2e-tests-statefulset-qgxtt ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 27 02:36:59.713: INFO: stderr: ""
Dec 27 02:36:59.713: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 27 02:36:59.713: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 27 02:36:59.713: INFO: Waiting for statefulset status.replicas updated to 0
Dec 27 02:36:59.721: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Dec 27 02:37:09.726: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 27 02:37:09.726: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec 27 02:37:09.726: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec 27 02:37:09.737: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Dec 27 02:37:09.737: INFO: ss-0  guojing-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:18 +0000 UTC  }]
Dec 27 02:37:09.737: INFO: ss-1  guojing-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:38 +0000 UTC  }]
Dec 27 02:37:09.737: INFO: ss-2  guojing-3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:38 +0000 UTC  }]
Dec 27 02:37:09.737: INFO: 
Dec 27 02:37:09.737: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 27 02:37:10.740: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Dec 27 02:37:10.741: INFO: ss-0  guojing-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:18 +0000 UTC  }]
Dec 27 02:37:10.741: INFO: ss-1  guojing-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:38 +0000 UTC  }]
Dec 27 02:37:10.741: INFO: ss-2  guojing-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:38 +0000 UTC  }]
Dec 27 02:37:10.741: INFO: 
Dec 27 02:37:10.741: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 27 02:37:11.744: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Dec 27 02:37:11.744: INFO: ss-0  guojing-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:18 +0000 UTC  }]
Dec 27 02:37:11.744: INFO: ss-1  guojing-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:38 +0000 UTC  }]
Dec 27 02:37:11.744: INFO: ss-2  guojing-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:38 +0000 UTC  }]
Dec 27 02:37:11.744: INFO: 
Dec 27 02:37:11.744: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 27 02:37:12.747: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Dec 27 02:37:12.747: INFO: ss-0  guojing-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:18 +0000 UTC  }]
Dec 27 02:37:12.747: INFO: ss-1  guojing-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:38 +0000 UTC  }]
Dec 27 02:37:12.747: INFO: ss-2  guojing-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:38 +0000 UTC  }]
Dec 27 02:37:12.747: INFO: 
Dec 27 02:37:12.747: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 27 02:37:13.750: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Dec 27 02:37:13.750: INFO: ss-0  guojing-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:18 +0000 UTC  }]
Dec 27 02:37:13.750: INFO: ss-1  guojing-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:38 +0000 UTC  }]
Dec 27 02:37:13.750: INFO: ss-2  guojing-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:38 +0000 UTC  }]
Dec 27 02:37:13.750: INFO: 
Dec 27 02:37:13.750: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 27 02:37:14.753: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Dec 27 02:37:14.753: INFO: ss-0  guojing-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:18 +0000 UTC  }]
Dec 27 02:37:14.753: INFO: 
Dec 27 02:37:14.753: INFO: StatefulSet ss has not reached scale 0, at 1
Dec 27 02:37:15.756: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Dec 27 02:37:15.756: INFO: ss-0  guojing-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:18 +0000 UTC  }]
Dec 27 02:37:15.756: INFO: 
Dec 27 02:37:15.756: INFO: StatefulSet ss has not reached scale 0, at 1
Dec 27 02:37:16.760: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Dec 27 02:37:16.760: INFO: ss-0  guojing-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:18 +0000 UTC  }]
Dec 27 02:37:16.760: INFO: 
Dec 27 02:37:16.760: INFO: StatefulSet ss has not reached scale 0, at 1
Dec 27 02:37:17.763: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Dec 27 02:37:17.763: INFO: ss-0  guojing-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:36:18 +0000 UTC  }]
Dec 27 02:37:17.763: INFO: 
Dec 27 02:37:17.763: INFO: StatefulSet ss has not reached scale 0, at 1
Dec 27 02:37:18.766: INFO: Verifying statefulset ss doesn't scale past 0 for another 971.31756ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-qgxtt
Dec 27 02:37:19.769: INFO: Scaling statefulset ss to 0
Dec 27 02:37:19.775: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec 27 02:37:19.777: INFO: Deleting all statefulset in ns e2e-tests-statefulset-qgxtt
Dec 27 02:37:19.778: INFO: Scaling statefulset ss to 0
Dec 27 02:37:19.784: INFO: Waiting for statefulset status.replicas updated to 0
Dec 27 02:37:19.786: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:37:19.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-qgxtt" for this suite.
Dec 27 02:37:25.813: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:37:25.848: INFO: namespace: e2e-tests-statefulset-qgxtt, resource: bindings, ignored listing per whitelist
Dec 27 02:37:25.872: INFO: namespace e2e-tests-statefulset-qgxtt deletion completed in 6.068930785s

• [SLOW TEST:67.333 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:37:25.872: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-58a58fce-0980-11e9-a1bd-0a580a2100c6
STEP: Creating a pod to test consume configMaps
Dec 27 02:37:25.932: INFO: Waiting up to 5m0s for pod "pod-configmaps-58a6573f-0980-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-configmap-8vwgd" to be "success or failure"
Dec 27 02:37:25.934: INFO: Pod "pod-configmaps-58a6573f-0980-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.9685ms
Dec 27 02:37:27.936: INFO: Pod "pod-configmaps-58a6573f-0980-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004840257s
STEP: Saw pod success
Dec 27 02:37:27.936: INFO: Pod "pod-configmaps-58a6573f-0980-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:37:27.938: INFO: Trying to get logs from node guojing-2 pod pod-configmaps-58a6573f-0980-11e9-a1bd-0a580a2100c6 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 27 02:37:27.956: INFO: Waiting for pod pod-configmaps-58a6573f-0980-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:37:27.958: INFO: Pod pod-configmaps-58a6573f-0980-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:37:27.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-8vwgd" for this suite.
Dec 27 02:37:33.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:37:34.020: INFO: namespace: e2e-tests-configmap-8vwgd, resource: bindings, ignored listing per whitelist
Dec 27 02:37:34.031: INFO: namespace e2e-tests-configmap-8vwgd deletion completed in 6.069479647s

• [SLOW TEST:8.158 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:37:34.031: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec 27 02:37:34.089: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:37:37.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-h67gm" for this suite.
Dec 27 02:37:43.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:37:43.373: INFO: namespace: e2e-tests-init-container-h67gm, resource: bindings, ignored listing per whitelist
Dec 27 02:37:43.401: INFO: namespace e2e-tests-init-container-h67gm deletion completed in 6.067854998s

• [SLOW TEST:9.370 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:37:43.401: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 27 02:37:43.448: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:37:45.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-zxffp" for this suite.
Dec 27 02:38:23.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:38:23.589: INFO: namespace: e2e-tests-pods-zxffp, resource: bindings, ignored listing per whitelist
Dec 27 02:38:23.612: INFO: namespace e2e-tests-pods-zxffp deletion completed in 38.065793763s

• [SLOW TEST:40.210 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:38:23.612: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-nhr88
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Dec 27 02:38:23.673: INFO: Found 0 stateful pods, waiting for 3
Dec 27 02:38:33.676: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 27 02:38:33.676: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 27 02:38:33.676: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Dec 27 02:38:33.701: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Dec 27 02:38:43.727: INFO: Updating stateful set ss2
Dec 27 02:38:43.731: INFO: Waiting for Pod e2e-tests-statefulset-nhr88/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec 27 02:38:53.736: INFO: Waiting for Pod e2e-tests-statefulset-nhr88/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Dec 27 02:39:03.791: INFO: Found 2 stateful pods, waiting for 3
Dec 27 02:39:13.795: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 27 02:39:13.795: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 27 02:39:13.795: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Dec 27 02:39:13.816: INFO: Updating stateful set ss2
Dec 27 02:39:13.830: INFO: Waiting for Pod e2e-tests-statefulset-nhr88/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec 27 02:39:23.835: INFO: Waiting for Pod e2e-tests-statefulset-nhr88/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec 27 02:39:33.854: INFO: Updating stateful set ss2
Dec 27 02:39:33.860: INFO: Waiting for StatefulSet e2e-tests-statefulset-nhr88/ss2 to complete update
Dec 27 02:39:33.860: INFO: Waiting for Pod e2e-tests-statefulset-nhr88/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec 27 02:39:43.865: INFO: Deleting all statefulset in ns e2e-tests-statefulset-nhr88
Dec 27 02:39:43.867: INFO: Scaling statefulset ss2 to 0
Dec 27 02:40:03.880: INFO: Waiting for statefulset status.replicas updated to 0
Dec 27 02:40:03.882: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:40:03.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-nhr88" for this suite.
Dec 27 02:40:09.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:40:09.968: INFO: namespace: e2e-tests-statefulset-nhr88, resource: bindings, ignored listing per whitelist
Dec 27 02:40:09.975: INFO: namespace e2e-tests-statefulset-nhr88 deletion completed in 6.074501811s

• [SLOW TEST:106.363 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:40:09.975: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec 27 02:40:12.561: INFO: Successfully updated pod "annotationupdateba7595d1-0980-11e9-a1bd-0a580a2100c6"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:40:16.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-djv5d" for this suite.
Dec 27 02:40:38.592: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:40:38.603: INFO: namespace: e2e-tests-projected-djv5d, resource: bindings, ignored listing per whitelist
Dec 27 02:40:38.650: INFO: namespace e2e-tests-projected-djv5d deletion completed in 22.066878913s

• [SLOW TEST:28.674 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:40:38.650: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec 27 02:40:38.711: INFO: Waiting up to 5m0s for pod "downward-api-cb8dde78-0980-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-downward-api-czpnf" to be "success or failure"
Dec 27 02:40:38.713: INFO: Pod "downward-api-cb8dde78-0980-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.934682ms
Dec 27 02:40:40.716: INFO: Pod "downward-api-cb8dde78-0980-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004962392s
STEP: Saw pod success
Dec 27 02:40:40.716: INFO: Pod "downward-api-cb8dde78-0980-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:40:40.718: INFO: Trying to get logs from node guojing-2 pod downward-api-cb8dde78-0980-11e9-a1bd-0a580a2100c6 container dapi-container: <nil>
STEP: delete the pod
Dec 27 02:40:40.737: INFO: Waiting for pod downward-api-cb8dde78-0980-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:40:40.739: INFO: Pod downward-api-cb8dde78-0980-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:40:40.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-czpnf" for this suite.
Dec 27 02:40:46.751: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:40:46.789: INFO: namespace: e2e-tests-downward-api-czpnf, resource: bindings, ignored listing per whitelist
Dec 27 02:40:46.811: INFO: namespace e2e-tests-downward-api-czpnf deletion completed in 6.06901146s

• [SLOW TEST:8.162 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:40:46.812: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-9rml
STEP: Creating a pod to test atomic-volume-subpath
Dec 27 02:40:46.889: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-9rml" in namespace "e2e-tests-subpath-ll4ww" to be "success or failure"
Dec 27 02:40:46.891: INFO: Pod "pod-subpath-test-secret-9rml": Phase="Pending", Reason="", readiness=false. Elapsed: 2.060921ms
Dec 27 02:40:48.894: INFO: Pod "pod-subpath-test-secret-9rml": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004914055s
Dec 27 02:40:50.896: INFO: Pod "pod-subpath-test-secret-9rml": Phase="Running", Reason="", readiness=false. Elapsed: 4.007770073s
Dec 27 02:40:52.899: INFO: Pod "pod-subpath-test-secret-9rml": Phase="Running", Reason="", readiness=false. Elapsed: 6.010354373s
Dec 27 02:40:54.905: INFO: Pod "pod-subpath-test-secret-9rml": Phase="Running", Reason="", readiness=false. Elapsed: 8.016570047s
Dec 27 02:40:56.908: INFO: Pod "pod-subpath-test-secret-9rml": Phase="Running", Reason="", readiness=false. Elapsed: 10.019306591s
Dec 27 02:40:58.911: INFO: Pod "pod-subpath-test-secret-9rml": Phase="Running", Reason="", readiness=false. Elapsed: 12.022192706s
Dec 27 02:41:00.913: INFO: Pod "pod-subpath-test-secret-9rml": Phase="Running", Reason="", readiness=false. Elapsed: 14.024694555s
Dec 27 02:41:02.916: INFO: Pod "pod-subpath-test-secret-9rml": Phase="Running", Reason="", readiness=false. Elapsed: 16.027450076s
Dec 27 02:41:04.922: INFO: Pod "pod-subpath-test-secret-9rml": Phase="Running", Reason="", readiness=false. Elapsed: 18.03359913s
Dec 27 02:41:06.926: INFO: Pod "pod-subpath-test-secret-9rml": Phase="Running", Reason="", readiness=false. Elapsed: 20.037237847s
Dec 27 02:41:08.929: INFO: Pod "pod-subpath-test-secret-9rml": Phase="Running", Reason="", readiness=false. Elapsed: 22.040502394s
Dec 27 02:41:10.932: INFO: Pod "pod-subpath-test-secret-9rml": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.043431581s
STEP: Saw pod success
Dec 27 02:41:10.932: INFO: Pod "pod-subpath-test-secret-9rml" satisfied condition "success or failure"
Dec 27 02:41:10.934: INFO: Trying to get logs from node guojing-3 pod pod-subpath-test-secret-9rml container test-container-subpath-secret-9rml: <nil>
STEP: delete the pod
Dec 27 02:41:10.958: INFO: Waiting for pod pod-subpath-test-secret-9rml to disappear
Dec 27 02:41:10.960: INFO: Pod pod-subpath-test-secret-9rml no longer exists
STEP: Deleting pod pod-subpath-test-secret-9rml
Dec 27 02:41:10.960: INFO: Deleting pod "pod-subpath-test-secret-9rml" in namespace "e2e-tests-subpath-ll4ww"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:41:10.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-ll4ww" for this suite.
Dec 27 02:41:16.973: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:41:17.027: INFO: namespace: e2e-tests-subpath-ll4ww, resource: bindings, ignored listing per whitelist
Dec 27 02:41:17.032: INFO: namespace e2e-tests-subpath-ll4ww deletion completed in 6.068236878s

• [SLOW TEST:30.221 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:41:17.033: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec 27 02:41:19.611: INFO: Successfully updated pod "labelsupdatee26dddb3-0980-11e9-a1bd-0a580a2100c6"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:41:23.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4tlz4" for this suite.
Dec 27 02:41:45.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:41:45.654: INFO: namespace: e2e-tests-projected-4tlz4, resource: bindings, ignored listing per whitelist
Dec 27 02:41:45.703: INFO: namespace e2e-tests-projected-4tlz4 deletion completed in 22.070014985s

• [SLOW TEST:28.671 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:41:45.703: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:41:49.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-ttbz6" for this suite.
Dec 27 02:41:55.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:41:55.830: INFO: namespace: e2e-tests-kubelet-test-ttbz6, resource: bindings, ignored listing per whitelist
Dec 27 02:41:55.839: INFO: namespace e2e-tests-kubelet-test-ttbz6 deletion completed in 6.068203332s

• [SLOW TEST:10.136 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:41:55.839: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-ww2v8
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-ww2v8 to expose endpoints map[]
Dec 27 02:41:55.922: INFO: Get endpoints failed (1.887479ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Dec 27 02:41:56.925: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-ww2v8 exposes endpoints map[] (1.004633757s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-ww2v8
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-ww2v8 to expose endpoints map[pod1:[100]]
Dec 27 02:41:57.949: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-ww2v8 exposes endpoints map[pod1:[100]] (1.017019746s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-ww2v8
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-ww2v8 to expose endpoints map[pod1:[100] pod2:[101]]
Dec 27 02:41:59.983: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-ww2v8 exposes endpoints map[pod1:[100] pod2:[101]] (2.030212837s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-ww2v8
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-ww2v8 to expose endpoints map[pod2:[101]]
Dec 27 02:42:00.999: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-ww2v8 exposes endpoints map[pod2:[101]] (1.008835762s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-ww2v8
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-ww2v8 to expose endpoints map[]
Dec 27 02:42:02.011: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-ww2v8 exposes endpoints map[] (1.004505907s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:42:02.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-ww2v8" for this suite.
Dec 27 02:42:24.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:42:24.109: INFO: namespace: e2e-tests-services-ww2v8, resource: bindings, ignored listing per whitelist
Dec 27 02:42:24.118: INFO: namespace e2e-tests-services-ww2v8 deletion completed in 22.07424521s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:28.279 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:42:24.118: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 27 02:42:24.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-jqtjq'
Dec 27 02:42:24.265: INFO: stderr: ""
Dec 27 02:42:24.265: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Dec 27 02:42:24.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-jqtjq'
Dec 27 02:42:34.069: INFO: stderr: ""
Dec 27 02:42:34.069: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:42:34.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jqtjq" for this suite.
Dec 27 02:42:40.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:42:40.130: INFO: namespace: e2e-tests-kubectl-jqtjq, resource: bindings, ignored listing per whitelist
Dec 27 02:42:40.147: INFO: namespace e2e-tests-kubectl-jqtjq deletion completed in 6.073717383s

• [SLOW TEST:16.029 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:42:40.147: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 27 02:42:40.212: INFO: Waiting up to 5m0s for pod "downwardapi-volume-13f92f16-0981-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-projected-flkhc" to be "success or failure"
Dec 27 02:42:40.214: INFO: Pod "downwardapi-volume-13f92f16-0981-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.090258ms
Dec 27 02:42:42.216: INFO: Pod "downwardapi-volume-13f92f16-0981-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004687326s
STEP: Saw pod success
Dec 27 02:42:42.217: INFO: Pod "downwardapi-volume-13f92f16-0981-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:42:42.218: INFO: Trying to get logs from node guojing-3 pod downwardapi-volume-13f92f16-0981-11e9-a1bd-0a580a2100c6 container client-container: <nil>
STEP: delete the pod
Dec 27 02:42:42.234: INFO: Waiting for pod downwardapi-volume-13f92f16-0981-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:42:42.236: INFO: Pod downwardapi-volume-13f92f16-0981-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:42:42.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-flkhc" for this suite.
Dec 27 02:42:48.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:42:48.306: INFO: namespace: e2e-tests-projected-flkhc, resource: bindings, ignored listing per whitelist
Dec 27 02:42:48.317: INFO: namespace e2e-tests-projected-flkhc deletion completed in 6.079014801s

• [SLOW TEST:8.171 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:42:48.318: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec 27 02:42:52.410: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 27 02:42:52.416: INFO: Pod pod-with-prestop-http-hook still exists
Dec 27 02:42:54.416: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 27 02:42:54.419: INFO: Pod pod-with-prestop-http-hook still exists
Dec 27 02:42:56.416: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 27 02:42:56.419: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:42:56.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-5jdpf" for this suite.
Dec 27 02:43:18.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:43:18.448: INFO: namespace: e2e-tests-container-lifecycle-hook-5jdpf, resource: bindings, ignored listing per whitelist
Dec 27 02:43:18.494: INFO: namespace e2e-tests-container-lifecycle-hook-5jdpf deletion completed in 22.06677075s

• [SLOW TEST:30.177 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:43:18.495: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Dec 27 02:43:20.555: INFO: Pod pod-hostip-2ad30dba-0981-11e9-a1bd-0a580a2100c6 has hostIP: 172.19.16.36
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:43:20.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-wplv6" for this suite.
Dec 27 02:43:42.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:43:42.604: INFO: namespace: e2e-tests-pods-wplv6, resource: bindings, ignored listing per whitelist
Dec 27 02:43:42.628: INFO: namespace e2e-tests-pods-wplv6 deletion completed in 22.069703647s

• [SLOW TEST:24.134 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:43:42.628: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-39368cda-0981-11e9-a1bd-0a580a2100c6
STEP: Creating configMap with name cm-test-opt-upd-39368d2a-0981-11e9-a1bd-0a580a2100c6
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-39368cda-0981-11e9-a1bd-0a580a2100c6
STEP: Updating configmap cm-test-opt-upd-39368d2a-0981-11e9-a1bd-0a580a2100c6
STEP: Creating configMap with name cm-test-opt-create-39368d43-0981-11e9-a1bd-0a580a2100c6
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:43:46.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-6j9dw" for this suite.
Dec 27 02:44:08.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:44:08.798: INFO: namespace: e2e-tests-configmap-6j9dw, resource: bindings, ignored listing per whitelist
Dec 27 02:44:08.833: INFO: namespace e2e-tests-configmap-6j9dw deletion completed in 22.07044889s

• [SLOW TEST:26.204 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:44:08.833: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W1227 02:44:39.415860      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 27 02:44:39.415: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:44:39.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-jhdhr" for this suite.
Dec 27 02:44:45.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:44:45.478: INFO: namespace: e2e-tests-gc-jhdhr, resource: bindings, ignored listing per whitelist
Dec 27 02:44:45.487: INFO: namespace e2e-tests-gc-jhdhr deletion completed in 6.068405271s

• [SLOW TEST:36.654 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:44:45.487: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 27 02:44:45.545: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5ead7d18-0981-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-projected-7lp7b" to be "success or failure"
Dec 27 02:44:45.547: INFO: Pod "downwardapi-volume-5ead7d18-0981-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.116256ms
Dec 27 02:44:47.550: INFO: Pod "downwardapi-volume-5ead7d18-0981-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005077265s
STEP: Saw pod success
Dec 27 02:44:47.550: INFO: Pod "downwardapi-volume-5ead7d18-0981-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:44:47.552: INFO: Trying to get logs from node guojing-1 pod downwardapi-volume-5ead7d18-0981-11e9-a1bd-0a580a2100c6 container client-container: <nil>
STEP: delete the pod
Dec 27 02:44:47.570: INFO: Waiting for pod downwardapi-volume-5ead7d18-0981-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:44:47.572: INFO: Pod downwardapi-volume-5ead7d18-0981-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:44:47.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7lp7b" for this suite.
Dec 27 02:44:53.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:44:53.628: INFO: namespace: e2e-tests-projected-7lp7b, resource: bindings, ignored listing per whitelist
Dec 27 02:44:53.642: INFO: namespace e2e-tests-projected-7lp7b deletion completed in 6.06679918s

• [SLOW TEST:8.155 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:44:53.642: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:45:02.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-5nw6z" for this suite.
Dec 27 02:45:24.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:45:24.756: INFO: namespace: e2e-tests-replication-controller-5nw6z, resource: bindings, ignored listing per whitelist
Dec 27 02:45:24.784: INFO: namespace e2e-tests-replication-controller-5nw6z deletion completed in 22.068686472s

• [SLOW TEST:31.142 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:45:24.784: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:45:24.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-r8n8x" for this suite.
Dec 27 02:45:30.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:45:30.892: INFO: namespace: e2e-tests-services-r8n8x, resource: bindings, ignored listing per whitelist
Dec 27 02:45:30.917: INFO: namespace e2e-tests-services-r8n8x deletion completed in 6.072811334s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:6.133 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:45:30.917: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-79c0bf93-0981-11e9-a1bd-0a580a2100c6
STEP: Creating a pod to test consume configMaps
Dec 27 02:45:30.982: INFO: Waiting up to 5m0s for pod "pod-configmaps-79c18014-0981-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-configmap-f4fs4" to be "success or failure"
Dec 27 02:45:30.984: INFO: Pod "pod-configmaps-79c18014-0981-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.978684ms
Dec 27 02:45:32.986: INFO: Pod "pod-configmaps-79c18014-0981-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004687862s
STEP: Saw pod success
Dec 27 02:45:32.986: INFO: Pod "pod-configmaps-79c18014-0981-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:45:32.988: INFO: Trying to get logs from node guojing-3 pod pod-configmaps-79c18014-0981-11e9-a1bd-0a580a2100c6 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 27 02:45:33.004: INFO: Waiting for pod pod-configmaps-79c18014-0981-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:45:33.005: INFO: Pod pod-configmaps-79c18014-0981-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:45:33.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-f4fs4" for this suite.
Dec 27 02:45:39.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:45:39.144: INFO: namespace: e2e-tests-configmap-f4fs4, resource: bindings, ignored listing per whitelist
Dec 27 02:45:39.184: INFO: namespace e2e-tests-configmap-f4fs4 deletion completed in 6.175481906s

• [SLOW TEST:8.267 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:45:39.184: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-2g68b
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Dec 27 02:45:39.243: INFO: Found 0 stateful pods, waiting for 3
Dec 27 02:45:49.246: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 27 02:45:49.246: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 27 02:45:49.246: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Dec 27 02:45:49.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 exec --namespace=e2e-tests-statefulset-2g68b ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 27 02:45:49.419: INFO: stderr: ""
Dec 27 02:45:49.419: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 27 02:45:49.419: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Dec 27 02:45:59.446: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Dec 27 02:46:09.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 exec --namespace=e2e-tests-statefulset-2g68b ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 27 02:46:09.617: INFO: stderr: ""
Dec 27 02:46:09.617: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 27 02:46:09.617: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

STEP: Rolling back to a previous revision
Dec 27 02:46:39.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 exec --namespace=e2e-tests-statefulset-2g68b ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 27 02:46:39.795: INFO: stderr: ""
Dec 27 02:46:39.795: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 27 02:46:39.795: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 27 02:46:49.822: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Dec 27 02:46:59.843: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 exec --namespace=e2e-tests-statefulset-2g68b ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 27 02:46:59.997: INFO: stderr: ""
Dec 27 02:46:59.997: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 27 02:46:59.997: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 27 02:47:20.012: INFO: Waiting for StatefulSet e2e-tests-statefulset-2g68b/ss2 to complete update
Dec 27 02:47:20.012: INFO: Waiting for Pod e2e-tests-statefulset-2g68b/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec 27 02:47:30.017: INFO: Deleting all statefulset in ns e2e-tests-statefulset-2g68b
Dec 27 02:47:30.019: INFO: Scaling statefulset ss2 to 0
Dec 27 02:47:40.031: INFO: Waiting for statefulset status.replicas updated to 0
Dec 27 02:47:40.033: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:47:40.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-2g68b" for this suite.
Dec 27 02:47:46.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:47:46.093: INFO: namespace: e2e-tests-statefulset-2g68b, resource: bindings, ignored listing per whitelist
Dec 27 02:47:46.122: INFO: namespace e2e-tests-statefulset-2g68b deletion completed in 6.075965192s

• [SLOW TEST:126.938 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:47:46.122: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-ca57e2f0-0981-11e9-a1bd-0a580a2100c6
STEP: Creating a pod to test consume configMaps
Dec 27 02:47:46.183: INFO: Waiting up to 5m0s for pod "pod-configmaps-ca5911f1-0981-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-configmap-mpjbb" to be "success or failure"
Dec 27 02:47:46.185: INFO: Pod "pod-configmaps-ca5911f1-0981-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.843762ms
Dec 27 02:47:48.188: INFO: Pod "pod-configmaps-ca5911f1-0981-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004604922s
STEP: Saw pod success
Dec 27 02:47:48.188: INFO: Pod "pod-configmaps-ca5911f1-0981-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:47:48.189: INFO: Trying to get logs from node guojing-1 pod pod-configmaps-ca5911f1-0981-11e9-a1bd-0a580a2100c6 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 27 02:47:48.208: INFO: Waiting for pod pod-configmaps-ca5911f1-0981-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:47:48.210: INFO: Pod pod-configmaps-ca5911f1-0981-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:47:48.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-mpjbb" for this suite.
Dec 27 02:47:54.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:47:54.241: INFO: namespace: e2e-tests-configmap-mpjbb, resource: bindings, ignored listing per whitelist
Dec 27 02:47:54.283: INFO: namespace e2e-tests-configmap-mpjbb deletion completed in 6.069902012s

• [SLOW TEST:8.160 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:47:54.283: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 27 02:47:54.339: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cf352017-0981-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-projected-mmsg4" to be "success or failure"
Dec 27 02:47:54.341: INFO: Pod "downwardapi-volume-cf352017-0981-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.929515ms
Dec 27 02:47:56.352: INFO: Pod "downwardapi-volume-cf352017-0981-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013053676s
STEP: Saw pod success
Dec 27 02:47:56.352: INFO: Pod "downwardapi-volume-cf352017-0981-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:47:56.354: INFO: Trying to get logs from node guojing-2 pod downwardapi-volume-cf352017-0981-11e9-a1bd-0a580a2100c6 container client-container: <nil>
STEP: delete the pod
Dec 27 02:47:56.372: INFO: Waiting for pod downwardapi-volume-cf352017-0981-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:47:56.374: INFO: Pod downwardapi-volume-cf352017-0981-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:47:56.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mmsg4" for this suite.
Dec 27 02:48:02.385: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:48:02.443: INFO: namespace: e2e-tests-projected-mmsg4, resource: bindings, ignored listing per whitelist
Dec 27 02:48:02.447: INFO: namespace e2e-tests-projected-mmsg4 deletion completed in 6.069580194s

• [SLOW TEST:8.164 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:48:02.447: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-d413c716-0981-11e9-a1bd-0a580a2100c6
STEP: Creating a pod to test consume secrets
Dec 27 02:48:02.513: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d41491a5-0981-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-projected-kqpvq" to be "success or failure"
Dec 27 02:48:02.514: INFO: Pod "pod-projected-secrets-d41491a5-0981-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.865319ms
Dec 27 02:48:04.518: INFO: Pod "pod-projected-secrets-d41491a5-0981-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00496136s
STEP: Saw pod success
Dec 27 02:48:04.518: INFO: Pod "pod-projected-secrets-d41491a5-0981-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:48:04.520: INFO: Trying to get logs from node guojing-3 pod pod-projected-secrets-d41491a5-0981-11e9-a1bd-0a580a2100c6 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 27 02:48:04.541: INFO: Waiting for pod pod-projected-secrets-d41491a5-0981-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:48:04.543: INFO: Pod pod-projected-secrets-d41491a5-0981-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:48:04.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kqpvq" for this suite.
Dec 27 02:48:10.554: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:48:10.608: INFO: namespace: e2e-tests-projected-kqpvq, resource: bindings, ignored listing per whitelist
Dec 27 02:48:10.615: INFO: namespace e2e-tests-projected-kqpvq deletion completed in 6.069141854s

• [SLOW TEST:8.168 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:48:10.615: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-7zjqf/configmap-test-d8f0c220-0981-11e9-a1bd-0a580a2100c6
STEP: Creating a pod to test consume configMaps
Dec 27 02:48:10.672: INFO: Waiting up to 5m0s for pod "pod-configmaps-d8f185cf-0981-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-configmap-7zjqf" to be "success or failure"
Dec 27 02:48:10.673: INFO: Pod "pod-configmaps-d8f185cf-0981-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.749352ms
Dec 27 02:48:12.676: INFO: Pod "pod-configmaps-d8f185cf-0981-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004530852s
STEP: Saw pod success
Dec 27 02:48:12.676: INFO: Pod "pod-configmaps-d8f185cf-0981-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:48:12.678: INFO: Trying to get logs from node guojing-2 pod pod-configmaps-d8f185cf-0981-11e9-a1bd-0a580a2100c6 container env-test: <nil>
STEP: delete the pod
Dec 27 02:48:12.697: INFO: Waiting for pod pod-configmaps-d8f185cf-0981-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:48:12.699: INFO: Pod pod-configmaps-d8f185cf-0981-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:48:12.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-7zjqf" for this suite.
Dec 27 02:48:18.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:48:18.735: INFO: namespace: e2e-tests-configmap-7zjqf, resource: bindings, ignored listing per whitelist
Dec 27 02:48:18.780: INFO: namespace e2e-tests-configmap-7zjqf deletion completed in 6.077722282s

• [SLOW TEST:8.165 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:48:18.780: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Dec 27 02:48:18.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 create -f - --namespace=e2e-tests-kubectl-kbfdk'
Dec 27 02:48:19.249: INFO: stderr: ""
Dec 27 02:48:19.249: INFO: stdout: "pod/pause created\n"
Dec 27 02:48:19.249: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Dec 27 02:48:19.249: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-kbfdk" to be "running and ready"
Dec 27 02:48:19.252: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 3.065949ms
Dec 27 02:48:21.254: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.005780886s
Dec 27 02:48:21.254: INFO: Pod "pause" satisfied condition "running and ready"
Dec 27 02:48:21.255: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Dec 27 02:48:21.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-kbfdk'
Dec 27 02:48:21.333: INFO: stderr: ""
Dec 27 02:48:21.333: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Dec 27 02:48:21.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pod pause -L testing-label --namespace=e2e-tests-kubectl-kbfdk'
Dec 27 02:48:21.407: INFO: stderr: ""
Dec 27 02:48:21.407: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Dec 27 02:48:21.407: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 label pods pause testing-label- --namespace=e2e-tests-kubectl-kbfdk'
Dec 27 02:48:21.481: INFO: stderr: ""
Dec 27 02:48:21.481: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Dec 27 02:48:21.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pod pause -L testing-label --namespace=e2e-tests-kubectl-kbfdk'
Dec 27 02:48:21.540: INFO: stderr: ""
Dec 27 02:48:21.540: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Dec 27 02:48:21.540: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-kbfdk'
Dec 27 02:48:21.624: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 27 02:48:21.624: INFO: stdout: "pod \"pause\" force deleted\n"
Dec 27 02:48:21.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-kbfdk'
Dec 27 02:48:21.696: INFO: stderr: "No resources found.\n"
Dec 27 02:48:21.696: INFO: stdout: ""
Dec 27 02:48:21.696: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods -l name=pause --namespace=e2e-tests-kubectl-kbfdk -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 27 02:48:21.766: INFO: stderr: ""
Dec 27 02:48:21.766: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:48:21.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kbfdk" for this suite.
Dec 27 02:48:27.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:48:27.829: INFO: namespace: e2e-tests-kubectl-kbfdk, resource: bindings, ignored listing per whitelist
Dec 27 02:48:27.838: INFO: namespace e2e-tests-kubectl-kbfdk deletion completed in 6.067998365s

• [SLOW TEST:9.058 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:48:27.838: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Dec 27 02:48:29.911: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-e335fab6-0981-11e9-a1bd-0a580a2100c6", GenerateName:"", Namespace:"e2e-tests-pods-6t86s", SelfLink:"/api/v1/namespaces/e2e-tests-pods-6t86s/pods/pod-submit-remove-e335fab6-0981-11e9-a1bd-0a580a2100c6", UID:"e336afa7-0981-11e9-9853-debd8636412e", ResourceVersion:"19496", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63681475707, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"890763401"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-bhvws", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0024b2000), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-bhvws", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0020fb898), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"guojing-3", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001800840), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0020fb8e0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0020fb900)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0020fb908), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0020fb90c)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681475707, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681475709, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681475709, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681475707, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.19.16.36", PodIP:"10.33.1.135", StartTime:(*v1.Time)(0xc002356080), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc0023560a0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96", ContainerID:"docker://53e97324c98c5aed8a03f237d692a792c5de3b3c6deb00010961f22472ded351"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:48:44.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-6t86s" for this suite.
Dec 27 02:48:50.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:48:50.064: INFO: namespace: e2e-tests-pods-6t86s, resource: bindings, ignored listing per whitelist
Dec 27 02:48:50.111: INFO: namespace e2e-tests-pods-6t86s deletion completed in 6.072999339s

• [SLOW TEST:22.273 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:48:50.111: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 27 02:48:50.166: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Dec 27 02:48:55.169: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 27 02:48:55.169: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec 27 02:48:55.189: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-slpg6,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-slpg6/deployments/test-cleanup-deployment,UID:f378def4-0981-11e9-9853-debd8636412e,ResourceVersion:19570,Generation:1,CreationTimestamp:2018-12-27 02:48:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Dec 27 02:48:55.191: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Dec 27 02:48:55.191: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Dec 27 02:48:55.191: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-slpg6,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-slpg6/replicasets/test-cleanup-controller,UID:f07c06bb-0981-11e9-9853-debd8636412e,ResourceVersion:19571,Generation:1,CreationTimestamp:2018-12-27 02:48:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment f378def4-0981-11e9-9853-debd8636412e 0xc001c6db97 0xc001c6db98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec 27 02:48:55.194: INFO: Pod "test-cleanup-controller-9bbh6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-9bbh6,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-slpg6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-slpg6/pods/test-cleanup-controller-9bbh6,UID:f07d7b56-0981-11e9-b34c-525400cd4ed0,ResourceVersion:19564,Generation:0,CreationTimestamp:2018-12-27 02:48:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller f07c06bb-0981-11e9-9853-debd8636412e 0xc002196247 0xc002196248}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-md2vz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-md2vz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-md2vz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:guojing-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021962c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021964b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:48:50 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:48:51 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:48:51 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:48:50 +0000 UTC  }],Message:,Reason:,HostIP:172.19.16.27,PodIP:10.33.0.74,StartTime:2018-12-27 02:48:50 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-27 02:48:50 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://c504783dc3083470ef61f3d4d85c7ef8cd8276f1e27b401c5ab589a93f919ca2}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:48:55.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-slpg6" for this suite.
Dec 27 02:49:01.216: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:49:01.258: INFO: namespace: e2e-tests-deployment-slpg6, resource: bindings, ignored listing per whitelist
Dec 27 02:49:01.276: INFO: namespace e2e-tests-deployment-slpg6 deletion completed in 6.076619219s

• [SLOW TEST:11.165 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:49:01.276: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-f724ad4f-0981-11e9-a1bd-0a580a2100c6
STEP: Creating configMap with name cm-test-opt-upd-f724ada4-0981-11e9-a1bd-0a580a2100c6
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-f724ad4f-0981-11e9-a1bd-0a580a2100c6
STEP: Updating configmap cm-test-opt-upd-f724ada4-0981-11e9-a1bd-0a580a2100c6
STEP: Creating configMap with name cm-test-opt-create-f724adc3-0981-11e9-a1bd-0a580a2100c6
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:49:05.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6rlqm" for this suite.
Dec 27 02:49:27.424: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:49:27.464: INFO: namespace: e2e-tests-projected-6rlqm, resource: bindings, ignored listing per whitelist
Dec 27 02:49:27.482: INFO: namespace e2e-tests-projected-6rlqm deletion completed in 22.066802742s

• [SLOW TEST:26.206 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:49:27.482: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Dec 27 02:49:27.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 create -f - --namespace=e2e-tests-kubectl-4bg2v'
Dec 27 02:49:27.711: INFO: stderr: ""
Dec 27 02:49:27.711: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 27 02:49:27.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-4bg2v'
Dec 27 02:49:27.789: INFO: stderr: ""
Dec 27 02:49:27.789: INFO: stdout: "update-demo-nautilus-7zzzp update-demo-nautilus-zmwvv "
Dec 27 02:49:27.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods update-demo-nautilus-7zzzp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4bg2v'
Dec 27 02:49:27.860: INFO: stderr: ""
Dec 27 02:49:27.860: INFO: stdout: ""
Dec 27 02:49:27.860: INFO: update-demo-nautilus-7zzzp is created but not running
Dec 27 02:49:32.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-4bg2v'
Dec 27 02:49:32.930: INFO: stderr: ""
Dec 27 02:49:32.930: INFO: stdout: "update-demo-nautilus-7zzzp update-demo-nautilus-zmwvv "
Dec 27 02:49:32.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods update-demo-nautilus-7zzzp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4bg2v'
Dec 27 02:49:32.991: INFO: stderr: ""
Dec 27 02:49:32.991: INFO: stdout: "true"
Dec 27 02:49:32.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods update-demo-nautilus-7zzzp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4bg2v'
Dec 27 02:49:33.056: INFO: stderr: ""
Dec 27 02:49:33.056: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 27 02:49:33.056: INFO: validating pod update-demo-nautilus-7zzzp
Dec 27 02:49:33.060: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 27 02:49:33.060: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 27 02:49:33.060: INFO: update-demo-nautilus-7zzzp is verified up and running
Dec 27 02:49:33.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods update-demo-nautilus-zmwvv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4bg2v'
Dec 27 02:49:33.123: INFO: stderr: ""
Dec 27 02:49:33.123: INFO: stdout: "true"
Dec 27 02:49:33.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods update-demo-nautilus-zmwvv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4bg2v'
Dec 27 02:49:33.188: INFO: stderr: ""
Dec 27 02:49:33.188: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 27 02:49:33.188: INFO: validating pod update-demo-nautilus-zmwvv
Dec 27 02:49:33.192: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 27 02:49:33.192: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 27 02:49:33.192: INFO: update-demo-nautilus-zmwvv is verified up and running
STEP: scaling down the replication controller
Dec 27 02:49:33.193: INFO: scanned /root for discovery docs: <nil>
Dec 27 02:49:33.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-4bg2v'
Dec 27 02:49:34.280: INFO: stderr: ""
Dec 27 02:49:34.280: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 27 02:49:34.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-4bg2v'
Dec 27 02:49:34.346: INFO: stderr: ""
Dec 27 02:49:34.346: INFO: stdout: "update-demo-nautilus-7zzzp update-demo-nautilus-zmwvv "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec 27 02:49:39.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-4bg2v'
Dec 27 02:49:39.416: INFO: stderr: ""
Dec 27 02:49:39.416: INFO: stdout: "update-demo-nautilus-7zzzp "
Dec 27 02:49:39.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods update-demo-nautilus-7zzzp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4bg2v'
Dec 27 02:49:39.483: INFO: stderr: ""
Dec 27 02:49:39.483: INFO: stdout: "true"
Dec 27 02:49:39.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods update-demo-nautilus-7zzzp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4bg2v'
Dec 27 02:49:39.549: INFO: stderr: ""
Dec 27 02:49:39.549: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 27 02:49:39.549: INFO: validating pod update-demo-nautilus-7zzzp
Dec 27 02:49:39.551: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 27 02:49:39.551: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 27 02:49:39.551: INFO: update-demo-nautilus-7zzzp is verified up and running
STEP: scaling up the replication controller
Dec 27 02:49:39.553: INFO: scanned /root for discovery docs: <nil>
Dec 27 02:49:39.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-4bg2v'
Dec 27 02:49:40.640: INFO: stderr: ""
Dec 27 02:49:40.640: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 27 02:49:40.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-4bg2v'
Dec 27 02:49:40.708: INFO: stderr: ""
Dec 27 02:49:40.708: INFO: stdout: "update-demo-nautilus-7zzzp update-demo-nautilus-lsrl4 "
Dec 27 02:49:40.708: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods update-demo-nautilus-7zzzp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4bg2v'
Dec 27 02:49:40.773: INFO: stderr: ""
Dec 27 02:49:40.773: INFO: stdout: "true"
Dec 27 02:49:40.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods update-demo-nautilus-7zzzp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4bg2v'
Dec 27 02:49:40.836: INFO: stderr: ""
Dec 27 02:49:40.836: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 27 02:49:40.836: INFO: validating pod update-demo-nautilus-7zzzp
Dec 27 02:49:40.838: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 27 02:49:40.838: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 27 02:49:40.838: INFO: update-demo-nautilus-7zzzp is verified up and running
Dec 27 02:49:40.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods update-demo-nautilus-lsrl4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4bg2v'
Dec 27 02:49:40.903: INFO: stderr: ""
Dec 27 02:49:40.903: INFO: stdout: ""
Dec 27 02:49:40.903: INFO: update-demo-nautilus-lsrl4 is created but not running
Dec 27 02:49:45.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-4bg2v'
Dec 27 02:49:45.975: INFO: stderr: ""
Dec 27 02:49:45.975: INFO: stdout: "update-demo-nautilus-7zzzp update-demo-nautilus-lsrl4 "
Dec 27 02:49:45.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods update-demo-nautilus-7zzzp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4bg2v'
Dec 27 02:49:46.040: INFO: stderr: ""
Dec 27 02:49:46.040: INFO: stdout: "true"
Dec 27 02:49:46.040: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods update-demo-nautilus-7zzzp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4bg2v'
Dec 27 02:49:46.111: INFO: stderr: ""
Dec 27 02:49:46.111: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 27 02:49:46.111: INFO: validating pod update-demo-nautilus-7zzzp
Dec 27 02:49:46.113: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 27 02:49:46.113: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 27 02:49:46.113: INFO: update-demo-nautilus-7zzzp is verified up and running
Dec 27 02:49:46.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods update-demo-nautilus-lsrl4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4bg2v'
Dec 27 02:49:46.179: INFO: stderr: ""
Dec 27 02:49:46.179: INFO: stdout: "true"
Dec 27 02:49:46.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods update-demo-nautilus-lsrl4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4bg2v'
Dec 27 02:49:46.242: INFO: stderr: ""
Dec 27 02:49:46.242: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 27 02:49:46.242: INFO: validating pod update-demo-nautilus-lsrl4
Dec 27 02:49:46.246: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 27 02:49:46.246: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 27 02:49:46.246: INFO: update-demo-nautilus-lsrl4 is verified up and running
STEP: using delete to clean up resources
Dec 27 02:49:46.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-4bg2v'
Dec 27 02:49:46.316: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 27 02:49:46.316: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec 27 02:49:46.316: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-4bg2v'
Dec 27 02:49:46.386: INFO: stderr: "No resources found.\n"
Dec 27 02:49:46.386: INFO: stdout: ""
Dec 27 02:49:46.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods -l name=update-demo --namespace=e2e-tests-kubectl-4bg2v -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 27 02:49:46.455: INFO: stderr: ""
Dec 27 02:49:46.455: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:49:46.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4bg2v" for this suite.
Dec 27 02:50:08.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:50:08.486: INFO: namespace: e2e-tests-kubectl-4bg2v, resource: bindings, ignored listing per whitelist
Dec 27 02:50:08.539: INFO: namespace e2e-tests-kubectl-4bg2v deletion completed in 22.080044914s

• [SLOW TEST:41.057 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:50:08.539: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 27 02:50:08.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-dpj66'
Dec 27 02:50:08.663: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 27 02:50:08.663: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Dec 27 02:50:08.668: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Dec 27 02:50:08.674: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Dec 27 02:50:08.683: INFO: scanned /root for discovery docs: <nil>
Dec 27 02:50:08.683: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-dpj66'
Dec 27 02:50:24.436: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec 27 02:50:24.436: INFO: stdout: "Created e2e-test-nginx-rc-91202324dcd296e7a033fee76d3e303d\nScaling up e2e-test-nginx-rc-91202324dcd296e7a033fee76d3e303d from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-91202324dcd296e7a033fee76d3e303d up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-91202324dcd296e7a033fee76d3e303d to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Dec 27 02:50:24.436: INFO: stdout: "Created e2e-test-nginx-rc-91202324dcd296e7a033fee76d3e303d\nScaling up e2e-test-nginx-rc-91202324dcd296e7a033fee76d3e303d from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-91202324dcd296e7a033fee76d3e303d up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-91202324dcd296e7a033fee76d3e303d to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Dec 27 02:50:24.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-dpj66'
Dec 27 02:50:24.501: INFO: stderr: ""
Dec 27 02:50:24.501: INFO: stdout: "e2e-test-nginx-rc-91202324dcd296e7a033fee76d3e303d-bfqwr "
Dec 27 02:50:24.501: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods e2e-test-nginx-rc-91202324dcd296e7a033fee76d3e303d-bfqwr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dpj66'
Dec 27 02:50:24.566: INFO: stderr: ""
Dec 27 02:50:24.566: INFO: stdout: "true"
Dec 27 02:50:24.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 get pods e2e-test-nginx-rc-91202324dcd296e7a033fee76d3e303d-bfqwr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dpj66'
Dec 27 02:50:24.627: INFO: stderr: ""
Dec 27 02:50:24.627: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Dec 27 02:50:24.627: INFO: e2e-test-nginx-rc-91202324dcd296e7a033fee76d3e303d-bfqwr is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Dec 27 02:50:24.627: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-574749520 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-dpj66'
Dec 27 02:50:24.694: INFO: stderr: ""
Dec 27 02:50:24.694: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:50:24.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dpj66" for this suite.
Dec 27 02:50:30.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:50:30.739: INFO: namespace: e2e-tests-kubectl-dpj66, resource: bindings, ignored listing per whitelist
Dec 27 02:50:30.770: INFO: namespace e2e-tests-kubectl-dpj66 deletion completed in 6.073593753s

• [SLOW TEST:22.232 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:50:30.771: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec 27 02:50:30.832: INFO: Waiting up to 5m0s for pod "downward-api-2c7b5074-0982-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-downward-api-6k2tr" to be "success or failure"
Dec 27 02:50:30.834: INFO: Pod "downward-api-2c7b5074-0982-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.995058ms
Dec 27 02:50:32.837: INFO: Pod "downward-api-2c7b5074-0982-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004695741s
STEP: Saw pod success
Dec 27 02:50:32.837: INFO: Pod "downward-api-2c7b5074-0982-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:50:32.838: INFO: Trying to get logs from node guojing-3 pod downward-api-2c7b5074-0982-11e9-a1bd-0a580a2100c6 container dapi-container: <nil>
STEP: delete the pod
Dec 27 02:50:32.853: INFO: Waiting for pod downward-api-2c7b5074-0982-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:50:32.855: INFO: Pod downward-api-2c7b5074-0982-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:50:32.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-6k2tr" for this suite.
Dec 27 02:50:38.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:50:38.881: INFO: namespace: e2e-tests-downward-api-6k2tr, resource: bindings, ignored listing per whitelist
Dec 27 02:50:38.937: INFO: namespace e2e-tests-downward-api-6k2tr deletion completed in 6.07847016s

• [SLOW TEST:8.166 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:50:38.937: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Dec 27 02:50:39.505: INFO: created pod pod-service-account-defaultsa
Dec 27 02:50:39.505: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Dec 27 02:50:39.510: INFO: created pod pod-service-account-mountsa
Dec 27 02:50:39.510: INFO: pod pod-service-account-mountsa service account token volume mount: true
Dec 27 02:50:39.518: INFO: created pod pod-service-account-nomountsa
Dec 27 02:50:39.518: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Dec 27 02:50:39.525: INFO: created pod pod-service-account-defaultsa-mountspec
Dec 27 02:50:39.525: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Dec 27 02:50:39.532: INFO: created pod pod-service-account-mountsa-mountspec
Dec 27 02:50:39.532: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Dec 27 02:50:39.542: INFO: created pod pod-service-account-nomountsa-mountspec
Dec 27 02:50:39.542: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Dec 27 02:50:39.556: INFO: created pod pod-service-account-defaultsa-nomountspec
Dec 27 02:50:39.556: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Dec 27 02:50:39.569: INFO: created pod pod-service-account-mountsa-nomountspec
Dec 27 02:50:39.569: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Dec 27 02:50:39.579: INFO: created pod pod-service-account-nomountsa-nomountspec
Dec 27 02:50:39.579: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:50:39.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-qwt9w" for this suite.
Dec 27 02:50:45.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:50:45.670: INFO: namespace: e2e-tests-svcaccounts-qwt9w, resource: bindings, ignored listing per whitelist
Dec 27 02:50:45.672: INFO: namespace e2e-tests-svcaccounts-qwt9w deletion completed in 6.083900441s

• [SLOW TEST:6.735 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:50:45.672: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Dec 27 02:50:45.726: INFO: Waiting up to 5m0s for pod "var-expansion-355cefc6-0982-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-var-expansion-mvlh7" to be "success or failure"
Dec 27 02:50:45.727: INFO: Pod "var-expansion-355cefc6-0982-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.765534ms
Dec 27 02:50:47.730: INFO: Pod "var-expansion-355cefc6-0982-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004295515s
STEP: Saw pod success
Dec 27 02:50:47.730: INFO: Pod "var-expansion-355cefc6-0982-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:50:47.732: INFO: Trying to get logs from node guojing-1 pod var-expansion-355cefc6-0982-11e9-a1bd-0a580a2100c6 container dapi-container: <nil>
STEP: delete the pod
Dec 27 02:50:47.750: INFO: Waiting for pod var-expansion-355cefc6-0982-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:50:47.752: INFO: Pod var-expansion-355cefc6-0982-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:50:47.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-mvlh7" for this suite.
Dec 27 02:50:53.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:50:53.799: INFO: namespace: e2e-tests-var-expansion-mvlh7, resource: bindings, ignored listing per whitelist
Dec 27 02:50:53.827: INFO: namespace e2e-tests-var-expansion-mvlh7 deletion completed in 6.072537371s

• [SLOW TEST:8.155 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:50:53.828: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 27 02:50:53.880: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Dec 27 02:50:53.888: INFO: Pod name sample-pod: Found 0 pods out of 1
Dec 27 02:50:58.891: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 27 02:50:58.891: INFO: Creating deployment "test-rolling-update-deployment"
Dec 27 02:50:58.896: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Dec 27 02:50:58.899: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Dec 27 02:51:00.904: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Dec 27 02:51:00.906: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec 27 02:51:00.912: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-fqc8d,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fqc8d/deployments/test-rolling-update-deployment,UID:3d370a27-0982-11e9-9853-debd8636412e,ResourceVersion:20207,Generation:1,CreationTimestamp:2018-12-27 02:50:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-12-27 02:50:58 +0000 UTC 2018-12-27 02:50:58 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-12-27 02:51:00 +0000 UTC 2018-12-27 02:50:58 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec 27 02:51:00.914: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-fqc8d,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fqc8d/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:3d39b71b-0982-11e9-b34c-525400cd4ed0,ResourceVersion:20198,Generation:1,CreationTimestamp:2018-12-27 02:50:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 3d370a27-0982-11e9-9853-debd8636412e 0xc0022b8c47 0xc0022b8c48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec 27 02:51:00.914: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Dec 27 02:51:00.914: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-fqc8d,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fqc8d/replicasets/test-rolling-update-controller,UID:3a3a696c-0982-11e9-9853-debd8636412e,ResourceVersion:20206,Generation:2,CreationTimestamp:2018-12-27 02:50:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 3d370a27-0982-11e9-9853-debd8636412e 0xc0022b8b87 0xc0022b8b88}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 27 02:51:00.916: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-9wpvf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-9wpvf,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-fqc8d,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fqc8d/pods/test-rolling-update-deployment-68b55d7bc6-9wpvf,UID:3d3a4b3b-0982-11e9-b34c-525400cd4ed0,ResourceVersion:20197,Generation:0,CreationTimestamp:2018-12-27 02:50:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 3d39b71b-0982-11e9-b34c-525400cd4ed0 0xc0022b9507 0xc0022b9508}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jc2nv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jc2nv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-jc2nv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:guojing-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022b9580} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022b95a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:50:58 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:51:00 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:51:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-27 02:50:58 +0000 UTC  }],Message:,Reason:,HostIP:172.19.16.36,PodIP:10.33.1.141,StartTime:2018-12-27 02:50:58 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-12-27 02:50:59 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://3e4b2ea9d65a0e5e2d6a6c0b30e927f01c516137c15a4d27009b144737cf6a8d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:51:00.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-fqc8d" for this suite.
Dec 27 02:51:06.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:51:06.975: INFO: namespace: e2e-tests-deployment-fqc8d, resource: bindings, ignored listing per whitelist
Dec 27 02:51:06.992: INFO: namespace e2e-tests-deployment-fqc8d deletion completed in 6.072843382s

• [SLOW TEST:13.164 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:51:06.992: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec 27 02:51:11.077: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 27 02:51:11.079: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 27 02:51:13.079: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 27 02:51:13.082: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 27 02:51:15.079: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 27 02:51:15.082: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 27 02:51:17.079: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 27 02:51:17.082: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 27 02:51:19.079: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 27 02:51:19.082: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 27 02:51:21.079: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 27 02:51:21.082: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 27 02:51:23.079: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 27 02:51:23.082: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 27 02:51:25.079: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 27 02:51:25.082: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 27 02:51:27.079: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 27 02:51:27.082: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 27 02:51:29.079: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 27 02:51:29.082: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 27 02:51:31.079: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 27 02:51:31.082: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 27 02:51:33.079: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 27 02:51:33.082: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 27 02:51:35.079: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 27 02:51:35.082: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 27 02:51:37.079: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 27 02:51:37.082: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 27 02:51:39.079: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 27 02:51:39.082: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:51:39.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-bfqcg" for this suite.
Dec 27 02:52:01.094: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:52:01.117: INFO: namespace: e2e-tests-container-lifecycle-hook-bfqcg, resource: bindings, ignored listing per whitelist
Dec 27 02:52:01.157: INFO: namespace e2e-tests-container-lifecycle-hook-bfqcg deletion completed in 22.072148655s

• [SLOW TEST:54.165 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:52:01.157: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec 27 02:52:03.753: INFO: Successfully updated pod "labelsupdate625ce47d-0982-11e9-a1bd-0a580a2100c6"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:52:07.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-mzdzd" for this suite.
Dec 27 02:52:29.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:52:29.811: INFO: namespace: e2e-tests-downward-api-mzdzd, resource: bindings, ignored listing per whitelist
Dec 27 02:52:29.847: INFO: namespace e2e-tests-downward-api-mzdzd deletion completed in 22.072606109s

• [SLOW TEST:28.689 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:52:29.847: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-73764044-0982-11e9-a1bd-0a580a2100c6
STEP: Creating a pod to test consume secrets
Dec 27 02:52:29.913: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7376fbf3-0982-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-projected-4kz8k" to be "success or failure"
Dec 27 02:52:29.915: INFO: Pod "pod-projected-secrets-7376fbf3-0982-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.885486ms
Dec 27 02:52:31.917: INFO: Pod "pod-projected-secrets-7376fbf3-0982-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004378119s
STEP: Saw pod success
Dec 27 02:52:31.917: INFO: Pod "pod-projected-secrets-7376fbf3-0982-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:52:31.919: INFO: Trying to get logs from node guojing-1 pod pod-projected-secrets-7376fbf3-0982-11e9-a1bd-0a580a2100c6 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 27 02:52:31.933: INFO: Waiting for pod pod-projected-secrets-7376fbf3-0982-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:52:31.935: INFO: Pod pod-projected-secrets-7376fbf3-0982-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:52:31.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4kz8k" for this suite.
Dec 27 02:52:37.947: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:52:37.973: INFO: namespace: e2e-tests-projected-4kz8k, resource: bindings, ignored listing per whitelist
Dec 27 02:52:38.004: INFO: namespace e2e-tests-projected-4kz8k deletion completed in 6.065828161s

• [SLOW TEST:8.157 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 27 02:52:38.004: INFO: >>> kubeConfig: /tmp/kubeconfig-574749520
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-7851c998-0982-11e9-a1bd-0a580a2100c6
STEP: Creating a pod to test consume secrets
Dec 27 02:52:38.064: INFO: Waiting up to 5m0s for pod "pod-secrets-7852c53b-0982-11e9-a1bd-0a580a2100c6" in namespace "e2e-tests-secrets-m42n6" to be "success or failure"
Dec 27 02:52:38.066: INFO: Pod "pod-secrets-7852c53b-0982-11e9-a1bd-0a580a2100c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.824344ms
Dec 27 02:52:40.069: INFO: Pod "pod-secrets-7852c53b-0982-11e9-a1bd-0a580a2100c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00443037s
STEP: Saw pod success
Dec 27 02:52:40.069: INFO: Pod "pod-secrets-7852c53b-0982-11e9-a1bd-0a580a2100c6" satisfied condition "success or failure"
Dec 27 02:52:40.070: INFO: Trying to get logs from node guojing-2 pod pod-secrets-7852c53b-0982-11e9-a1bd-0a580a2100c6 container secret-volume-test: <nil>
STEP: delete the pod
Dec 27 02:52:40.085: INFO: Waiting for pod pod-secrets-7852c53b-0982-11e9-a1bd-0a580a2100c6 to disappear
Dec 27 02:52:40.090: INFO: Pod pod-secrets-7852c53b-0982-11e9-a1bd-0a580a2100c6 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 27 02:52:40.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-m42n6" for this suite.
Dec 27 02:52:46.102: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 27 02:52:46.129: INFO: namespace: e2e-tests-secrets-m42n6, resource: bindings, ignored listing per whitelist
Dec 27 02:52:46.161: INFO: namespace e2e-tests-secrets-m42n6 deletion completed in 6.067875347s

• [SLOW TEST:8.157 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSDec 27 02:52:46.161: INFO: Running AfterSuite actions on all nodes
Dec 27 02:52:46.161: INFO: Running AfterSuite actions on node 1
Dec 27 02:52:46.161: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 5195.959 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h26m36.579064835s
Test Suite Passed
