I0318 07:34:55.296777      18 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-236863226
I0318 07:34:55.297083      18 e2e.go:224] Starting e2e run "52cb4cad-4950-11e9-86d2-4ea95915efee" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1552894494 - Will randomize all specs
Will run 201 of 1946 specs

Mar 18 07:34:55.448: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
Mar 18 07:34:55.451: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Mar 18 07:34:55.467: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Mar 18 07:34:55.499: INFO: 12 / 12 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Mar 18 07:34:55.499: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Mar 18 07:34:55.499: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Mar 18 07:34:55.507: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Mar 18 07:34:55.507: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'weave-net' (0 seconds elapsed)
Mar 18 07:34:55.507: INFO: e2e test version: v1.13.0
Mar 18 07:34:55.510: INFO: kube-apiserver version: v1.13.1
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:34:55.510: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename statefulset
Mar 18 07:34:55.631: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-t8p84
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Mar 18 07:34:55.646: INFO: Found 0 stateful pods, waiting for 3
Mar 18 07:35:05.666: INFO: Found 2 stateful pods, waiting for 3
Mar 18 07:35:15.650: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 18 07:35:15.650: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 18 07:35:15.650: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Mar 18 07:35:15.663: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 exec --namespace=e2e-tests-statefulset-t8p84 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 18 07:35:15.875: INFO: stderr: ""
Mar 18 07:35:15.875: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 18 07:35:15.875: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Mar 18 07:35:25.908: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Mar 18 07:35:35.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 exec --namespace=e2e-tests-statefulset-t8p84 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 18 07:35:36.139: INFO: stderr: ""
Mar 18 07:35:36.139: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 18 07:35:36.139: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 18 07:35:46.159: INFO: Waiting for StatefulSet e2e-tests-statefulset-t8p84/ss2 to complete update
Mar 18 07:35:46.159: INFO: Waiting for Pod e2e-tests-statefulset-t8p84/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 18 07:35:46.159: INFO: Waiting for Pod e2e-tests-statefulset-t8p84/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 18 07:35:56.166: INFO: Waiting for StatefulSet e2e-tests-statefulset-t8p84/ss2 to complete update
Mar 18 07:35:56.166: INFO: Waiting for Pod e2e-tests-statefulset-t8p84/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 18 07:35:56.166: INFO: Waiting for Pod e2e-tests-statefulset-t8p84/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 18 07:36:06.166: INFO: Waiting for StatefulSet e2e-tests-statefulset-t8p84/ss2 to complete update
Mar 18 07:36:06.166: INFO: Waiting for Pod e2e-tests-statefulset-t8p84/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Mar 18 07:36:16.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 exec --namespace=e2e-tests-statefulset-t8p84 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 18 07:36:16.381: INFO: stderr: ""
Mar 18 07:36:16.381: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 18 07:36:16.381: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 18 07:36:26.414: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Mar 18 07:36:36.435: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 exec --namespace=e2e-tests-statefulset-t8p84 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 18 07:36:36.642: INFO: stderr: ""
Mar 18 07:36:36.642: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 18 07:36:36.643: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 18 07:36:56.664: INFO: Waiting for StatefulSet e2e-tests-statefulset-t8p84/ss2 to complete update
Mar 18 07:36:56.664: INFO: Waiting for Pod e2e-tests-statefulset-t8p84/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 18 07:37:06.672: INFO: Deleting all statefulset in ns e2e-tests-statefulset-t8p84
Mar 18 07:37:06.675: INFO: Scaling statefulset ss2 to 0
Mar 18 07:37:26.692: INFO: Waiting for statefulset status.replicas updated to 0
Mar 18 07:37:26.696: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:37:26.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-t8p84" for this suite.
Mar 18 07:37:32.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:37:32.773: INFO: namespace: e2e-tests-statefulset-t8p84, resource: bindings, ignored listing per whitelist
Mar 18 07:37:32.839: INFO: namespace e2e-tests-statefulset-t8p84 deletion completed in 6.1202277s

â€¢ [SLOW TEST:157.329 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:37:32.839: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar 18 07:37:32.947: INFO: Waiting up to 5m0s for pod "downward-api-b120660f-4950-11e9-86d2-4ea95915efee" in namespace "e2e-tests-downward-api-5n58v" to be "success or failure"
Mar 18 07:37:32.950: INFO: Pod "downward-api-b120660f-4950-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.86067ms
Mar 18 07:37:34.954: INFO: Pod "downward-api-b120660f-4950-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006745216s
Mar 18 07:37:36.962: INFO: Pod "downward-api-b120660f-4950-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015066126s
Mar 18 07:37:38.966: INFO: Pod "downward-api-b120660f-4950-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 6.018587751s
Mar 18 07:37:40.969: INFO: Pod "downward-api-b120660f-4950-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.022550802s
STEP: Saw pod success
Mar 18 07:37:40.970: INFO: Pod "downward-api-b120660f-4950-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 07:37:40.972: INFO: Trying to get logs from node worker02 pod downward-api-b120660f-4950-11e9-86d2-4ea95915efee container dapi-container: <nil>
STEP: delete the pod
Mar 18 07:37:41.009: INFO: Waiting for pod downward-api-b120660f-4950-11e9-86d2-4ea95915efee to disappear
Mar 18 07:37:41.012: INFO: Pod downward-api-b120660f-4950-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:37:41.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5n58v" for this suite.
Mar 18 07:37:47.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:37:47.112: INFO: namespace: e2e-tests-downward-api-5n58v, resource: bindings, ignored listing per whitelist
Mar 18 07:37:47.147: INFO: namespace e2e-tests-downward-api-5n58v deletion completed in 6.130208293s

â€¢ [SLOW TEST:14.308 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:37:47.147: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Mar 18 07:37:47.292: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 07:37:47.297: INFO: Number of nodes with available pods: 0
Mar 18 07:37:47.297: INFO: Node worker01 is running more than one daemon pod
Mar 18 07:37:48.318: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 07:37:48.321: INFO: Number of nodes with available pods: 0
Mar 18 07:37:48.321: INFO: Node worker01 is running more than one daemon pod
Mar 18 07:37:49.303: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 07:37:49.306: INFO: Number of nodes with available pods: 0
Mar 18 07:37:49.306: INFO: Node worker01 is running more than one daemon pod
Mar 18 07:37:50.302: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 07:37:50.306: INFO: Number of nodes with available pods: 0
Mar 18 07:37:50.306: INFO: Node worker01 is running more than one daemon pod
Mar 18 07:37:51.302: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 07:37:51.305: INFO: Number of nodes with available pods: 0
Mar 18 07:37:51.305: INFO: Node worker01 is running more than one daemon pod
Mar 18 07:37:52.307: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 07:37:52.309: INFO: Number of nodes with available pods: 1
Mar 18 07:37:52.309: INFO: Node worker02 is running more than one daemon pod
Mar 18 07:37:53.304: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 07:37:53.307: INFO: Number of nodes with available pods: 2
Mar 18 07:37:53.307: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Mar 18 07:37:53.328: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 07:37:53.335: INFO: Number of nodes with available pods: 1
Mar 18 07:37:53.335: INFO: Node worker02 is running more than one daemon pod
Mar 18 07:37:54.339: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 07:37:54.344: INFO: Number of nodes with available pods: 1
Mar 18 07:37:54.344: INFO: Node worker02 is running more than one daemon pod
Mar 18 07:37:55.340: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 07:37:55.344: INFO: Number of nodes with available pods: 2
Mar 18 07:37:55.344: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-lh2vr, will wait for the garbage collector to delete the pods
Mar 18 07:37:55.408: INFO: Deleting DaemonSet.extensions daemon-set took: 5.938753ms
Mar 18 07:37:55.508: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.211363ms
Mar 18 07:38:41.818: INFO: Number of nodes with available pods: 0
Mar 18 07:38:41.818: INFO: Number of running nodes: 0, number of available pods: 0
Mar 18 07:38:41.822: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-lh2vr/daemonsets","resourceVersion":"188876"},"items":null}

Mar 18 07:38:41.825: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-lh2vr/pods","resourceVersion":"188876"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:38:41.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-lh2vr" for this suite.
Mar 18 07:38:47.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:38:47.896: INFO: namespace: e2e-tests-daemonsets-lh2vr, resource: bindings, ignored listing per whitelist
Mar 18 07:38:47.954: INFO: namespace e2e-tests-daemonsets-lh2vr deletion completed in 6.111465678s

â€¢ [SLOW TEST:60.807 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:38:47.954: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Mar 18 07:38:48.090: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Mar 18 07:38:48.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 create -f - --namespace=e2e-tests-kubectl-kq27q'
Mar 18 07:38:48.937: INFO: stderr: ""
Mar 18 07:38:48.938: INFO: stdout: "service/redis-slave created\n"
Mar 18 07:38:48.938: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Mar 18 07:38:48.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 create -f - --namespace=e2e-tests-kubectl-kq27q'
Mar 18 07:38:49.156: INFO: stderr: ""
Mar 18 07:38:49.156: INFO: stdout: "service/redis-master created\n"
Mar 18 07:38:49.156: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Mar 18 07:38:49.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 create -f - --namespace=e2e-tests-kubectl-kq27q'
Mar 18 07:38:49.374: INFO: stderr: ""
Mar 18 07:38:49.374: INFO: stdout: "service/frontend created\n"
Mar 18 07:38:49.374: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Mar 18 07:38:49.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 create -f - --namespace=e2e-tests-kubectl-kq27q'
Mar 18 07:38:49.566: INFO: stderr: ""
Mar 18 07:38:49.566: INFO: stdout: "deployment.extensions/frontend created\n"
Mar 18 07:38:49.566: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Mar 18 07:38:49.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 create -f - --namespace=e2e-tests-kubectl-kq27q'
Mar 18 07:38:49.770: INFO: stderr: ""
Mar 18 07:38:49.770: INFO: stdout: "deployment.extensions/redis-master created\n"
Mar 18 07:38:49.770: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Mar 18 07:38:49.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 create -f - --namespace=e2e-tests-kubectl-kq27q'
Mar 18 07:38:49.970: INFO: stderr: ""
Mar 18 07:38:49.970: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Mar 18 07:38:49.970: INFO: Waiting for all frontend pods to be Running.
Mar 18 07:39:15.021: INFO: Waiting for frontend to serve content.
Mar 18 07:39:20.045: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Mar 18 07:39:25.066: INFO: Trying to add a new entry to the guestbook.
Mar 18 07:39:25.082: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Mar 18 07:39:25.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-kq27q'
Mar 18 07:39:25.215: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 18 07:39:25.215: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Mar 18 07:39:25.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-kq27q'
Mar 18 07:39:25.323: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 18 07:39:25.323: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Mar 18 07:39:25.323: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-kq27q'
Mar 18 07:39:25.465: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 18 07:39:25.465: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Mar 18 07:39:25.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-kq27q'
Mar 18 07:39:25.577: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 18 07:39:25.577: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Mar 18 07:39:25.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-kq27q'
Mar 18 07:39:25.673: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 18 07:39:25.673: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Mar 18 07:39:25.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-kq27q'
Mar 18 07:39:25.788: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 18 07:39:25.788: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:39:25.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kq27q" for this suite.
Mar 18 07:40:07.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:40:07.860: INFO: namespace: e2e-tests-kubectl-kq27q, resource: bindings, ignored listing per whitelist
Mar 18 07:40:07.926: INFO: namespace e2e-tests-kubectl-kq27q deletion completed in 42.130179563s

â€¢ [SLOW TEST:79.972 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:40:07.926: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Mar 18 07:40:18.056: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 18 07:40:18.115: INFO: Pod pod-with-prestop-http-hook still exists
Mar 18 07:40:20.115: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 18 07:40:20.120: INFO: Pod pod-with-prestop-http-hook still exists
Mar 18 07:40:22.115: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 18 07:40:22.118: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:40:22.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-dp9hq" for this suite.
Mar 18 07:40:36.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:40:36.208: INFO: namespace: e2e-tests-container-lifecycle-hook-dp9hq, resource: bindings, ignored listing per whitelist
Mar 18 07:40:36.265: INFO: namespace e2e-tests-container-lifecycle-hook-dp9hq deletion completed in 14.130708484s

â€¢ [SLOW TEST:28.339 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:40:36.265: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 18 07:40:36.379: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1e7625ca-4951-11e9-86d2-4ea95915efee" in namespace "e2e-tests-projected-qklqf" to be "success or failure"
Mar 18 07:40:36.390: INFO: Pod "downwardapi-volume-1e7625ca-4951-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 10.243409ms
Mar 18 07:40:38.393: INFO: Pod "downwardapi-volume-1e7625ca-4951-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013291506s
Mar 18 07:40:40.396: INFO: Pod "downwardapi-volume-1e7625ca-4951-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016959539s
Mar 18 07:40:42.400: INFO: Pod "downwardapi-volume-1e7625ca-4951-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.020448262s
STEP: Saw pod success
Mar 18 07:40:42.400: INFO: Pod "downwardapi-volume-1e7625ca-4951-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 07:40:42.402: INFO: Trying to get logs from node worker01 pod downwardapi-volume-1e7625ca-4951-11e9-86d2-4ea95915efee container client-container: <nil>
STEP: delete the pod
Mar 18 07:40:42.426: INFO: Waiting for pod downwardapi-volume-1e7625ca-4951-11e9-86d2-4ea95915efee to disappear
Mar 18 07:40:42.429: INFO: Pod downwardapi-volume-1e7625ca-4951-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:40:42.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qklqf" for this suite.
Mar 18 07:40:48.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:40:48.487: INFO: namespace: e2e-tests-projected-qklqf, resource: bindings, ignored listing per whitelist
Mar 18 07:40:48.544: INFO: namespace e2e-tests-projected-qklqf deletion completed in 6.110902445s

â€¢ [SLOW TEST:12.279 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:40:48.545: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 18 07:40:48.666: INFO: Waiting up to 5m0s for pod "downwardapi-volume-25c67726-4951-11e9-86d2-4ea95915efee" in namespace "e2e-tests-downward-api-8hjt2" to be "success or failure"
Mar 18 07:40:48.677: INFO: Pod "downwardapi-volume-25c67726-4951-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 10.397218ms
Mar 18 07:40:50.680: INFO: Pod "downwardapi-volume-25c67726-4951-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013447015s
Mar 18 07:40:52.683: INFO: Pod "downwardapi-volume-25c67726-4951-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016452009s
Mar 18 07:40:54.686: INFO: Pod "downwardapi-volume-25c67726-4951-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.019571709s
STEP: Saw pod success
Mar 18 07:40:54.686: INFO: Pod "downwardapi-volume-25c67726-4951-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 07:40:54.695: INFO: Trying to get logs from node worker02 pod downwardapi-volume-25c67726-4951-11e9-86d2-4ea95915efee container client-container: <nil>
STEP: delete the pod
Mar 18 07:40:54.716: INFO: Waiting for pod downwardapi-volume-25c67726-4951-11e9-86d2-4ea95915efee to disappear
Mar 18 07:40:54.719: INFO: Pod downwardapi-volume-25c67726-4951-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:40:54.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-8hjt2" for this suite.
Mar 18 07:41:00.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:41:00.838: INFO: namespace: e2e-tests-downward-api-8hjt2, resource: bindings, ignored listing per whitelist
Mar 18 07:41:00.850: INFO: namespace e2e-tests-downward-api-8hjt2 deletion completed in 6.126412968s

â€¢ [SLOW TEST:12.305 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:41:00.850: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-4t9xg.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-4t9xg.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-4t9xg.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-4t9xg.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-4t9xg.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-4t9xg.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar 18 07:41:21.080: INFO: DNS probes using e2e-tests-dns-4t9xg/dns-test-2d1b1e9b-4951-11e9-86d2-4ea95915efee succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:41:21.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-4t9xg" for this suite.
Mar 18 07:41:27.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:41:27.130: INFO: namespace: e2e-tests-dns-4t9xg, resource: bindings, ignored listing per whitelist
Mar 18 07:41:27.216: INFO: namespace e2e-tests-dns-4t9xg deletion completed in 6.109497261s

â€¢ [SLOW TEST:26.366 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:41:27.217: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Mar 18 07:41:29.350: INFO: Pod pod-hostip-3cd2cc0e-4951-11e9-86d2-4ea95915efee has hostIP: 10.0.2.4
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:41:29.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-tpt4r" for this suite.
Mar 18 07:41:51.365: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:41:51.396: INFO: namespace: e2e-tests-pods-tpt4r, resource: bindings, ignored listing per whitelist
Mar 18 07:41:51.473: INFO: namespace e2e-tests-pods-tpt4r deletion completed in 22.118851338s

â€¢ [SLOW TEST:24.256 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:41:51.473: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar 18 07:41:51.587: INFO: Waiting up to 5m0s for pod "downward-api-4b49ea68-4951-11e9-86d2-4ea95915efee" in namespace "e2e-tests-downward-api-7ftdt" to be "success or failure"
Mar 18 07:41:51.591: INFO: Pod "downward-api-4b49ea68-4951-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 3.720922ms
Mar 18 07:41:53.594: INFO: Pod "downward-api-4b49ea68-4951-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007401156s
Mar 18 07:41:55.599: INFO: Pod "downward-api-4b49ea68-4951-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011621722s
Mar 18 07:41:57.603: INFO: Pod "downward-api-4b49ea68-4951-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 6.015953395s
Mar 18 07:41:59.607: INFO: Pod "downward-api-4b49ea68-4951-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 8.019751336s
Mar 18 07:42:01.617: INFO: Pod "downward-api-4b49ea68-4951-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.029675942s
STEP: Saw pod success
Mar 18 07:42:01.617: INFO: Pod "downward-api-4b49ea68-4951-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 07:42:01.619: INFO: Trying to get logs from node worker01 pod downward-api-4b49ea68-4951-11e9-86d2-4ea95915efee container dapi-container: <nil>
STEP: delete the pod
Mar 18 07:42:01.636: INFO: Waiting for pod downward-api-4b49ea68-4951-11e9-86d2-4ea95915efee to disappear
Mar 18 07:42:01.646: INFO: Pod downward-api-4b49ea68-4951-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:42:01.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7ftdt" for this suite.
Mar 18 07:42:07.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:42:07.694: INFO: namespace: e2e-tests-downward-api-7ftdt, resource: bindings, ignored listing per whitelist
Mar 18 07:42:07.771: INFO: namespace e2e-tests-downward-api-7ftdt deletion completed in 6.12124316s

â€¢ [SLOW TEST:16.298 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:42:07.772: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 18 07:42:07.897: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5502af36-4951-11e9-86d2-4ea95915efee" in namespace "e2e-tests-downward-api-j69fd" to be "success or failure"
Mar 18 07:42:07.901: INFO: Pod "downwardapi-volume-5502af36-4951-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 4.490867ms
Mar 18 07:42:09.905: INFO: Pod "downwardapi-volume-5502af36-4951-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008014692s
STEP: Saw pod success
Mar 18 07:42:09.905: INFO: Pod "downwardapi-volume-5502af36-4951-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 07:42:09.907: INFO: Trying to get logs from node worker02 pod downwardapi-volume-5502af36-4951-11e9-86d2-4ea95915efee container client-container: <nil>
STEP: delete the pod
Mar 18 07:42:09.929: INFO: Waiting for pod downwardapi-volume-5502af36-4951-11e9-86d2-4ea95915efee to disappear
Mar 18 07:42:09.933: INFO: Pod downwardapi-volume-5502af36-4951-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:42:09.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-j69fd" for this suite.
Mar 18 07:42:15.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:42:16.047: INFO: namespace: e2e-tests-downward-api-j69fd, resource: bindings, ignored listing per whitelist
Mar 18 07:42:16.064: INFO: namespace e2e-tests-downward-api-j69fd deletion completed in 6.126850294s

â€¢ [SLOW TEST:8.292 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:42:16.064: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Mar 18 07:42:16.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 cluster-info'
Mar 18 07:42:16.242: INFO: stderr: ""
Mar 18 07:42:16.242: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:42:16.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qzldd" for this suite.
Mar 18 07:42:22.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:42:22.353: INFO: namespace: e2e-tests-kubectl-qzldd, resource: bindings, ignored listing per whitelist
Mar 18 07:42:22.363: INFO: namespace e2e-tests-kubectl-qzldd deletion completed in 6.117656246s

â€¢ [SLOW TEST:6.299 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:42:22.363: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0318 07:43:02.479073      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 18 07:43:02.479: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:43:02.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-2rqft" for this suite.
Mar 18 07:43:08.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:43:08.540: INFO: namespace: e2e-tests-gc-2rqft, resource: bindings, ignored listing per whitelist
Mar 18 07:43:08.607: INFO: namespace e2e-tests-gc-2rqft deletion completed in 6.12426854s

â€¢ [SLOW TEST:46.244 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:43:08.607: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Mar 18 07:43:08.710: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-236863226 proxy --unix-socket=/tmp/kubectl-proxy-unix705326097/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:43:08.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2pvdz" for this suite.
Mar 18 07:43:14.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:43:14.864: INFO: namespace: e2e-tests-kubectl-2pvdz, resource: bindings, ignored listing per whitelist
Mar 18 07:43:14.900: INFO: namespace e2e-tests-kubectl-2pvdz deletion completed in 6.115235903s

â€¢ [SLOW TEST:6.293 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:43:14.900: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Mar 18 07:43:15.041: INFO: Waiting up to 5m0s for pod "pod-7d080435-4951-11e9-86d2-4ea95915efee" in namespace "e2e-tests-emptydir-p7frq" to be "success or failure"
Mar 18 07:43:15.052: INFO: Pod "pod-7d080435-4951-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 10.742939ms
Mar 18 07:43:17.055: INFO: Pod "pod-7d080435-4951-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014320767s
Mar 18 07:43:19.066: INFO: Pod "pod-7d080435-4951-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02487091s
Mar 18 07:43:21.070: INFO: Pod "pod-7d080435-4951-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.02848754s
STEP: Saw pod success
Mar 18 07:43:21.070: INFO: Pod "pod-7d080435-4951-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 07:43:21.072: INFO: Trying to get logs from node worker01 pod pod-7d080435-4951-11e9-86d2-4ea95915efee container test-container: <nil>
STEP: delete the pod
Mar 18 07:43:21.090: INFO: Waiting for pod pod-7d080435-4951-11e9-86d2-4ea95915efee to disappear
Mar 18 07:43:21.094: INFO: Pod pod-7d080435-4951-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:43:21.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-p7frq" for this suite.
Mar 18 07:43:27.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:43:27.213: INFO: namespace: e2e-tests-emptydir-p7frq, resource: bindings, ignored listing per whitelist
Mar 18 07:43:27.238: INFO: namespace e2e-tests-emptydir-p7frq deletion completed in 6.139108924s

â€¢ [SLOW TEST:12.338 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:43:27.238: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Mar 18 07:43:27.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 create -f - --namespace=e2e-tests-kubectl-fd45w'
Mar 18 07:43:27.573: INFO: stderr: ""
Mar 18 07:43:27.573: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 18 07:43:27.573: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-fd45w'
Mar 18 07:43:27.677: INFO: stderr: ""
Mar 18 07:43:27.677: INFO: stdout: "update-demo-nautilus-24qcg update-demo-nautilus-56pjl "
Mar 18 07:43:27.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods update-demo-nautilus-24qcg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fd45w'
Mar 18 07:43:27.762: INFO: stderr: ""
Mar 18 07:43:27.762: INFO: stdout: ""
Mar 18 07:43:27.762: INFO: update-demo-nautilus-24qcg is created but not running
Mar 18 07:43:32.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-fd45w'
Mar 18 07:43:32.852: INFO: stderr: ""
Mar 18 07:43:32.852: INFO: stdout: "update-demo-nautilus-24qcg update-demo-nautilus-56pjl "
Mar 18 07:43:32.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods update-demo-nautilus-24qcg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fd45w'
Mar 18 07:43:32.933: INFO: stderr: ""
Mar 18 07:43:32.933: INFO: stdout: "true"
Mar 18 07:43:32.934: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods update-demo-nautilus-24qcg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fd45w'
Mar 18 07:43:33.014: INFO: stderr: ""
Mar 18 07:43:33.014: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 18 07:43:33.014: INFO: validating pod update-demo-nautilus-24qcg
Mar 18 07:43:33.021: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 18 07:43:33.022: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 18 07:43:33.022: INFO: update-demo-nautilus-24qcg is verified up and running
Mar 18 07:43:33.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods update-demo-nautilus-56pjl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fd45w'
Mar 18 07:43:33.099: INFO: stderr: ""
Mar 18 07:43:33.099: INFO: stdout: "true"
Mar 18 07:43:33.099: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods update-demo-nautilus-56pjl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fd45w'
Mar 18 07:43:33.184: INFO: stderr: ""
Mar 18 07:43:33.184: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 18 07:43:33.184: INFO: validating pod update-demo-nautilus-56pjl
Mar 18 07:43:33.196: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 18 07:43:33.196: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 18 07:43:33.196: INFO: update-demo-nautilus-56pjl is verified up and running
STEP: using delete to clean up resources
Mar 18 07:43:33.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-fd45w'
Mar 18 07:43:33.276: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 18 07:43:33.276: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Mar 18 07:43:33.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-fd45w'
Mar 18 07:43:33.365: INFO: stderr: "No resources found.\n"
Mar 18 07:43:33.365: INFO: stdout: ""
Mar 18 07:43:33.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods -l name=update-demo --namespace=e2e-tests-kubectl-fd45w -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 18 07:43:33.457: INFO: stderr: ""
Mar 18 07:43:33.457: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:43:33.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-fd45w" for this suite.
Mar 18 07:43:39.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:43:39.511: INFO: namespace: e2e-tests-kubectl-fd45w, resource: bindings, ignored listing per whitelist
Mar 18 07:43:39.587: INFO: namespace e2e-tests-kubectl-fd45w deletion completed in 6.124660064s

â€¢ [SLOW TEST:12.349 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:43:39.587: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:43:41.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-cmkw5" for this suite.
Mar 18 07:44:23.740: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:44:23.843: INFO: namespace: e2e-tests-kubelet-test-cmkw5, resource: bindings, ignored listing per whitelist
Mar 18 07:44:23.851: INFO: namespace e2e-tests-kubelet-test-cmkw5 deletion completed in 42.123714978s

â€¢ [SLOW TEST:44.264 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:44:23.852: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-2wxgx in namespace e2e-tests-proxy-n8mc9
I0318 07:44:23.965945      18 runners.go:184] Created replication controller with name: proxy-service-2wxgx, namespace: e2e-tests-proxy-n8mc9, replica count: 1
I0318 07:44:25.016355      18 runners.go:184] proxy-service-2wxgx Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0318 07:44:26.016577      18 runners.go:184] proxy-service-2wxgx Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0318 07:44:27.016817      18 runners.go:184] proxy-service-2wxgx Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0318 07:44:28.017079      18 runners.go:184] proxy-service-2wxgx Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0318 07:44:29.017266      18 runners.go:184] proxy-service-2wxgx Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0318 07:44:30.017476      18 runners.go:184] proxy-service-2wxgx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0318 07:44:31.017708      18 runners.go:184] proxy-service-2wxgx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0318 07:44:32.017926      18 runners.go:184] proxy-service-2wxgx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0318 07:44:33.018134      18 runners.go:184] proxy-service-2wxgx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0318 07:44:34.018342      18 runners.go:184] proxy-service-2wxgx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0318 07:44:35.018551      18 runners.go:184] proxy-service-2wxgx Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar 18 07:44:35.021: INFO: setup took 11.079578219s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Mar 18 07:44:35.032: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:160/proxy/: foo (200; 11.059158ms)
Mar 18 07:44:35.032: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/http:proxy-service-2wxgx:portname1/proxy/: foo (200; 10.686635ms)
Mar 18 07:44:35.033: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:160/proxy/: foo (200; 10.843045ms)
Mar 18 07:44:35.033: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:1080/proxy/... (200; 11.229468ms)
Mar 18 07:44:35.033: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:1080/proxy/rewri... (200; 11.43378ms)
Mar 18 07:44:35.033: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:162/proxy/: bar (200; 10.656535ms)
Mar 18 07:44:35.033: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/proxy-service-2wxgx:portname2/proxy/: bar (200; 10.462223ms)
Mar 18 07:44:35.034: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/proxy-service-2wxgx:portname1/proxy/: foo (200; 11.325174ms)
Mar 18 07:44:35.034: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:162/proxy/: bar (200; 11.531986ms)
Mar 18 07:44:35.034: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/http:proxy-service-2wxgx:portname2/proxy/: bar (200; 11.819904ms)
Mar 18 07:44:35.039: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm/proxy/rewriteme"... (200; 17.271328ms)
Mar 18 07:44:35.043: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:462/proxy/: tls qux (200; 20.182101ms)
Mar 18 07:44:35.043: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:443/proxy/... (200; 20.290008ms)
Mar 18 07:44:35.043: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/https:proxy-service-2wxgx:tlsportname1/proxy/: tls baz (200; 20.66013ms)
Mar 18 07:44:35.047: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/https:proxy-service-2wxgx:tlsportname2/proxy/: tls qux (200; 24.243743ms)
Mar 18 07:44:35.047: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:460/proxy/: tls baz (200; 24.837178ms)
Mar 18 07:44:35.053: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:443/proxy/... (200; 6.06236ms)
Mar 18 07:44:35.053: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:1080/proxy/... (200; 6.184468ms)
Mar 18 07:44:35.053: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:162/proxy/: bar (200; 6.132965ms)
Mar 18 07:44:35.053: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:462/proxy/: tls qux (200; 6.175167ms)
Mar 18 07:44:35.054: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:160/proxy/: foo (200; 6.361678ms)
Mar 18 07:44:35.055: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:160/proxy/: foo (200; 7.318336ms)
Mar 18 07:44:35.055: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm/proxy/rewriteme"... (200; 7.833066ms)
Mar 18 07:44:35.055: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/https:proxy-service-2wxgx:tlsportname1/proxy/: tls baz (200; 8.422001ms)
Mar 18 07:44:35.056: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:1080/proxy/rewri... (200; 8.421301ms)
Mar 18 07:44:35.056: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:460/proxy/: tls baz (200; 8.540608ms)
Mar 18 07:44:35.056: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/proxy-service-2wxgx:portname2/proxy/: bar (200; 8.615613ms)
Mar 18 07:44:35.056: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/http:proxy-service-2wxgx:portname2/proxy/: bar (200; 8.771622ms)
Mar 18 07:44:35.056: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/proxy-service-2wxgx:portname1/proxy/: foo (200; 8.954332ms)
Mar 18 07:44:35.056: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/http:proxy-service-2wxgx:portname1/proxy/: foo (200; 9.124343ms)
Mar 18 07:44:35.057: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/https:proxy-service-2wxgx:tlsportname2/proxy/: tls qux (200; 9.686376ms)
Mar 18 07:44:35.058: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:162/proxy/: bar (200; 10.524526ms)
Mar 18 07:44:35.062: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:462/proxy/: tls qux (200; 4.506868ms)
Mar 18 07:44:35.063: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:1080/proxy/... (200; 4.844989ms)
Mar 18 07:44:35.065: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:160/proxy/: foo (200; 7.449544ms)
Mar 18 07:44:35.065: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:162/proxy/: bar (200; 7.414842ms)
Mar 18 07:44:35.065: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:460/proxy/: tls baz (200; 7.498946ms)
Mar 18 07:44:35.065: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:160/proxy/: foo (200; 7.549249ms)
Mar 18 07:44:35.066: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:1080/proxy/rewri... (200; 7.820365ms)
Mar 18 07:44:35.066: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm/proxy/rewriteme"... (200; 7.689958ms)
Mar 18 07:44:35.066: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:443/proxy/... (200; 7.787564ms)
Mar 18 07:44:35.066: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:162/proxy/: bar (200; 7.72036ms)
Mar 18 07:44:35.067: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/http:proxy-service-2wxgx:portname2/proxy/: bar (200; 8.547409ms)
Mar 18 07:44:35.067: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/http:proxy-service-2wxgx:portname1/proxy/: foo (200; 8.825026ms)
Mar 18 07:44:35.067: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/proxy-service-2wxgx:portname2/proxy/: bar (200; 8.885829ms)
Mar 18 07:44:35.067: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/https:proxy-service-2wxgx:tlsportname1/proxy/: tls baz (200; 8.987435ms)
Mar 18 07:44:35.067: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/https:proxy-service-2wxgx:tlsportname2/proxy/: tls qux (200; 8.944632ms)
Mar 18 07:44:35.067: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/proxy-service-2wxgx:portname1/proxy/: foo (200; 8.877228ms)
Mar 18 07:44:35.074: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:460/proxy/: tls baz (200; 6.87891ms)
Mar 18 07:44:35.075: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:443/proxy/... (200; 6.869509ms)
Mar 18 07:44:35.075: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:1080/proxy/rewri... (200; 7.512147ms)
Mar 18 07:44:35.075: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:160/proxy/: foo (200; 7.412341ms)
Mar 18 07:44:35.075: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm/proxy/rewriteme"... (200; 7.239431ms)
Mar 18 07:44:35.075: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:162/proxy/: bar (200; 7.171426ms)
Mar 18 07:44:35.076: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:160/proxy/: foo (200; 8.620913ms)
Mar 18 07:44:35.076: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:462/proxy/: tls qux (200; 8.06758ms)
Mar 18 07:44:35.076: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:162/proxy/: bar (200; 8.57801ms)
Mar 18 07:44:35.076: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:1080/proxy/... (200; 8.72992ms)
Mar 18 07:44:35.076: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/http:proxy-service-2wxgx:portname2/proxy/: bar (200; 8.445603ms)
Mar 18 07:44:35.076: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/proxy-service-2wxgx:portname1/proxy/: foo (200; 8.590711ms)
Mar 18 07:44:35.077: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/https:proxy-service-2wxgx:tlsportname1/proxy/: tls baz (200; 9.115342ms)
Mar 18 07:44:35.077: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/https:proxy-service-2wxgx:tlsportname2/proxy/: tls qux (200; 9.970793ms)
Mar 18 07:44:35.077: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/proxy-service-2wxgx:portname2/proxy/: bar (200; 9.89909ms)
Mar 18 07:44:35.077: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/http:proxy-service-2wxgx:portname1/proxy/: foo (200; 9.453362ms)
Mar 18 07:44:35.085: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:160/proxy/: foo (200; 7.513447ms)
Mar 18 07:44:35.085: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:162/proxy/: bar (200; 8.250191ms)
Mar 18 07:44:35.086: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:162/proxy/: bar (200; 8.169587ms)
Mar 18 07:44:35.086: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/proxy-service-2wxgx:portname1/proxy/: foo (200; 8.346397ms)
Mar 18 07:44:35.086: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:462/proxy/: tls qux (200; 8.73772ms)
Mar 18 07:44:35.087: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/proxy-service-2wxgx:portname2/proxy/: bar (200; 9.469464ms)
Mar 18 07:44:35.087: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:443/proxy/... (200; 9.569769ms)
Mar 18 07:44:35.088: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/https:proxy-service-2wxgx:tlsportname2/proxy/: tls qux (200; 10.448922ms)
Mar 18 07:44:35.088: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/https:proxy-service-2wxgx:tlsportname1/proxy/: tls baz (200; 10.510325ms)
Mar 18 07:44:35.089: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:1080/proxy/rewri... (200; 11.652094ms)
Mar 18 07:44:35.090: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:460/proxy/: tls baz (200; 11.7525ms)
Mar 18 07:44:35.090: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:160/proxy/: foo (200; 11.796002ms)
Mar 18 07:44:35.090: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm/proxy/rewriteme"... (200; 12.019815ms)
Mar 18 07:44:35.090: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:1080/proxy/... (200; 12.476142ms)
Mar 18 07:44:35.091: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/http:proxy-service-2wxgx:portname1/proxy/: foo (200; 12.904568ms)
Mar 18 07:44:35.091: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/http:proxy-service-2wxgx:portname2/proxy/: bar (200; 12.917969ms)
Mar 18 07:44:35.095: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:460/proxy/: tls baz (200; 4.433664ms)
Mar 18 07:44:35.096: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:162/proxy/: bar (200; 4.662578ms)
Mar 18 07:44:35.096: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:160/proxy/: foo (200; 4.771984ms)
Mar 18 07:44:35.099: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:1080/proxy/... (200; 7.768262ms)
Mar 18 07:44:35.099: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:162/proxy/: bar (200; 8.112383ms)
Mar 18 07:44:35.099: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:462/proxy/: tls qux (200; 8.027678ms)
Mar 18 07:44:35.099: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/proxy-service-2wxgx:portname1/proxy/: foo (200; 8.323796ms)
Mar 18 07:44:35.099: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:443/proxy/... (200; 8.112583ms)
Mar 18 07:44:35.099: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:1080/proxy/rewri... (200; 7.932772ms)
Mar 18 07:44:35.099: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm/proxy/rewriteme"... (200; 7.786963ms)
Mar 18 07:44:35.099: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:160/proxy/: foo (200; 8.560009ms)
Mar 18 07:44:35.099: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/https:proxy-service-2wxgx:tlsportname2/proxy/: tls qux (200; 8.259092ms)
Mar 18 07:44:35.101: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/http:proxy-service-2wxgx:portname2/proxy/: bar (200; 9.172246ms)
Mar 18 07:44:35.101: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/https:proxy-service-2wxgx:tlsportname1/proxy/: tls baz (200; 9.872187ms)
Mar 18 07:44:35.101: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/http:proxy-service-2wxgx:portname1/proxy/: foo (200; 9.511866ms)
Mar 18 07:44:35.101: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/proxy-service-2wxgx:portname2/proxy/: bar (200; 9.673775ms)
Mar 18 07:44:35.106: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:462/proxy/: tls qux (200; 5.163107ms)
Mar 18 07:44:35.106: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:443/proxy/... (200; 5.219711ms)
Mar 18 07:44:35.107: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:162/proxy/: bar (200; 5.37682ms)
Mar 18 07:44:35.107: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm/proxy/rewriteme"... (200; 5.70414ms)
Mar 18 07:44:35.108: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/https:proxy-service-2wxgx:tlsportname2/proxy/: tls qux (200; 6.955614ms)
Mar 18 07:44:35.108: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:1080/proxy/... (200; 6.38238ms)
Mar 18 07:44:35.109: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:160/proxy/: foo (200; 7.471245ms)
Mar 18 07:44:35.109: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/proxy-service-2wxgx:portname1/proxy/: foo (200; 7.965374ms)
Mar 18 07:44:35.109: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:460/proxy/: tls baz (200; 7.38824ms)
Mar 18 07:44:35.109: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:162/proxy/: bar (200; 7.531448ms)
Mar 18 07:44:35.109: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/http:proxy-service-2wxgx:portname2/proxy/: bar (200; 8.365398ms)
Mar 18 07:44:35.109: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/https:proxy-service-2wxgx:tlsportname1/proxy/: tls baz (200; 7.992176ms)
Mar 18 07:44:35.109: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:1080/proxy/rewri... (200; 7.785164ms)
Mar 18 07:44:35.110: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/proxy-service-2wxgx:portname2/proxy/: bar (200; 8.72612ms)
Mar 18 07:44:35.111: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/http:proxy-service-2wxgx:portname1/proxy/: foo (200; 8.526607ms)
Mar 18 07:44:35.111: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:160/proxy/: foo (200; 9.001635ms)
Mar 18 07:44:35.118: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:160/proxy/: foo (200; 7.036419ms)
Mar 18 07:44:35.118: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:1080/proxy/rewri... (200; 6.934113ms)
Mar 18 07:44:35.120: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:160/proxy/: foo (200; 8.381298ms)
Mar 18 07:44:35.120: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:162/proxy/: bar (200; 8.633214ms)
Mar 18 07:44:35.120: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:460/proxy/: tls baz (200; 9.061939ms)
Mar 18 07:44:35.120: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm/proxy/rewriteme"... (200; 8.817125ms)
Mar 18 07:44:35.120: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:1080/proxy/... (200; 9.153045ms)
Mar 18 07:44:35.120: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:443/proxy/... (200; 8.158785ms)
Mar 18 07:44:35.120: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:462/proxy/: tls qux (200; 8.602712ms)
Mar 18 07:44:35.120: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:162/proxy/: bar (200; 8.392199ms)
Mar 18 07:44:35.122: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/http:proxy-service-2wxgx:portname2/proxy/: bar (200; 10.41492ms)
Mar 18 07:44:35.122: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/proxy-service-2wxgx:portname2/proxy/: bar (200; 9.74708ms)
Mar 18 07:44:35.122: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/https:proxy-service-2wxgx:tlsportname2/proxy/: tls qux (200; 9.846385ms)
Mar 18 07:44:35.122: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/https:proxy-service-2wxgx:tlsportname1/proxy/: tls baz (200; 9.965693ms)
Mar 18 07:44:35.122: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/http:proxy-service-2wxgx:portname1/proxy/: foo (200; 10.651634ms)
Mar 18 07:44:35.122: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/proxy-service-2wxgx:portname1/proxy/: foo (200; 10.175006ms)
Mar 18 07:44:35.130: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:1080/proxy/rewri... (200; 7.570551ms)
Mar 18 07:44:35.130: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:162/proxy/: bar (200; 7.90027ms)
Mar 18 07:44:35.130: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm/proxy/rewriteme"... (200; 7.659556ms)
Mar 18 07:44:35.130: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:443/proxy/... (200; 7.945472ms)
Mar 18 07:44:35.130: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:462/proxy/: tls qux (200; 7.915571ms)
Mar 18 07:44:35.130: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:1080/proxy/... (200; 7.818165ms)
Mar 18 07:44:35.130: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:160/proxy/: foo (200; 8.23189ms)
Mar 18 07:44:35.130: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:162/proxy/: bar (200; 7.833667ms)
Mar 18 07:44:35.130: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:460/proxy/: tls baz (200; 8.260792ms)
Mar 18 07:44:35.130: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:160/proxy/: foo (200; 8.013277ms)
Mar 18 07:44:35.132: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/http:proxy-service-2wxgx:portname1/proxy/: foo (200; 9.793882ms)
Mar 18 07:44:35.132: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/proxy-service-2wxgx:portname1/proxy/: foo (200; 10.190906ms)
Mar 18 07:44:35.132: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/https:proxy-service-2wxgx:tlsportname1/proxy/: tls baz (200; 10.158005ms)
Mar 18 07:44:35.132: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/https:proxy-service-2wxgx:tlsportname2/proxy/: tls qux (200; 10.155405ms)
Mar 18 07:44:35.132: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/http:proxy-service-2wxgx:portname2/proxy/: bar (200; 10.000495ms)
Mar 18 07:44:35.133: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/proxy-service-2wxgx:portname2/proxy/: bar (200; 10.740639ms)
Mar 18 07:44:35.139: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:160/proxy/: foo (200; 6.279073ms)
Mar 18 07:44:35.142: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:1080/proxy/... (200; 8.279093ms)
Mar 18 07:44:35.142: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm/proxy/rewriteme"... (200; 8.140584ms)
Mar 18 07:44:35.142: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:460/proxy/: tls baz (200; 8.264992ms)
Mar 18 07:44:35.142: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:1080/proxy/rewri... (200; 9.314955ms)
Mar 18 07:44:35.142: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:160/proxy/: foo (200; 9.687277ms)
Mar 18 07:44:35.143: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/https:proxy-service-2wxgx:tlsportname2/proxy/: tls qux (200; 9.503565ms)
Mar 18 07:44:35.143: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:462/proxy/: tls qux (200; 9.677476ms)
Mar 18 07:44:35.144: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:162/proxy/: bar (200; 10.328114ms)
Mar 18 07:44:35.144: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:443/proxy/... (200; 10.75924ms)
Mar 18 07:44:35.144: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:162/proxy/: bar (200; 10.586229ms)
Mar 18 07:44:35.144: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/https:proxy-service-2wxgx:tlsportname1/proxy/: tls baz (200; 11.351176ms)
Mar 18 07:44:35.144: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/http:proxy-service-2wxgx:portname1/proxy/: foo (200; 10.829744ms)
Mar 18 07:44:35.145: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/proxy-service-2wxgx:portname1/proxy/: foo (200; 11.689596ms)
Mar 18 07:44:35.146: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/proxy-service-2wxgx:portname2/proxy/: bar (200; 12.588149ms)
Mar 18 07:44:35.146: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/http:proxy-service-2wxgx:portname2/proxy/: bar (200; 12.43194ms)
Mar 18 07:44:35.153: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:162/proxy/: bar (200; 7.118024ms)
Mar 18 07:44:35.153: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:443/proxy/... (200; 7.116224ms)
Mar 18 07:44:35.153: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:162/proxy/: bar (200; 7.282733ms)
Mar 18 07:44:35.153: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:160/proxy/: foo (200; 7.447343ms)
Mar 18 07:44:35.153: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:462/proxy/: tls qux (200; 7.169226ms)
Mar 18 07:44:35.153: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm/proxy/rewriteme"... (200; 7.22613ms)
Mar 18 07:44:35.154: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:1080/proxy/rewri... (200; 7.654856ms)
Mar 18 07:44:35.154: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:160/proxy/: foo (200; 7.55805ms)
Mar 18 07:44:35.154: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:1080/proxy/... (200; 7.72926ms)
Mar 18 07:44:35.154: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:460/proxy/: tls baz (200; 8.022177ms)
Mar 18 07:44:35.155: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/proxy-service-2wxgx:portname1/proxy/: foo (200; 9.145944ms)
Mar 18 07:44:35.155: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/https:proxy-service-2wxgx:tlsportname1/proxy/: tls baz (200; 9.225749ms)
Mar 18 07:44:35.155: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/proxy-service-2wxgx:portname2/proxy/: bar (200; 9.112842ms)
Mar 18 07:44:35.155: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/http:proxy-service-2wxgx:portname1/proxy/: foo (200; 9.265751ms)
Mar 18 07:44:35.156: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/https:proxy-service-2wxgx:tlsportname2/proxy/: tls qux (200; 9.595971ms)
Mar 18 07:44:35.157: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/http:proxy-service-2wxgx:portname2/proxy/: bar (200; 11.390578ms)
Mar 18 07:44:35.165: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:462/proxy/: tls qux (200; 6.766102ms)
Mar 18 07:44:35.165: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/proxy-service-2wxgx:portname1/proxy/: foo (200; 6.712499ms)
Mar 18 07:44:35.165: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:443/proxy/... (200; 6.90001ms)
Mar 18 07:44:35.165: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:1080/proxy/... (200; 6.642895ms)
Mar 18 07:44:35.165: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:160/proxy/: foo (200; 6.671297ms)
Mar 18 07:44:35.167: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:162/proxy/: bar (200; 8.417201ms)
Mar 18 07:44:35.167: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:162/proxy/: bar (200; 8.873528ms)
Mar 18 07:44:35.167: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm/proxy/rewriteme"... (200; 9.026437ms)
Mar 18 07:44:35.167: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:1080/proxy/rewri... (200; 9.277052ms)
Mar 18 07:44:35.167: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:460/proxy/: tls baz (200; 8.830926ms)
Mar 18 07:44:35.168: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/http:proxy-service-2wxgx:portname1/proxy/: foo (200; 9.721778ms)
Mar 18 07:44:35.168: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/https:proxy-service-2wxgx:tlsportname2/proxy/: tls qux (200; 9.595071ms)
Mar 18 07:44:35.168: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:160/proxy/: foo (200; 10.021596ms)
Mar 18 07:44:35.168: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/https:proxy-service-2wxgx:tlsportname1/proxy/: tls baz (200; 9.703078ms)
Mar 18 07:44:35.168: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/proxy-service-2wxgx:portname2/proxy/: bar (200; 9.460363ms)
Mar 18 07:44:35.168: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/http:proxy-service-2wxgx:portname2/proxy/: bar (200; 10.460822ms)
Mar 18 07:44:35.173: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:160/proxy/: foo (200; 4.639776ms)
Mar 18 07:44:35.173: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:1080/proxy/... (200; 4.895992ms)
Mar 18 07:44:35.173: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:1080/proxy/rewri... (200; 5.0327ms)
Mar 18 07:44:35.175: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/http:proxy-service-2wxgx:portname1/proxy/: foo (200; 6.942813ms)
Mar 18 07:44:35.175: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:443/proxy/... (200; 6.686698ms)
Mar 18 07:44:35.176: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/http:proxy-service-2wxgx:portname2/proxy/: bar (200; 7.142025ms)
Mar 18 07:44:35.176: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:460/proxy/: tls baz (200; 7.138925ms)
Mar 18 07:44:35.176: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:162/proxy/: bar (200; 7.483446ms)
Mar 18 07:44:35.176: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:160/proxy/: foo (200; 7.718659ms)
Mar 18 07:44:35.177: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm/proxy/rewriteme"... (200; 8.152185ms)
Mar 18 07:44:35.177: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:162/proxy/: bar (200; 7.988976ms)
Mar 18 07:44:35.177: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:462/proxy/: tls qux (200; 7.931172ms)
Mar 18 07:44:35.177: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/proxy-service-2wxgx:portname1/proxy/: foo (200; 7.996676ms)
Mar 18 07:44:35.178: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/https:proxy-service-2wxgx:tlsportname1/proxy/: tls baz (200; 9.080941ms)
Mar 18 07:44:35.178: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/proxy-service-2wxgx:portname2/proxy/: bar (200; 8.91073ms)
Mar 18 07:44:35.178: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/https:proxy-service-2wxgx:tlsportname2/proxy/: tls qux (200; 9.24805ms)
Mar 18 07:44:35.183: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:460/proxy/: tls baz (200; 4.827088ms)
Mar 18 07:44:35.187: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:160/proxy/: foo (200; 7.89477ms)
Mar 18 07:44:35.187: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm/proxy/rewriteme"... (200; 7.860568ms)
Mar 18 07:44:35.187: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/https:proxy-service-2wxgx:tlsportname1/proxy/: tls baz (200; 8.330695ms)
Mar 18 07:44:35.187: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:1080/proxy/rewri... (200; 8.288393ms)
Mar 18 07:44:35.187: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:162/proxy/: bar (200; 8.469203ms)
Mar 18 07:44:35.187: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/http:proxy-service-2wxgx:portname1/proxy/: foo (200; 8.307394ms)
Mar 18 07:44:35.187: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:462/proxy/: tls qux (200; 8.362197ms)
Mar 18 07:44:35.187: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/https:proxy-service-2wxgx:tlsportname2/proxy/: tls qux (200; 8.680217ms)
Mar 18 07:44:35.187: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/http:proxy-service-2wxgx:portname2/proxy/: bar (200; 8.302594ms)
Mar 18 07:44:35.188: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:443/proxy/... (200; 9.354056ms)
Mar 18 07:44:35.188: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:1080/proxy/... (200; 9.518567ms)
Mar 18 07:44:35.188: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:162/proxy/: bar (200; 9.363258ms)
Mar 18 07:44:35.188: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/proxy-service-2wxgx:portname2/proxy/: bar (200; 9.527667ms)
Mar 18 07:44:35.188: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:160/proxy/: foo (200; 9.421361ms)
Mar 18 07:44:35.188: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/proxy-service-2wxgx:portname1/proxy/: foo (200; 10.061498ms)
Mar 18 07:44:35.195: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:160/proxy/: foo (200; 6.367979ms)
Mar 18 07:44:35.196: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:462/proxy/: tls qux (200; 7.102323ms)
Mar 18 07:44:35.197: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/proxy-service-2wxgx:portname2/proxy/: bar (200; 8.317295ms)
Mar 18 07:44:35.197: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:1080/proxy/rewri... (200; 8.878828ms)
Mar 18 07:44:35.197: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:443/proxy/... (200; 8.352497ms)
Mar 18 07:44:35.197: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm/proxy/rewriteme"... (200; 8.75022ms)
Mar 18 07:44:35.197: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:1080/proxy/... (200; 8.91403ms)
Mar 18 07:44:35.197: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:160/proxy/: foo (200; 8.797724ms)
Mar 18 07:44:35.197: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/https:proxy-service-2wxgx:tlsportname2/proxy/: tls qux (200; 8.779823ms)
Mar 18 07:44:35.197: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/https:proxy-service-2wxgx:tlsportname1/proxy/: tls baz (200; 8.643514ms)
Mar 18 07:44:35.198: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/proxy-service-2wxgx:portname1/proxy/: foo (200; 8.919731ms)
Mar 18 07:44:35.198: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:460/proxy/: tls baz (200; 9.25625ms)
Mar 18 07:44:35.198: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:162/proxy/: bar (200; 9.347856ms)
Mar 18 07:44:35.198: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:162/proxy/: bar (200; 9.580671ms)
Mar 18 07:44:35.199: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/http:proxy-service-2wxgx:portname2/proxy/: bar (200; 10.202507ms)
Mar 18 07:44:35.199: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/http:proxy-service-2wxgx:portname1/proxy/: foo (200; 10.233109ms)
Mar 18 07:44:35.204: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm/proxy/rewriteme"... (200; 4.565772ms)
Mar 18 07:44:35.204: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:1080/proxy/... (200; 4.959795ms)
Mar 18 07:44:35.207: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:162/proxy/: bar (200; 7.743061ms)
Mar 18 07:44:35.207: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:462/proxy/: tls qux (200; 7.370538ms)
Mar 18 07:44:35.207: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:160/proxy/: foo (200; 7.89887ms)
Mar 18 07:44:35.207: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:1080/proxy/rewri... (200; 7.767162ms)
Mar 18 07:44:35.208: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/http:proxy-service-2wxgx:portname2/proxy/: bar (200; 8.869028ms)
Mar 18 07:44:35.208: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:160/proxy/: foo (200; 8.108582ms)
Mar 18 07:44:35.208: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:162/proxy/: bar (200; 8.810024ms)
Mar 18 07:44:35.208: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:460/proxy/: tls baz (200; 9.07014ms)
Mar 18 07:44:35.208: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/http:proxy-service-2wxgx:portname1/proxy/: foo (200; 9.429161ms)
Mar 18 07:44:35.208: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:443/proxy/... (200; 8.828325ms)
Mar 18 07:44:35.209: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/https:proxy-service-2wxgx:tlsportname1/proxy/: tls baz (200; 10.181706ms)
Mar 18 07:44:35.210: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/https:proxy-service-2wxgx:tlsportname2/proxy/: tls qux (200; 10.294413ms)
Mar 18 07:44:35.210: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/proxy-service-2wxgx:portname2/proxy/: bar (200; 9.953693ms)
Mar 18 07:44:35.210: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/proxy-service-2wxgx:portname1/proxy/: foo (200; 10.602931ms)
Mar 18 07:44:35.217: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:1080/proxy/... (200; 6.683398ms)
Mar 18 07:44:35.217: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:162/proxy/: bar (200; 6.517688ms)
Mar 18 07:44:35.217: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm/proxy/rewriteme"... (200; 6.200369ms)
Mar 18 07:44:35.217: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:443/proxy/... (200; 6.076962ms)
Mar 18 07:44:35.217: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:160/proxy/: foo (200; 7.058821ms)
Mar 18 07:44:35.218: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:160/proxy/: foo (200; 7.433542ms)
Mar 18 07:44:35.218: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:462/proxy/: tls qux (200; 6.812505ms)
Mar 18 07:44:35.218: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:460/proxy/: tls baz (200; 7.299235ms)
Mar 18 07:44:35.218: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:1080/proxy/rewri... (200; 7.715959ms)
Mar 18 07:44:35.218: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:162/proxy/: bar (200; 6.993916ms)
Mar 18 07:44:35.220: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/https:proxy-service-2wxgx:tlsportname1/proxy/: tls baz (200; 8.685517ms)
Mar 18 07:44:35.220: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/http:proxy-service-2wxgx:portname2/proxy/: bar (200; 9.217249ms)
Mar 18 07:44:35.220: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/http:proxy-service-2wxgx:portname1/proxy/: foo (200; 9.288253ms)
Mar 18 07:44:35.220: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/https:proxy-service-2wxgx:tlsportname2/proxy/: tls qux (200; 8.674416ms)
Mar 18 07:44:35.220: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/proxy-service-2wxgx:portname2/proxy/: bar (200; 8.624013ms)
Mar 18 07:44:35.220: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/proxy-service-2wxgx:portname1/proxy/: foo (200; 8.813425ms)
Mar 18 07:44:35.227: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:162/proxy/: bar (200; 6.877009ms)
Mar 18 07:44:35.227: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:1080/proxy/... (200; 6.824906ms)
Mar 18 07:44:35.227: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:160/proxy/: foo (200; 6.945413ms)
Mar 18 07:44:35.228: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:443/proxy/... (200; 8.004776ms)
Mar 18 07:44:35.228: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:460/proxy/: tls baz (200; 8.338496ms)
Mar 18 07:44:35.229: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:162/proxy/: bar (200; 8.512307ms)
Mar 18 07:44:35.229: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/http:proxy-service-2wxgx:portname2/proxy/: bar (200; 8.819625ms)
Mar 18 07:44:35.229: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/https:proxy-service-2wxgx:tlsportname2/proxy/: tls qux (200; 8.816925ms)
Mar 18 07:44:35.229: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:1080/proxy/rewri... (200; 9.115943ms)
Mar 18 07:44:35.229: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/proxy-service-2wxgx:portname1/proxy/: foo (200; 8.754521ms)
Mar 18 07:44:35.229: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:160/proxy/: foo (200; 8.854427ms)
Mar 18 07:44:35.230: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/https:proxy-service-2wxgx:tlsportname1/proxy/: tls baz (200; 9.57237ms)
Mar 18 07:44:35.230: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm/proxy/rewriteme"... (200; 9.730579ms)
Mar 18 07:44:35.230: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/proxy-service-2wxgx:portname2/proxy/: bar (200; 9.650575ms)
Mar 18 07:44:35.230: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:462/proxy/: tls qux (200; 9.855287ms)
Mar 18 07:44:35.230: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/http:proxy-service-2wxgx:portname1/proxy/: foo (200; 10.0797ms)
Mar 18 07:44:35.236: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:460/proxy/: tls baz (200; 5.591333ms)
Mar 18 07:44:35.236: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:160/proxy/: foo (200; 5.325217ms)
Mar 18 07:44:35.236: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:160/proxy/: foo (200; 5.569131ms)
Mar 18 07:44:35.236: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/proxy-service-2wxgx:portname2/proxy/: bar (200; 5.640636ms)
Mar 18 07:44:35.236: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:443/proxy/... (200; 5.818247ms)
Mar 18 07:44:35.236: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:162/proxy/: bar (200; 6.001858ms)
Mar 18 07:44:35.237: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/http:proxy-service-2wxgx:portname1/proxy/: foo (200; 6.690898ms)
Mar 18 07:44:35.237: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:462/proxy/: tls qux (200; 6.322176ms)
Mar 18 07:44:35.237: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/proxy-service-2wxgx:portname1/proxy/: foo (200; 6.524088ms)
Mar 18 07:44:35.237: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/http:proxy-service-2wxgx:portname2/proxy/: bar (200; 6.697599ms)
Mar 18 07:44:35.239: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm/proxy/rewriteme"... (200; 8.517007ms)
Mar 18 07:44:35.239: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:162/proxy/: bar (200; 8.501006ms)
Mar 18 07:44:35.239: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/https:proxy-service-2wxgx:tlsportname2/proxy/: tls qux (200; 8.327595ms)
Mar 18 07:44:35.239: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/https:proxy-service-2wxgx:tlsportname1/proxy/: tls baz (200; 8.22829ms)
Mar 18 07:44:35.239: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:1080/proxy/... (200; 8.720319ms)
Mar 18 07:44:35.239: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:1080/proxy/rewri... (200; 8.762221ms)
Mar 18 07:44:35.245: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:160/proxy/: foo (200; 6.171767ms)
Mar 18 07:44:35.245: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:1080/proxy/rewri... (200; 5.993557ms)
Mar 18 07:44:35.248: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:162/proxy/: bar (200; 8.355398ms)
Mar 18 07:44:35.248: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm/proxy/rewriteme"... (200; 8.285593ms)
Mar 18 07:44:35.248: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:160/proxy/: foo (200; 8.393199ms)
Mar 18 07:44:35.249: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/http:proxy-service-2wxgx:portname1/proxy/: foo (200; 9.432762ms)
Mar 18 07:44:35.249: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/https:proxy-service-2wxgx:tlsportname2/proxy/: tls qux (200; 9.807984ms)
Mar 18 07:44:35.249: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/https:proxy-service-2wxgx:tlsportname1/proxy/: tls baz (200; 9.73848ms)
Mar 18 07:44:35.249: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/http:proxy-service-2wxgx:portname2/proxy/: bar (200; 9.92269ms)
Mar 18 07:44:35.249: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/proxy-service-2wxgx:portname2/proxy/: bar (200; 9.892989ms)
Mar 18 07:44:35.249: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:443/proxy/... (200; 9.847086ms)
Mar 18 07:44:35.253: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/http:proxy-service-2wxgx-nwbkm:1080/proxy/... (200; 13.866325ms)
Mar 18 07:44:35.253: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:462/proxy/: tls qux (200; 14.065637ms)
Mar 18 07:44:35.253: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/proxy-service-2wxgx-nwbkm:162/proxy/: bar (200; 13.920128ms)
Mar 18 07:44:35.253: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-n8mc9/pods/https:proxy-service-2wxgx-nwbkm:460/proxy/: tls baz (200; 13.970531ms)
Mar 18 07:44:35.253: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-n8mc9/services/proxy-service-2wxgx:portname1/proxy/: foo (200; 14.072938ms)
STEP: deleting ReplicationController proxy-service-2wxgx in namespace e2e-tests-proxy-n8mc9, will wait for the garbage collector to delete the pods
Mar 18 07:44:35.311: INFO: Deleting ReplicationController proxy-service-2wxgx took: 5.312916ms
Mar 18 07:44:35.412: INFO: Terminating ReplicationController proxy-service-2wxgx pods took: 100.275767ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:44:38.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-n8mc9" for this suite.
Mar 18 07:44:44.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:44:44.640: INFO: namespace: e2e-tests-proxy-n8mc9, resource: bindings, ignored listing per whitelist
Mar 18 07:44:44.646: INFO: namespace e2e-tests-proxy-n8mc9 deletion completed in 6.128266578s

â€¢ [SLOW TEST:20.794 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:44:44.647: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:44:44.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-h6zl7" for this suite.
Mar 18 07:44:50.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:44:50.843: INFO: namespace: e2e-tests-services-h6zl7, resource: bindings, ignored listing per whitelist
Mar 18 07:44:50.884: INFO: namespace e2e-tests-services-h6zl7 deletion completed in 6.134374341s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

â€¢ [SLOW TEST:6.237 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:44:50.884: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0318 07:45:21.528491      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 18 07:45:21.528: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:45:21.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-5qcll" for this suite.
Mar 18 07:45:27.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:45:27.575: INFO: namespace: e2e-tests-gc-5qcll, resource: bindings, ignored listing per whitelist
Mar 18 07:45:27.654: INFO: namespace e2e-tests-gc-5qcll deletion completed in 6.122142213s

â€¢ [SLOW TEST:36.770 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:45:27.655: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Mar 18 07:45:27.750: INFO: Waiting up to 5m0s for pod "pod-cc21d70d-4951-11e9-86d2-4ea95915efee" in namespace "e2e-tests-emptydir-gqr2r" to be "success or failure"
Mar 18 07:45:27.756: INFO: Pod "pod-cc21d70d-4951-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 5.906851ms
Mar 18 07:45:29.759: INFO: Pod "pod-cc21d70d-4951-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008961948s
Mar 18 07:45:31.764: INFO: Pod "pod-cc21d70d-4951-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013621241s
Mar 18 07:45:33.767: INFO: Pod "pod-cc21d70d-4951-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.01689345s
STEP: Saw pod success
Mar 18 07:45:33.767: INFO: Pod "pod-cc21d70d-4951-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 07:45:33.770: INFO: Trying to get logs from node worker02 pod pod-cc21d70d-4951-11e9-86d2-4ea95915efee container test-container: <nil>
STEP: delete the pod
Mar 18 07:45:33.793: INFO: Waiting for pod pod-cc21d70d-4951-11e9-86d2-4ea95915efee to disappear
Mar 18 07:45:33.796: INFO: Pod pod-cc21d70d-4951-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:45:33.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-gqr2r" for this suite.
Mar 18 07:45:39.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:45:39.923: INFO: namespace: e2e-tests-emptydir-gqr2r, resource: bindings, ignored listing per whitelist
Mar 18 07:45:39.927: INFO: namespace e2e-tests-emptydir-gqr2r deletion completed in 6.126607579s

â€¢ [SLOW TEST:12.272 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:45:39.927: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 18 07:45:40.034: INFO: (0) /api/v1/nodes/worker01/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="azure/">azure/</a>
<... (200; 7.464644ms)
Mar 18 07:45:40.042: INFO: (1) /api/v1/nodes/worker01/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="azure/">azure/</a>
<... (200; 7.609452ms)
Mar 18 07:45:40.048: INFO: (2) /api/v1/nodes/worker01/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="azure/">azure/</a>
<... (200; 6.328077ms)
Mar 18 07:45:40.054: INFO: (3) /api/v1/nodes/worker01/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="azure/">azure/</a>
<... (200; 6.004457ms)
Mar 18 07:45:40.059: INFO: (4) /api/v1/nodes/worker01/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="azure/">azure/</a>
<... (200; 4.316757ms)
Mar 18 07:45:40.063: INFO: (5) /api/v1/nodes/worker01/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="azure/">azure/</a>
<... (200; 4.900592ms)
Mar 18 07:45:40.068: INFO: (6) /api/v1/nodes/worker01/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="azure/">azure/</a>
<... (200; 4.563771ms)
Mar 18 07:45:40.073: INFO: (7) /api/v1/nodes/worker01/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="azure/">azure/</a>
<... (200; 4.661578ms)
Mar 18 07:45:40.077: INFO: (8) /api/v1/nodes/worker01/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="azure/">azure/</a>
<... (200; 3.901232ms)
Mar 18 07:45:40.081: INFO: (9) /api/v1/nodes/worker01/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="azure/">azure/</a>
<... (200; 4.668178ms)
Mar 18 07:45:40.086: INFO: (10) /api/v1/nodes/worker01/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="azure/">azure/</a>
<... (200; 4.288555ms)
Mar 18 07:45:40.091: INFO: (11) /api/v1/nodes/worker01/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="azure/">azure/</a>
<... (200; 4.897392ms)
Mar 18 07:45:40.095: INFO: (12) /api/v1/nodes/worker01/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="azure/">azure/</a>
<... (200; 4.083043ms)
Mar 18 07:45:40.099: INFO: (13) /api/v1/nodes/worker01/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="azure/">azure/</a>
<... (200; 4.544471ms)
Mar 18 07:45:40.105: INFO: (14) /api/v1/nodes/worker01/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="azure/">azure/</a>
<... (200; 5.276414ms)
Mar 18 07:45:40.109: INFO: (15) /api/v1/nodes/worker01/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="azure/">azure/</a>
<... (200; 4.282955ms)
Mar 18 07:45:40.114: INFO: (16) /api/v1/nodes/worker01/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="azure/">azure/</a>
<... (200; 4.616474ms)
Mar 18 07:45:40.118: INFO: (17) /api/v1/nodes/worker01/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="azure/">azure/</a>
<... (200; 4.733781ms)
Mar 18 07:45:40.124: INFO: (18) /api/v1/nodes/worker01/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="azure/">azure/</a>
<... (200; 5.189109ms)
Mar 18 07:45:40.128: INFO: (19) /api/v1/nodes/worker01/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="azure/">azure/</a>
<... (200; 4.142747ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:45:40.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-k9tvv" for this suite.
Mar 18 07:45:46.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:45:46.220: INFO: namespace: e2e-tests-proxy-k9tvv, resource: bindings, ignored listing per whitelist
Mar 18 07:45:46.256: INFO: namespace e2e-tests-proxy-k9tvv deletion completed in 6.120783232s

â€¢ [SLOW TEST:6.329 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:45:46.257: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0318 07:45:47.390783      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 18 07:45:47.390: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:45:47.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-k94gm" for this suite.
Mar 18 07:45:53.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:45:53.490: INFO: namespace: e2e-tests-gc-k94gm, resource: bindings, ignored listing per whitelist
Mar 18 07:45:53.516: INFO: namespace e2e-tests-gc-k94gm deletion completed in 6.116297266s

â€¢ [SLOW TEST:7.260 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:45:53.517: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-c9cvs
Mar 18 07:45:59.637: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-c9cvs
STEP: checking the pod's current state and verifying that restartCount is present
Mar 18 07:45:59.640: INFO: Initial restart count of pod liveness-http is 0
Mar 18 07:46:15.668: INFO: Restart count of pod e2e-tests-container-probe-c9cvs/liveness-http is now 1 (16.028645025s elapsed)
Mar 18 07:46:37.720: INFO: Restart count of pod e2e-tests-container-probe-c9cvs/liveness-http is now 2 (38.080507177s elapsed)
Mar 18 07:46:55.770: INFO: Restart count of pod e2e-tests-container-probe-c9cvs/liveness-http is now 3 (56.130809105s elapsed)
Mar 18 07:47:15.824: INFO: Restart count of pod e2e-tests-container-probe-c9cvs/liveness-http is now 4 (1m16.183931539s elapsed)
Mar 18 07:48:24.029: INFO: Restart count of pod e2e-tests-container-probe-c9cvs/liveness-http is now 5 (2m24.38938182s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:48:24.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-c9cvs" for this suite.
Mar 18 07:48:30.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:48:30.117: INFO: namespace: e2e-tests-container-probe-c9cvs, resource: bindings, ignored listing per whitelist
Mar 18 07:48:30.178: INFO: namespace e2e-tests-container-probe-c9cvs deletion completed in 6.127024726s

â€¢ [SLOW TEST:156.662 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:48:30.178: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Mar 18 07:48:30.296: INFO: Waiting up to 5m0s for pod "client-containers-38f0293d-4952-11e9-86d2-4ea95915efee" in namespace "e2e-tests-containers-nfx5q" to be "success or failure"
Mar 18 07:48:30.299: INFO: Pod "client-containers-38f0293d-4952-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 3.322798ms
Mar 18 07:48:32.302: INFO: Pod "client-containers-38f0293d-4952-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006078284s
Mar 18 07:48:34.305: INFO: Pod "client-containers-38f0293d-4952-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009692021s
Mar 18 07:48:36.314: INFO: Pod "client-containers-38f0293d-4952-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018359059s
STEP: Saw pod success
Mar 18 07:48:36.314: INFO: Pod "client-containers-38f0293d-4952-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 07:48:36.317: INFO: Trying to get logs from node worker02 pod client-containers-38f0293d-4952-11e9-86d2-4ea95915efee container test-container: <nil>
STEP: delete the pod
Mar 18 07:48:36.341: INFO: Waiting for pod client-containers-38f0293d-4952-11e9-86d2-4ea95915efee to disappear
Mar 18 07:48:36.346: INFO: Pod client-containers-38f0293d-4952-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:48:36.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-nfx5q" for this suite.
Mar 18 07:48:42.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:48:42.438: INFO: namespace: e2e-tests-containers-nfx5q, resource: bindings, ignored listing per whitelist
Mar 18 07:48:42.467: INFO: namespace e2e-tests-containers-nfx5q deletion completed in 6.11667281s

â€¢ [SLOW TEST:12.289 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:48:42.467: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Mar 18 07:48:42.558: INFO: Waiting up to 5m0s for pod "pod-403efc2f-4952-11e9-86d2-4ea95915efee" in namespace "e2e-tests-emptydir-b8zbm" to be "success or failure"
Mar 18 07:48:42.570: INFO: Pod "pod-403efc2f-4952-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 11.484384ms
Mar 18 07:48:44.574: INFO: Pod "pod-403efc2f-4952-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015335435s
Mar 18 07:48:46.578: INFO: Pod "pod-403efc2f-4952-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019470503s
STEP: Saw pod success
Mar 18 07:48:46.578: INFO: Pod "pod-403efc2f-4952-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 07:48:46.580: INFO: Trying to get logs from node worker01 pod pod-403efc2f-4952-11e9-86d2-4ea95915efee container test-container: <nil>
STEP: delete the pod
Mar 18 07:48:46.613: INFO: Waiting for pod pod-403efc2f-4952-11e9-86d2-4ea95915efee to disappear
Mar 18 07:48:46.622: INFO: Pod pod-403efc2f-4952-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:48:46.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-b8zbm" for this suite.
Mar 18 07:48:52.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:48:52.699: INFO: namespace: e2e-tests-emptydir-b8zbm, resource: bindings, ignored listing per whitelist
Mar 18 07:48:52.740: INFO: namespace e2e-tests-emptydir-b8zbm deletion completed in 6.113664731s

â€¢ [SLOW TEST:10.273 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:48:52.740: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-465fbe3c-4952-11e9-86d2-4ea95915efee
STEP: Creating a pod to test consume configMaps
Mar 18 07:48:52.841: INFO: Waiting up to 5m0s for pod "pod-configmaps-46603ace-4952-11e9-86d2-4ea95915efee" in namespace "e2e-tests-configmap-zv4jh" to be "success or failure"
Mar 18 07:48:52.844: INFO: Pod "pod-configmaps-46603ace-4952-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 3.114985ms
Mar 18 07:48:54.848: INFO: Pod "pod-configmaps-46603ace-4952-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006986838s
STEP: Saw pod success
Mar 18 07:48:54.848: INFO: Pod "pod-configmaps-46603ace-4952-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 07:48:54.851: INFO: Trying to get logs from node worker02 pod pod-configmaps-46603ace-4952-11e9-86d2-4ea95915efee container configmap-volume-test: <nil>
STEP: delete the pod
Mar 18 07:48:54.873: INFO: Waiting for pod pod-configmaps-46603ace-4952-11e9-86d2-4ea95915efee to disappear
Mar 18 07:48:54.876: INFO: Pod pod-configmaps-46603ace-4952-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:48:54.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-zv4jh" for this suite.
Mar 18 07:49:00.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:49:00.972: INFO: namespace: e2e-tests-configmap-zv4jh, resource: bindings, ignored listing per whitelist
Mar 18 07:49:01.008: INFO: namespace e2e-tests-configmap-zv4jh deletion completed in 6.12743425s

â€¢ [SLOW TEST:8.268 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:49:01.009: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Mar 18 07:49:01.090: INFO: namespace e2e-tests-kubectl-v4hcm
Mar 18 07:49:01.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 create -f - --namespace=e2e-tests-kubectl-v4hcm'
Mar 18 07:49:01.923: INFO: stderr: ""
Mar 18 07:49:01.923: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar 18 07:49:02.928: INFO: Selector matched 1 pods for map[app:redis]
Mar 18 07:49:02.928: INFO: Found 0 / 1
Mar 18 07:49:03.928: INFO: Selector matched 1 pods for map[app:redis]
Mar 18 07:49:03.928: INFO: Found 0 / 1
Mar 18 07:49:04.927: INFO: Selector matched 1 pods for map[app:redis]
Mar 18 07:49:04.927: INFO: Found 0 / 1
Mar 18 07:49:05.928: INFO: Selector matched 1 pods for map[app:redis]
Mar 18 07:49:05.928: INFO: Found 0 / 1
Mar 18 07:49:06.927: INFO: Selector matched 1 pods for map[app:redis]
Mar 18 07:49:06.927: INFO: Found 0 / 1
Mar 18 07:49:07.928: INFO: Selector matched 1 pods for map[app:redis]
Mar 18 07:49:07.928: INFO: Found 1 / 1
Mar 18 07:49:07.928: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar 18 07:49:07.931: INFO: Selector matched 1 pods for map[app:redis]
Mar 18 07:49:07.931: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar 18 07:49:07.931: INFO: wait on redis-master startup in e2e-tests-kubectl-v4hcm 
Mar 18 07:49:07.931: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 logs redis-master-bkzh5 redis-master --namespace=e2e-tests-kubectl-v4hcm'
Mar 18 07:49:08.025: INFO: stderr: ""
Mar 18 07:49:08.025: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 18 Mar 07:49:06.179 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 18 Mar 07:49:06.179 # Server started, Redis version 3.2.12\n1:M 18 Mar 07:49:06.179 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 18 Mar 07:49:06.179 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Mar 18 07:49:08.025: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-v4hcm'
Mar 18 07:49:08.136: INFO: stderr: ""
Mar 18 07:49:08.136: INFO: stdout: "service/rm2 exposed\n"
Mar 18 07:49:08.139: INFO: Service rm2 in namespace e2e-tests-kubectl-v4hcm found.
STEP: exposing service
Mar 18 07:49:10.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-v4hcm'
Mar 18 07:49:10.246: INFO: stderr: ""
Mar 18 07:49:10.246: INFO: stdout: "service/rm3 exposed\n"
Mar 18 07:49:10.268: INFO: Service rm3 in namespace e2e-tests-kubectl-v4hcm found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:49:12.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-v4hcm" for this suite.
Mar 18 07:49:34.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:49:34.304: INFO: namespace: e2e-tests-kubectl-v4hcm, resource: bindings, ignored listing per whitelist
Mar 18 07:49:34.399: INFO: namespace e2e-tests-kubectl-v4hcm deletion completed in 22.120284502s

â€¢ [SLOW TEST:33.391 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:49:34.399: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 18 07:49:34.506: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5f35dca9-4952-11e9-86d2-4ea95915efee" in namespace "e2e-tests-projected-x87fk" to be "success or failure"
Mar 18 07:49:34.511: INFO: Pod "downwardapi-volume-5f35dca9-4952-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 4.454165ms
Mar 18 07:49:36.515: INFO: Pod "downwardapi-volume-5f35dca9-4952-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008561132s
STEP: Saw pod success
Mar 18 07:49:36.515: INFO: Pod "downwardapi-volume-5f35dca9-4952-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 07:49:36.518: INFO: Trying to get logs from node worker02 pod downwardapi-volume-5f35dca9-4952-11e9-86d2-4ea95915efee container client-container: <nil>
STEP: delete the pod
Mar 18 07:49:36.538: INFO: Waiting for pod downwardapi-volume-5f35dca9-4952-11e9-86d2-4ea95915efee to disappear
Mar 18 07:49:36.550: INFO: Pod downwardapi-volume-5f35dca9-4952-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:49:36.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-x87fk" for this suite.
Mar 18 07:49:42.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:49:42.643: INFO: namespace: e2e-tests-projected-x87fk, resource: bindings, ignored listing per whitelist
Mar 18 07:49:42.733: INFO: namespace e2e-tests-projected-x87fk deletion completed in 6.178327379s

â€¢ [SLOW TEST:8.334 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:49:42.733: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar 18 07:49:42.860: INFO: Waiting up to 5m0s for pod "downward-api-642fff0f-4952-11e9-86d2-4ea95915efee" in namespace "e2e-tests-downward-api-ksxps" to be "success or failure"
Mar 18 07:49:42.869: INFO: Pod "downward-api-642fff0f-4952-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 8.422401ms
Mar 18 07:49:44.873: INFO: Pod "downward-api-642fff0f-4952-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012409961s
STEP: Saw pod success
Mar 18 07:49:44.873: INFO: Pod "downward-api-642fff0f-4952-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 07:49:44.875: INFO: Trying to get logs from node worker01 pod downward-api-642fff0f-4952-11e9-86d2-4ea95915efee container dapi-container: <nil>
STEP: delete the pod
Mar 18 07:49:44.895: INFO: Waiting for pod downward-api-642fff0f-4952-11e9-86d2-4ea95915efee to disappear
Mar 18 07:49:44.904: INFO: Pod downward-api-642fff0f-4952-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:49:44.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-ksxps" for this suite.
Mar 18 07:49:50.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:49:50.963: INFO: namespace: e2e-tests-downward-api-ksxps, resource: bindings, ignored listing per whitelist
Mar 18 07:49:51.030: INFO: namespace e2e-tests-downward-api-ksxps deletion completed in 6.121059871s

â€¢ [SLOW TEST:8.297 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:49:51.030: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-6921fd52-4952-11e9-86d2-4ea95915efee
STEP: Creating a pod to test consume secrets
Mar 18 07:49:51.160: INFO: Waiting up to 5m0s for pod "pod-secrets-6922983b-4952-11e9-86d2-4ea95915efee" in namespace "e2e-tests-secrets-zj4zc" to be "success or failure"
Mar 18 07:49:51.172: INFO: Pod "pod-secrets-6922983b-4952-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 11.524986ms
Mar 18 07:49:53.175: INFO: Pod "pod-secrets-6922983b-4952-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014970013s
Mar 18 07:49:55.179: INFO: Pod "pod-secrets-6922983b-4952-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018635353s
STEP: Saw pod success
Mar 18 07:49:55.179: INFO: Pod "pod-secrets-6922983b-4952-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 07:49:55.182: INFO: Trying to get logs from node worker02 pod pod-secrets-6922983b-4952-11e9-86d2-4ea95915efee container secret-volume-test: <nil>
STEP: delete the pod
Mar 18 07:49:55.209: INFO: Waiting for pod pod-secrets-6922983b-4952-11e9-86d2-4ea95915efee to disappear
Mar 18 07:49:55.212: INFO: Pod pod-secrets-6922983b-4952-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:49:55.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-zj4zc" for this suite.
Mar 18 07:50:01.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:50:01.282: INFO: namespace: e2e-tests-secrets-zj4zc, resource: bindings, ignored listing per whitelist
Mar 18 07:50:01.353: INFO: namespace e2e-tests-secrets-zj4zc deletion completed in 6.136432586s

â€¢ [SLOW TEST:10.323 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:50:01.353: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 18 07:50:01.479: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6f4967a0-4952-11e9-86d2-4ea95915efee" in namespace "e2e-tests-downward-api-d9bd4" to be "success or failure"
Mar 18 07:50:01.482: INFO: Pod "downwardapi-volume-6f4967a0-4952-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.959776ms
Mar 18 07:50:03.485: INFO: Pod "downwardapi-volume-6f4967a0-4952-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006240293s
STEP: Saw pod success
Mar 18 07:50:03.485: INFO: Pod "downwardapi-volume-6f4967a0-4952-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 07:50:03.488: INFO: Trying to get logs from node worker01 pod downwardapi-volume-6f4967a0-4952-11e9-86d2-4ea95915efee container client-container: <nil>
STEP: delete the pod
Mar 18 07:50:03.505: INFO: Waiting for pod downwardapi-volume-6f4967a0-4952-11e9-86d2-4ea95915efee to disappear
Mar 18 07:50:03.508: INFO: Pod downwardapi-volume-6f4967a0-4952-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:50:03.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-d9bd4" for this suite.
Mar 18 07:50:09.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:50:09.548: INFO: namespace: e2e-tests-downward-api-d9bd4, resource: bindings, ignored listing per whitelist
Mar 18 07:50:09.648: INFO: namespace e2e-tests-downward-api-d9bd4 deletion completed in 6.135038303s

â€¢ [SLOW TEST:8.295 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:50:09.648: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Mar 18 07:50:09.744: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-6mqs4" to be "success or failure"
Mar 18 07:50:09.772: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 27.515637ms
Mar 18 07:50:11.775: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030852258s
Mar 18 07:50:13.779: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03471921s
STEP: Saw pod success
Mar 18 07:50:13.779: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Mar 18 07:50:13.782: INFO: Trying to get logs from node worker02 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Mar 18 07:50:13.804: INFO: Waiting for pod pod-host-path-test to disappear
Mar 18 07:50:13.807: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:50:13.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-6mqs4" for this suite.
Mar 18 07:50:19.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:50:19.960: INFO: namespace: e2e-tests-hostpath-6mqs4, resource: bindings, ignored listing per whitelist
Mar 18 07:50:20.006: INFO: namespace e2e-tests-hostpath-6mqs4 deletion completed in 6.193242067s

â€¢ [SLOW TEST:10.358 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:50:20.006: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-7a6654ed-4952-11e9-86d2-4ea95915efee
STEP: Creating a pod to test consume configMaps
Mar 18 07:50:20.126: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7a66c287-4952-11e9-86d2-4ea95915efee" in namespace "e2e-tests-projected-46md9" to be "success or failure"
Mar 18 07:50:20.137: INFO: Pod "pod-projected-configmaps-7a66c287-4952-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 11.168064ms
Mar 18 07:50:22.141: INFO: Pod "pod-projected-configmaps-7a66c287-4952-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015052818s
STEP: Saw pod success
Mar 18 07:50:22.141: INFO: Pod "pod-projected-configmaps-7a66c287-4952-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 07:50:22.144: INFO: Trying to get logs from node worker01 pod pod-projected-configmaps-7a66c287-4952-11e9-86d2-4ea95915efee container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 18 07:50:22.170: INFO: Waiting for pod pod-projected-configmaps-7a66c287-4952-11e9-86d2-4ea95915efee to disappear
Mar 18 07:50:22.173: INFO: Pod pod-projected-configmaps-7a66c287-4952-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:50:22.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-46md9" for this suite.
Mar 18 07:50:28.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:50:28.233: INFO: namespace: e2e-tests-projected-46md9, resource: bindings, ignored listing per whitelist
Mar 18 07:50:28.300: INFO: namespace e2e-tests-projected-46md9 deletion completed in 6.121567601s

â€¢ [SLOW TEST:8.294 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:50:28.300: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-wpcpl
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-wpcpl
STEP: Deleting pre-stop pod
Mar 18 07:50:43.439: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:50:43.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-wpcpl" for this suite.
Mar 18 07:51:21.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:51:21.552: INFO: namespace: e2e-tests-prestop-wpcpl, resource: bindings, ignored listing per whitelist
Mar 18 07:51:21.575: INFO: namespace e2e-tests-prestop-wpcpl deletion completed in 38.121032824s

â€¢ [SLOW TEST:53.275 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:51:21.576: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0318 07:51:31.699294      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 18 07:51:31.699: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:51:31.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-g48qj" for this suite.
Mar 18 07:51:37.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:51:37.791: INFO: namespace: e2e-tests-gc-g48qj, resource: bindings, ignored listing per whitelist
Mar 18 07:51:37.823: INFO: namespace e2e-tests-gc-g48qj deletion completed in 6.120499438s

â€¢ [SLOW TEST:16.247 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:51:37.823: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Mar 18 07:51:37.915: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 18 07:51:37.923: INFO: Waiting for terminating namespaces to be deleted...
Mar 18 07:51:37.925: INFO: 
Logging pods the kubelet thinks is on node worker01 before test
Mar 18 07:51:37.934: INFO: weave-net-zld25 from kube-system started at 2019-03-14 07:08:17 +0000 UTC (2 container statuses recorded)
Mar 18 07:51:37.934: INFO: 	Container weave ready: true, restart count 2
Mar 18 07:51:37.934: INFO: 	Container weave-npc ready: true, restart count 1
Mar 18 07:51:37.934: INFO: disk-usage-exporter-hdpcs from cocktail-addon started at 2019-03-14 07:08:39 +0000 UTC (1 container statuses recorded)
Mar 18 07:51:37.934: INFO: 	Container disk-usage-exporter ready: true, restart count 1
Mar 18 07:51:37.934: INFO: sonobuoy from heptio-sonobuoy started at 2019-03-18 07:34:26 +0000 UTC (3 container statuses recorded)
Mar 18 07:51:37.934: INFO: 	Container cleanup ready: true, restart count 0
Mar 18 07:51:37.934: INFO: 	Container forwarder ready: true, restart count 0
Mar 18 07:51:37.934: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar 18 07:51:37.934: INFO: kube-proxy-hqq6s from kube-system started at 2019-03-14 07:08:03 +0000 UTC (1 container statuses recorded)
Mar 18 07:51:37.934: INFO: 	Container kube-proxy ready: true, restart count 1
Mar 18 07:51:37.934: INFO: node-exporter-59tlh from cocktail-addon started at 2019-03-14 07:08:39 +0000 UTC (1 container statuses recorded)
Mar 18 07:51:37.934: INFO: 	Container node-exporter ready: true, restart count 1
Mar 18 07:51:37.934: INFO: 
Logging pods the kubelet thinks is on node worker02 before test
Mar 18 07:51:37.943: INFO: coredns-5b468bcb45-zf7fk from kube-system started at 2019-03-14 07:08:04 +0000 UTC (1 container statuses recorded)
Mar 18 07:51:37.943: INFO: 	Container coredns ready: true, restart count 1
Mar 18 07:51:37.943: INFO: weave-net-knnjf from kube-system started at 2019-03-14 07:08:17 +0000 UTC (2 container statuses recorded)
Mar 18 07:51:37.943: INFO: 	Container weave ready: true, restart count 2
Mar 18 07:51:37.943: INFO: 	Container weave-npc ready: true, restart count 1
Mar 18 07:51:37.943: INFO: disk-usage-exporter-95k5q from cocktail-addon started at 2019-03-14 07:08:40 +0000 UTC (1 container statuses recorded)
Mar 18 07:51:37.943: INFO: 	Container disk-usage-exporter ready: true, restart count 1
Mar 18 07:51:37.943: INFO: coredns-5b468bcb45-wbwpw from kube-system started at 2019-03-14 07:08:04 +0000 UTC (1 container statuses recorded)
Mar 18 07:51:37.943: INFO: 	Container coredns ready: true, restart count 1
Mar 18 07:51:37.943: INFO: kube-proxy-gclqz from kube-system started at 2019-03-14 07:08:04 +0000 UTC (1 container statuses recorded)
Mar 18 07:51:37.943: INFO: 	Container kube-proxy ready: true, restart count 1
Mar 18 07:51:37.943: INFO: node-exporter-4t5db from cocktail-addon started at 2019-03-14 07:08:40 +0000 UTC (1 container statuses recorded)
Mar 18 07:51:37.943: INFO: 	Container node-exporter ready: true, restart count 1
Mar 18 07:51:37.943: INFO: sonobuoy-e2e-job-f4149a4c7cc34126 from heptio-sonobuoy started at 2019-03-18 07:34:33 +0000 UTC (2 container statuses recorded)
Mar 18 07:51:37.943: INFO: 	Container e2e ready: true, restart count 0
Mar 18 07:51:37.943: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node worker01
STEP: verifying the node has the label node worker02
Mar 18 07:51:37.994: INFO: Pod disk-usage-exporter-95k5q requesting resource cpu=100m on Node worker02
Mar 18 07:51:37.994: INFO: Pod disk-usage-exporter-hdpcs requesting resource cpu=100m on Node worker01
Mar 18 07:51:37.994: INFO: Pod node-exporter-4t5db requesting resource cpu=200m on Node worker02
Mar 18 07:51:37.994: INFO: Pod node-exporter-59tlh requesting resource cpu=200m on Node worker01
Mar 18 07:51:37.994: INFO: Pod sonobuoy requesting resource cpu=0m on Node worker01
Mar 18 07:51:37.994: INFO: Pod sonobuoy-e2e-job-f4149a4c7cc34126 requesting resource cpu=0m on Node worker02
Mar 18 07:51:37.994: INFO: Pod coredns-5b468bcb45-wbwpw requesting resource cpu=100m on Node worker02
Mar 18 07:51:37.994: INFO: Pod coredns-5b468bcb45-zf7fk requesting resource cpu=100m on Node worker02
Mar 18 07:51:37.994: INFO: Pod kube-proxy-gclqz requesting resource cpu=0m on Node worker02
Mar 18 07:51:37.994: INFO: Pod kube-proxy-hqq6s requesting resource cpu=0m on Node worker01
Mar 18 07:51:37.994: INFO: Pod weave-net-knnjf requesting resource cpu=20m on Node worker02
Mar 18 07:51:37.994: INFO: Pod weave-net-zld25 requesting resource cpu=20m on Node worker01
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a8d1432b-4952-11e9-86d2-4ea95915efee.158cfe3a53b5b71e], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-vhrqz/filler-pod-a8d1432b-4952-11e9-86d2-4ea95915efee to worker01]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a8d1432b-4952-11e9-86d2-4ea95915efee.158cfe3a87f8be20], Reason = [Pulling], Message = [pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a8d1432b-4952-11e9-86d2-4ea95915efee.158cfe3b0d4edba1], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a8d1432b-4952-11e9-86d2-4ea95915efee.158cfe3b1265b848], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a8d1432b-4952-11e9-86d2-4ea95915efee.158cfe3b1bb320e0], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a8d211dc-4952-11e9-86d2-4ea95915efee.158cfe3a548eda98], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-vhrqz/filler-pod-a8d211dc-4952-11e9-86d2-4ea95915efee to worker02]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a8d211dc-4952-11e9-86d2-4ea95915efee.158cfe3a86f043c7], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a8d211dc-4952-11e9-86d2-4ea95915efee.158cfe3a8b82b668], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a8d211dc-4952-11e9-86d2-4ea95915efee.158cfe3a949780c3], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.158cfe3b440e5eaa], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node worker02
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node worker01
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:51:43.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-vhrqz" for this suite.
Mar 18 07:51:49.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:51:49.159: INFO: namespace: e2e-tests-sched-pred-vhrqz, resource: bindings, ignored listing per whitelist
Mar 18 07:51:49.211: INFO: namespace e2e-tests-sched-pred-vhrqz deletion completed in 6.125576739s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

â€¢ [SLOW TEST:11.389 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:51:49.212: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 18 07:51:49.304: INFO: Waiting up to 5m0s for pod "downwardapi-volume-af8dfd20-4952-11e9-86d2-4ea95915efee" in namespace "e2e-tests-downward-api-w6qvb" to be "success or failure"
Mar 18 07:51:49.310: INFO: Pod "downwardapi-volume-af8dfd20-4952-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 6.665397ms
Mar 18 07:51:51.314: INFO: Pod "downwardapi-volume-af8dfd20-4952-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010394241s
STEP: Saw pod success
Mar 18 07:51:51.314: INFO: Pod "downwardapi-volume-af8dfd20-4952-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 07:51:51.317: INFO: Trying to get logs from node worker02 pod downwardapi-volume-af8dfd20-4952-11e9-86d2-4ea95915efee container client-container: <nil>
STEP: delete the pod
Mar 18 07:51:51.341: INFO: Waiting for pod downwardapi-volume-af8dfd20-4952-11e9-86d2-4ea95915efee to disappear
Mar 18 07:51:51.344: INFO: Pod downwardapi-volume-af8dfd20-4952-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:51:51.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-w6qvb" for this suite.
Mar 18 07:51:57.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:51:57.452: INFO: namespace: e2e-tests-downward-api-w6qvb, resource: bindings, ignored listing per whitelist
Mar 18 07:51:57.464: INFO: namespace e2e-tests-downward-api-w6qvb deletion completed in 6.114369273s

â€¢ [SLOW TEST:8.252 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:51:57.464: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Mar 18 07:51:57.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 create -f - --namespace=e2e-tests-kubectl-tdrbs'
Mar 18 07:51:57.741: INFO: stderr: ""
Mar 18 07:51:57.741: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Mar 18 07:51:58.747: INFO: Selector matched 1 pods for map[app:redis]
Mar 18 07:51:58.747: INFO: Found 0 / 1
Mar 18 07:51:59.745: INFO: Selector matched 1 pods for map[app:redis]
Mar 18 07:51:59.745: INFO: Found 1 / 1
Mar 18 07:51:59.745: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar 18 07:51:59.749: INFO: Selector matched 1 pods for map[app:redis]
Mar 18 07:51:59.749: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Mar 18 07:51:59.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 logs redis-master-klc4p redis-master --namespace=e2e-tests-kubectl-tdrbs'
Mar 18 07:51:59.843: INFO: stderr: ""
Mar 18 07:51:59.843: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 18 Mar 07:51:58.813 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 18 Mar 07:51:58.813 # Server started, Redis version 3.2.12\n1:M 18 Mar 07:51:58.813 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 18 Mar 07:51:58.813 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Mar 18 07:51:59.843: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 log redis-master-klc4p redis-master --namespace=e2e-tests-kubectl-tdrbs --tail=1'
Mar 18 07:51:59.934: INFO: stderr: ""
Mar 18 07:51:59.934: INFO: stdout: "1:M 18 Mar 07:51:58.813 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Mar 18 07:51:59.934: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 log redis-master-klc4p redis-master --namespace=e2e-tests-kubectl-tdrbs --limit-bytes=1'
Mar 18 07:52:00.030: INFO: stderr: ""
Mar 18 07:52:00.030: INFO: stdout: " "
STEP: exposing timestamps
Mar 18 07:52:00.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 log redis-master-klc4p redis-master --namespace=e2e-tests-kubectl-tdrbs --tail=1 --timestamps'
Mar 18 07:52:00.124: INFO: stderr: ""
Mar 18 07:52:00.124: INFO: stdout: "2019-03-18T07:51:58.813863155Z 1:M 18 Mar 07:51:58.813 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Mar 18 07:52:02.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 log redis-master-klc4p redis-master --namespace=e2e-tests-kubectl-tdrbs --since=1s'
Mar 18 07:52:02.725: INFO: stderr: ""
Mar 18 07:52:02.725: INFO: stdout: ""
Mar 18 07:52:02.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 log redis-master-klc4p redis-master --namespace=e2e-tests-kubectl-tdrbs --since=24h'
Mar 18 07:52:02.825: INFO: stderr: ""
Mar 18 07:52:02.825: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 18 Mar 07:51:58.813 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 18 Mar 07:51:58.813 # Server started, Redis version 3.2.12\n1:M 18 Mar 07:51:58.813 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 18 Mar 07:51:58.813 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Mar 18 07:52:02.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-tdrbs'
Mar 18 07:52:02.906: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 18 07:52:02.906: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Mar 18 07:52:02.906: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-tdrbs'
Mar 18 07:52:02.993: INFO: stderr: "No resources found.\n"
Mar 18 07:52:02.993: INFO: stdout: ""
Mar 18 07:52:02.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods -l name=nginx --namespace=e2e-tests-kubectl-tdrbs -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 18 07:52:03.078: INFO: stderr: ""
Mar 18 07:52:03.078: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:52:03.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tdrbs" for this suite.
Mar 18 07:52:25.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:52:25.191: INFO: namespace: e2e-tests-kubectl-tdrbs, resource: bindings, ignored listing per whitelist
Mar 18 07:52:25.199: INFO: namespace e2e-tests-kubectl-tdrbs deletion completed in 22.116335267s

â€¢ [SLOW TEST:27.735 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:52:25.199: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-dn64b
Mar 18 07:52:27.304: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-dn64b
STEP: checking the pod's current state and verifying that restartCount is present
Mar 18 07:52:27.307: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:56:27.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-dn64b" for this suite.
Mar 18 07:56:33.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:56:33.911: INFO: namespace: e2e-tests-container-probe-dn64b, resource: bindings, ignored listing per whitelist
Mar 18 07:56:33.927: INFO: namespace e2e-tests-container-probe-dn64b deletion completed in 6.118826138s

â€¢ [SLOW TEST:248.728 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:56:33.927: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar 18 07:56:34.027: INFO: PodSpec: initContainers in spec.initContainers
Mar 18 07:57:20.242: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-594468bc-4953-11e9-86d2-4ea95915efee", GenerateName:"", Namespace:"e2e-tests-init-container-x5t9n", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-x5t9n/pods/pod-init-594468bc-4953-11e9-86d2-4ea95915efee", UID:"59451ef0-4953-11e9-b44d-0022480537ee", ResourceVersion:"192154", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63688492594, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"27954687"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-7rntv", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001a68d00), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-7rntv", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-7rntv", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-7rntv", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc000c86d08), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"worker01", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0015939e0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000c86d90)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000c86db0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc000c86db8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc000c86dbc)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688492594, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688492594, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688492594, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688492594, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.2.5", PodIP:"10.32.0.5", StartTime:(*v1.Time)(0xc0016223e0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0016a7570)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0016a78f0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://6c14c290289b5121b2710dad0de05fcc0ce93029a1bafa1736b4f3ba409e755d"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001622440), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001622400), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:57:20.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-x5t9n" for this suite.
Mar 18 07:57:42.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:57:42.289: INFO: namespace: e2e-tests-init-container-x5t9n, resource: bindings, ignored listing per whitelist
Mar 18 07:57:42.361: INFO: namespace e2e-tests-init-container-x5t9n deletion completed in 22.112926265s

â€¢ [SLOW TEST:68.434 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:57:42.361: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Mar 18 07:57:42.456: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-236863226 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:57:42.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-fz9c2" for this suite.
Mar 18 07:57:48.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:57:48.595: INFO: namespace: e2e-tests-kubectl-fz9c2, resource: bindings, ignored listing per whitelist
Mar 18 07:57:48.651: INFO: namespace e2e-tests-kubectl-fz9c2 deletion completed in 6.11852232s

â€¢ [SLOW TEST:6.290 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:57:48.651: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 18 07:57:48.746: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 version'
Mar 18 07:57:48.836: INFO: stderr: ""
Mar 18 07:57:48.836: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.1\", GitCommit:\"eec55b9ba98609a46fee712359c7b5b365bdd920\", GitTreeState:\"clean\", BuildDate:\"2018-12-13T10:31:33Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:57:48.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xxdjb" for this suite.
Mar 18 07:57:54.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:57:54.949: INFO: namespace: e2e-tests-kubectl-xxdjb, resource: bindings, ignored listing per whitelist
Mar 18 07:57:54.971: INFO: namespace e2e-tests-kubectl-xxdjb deletion completed in 6.130212616s

â€¢ [SLOW TEST:6.320 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:57:54.971: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-89925361-4953-11e9-86d2-4ea95915efee
STEP: Creating a pod to test consume secrets
Mar 18 07:57:55.080: INFO: Waiting up to 5m0s for pod "pod-secrets-8992c9d9-4953-11e9-86d2-4ea95915efee" in namespace "e2e-tests-secrets-4tlbq" to be "success or failure"
Mar 18 07:57:55.092: INFO: Pod "pod-secrets-8992c9d9-4953-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 11.93241ms
Mar 18 07:57:57.095: INFO: Pod "pod-secrets-8992c9d9-4953-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015666154s
STEP: Saw pod success
Mar 18 07:57:57.096: INFO: Pod "pod-secrets-8992c9d9-4953-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 07:57:57.098: INFO: Trying to get logs from node worker01 pod pod-secrets-8992c9d9-4953-11e9-86d2-4ea95915efee container secret-volume-test: <nil>
STEP: delete the pod
Mar 18 07:57:57.117: INFO: Waiting for pod pod-secrets-8992c9d9-4953-11e9-86d2-4ea95915efee to disappear
Mar 18 07:57:57.120: INFO: Pod pod-secrets-8992c9d9-4953-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:57:57.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-4tlbq" for this suite.
Mar 18 07:58:03.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:58:03.154: INFO: namespace: e2e-tests-secrets-4tlbq, resource: bindings, ignored listing per whitelist
Mar 18 07:58:03.251: INFO: namespace e2e-tests-secrets-4tlbq deletion completed in 6.126672806s

â€¢ [SLOW TEST:8.280 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:58:03.252: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-t8v92
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-t8v92
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-t8v92
Mar 18 07:58:03.362: INFO: Found 0 stateful pods, waiting for 1
Mar 18 07:58:13.366: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Mar 18 07:58:13.370: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 exec --namespace=e2e-tests-statefulset-t8v92 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 18 07:58:13.585: INFO: stderr: ""
Mar 18 07:58:13.585: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 18 07:58:13.585: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 18 07:58:13.589: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar 18 07:58:23.592: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 18 07:58:23.592: INFO: Waiting for statefulset status.replicas updated to 0
Mar 18 07:58:23.618: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Mar 18 07:58:23.618: INFO: ss-0  worker01  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:03 +0000 UTC  }]
Mar 18 07:58:23.618: INFO: 
Mar 18 07:58:23.618: INFO: StatefulSet ss has not reached scale 3, at 1
Mar 18 07:58:24.622: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.985630133s
Mar 18 07:58:25.626: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.981100953s
Mar 18 07:58:26.631: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.977140006s
Mar 18 07:58:27.635: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.97234751s
Mar 18 07:58:28.639: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.968613176s
Mar 18 07:58:29.644: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.963950588s
Mar 18 07:58:30.647: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.959902036s
Mar 18 07:58:31.652: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.956188204s
Mar 18 07:58:32.656: INFO: Verifying statefulset ss doesn't scale past 3 for another 951.556317ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-t8v92
Mar 18 07:58:33.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 exec --namespace=e2e-tests-statefulset-t8v92 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 18 07:58:33.859: INFO: stderr: ""
Mar 18 07:58:33.859: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 18 07:58:33.859: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 18 07:58:33.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 exec --namespace=e2e-tests-statefulset-t8v92 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 18 07:58:34.065: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Mar 18 07:58:34.065: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 18 07:58:34.065: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 18 07:58:34.065: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 exec --namespace=e2e-tests-statefulset-t8v92 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 18 07:58:34.266: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Mar 18 07:58:34.266: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 18 07:58:34.266: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 18 07:58:34.269: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 18 07:58:34.269: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 18 07:58:34.269: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Mar 18 07:58:34.272: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 exec --namespace=e2e-tests-statefulset-t8v92 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 18 07:58:34.471: INFO: stderr: ""
Mar 18 07:58:34.471: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 18 07:58:34.471: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 18 07:58:34.471: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 exec --namespace=e2e-tests-statefulset-t8v92 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 18 07:58:34.687: INFO: stderr: ""
Mar 18 07:58:34.687: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 18 07:58:34.687: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 18 07:58:34.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 exec --namespace=e2e-tests-statefulset-t8v92 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 18 07:58:34.947: INFO: stderr: ""
Mar 18 07:58:34.947: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 18 07:58:34.947: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 18 07:58:34.947: INFO: Waiting for statefulset status.replicas updated to 0
Mar 18 07:58:34.972: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Mar 18 07:58:44.984: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 18 07:58:44.984: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar 18 07:58:44.984: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar 18 07:58:45.001: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Mar 18 07:58:45.001: INFO: ss-0  worker01  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:03 +0000 UTC  }]
Mar 18 07:58:45.001: INFO: ss-1  worker02  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:23 +0000 UTC  }]
Mar 18 07:58:45.001: INFO: ss-2  worker01  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:23 +0000 UTC  }]
Mar 18 07:58:45.001: INFO: 
Mar 18 07:58:45.001: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 18 07:58:46.005: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Mar 18 07:58:46.005: INFO: ss-0  worker01  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:03 +0000 UTC  }]
Mar 18 07:58:46.005: INFO: ss-1  worker02  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:23 +0000 UTC  }]
Mar 18 07:58:46.005: INFO: ss-2  worker01  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:23 +0000 UTC  }]
Mar 18 07:58:46.005: INFO: 
Mar 18 07:58:46.005: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 18 07:58:47.009: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Mar 18 07:58:47.009: INFO: ss-1  worker02  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:23 +0000 UTC  }]
Mar 18 07:58:47.009: INFO: ss-2  worker01  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:23 +0000 UTC  }]
Mar 18 07:58:47.009: INFO: 
Mar 18 07:58:47.009: INFO: StatefulSet ss has not reached scale 0, at 2
Mar 18 07:58:48.013: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Mar 18 07:58:48.013: INFO: ss-1  worker02  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:23 +0000 UTC  }]
Mar 18 07:58:48.014: INFO: ss-2  worker01  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:23 +0000 UTC  }]
Mar 18 07:58:48.014: INFO: 
Mar 18 07:58:48.014: INFO: StatefulSet ss has not reached scale 0, at 2
Mar 18 07:58:49.018: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Mar 18 07:58:49.018: INFO: ss-1  worker02  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:23 +0000 UTC  }]
Mar 18 07:58:49.018: INFO: ss-2  worker01  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:23 +0000 UTC  }]
Mar 18 07:58:49.018: INFO: 
Mar 18 07:58:49.018: INFO: StatefulSet ss has not reached scale 0, at 2
Mar 18 07:58:50.021: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Mar 18 07:58:50.021: INFO: ss-1  worker02  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:23 +0000 UTC  }]
Mar 18 07:58:50.022: INFO: ss-2  worker01  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:23 +0000 UTC  }]
Mar 18 07:58:50.022: INFO: 
Mar 18 07:58:50.022: INFO: StatefulSet ss has not reached scale 0, at 2
Mar 18 07:58:51.026: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Mar 18 07:58:51.026: INFO: ss-1  worker02  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:23 +0000 UTC  }]
Mar 18 07:58:51.026: INFO: ss-2  worker01  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:23 +0000 UTC  }]
Mar 18 07:58:51.026: INFO: 
Mar 18 07:58:51.026: INFO: StatefulSet ss has not reached scale 0, at 2
Mar 18 07:58:52.030: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Mar 18 07:58:52.030: INFO: ss-2  worker01  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:23 +0000 UTC  }]
Mar 18 07:58:52.030: INFO: 
Mar 18 07:58:52.030: INFO: StatefulSet ss has not reached scale 0, at 1
Mar 18 07:58:53.034: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Mar 18 07:58:53.034: INFO: ss-2  worker01  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 07:58:23 +0000 UTC  }]
Mar 18 07:58:53.034: INFO: 
Mar 18 07:58:53.034: INFO: StatefulSet ss has not reached scale 0, at 1
Mar 18 07:58:54.040: INFO: Verifying statefulset ss doesn't scale past 0 for another 958.352222ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-t8v92
Mar 18 07:58:55.043: INFO: Scaling statefulset ss to 0
Mar 18 07:58:55.053: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 18 07:58:55.056: INFO: Deleting all statefulset in ns e2e-tests-statefulset-t8v92
Mar 18 07:58:55.058: INFO: Scaling statefulset ss to 0
Mar 18 07:58:55.067: INFO: Waiting for statefulset status.replicas updated to 0
Mar 18 07:58:55.070: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:58:55.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-t8v92" for this suite.
Mar 18 07:59:01.107: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:59:01.195: INFO: namespace: e2e-tests-statefulset-t8v92, resource: bindings, ignored listing per whitelist
Mar 18 07:59:01.219: INFO: namespace e2e-tests-statefulset-t8v92 deletion completed in 6.132456949s

â€¢ [SLOW TEST:57.967 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:59:01.219: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-mm8rk
Mar 18 07:59:03.334: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-mm8rk
STEP: checking the pod's current state and verifying that restartCount is present
Mar 18 07:59:03.340: INFO: Initial restart count of pod liveness-exec is 0
Mar 18 07:59:51.445: INFO: Restart count of pod e2e-tests-container-probe-mm8rk/liveness-exec is now 1 (48.104082726s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:59:51.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-mm8rk" for this suite.
Mar 18 07:59:57.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 07:59:57.612: INFO: namespace: e2e-tests-container-probe-mm8rk, resource: bindings, ignored listing per whitelist
Mar 18 07:59:57.617: INFO: namespace e2e-tests-container-probe-mm8rk deletion completed in 6.145316615s

â€¢ [SLOW TEST:56.398 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 07:59:57.618: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-d2aca02f-4953-11e9-86d2-4ea95915efee
STEP: Creating a pod to test consume secrets
Mar 18 07:59:57.729: INFO: Waiting up to 5m0s for pod "pod-secrets-d2ad1460-4953-11e9-86d2-4ea95915efee" in namespace "e2e-tests-secrets-4znb2" to be "success or failure"
Mar 18 07:59:57.733: INFO: Pod "pod-secrets-d2ad1460-4953-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 4.095544ms
Mar 18 07:59:59.737: INFO: Pod "pod-secrets-d2ad1460-4953-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008165908s
STEP: Saw pod success
Mar 18 07:59:59.737: INFO: Pod "pod-secrets-d2ad1460-4953-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 07:59:59.740: INFO: Trying to get logs from node worker01 pod pod-secrets-d2ad1460-4953-11e9-86d2-4ea95915efee container secret-volume-test: <nil>
STEP: delete the pod
Mar 18 07:59:59.758: INFO: Waiting for pod pod-secrets-d2ad1460-4953-11e9-86d2-4ea95915efee to disappear
Mar 18 07:59:59.762: INFO: Pod pod-secrets-d2ad1460-4953-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 07:59:59.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-4znb2" for this suite.
Mar 18 08:00:05.778: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:00:05.825: INFO: namespace: e2e-tests-secrets-4znb2, resource: bindings, ignored listing per whitelist
Mar 18 08:00:05.887: INFO: namespace e2e-tests-secrets-4znb2 deletion completed in 6.120121315s

â€¢ [SLOW TEST:8.270 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:00:05.888: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 18 08:00:06.013: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Mar 18 08:00:06.019: INFO: Number of nodes with available pods: 0
Mar 18 08:00:06.019: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Mar 18 08:00:06.043: INFO: Number of nodes with available pods: 0
Mar 18 08:00:06.043: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:00:07.047: INFO: Number of nodes with available pods: 0
Mar 18 08:00:07.047: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:00:08.047: INFO: Number of nodes with available pods: 1
Mar 18 08:00:08.047: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Mar 18 08:00:08.072: INFO: Number of nodes with available pods: 1
Mar 18 08:00:08.072: INFO: Number of running nodes: 0, number of available pods: 1
Mar 18 08:00:09.076: INFO: Number of nodes with available pods: 0
Mar 18 08:00:09.076: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Mar 18 08:00:09.085: INFO: Number of nodes with available pods: 0
Mar 18 08:00:09.085: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:00:10.090: INFO: Number of nodes with available pods: 0
Mar 18 08:00:10.090: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:00:11.090: INFO: Number of nodes with available pods: 0
Mar 18 08:00:11.090: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:00:12.090: INFO: Number of nodes with available pods: 0
Mar 18 08:00:12.090: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:00:13.090: INFO: Number of nodes with available pods: 0
Mar 18 08:00:13.090: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:00:14.090: INFO: Number of nodes with available pods: 0
Mar 18 08:00:14.090: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:00:15.090: INFO: Number of nodes with available pods: 0
Mar 18 08:00:15.090: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:00:16.089: INFO: Number of nodes with available pods: 0
Mar 18 08:00:16.089: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:00:17.090: INFO: Number of nodes with available pods: 0
Mar 18 08:00:17.090: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:00:18.089: INFO: Number of nodes with available pods: 0
Mar 18 08:00:18.089: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:00:19.089: INFO: Number of nodes with available pods: 0
Mar 18 08:00:19.089: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:00:20.089: INFO: Number of nodes with available pods: 0
Mar 18 08:00:20.089: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:00:21.089: INFO: Number of nodes with available pods: 0
Mar 18 08:00:21.089: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:00:22.090: INFO: Number of nodes with available pods: 0
Mar 18 08:00:22.090: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:00:23.089: INFO: Number of nodes with available pods: 0
Mar 18 08:00:23.089: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:00:24.089: INFO: Number of nodes with available pods: 0
Mar 18 08:00:24.089: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:00:25.089: INFO: Number of nodes with available pods: 0
Mar 18 08:00:25.089: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:00:26.092: INFO: Number of nodes with available pods: 0
Mar 18 08:00:26.092: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:00:27.089: INFO: Number of nodes with available pods: 0
Mar 18 08:00:27.089: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:00:28.090: INFO: Number of nodes with available pods: 0
Mar 18 08:00:28.090: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:00:29.090: INFO: Number of nodes with available pods: 0
Mar 18 08:00:29.090: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:00:30.089: INFO: Number of nodes with available pods: 0
Mar 18 08:00:30.089: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:00:31.089: INFO: Number of nodes with available pods: 0
Mar 18 08:00:31.090: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:00:32.089: INFO: Number of nodes with available pods: 0
Mar 18 08:00:32.089: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:00:33.090: INFO: Number of nodes with available pods: 0
Mar 18 08:00:33.090: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:00:34.090: INFO: Number of nodes with available pods: 0
Mar 18 08:00:34.090: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:00:35.092: INFO: Number of nodes with available pods: 0
Mar 18 08:00:35.092: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:00:36.091: INFO: Number of nodes with available pods: 0
Mar 18 08:00:36.091: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:00:37.090: INFO: Number of nodes with available pods: 0
Mar 18 08:00:37.090: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:00:38.089: INFO: Number of nodes with available pods: 0
Mar 18 08:00:38.089: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:00:39.089: INFO: Number of nodes with available pods: 0
Mar 18 08:00:39.089: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:00:40.089: INFO: Number of nodes with available pods: 0
Mar 18 08:00:40.089: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:00:41.090: INFO: Number of nodes with available pods: 0
Mar 18 08:00:41.090: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:00:42.089: INFO: Number of nodes with available pods: 0
Mar 18 08:00:42.089: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:00:43.089: INFO: Number of nodes with available pods: 0
Mar 18 08:00:43.090: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:00:44.089: INFO: Number of nodes with available pods: 0
Mar 18 08:00:44.090: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:00:45.089: INFO: Number of nodes with available pods: 0
Mar 18 08:00:45.089: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:00:46.090: INFO: Number of nodes with available pods: 1
Mar 18 08:00:46.090: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-dhfmd, will wait for the garbage collector to delete the pods
Mar 18 08:00:46.156: INFO: Deleting DaemonSet.extensions daemon-set took: 5.171207ms
Mar 18 08:00:46.256: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.195263ms
Mar 18 08:01:23.876: INFO: Number of nodes with available pods: 0
Mar 18 08:01:23.876: INFO: Number of running nodes: 0, number of available pods: 0
Mar 18 08:01:23.878: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-dhfmd/daemonsets","resourceVersion":"192865"},"items":null}

Mar 18 08:01:23.881: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-dhfmd/pods","resourceVersion":"192865"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:01:23.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-dhfmd" for this suite.
Mar 18 08:01:29.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:01:29.955: INFO: namespace: e2e-tests-daemonsets-dhfmd, resource: bindings, ignored listing per whitelist
Mar 18 08:01:30.024: INFO: namespace e2e-tests-daemonsets-dhfmd deletion completed in 6.117701471s

â€¢ [SLOW TEST:84.137 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:01:30.025: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Mar 18 08:01:30.140: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-wlx2h,SelfLink:/api/v1/namespaces/e2e-tests-watch-wlx2h/configmaps/e2e-watch-test-label-changed,UID:09c167ce-4954-11e9-b44d-0022480537ee,ResourceVersion:192897,Generation:0,CreationTimestamp:2019-03-18 08:01:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 18 08:01:30.141: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-wlx2h,SelfLink:/api/v1/namespaces/e2e-tests-watch-wlx2h/configmaps/e2e-watch-test-label-changed,UID:09c167ce-4954-11e9-b44d-0022480537ee,ResourceVersion:192898,Generation:0,CreationTimestamp:2019-03-18 08:01:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar 18 08:01:30.141: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-wlx2h,SelfLink:/api/v1/namespaces/e2e-tests-watch-wlx2h/configmaps/e2e-watch-test-label-changed,UID:09c167ce-4954-11e9-b44d-0022480537ee,ResourceVersion:192899,Generation:0,CreationTimestamp:2019-03-18 08:01:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Mar 18 08:01:40.170: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-wlx2h,SelfLink:/api/v1/namespaces/e2e-tests-watch-wlx2h/configmaps/e2e-watch-test-label-changed,UID:09c167ce-4954-11e9-b44d-0022480537ee,ResourceVersion:192916,Generation:0,CreationTimestamp:2019-03-18 08:01:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 18 08:01:40.170: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-wlx2h,SelfLink:/api/v1/namespaces/e2e-tests-watch-wlx2h/configmaps/e2e-watch-test-label-changed,UID:09c167ce-4954-11e9-b44d-0022480537ee,ResourceVersion:192917,Generation:0,CreationTimestamp:2019-03-18 08:01:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Mar 18 08:01:40.170: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-wlx2h,SelfLink:/api/v1/namespaces/e2e-tests-watch-wlx2h/configmaps/e2e-watch-test-label-changed,UID:09c167ce-4954-11e9-b44d-0022480537ee,ResourceVersion:192918,Generation:0,CreationTimestamp:2019-03-18 08:01:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:01:40.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-wlx2h" for this suite.
Mar 18 08:01:46.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:01:46.276: INFO: namespace: e2e-tests-watch-wlx2h, resource: bindings, ignored listing per whitelist
Mar 18 08:01:46.307: INFO: namespace e2e-tests-watch-wlx2h deletion completed in 6.132753066s

â€¢ [SLOW TEST:16.283 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:01:46.308: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-13773459-4954-11e9-86d2-4ea95915efee
STEP: Creating a pod to test consume secrets
Mar 18 08:01:46.453: INFO: Waiting up to 5m0s for pod "pod-secrets-137bd709-4954-11e9-86d2-4ea95915efee" in namespace "e2e-tests-secrets-9dm55" to be "success or failure"
Mar 18 08:01:46.465: INFO: Pod "pod-secrets-137bd709-4954-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 11.818103ms
Mar 18 08:01:48.468: INFO: Pod "pod-secrets-137bd709-4954-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015294932s
STEP: Saw pod success
Mar 18 08:01:48.468: INFO: Pod "pod-secrets-137bd709-4954-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:01:48.472: INFO: Trying to get logs from node worker02 pod pod-secrets-137bd709-4954-11e9-86d2-4ea95915efee container secret-volume-test: <nil>
STEP: delete the pod
Mar 18 08:01:48.492: INFO: Waiting for pod pod-secrets-137bd709-4954-11e9-86d2-4ea95915efee to disappear
Mar 18 08:01:48.495: INFO: Pod pod-secrets-137bd709-4954-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:01:48.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-9dm55" for this suite.
Mar 18 08:01:54.511: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:01:54.581: INFO: namespace: e2e-tests-secrets-9dm55, resource: bindings, ignored listing per whitelist
Mar 18 08:01:54.618: INFO: namespace e2e-tests-secrets-9dm55 deletion completed in 6.117645867s
STEP: Destroying namespace "e2e-tests-secret-namespace-qxgsb" for this suite.
Mar 18 08:02:00.631: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:02:00.666: INFO: namespace: e2e-tests-secret-namespace-qxgsb, resource: bindings, ignored listing per whitelist
Mar 18 08:02:00.746: INFO: namespace e2e-tests-secret-namespace-qxgsb deletion completed in 6.128347105s

â€¢ [SLOW TEST:14.439 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:02:00.747: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-1c103467-4954-11e9-86d2-4ea95915efee
STEP: Creating a pod to test consume configMaps
Mar 18 08:02:00.858: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1c1208aa-4954-11e9-86d2-4ea95915efee" in namespace "e2e-tests-projected-jxl52" to be "success or failure"
Mar 18 08:02:00.862: INFO: Pod "pod-projected-configmaps-1c1208aa-4954-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 3.244493ms
Mar 18 08:02:02.865: INFO: Pod "pod-projected-configmaps-1c1208aa-4954-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006944135s
STEP: Saw pod success
Mar 18 08:02:02.865: INFO: Pod "pod-projected-configmaps-1c1208aa-4954-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:02:02.868: INFO: Trying to get logs from node worker01 pod pod-projected-configmaps-1c1208aa-4954-11e9-86d2-4ea95915efee container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 18 08:02:02.927: INFO: Waiting for pod pod-projected-configmaps-1c1208aa-4954-11e9-86d2-4ea95915efee to disappear
Mar 18 08:02:02.938: INFO: Pod pod-projected-configmaps-1c1208aa-4954-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:02:02.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jxl52" for this suite.
Mar 18 08:02:08.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:02:09.030: INFO: namespace: e2e-tests-projected-jxl52, resource: bindings, ignored listing per whitelist
Mar 18 08:02:09.083: INFO: namespace e2e-tests-projected-jxl52 deletion completed in 6.14036022s

â€¢ [SLOW TEST:8.337 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:02:09.084: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Mar 18 08:02:09.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 create -f - --namespace=e2e-tests-kubectl-72l4b'
Mar 18 08:02:09.962: INFO: stderr: ""
Mar 18 08:02:09.962: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 18 08:02:09.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-72l4b'
Mar 18 08:02:10.067: INFO: stderr: ""
Mar 18 08:02:10.067: INFO: stdout: "update-demo-nautilus-pxb42 update-demo-nautilus-qdltg "
Mar 18 08:02:10.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods update-demo-nautilus-pxb42 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-72l4b'
Mar 18 08:02:10.151: INFO: stderr: ""
Mar 18 08:02:10.151: INFO: stdout: ""
Mar 18 08:02:10.151: INFO: update-demo-nautilus-pxb42 is created but not running
Mar 18 08:02:15.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-72l4b'
Mar 18 08:02:15.252: INFO: stderr: ""
Mar 18 08:02:15.252: INFO: stdout: "update-demo-nautilus-pxb42 update-demo-nautilus-qdltg "
Mar 18 08:02:15.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods update-demo-nautilus-pxb42 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-72l4b'
Mar 18 08:02:15.348: INFO: stderr: ""
Mar 18 08:02:15.348: INFO: stdout: "true"
Mar 18 08:02:15.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods update-demo-nautilus-pxb42 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-72l4b'
Mar 18 08:02:15.429: INFO: stderr: ""
Mar 18 08:02:15.429: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 18 08:02:15.429: INFO: validating pod update-demo-nautilus-pxb42
Mar 18 08:02:15.437: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 18 08:02:15.437: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 18 08:02:15.437: INFO: update-demo-nautilus-pxb42 is verified up and running
Mar 18 08:02:15.437: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods update-demo-nautilus-qdltg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-72l4b'
Mar 18 08:02:15.518: INFO: stderr: ""
Mar 18 08:02:15.518: INFO: stdout: "true"
Mar 18 08:02:15.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods update-demo-nautilus-qdltg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-72l4b'
Mar 18 08:02:15.601: INFO: stderr: ""
Mar 18 08:02:15.601: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 18 08:02:15.601: INFO: validating pod update-demo-nautilus-qdltg
Mar 18 08:02:15.616: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 18 08:02:15.616: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 18 08:02:15.616: INFO: update-demo-nautilus-qdltg is verified up and running
STEP: rolling-update to new replication controller
Mar 18 08:02:15.619: INFO: scanned /root for discovery docs: <nil>
Mar 18 08:02:15.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-72l4b'
Mar 18 08:02:40.066: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Mar 18 08:02:40.066: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 18 08:02:40.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-72l4b'
Mar 18 08:02:40.160: INFO: stderr: ""
Mar 18 08:02:40.160: INFO: stdout: "update-demo-kitten-77vsp update-demo-kitten-979q6 "
Mar 18 08:02:40.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods update-demo-kitten-77vsp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-72l4b'
Mar 18 08:02:40.244: INFO: stderr: ""
Mar 18 08:02:40.244: INFO: stdout: "true"
Mar 18 08:02:40.244: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods update-demo-kitten-77vsp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-72l4b'
Mar 18 08:02:40.329: INFO: stderr: ""
Mar 18 08:02:40.329: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Mar 18 08:02:40.329: INFO: validating pod update-demo-kitten-77vsp
Mar 18 08:02:40.337: INFO: got data: {
  "image": "kitten.jpg"
}

Mar 18 08:02:40.337: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Mar 18 08:02:40.337: INFO: update-demo-kitten-77vsp is verified up and running
Mar 18 08:02:40.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods update-demo-kitten-979q6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-72l4b'
Mar 18 08:02:40.424: INFO: stderr: ""
Mar 18 08:02:40.424: INFO: stdout: "true"
Mar 18 08:02:40.424: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods update-demo-kitten-979q6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-72l4b'
Mar 18 08:02:40.512: INFO: stderr: ""
Mar 18 08:02:40.512: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Mar 18 08:02:40.512: INFO: validating pod update-demo-kitten-979q6
Mar 18 08:02:40.520: INFO: got data: {
  "image": "kitten.jpg"
}

Mar 18 08:02:40.520: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Mar 18 08:02:40.520: INFO: update-demo-kitten-979q6 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:02:40.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-72l4b" for this suite.
Mar 18 08:03:02.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:03:02.629: INFO: namespace: e2e-tests-kubectl-72l4b, resource: bindings, ignored listing per whitelist
Mar 18 08:03:02.649: INFO: namespace e2e-tests-kubectl-72l4b deletion completed in 22.124974181s

â€¢ [SLOW TEST:53.566 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:03:02.650: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:03:06.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-jm9nd" for this suite.
Mar 18 08:03:12.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:03:12.888: INFO: namespace: e2e-tests-kubelet-test-jm9nd, resource: bindings, ignored listing per whitelist
Mar 18 08:03:12.906: INFO: namespace e2e-tests-kubelet-test-jm9nd deletion completed in 6.135029602s

â€¢ [SLOW TEST:10.257 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:03:12.907: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Mar 18 08:03:13.006: INFO: Waiting up to 5m0s for pod "pod-47125319-4954-11e9-86d2-4ea95915efee" in namespace "e2e-tests-emptydir-f765f" to be "success or failure"
Mar 18 08:03:13.011: INFO: Pod "pod-47125319-4954-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 5.139006ms
Mar 18 08:03:15.014: INFO: Pod "pod-47125319-4954-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008437824s
STEP: Saw pod success
Mar 18 08:03:15.014: INFO: Pod "pod-47125319-4954-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:03:15.017: INFO: Trying to get logs from node worker01 pod pod-47125319-4954-11e9-86d2-4ea95915efee container test-container: <nil>
STEP: delete the pod
Mar 18 08:03:15.042: INFO: Waiting for pod pod-47125319-4954-11e9-86d2-4ea95915efee to disappear
Mar 18 08:03:15.046: INFO: Pod pod-47125319-4954-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:03:15.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-f765f" for this suite.
Mar 18 08:03:21.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:03:21.166: INFO: namespace: e2e-tests-emptydir-f765f, resource: bindings, ignored listing per whitelist
Mar 18 08:03:21.171: INFO: namespace e2e-tests-emptydir-f765f deletion completed in 6.120629146s

â€¢ [SLOW TEST:8.265 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:03:21.171: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Mar 18 08:03:21.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 --namespace=e2e-tests-kubectl-lxsfp run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Mar 18 08:03:22.970: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Mar 18 08:03:22.970: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:03:24.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lxsfp" for this suite.
Mar 18 08:03:32.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:03:33.081: INFO: namespace: e2e-tests-kubectl-lxsfp, resource: bindings, ignored listing per whitelist
Mar 18 08:03:33.105: INFO: namespace e2e-tests-kubectl-lxsfp deletion completed in 8.124111875s

â€¢ [SLOW TEST:11.934 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:03:33.106: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Mar 18 08:03:37.729: INFO: Successfully updated pod "pod-update-531dc5fa-4954-11e9-86d2-4ea95915efee"
STEP: verifying the updated pod is in kubernetes
Mar 18 08:03:37.745: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:03:37.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-qpclw" for this suite.
Mar 18 08:03:59.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:03:59.793: INFO: namespace: e2e-tests-pods-qpclw, resource: bindings, ignored listing per whitelist
Mar 18 08:03:59.863: INFO: namespace e2e-tests-pods-qpclw deletion completed in 22.113828018s

â€¢ [SLOW TEST:26.757 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:03:59.863: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 18 08:03:59.963: INFO: Waiting up to 5m0s for pod "downwardapi-volume-630fe6ec-4954-11e9-86d2-4ea95915efee" in namespace "e2e-tests-projected-mgj59" to be "success or failure"
Mar 18 08:03:59.968: INFO: Pod "downwardapi-volume-630fe6ec-4954-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 5.20711ms
Mar 18 08:04:01.975: INFO: Pod "downwardapi-volume-630fe6ec-4954-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012356958s
STEP: Saw pod success
Mar 18 08:04:01.975: INFO: Pod "downwardapi-volume-630fe6ec-4954-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:04:01.978: INFO: Trying to get logs from node worker02 pod downwardapi-volume-630fe6ec-4954-11e9-86d2-4ea95915efee container client-container: <nil>
STEP: delete the pod
Mar 18 08:04:02.004: INFO: Waiting for pod downwardapi-volume-630fe6ec-4954-11e9-86d2-4ea95915efee to disappear
Mar 18 08:04:02.006: INFO: Pod downwardapi-volume-630fe6ec-4954-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:04:02.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mgj59" for this suite.
Mar 18 08:04:08.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:04:08.074: INFO: namespace: e2e-tests-projected-mgj59, resource: bindings, ignored listing per whitelist
Mar 18 08:04:08.134: INFO: namespace e2e-tests-projected-mgj59 deletion completed in 6.122757072s

â€¢ [SLOW TEST:8.270 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:04:08.134: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-67fc908f-4954-11e9-86d2-4ea95915efee
STEP: Creating a pod to test consume configMaps
Mar 18 08:04:08.228: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-67fd1a90-4954-11e9-86d2-4ea95915efee" in namespace "e2e-tests-projected-g7rcb" to be "success or failure"
Mar 18 08:04:08.238: INFO: Pod "pod-projected-configmaps-67fd1a90-4954-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 9.806983ms
Mar 18 08:04:10.241: INFO: Pod "pod-projected-configmaps-67fd1a90-4954-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013232109s
STEP: Saw pod success
Mar 18 08:04:10.241: INFO: Pod "pod-projected-configmaps-67fd1a90-4954-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:04:10.245: INFO: Trying to get logs from node worker01 pod pod-projected-configmaps-67fd1a90-4954-11e9-86d2-4ea95915efee container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 18 08:04:10.263: INFO: Waiting for pod pod-projected-configmaps-67fd1a90-4954-11e9-86d2-4ea95915efee to disappear
Mar 18 08:04:10.267: INFO: Pod pod-projected-configmaps-67fd1a90-4954-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:04:10.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-g7rcb" for this suite.
Mar 18 08:04:16.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:04:16.305: INFO: namespace: e2e-tests-projected-g7rcb, resource: bindings, ignored listing per whitelist
Mar 18 08:04:16.392: INFO: namespace e2e-tests-projected-g7rcb deletion completed in 6.120912562s

â€¢ [SLOW TEST:8.258 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:04:16.393: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Mar 18 08:04:16.505: INFO: Waiting up to 5m0s for pod "pod-6ce8ac31-4954-11e9-86d2-4ea95915efee" in namespace "e2e-tests-emptydir-j9ls8" to be "success or failure"
Mar 18 08:04:16.517: INFO: Pod "pod-6ce8ac31-4954-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 11.92491ms
Mar 18 08:04:18.521: INFO: Pod "pod-6ce8ac31-4954-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015699957s
Mar 18 08:04:20.525: INFO: Pod "pod-6ce8ac31-4954-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019807323s
STEP: Saw pod success
Mar 18 08:04:20.525: INFO: Pod "pod-6ce8ac31-4954-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:04:20.528: INFO: Trying to get logs from node worker02 pod pod-6ce8ac31-4954-11e9-86d2-4ea95915efee container test-container: <nil>
STEP: delete the pod
Mar 18 08:04:20.546: INFO: Waiting for pod pod-6ce8ac31-4954-11e9-86d2-4ea95915efee to disappear
Mar 18 08:04:20.556: INFO: Pod pod-6ce8ac31-4954-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:04:20.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-j9ls8" for this suite.
Mar 18 08:04:26.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:04:26.654: INFO: namespace: e2e-tests-emptydir-j9ls8, resource: bindings, ignored listing per whitelist
Mar 18 08:04:26.701: INFO: namespace e2e-tests-emptydir-j9ls8 deletion completed in 6.139262054s

â€¢ [SLOW TEST:10.308 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:04:26.701: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 18 08:04:26.806: INFO: Pod name rollover-pod: Found 0 pods out of 1
Mar 18 08:04:31.813: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar 18 08:04:31.813: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Mar 18 08:04:33.818: INFO: Creating deployment "test-rollover-deployment"
Mar 18 08:04:33.824: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Mar 18 08:04:35.831: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Mar 18 08:04:35.836: INFO: Ensure that both replica sets have 1 created replica
Mar 18 08:04:35.842: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Mar 18 08:04:35.848: INFO: Updating deployment test-rollover-deployment
Mar 18 08:04:35.848: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Mar 18 08:04:37.862: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Mar 18 08:04:37.867: INFO: Make sure deployment "test-rollover-deployment" is complete
Mar 18 08:04:37.873: INFO: all replica sets need to contain the pod-template-hash label
Mar 18 08:04:37.873: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688493073, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688493073, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688493077, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688493073, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 18 08:04:39.881: INFO: all replica sets need to contain the pod-template-hash label
Mar 18 08:04:39.881: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688493073, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688493073, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688493077, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688493073, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 18 08:04:41.881: INFO: all replica sets need to contain the pod-template-hash label
Mar 18 08:04:41.881: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688493073, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688493073, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688493077, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688493073, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 18 08:04:43.880: INFO: all replica sets need to contain the pod-template-hash label
Mar 18 08:04:43.880: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688493073, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688493073, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688493077, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688493073, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 18 08:04:45.883: INFO: all replica sets need to contain the pod-template-hash label
Mar 18 08:04:45.883: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688493073, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688493073, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688493077, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688493073, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 18 08:04:47.881: INFO: 
Mar 18 08:04:47.881: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 18 08:04:47.891: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-hjf94,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-hjf94/deployments/test-rollover-deployment,UID:773e9762-4954-11e9-b44d-0022480537ee,ResourceVersion:193660,Generation:2,CreationTimestamp:2019-03-18 08:04:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-03-18 08:04:33 +0000 UTC 2019-03-18 08:04:33 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-03-18 08:04:47 +0000 UTC 2019-03-18 08:04:33 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Mar 18 08:04:47.894: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-hjf94,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-hjf94/replicasets/test-rollover-deployment-6b7f9d6597,UID:78747255-4954-11e9-b44d-0022480537ee,ResourceVersion:193651,Generation:2,CreationTimestamp:2019-03-18 08:04:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 773e9762-4954-11e9-b44d-0022480537ee 0xc00233de27 0xc00233de28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar 18 08:04:47.894: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Mar 18 08:04:47.894: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-hjf94,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-hjf94/replicasets/test-rollover-controller,UID:730fd0ad-4954-11e9-b44d-0022480537ee,ResourceVersion:193659,Generation:2,CreationTimestamp:2019-03-18 08:04:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 773e9762-4954-11e9-b44d-0022480537ee 0xc00233dc97 0xc00233dc98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 18 08:04:47.895: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-hjf94,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-hjf94/replicasets/test-rollover-deployment-6586df867b,UID:7741748c-4954-11e9-b44d-0022480537ee,ResourceVersion:193622,Generation:2,CreationTimestamp:2019-03-18 08:04:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 773e9762-4954-11e9-b44d-0022480537ee 0xc00233dd57 0xc00233dd58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 18 08:04:47.899: INFO: Pod "test-rollover-deployment-6b7f9d6597-j9j9l" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-j9j9l,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-hjf94,SelfLink:/api/v1/namespaces/e2e-tests-deployment-hjf94/pods/test-rollover-deployment-6b7f9d6597-j9j9l,UID:787a25aa-4954-11e9-b44d-0022480537ee,ResourceVersion:193632,Generation:0,CreationTimestamp:2019-03-18 08:04:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 78747255-4954-11e9-b44d-0022480537ee 0xc002200997 0xc002200998}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-s6pfs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s6pfs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-s6pfs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker01,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002200a10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002200a30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:04:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:04:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:04:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:04:35 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.5,PodIP:10.32.0.6,StartTime:2019-03-18 08:04:35 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-03-18 08:04:36 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://7b3061b1e0598031a46759c6e3eba87670779ef00d4986e2df288c49b61afc2e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:04:47.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-hjf94" for this suite.
Mar 18 08:04:53.913: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:04:53.941: INFO: namespace: e2e-tests-deployment-hjf94, resource: bindings, ignored listing per whitelist
Mar 18 08:04:54.019: INFO: namespace e2e-tests-deployment-hjf94 deletion completed in 6.115477899s

â€¢ [SLOW TEST:27.318 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:04:54.019: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-835a861f-4954-11e9-86d2-4ea95915efee
STEP: Creating a pod to test consume configMaps
Mar 18 08:04:54.143: INFO: Waiting up to 5m0s for pod "pod-configmaps-835b0e8c-4954-11e9-86d2-4ea95915efee" in namespace "e2e-tests-configmap-hd2cp" to be "success or failure"
Mar 18 08:04:54.154: INFO: Pod "pod-configmaps-835b0e8c-4954-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 10.682836ms
Mar 18 08:04:56.158: INFO: Pod "pod-configmaps-835b0e8c-4954-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014583843s
Mar 18 08:04:58.162: INFO: Pod "pod-configmaps-835b0e8c-4954-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018234535s
STEP: Saw pod success
Mar 18 08:04:58.162: INFO: Pod "pod-configmaps-835b0e8c-4954-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:04:58.165: INFO: Trying to get logs from node worker02 pod pod-configmaps-835b0e8c-4954-11e9-86d2-4ea95915efee container configmap-volume-test: <nil>
STEP: delete the pod
Mar 18 08:04:58.191: INFO: Waiting for pod pod-configmaps-835b0e8c-4954-11e9-86d2-4ea95915efee to disappear
Mar 18 08:04:58.194: INFO: Pod pod-configmaps-835b0e8c-4954-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:04:58.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-hd2cp" for this suite.
Mar 18 08:05:04.208: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:05:04.273: INFO: namespace: e2e-tests-configmap-hd2cp, resource: bindings, ignored listing per whitelist
Mar 18 08:05:04.305: INFO: namespace e2e-tests-configmap-hd2cp deletion completed in 6.106843985s

â€¢ [SLOW TEST:10.286 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:05:04.305: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-mlv6c
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Mar 18 08:05:04.408: INFO: Found 0 stateful pods, waiting for 3
Mar 18 08:05:14.412: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 18 08:05:14.412: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 18 08:05:14.412: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Mar 18 08:05:14.437: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Mar 18 08:05:24.468: INFO: Updating stateful set ss2
Mar 18 08:05:24.474: INFO: Waiting for Pod e2e-tests-statefulset-mlv6c/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Mar 18 08:05:34.522: INFO: Found 1 stateful pods, waiting for 3
Mar 18 08:05:44.526: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 18 08:05:44.526: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 18 08:05:44.526: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Mar 18 08:05:44.550: INFO: Updating stateful set ss2
Mar 18 08:05:44.578: INFO: Waiting for Pod e2e-tests-statefulset-mlv6c/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 18 08:05:54.602: INFO: Updating stateful set ss2
Mar 18 08:05:54.608: INFO: Waiting for StatefulSet e2e-tests-statefulset-mlv6c/ss2 to complete update
Mar 18 08:05:54.608: INFO: Waiting for Pod e2e-tests-statefulset-mlv6c/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 18 08:06:04.615: INFO: Deleting all statefulset in ns e2e-tests-statefulset-mlv6c
Mar 18 08:06:04.618: INFO: Scaling statefulset ss2 to 0
Mar 18 08:06:24.634: INFO: Waiting for statefulset status.replicas updated to 0
Mar 18 08:06:24.636: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:06:24.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-mlv6c" for this suite.
Mar 18 08:06:30.670: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:06:30.735: INFO: namespace: e2e-tests-statefulset-mlv6c, resource: bindings, ignored listing per whitelist
Mar 18 08:06:30.781: INFO: namespace e2e-tests-statefulset-mlv6c deletion completed in 6.127155794s

â€¢ [SLOW TEST:86.475 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:06:30.781: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Mar 18 08:06:35.407: INFO: Successfully updated pod "pod-update-activedeadlineseconds-bd03f04f-4954-11e9-86d2-4ea95915efee"
Mar 18 08:06:35.407: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-bd03f04f-4954-11e9-86d2-4ea95915efee" in namespace "e2e-tests-pods-kftx7" to be "terminated due to deadline exceeded"
Mar 18 08:06:35.418: INFO: Pod "pod-update-activedeadlineseconds-bd03f04f-4954-11e9-86d2-4ea95915efee": Phase="Running", Reason="", readiness=true. Elapsed: 10.357117ms
Mar 18 08:06:37.421: INFO: Pod "pod-update-activedeadlineseconds-bd03f04f-4954-11e9-86d2-4ea95915efee": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.013495579s
Mar 18 08:06:37.421: INFO: Pod "pod-update-activedeadlineseconds-bd03f04f-4954-11e9-86d2-4ea95915efee" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:06:37.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-kftx7" for this suite.
Mar 18 08:06:43.442: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:06:43.496: INFO: namespace: e2e-tests-pods-kftx7, resource: bindings, ignored listing per whitelist
Mar 18 08:06:43.546: INFO: namespace e2e-tests-pods-kftx7 deletion completed in 6.120642807s

â€¢ [SLOW TEST:12.765 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:06:43.546: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:07:43.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-5mhdx" for this suite.
Mar 18 08:08:05.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:08:05.683: INFO: namespace: e2e-tests-container-probe-5mhdx, resource: bindings, ignored listing per whitelist
Mar 18 08:08:05.780: INFO: namespace e2e-tests-container-probe-5mhdx deletion completed in 22.132210992s

â€¢ [SLOW TEST:82.234 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:08:05.780: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Mar 18 08:08:05.876: INFO: Waiting up to 5m0s for pod "pod-f5a309b5-4954-11e9-86d2-4ea95915efee" in namespace "e2e-tests-emptydir-vrk2g" to be "success or failure"
Mar 18 08:08:05.880: INFO: Pod "pod-f5a309b5-4954-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 3.763824ms
Mar 18 08:08:07.883: INFO: Pod "pod-f5a309b5-4954-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007278008s
STEP: Saw pod success
Mar 18 08:08:07.883: INFO: Pod "pod-f5a309b5-4954-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:08:07.887: INFO: Trying to get logs from node worker01 pod pod-f5a309b5-4954-11e9-86d2-4ea95915efee container test-container: <nil>
STEP: delete the pod
Mar 18 08:08:07.919: INFO: Waiting for pod pod-f5a309b5-4954-11e9-86d2-4ea95915efee to disappear
Mar 18 08:08:07.922: INFO: Pod pod-f5a309b5-4954-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:08:07.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-vrk2g" for this suite.
Mar 18 08:08:13.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:08:13.970: INFO: namespace: e2e-tests-emptydir-vrk2g, resource: bindings, ignored listing per whitelist
Mar 18 08:08:14.062: INFO: namespace e2e-tests-emptydir-vrk2g deletion completed in 6.135103168s

â€¢ [SLOW TEST:8.282 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:08:14.062: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 18 08:08:14.154: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fa927405-4954-11e9-86d2-4ea95915efee" in namespace "e2e-tests-downward-api-mbskl" to be "success or failure"
Mar 18 08:08:14.164: INFO: Pod "downwardapi-volume-fa927405-4954-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 9.982295ms
Mar 18 08:08:16.167: INFO: Pod "downwardapi-volume-fa927405-4954-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013006349s
STEP: Saw pod success
Mar 18 08:08:16.167: INFO: Pod "downwardapi-volume-fa927405-4954-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:08:16.170: INFO: Trying to get logs from node worker02 pod downwardapi-volume-fa927405-4954-11e9-86d2-4ea95915efee container client-container: <nil>
STEP: delete the pod
Mar 18 08:08:16.196: INFO: Waiting for pod downwardapi-volume-fa927405-4954-11e9-86d2-4ea95915efee to disappear
Mar 18 08:08:16.225: INFO: Pod downwardapi-volume-fa927405-4954-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:08:16.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-mbskl" for this suite.
Mar 18 08:08:22.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:08:22.342: INFO: namespace: e2e-tests-downward-api-mbskl, resource: bindings, ignored listing per whitelist
Mar 18 08:08:22.342: INFO: namespace e2e-tests-downward-api-mbskl deletion completed in 6.112704434s

â€¢ [SLOW TEST:8.280 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:08:22.342: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Mar 18 08:08:22.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 api-versions'
Mar 18 08:08:22.533: INFO: stderr: ""
Mar 18 08:08:22.533: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:08:22.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xqxxn" for this suite.
Mar 18 08:08:28.548: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:08:28.576: INFO: namespace: e2e-tests-kubectl-xqxxn, resource: bindings, ignored listing per whitelist
Mar 18 08:08:28.652: INFO: namespace e2e-tests-kubectl-xqxxn deletion completed in 6.11464705s

â€¢ [SLOW TEST:6.309 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:08:28.652: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Mar 18 08:08:39.785: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:08:40.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-r7rtb" for this suite.
Mar 18 08:09:02.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:09:02.890: INFO: namespace: e2e-tests-replicaset-r7rtb, resource: bindings, ignored listing per whitelist
Mar 18 08:09:02.926: INFO: namespace e2e-tests-replicaset-r7rtb deletion completed in 22.109872462s

â€¢ [SLOW TEST:34.274 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:09:02.926: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 18 08:09:03.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-7js8k'
Mar 18 08:09:03.118: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar 18 08:09:03.118: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Mar 18 08:09:05.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-7js8k'
Mar 18 08:09:05.222: INFO: stderr: ""
Mar 18 08:09:05.222: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:09:05.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7js8k" for this suite.
Mar 18 08:09:27.238: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:09:27.295: INFO: namespace: e2e-tests-kubectl-7js8k, resource: bindings, ignored listing per whitelist
Mar 18 08:09:27.343: INFO: namespace e2e-tests-kubectl-7js8k deletion completed in 22.116172337s

â€¢ [SLOW TEST:24.417 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:09:27.343: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:09:31.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-n86b8" for this suite.
Mar 18 08:10:09.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:10:09.505: INFO: namespace: e2e-tests-kubelet-test-n86b8, resource: bindings, ignored listing per whitelist
Mar 18 08:10:09.602: INFO: namespace e2e-tests-kubelet-test-n86b8 deletion completed in 38.127915434s

â€¢ [SLOW TEST:42.259 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:10:09.602: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 18 08:10:09.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-7zjd7'
Mar 18 08:10:09.787: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar 18 08:10:09.787: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Mar 18 08:10:09.803: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-lsbzf]
Mar 18 08:10:09.803: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-lsbzf" in namespace "e2e-tests-kubectl-7zjd7" to be "running and ready"
Mar 18 08:10:09.807: INFO: Pod "e2e-test-nginx-rc-lsbzf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.155047ms
Mar 18 08:10:11.810: INFO: Pod "e2e-test-nginx-rc-lsbzf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00781494s
Mar 18 08:10:13.815: INFO: Pod "e2e-test-nginx-rc-lsbzf": Phase="Running", Reason="", readiness=true. Elapsed: 4.012217776s
Mar 18 08:10:13.815: INFO: Pod "e2e-test-nginx-rc-lsbzf" satisfied condition "running and ready"
Mar 18 08:10:13.815: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-lsbzf]
Mar 18 08:10:13.815: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-7zjd7'
Mar 18 08:10:13.917: INFO: stderr: ""
Mar 18 08:10:13.917: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Mar 18 08:10:13.917: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-7zjd7'
Mar 18 08:10:14.001: INFO: stderr: ""
Mar 18 08:10:14.001: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:10:14.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7zjd7" for this suite.
Mar 18 08:10:20.024: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:10:20.124: INFO: namespace: e2e-tests-kubectl-7zjd7, resource: bindings, ignored listing per whitelist
Mar 18 08:10:20.126: INFO: namespace e2e-tests-kubectl-7zjd7 deletion completed in 6.120715111s

â€¢ [SLOW TEST:10.524 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:10:20.127: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar 18 08:10:24.748: INFO: Successfully updated pod "labelsupdate45b60018-4955-11e9-86d2-4ea95915efee"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:10:26.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-p6ssf" for this suite.
Mar 18 08:10:48.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:10:48.895: INFO: namespace: e2e-tests-downward-api-p6ssf, resource: bindings, ignored listing per whitelist
Mar 18 08:10:48.931: INFO: namespace e2e-tests-downward-api-p6ssf deletion completed in 22.126836673s

â€¢ [SLOW TEST:28.804 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:10:48.931: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-56e39d18-4955-11e9-86d2-4ea95915efee
STEP: Creating secret with name s-test-opt-upd-56e39d54-4955-11e9-86d2-4ea95915efee
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-56e39d18-4955-11e9-86d2-4ea95915efee
STEP: Updating secret s-test-opt-upd-56e39d54-4955-11e9-86d2-4ea95915efee
STEP: Creating secret with name s-test-opt-create-56e39d76-4955-11e9-86d2-4ea95915efee
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:11:59.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-rv9wq" for this suite.
Mar 18 08:12:21.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:12:21.535: INFO: namespace: e2e-tests-secrets-rv9wq, resource: bindings, ignored listing per whitelist
Mar 18 08:12:21.599: INFO: namespace e2e-tests-secrets-rv9wq deletion completed in 22.133582775s

â€¢ [SLOW TEST:92.667 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:12:21.599: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:12:44.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-cxwjw" for this suite.
Mar 18 08:12:50.936: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:12:51.020: INFO: namespace: e2e-tests-container-runtime-cxwjw, resource: bindings, ignored listing per whitelist
Mar 18 08:12:51.057: INFO: namespace e2e-tests-container-runtime-cxwjw deletion completed in 6.131761469s

â€¢ [SLOW TEST:29.458 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:12:51.057: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 18 08:12:51.179: INFO: Creating deployment "nginx-deployment"
Mar 18 08:12:51.182: INFO: Waiting for observed generation 1
Mar 18 08:12:53.189: INFO: Waiting for all required pods to come up
Mar 18 08:12:53.193: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Mar 18 08:12:55.211: INFO: Waiting for deployment "nginx-deployment" to complete
Mar 18 08:12:55.218: INFO: Updating deployment "nginx-deployment" with a non-existent image
Mar 18 08:12:55.226: INFO: Updating deployment nginx-deployment
Mar 18 08:12:55.226: INFO: Waiting for observed generation 2
Mar 18 08:12:57.239: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Mar 18 08:12:57.243: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Mar 18 08:12:57.245: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Mar 18 08:12:57.252: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Mar 18 08:12:57.252: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Mar 18 08:12:57.255: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Mar 18 08:12:57.261: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Mar 18 08:12:57.261: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Mar 18 08:12:57.267: INFO: Updating deployment nginx-deployment
Mar 18 08:12:57.267: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Mar 18 08:12:57.280: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Mar 18 08:12:57.285: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 18 08:12:57.350: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-nljv4,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-nljv4/deployments/nginx-deployment,UID:9fb1df24-4955-11e9-b44d-0022480537ee,ResourceVersion:195338,Generation:3,CreationTimestamp:2019-03-18 08:12:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Progressing True 2019-03-18 08:12:55 +0000 UTC 2019-03-18 08:12:51 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.} {Available False 2019-03-18 08:12:57 +0000 UTC 2019-03-18 08:12:57 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Mar 18 08:12:57.365: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-nljv4,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-nljv4/replicasets/nginx-deployment-65bbdb5f8,UID:a21b477e-4955-11e9-b44d-0022480537ee,ResourceVersion:195370,Generation:3,CreationTimestamp:2019-03-18 08:12:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 9fb1df24-4955-11e9-b44d-0022480537ee 0xc001c29767 0xc001c29768}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 18 08:12:57.365: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Mar 18 08:12:57.365: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-nljv4,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-nljv4/replicasets/nginx-deployment-555b55d965,UID:9fb2c682-4955-11e9-b44d-0022480537ee,ResourceVersion:195371,Generation:3,CreationTimestamp:2019-03-18 08:12:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 9fb1df24-4955-11e9-b44d-0022480537ee 0xc001c296a7 0xc001c296a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Mar 18 08:12:57.393: INFO: Pod "nginx-deployment-555b55d965-29b6n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-29b6n,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-nljv4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nljv4/pods/nginx-deployment-555b55d965-29b6n,UID:a35ae7b7-4955-11e9-b44d-0022480537ee,ResourceVersion:195374,Generation:0,CreationTimestamp:2019-03-18 08:12:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 9fb2c682-4955-11e9-b44d-0022480537ee 0xc001cca767 0xc001cca768}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jgzvb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgzvb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jgzvb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker01,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001cca7e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001cca800}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:57 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 08:12:57.393: INFO: Pod "nginx-deployment-555b55d965-5rrp9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-5rrp9,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-nljv4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nljv4/pods/nginx-deployment-555b55d965-5rrp9,UID:a35b82a6-4955-11e9-b44d-0022480537ee,ResourceVersion:195376,Generation:0,CreationTimestamp:2019-03-18 08:12:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 9fb2c682-4955-11e9-b44d-0022480537ee 0xc001ccaa60 0xc001ccaa61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jgzvb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgzvb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jgzvb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker01,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ccaad0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ccab10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:57 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 08:12:57.393: INFO: Pod "nginx-deployment-555b55d965-6tcjv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-6tcjv,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-nljv4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nljv4/pods/nginx-deployment-555b55d965-6tcjv,UID:a3586114-4955-11e9-b44d-0022480537ee,ResourceVersion:195366,Generation:0,CreationTimestamp:2019-03-18 08:12:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 9fb2c682-4955-11e9-b44d-0022480537ee 0xc001ccacd0 0xc001ccacd1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jgzvb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgzvb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jgzvb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker01,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ccad70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ccad90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:57 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 08:12:57.393: INFO: Pod "nginx-deployment-555b55d965-79w6r" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-79w6r,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-nljv4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nljv4/pods/nginx-deployment-555b55d965-79w6r,UID:a35baafc-4955-11e9-b44d-0022480537ee,ResourceVersion:195378,Generation:0,CreationTimestamp:2019-03-18 08:12:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 9fb2c682-4955-11e9-b44d-0022480537ee 0xc001ccae40 0xc001ccae41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jgzvb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgzvb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jgzvb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker02,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ccaef0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ccaff0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:57 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 08:12:57.394: INFO: Pod "nginx-deployment-555b55d965-8zsbf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-8zsbf,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-nljv4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nljv4/pods/nginx-deployment-555b55d965-8zsbf,UID:a35539b8-4955-11e9-b44d-0022480537ee,ResourceVersion:195342,Generation:0,CreationTimestamp:2019-03-18 08:12:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 9fb2c682-4955-11e9-b44d-0022480537ee 0xc001ccb060 0xc001ccb061}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jgzvb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgzvb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jgzvb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker02,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ccb0d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ccb0f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:57 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 08:12:57.394: INFO: Pod "nginx-deployment-555b55d965-bbt4f" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-bbt4f,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-nljv4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nljv4/pods/nginx-deployment-555b55d965-bbt4f,UID:9fb7a8e2-4955-11e9-b44d-0022480537ee,ResourceVersion:195250,Generation:0,CreationTimestamp:2019-03-18 08:12:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 9fb2c682-4955-11e9-b44d-0022480537ee 0xc001ccb550 0xc001ccb551}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jgzvb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgzvb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jgzvb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker02,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ccb5c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ccb5e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:51 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:53 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:53 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:51 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.4,PodIP:10.38.0.9,StartTime:2019-03-18 08:12:51 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-18 08:12:52 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://8b936b62f1870561000872b7aaca40740f318aeff8d8bc12da477ed8464f31ee}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 08:12:57.394: INFO: Pod "nginx-deployment-555b55d965-dh7nx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-dh7nx,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-nljv4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nljv4/pods/nginx-deployment-555b55d965-dh7nx,UID:9fb9af30-4955-11e9-b44d-0022480537ee,ResourceVersion:195253,Generation:0,CreationTimestamp:2019-03-18 08:12:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 9fb2c682-4955-11e9-b44d-0022480537ee 0xc001ccb730 0xc001ccb731}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jgzvb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgzvb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jgzvb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker02,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ccb7e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ccb800}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:51 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:53 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:53 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:51 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.4,PodIP:10.38.0.10,StartTime:2019-03-18 08:12:51 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-18 08:12:52 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://fa56635677dd7eac47f6ad4cc64607c333aa4ee172f812178643ede849747403}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 08:12:57.394: INFO: Pod "nginx-deployment-555b55d965-hgfcd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-hgfcd,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-nljv4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nljv4/pods/nginx-deployment-555b55d965-hgfcd,UID:9fb7bf39-4955-11e9-b44d-0022480537ee,ResourceVersion:195241,Generation:0,CreationTimestamp:2019-03-18 08:12:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 9fb2c682-4955-11e9-b44d-0022480537ee 0xc001ccb9c0 0xc001ccb9c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jgzvb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgzvb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jgzvb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker01,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ccba30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ccba50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:51 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:53 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:53 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:51 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.5,PodIP:10.32.0.7,StartTime:2019-03-18 08:12:51 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-18 08:12:53 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://3f5a05b05725fde0122e8268af64e8166d51b3f1f5f025876241d99b0cfdab8b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 08:12:57.394: INFO: Pod "nginx-deployment-555b55d965-hq7b2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-hq7b2,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-nljv4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nljv4/pods/nginx-deployment-555b55d965-hq7b2,UID:9fb5d984-4955-11e9-b44d-0022480537ee,ResourceVersion:195229,Generation:0,CreationTimestamp:2019-03-18 08:12:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 9fb2c682-4955-11e9-b44d-0022480537ee 0xc001ccbb80 0xc001ccbb81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jgzvb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgzvb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jgzvb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker01,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ccbc00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ccbc20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:51 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:53 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:53 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:51 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.5,PodIP:10.32.0.6,StartTime:2019-03-18 08:12:51 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-18 08:12:53 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://655efb4db51d080d9ea938b1f8b89082f4f88891c33dfee80eb6c6f0d3d96024}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 08:12:57.394: INFO: Pod "nginx-deployment-555b55d965-jbs5j" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-jbs5j,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-nljv4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nljv4/pods/nginx-deployment-555b55d965-jbs5j,UID:9fb9a565-4955-11e9-b44d-0022480537ee,ResourceVersion:195235,Generation:0,CreationTimestamp:2019-03-18 08:12:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 9fb2c682-4955-11e9-b44d-0022480537ee 0xc0010f2040 0xc0010f2041}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jgzvb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgzvb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jgzvb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker01,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0010f2330} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0010f2350}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:51 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:53 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:53 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:51 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.5,PodIP:10.32.0.9,StartTime:2019-03-18 08:12:51 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-18 08:12:53 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://c288b3a1a7fa062ee8f18e2ce2709aa76f970a78100b1d8bb1044a8e95ae76a0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 08:12:57.395: INFO: Pod "nginx-deployment-555b55d965-jf4zt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-jf4zt,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-nljv4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nljv4/pods/nginx-deployment-555b55d965-jf4zt,UID:9fb9962f-4955-11e9-b44d-0022480537ee,ResourceVersion:195247,Generation:0,CreationTimestamp:2019-03-18 08:12:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 9fb2c682-4955-11e9-b44d-0022480537ee 0xc0010f2690 0xc0010f2691}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jgzvb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgzvb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jgzvb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker02,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0010f2700} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0010f2720}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:51 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:53 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:53 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:51 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.4,PodIP:10.38.0.11,StartTime:2019-03-18 08:12:51 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-18 08:12:53 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://65b00e4baf59117bb829641ae325925b82d4aa4e67a842219577f9a6df50ef2f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 08:12:57.395: INFO: Pod "nginx-deployment-555b55d965-jt2x8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-jt2x8,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-nljv4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nljv4/pods/nginx-deployment-555b55d965-jt2x8,UID:a3552280-4955-11e9-b44d-0022480537ee,ResourceVersion:195350,Generation:0,CreationTimestamp:2019-03-18 08:12:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 9fb2c682-4955-11e9-b44d-0022480537ee 0xc0010f2860 0xc0010f2861}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jgzvb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgzvb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jgzvb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker01,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0010f28d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0010f28f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:57 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 08:12:57.395: INFO: Pod "nginx-deployment-555b55d965-kkscj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-kkscj,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-nljv4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nljv4/pods/nginx-deployment-555b55d965-kkscj,UID:9fb515f3-4955-11e9-b44d-0022480537ee,ResourceVersion:195232,Generation:0,CreationTimestamp:2019-03-18 08:12:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 9fb2c682-4955-11e9-b44d-0022480537ee 0xc0010f2960 0xc0010f2961}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jgzvb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgzvb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jgzvb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker01,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0010f2ab0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0010f2ad0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:51 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:53 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:53 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:51 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.5,PodIP:10.32.0.5,StartTime:2019-03-18 08:12:51 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-18 08:12:52 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://eb5f4b424e45ab7f0e755caa78cdc8ed6ca24f5f96ca36dce482166c46e58e1d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 08:12:57.395: INFO: Pod "nginx-deployment-555b55d965-l7z5g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-l7z5g,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-nljv4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nljv4/pods/nginx-deployment-555b55d965-l7z5g,UID:a3544f14-4955-11e9-b44d-0022480537ee,ResourceVersion:195362,Generation:0,CreationTimestamp:2019-03-18 08:12:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 9fb2c682-4955-11e9-b44d-0022480537ee 0xc0010f3850 0xc0010f3851}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jgzvb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgzvb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jgzvb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker01,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0010f38c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0010f38e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:57 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.5,PodIP:,StartTime:2019-03-18 08:12:57 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 08:12:57.395: INFO: Pod "nginx-deployment-555b55d965-m4jnh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-m4jnh,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-nljv4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nljv4/pods/nginx-deployment-555b55d965-m4jnh,UID:a3580f0f-4955-11e9-b44d-0022480537ee,ResourceVersion:195365,Generation:0,CreationTimestamp:2019-03-18 08:12:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 9fb2c682-4955-11e9-b44d-0022480537ee 0xc0010f3990 0xc0010f3991}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jgzvb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgzvb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jgzvb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker01,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0010f3a80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0010f3aa0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:57 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 08:12:57.396: INFO: Pod "nginx-deployment-555b55d965-pwrd2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-pwrd2,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-nljv4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nljv4/pods/nginx-deployment-555b55d965-pwrd2,UID:9fb7bbae-4955-11e9-b44d-0022480537ee,ResourceVersion:195256,Generation:0,CreationTimestamp:2019-03-18 08:12:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 9fb2c682-4955-11e9-b44d-0022480537ee 0xc0010f3b10 0xc0010f3b11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jgzvb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgzvb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jgzvb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker02,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0010f3b80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0010f3ba0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:51 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:53 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:53 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:51 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.4,PodIP:10.38.0.12,StartTime:2019-03-18 08:12:51 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-18 08:12:53 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://8aeea20fcc356cde39daffbfb71eb85e10d55208464e7a1a4be5d5e952e6fa29}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 08:12:57.396: INFO: Pod "nginx-deployment-555b55d965-s75kp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-s75kp,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-nljv4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nljv4/pods/nginx-deployment-555b55d965-s75kp,UID:a3582474-4955-11e9-b44d-0022480537ee,ResourceVersion:195364,Generation:0,CreationTimestamp:2019-03-18 08:12:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 9fb2c682-4955-11e9-b44d-0022480537ee 0xc0018720e0 0xc0018720e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jgzvb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgzvb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jgzvb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker02,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001872150} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001872170}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:57 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 08:12:57.396: INFO: Pod "nginx-deployment-555b55d965-sh56l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-sh56l,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-nljv4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nljv4/pods/nginx-deployment-555b55d965-sh56l,UID:a3584520-4955-11e9-b44d-0022480537ee,ResourceVersion:195356,Generation:0,CreationTimestamp:2019-03-18 08:12:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 9fb2c682-4955-11e9-b44d-0022480537ee 0xc0018721e0 0xc0018721e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jgzvb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgzvb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jgzvb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker02,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001872260} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001872280}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:57 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 08:12:57.396: INFO: Pod "nginx-deployment-555b55d965-w9bvr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-w9bvr,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-nljv4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nljv4/pods/nginx-deployment-555b55d965-w9bvr,UID:a35b8dfc-4955-11e9-b44d-0022480537ee,ResourceVersion:195375,Generation:0,CreationTimestamp:2019-03-18 08:12:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 9fb2c682-4955-11e9-b44d-0022480537ee 0xc0018723a0 0xc0018723a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jgzvb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgzvb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jgzvb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker02,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001872410} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001872430}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:57 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 08:12:57.396: INFO: Pod "nginx-deployment-555b55d965-xxxzk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-xxxzk,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-nljv4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nljv4/pods/nginx-deployment-555b55d965-xxxzk,UID:a35b7ff2-4955-11e9-b44d-0022480537ee,ResourceVersion:195377,Generation:0,CreationTimestamp:2019-03-18 08:12:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 9fb2c682-4955-11e9-b44d-0022480537ee 0xc0018724a0 0xc0018724a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jgzvb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgzvb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jgzvb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker02,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001872580} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018725a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:57 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 08:12:57.396: INFO: Pod "nginx-deployment-65bbdb5f8-56dbt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-56dbt,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-nljv4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nljv4/pods/nginx-deployment-65bbdb5f8-56dbt,UID:a355d711-4955-11e9-b44d-0022480537ee,ResourceVersion:195383,Generation:0,CreationTimestamp:2019-03-18 08:12:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 a21b477e-4955-11e9-b44d-0022480537ee 0xc001872610 0xc001872611}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jgzvb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgzvb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jgzvb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker01,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001872690} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018726b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:57 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.5,PodIP:,StartTime:2019-03-18 08:12:57 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 08:12:57.397: INFO: Pod "nginx-deployment-65bbdb5f8-8kkwc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-8kkwc,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-nljv4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nljv4/pods/nginx-deployment-65bbdb5f8-8kkwc,UID:a357be9e-4955-11e9-b44d-0022480537ee,ResourceVersion:195367,Generation:0,CreationTimestamp:2019-03-18 08:12:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 a21b477e-4955-11e9-b44d-0022480537ee 0xc001872770 0xc001872771}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jgzvb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgzvb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jgzvb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker02,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018727f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001872810}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:57 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 08:12:57.397: INFO: Pod "nginx-deployment-65bbdb5f8-8w7z5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-8w7z5,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-nljv4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nljv4/pods/nginx-deployment-65bbdb5f8-8w7z5,UID:a35837a8-4955-11e9-b44d-0022480537ee,ResourceVersion:195363,Generation:0,CreationTimestamp:2019-03-18 08:12:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 a21b477e-4955-11e9-b44d-0022480537ee 0xc001872890 0xc001872891}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jgzvb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgzvb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jgzvb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker02,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001872910} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001872930}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:57 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 08:12:57.397: INFO: Pod "nginx-deployment-65bbdb5f8-9n5p7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-9n5p7,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-nljv4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nljv4/pods/nginx-deployment-65bbdb5f8-9n5p7,UID:a21cab00-4955-11e9-b44d-0022480537ee,ResourceVersion:195282,Generation:0,CreationTimestamp:2019-03-18 08:12:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 a21b477e-4955-11e9-b44d-0022480537ee 0xc0018729a0 0xc0018729a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jgzvb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgzvb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jgzvb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker01,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001872a20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001872a40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:55 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.5,PodIP:,StartTime:2019-03-18 08:12:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 08:12:57.397: INFO: Pod "nginx-deployment-65bbdb5f8-dfq9c" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-dfq9c,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-nljv4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nljv4/pods/nginx-deployment-65bbdb5f8-dfq9c,UID:a35ac71d-4955-11e9-b44d-0022480537ee,ResourceVersion:195373,Generation:0,CreationTimestamp:2019-03-18 08:12:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 a21b477e-4955-11e9-b44d-0022480537ee 0xc001872b00 0xc001872b01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jgzvb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgzvb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jgzvb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker02,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001872b80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001872ba0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:57 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 08:12:57.397: INFO: Pod "nginx-deployment-65bbdb5f8-grr67" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-grr67,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-nljv4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nljv4/pods/nginx-deployment-65bbdb5f8-grr67,UID:a21e2c60-4955-11e9-b44d-0022480537ee,ResourceVersion:195289,Generation:0,CreationTimestamp:2019-03-18 08:12:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 a21b477e-4955-11e9-b44d-0022480537ee 0xc001872c10 0xc001872c11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jgzvb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgzvb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jgzvb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker01,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001872c90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001872cb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:55 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.5,PodIP:,StartTime:2019-03-18 08:12:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 08:12:57.397: INFO: Pod "nginx-deployment-65bbdb5f8-js5br" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-js5br,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-nljv4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nljv4/pods/nginx-deployment-65bbdb5f8-js5br,UID:a3582d48-4955-11e9-b44d-0022480537ee,ResourceVersion:195368,Generation:0,CreationTimestamp:2019-03-18 08:12:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 a21b477e-4955-11e9-b44d-0022480537ee 0xc001872d70 0xc001872d71}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jgzvb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgzvb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jgzvb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker01,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001872df0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001872e10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:57 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 08:12:57.398: INFO: Pod "nginx-deployment-65bbdb5f8-v22hp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-v22hp,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-nljv4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nljv4/pods/nginx-deployment-65bbdb5f8-v22hp,UID:a21dff0c-4955-11e9-b44d-0022480537ee,ResourceVersion:195286,Generation:0,CreationTimestamp:2019-03-18 08:12:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 a21b477e-4955-11e9-b44d-0022480537ee 0xc001872e80 0xc001872e81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jgzvb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgzvb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jgzvb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker02,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001872f00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001872f20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:55 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.4,PodIP:,StartTime:2019-03-18 08:12:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 08:12:57.398: INFO: Pod "nginx-deployment-65bbdb5f8-vgs25" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-vgs25,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-nljv4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nljv4/pods/nginx-deployment-65bbdb5f8-vgs25,UID:a227527e-4955-11e9-b44d-0022480537ee,ResourceVersion:195308,Generation:0,CreationTimestamp:2019-03-18 08:12:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 a21b477e-4955-11e9-b44d-0022480537ee 0xc001872fe0 0xc001872fe1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jgzvb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgzvb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jgzvb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker02,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001873060} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001873080}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:55 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.4,PodIP:,StartTime:2019-03-18 08:12:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 08:12:57.398: INFO: Pod "nginx-deployment-65bbdb5f8-vwjcq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-vwjcq,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-nljv4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nljv4/pods/nginx-deployment-65bbdb5f8-vwjcq,UID:a22962f2-4955-11e9-b44d-0022480537ee,ResourceVersion:195306,Generation:0,CreationTimestamp:2019-03-18 08:12:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 a21b477e-4955-11e9-b44d-0022480537ee 0xc001873140 0xc001873141}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jgzvb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgzvb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jgzvb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker01,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018731c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018731e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:55 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.5,PodIP:,StartTime:2019-03-18 08:12:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 08:12:57.398: INFO: Pod "nginx-deployment-65bbdb5f8-x7rq2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-x7rq2,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-nljv4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nljv4/pods/nginx-deployment-65bbdb5f8-x7rq2,UID:a355c530-4955-11e9-b44d-0022480537ee,ResourceVersion:195347,Generation:0,CreationTimestamp:2019-03-18 08:12:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 a21b477e-4955-11e9-b44d-0022480537ee 0xc0018732c0 0xc0018732c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jgzvb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgzvb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jgzvb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker02,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001873350} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001873370}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:57 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 08:12:57.398: INFO: Pod "nginx-deployment-65bbdb5f8-xlf8q" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-xlf8q,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-nljv4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nljv4/pods/nginx-deployment-65bbdb5f8-xlf8q,UID:a3585050-4955-11e9-b44d-0022480537ee,ResourceVersion:195361,Generation:0,CreationTimestamp:2019-03-18 08:12:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 a21b477e-4955-11e9-b44d-0022480537ee 0xc0018733e0 0xc0018733e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jgzvb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgzvb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jgzvb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker01,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001873470} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001873490}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:57 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 08:12:57.399: INFO: Pod "nginx-deployment-65bbdb5f8-z8cw7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-z8cw7,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-nljv4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nljv4/pods/nginx-deployment-65bbdb5f8-z8cw7,UID:a354dc14-4955-11e9-b44d-0022480537ee,ResourceVersion:195380,Generation:0,CreationTimestamp:2019-03-18 08:12:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 a21b477e-4955-11e9-b44d-0022480537ee 0xc001873500 0xc001873501}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jgzvb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jgzvb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jgzvb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker02,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001873580} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018735a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:12:57 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.4,PodIP:,StartTime:2019-03-18 08:12:57 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:12:57.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-nljv4" for this suite.
Mar 18 08:13:05.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:13:05.458: INFO: namespace: e2e-tests-deployment-nljv4, resource: bindings, ignored listing per whitelist
Mar 18 08:13:05.553: INFO: namespace e2e-tests-deployment-nljv4 deletion completed in 8.13524095s

â€¢ [SLOW TEST:14.496 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:13:05.554: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-bp48d A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-bp48d;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-bp48d A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-bp48d;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-bp48d.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-bp48d.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-bp48d.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-bp48d.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-bp48d.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-bp48d.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-bp48d.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-bp48d.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-bp48d.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-bp48d.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-bp48d.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-bp48d.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-bp48d.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 200.251.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.251.200_udp@PTR;check="$$(dig +tcp +noall +answer +search 200.251.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.251.200_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-bp48d A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-bp48d;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-bp48d A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-bp48d;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-bp48d.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-bp48d.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-bp48d.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-bp48d.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-bp48d.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-bp48d.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-bp48d.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-bp48d.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-bp48d.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-bp48d.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-bp48d.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-bp48d.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-bp48d.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 200.251.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.251.200_udp@PTR;check="$$(dig +tcp +noall +answer +search 200.251.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.251.200_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar 18 08:13:27.811: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-bp48d/dns-test-a85a905d-4955-11e9-86d2-4ea95915efee: the server could not find the requested resource (get pods dns-test-a85a905d-4955-11e9-86d2-4ea95915efee)
Mar 18 08:13:27.815: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-bp48d/dns-test-a85a905d-4955-11e9-86d2-4ea95915efee: the server could not find the requested resource (get pods dns-test-a85a905d-4955-11e9-86d2-4ea95915efee)
Mar 18 08:13:27.820: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-bp48d from pod e2e-tests-dns-bp48d/dns-test-a85a905d-4955-11e9-86d2-4ea95915efee: the server could not find the requested resource (get pods dns-test-a85a905d-4955-11e9-86d2-4ea95915efee)
Mar 18 08:13:27.824: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-bp48d from pod e2e-tests-dns-bp48d/dns-test-a85a905d-4955-11e9-86d2-4ea95915efee: the server could not find the requested resource (get pods dns-test-a85a905d-4955-11e9-86d2-4ea95915efee)
Mar 18 08:13:27.828: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-bp48d.svc from pod e2e-tests-dns-bp48d/dns-test-a85a905d-4955-11e9-86d2-4ea95915efee: the server could not find the requested resource (get pods dns-test-a85a905d-4955-11e9-86d2-4ea95915efee)
Mar 18 08:13:27.832: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-bp48d.svc from pod e2e-tests-dns-bp48d/dns-test-a85a905d-4955-11e9-86d2-4ea95915efee: the server could not find the requested resource (get pods dns-test-a85a905d-4955-11e9-86d2-4ea95915efee)
Mar 18 08:13:27.836: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-bp48d.svc from pod e2e-tests-dns-bp48d/dns-test-a85a905d-4955-11e9-86d2-4ea95915efee: the server could not find the requested resource (get pods dns-test-a85a905d-4955-11e9-86d2-4ea95915efee)
Mar 18 08:13:27.840: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-bp48d.svc from pod e2e-tests-dns-bp48d/dns-test-a85a905d-4955-11e9-86d2-4ea95915efee: the server could not find the requested resource (get pods dns-test-a85a905d-4955-11e9-86d2-4ea95915efee)
Mar 18 08:13:27.870: INFO: Lookups using e2e-tests-dns-bp48d/dns-test-a85a905d-4955-11e9-86d2-4ea95915efee failed for: [jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-bp48d jessie_tcp@dns-test-service.e2e-tests-dns-bp48d jessie_udp@dns-test-service.e2e-tests-dns-bp48d.svc jessie_tcp@dns-test-service.e2e-tests-dns-bp48d.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-bp48d.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-bp48d.svc]

Mar 18 08:13:32.948: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-bp48d/dns-test-a85a905d-4955-11e9-86d2-4ea95915efee: the server could not find the requested resource (get pods dns-test-a85a905d-4955-11e9-86d2-4ea95915efee)
Mar 18 08:13:32.953: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-bp48d/dns-test-a85a905d-4955-11e9-86d2-4ea95915efee: the server could not find the requested resource (get pods dns-test-a85a905d-4955-11e9-86d2-4ea95915efee)
Mar 18 08:13:32.958: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-bp48d from pod e2e-tests-dns-bp48d/dns-test-a85a905d-4955-11e9-86d2-4ea95915efee: the server could not find the requested resource (get pods dns-test-a85a905d-4955-11e9-86d2-4ea95915efee)
Mar 18 08:13:32.966: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-bp48d from pod e2e-tests-dns-bp48d/dns-test-a85a905d-4955-11e9-86d2-4ea95915efee: the server could not find the requested resource (get pods dns-test-a85a905d-4955-11e9-86d2-4ea95915efee)
Mar 18 08:13:32.970: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-bp48d.svc from pod e2e-tests-dns-bp48d/dns-test-a85a905d-4955-11e9-86d2-4ea95915efee: the server could not find the requested resource (get pods dns-test-a85a905d-4955-11e9-86d2-4ea95915efee)
Mar 18 08:13:32.974: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-bp48d.svc from pod e2e-tests-dns-bp48d/dns-test-a85a905d-4955-11e9-86d2-4ea95915efee: the server could not find the requested resource (get pods dns-test-a85a905d-4955-11e9-86d2-4ea95915efee)
Mar 18 08:13:32.979: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-bp48d.svc from pod e2e-tests-dns-bp48d/dns-test-a85a905d-4955-11e9-86d2-4ea95915efee: the server could not find the requested resource (get pods dns-test-a85a905d-4955-11e9-86d2-4ea95915efee)
Mar 18 08:13:32.983: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-bp48d.svc from pod e2e-tests-dns-bp48d/dns-test-a85a905d-4955-11e9-86d2-4ea95915efee: the server could not find the requested resource (get pods dns-test-a85a905d-4955-11e9-86d2-4ea95915efee)
Mar 18 08:13:33.006: INFO: Lookups using e2e-tests-dns-bp48d/dns-test-a85a905d-4955-11e9-86d2-4ea95915efee failed for: [jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-bp48d jessie_tcp@dns-test-service.e2e-tests-dns-bp48d jessie_udp@dns-test-service.e2e-tests-dns-bp48d.svc jessie_tcp@dns-test-service.e2e-tests-dns-bp48d.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-bp48d.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-bp48d.svc]

Mar 18 08:13:37.936: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-bp48d/dns-test-a85a905d-4955-11e9-86d2-4ea95915efee: the server could not find the requested resource (get pods dns-test-a85a905d-4955-11e9-86d2-4ea95915efee)
Mar 18 08:13:37.940: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-bp48d/dns-test-a85a905d-4955-11e9-86d2-4ea95915efee: the server could not find the requested resource (get pods dns-test-a85a905d-4955-11e9-86d2-4ea95915efee)
Mar 18 08:13:37.944: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-bp48d from pod e2e-tests-dns-bp48d/dns-test-a85a905d-4955-11e9-86d2-4ea95915efee: the server could not find the requested resource (get pods dns-test-a85a905d-4955-11e9-86d2-4ea95915efee)
Mar 18 08:13:37.949: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-bp48d from pod e2e-tests-dns-bp48d/dns-test-a85a905d-4955-11e9-86d2-4ea95915efee: the server could not find the requested resource (get pods dns-test-a85a905d-4955-11e9-86d2-4ea95915efee)
Mar 18 08:13:37.952: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-bp48d.svc from pod e2e-tests-dns-bp48d/dns-test-a85a905d-4955-11e9-86d2-4ea95915efee: the server could not find the requested resource (get pods dns-test-a85a905d-4955-11e9-86d2-4ea95915efee)
Mar 18 08:13:37.958: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-bp48d.svc from pod e2e-tests-dns-bp48d/dns-test-a85a905d-4955-11e9-86d2-4ea95915efee: the server could not find the requested resource (get pods dns-test-a85a905d-4955-11e9-86d2-4ea95915efee)
Mar 18 08:13:37.963: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-bp48d.svc from pod e2e-tests-dns-bp48d/dns-test-a85a905d-4955-11e9-86d2-4ea95915efee: the server could not find the requested resource (get pods dns-test-a85a905d-4955-11e9-86d2-4ea95915efee)
Mar 18 08:13:37.967: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-bp48d.svc from pod e2e-tests-dns-bp48d/dns-test-a85a905d-4955-11e9-86d2-4ea95915efee: the server could not find the requested resource (get pods dns-test-a85a905d-4955-11e9-86d2-4ea95915efee)
Mar 18 08:13:37.993: INFO: Lookups using e2e-tests-dns-bp48d/dns-test-a85a905d-4955-11e9-86d2-4ea95915efee failed for: [jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-bp48d jessie_tcp@dns-test-service.e2e-tests-dns-bp48d jessie_udp@dns-test-service.e2e-tests-dns-bp48d.svc jessie_tcp@dns-test-service.e2e-tests-dns-bp48d.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-bp48d.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-bp48d.svc]

Mar 18 08:13:42.937: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-bp48d/dns-test-a85a905d-4955-11e9-86d2-4ea95915efee: the server could not find the requested resource (get pods dns-test-a85a905d-4955-11e9-86d2-4ea95915efee)
Mar 18 08:13:42.941: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-bp48d/dns-test-a85a905d-4955-11e9-86d2-4ea95915efee: the server could not find the requested resource (get pods dns-test-a85a905d-4955-11e9-86d2-4ea95915efee)
Mar 18 08:13:42.945: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-bp48d from pod e2e-tests-dns-bp48d/dns-test-a85a905d-4955-11e9-86d2-4ea95915efee: the server could not find the requested resource (get pods dns-test-a85a905d-4955-11e9-86d2-4ea95915efee)
Mar 18 08:13:42.948: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-bp48d from pod e2e-tests-dns-bp48d/dns-test-a85a905d-4955-11e9-86d2-4ea95915efee: the server could not find the requested resource (get pods dns-test-a85a905d-4955-11e9-86d2-4ea95915efee)
Mar 18 08:13:42.951: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-bp48d.svc from pod e2e-tests-dns-bp48d/dns-test-a85a905d-4955-11e9-86d2-4ea95915efee: the server could not find the requested resource (get pods dns-test-a85a905d-4955-11e9-86d2-4ea95915efee)
Mar 18 08:13:42.955: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-bp48d.svc from pod e2e-tests-dns-bp48d/dns-test-a85a905d-4955-11e9-86d2-4ea95915efee: the server could not find the requested resource (get pods dns-test-a85a905d-4955-11e9-86d2-4ea95915efee)
Mar 18 08:13:42.959: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-bp48d.svc from pod e2e-tests-dns-bp48d/dns-test-a85a905d-4955-11e9-86d2-4ea95915efee: the server could not find the requested resource (get pods dns-test-a85a905d-4955-11e9-86d2-4ea95915efee)
Mar 18 08:13:42.963: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-bp48d.svc from pod e2e-tests-dns-bp48d/dns-test-a85a905d-4955-11e9-86d2-4ea95915efee: the server could not find the requested resource (get pods dns-test-a85a905d-4955-11e9-86d2-4ea95915efee)
Mar 18 08:13:43.003: INFO: Lookups using e2e-tests-dns-bp48d/dns-test-a85a905d-4955-11e9-86d2-4ea95915efee failed for: [jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-bp48d jessie_tcp@dns-test-service.e2e-tests-dns-bp48d jessie_udp@dns-test-service.e2e-tests-dns-bp48d.svc jessie_tcp@dns-test-service.e2e-tests-dns-bp48d.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-bp48d.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-bp48d.svc]

Mar 18 08:13:47.960: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-bp48d.svc from pod e2e-tests-dns-bp48d/dns-test-a85a905d-4955-11e9-86d2-4ea95915efee: the server could not find the requested resource (get pods dns-test-a85a905d-4955-11e9-86d2-4ea95915efee)
Mar 18 08:13:47.990: INFO: Lookups using e2e-tests-dns-bp48d/dns-test-a85a905d-4955-11e9-86d2-4ea95915efee failed for: [jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-bp48d.svc]

Mar 18 08:13:53.005: INFO: DNS probes using e2e-tests-dns-bp48d/dns-test-a85a905d-4955-11e9-86d2-4ea95915efee succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:13:53.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-bp48d" for this suite.
Mar 18 08:13:59.089: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:13:59.181: INFO: namespace: e2e-tests-dns-bp48d, resource: bindings, ignored listing per whitelist
Mar 18 08:13:59.192: INFO: namespace e2e-tests-dns-bp48d deletion completed in 6.112627829s

â€¢ [SLOW TEST:53.638 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:13:59.192: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Mar 18 08:14:03.397: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 18 08:14:03.405: INFO: Pod pod-with-poststart-http-hook still exists
Mar 18 08:14:05.405: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 18 08:14:05.409: INFO: Pod pod-with-poststart-http-hook still exists
Mar 18 08:14:07.406: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 18 08:14:07.410: INFO: Pod pod-with-poststart-http-hook still exists
Mar 18 08:14:09.406: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 18 08:14:09.409: INFO: Pod pod-with-poststart-http-hook still exists
Mar 18 08:14:11.406: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 18 08:14:11.409: INFO: Pod pod-with-poststart-http-hook still exists
Mar 18 08:14:13.406: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 18 08:14:13.409: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:14:13.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-mc9h8" for this suite.
Mar 18 08:14:35.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:14:35.525: INFO: namespace: e2e-tests-container-lifecycle-hook-mc9h8, resource: bindings, ignored listing per whitelist
Mar 18 08:14:35.534: INFO: namespace e2e-tests-container-lifecycle-hook-mc9h8 deletion completed in 22.120616602s

â€¢ [SLOW TEST:36.342 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:14:35.534: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Mar 18 08:14:35.898: INFO: Pod name wrapped-volume-race-de17fca1-4955-11e9-86d2-4ea95915efee: Found 0 pods out of 5
Mar 18 08:14:40.906: INFO: Pod name wrapped-volume-race-de17fca1-4955-11e9-86d2-4ea95915efee: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-de17fca1-4955-11e9-86d2-4ea95915efee in namespace e2e-tests-emptydir-wrapper-vgc7l, will wait for the garbage collector to delete the pods
Mar 18 08:14:50.983: INFO: Deleting ReplicationController wrapped-volume-race-de17fca1-4955-11e9-86d2-4ea95915efee took: 5.480026ms
Mar 18 08:14:51.083: INFO: Terminating ReplicationController wrapped-volume-race-de17fca1-4955-11e9-86d2-4ea95915efee pods took: 100.255569ms
STEP: Creating RC which spawns configmap-volume pods
Mar 18 08:15:34.904: INFO: Pod name wrapped-volume-race-0145457e-4956-11e9-86d2-4ea95915efee: Found 0 pods out of 5
Mar 18 08:15:39.912: INFO: Pod name wrapped-volume-race-0145457e-4956-11e9-86d2-4ea95915efee: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-0145457e-4956-11e9-86d2-4ea95915efee in namespace e2e-tests-emptydir-wrapper-vgc7l, will wait for the garbage collector to delete the pods
Mar 18 08:15:51.990: INFO: Deleting ReplicationController wrapped-volume-race-0145457e-4956-11e9-86d2-4ea95915efee took: 5.597333ms
Mar 18 08:15:52.090: INFO: Terminating ReplicationController wrapped-volume-race-0145457e-4956-11e9-86d2-4ea95915efee pods took: 100.219267ms
STEP: Creating RC which spawns configmap-volume pods
Mar 18 08:16:26.114: INFO: Pod name wrapped-volume-race-1fcaca7b-4956-11e9-86d2-4ea95915efee: Found 0 pods out of 5
Mar 18 08:16:31.122: INFO: Pod name wrapped-volume-race-1fcaca7b-4956-11e9-86d2-4ea95915efee: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-1fcaca7b-4956-11e9-86d2-4ea95915efee in namespace e2e-tests-emptydir-wrapper-vgc7l, will wait for the garbage collector to delete the pods
Mar 18 08:16:43.199: INFO: Deleting ReplicationController wrapped-volume-race-1fcaca7b-4956-11e9-86d2-4ea95915efee took: 5.147106ms
Mar 18 08:16:43.299: INFO: Terminating ReplicationController wrapped-volume-race-1fcaca7b-4956-11e9-86d2-4ea95915efee pods took: 100.204366ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:17:25.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-vgc7l" for this suite.
Mar 18 08:17:33.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:17:33.213: INFO: namespace: e2e-tests-emptydir-wrapper-vgc7l, resource: bindings, ignored listing per whitelist
Mar 18 08:17:33.314: INFO: namespace e2e-tests-emptydir-wrapper-vgc7l deletion completed in 8.137052258s

â€¢ [SLOW TEST:177.780 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:17:33.315: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Mar 18 08:17:33.405: INFO: Waiting up to 5m0s for pod "pod-47e927c8-4956-11e9-86d2-4ea95915efee" in namespace "e2e-tests-emptydir-b7dsr" to be "success or failure"
Mar 18 08:17:33.412: INFO: Pod "pod-47e927c8-4956-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 7.342037ms
Mar 18 08:17:35.415: INFO: Pod "pod-47e927c8-4956-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010571904s
Mar 18 08:17:37.418: INFO: Pod "pod-47e927c8-4956-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013610359s
STEP: Saw pod success
Mar 18 08:17:37.418: INFO: Pod "pod-47e927c8-4956-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:17:37.421: INFO: Trying to get logs from node worker01 pod pod-47e927c8-4956-11e9-86d2-4ea95915efee container test-container: <nil>
STEP: delete the pod
Mar 18 08:17:37.440: INFO: Waiting for pod pod-47e927c8-4956-11e9-86d2-4ea95915efee to disappear
Mar 18 08:17:37.444: INFO: Pod pod-47e927c8-4956-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:17:37.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-b7dsr" for this suite.
Mar 18 08:17:43.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:17:43.545: INFO: namespace: e2e-tests-emptydir-b7dsr, resource: bindings, ignored listing per whitelist
Mar 18 08:17:43.581: INFO: namespace e2e-tests-emptydir-b7dsr deletion completed in 6.133101349s

â€¢ [SLOW TEST:10.267 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:17:43.582: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 18 08:17:43.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-9gxbr'
Mar 18 08:17:44.653: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar 18 08:17:44.653: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Mar 18 08:17:48.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-9gxbr'
Mar 18 08:17:48.764: INFO: stderr: ""
Mar 18 08:17:48.764: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:17:48.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9gxbr" for this suite.
Mar 18 08:18:10.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:18:10.839: INFO: namespace: e2e-tests-kubectl-9gxbr, resource: bindings, ignored listing per whitelist
Mar 18 08:18:10.890: INFO: namespace e2e-tests-kubectl-9gxbr deletion completed in 22.122086289s

â€¢ [SLOW TEST:27.309 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:18:10.891: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Mar 18 08:18:10.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 create -f - --namespace=e2e-tests-kubectl-52l8w'
Mar 18 08:18:11.229: INFO: stderr: ""
Mar 18 08:18:11.229: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar 18 08:18:12.233: INFO: Selector matched 1 pods for map[app:redis]
Mar 18 08:18:12.233: INFO: Found 0 / 1
Mar 18 08:18:13.232: INFO: Selector matched 1 pods for map[app:redis]
Mar 18 08:18:13.232: INFO: Found 0 / 1
Mar 18 08:18:14.234: INFO: Selector matched 1 pods for map[app:redis]
Mar 18 08:18:14.234: INFO: Found 1 / 1
Mar 18 08:18:14.234: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Mar 18 08:18:14.238: INFO: Selector matched 1 pods for map[app:redis]
Mar 18 08:18:14.238: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar 18 08:18:14.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 patch pod redis-master-nr5k5 --namespace=e2e-tests-kubectl-52l8w -p {"metadata":{"annotations":{"x":"y"}}}'
Mar 18 08:18:14.327: INFO: stderr: ""
Mar 18 08:18:14.327: INFO: stdout: "pod/redis-master-nr5k5 patched\n"
STEP: checking annotations
Mar 18 08:18:14.331: INFO: Selector matched 1 pods for map[app:redis]
Mar 18 08:18:14.331: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:18:14.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-52l8w" for this suite.
Mar 18 08:18:36.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:18:36.387: INFO: namespace: e2e-tests-kubectl-52l8w, resource: bindings, ignored listing per whitelist
Mar 18 08:18:36.463: INFO: namespace e2e-tests-kubectl-52l8w deletion completed in 22.127346203s

â€¢ [SLOW TEST:25.572 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:18:36.463: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Mar 18 08:18:36.563: INFO: Waiting up to 5m0s for pod "pod-6d8e6f15-4956-11e9-86d2-4ea95915efee" in namespace "e2e-tests-emptydir-6rwgc" to be "success or failure"
Mar 18 08:18:36.568: INFO: Pod "pod-6d8e6f15-4956-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 5.143307ms
Mar 18 08:18:38.572: INFO: Pod "pod-6d8e6f15-4956-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008777498s
STEP: Saw pod success
Mar 18 08:18:38.572: INFO: Pod "pod-6d8e6f15-4956-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:18:38.574: INFO: Trying to get logs from node worker02 pod pod-6d8e6f15-4956-11e9-86d2-4ea95915efee container test-container: <nil>
STEP: delete the pod
Mar 18 08:18:38.601: INFO: Waiting for pod pod-6d8e6f15-4956-11e9-86d2-4ea95915efee to disappear
Mar 18 08:18:38.604: INFO: Pod pod-6d8e6f15-4956-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:18:38.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-6rwgc" for this suite.
Mar 18 08:18:44.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:18:44.671: INFO: namespace: e2e-tests-emptydir-6rwgc, resource: bindings, ignored listing per whitelist
Mar 18 08:18:44.723: INFO: namespace e2e-tests-emptydir-6rwgc deletion completed in 6.114108517s

â€¢ [SLOW TEST:8.260 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:18:44.723: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Mar 18 08:18:52.862: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 18 08:18:52.871: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 18 08:18:54.872: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 18 08:18:54.876: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 18 08:18:56.872: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 18 08:18:56.875: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 18 08:18:58.872: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 18 08:18:58.875: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 18 08:19:00.872: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 18 08:19:00.875: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 18 08:19:02.872: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 18 08:19:02.876: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 18 08:19:04.872: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 18 08:19:04.875: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 18 08:19:06.872: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 18 08:19:06.875: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 18 08:19:08.872: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 18 08:19:08.875: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 18 08:19:10.872: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 18 08:19:10.876: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 18 08:19:12.872: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 18 08:19:12.875: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 18 08:19:14.872: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 18 08:19:14.875: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 18 08:19:16.872: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 18 08:19:16.875: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 18 08:19:18.872: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 18 08:19:18.876: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 18 08:19:20.876: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 18 08:19:20.880: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 18 08:19:22.872: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 18 08:19:22.875: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:19:22.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-5l57k" for this suite.
Mar 18 08:19:44.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:19:44.980: INFO: namespace: e2e-tests-container-lifecycle-hook-5l57k, resource: bindings, ignored listing per whitelist
Mar 18 08:19:44.999: INFO: namespace e2e-tests-container-lifecycle-hook-5l57k deletion completed in 22.118668086s

â€¢ [SLOW TEST:60.276 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:19:44.999: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Mar 18 08:19:45.109: INFO: Waiting up to 5m0s for pod "pod-9668df55-4956-11e9-86d2-4ea95915efee" in namespace "e2e-tests-emptydir-mpbtn" to be "success or failure"
Mar 18 08:19:45.114: INFO: Pod "pod-9668df55-4956-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 5.122805ms
Mar 18 08:19:47.119: INFO: Pod "pod-9668df55-4956-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009817159s
STEP: Saw pod success
Mar 18 08:19:47.119: INFO: Pod "pod-9668df55-4956-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:19:47.121: INFO: Trying to get logs from node worker01 pod pod-9668df55-4956-11e9-86d2-4ea95915efee container test-container: <nil>
STEP: delete the pod
Mar 18 08:19:47.150: INFO: Waiting for pod pod-9668df55-4956-11e9-86d2-4ea95915efee to disappear
Mar 18 08:19:47.153: INFO: Pod pod-9668df55-4956-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:19:47.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-mpbtn" for this suite.
Mar 18 08:19:53.184: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:19:53.290: INFO: namespace: e2e-tests-emptydir-mpbtn, resource: bindings, ignored listing per whitelist
Mar 18 08:19:53.321: INFO: namespace e2e-tests-emptydir-mpbtn deletion completed in 6.163179439s

â€¢ [SLOW TEST:8.322 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:19:53.321: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Mar 18 08:19:53.917: INFO: Waiting up to 5m0s for pod "pod-service-account-9ba9d110-4956-11e9-86d2-4ea95915efee-mzdmz" in namespace "e2e-tests-svcaccounts-8tbs6" to be "success or failure"
Mar 18 08:19:53.932: INFO: Pod "pod-service-account-9ba9d110-4956-11e9-86d2-4ea95915efee-mzdmz": Phase="Pending", Reason="", readiness=false. Elapsed: 14.930288ms
Mar 18 08:19:55.936: INFO: Pod "pod-service-account-9ba9d110-4956-11e9-86d2-4ea95915efee-mzdmz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018828595s
STEP: Saw pod success
Mar 18 08:19:55.936: INFO: Pod "pod-service-account-9ba9d110-4956-11e9-86d2-4ea95915efee-mzdmz" satisfied condition "success or failure"
Mar 18 08:19:55.939: INFO: Trying to get logs from node worker02 pod pod-service-account-9ba9d110-4956-11e9-86d2-4ea95915efee-mzdmz container token-test: <nil>
STEP: delete the pod
Mar 18 08:19:55.963: INFO: Waiting for pod pod-service-account-9ba9d110-4956-11e9-86d2-4ea95915efee-mzdmz to disappear
Mar 18 08:19:55.965: INFO: Pod pod-service-account-9ba9d110-4956-11e9-86d2-4ea95915efee-mzdmz no longer exists
STEP: Creating a pod to test consume service account root CA
Mar 18 08:19:55.975: INFO: Waiting up to 5m0s for pod "pod-service-account-9ba9d110-4956-11e9-86d2-4ea95915efee-2gz8w" in namespace "e2e-tests-svcaccounts-8tbs6" to be "success or failure"
Mar 18 08:19:55.978: INFO: Pod "pod-service-account-9ba9d110-4956-11e9-86d2-4ea95915efee-2gz8w": Phase="Pending", Reason="", readiness=false. Elapsed: 2.544552ms
Mar 18 08:19:57.981: INFO: Pod "pod-service-account-9ba9d110-4956-11e9-86d2-4ea95915efee-2gz8w": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006313251s
STEP: Saw pod success
Mar 18 08:19:57.981: INFO: Pod "pod-service-account-9ba9d110-4956-11e9-86d2-4ea95915efee-2gz8w" satisfied condition "success or failure"
Mar 18 08:19:57.984: INFO: Trying to get logs from node worker01 pod pod-service-account-9ba9d110-4956-11e9-86d2-4ea95915efee-2gz8w container root-ca-test: <nil>
STEP: delete the pod
Mar 18 08:19:58.007: INFO: Waiting for pod pod-service-account-9ba9d110-4956-11e9-86d2-4ea95915efee-2gz8w to disappear
Mar 18 08:19:58.010: INFO: Pod pod-service-account-9ba9d110-4956-11e9-86d2-4ea95915efee-2gz8w no longer exists
STEP: Creating a pod to test consume service account namespace
Mar 18 08:19:58.014: INFO: Waiting up to 5m0s for pod "pod-service-account-9ba9d110-4956-11e9-86d2-4ea95915efee-vf92n" in namespace "e2e-tests-svcaccounts-8tbs6" to be "success or failure"
Mar 18 08:19:58.024: INFO: Pod "pod-service-account-9ba9d110-4956-11e9-86d2-4ea95915efee-vf92n": Phase="Pending", Reason="", readiness=false. Elapsed: 9.589371ms
Mar 18 08:20:00.026: INFO: Pod "pod-service-account-9ba9d110-4956-11e9-86d2-4ea95915efee-vf92n": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012428515s
STEP: Saw pod success
Mar 18 08:20:00.026: INFO: Pod "pod-service-account-9ba9d110-4956-11e9-86d2-4ea95915efee-vf92n" satisfied condition "success or failure"
Mar 18 08:20:00.033: INFO: Trying to get logs from node worker02 pod pod-service-account-9ba9d110-4956-11e9-86d2-4ea95915efee-vf92n container namespace-test: <nil>
STEP: delete the pod
Mar 18 08:20:00.096: INFO: Waiting for pod pod-service-account-9ba9d110-4956-11e9-86d2-4ea95915efee-vf92n to disappear
Mar 18 08:20:00.099: INFO: Pod pod-service-account-9ba9d110-4956-11e9-86d2-4ea95915efee-vf92n no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:20:00.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-8tbs6" for this suite.
Mar 18 08:20:06.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:20:06.207: INFO: namespace: e2e-tests-svcaccounts-8tbs6, resource: bindings, ignored listing per whitelist
Mar 18 08:20:06.229: INFO: namespace e2e-tests-svcaccounts-8tbs6 deletion completed in 6.125223579s

â€¢ [SLOW TEST:12.907 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:20:06.229: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 18 08:20:06.330: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a30fe9dc-4956-11e9-86d2-4ea95915efee" in namespace "e2e-tests-projected-nfl47" to be "success or failure"
Mar 18 08:20:06.341: INFO: Pod "downwardapi-volume-a30fe9dc-4956-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 11.110261ms
Mar 18 08:20:08.345: INFO: Pod "downwardapi-volume-a30fe9dc-4956-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014776954s
STEP: Saw pod success
Mar 18 08:20:08.345: INFO: Pod "downwardapi-volume-a30fe9dc-4956-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:20:08.348: INFO: Trying to get logs from node worker01 pod downwardapi-volume-a30fe9dc-4956-11e9-86d2-4ea95915efee container client-container: <nil>
STEP: delete the pod
Mar 18 08:20:08.388: INFO: Waiting for pod downwardapi-volume-a30fe9dc-4956-11e9-86d2-4ea95915efee to disappear
Mar 18 08:20:08.392: INFO: Pod downwardapi-volume-a30fe9dc-4956-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:20:08.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nfl47" for this suite.
Mar 18 08:20:14.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:20:14.558: INFO: namespace: e2e-tests-projected-nfl47, resource: bindings, ignored listing per whitelist
Mar 18 08:20:14.558: INFO: namespace e2e-tests-projected-nfl47 deletion completed in 6.161015811s

â€¢ [SLOW TEST:8.329 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:20:14.558: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-a8080bbf-4956-11e9-86d2-4ea95915efee
STEP: Creating configMap with name cm-test-opt-upd-a8080bf5-4956-11e9-86d2-4ea95915efee
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-a8080bbf-4956-11e9-86d2-4ea95915efee
STEP: Updating configmap cm-test-opt-upd-a8080bf5-4956-11e9-86d2-4ea95915efee
STEP: Creating configMap with name cm-test-opt-create-a8080c0c-4956-11e9-86d2-4ea95915efee
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:21:27.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sr686" for this suite.
Mar 18 08:21:49.205: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:21:49.306: INFO: namespace: e2e-tests-projected-sr686, resource: bindings, ignored listing per whitelist
Mar 18 08:21:49.309: INFO: namespace e2e-tests-projected-sr686 deletion completed in 22.114497715s

â€¢ [SLOW TEST:94.751 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:21:49.309: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 18 08:21:49.413: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e08122b9-4956-11e9-86d2-4ea95915efee" in namespace "e2e-tests-downward-api-7gj9b" to be "success or failure"
Mar 18 08:21:49.417: INFO: Pod "downwardapi-volume-e08122b9-4956-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 4.042742ms
Mar 18 08:21:51.421: INFO: Pod "downwardapi-volume-e08122b9-4956-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007762865s
STEP: Saw pod success
Mar 18 08:21:51.421: INFO: Pod "downwardapi-volume-e08122b9-4956-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:21:51.424: INFO: Trying to get logs from node worker01 pod downwardapi-volume-e08122b9-4956-11e9-86d2-4ea95915efee container client-container: <nil>
STEP: delete the pod
Mar 18 08:21:51.448: INFO: Waiting for pod downwardapi-volume-e08122b9-4956-11e9-86d2-4ea95915efee to disappear
Mar 18 08:21:51.484: INFO: Pod downwardapi-volume-e08122b9-4956-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:21:51.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7gj9b" for this suite.
Mar 18 08:21:57.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:21:57.578: INFO: namespace: e2e-tests-downward-api-7gj9b, resource: bindings, ignored listing per whitelist
Mar 18 08:21:57.610: INFO: namespace e2e-tests-downward-api-7gj9b deletion completed in 6.121435353s

â€¢ [SLOW TEST:8.301 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:21:57.610: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 18 08:21:57.709: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e57256d9-4956-11e9-86d2-4ea95915efee" in namespace "e2e-tests-projected-kvb85" to be "success or failure"
Mar 18 08:21:57.722: INFO: Pod "downwardapi-volume-e57256d9-4956-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 13.185388ms
Mar 18 08:21:59.726: INFO: Pod "downwardapi-volume-e57256d9-4956-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016863608s
STEP: Saw pod success
Mar 18 08:21:59.726: INFO: Pod "downwardapi-volume-e57256d9-4956-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:21:59.729: INFO: Trying to get logs from node worker02 pod downwardapi-volume-e57256d9-4956-11e9-86d2-4ea95915efee container client-container: <nil>
STEP: delete the pod
Mar 18 08:21:59.757: INFO: Waiting for pod downwardapi-volume-e57256d9-4956-11e9-86d2-4ea95915efee to disappear
Mar 18 08:21:59.759: INFO: Pod downwardapi-volume-e57256d9-4956-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:21:59.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kvb85" for this suite.
Mar 18 08:22:05.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:22:05.878: INFO: namespace: e2e-tests-projected-kvb85, resource: bindings, ignored listing per whitelist
Mar 18 08:22:05.878: INFO: namespace e2e-tests-projected-kvb85 deletion completed in 6.114380532s

â€¢ [SLOW TEST:8.268 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:22:05.879: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Mar 18 08:22:14.014: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-54c44 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 18 08:22:14.014: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
Mar 18 08:22:14.134: INFO: Exec stderr: ""
Mar 18 08:22:14.134: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-54c44 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 18 08:22:14.134: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
Mar 18 08:22:14.249: INFO: Exec stderr: ""
Mar 18 08:22:14.249: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-54c44 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 18 08:22:14.249: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
Mar 18 08:22:14.355: INFO: Exec stderr: ""
Mar 18 08:22:14.355: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-54c44 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 18 08:22:14.355: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
Mar 18 08:22:14.475: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Mar 18 08:22:14.475: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-54c44 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 18 08:22:14.475: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
Mar 18 08:22:14.585: INFO: Exec stderr: ""
Mar 18 08:22:14.585: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-54c44 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 18 08:22:14.585: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
Mar 18 08:22:14.712: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Mar 18 08:22:14.712: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-54c44 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 18 08:22:14.712: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
Mar 18 08:22:14.828: INFO: Exec stderr: ""
Mar 18 08:22:14.828: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-54c44 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 18 08:22:14.828: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
Mar 18 08:22:14.937: INFO: Exec stderr: ""
Mar 18 08:22:14.937: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-54c44 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 18 08:22:14.937: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
Mar 18 08:22:15.055: INFO: Exec stderr: ""
Mar 18 08:22:15.055: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-54c44 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 18 08:22:15.055: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
Mar 18 08:22:15.185: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:22:15.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-54c44" for this suite.
Mar 18 08:22:53.201: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:22:53.294: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-54c44, resource: bindings, ignored listing per whitelist
Mar 18 08:22:53.304: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-54c44 deletion completed in 38.113801318s

â€¢ [SLOW TEST:47.425 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:22:53.304: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Mar 18 08:22:53.405: INFO: Pod name pod-release: Found 0 pods out of 1
Mar 18 08:22:58.408: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:22:59.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-b5j5z" for this suite.
Mar 18 08:23:05.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:23:05.457: INFO: namespace: e2e-tests-replication-controller-b5j5z, resource: bindings, ignored listing per whitelist
Mar 18 08:23:05.563: INFO: namespace e2e-tests-replication-controller-b5j5z deletion completed in 6.137574817s

â€¢ [SLOW TEST:12.259 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:23:05.564: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:23:11.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-rtmn7" for this suite.
Mar 18 08:23:17.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:23:17.817: INFO: namespace: e2e-tests-namespaces-rtmn7, resource: bindings, ignored listing per whitelist
Mar 18 08:23:17.921: INFO: namespace e2e-tests-namespaces-rtmn7 deletion completed in 6.123486476s
STEP: Destroying namespace "e2e-tests-nsdeletetest-9slgg" for this suite.
Mar 18 08:23:17.925: INFO: Namespace e2e-tests-nsdeletetest-9slgg was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-xqxtx" for this suite.
Mar 18 08:23:23.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:23:23.994: INFO: namespace: e2e-tests-nsdeletetest-xqxtx, resource: bindings, ignored listing per whitelist
Mar 18 08:23:24.080: INFO: namespace e2e-tests-nsdeletetest-xqxtx deletion completed in 6.155552191s

â€¢ [SLOW TEST:18.517 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:23:24.081: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Mar 18 08:23:28.213: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-18fe03c4-4957-11e9-86d2-4ea95915efee", GenerateName:"", Namespace:"e2e-tests-pods-dnbbk", SelfLink:"/api/v1/namespaces/e2e-tests-pods-dnbbk/pods/pod-submit-remove-18fe03c4-4957-11e9-86d2-4ea95915efee", UID:"18fee145-4957-11e9-b44d-0022480537ee", ResourceVersion:"198083", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63688494204, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"179354441"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-kswwd", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001ccc680), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-kswwd", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001ea8ef8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"worker01", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001c1f2c0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001ea8f40)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001ea8f60)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001ea8f68), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001ea8f6c)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688494204, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688494206, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688494206, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688494204, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.2.5", PodIP:"10.32.0.5", StartTime:(*v1.Time)(0xc001f1e500), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc001f1e520), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d", ContainerID:"docker://3baa5125555870346438dcbd9088432dc64e4873c3943b624950ebadb5d7c162"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Mar 18 08:23:33.230: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:23:33.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-dnbbk" for this suite.
Mar 18 08:23:39.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:23:39.285: INFO: namespace: e2e-tests-pods-dnbbk, resource: bindings, ignored listing per whitelist
Mar 18 08:23:39.366: INFO: namespace e2e-tests-pods-dnbbk deletion completed in 6.128563579s

â€¢ [SLOW TEST:15.285 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:23:39.366: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Mar 18 08:23:39.464: INFO: Waiting up to 5m0s for pod "pod-22197399-4957-11e9-86d2-4ea95915efee" in namespace "e2e-tests-emptydir-62r2f" to be "success or failure"
Mar 18 08:23:39.481: INFO: Pod "pod-22197399-4957-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 17.735359ms
Mar 18 08:23:41.486: INFO: Pod "pod-22197399-4957-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021888008s
Mar 18 08:23:43.490: INFO: Pod "pod-22197399-4957-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026105661s
STEP: Saw pod success
Mar 18 08:23:43.490: INFO: Pod "pod-22197399-4957-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:23:43.492: INFO: Trying to get logs from node worker02 pod pod-22197399-4957-11e9-86d2-4ea95915efee container test-container: <nil>
STEP: delete the pod
Mar 18 08:23:43.525: INFO: Waiting for pod pod-22197399-4957-11e9-86d2-4ea95915efee to disappear
Mar 18 08:23:43.531: INFO: Pod pod-22197399-4957-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:23:43.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-62r2f" for this suite.
Mar 18 08:23:49.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:23:49.615: INFO: namespace: e2e-tests-emptydir-62r2f, resource: bindings, ignored listing per whitelist
Mar 18 08:23:49.694: INFO: namespace e2e-tests-emptydir-62r2f deletion completed in 6.158866388s

â€¢ [SLOW TEST:10.328 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:23:49.695: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-28423994-4957-11e9-86d2-4ea95915efee
STEP: Creating secret with name s-test-opt-upd-284239ce-4957-11e9-86d2-4ea95915efee
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-28423994-4957-11e9-86d2-4ea95915efee
STEP: Updating secret s-test-opt-upd-284239ce-4957-11e9-86d2-4ea95915efee
STEP: Creating secret with name s-test-opt-create-284239e1-4957-11e9-86d2-4ea95915efee
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:23:53.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-754zf" for this suite.
Mar 18 08:24:15.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:24:15.985: INFO: namespace: e2e-tests-projected-754zf, resource: bindings, ignored listing per whitelist
Mar 18 08:24:16.005: INFO: namespace e2e-tests-projected-754zf deletion completed in 22.118394882s

â€¢ [SLOW TEST:26.310 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:24:16.005: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar 18 08:24:20.660: INFO: Successfully updated pod "annotationupdate37f455ca-4957-11e9-86d2-4ea95915efee"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:24:22.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sf6xc" for this suite.
Mar 18 08:24:44.718: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:24:44.799: INFO: namespace: e2e-tests-projected-sf6xc, resource: bindings, ignored listing per whitelist
Mar 18 08:24:44.818: INFO: namespace e2e-tests-projected-sf6xc deletion completed in 22.110688022s

â€¢ [SLOW TEST:28.813 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:24:44.818: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Mar 18 08:24:44.939: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-d66rt,SelfLink:/api/v1/namespaces/e2e-tests-watch-d66rt/configmaps/e2e-watch-test-resource-version,UID:491cd3e8-4957-11e9-b44d-0022480537ee,ResourceVersion:198327,Generation:0,CreationTimestamp:2019-03-18 08:24:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 18 08:24:44.940: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-d66rt,SelfLink:/api/v1/namespaces/e2e-tests-watch-d66rt/configmaps/e2e-watch-test-resource-version,UID:491cd3e8-4957-11e9-b44d-0022480537ee,ResourceVersion:198328,Generation:0,CreationTimestamp:2019-03-18 08:24:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:24:44.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-d66rt" for this suite.
Mar 18 08:24:50.990: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:24:51.050: INFO: namespace: e2e-tests-watch-d66rt, resource: bindings, ignored listing per whitelist
Mar 18 08:24:51.173: INFO: namespace e2e-tests-watch-d66rt deletion completed in 6.228809663s

â€¢ [SLOW TEST:6.355 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:24:51.173: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Mar 18 08:24:51.279: INFO: Waiting up to 5m0s for pod "pod-4ce792d7-4957-11e9-86d2-4ea95915efee" in namespace "e2e-tests-emptydir-cf6x8" to be "success or failure"
Mar 18 08:24:51.287: INFO: Pod "pod-4ce792d7-4957-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 8.030479ms
Mar 18 08:24:53.296: INFO: Pod "pod-4ce792d7-4957-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017304634s
STEP: Saw pod success
Mar 18 08:24:53.296: INFO: Pod "pod-4ce792d7-4957-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:24:53.299: INFO: Trying to get logs from node worker01 pod pod-4ce792d7-4957-11e9-86d2-4ea95915efee container test-container: <nil>
STEP: delete the pod
Mar 18 08:24:53.317: INFO: Waiting for pod pod-4ce792d7-4957-11e9-86d2-4ea95915efee to disappear
Mar 18 08:24:53.327: INFO: Pod pod-4ce792d7-4957-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:24:53.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-cf6x8" for this suite.
Mar 18 08:24:59.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:24:59.432: INFO: namespace: e2e-tests-emptydir-cf6x8, resource: bindings, ignored listing per whitelist
Mar 18 08:24:59.457: INFO: namespace e2e-tests-emptydir-cf6x8 deletion completed in 6.118114355s

â€¢ [SLOW TEST:8.284 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:24:59.457: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Mar 18 08:24:59.559: INFO: Waiting up to 5m0s for pod "client-containers-51d72112-4957-11e9-86d2-4ea95915efee" in namespace "e2e-tests-containers-cj76g" to be "success or failure"
Mar 18 08:24:59.570: INFO: Pod "client-containers-51d72112-4957-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 11.502387ms
Mar 18 08:25:01.574: INFO: Pod "client-containers-51d72112-4957-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015267113s
STEP: Saw pod success
Mar 18 08:25:01.574: INFO: Pod "client-containers-51d72112-4957-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:25:01.577: INFO: Trying to get logs from node worker02 pod client-containers-51d72112-4957-11e9-86d2-4ea95915efee container test-container: <nil>
STEP: delete the pod
Mar 18 08:25:01.612: INFO: Waiting for pod client-containers-51d72112-4957-11e9-86d2-4ea95915efee to disappear
Mar 18 08:25:01.614: INFO: Pod client-containers-51d72112-4957-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:25:01.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-cj76g" for this suite.
Mar 18 08:25:07.629: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:25:07.716: INFO: namespace: e2e-tests-containers-cj76g, resource: bindings, ignored listing per whitelist
Mar 18 08:25:07.729: INFO: namespace e2e-tests-containers-cj76g deletion completed in 6.110436097s

â€¢ [SLOW TEST:8.272 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:25:07.729: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar 18 08:25:07.815: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:25:11.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-g5pt4" for this suite.
Mar 18 08:25:17.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:25:17.705: INFO: namespace: e2e-tests-init-container-g5pt4, resource: bindings, ignored listing per whitelist
Mar 18 08:25:17.757: INFO: namespace e2e-tests-init-container-g5pt4 deletion completed in 6.114718552s

â€¢ [SLOW TEST:10.028 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:25:17.757: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-qv67c/configmap-test-5cbf3268-4957-11e9-86d2-4ea95915efee
STEP: Creating a pod to test consume configMaps
Mar 18 08:25:17.865: INFO: Waiting up to 5m0s for pod "pod-configmaps-5cbf9852-4957-11e9-86d2-4ea95915efee" in namespace "e2e-tests-configmap-qv67c" to be "success or failure"
Mar 18 08:25:17.868: INFO: Pod "pod-configmaps-5cbf9852-4957-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.830469ms
Mar 18 08:25:19.877: INFO: Pod "pod-configmaps-5cbf9852-4957-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011882211s
STEP: Saw pod success
Mar 18 08:25:19.877: INFO: Pod "pod-configmaps-5cbf9852-4957-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:25:19.882: INFO: Trying to get logs from node worker02 pod pod-configmaps-5cbf9852-4957-11e9-86d2-4ea95915efee container env-test: <nil>
STEP: delete the pod
Mar 18 08:25:19.910: INFO: Waiting for pod pod-configmaps-5cbf9852-4957-11e9-86d2-4ea95915efee to disappear
Mar 18 08:25:19.914: INFO: Pod pod-configmaps-5cbf9852-4957-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:25:19.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-qv67c" for this suite.
Mar 18 08:25:25.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:25:26.006: INFO: namespace: e2e-tests-configmap-qv67c, resource: bindings, ignored listing per whitelist
Mar 18 08:25:26.048: INFO: namespace e2e-tests-configmap-qv67c deletion completed in 6.129201617s

â€¢ [SLOW TEST:8.290 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:25:26.048: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Mar 18 08:25:26.149: INFO: Waiting up to 5m0s for pod "client-containers-61b068f2-4957-11e9-86d2-4ea95915efee" in namespace "e2e-tests-containers-5pw6d" to be "success or failure"
Mar 18 08:25:26.161: INFO: Pod "client-containers-61b068f2-4957-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 11.974215ms
Mar 18 08:25:28.165: INFO: Pod "client-containers-61b068f2-4957-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015656036s
Mar 18 08:25:30.168: INFO: Pod "client-containers-61b068f2-4957-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019299055s
Mar 18 08:25:32.172: INFO: Pod "client-containers-61b068f2-4957-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.022672658s
STEP: Saw pod success
Mar 18 08:25:32.172: INFO: Pod "client-containers-61b068f2-4957-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:25:32.174: INFO: Trying to get logs from node worker01 pod client-containers-61b068f2-4957-11e9-86d2-4ea95915efee container test-container: <nil>
STEP: delete the pod
Mar 18 08:25:32.191: INFO: Waiting for pod client-containers-61b068f2-4957-11e9-86d2-4ea95915efee to disappear
Mar 18 08:25:32.200: INFO: Pod client-containers-61b068f2-4957-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:25:32.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-5pw6d" for this suite.
Mar 18 08:25:38.221: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:25:38.316: INFO: namespace: e2e-tests-containers-5pw6d, resource: bindings, ignored listing per whitelist
Mar 18 08:25:38.333: INFO: namespace e2e-tests-containers-5pw6d deletion completed in 6.126478554s

â€¢ [SLOW TEST:12.285 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:25:38.334: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-dxcd
STEP: Creating a pod to test atomic-volume-subpath
Mar 18 08:25:38.486: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-dxcd" in namespace "e2e-tests-subpath-gvnr6" to be "success or failure"
Mar 18 08:25:38.495: INFO: Pod "pod-subpath-test-configmap-dxcd": Phase="Pending", Reason="", readiness=false. Elapsed: 9.022939ms
Mar 18 08:25:40.498: INFO: Pod "pod-subpath-test-configmap-dxcd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012446744s
Mar 18 08:25:42.502: INFO: Pod "pod-subpath-test-configmap-dxcd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015566732s
Mar 18 08:25:44.505: INFO: Pod "pod-subpath-test-configmap-dxcd": Phase="Running", Reason="", readiness=false. Elapsed: 6.019148847s
Mar 18 08:25:46.509: INFO: Pod "pod-subpath-test-configmap-dxcd": Phase="Running", Reason="", readiness=false. Elapsed: 8.022853469s
Mar 18 08:25:48.513: INFO: Pod "pod-subpath-test-configmap-dxcd": Phase="Running", Reason="", readiness=false. Elapsed: 10.026601594s
Mar 18 08:25:50.521: INFO: Pod "pod-subpath-test-configmap-dxcd": Phase="Running", Reason="", readiness=false. Elapsed: 12.035340517s
Mar 18 08:25:52.525: INFO: Pod "pod-subpath-test-configmap-dxcd": Phase="Running", Reason="", readiness=false. Elapsed: 14.039357358s
Mar 18 08:25:54.529: INFO: Pod "pod-subpath-test-configmap-dxcd": Phase="Running", Reason="", readiness=false. Elapsed: 16.043040179s
Mar 18 08:25:56.532: INFO: Pod "pod-subpath-test-configmap-dxcd": Phase="Running", Reason="", readiness=false. Elapsed: 18.046305775s
Mar 18 08:25:58.535: INFO: Pod "pod-subpath-test-configmap-dxcd": Phase="Running", Reason="", readiness=false. Elapsed: 20.049362859s
Mar 18 08:26:00.542: INFO: Pod "pod-subpath-test-configmap-dxcd": Phase="Running", Reason="", readiness=false. Elapsed: 22.05589025s
Mar 18 08:26:02.546: INFO: Pod "pod-subpath-test-configmap-dxcd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.060163507s
STEP: Saw pod success
Mar 18 08:26:02.546: INFO: Pod "pod-subpath-test-configmap-dxcd" satisfied condition "success or failure"
Mar 18 08:26:02.549: INFO: Trying to get logs from node worker02 pod pod-subpath-test-configmap-dxcd container test-container-subpath-configmap-dxcd: <nil>
STEP: delete the pod
Mar 18 08:26:02.586: INFO: Waiting for pod pod-subpath-test-configmap-dxcd to disappear
Mar 18 08:26:02.594: INFO: Pod pod-subpath-test-configmap-dxcd no longer exists
STEP: Deleting pod pod-subpath-test-configmap-dxcd
Mar 18 08:26:02.594: INFO: Deleting pod "pod-subpath-test-configmap-dxcd" in namespace "e2e-tests-subpath-gvnr6"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:26:02.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-gvnr6" for this suite.
Mar 18 08:26:08.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:26:08.622: INFO: namespace: e2e-tests-subpath-gvnr6, resource: bindings, ignored listing per whitelist
Mar 18 08:26:08.717: INFO: namespace e2e-tests-subpath-gvnr6 deletion completed in 6.115805517s

â€¢ [SLOW TEST:30.384 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:26:08.718: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-7b1e72ff-4957-11e9-86d2-4ea95915efee
STEP: Creating a pod to test consume configMaps
Mar 18 08:26:08.823: INFO: Waiting up to 5m0s for pod "pod-configmaps-7b1edb25-4957-11e9-86d2-4ea95915efee" in namespace "e2e-tests-configmap-bv8f9" to be "success or failure"
Mar 18 08:26:08.826: INFO: Pod "pod-configmaps-7b1edb25-4957-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.762165ms
Mar 18 08:26:10.829: INFO: Pod "pod-configmaps-7b1edb25-4957-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005999659s
Mar 18 08:26:12.832: INFO: Pod "pod-configmaps-7b1edb25-4957-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009106346s
STEP: Saw pod success
Mar 18 08:26:12.832: INFO: Pod "pod-configmaps-7b1edb25-4957-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:26:12.835: INFO: Trying to get logs from node worker02 pod pod-configmaps-7b1edb25-4957-11e9-86d2-4ea95915efee container configmap-volume-test: <nil>
STEP: delete the pod
Mar 18 08:26:12.852: INFO: Waiting for pod pod-configmaps-7b1edb25-4957-11e9-86d2-4ea95915efee to disappear
Mar 18 08:26:12.855: INFO: Pod pod-configmaps-7b1edb25-4957-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:26:12.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-bv8f9" for this suite.
Mar 18 08:26:18.870: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:26:18.897: INFO: namespace: e2e-tests-configmap-bv8f9, resource: bindings, ignored listing per whitelist
Mar 18 08:26:18.981: INFO: namespace e2e-tests-configmap-bv8f9 deletion completed in 6.121021729s

â€¢ [SLOW TEST:10.263 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:26:18.982: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Mar 18 08:26:19.087: INFO: Waiting up to 5m0s for pod "var-expansion-813df14a-4957-11e9-86d2-4ea95915efee" in namespace "e2e-tests-var-expansion-g45v7" to be "success or failure"
Mar 18 08:26:19.094: INFO: Pod "var-expansion-813df14a-4957-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 6.971616ms
Mar 18 08:26:21.098: INFO: Pod "var-expansion-813df14a-4957-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010392922s
Mar 18 08:26:23.101: INFO: Pod "var-expansion-813df14a-4957-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01386513s
STEP: Saw pod success
Mar 18 08:26:23.101: INFO: Pod "var-expansion-813df14a-4957-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:26:23.104: INFO: Trying to get logs from node worker02 pod var-expansion-813df14a-4957-11e9-86d2-4ea95915efee container dapi-container: <nil>
STEP: delete the pod
Mar 18 08:26:23.126: INFO: Waiting for pod var-expansion-813df14a-4957-11e9-86d2-4ea95915efee to disappear
Mar 18 08:26:23.129: INFO: Pod var-expansion-813df14a-4957-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:26:23.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-g45v7" for this suite.
Mar 18 08:26:29.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:26:29.208: INFO: namespace: e2e-tests-var-expansion-g45v7, resource: bindings, ignored listing per whitelist
Mar 18 08:26:29.254: INFO: namespace e2e-tests-var-expansion-g45v7 deletion completed in 6.116587464s

â€¢ [SLOW TEST:10.272 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:26:29.254: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 18 08:26:29.364: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Mar 18 08:26:29.369: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-2lv5v/daemonsets","resourceVersion":"198726"},"items":null}

Mar 18 08:26:29.372: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-2lv5v/pods","resourceVersion":"198726"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:26:29.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-2lv5v" for this suite.
Mar 18 08:26:35.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:26:35.450: INFO: namespace: e2e-tests-daemonsets-2lv5v, resource: bindings, ignored listing per whitelist
Mar 18 08:26:35.506: INFO: namespace e2e-tests-daemonsets-2lv5v deletion completed in 6.119708151s

S [SKIPPING] [6.252 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Mar 18 08:26:29.364: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:26:35.506: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar 18 08:26:40.150: INFO: Successfully updated pod "annotationupdate8b152932-4957-11e9-86d2-4ea95915efee"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:26:42.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-bsbtk" for this suite.
Mar 18 08:27:04.199: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:27:04.243: INFO: namespace: e2e-tests-downward-api-bsbtk, resource: bindings, ignored listing per whitelist
Mar 18 08:27:04.300: INFO: namespace e2e-tests-downward-api-bsbtk deletion completed in 22.116752284s

â€¢ [SLOW TEST:28.794 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:27:04.300: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-9c407fac-4957-11e9-86d2-4ea95915efee
STEP: Creating secret with name secret-projected-all-test-volume-9c407f95-4957-11e9-86d2-4ea95915efee
STEP: Creating a pod to test Check all projections for projected volume plugin
Mar 18 08:27:04.408: INFO: Waiting up to 5m0s for pod "projected-volume-9c407e75-4957-11e9-86d2-4ea95915efee" in namespace "e2e-tests-projected-9thx8" to be "success or failure"
Mar 18 08:27:04.417: INFO: Pod "projected-volume-9c407e75-4957-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 9.093242ms
Mar 18 08:27:06.420: INFO: Pod "projected-volume-9c407e75-4957-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012433143s
STEP: Saw pod success
Mar 18 08:27:06.420: INFO: Pod "projected-volume-9c407e75-4957-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:27:06.427: INFO: Trying to get logs from node worker02 pod projected-volume-9c407e75-4957-11e9-86d2-4ea95915efee container projected-all-volume-test: <nil>
STEP: delete the pod
Mar 18 08:27:06.455: INFO: Waiting for pod projected-volume-9c407e75-4957-11e9-86d2-4ea95915efee to disappear
Mar 18 08:27:06.457: INFO: Pod projected-volume-9c407e75-4957-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:27:06.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9thx8" for this suite.
Mar 18 08:27:12.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:27:12.561: INFO: namespace: e2e-tests-projected-9thx8, resource: bindings, ignored listing per whitelist
Mar 18 08:27:12.581: INFO: namespace e2e-tests-projected-9thx8 deletion completed in 6.119071513s

â€¢ [SLOW TEST:8.281 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:27:12.581: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-a1370042-4957-11e9-86d2-4ea95915efee
STEP: Creating a pod to test consume configMaps
Mar 18 08:27:12.731: INFO: Waiting up to 5m0s for pod "pod-configmaps-a13785a7-4957-11e9-86d2-4ea95915efee" in namespace "e2e-tests-configmap-rz92j" to be "success or failure"
Mar 18 08:27:12.743: INFO: Pod "pod-configmaps-a13785a7-4957-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 11.39758ms
Mar 18 08:27:14.746: INFO: Pod "pod-configmaps-a13785a7-4957-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014858888s
STEP: Saw pod success
Mar 18 08:27:14.746: INFO: Pod "pod-configmaps-a13785a7-4957-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:27:14.749: INFO: Trying to get logs from node worker01 pod pod-configmaps-a13785a7-4957-11e9-86d2-4ea95915efee container configmap-volume-test: <nil>
STEP: delete the pod
Mar 18 08:27:14.776: INFO: Waiting for pod pod-configmaps-a13785a7-4957-11e9-86d2-4ea95915efee to disappear
Mar 18 08:27:14.780: INFO: Pod pod-configmaps-a13785a7-4957-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:27:14.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-rz92j" for this suite.
Mar 18 08:27:20.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:27:20.826: INFO: namespace: e2e-tests-configmap-rz92j, resource: bindings, ignored listing per whitelist
Mar 18 08:27:20.905: INFO: namespace e2e-tests-configmap-rz92j deletion completed in 6.119654047s

â€¢ [SLOW TEST:8.324 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:27:20.905: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-a625eb44-4957-11e9-86d2-4ea95915efee
STEP: Creating a pod to test consume secrets
Mar 18 08:27:21.007: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a6266265-4957-11e9-86d2-4ea95915efee" in namespace "e2e-tests-projected-4tnw9" to be "success or failure"
Mar 18 08:27:21.012: INFO: Pod "pod-projected-secrets-a6266265-4957-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 4.941595ms
Mar 18 08:27:23.015: INFO: Pod "pod-projected-secrets-a6266265-4957-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007930875s
Mar 18 08:27:25.018: INFO: Pod "pod-projected-secrets-a6266265-4957-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011045062s
STEP: Saw pod success
Mar 18 08:27:25.018: INFO: Pod "pod-projected-secrets-a6266265-4957-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:27:25.021: INFO: Trying to get logs from node worker02 pod pod-projected-secrets-a6266265-4957-11e9-86d2-4ea95915efee container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 18 08:27:25.039: INFO: Waiting for pod pod-projected-secrets-a6266265-4957-11e9-86d2-4ea95915efee to disappear
Mar 18 08:27:25.043: INFO: Pod pod-projected-secrets-a6266265-4957-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:27:25.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4tnw9" for this suite.
Mar 18 08:27:31.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:27:31.127: INFO: namespace: e2e-tests-projected-4tnw9, resource: bindings, ignored listing per whitelist
Mar 18 08:27:31.180: INFO: namespace e2e-tests-projected-4tnw9 deletion completed in 6.132738428s

â€¢ [SLOW TEST:10.275 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:27:31.180: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0318 08:27:37.321309      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 18 08:27:37.321: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:27:37.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-hcszj" for this suite.
Mar 18 08:27:43.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:27:43.365: INFO: namespace: e2e-tests-gc-hcszj, resource: bindings, ignored listing per whitelist
Mar 18 08:27:43.450: INFO: namespace e2e-tests-gc-hcszj deletion completed in 6.124718449s

â€¢ [SLOW TEST:12.270 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:27:43.450: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-cpjwm
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 18 08:27:43.544: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 18 08:28:05.609: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.32.0.5 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-cpjwm PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 18 08:28:05.609: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
Mar 18 08:28:06.731: INFO: Found all expected endpoints: [netserver-0]
Mar 18 08:28:06.734: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.38.0.8 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-cpjwm PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 18 08:28:06.734: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
Mar 18 08:28:07.856: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:28:07.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-cpjwm" for this suite.
Mar 18 08:28:29.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:28:29.925: INFO: namespace: e2e-tests-pod-network-test-cpjwm, resource: bindings, ignored listing per whitelist
Mar 18 08:28:29.994: INFO: namespace e2e-tests-pod-network-test-cpjwm deletion completed in 22.132646732s

â€¢ [SLOW TEST:46.543 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:28:29.994: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-cf5450ce-4957-11e9-86d2-4ea95915efee
STEP: Creating a pod to test consume secrets
Mar 18 08:28:30.098: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-cf54dc90-4957-11e9-86d2-4ea95915efee" in namespace "e2e-tests-projected-tfgc8" to be "success or failure"
Mar 18 08:28:30.107: INFO: Pod "pod-projected-secrets-cf54dc90-4957-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 8.961035ms
Mar 18 08:28:32.111: INFO: Pod "pod-projected-secrets-cf54dc90-4957-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013263893s
Mar 18 08:28:34.115: INFO: Pod "pod-projected-secrets-cf54dc90-4957-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01688361s
STEP: Saw pod success
Mar 18 08:28:34.115: INFO: Pod "pod-projected-secrets-cf54dc90-4957-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:28:34.118: INFO: Trying to get logs from node worker01 pod pod-projected-secrets-cf54dc90-4957-11e9-86d2-4ea95915efee container secret-volume-test: <nil>
STEP: delete the pod
Mar 18 08:28:34.144: INFO: Waiting for pod pod-projected-secrets-cf54dc90-4957-11e9-86d2-4ea95915efee to disappear
Mar 18 08:28:34.148: INFO: Pod pod-projected-secrets-cf54dc90-4957-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:28:34.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tfgc8" for this suite.
Mar 18 08:28:40.170: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:28:40.238: INFO: namespace: e2e-tests-projected-tfgc8, resource: bindings, ignored listing per whitelist
Mar 18 08:28:40.290: INFO: namespace e2e-tests-projected-tfgc8 deletion completed in 6.136841373s

â€¢ [SLOW TEST:10.296 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:28:40.290: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-d579d07f-4957-11e9-86d2-4ea95915efee
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-d579d07f-4957-11e9-86d2-4ea95915efee
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:28:48.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-r5gnf" for this suite.
Mar 18 08:29:10.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:29:10.534: INFO: namespace: e2e-tests-projected-r5gnf, resource: bindings, ignored listing per whitelist
Mar 18 08:29:10.586: INFO: namespace e2e-tests-projected-r5gnf deletion completed in 22.116625976s

â€¢ [SLOW TEST:30.296 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:29:10.586: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Mar 18 08:29:14.722: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 18 08:29:14.725: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 18 08:29:16.725: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 18 08:29:16.729: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 18 08:29:18.725: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 18 08:29:18.729: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 18 08:29:20.725: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 18 08:29:20.729: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 18 08:29:22.725: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 18 08:29:22.729: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 18 08:29:24.725: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 18 08:29:24.729: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 18 08:29:26.725: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 18 08:29:26.729: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 18 08:29:28.725: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 18 08:29:28.729: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 18 08:29:30.725: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 18 08:29:30.729: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 18 08:29:32.725: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 18 08:29:32.733: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 18 08:29:34.725: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 18 08:29:34.729: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:29:34.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-8ncsq" for this suite.
Mar 18 08:29:56.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:29:56.852: INFO: namespace: e2e-tests-container-lifecycle-hook-8ncsq, resource: bindings, ignored listing per whitelist
Mar 18 08:29:56.857: INFO: namespace e2e-tests-container-lifecycle-hook-8ncsq deletion completed in 22.114781966s

â€¢ [SLOW TEST:46.271 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:29:56.857: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Mar 18 08:29:56.959: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 18 08:29:56.975: INFO: Waiting for terminating namespaces to be deleted...
Mar 18 08:29:56.977: INFO: 
Logging pods the kubelet thinks is on node worker01 before test
Mar 18 08:29:56.986: INFO: node-exporter-59tlh from cocktail-addon started at 2019-03-14 07:08:39 +0000 UTC (1 container statuses recorded)
Mar 18 08:29:56.986: INFO: 	Container node-exporter ready: true, restart count 1
Mar 18 08:29:56.986: INFO: sonobuoy from heptio-sonobuoy started at 2019-03-18 07:34:26 +0000 UTC (3 container statuses recorded)
Mar 18 08:29:56.986: INFO: 	Container cleanup ready: true, restart count 0
Mar 18 08:29:56.986: INFO: 	Container forwarder ready: true, restart count 0
Mar 18 08:29:56.986: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar 18 08:29:56.986: INFO: weave-net-zld25 from kube-system started at 2019-03-14 07:08:17 +0000 UTC (2 container statuses recorded)
Mar 18 08:29:56.986: INFO: 	Container weave ready: true, restart count 2
Mar 18 08:29:56.986: INFO: 	Container weave-npc ready: true, restart count 1
Mar 18 08:29:56.986: INFO: disk-usage-exporter-hdpcs from cocktail-addon started at 2019-03-14 07:08:39 +0000 UTC (1 container statuses recorded)
Mar 18 08:29:56.986: INFO: 	Container disk-usage-exporter ready: true, restart count 1
Mar 18 08:29:56.986: INFO: kube-proxy-hqq6s from kube-system started at 2019-03-14 07:08:03 +0000 UTC (1 container statuses recorded)
Mar 18 08:29:56.986: INFO: 	Container kube-proxy ready: true, restart count 1
Mar 18 08:29:56.986: INFO: 
Logging pods the kubelet thinks is on node worker02 before test
Mar 18 08:29:57.000: INFO: disk-usage-exporter-95k5q from cocktail-addon started at 2019-03-14 07:08:40 +0000 UTC (1 container statuses recorded)
Mar 18 08:29:57.000: INFO: 	Container disk-usage-exporter ready: true, restart count 1
Mar 18 08:29:57.000: INFO: coredns-5b468bcb45-wbwpw from kube-system started at 2019-03-14 07:08:04 +0000 UTC (1 container statuses recorded)
Mar 18 08:29:57.000: INFO: 	Container coredns ready: true, restart count 1
Mar 18 08:29:57.000: INFO: node-exporter-4t5db from cocktail-addon started at 2019-03-14 07:08:40 +0000 UTC (1 container statuses recorded)
Mar 18 08:29:57.000: INFO: 	Container node-exporter ready: true, restart count 1
Mar 18 08:29:57.000: INFO: sonobuoy-e2e-job-f4149a4c7cc34126 from heptio-sonobuoy started at 2019-03-18 07:34:33 +0000 UTC (2 container statuses recorded)
Mar 18 08:29:57.000: INFO: 	Container e2e ready: true, restart count 0
Mar 18 08:29:57.000: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 18 08:29:57.000: INFO: coredns-5b468bcb45-zf7fk from kube-system started at 2019-03-14 07:08:04 +0000 UTC (1 container statuses recorded)
Mar 18 08:29:57.000: INFO: 	Container coredns ready: true, restart count 1
Mar 18 08:29:57.000: INFO: weave-net-knnjf from kube-system started at 2019-03-14 07:08:17 +0000 UTC (2 container statuses recorded)
Mar 18 08:29:57.000: INFO: 	Container weave ready: true, restart count 2
Mar 18 08:29:57.000: INFO: 	Container weave-npc ready: true, restart count 1
Mar 18 08:29:57.000: INFO: kube-proxy-gclqz from kube-system started at 2019-03-14 07:08:04 +0000 UTC (1 container statuses recorded)
Mar 18 08:29:57.000: INFO: 	Container kube-proxy ready: true, restart count 1
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-045719d4-4958-11e9-86d2-4ea95915efee 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-045719d4-4958-11e9-86d2-4ea95915efee off the node worker01
STEP: verifying the node doesn't have the label kubernetes.io/e2e-045719d4-4958-11e9-86d2-4ea95915efee
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:30:03.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-frvcn" for this suite.
Mar 18 08:30:11.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:30:11.149: INFO: namespace: e2e-tests-sched-pred-frvcn, resource: bindings, ignored listing per whitelist
Mar 18 08:30:11.194: INFO: namespace e2e-tests-sched-pred-frvcn deletion completed in 8.113471179s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

â€¢ [SLOW TEST:14.337 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:30:11.195: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Mar 18 08:30:11.325: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:30:11.329: INFO: Number of nodes with available pods: 0
Mar 18 08:30:11.329: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:30:12.334: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:30:12.337: INFO: Number of nodes with available pods: 0
Mar 18 08:30:12.337: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:30:13.338: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:30:13.341: INFO: Number of nodes with available pods: 1
Mar 18 08:30:13.341: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:30:14.336: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:30:14.339: INFO: Number of nodes with available pods: 2
Mar 18 08:30:14.339: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Mar 18 08:30:14.355: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:30:14.358: INFO: Number of nodes with available pods: 1
Mar 18 08:30:14.358: INFO: Node worker02 is running more than one daemon pod
Mar 18 08:30:15.364: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:30:15.366: INFO: Number of nodes with available pods: 1
Mar 18 08:30:15.366: INFO: Node worker02 is running more than one daemon pod
Mar 18 08:30:16.363: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:30:16.366: INFO: Number of nodes with available pods: 1
Mar 18 08:30:16.366: INFO: Node worker02 is running more than one daemon pod
Mar 18 08:30:17.363: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:30:17.367: INFO: Number of nodes with available pods: 1
Mar 18 08:30:17.367: INFO: Node worker02 is running more than one daemon pod
Mar 18 08:30:18.363: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:30:18.367: INFO: Number of nodes with available pods: 1
Mar 18 08:30:18.367: INFO: Node worker02 is running more than one daemon pod
Mar 18 08:30:19.363: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:30:19.366: INFO: Number of nodes with available pods: 1
Mar 18 08:30:19.366: INFO: Node worker02 is running more than one daemon pod
Mar 18 08:30:20.363: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:30:20.366: INFO: Number of nodes with available pods: 1
Mar 18 08:30:20.366: INFO: Node worker02 is running more than one daemon pod
Mar 18 08:30:21.364: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:30:21.367: INFO: Number of nodes with available pods: 1
Mar 18 08:30:21.367: INFO: Node worker02 is running more than one daemon pod
Mar 18 08:30:22.366: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:30:22.372: INFO: Number of nodes with available pods: 1
Mar 18 08:30:22.372: INFO: Node worker02 is running more than one daemon pod
Mar 18 08:30:23.364: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:30:23.367: INFO: Number of nodes with available pods: 1
Mar 18 08:30:23.367: INFO: Node worker02 is running more than one daemon pod
Mar 18 08:30:24.363: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:30:24.366: INFO: Number of nodes with available pods: 1
Mar 18 08:30:24.366: INFO: Node worker02 is running more than one daemon pod
Mar 18 08:30:25.364: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:30:25.367: INFO: Number of nodes with available pods: 1
Mar 18 08:30:25.367: INFO: Node worker02 is running more than one daemon pod
Mar 18 08:30:26.363: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:30:26.366: INFO: Number of nodes with available pods: 1
Mar 18 08:30:26.366: INFO: Node worker02 is running more than one daemon pod
Mar 18 08:30:27.363: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:30:27.366: INFO: Number of nodes with available pods: 1
Mar 18 08:30:27.366: INFO: Node worker02 is running more than one daemon pod
Mar 18 08:30:28.362: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:30:28.365: INFO: Number of nodes with available pods: 1
Mar 18 08:30:28.365: INFO: Node worker02 is running more than one daemon pod
Mar 18 08:30:29.389: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:30:29.392: INFO: Number of nodes with available pods: 1
Mar 18 08:30:29.392: INFO: Node worker02 is running more than one daemon pod
Mar 18 08:30:30.365: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:30:30.368: INFO: Number of nodes with available pods: 1
Mar 18 08:30:30.368: INFO: Node worker02 is running more than one daemon pod
Mar 18 08:30:31.363: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:30:31.365: INFO: Number of nodes with available pods: 1
Mar 18 08:30:31.366: INFO: Node worker02 is running more than one daemon pod
Mar 18 08:30:32.363: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:30:32.366: INFO: Number of nodes with available pods: 1
Mar 18 08:30:32.366: INFO: Node worker02 is running more than one daemon pod
Mar 18 08:30:33.364: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:30:33.366: INFO: Number of nodes with available pods: 1
Mar 18 08:30:33.366: INFO: Node worker02 is running more than one daemon pod
Mar 18 08:30:34.363: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:30:34.367: INFO: Number of nodes with available pods: 1
Mar 18 08:30:34.367: INFO: Node worker02 is running more than one daemon pod
Mar 18 08:30:35.364: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:30:35.367: INFO: Number of nodes with available pods: 1
Mar 18 08:30:35.367: INFO: Node worker02 is running more than one daemon pod
Mar 18 08:30:36.364: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:30:36.367: INFO: Number of nodes with available pods: 1
Mar 18 08:30:36.367: INFO: Node worker02 is running more than one daemon pod
Mar 18 08:30:37.364: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:30:37.367: INFO: Number of nodes with available pods: 1
Mar 18 08:30:37.367: INFO: Node worker02 is running more than one daemon pod
Mar 18 08:30:38.365: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:30:38.368: INFO: Number of nodes with available pods: 1
Mar 18 08:30:38.368: INFO: Node worker02 is running more than one daemon pod
Mar 18 08:30:39.363: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:30:39.366: INFO: Number of nodes with available pods: 1
Mar 18 08:30:39.366: INFO: Node worker02 is running more than one daemon pod
Mar 18 08:30:40.363: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:30:40.366: INFO: Number of nodes with available pods: 1
Mar 18 08:30:40.366: INFO: Node worker02 is running more than one daemon pod
Mar 18 08:30:41.364: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:30:41.367: INFO: Number of nodes with available pods: 1
Mar 18 08:30:41.367: INFO: Node worker02 is running more than one daemon pod
Mar 18 08:30:42.363: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:30:42.366: INFO: Number of nodes with available pods: 1
Mar 18 08:30:42.366: INFO: Node worker02 is running more than one daemon pod
Mar 18 08:30:43.363: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:30:43.366: INFO: Number of nodes with available pods: 1
Mar 18 08:30:43.366: INFO: Node worker02 is running more than one daemon pod
Mar 18 08:30:44.362: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:30:44.366: INFO: Number of nodes with available pods: 1
Mar 18 08:30:44.366: INFO: Node worker02 is running more than one daemon pod
Mar 18 08:30:45.363: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:30:45.366: INFO: Number of nodes with available pods: 1
Mar 18 08:30:45.366: INFO: Node worker02 is running more than one daemon pod
Mar 18 08:30:46.363: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:30:46.365: INFO: Number of nodes with available pods: 1
Mar 18 08:30:46.365: INFO: Node worker02 is running more than one daemon pod
Mar 18 08:30:47.364: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:30:47.367: INFO: Number of nodes with available pods: 1
Mar 18 08:30:47.367: INFO: Node worker02 is running more than one daemon pod
Mar 18 08:30:48.366: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:30:48.368: INFO: Number of nodes with available pods: 1
Mar 18 08:30:48.368: INFO: Node worker02 is running more than one daemon pod
Mar 18 08:30:49.364: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:30:49.367: INFO: Number of nodes with available pods: 1
Mar 18 08:30:49.367: INFO: Node worker02 is running more than one daemon pod
Mar 18 08:30:50.363: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:30:50.365: INFO: Number of nodes with available pods: 2
Mar 18 08:30:50.366: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-hc8mn, will wait for the garbage collector to delete the pods
Mar 18 08:30:50.428: INFO: Deleting DaemonSet.extensions daemon-set took: 6.878611ms
Mar 18 08:30:50.529: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.247285ms
Mar 18 08:31:24.532: INFO: Number of nodes with available pods: 0
Mar 18 08:31:24.532: INFO: Number of running nodes: 0, number of available pods: 0
Mar 18 08:31:24.535: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-hc8mn/daemonsets","resourceVersion":"199779"},"items":null}

Mar 18 08:31:24.537: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-hc8mn/pods","resourceVersion":"199779"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:31:24.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-hc8mn" for this suite.
Mar 18 08:31:30.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:31:30.665: INFO: namespace: e2e-tests-daemonsets-hc8mn, resource: bindings, ignored listing per whitelist
Mar 18 08:31:30.670: INFO: namespace e2e-tests-daemonsets-hc8mn deletion completed in 6.118318867s

â€¢ [SLOW TEST:79.476 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:31:30.671: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar 18 08:31:30.761: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:31:34.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-mwmln" for this suite.
Mar 18 08:31:56.835: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:31:56.887: INFO: namespace: e2e-tests-init-container-mwmln, resource: bindings, ignored listing per whitelist
Mar 18 08:31:56.937: INFO: namespace e2e-tests-init-container-mwmln deletion completed in 22.11149307s

â€¢ [SLOW TEST:26.267 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:31:56.937: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Mar 18 08:31:57.039: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 18 08:31:57.049: INFO: Waiting for terminating namespaces to be deleted...
Mar 18 08:31:57.052: INFO: 
Logging pods the kubelet thinks is on node worker01 before test
Mar 18 08:31:57.061: INFO: node-exporter-59tlh from cocktail-addon started at 2019-03-14 07:08:39 +0000 UTC (1 container statuses recorded)
Mar 18 08:31:57.061: INFO: 	Container node-exporter ready: true, restart count 1
Mar 18 08:31:57.061: INFO: disk-usage-exporter-hdpcs from cocktail-addon started at 2019-03-14 07:08:39 +0000 UTC (1 container statuses recorded)
Mar 18 08:31:57.061: INFO: 	Container disk-usage-exporter ready: true, restart count 1
Mar 18 08:31:57.061: INFO: sonobuoy from heptio-sonobuoy started at 2019-03-18 07:34:26 +0000 UTC (3 container statuses recorded)
Mar 18 08:31:57.061: INFO: 	Container cleanup ready: true, restart count 0
Mar 18 08:31:57.061: INFO: 	Container forwarder ready: true, restart count 0
Mar 18 08:31:57.061: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar 18 08:31:57.061: INFO: weave-net-zld25 from kube-system started at 2019-03-14 07:08:17 +0000 UTC (2 container statuses recorded)
Mar 18 08:31:57.061: INFO: 	Container weave ready: true, restart count 2
Mar 18 08:31:57.061: INFO: 	Container weave-npc ready: true, restart count 1
Mar 18 08:31:57.061: INFO: kube-proxy-hqq6s from kube-system started at 2019-03-14 07:08:03 +0000 UTC (1 container statuses recorded)
Mar 18 08:31:57.061: INFO: 	Container kube-proxy ready: true, restart count 1
Mar 18 08:31:57.061: INFO: 
Logging pods the kubelet thinks is on node worker02 before test
Mar 18 08:31:57.071: INFO: coredns-5b468bcb45-wbwpw from kube-system started at 2019-03-14 07:08:04 +0000 UTC (1 container statuses recorded)
Mar 18 08:31:57.071: INFO: 	Container coredns ready: true, restart count 1
Mar 18 08:31:57.071: INFO: node-exporter-4t5db from cocktail-addon started at 2019-03-14 07:08:40 +0000 UTC (1 container statuses recorded)
Mar 18 08:31:57.071: INFO: 	Container node-exporter ready: true, restart count 1
Mar 18 08:31:57.071: INFO: sonobuoy-e2e-job-f4149a4c7cc34126 from heptio-sonobuoy started at 2019-03-18 07:34:33 +0000 UTC (2 container statuses recorded)
Mar 18 08:31:57.071: INFO: 	Container e2e ready: true, restart count 0
Mar 18 08:31:57.071: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 18 08:31:57.071: INFO: coredns-5b468bcb45-zf7fk from kube-system started at 2019-03-14 07:08:04 +0000 UTC (1 container statuses recorded)
Mar 18 08:31:57.071: INFO: 	Container coredns ready: true, restart count 1
Mar 18 08:31:57.071: INFO: weave-net-knnjf from kube-system started at 2019-03-14 07:08:17 +0000 UTC (2 container statuses recorded)
Mar 18 08:31:57.071: INFO: 	Container weave ready: true, restart count 2
Mar 18 08:31:57.071: INFO: 	Container weave-npc ready: true, restart count 1
Mar 18 08:31:57.071: INFO: kube-proxy-gclqz from kube-system started at 2019-03-14 07:08:04 +0000 UTC (1 container statuses recorded)
Mar 18 08:31:57.071: INFO: 	Container kube-proxy ready: true, restart count 1
Mar 18 08:31:57.071: INFO: disk-usage-exporter-95k5q from cocktail-addon started at 2019-03-14 07:08:40 +0000 UTC (1 container statuses recorded)
Mar 18 08:31:57.071: INFO: 	Container disk-usage-exporter ready: true, restart count 1
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.158d006d90be661d], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:31:58.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-5z6qp" for this suite.
Mar 18 08:32:04.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:32:04.262: INFO: namespace: e2e-tests-sched-pred-5z6qp, resource: bindings, ignored listing per whitelist
Mar 18 08:32:04.265: INFO: namespace e2e-tests-sched-pred-5z6qp deletion completed in 6.161859567s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

â€¢ [SLOW TEST:7.327 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:32:04.265: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-4f0ac6a3-4958-11e9-86d2-4ea95915efee
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-4f0ac6a3-4958-11e9-86d2-4ea95915efee
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:32:08.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-zzlsk" for this suite.
Mar 18 08:32:30.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:32:30.497: INFO: namespace: e2e-tests-configmap-zzlsk, resource: bindings, ignored listing per whitelist
Mar 18 08:32:30.536: INFO: namespace e2e-tests-configmap-zzlsk deletion completed in 22.127929451s

â€¢ [SLOW TEST:26.271 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:32:30.536: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-5eb48c08-4958-11e9-86d2-4ea95915efee
STEP: Creating a pod to test consume secrets
Mar 18 08:32:30.644: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5eb5085b-4958-11e9-86d2-4ea95915efee" in namespace "e2e-tests-projected-sqwvj" to be "success or failure"
Mar 18 08:32:30.654: INFO: Pod "pod-projected-secrets-5eb5085b-4958-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 9.428663ms
Mar 18 08:32:32.659: INFO: Pod "pod-projected-secrets-5eb5085b-4958-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014664877s
STEP: Saw pod success
Mar 18 08:32:32.659: INFO: Pod "pod-projected-secrets-5eb5085b-4958-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:32:32.662: INFO: Trying to get logs from node worker02 pod pod-projected-secrets-5eb5085b-4958-11e9-86d2-4ea95915efee container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 18 08:32:32.686: INFO: Waiting for pod pod-projected-secrets-5eb5085b-4958-11e9-86d2-4ea95915efee to disappear
Mar 18 08:32:32.689: INFO: Pod pod-projected-secrets-5eb5085b-4958-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:32:32.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sqwvj" for this suite.
Mar 18 08:32:38.705: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:32:38.761: INFO: namespace: e2e-tests-projected-sqwvj, resource: bindings, ignored listing per whitelist
Mar 18 08:32:38.802: INFO: namespace e2e-tests-projected-sqwvj deletion completed in 6.107705833s

â€¢ [SLOW TEST:8.266 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:32:38.803: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0318 08:32:48.972286      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 18 08:32:48.972: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:32:48.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-2f7nx" for this suite.
Mar 18 08:32:54.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:32:55.089: INFO: namespace: e2e-tests-gc-2f7nx, resource: bindings, ignored listing per whitelist
Mar 18 08:32:55.089: INFO: namespace e2e-tests-gc-2f7nx deletion completed in 6.112797338s

â€¢ [SLOW TEST:16.286 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:32:55.090: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 18 08:32:55.181: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-spgp7'
Mar 18 08:32:55.899: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar 18 08:32:55.899: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: rolling-update to same image controller
Mar 18 08:32:55.910: INFO: scanned /root for discovery docs: <nil>
Mar 18 08:32:55.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-spgp7'
Mar 18 08:33:11.694: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Mar 18 08:33:11.694: INFO: stdout: "Created e2e-test-nginx-rc-13177d71638115f8b5a9ebe68f49f51d\nScaling up e2e-test-nginx-rc-13177d71638115f8b5a9ebe68f49f51d from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-13177d71638115f8b5a9ebe68f49f51d up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-13177d71638115f8b5a9ebe68f49f51d to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Mar 18 08:33:11.694: INFO: stdout: "Created e2e-test-nginx-rc-13177d71638115f8b5a9ebe68f49f51d\nScaling up e2e-test-nginx-rc-13177d71638115f8b5a9ebe68f49f51d from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-13177d71638115f8b5a9ebe68f49f51d up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-13177d71638115f8b5a9ebe68f49f51d to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Mar 18 08:33:11.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-spgp7'
Mar 18 08:33:11.784: INFO: stderr: ""
Mar 18 08:33:11.784: INFO: stdout: "e2e-test-nginx-rc-13177d71638115f8b5a9ebe68f49f51d-255hh "
Mar 18 08:33:11.784: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods e2e-test-nginx-rc-13177d71638115f8b5a9ebe68f49f51d-255hh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-spgp7'
Mar 18 08:33:11.866: INFO: stderr: ""
Mar 18 08:33:11.867: INFO: stdout: "true"
Mar 18 08:33:11.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods e2e-test-nginx-rc-13177d71638115f8b5a9ebe68f49f51d-255hh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-spgp7'
Mar 18 08:33:11.940: INFO: stderr: ""
Mar 18 08:33:11.940: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Mar 18 08:33:11.940: INFO: e2e-test-nginx-rc-13177d71638115f8b5a9ebe68f49f51d-255hh is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Mar 18 08:33:11.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-spgp7'
Mar 18 08:33:12.021: INFO: stderr: ""
Mar 18 08:33:12.021: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:33:12.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-spgp7" for this suite.
Mar 18 08:33:34.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:33:34.092: INFO: namespace: e2e-tests-kubectl-spgp7, resource: bindings, ignored listing per whitelist
Mar 18 08:33:34.152: INFO: namespace e2e-tests-kubectl-spgp7 deletion completed in 22.117301417s

â€¢ [SLOW TEST:39.062 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:33:34.152: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-tfxjs
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-tfxjs
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-tfxjs
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-tfxjs
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-tfxjs
Mar 18 08:33:38.293: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-tfxjs, name: ss-0, uid: 84b50f2e-4958-11e9-b44d-0022480537ee, status phase: Pending. Waiting for statefulset controller to delete.
Mar 18 08:33:43.827: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-tfxjs, name: ss-0, uid: 84b50f2e-4958-11e9-b44d-0022480537ee, status phase: Failed. Waiting for statefulset controller to delete.
Mar 18 08:33:43.842: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-tfxjs, name: ss-0, uid: 84b50f2e-4958-11e9-b44d-0022480537ee, status phase: Failed. Waiting for statefulset controller to delete.
Mar 18 08:33:43.848: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-tfxjs
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-tfxjs
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-tfxjs and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 18 08:34:03.931: INFO: Deleting all statefulset in ns e2e-tests-statefulset-tfxjs
Mar 18 08:34:03.934: INFO: Scaling statefulset ss to 0
Mar 18 08:34:13.954: INFO: Waiting for statefulset status.replicas updated to 0
Mar 18 08:34:13.956: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:34:13.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-tfxjs" for this suite.
Mar 18 08:34:20.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:34:20.034: INFO: namespace: e2e-tests-statefulset-tfxjs, resource: bindings, ignored listing per whitelist
Mar 18 08:34:20.100: INFO: namespace e2e-tests-statefulset-tfxjs deletion completed in 6.108788899s

â€¢ [SLOW TEST:45.948 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:34:20.100: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:34:27.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-fnt5j" for this suite.
Mar 18 08:34:49.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:34:49.339: INFO: namespace: e2e-tests-replication-controller-fnt5j, resource: bindings, ignored listing per whitelist
Mar 18 08:34:49.339: INFO: namespace e2e-tests-replication-controller-fnt5j deletion completed in 22.125768722s

â€¢ [SLOW TEST:29.239 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:34:49.340: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 18 08:34:49.450: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Mar 18 08:34:54.453: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar 18 08:34:54.453: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 18 08:34:54.476: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-ctf2r,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-ctf2r/deployments/test-cleanup-deployment,UID:b46e2aa8-4958-11e9-b44d-0022480537ee,ResourceVersion:200690,Generation:1,CreationTimestamp:2019-03-18 08:34:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Mar 18 08:34:54.486: INFO: New ReplicaSet "test-cleanup-deployment-7dbbfcf846" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-7dbbfcf846,GenerateName:,Namespace:e2e-tests-deployment-ctf2r,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-ctf2r/replicasets/test-cleanup-deployment-7dbbfcf846,UID:b4700698-4958-11e9-b44d-0022480537ee,ResourceVersion:200692,Generation:1,CreationTimestamp:2019-03-18 08:34:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment b46e2aa8-4958-11e9-b44d-0022480537ee 0xc000470387 0xc000470388}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 18 08:34:54.486: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Mar 18 08:34:54.486: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-ctf2r,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-ctf2r/replicasets/test-cleanup-controller,UID:b1710e01-4958-11e9-b44d-0022480537ee,ResourceVersion:200691,Generation:1,CreationTimestamp:2019-03-18 08:34:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment b46e2aa8-4958-11e9-b44d-0022480537ee 0xc00181ff57 0xc00181ff58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar 18 08:34:54.509: INFO: Pod "test-cleanup-controller-b94mm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-b94mm,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-ctf2r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ctf2r/pods/test-cleanup-controller-b94mm,UID:b1723079-4958-11e9-b44d-0022480537ee,ResourceVersion:200681,Generation:0,CreationTimestamp:2019-03-18 08:34:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller b1710e01-4958-11e9-b44d-0022480537ee 0xc0018eb287 0xc0018eb288}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wc4tl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wc4tl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wc4tl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker02,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018eb310} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018eb330}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:34:49 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:34:51 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:34:51 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:34:49 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.4,PodIP:10.38.0.8,StartTime:2019-03-18 08:34:49 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-18 08:34:50 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://5d881c12aa5b1729afe5801f254cbb30494dbd47a6a14b701766db5dcc8e3019}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 18 08:34:54.509: INFO: Pod "test-cleanup-deployment-7dbbfcf846-6bhng" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-7dbbfcf846-6bhng,GenerateName:test-cleanup-deployment-7dbbfcf846-,Namespace:e2e-tests-deployment-ctf2r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ctf2r/pods/test-cleanup-deployment-7dbbfcf846-6bhng,UID:b470d1eb-4958-11e9-b44d-0022480537ee,ResourceVersion:200694,Generation:0,CreationTimestamp:2019-03-18 08:34:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-7dbbfcf846 b4700698-4958-11e9-b44d-0022480537ee 0xc0018eb3f7 0xc0018eb3f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wc4tl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wc4tl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-wc4tl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018eb460} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018eb480}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:34:54.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-ctf2r" for this suite.
Mar 18 08:35:00.574: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:35:00.645: INFO: namespace: e2e-tests-deployment-ctf2r, resource: bindings, ignored listing per whitelist
Mar 18 08:35:00.689: INFO: namespace e2e-tests-deployment-ctf2r deletion completed in 6.151215431s

â€¢ [SLOW TEST:11.350 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:35:00.690: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 18 08:35:00.817: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:35:02.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-tfxtn" for this suite.
Mar 18 08:35:40.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:35:41.079: INFO: namespace: e2e-tests-pods-tfxtn, resource: bindings, ignored listing per whitelist
Mar 18 08:35:41.099: INFO: namespace e2e-tests-pods-tfxtn deletion completed in 38.136698384s

â€¢ [SLOW TEST:40.409 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:35:41.099: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Mar 18 08:35:41.208: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ff6ks,SelfLink:/api/v1/namespaces/e2e-tests-watch-ff6ks/configmaps/e2e-watch-test-configmap-a,UID:d04b3d9d-4958-11e9-b44d-0022480537ee,ResourceVersion:200833,Generation:0,CreationTimestamp:2019-03-18 08:35:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 18 08:35:41.209: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ff6ks,SelfLink:/api/v1/namespaces/e2e-tests-watch-ff6ks/configmaps/e2e-watch-test-configmap-a,UID:d04b3d9d-4958-11e9-b44d-0022480537ee,ResourceVersion:200833,Generation:0,CreationTimestamp:2019-03-18 08:35:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Mar 18 08:35:51.216: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ff6ks,SelfLink:/api/v1/namespaces/e2e-tests-watch-ff6ks/configmaps/e2e-watch-test-configmap-a,UID:d04b3d9d-4958-11e9-b44d-0022480537ee,ResourceVersion:200849,Generation:0,CreationTimestamp:2019-03-18 08:35:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar 18 08:35:51.216: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ff6ks,SelfLink:/api/v1/namespaces/e2e-tests-watch-ff6ks/configmaps/e2e-watch-test-configmap-a,UID:d04b3d9d-4958-11e9-b44d-0022480537ee,ResourceVersion:200849,Generation:0,CreationTimestamp:2019-03-18 08:35:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Mar 18 08:36:01.223: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ff6ks,SelfLink:/api/v1/namespaces/e2e-tests-watch-ff6ks/configmaps/e2e-watch-test-configmap-a,UID:d04b3d9d-4958-11e9-b44d-0022480537ee,ResourceVersion:200866,Generation:0,CreationTimestamp:2019-03-18 08:35:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 18 08:36:01.224: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ff6ks,SelfLink:/api/v1/namespaces/e2e-tests-watch-ff6ks/configmaps/e2e-watch-test-configmap-a,UID:d04b3d9d-4958-11e9-b44d-0022480537ee,ResourceVersion:200866,Generation:0,CreationTimestamp:2019-03-18 08:35:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Mar 18 08:36:11.230: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ff6ks,SelfLink:/api/v1/namespaces/e2e-tests-watch-ff6ks/configmaps/e2e-watch-test-configmap-a,UID:d04b3d9d-4958-11e9-b44d-0022480537ee,ResourceVersion:200882,Generation:0,CreationTimestamp:2019-03-18 08:35:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 18 08:36:11.230: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ff6ks,SelfLink:/api/v1/namespaces/e2e-tests-watch-ff6ks/configmaps/e2e-watch-test-configmap-a,UID:d04b3d9d-4958-11e9-b44d-0022480537ee,ResourceVersion:200882,Generation:0,CreationTimestamp:2019-03-18 08:35:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Mar 18 08:36:21.235: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-ff6ks,SelfLink:/api/v1/namespaces/e2e-tests-watch-ff6ks/configmaps/e2e-watch-test-configmap-b,UID:e82693ee-4958-11e9-b44d-0022480537ee,ResourceVersion:200899,Generation:0,CreationTimestamp:2019-03-18 08:36:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 18 08:36:21.236: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-ff6ks,SelfLink:/api/v1/namespaces/e2e-tests-watch-ff6ks/configmaps/e2e-watch-test-configmap-b,UID:e82693ee-4958-11e9-b44d-0022480537ee,ResourceVersion:200899,Generation:0,CreationTimestamp:2019-03-18 08:36:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Mar 18 08:36:31.241: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-ff6ks,SelfLink:/api/v1/namespaces/e2e-tests-watch-ff6ks/configmaps/e2e-watch-test-configmap-b,UID:e82693ee-4958-11e9-b44d-0022480537ee,ResourceVersion:200916,Generation:0,CreationTimestamp:2019-03-18 08:36:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 18 08:36:31.241: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-ff6ks,SelfLink:/api/v1/namespaces/e2e-tests-watch-ff6ks/configmaps/e2e-watch-test-configmap-b,UID:e82693ee-4958-11e9-b44d-0022480537ee,ResourceVersion:200916,Generation:0,CreationTimestamp:2019-03-18 08:36:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:36:41.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-ff6ks" for this suite.
Mar 18 08:36:47.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:36:47.284: INFO: namespace: e2e-tests-watch-ff6ks, resource: bindings, ignored listing per whitelist
Mar 18 08:36:47.375: INFO: namespace e2e-tests-watch-ff6ks deletion completed in 6.129187616s

â€¢ [SLOW TEST:66.277 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:36:47.376: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-f7ca7c96-4958-11e9-86d2-4ea95915efee
STEP: Creating a pod to test consume secrets
Mar 18 08:36:47.479: INFO: Waiting up to 5m0s for pod "pod-secrets-f7caf1df-4958-11e9-86d2-4ea95915efee" in namespace "e2e-tests-secrets-bqmwd" to be "success or failure"
Mar 18 08:36:47.493: INFO: Pod "pod-secrets-f7caf1df-4958-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 14.040238ms
Mar 18 08:36:49.497: INFO: Pod "pod-secrets-f7caf1df-4958-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01823079s
STEP: Saw pod success
Mar 18 08:36:49.497: INFO: Pod "pod-secrets-f7caf1df-4958-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:36:49.500: INFO: Trying to get logs from node worker02 pod pod-secrets-f7caf1df-4958-11e9-86d2-4ea95915efee container secret-env-test: <nil>
STEP: delete the pod
Mar 18 08:36:49.529: INFO: Waiting for pod pod-secrets-f7caf1df-4958-11e9-86d2-4ea95915efee to disappear
Mar 18 08:36:49.531: INFO: Pod pod-secrets-f7caf1df-4958-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:36:49.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-bqmwd" for this suite.
Mar 18 08:36:55.551: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:36:55.651: INFO: namespace: e2e-tests-secrets-bqmwd, resource: bindings, ignored listing per whitelist
Mar 18 08:36:55.656: INFO: namespace e2e-tests-secrets-bqmwd deletion completed in 6.120529899s

â€¢ [SLOW TEST:8.281 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:36:55.657: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-fcbad1a9-4958-11e9-86d2-4ea95915efee
STEP: Creating a pod to test consume configMaps
Mar 18 08:36:55.763: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-fcbb4158-4958-11e9-86d2-4ea95915efee" in namespace "e2e-tests-projected-r2ctd" to be "success or failure"
Mar 18 08:36:55.773: INFO: Pod "pod-projected-configmaps-fcbb4158-4958-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 9.439963ms
Mar 18 08:36:57.777: INFO: Pod "pod-projected-configmaps-fcbb4158-4958-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013463805s
STEP: Saw pod success
Mar 18 08:36:57.777: INFO: Pod "pod-projected-configmaps-fcbb4158-4958-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:36:57.780: INFO: Trying to get logs from node worker02 pod pod-projected-configmaps-fcbb4158-4958-11e9-86d2-4ea95915efee container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 18 08:36:57.806: INFO: Waiting for pod pod-projected-configmaps-fcbb4158-4958-11e9-86d2-4ea95915efee to disappear
Mar 18 08:36:57.810: INFO: Pod pod-projected-configmaps-fcbb4158-4958-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:36:57.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-r2ctd" for this suite.
Mar 18 08:37:03.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:37:03.876: INFO: namespace: e2e-tests-projected-r2ctd, resource: bindings, ignored listing per whitelist
Mar 18 08:37:03.962: INFO: namespace e2e-tests-projected-r2ctd deletion completed in 6.147032981s

â€¢ [SLOW TEST:8.306 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:37:03.963: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:37:06.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-78cf6" for this suite.
Mar 18 08:37:56.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:37:56.135: INFO: namespace: e2e-tests-kubelet-test-78cf6, resource: bindings, ignored listing per whitelist
Mar 18 08:37:56.205: INFO: namespace e2e-tests-kubelet-test-78cf6 deletion completed in 50.111524489s

â€¢ [SLOW TEST:52.242 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:37:56.205: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:37:58.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-62gtt" for this suite.
Mar 18 08:38:04.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:38:04.441: INFO: namespace: e2e-tests-emptydir-wrapper-62gtt, resource: bindings, ignored listing per whitelist
Mar 18 08:38:04.504: INFO: namespace e2e-tests-emptydir-wrapper-62gtt deletion completed in 6.126828475s

â€¢ [SLOW TEST:8.298 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:38:04.504: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-25c2ece7-4959-11e9-86d2-4ea95915efee
STEP: Creating a pod to test consume configMaps
Mar 18 08:38:04.605: INFO: Waiting up to 5m0s for pod "pod-configmaps-25c38b47-4959-11e9-86d2-4ea95915efee" in namespace "e2e-tests-configmap-pbqrk" to be "success or failure"
Mar 18 08:38:04.608: INFO: Pod "pod-configmaps-25c38b47-4959-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.635057ms
Mar 18 08:38:06.612: INFO: Pod "pod-configmaps-25c38b47-4959-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006946416s
STEP: Saw pod success
Mar 18 08:38:06.612: INFO: Pod "pod-configmaps-25c38b47-4959-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:38:06.615: INFO: Trying to get logs from node worker01 pod pod-configmaps-25c38b47-4959-11e9-86d2-4ea95915efee container configmap-volume-test: <nil>
STEP: delete the pod
Mar 18 08:38:06.640: INFO: Waiting for pod pod-configmaps-25c38b47-4959-11e9-86d2-4ea95915efee to disappear
Mar 18 08:38:06.643: INFO: Pod pod-configmaps-25c38b47-4959-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:38:06.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-pbqrk" for this suite.
Mar 18 08:38:12.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:38:12.673: INFO: namespace: e2e-tests-configmap-pbqrk, resource: bindings, ignored listing per whitelist
Mar 18 08:38:12.776: INFO: namespace e2e-tests-configmap-pbqrk deletion completed in 6.128706187s

â€¢ [SLOW TEST:8.273 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:38:12.777: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-2ab2c873-4959-11e9-86d2-4ea95915efee
STEP: Creating a pod to test consume configMaps
Mar 18 08:38:12.893: INFO: Waiting up to 5m0s for pod "pod-configmaps-2ab41298-4959-11e9-86d2-4ea95915efee" in namespace "e2e-tests-configmap-jhnpg" to be "success or failure"
Mar 18 08:38:12.898: INFO: Pod "pod-configmaps-2ab41298-4959-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 5.846349ms
Mar 18 08:38:14.903: INFO: Pod "pod-configmaps-2ab41298-4959-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009853889s
STEP: Saw pod success
Mar 18 08:38:14.903: INFO: Pod "pod-configmaps-2ab41298-4959-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:38:14.905: INFO: Trying to get logs from node worker02 pod pod-configmaps-2ab41298-4959-11e9-86d2-4ea95915efee container configmap-volume-test: <nil>
STEP: delete the pod
Mar 18 08:38:14.923: INFO: Waiting for pod pod-configmaps-2ab41298-4959-11e9-86d2-4ea95915efee to disappear
Mar 18 08:38:14.925: INFO: Pod pod-configmaps-2ab41298-4959-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:38:14.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-jhnpg" for this suite.
Mar 18 08:38:20.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:38:20.981: INFO: namespace: e2e-tests-configmap-jhnpg, resource: bindings, ignored listing per whitelist
Mar 18 08:38:21.061: INFO: namespace e2e-tests-configmap-jhnpg deletion completed in 6.130867716s

â€¢ [SLOW TEST:8.284 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:38:21.061: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 18 08:38:23.225: INFO: Waiting up to 5m0s for pod "client-envvars-30dcf6d9-4959-11e9-86d2-4ea95915efee" in namespace "e2e-tests-pods-pxdrf" to be "success or failure"
Mar 18 08:38:23.237: INFO: Pod "client-envvars-30dcf6d9-4959-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 12.05942ms
Mar 18 08:38:25.242: INFO: Pod "client-envvars-30dcf6d9-4959-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016860708s
STEP: Saw pod success
Mar 18 08:38:25.242: INFO: Pod "client-envvars-30dcf6d9-4959-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:38:25.244: INFO: Trying to get logs from node worker02 pod client-envvars-30dcf6d9-4959-11e9-86d2-4ea95915efee container env3cont: <nil>
STEP: delete the pod
Mar 18 08:38:25.288: INFO: Waiting for pod client-envvars-30dcf6d9-4959-11e9-86d2-4ea95915efee to disappear
Mar 18 08:38:25.296: INFO: Pod client-envvars-30dcf6d9-4959-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:38:25.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-pxdrf" for this suite.
Mar 18 08:39:03.311: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:39:03.362: INFO: namespace: e2e-tests-pods-pxdrf, resource: bindings, ignored listing per whitelist
Mar 18 08:39:03.417: INFO: namespace e2e-tests-pods-pxdrf deletion completed in 38.116573493s

â€¢ [SLOW TEST:42.356 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:39:03.417: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-fcrhq/configmap-test-48e35039-4959-11e9-86d2-4ea95915efee
STEP: Creating a pod to test consume configMaps
Mar 18 08:39:03.542: INFO: Waiting up to 5m0s for pod "pod-configmaps-48e43e10-4959-11e9-86d2-4ea95915efee" in namespace "e2e-tests-configmap-fcrhq" to be "success or failure"
Mar 18 08:39:03.545: INFO: Pod "pod-configmaps-48e43e10-4959-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 3.01668ms
Mar 18 08:39:05.548: INFO: Pod "pod-configmaps-48e43e10-4959-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006288278s
STEP: Saw pod success
Mar 18 08:39:05.548: INFO: Pod "pod-configmaps-48e43e10-4959-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:39:05.550: INFO: Trying to get logs from node worker01 pod pod-configmaps-48e43e10-4959-11e9-86d2-4ea95915efee container env-test: <nil>
STEP: delete the pod
Mar 18 08:39:05.567: INFO: Waiting for pod pod-configmaps-48e43e10-4959-11e9-86d2-4ea95915efee to disappear
Mar 18 08:39:05.570: INFO: Pod pod-configmaps-48e43e10-4959-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:39:05.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-fcrhq" for this suite.
Mar 18 08:39:11.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:39:11.634: INFO: namespace: e2e-tests-configmap-fcrhq, resource: bindings, ignored listing per whitelist
Mar 18 08:39:11.720: INFO: namespace e2e-tests-configmap-fcrhq deletion completed in 6.145576986s

â€¢ [SLOW TEST:8.303 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:39:11.720: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-4dd466bd-4959-11e9-86d2-4ea95915efee
STEP: Creating a pod to test consume secrets
Mar 18 08:39:11.827: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4dd4db8f-4959-11e9-86d2-4ea95915efee" in namespace "e2e-tests-projected-ffs87" to be "success or failure"
Mar 18 08:39:11.830: INFO: Pod "pod-projected-secrets-4dd4db8f-4959-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 3.254294ms
Mar 18 08:39:13.833: INFO: Pod "pod-projected-secrets-4dd4db8f-4959-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006220374s
STEP: Saw pod success
Mar 18 08:39:13.833: INFO: Pod "pod-projected-secrets-4dd4db8f-4959-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:39:13.836: INFO: Trying to get logs from node worker02 pod pod-projected-secrets-4dd4db8f-4959-11e9-86d2-4ea95915efee container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 18 08:39:13.855: INFO: Waiting for pod pod-projected-secrets-4dd4db8f-4959-11e9-86d2-4ea95915efee to disappear
Mar 18 08:39:13.858: INFO: Pod pod-projected-secrets-4dd4db8f-4959-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:39:13.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ffs87" for this suite.
Mar 18 08:39:19.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:39:19.912: INFO: namespace: e2e-tests-projected-ffs87, resource: bindings, ignored listing per whitelist
Mar 18 08:39:19.975: INFO: namespace e2e-tests-projected-ffs87 deletion completed in 6.112762831s

â€¢ [SLOW TEST:8.255 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:39:19.975: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 18 08:39:20.090: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:39:22.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-57slv" for this suite.
Mar 18 08:40:06.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:40:06.237: INFO: namespace: e2e-tests-pods-57slv, resource: bindings, ignored listing per whitelist
Mar 18 08:40:06.256: INFO: namespace e2e-tests-pods-57slv deletion completed in 44.123777451s

â€¢ [SLOW TEST:46.281 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:40:06.257: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:40:06.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-5hxl4" for this suite.
Mar 18 08:40:28.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:40:28.444: INFO: namespace: e2e-tests-pods-5hxl4, resource: bindings, ignored listing per whitelist
Mar 18 08:40:28.502: INFO: namespace e2e-tests-pods-5hxl4 deletion completed in 22.129042528s

â€¢ [SLOW TEST:22.245 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:40:28.502: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-7b96e633-4959-11e9-86d2-4ea95915efee
STEP: Creating a pod to test consume configMaps
Mar 18 08:40:28.600: INFO: Waiting up to 5m0s for pod "pod-configmaps-7b974fad-4959-11e9-86d2-4ea95915efee" in namespace "e2e-tests-configmap-d2b88" to be "success or failure"
Mar 18 08:40:28.609: INFO: Pod "pod-configmaps-7b974fad-4959-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 9.888889ms
Mar 18 08:40:30.613: INFO: Pod "pod-configmaps-7b974fad-4959-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01369422s
STEP: Saw pod success
Mar 18 08:40:30.613: INFO: Pod "pod-configmaps-7b974fad-4959-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:40:30.616: INFO: Trying to get logs from node worker01 pod pod-configmaps-7b974fad-4959-11e9-86d2-4ea95915efee container configmap-volume-test: <nil>
STEP: delete the pod
Mar 18 08:40:30.638: INFO: Waiting for pod pod-configmaps-7b974fad-4959-11e9-86d2-4ea95915efee to disappear
Mar 18 08:40:30.641: INFO: Pod pod-configmaps-7b974fad-4959-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:40:30.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-d2b88" for this suite.
Mar 18 08:40:36.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:40:36.742: INFO: namespace: e2e-tests-configmap-d2b88, resource: bindings, ignored listing per whitelist
Mar 18 08:40:36.796: INFO: namespace e2e-tests-configmap-d2b88 deletion completed in 6.14999305s

â€¢ [SLOW TEST:8.293 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:40:36.796: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 18 08:40:36.891: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8088a9c2-4959-11e9-86d2-4ea95915efee" in namespace "e2e-tests-downward-api-l2jqd" to be "success or failure"
Mar 18 08:40:36.900: INFO: Pod "downwardapi-volume-8088a9c2-4959-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 8.505007ms
Mar 18 08:40:38.906: INFO: Pod "downwardapi-volume-8088a9c2-4959-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014477166s
STEP: Saw pod success
Mar 18 08:40:38.906: INFO: Pod "downwardapi-volume-8088a9c2-4959-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:40:38.909: INFO: Trying to get logs from node worker02 pod downwardapi-volume-8088a9c2-4959-11e9-86d2-4ea95915efee container client-container: <nil>
STEP: delete the pod
Mar 18 08:40:38.938: INFO: Waiting for pod downwardapi-volume-8088a9c2-4959-11e9-86d2-4ea95915efee to disappear
Mar 18 08:40:38.941: INFO: Pod downwardapi-volume-8088a9c2-4959-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:40:38.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-l2jqd" for this suite.
Mar 18 08:40:44.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:40:45.032: INFO: namespace: e2e-tests-downward-api-l2jqd, resource: bindings, ignored listing per whitelist
Mar 18 08:40:45.058: INFO: namespace e2e-tests-downward-api-l2jqd deletion completed in 6.112502016s

â€¢ [SLOW TEST:8.262 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:40:45.058: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-2x499
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 18 08:40:45.190: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 18 08:41:05.271: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.38.0.8:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-2x499 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 18 08:41:05.272: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
Mar 18 08:41:05.409: INFO: Found all expected endpoints: [netserver-0]
Mar 18 08:41:05.413: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.32.0.5:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-2x499 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 18 08:41:05.413: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
Mar 18 08:41:05.532: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:41:05.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-2x499" for this suite.
Mar 18 08:41:27.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:41:27.620: INFO: namespace: e2e-tests-pod-network-test-2x499, resource: bindings, ignored listing per whitelist
Mar 18 08:41:27.666: INFO: namespace e2e-tests-pod-network-test-2x499 deletion completed in 22.128498496s

â€¢ [SLOW TEST:42.608 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:41:27.666: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-57qf8
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-57qf8
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-57qf8
Mar 18 08:41:27.820: INFO: Found 0 stateful pods, waiting for 1
Mar 18 08:41:37.824: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Mar 18 08:41:37.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 exec --namespace=e2e-tests-statefulset-57qf8 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 18 08:41:38.086: INFO: stderr: ""
Mar 18 08:41:38.086: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 18 08:41:38.086: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 18 08:41:38.094: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar 18 08:41:48.097: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 18 08:41:48.097: INFO: Waiting for statefulset status.replicas updated to 0
Mar 18 08:41:48.110: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.9999998s
Mar 18 08:41:49.118: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.996532192s
Mar 18 08:41:50.122: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.989009542s
Mar 18 08:41:51.126: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.984703383s
Mar 18 08:41:52.130: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.980326121s
Mar 18 08:41:53.133: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.976933717s
Mar 18 08:41:54.137: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.973139089s
Mar 18 08:41:55.142: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.969181352s
Mar 18 08:41:56.145: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.964623378s
Mar 18 08:41:57.150: INFO: Verifying statefulset ss doesn't scale past 1 for another 961.290778ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-57qf8
Mar 18 08:41:58.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 exec --namespace=e2e-tests-statefulset-57qf8 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 18 08:41:58.348: INFO: stderr: ""
Mar 18 08:41:58.348: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 18 08:41:58.349: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 18 08:41:58.352: INFO: Found 1 stateful pods, waiting for 3
Mar 18 08:42:08.356: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 18 08:42:08.356: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 18 08:42:08.356: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Mar 18 08:42:08.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 exec --namespace=e2e-tests-statefulset-57qf8 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 18 08:42:08.561: INFO: stderr: ""
Mar 18 08:42:08.561: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 18 08:42:08.561: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 18 08:42:08.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 exec --namespace=e2e-tests-statefulset-57qf8 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 18 08:42:08.767: INFO: stderr: ""
Mar 18 08:42:08.767: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 18 08:42:08.767: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 18 08:42:08.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 exec --namespace=e2e-tests-statefulset-57qf8 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 18 08:42:09.030: INFO: stderr: ""
Mar 18 08:42:09.030: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 18 08:42:09.030: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 18 08:42:09.030: INFO: Waiting for statefulset status.replicas updated to 0
Mar 18 08:42:09.034: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Mar 18 08:42:19.043: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 18 08:42:19.043: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar 18 08:42:19.043: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar 18 08:42:19.090: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.9999997s
Mar 18 08:42:20.094: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.959208867s
Mar 18 08:42:21.098: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.954921409s
Mar 18 08:42:22.103: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.950500344s
Mar 18 08:42:23.107: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.945604951s
Mar 18 08:42:24.112: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.941528106s
Mar 18 08:42:25.116: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.93709084s
Mar 18 08:42:26.120: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.932904389s
Mar 18 08:42:27.125: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.928394918s
Mar 18 08:42:28.129: INFO: Verifying statefulset ss doesn't scale past 3 for another 923.774241ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-57qf8
Mar 18 08:42:29.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 exec --namespace=e2e-tests-statefulset-57qf8 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 18 08:42:29.319: INFO: stderr: ""
Mar 18 08:42:29.319: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 18 08:42:29.319: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 18 08:42:29.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 exec --namespace=e2e-tests-statefulset-57qf8 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 18 08:42:29.503: INFO: stderr: ""
Mar 18 08:42:29.503: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 18 08:42:29.503: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 18 08:42:29.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 exec --namespace=e2e-tests-statefulset-57qf8 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 18 08:42:29.692: INFO: stderr: ""
Mar 18 08:42:29.692: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 18 08:42:29.692: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 18 08:42:29.692: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 18 08:42:39.707: INFO: Deleting all statefulset in ns e2e-tests-statefulset-57qf8
Mar 18 08:42:39.710: INFO: Scaling statefulset ss to 0
Mar 18 08:42:39.719: INFO: Waiting for statefulset status.replicas updated to 0
Mar 18 08:42:39.722: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:42:39.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-57qf8" for this suite.
Mar 18 08:42:45.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:42:45.793: INFO: namespace: e2e-tests-statefulset-57qf8, resource: bindings, ignored listing per whitelist
Mar 18 08:42:45.867: INFO: namespace e2e-tests-statefulset-57qf8 deletion completed in 6.125633798s

â€¢ [SLOW TEST:78.201 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:42:45.867: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 18 08:43:04.010: INFO: Container started at 2019-03-18 08:42:47 +0000 UTC, pod became ready at 2019-03-18 08:43:02 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:43:04.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-2vkwj" for this suite.
Mar 18 08:43:26.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:43:26.054: INFO: namespace: e2e-tests-container-probe-2vkwj, resource: bindings, ignored listing per whitelist
Mar 18 08:43:26.138: INFO: namespace e2e-tests-container-probe-2vkwj deletion completed in 22.12319138s

â€¢ [SLOW TEST:40.271 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:43:26.139: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-e582cee7-4959-11e9-86d2-4ea95915efee
STEP: Creating a pod to test consume configMaps
Mar 18 08:43:26.306: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e5834357-4959-11e9-86d2-4ea95915efee" in namespace "e2e-tests-projected-7w2gg" to be "success or failure"
Mar 18 08:43:26.315: INFO: Pod "pod-projected-configmaps-e5834357-4959-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 9.003137ms
Mar 18 08:43:28.319: INFO: Pod "pod-projected-configmaps-e5834357-4959-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013154788s
STEP: Saw pod success
Mar 18 08:43:28.319: INFO: Pod "pod-projected-configmaps-e5834357-4959-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:43:28.322: INFO: Trying to get logs from node worker01 pod pod-projected-configmaps-e5834357-4959-11e9-86d2-4ea95915efee container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 18 08:43:28.348: INFO: Waiting for pod pod-projected-configmaps-e5834357-4959-11e9-86d2-4ea95915efee to disappear
Mar 18 08:43:28.353: INFO: Pod pod-projected-configmaps-e5834357-4959-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:43:28.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7w2gg" for this suite.
Mar 18 08:43:34.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:43:34.414: INFO: namespace: e2e-tests-projected-7w2gg, resource: bindings, ignored listing per whitelist
Mar 18 08:43:34.473: INFO: namespace e2e-tests-projected-7w2gg deletion completed in 6.113220559s

â€¢ [SLOW TEST:8.334 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:43:34.473: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar 18 08:43:34.567: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:43:37.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-tlpcm" for this suite.
Mar 18 08:43:43.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:43:43.537: INFO: namespace: e2e-tests-init-container-tlpcm, resource: bindings, ignored listing per whitelist
Mar 18 08:43:43.644: INFO: namespace e2e-tests-init-container-tlpcm deletion completed in 6.137974633s

â€¢ [SLOW TEST:9.172 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:43:43.645: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 18 08:43:43.740: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Mar 18 08:43:43.747: INFO: Pod name sample-pod: Found 0 pods out of 1
Mar 18 08:43:48.751: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar 18 08:43:48.751: INFO: Creating deployment "test-rolling-update-deployment"
Mar 18 08:43:48.759: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Mar 18 08:43:48.792: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Mar 18 08:43:50.798: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Mar 18 08:43:50.801: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 18 08:43:50.819: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-fq2tv,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fq2tv/deployments/test-rolling-update-deployment,UID:f2e55738-4959-11e9-b44d-0022480537ee,ResourceVersion:202330,Generation:1,CreationTimestamp:2019-03-18 08:43:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-03-18 08:43:48 +0000 UTC 2019-03-18 08:43:48 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-03-18 08:43:50 +0000 UTC 2019-03-18 08:43:48 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Mar 18 08:43:50.822: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-fq2tv,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fq2tv/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:f2eb89ac-4959-11e9-b44d-0022480537ee,ResourceVersion:202321,Generation:1,CreationTimestamp:2019-03-18 08:43:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment f2e55738-4959-11e9-b44d-0022480537ee 0xc001c0f407 0xc001c0f408}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar 18 08:43:50.822: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Mar 18 08:43:50.822: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-fq2tv,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fq2tv/replicasets/test-rolling-update-controller,UID:efe838ca-4959-11e9-b44d-0022480537ee,ResourceVersion:202329,Generation:2,CreationTimestamp:2019-03-18 08:43:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment f2e55738-4959-11e9-b44d-0022480537ee 0xc001c0f347 0xc001c0f348}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 18 08:43:50.826: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-qfftr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-qfftr,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-fq2tv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fq2tv/pods/test-rolling-update-deployment-68b55d7bc6-qfftr,UID:f2ed109c-4959-11e9-b44d-0022480537ee,ResourceVersion:202320,Generation:0,CreationTimestamp:2019-03-18 08:43:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 f2eb89ac-4959-11e9-b44d-0022480537ee 0xc001c0fe47 0xc001c0fe48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-h6nj8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-h6nj8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-h6nj8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker02,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c0fec0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c0fee0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:43:48 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:43:50 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:43:50 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:43:48 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.4,PodIP:10.38.0.8,StartTime:2019-03-18 08:43:48 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-03-18 08:43:49 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://5fad319e062825c2da0e04424445d24cd1f2dbb17539112316ad378b8f629663}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:43:50.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-fq2tv" for this suite.
Mar 18 08:43:56.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:43:56.921: INFO: namespace: e2e-tests-deployment-fq2tv, resource: bindings, ignored listing per whitelist
Mar 18 08:43:56.948: INFO: namespace e2e-tests-deployment-fq2tv deletion completed in 6.11759972s

â€¢ [SLOW TEST:13.304 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:43:56.948: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 18 08:43:57.047: INFO: Creating deployment "test-recreate-deployment"
Mar 18 08:43:57.061: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Mar 18 08:43:57.070: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Mar 18 08:43:59.077: INFO: Waiting deployment "test-recreate-deployment" to complete
Mar 18 08:43:59.080: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Mar 18 08:43:59.088: INFO: Updating deployment test-recreate-deployment
Mar 18 08:43:59.088: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 18 08:43:59.179: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-j8xq8,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-j8xq8/deployments/test-recreate-deployment,UID:f7d76229-4959-11e9-b44d-0022480537ee,ResourceVersion:202411,Generation:2,CreationTimestamp:2019-03-18 08:43:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-03-18 08:43:59 +0000 UTC 2019-03-18 08:43:59 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-03-18 08:43:59 +0000 UTC 2019-03-18 08:43:57 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Mar 18 08:43:59.182: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-j8xq8,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-j8xq8/replicasets/test-recreate-deployment-697fbf54bf,UID:f9138e8f-4959-11e9-b44d-0022480537ee,ResourceVersion:202410,Generation:1,CreationTimestamp:2019-03-18 08:43:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment f7d76229-4959-11e9-b44d-0022480537ee 0xc0022f37d7 0xc0022f37d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 18 08:43:59.182: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Mar 18 08:43:59.182: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-j8xq8,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-j8xq8/replicasets/test-recreate-deployment-5dfdcc846d,UID:f7d8acb0-4959-11e9-b44d-0022480537ee,ResourceVersion:202399,Generation:2,CreationTimestamp:2019-03-18 08:43:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment f7d76229-4959-11e9-b44d-0022480537ee 0xc0022f3717 0xc0022f3718}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 18 08:43:59.185: INFO: Pod "test-recreate-deployment-697fbf54bf-dxvxn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-dxvxn,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-j8xq8,SelfLink:/api/v1/namespaces/e2e-tests-deployment-j8xq8/pods/test-recreate-deployment-697fbf54bf-dxvxn,UID:f913ee04-4959-11e9-b44d-0022480537ee,ResourceVersion:202409,Generation:0,CreationTimestamp:2019-03-18 08:43:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf f9138e8f-4959-11e9-b44d-0022480537ee 0xc0026ac027 0xc0026ac028}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-77m98 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-77m98,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-77m98 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker02,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0026ac0a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0026ac0c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:43:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:43:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:43:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:43:59 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.4,PodIP:,StartTime:2019-03-18 08:43:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:43:59.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-j8xq8" for this suite.
Mar 18 08:44:05.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:44:05.257: INFO: namespace: e2e-tests-deployment-j8xq8, resource: bindings, ignored listing per whitelist
Mar 18 08:44:05.309: INFO: namespace e2e-tests-deployment-j8xq8 deletion completed in 6.118941199s

â€¢ [SLOW TEST:8.360 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:44:05.309: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-fcd1aacb-4959-11e9-86d2-4ea95915efee
STEP: Creating a pod to test consume configMaps
Mar 18 08:44:05.417: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-fcd2e7ee-4959-11e9-86d2-4ea95915efee" in namespace "e2e-tests-projected-qpf5r" to be "success or failure"
Mar 18 08:44:05.439: INFO: Pod "pod-projected-configmaps-fcd2e7ee-4959-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 22.390634ms
Mar 18 08:44:07.443: INFO: Pod "pod-projected-configmaps-fcd2e7ee-4959-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025770539s
STEP: Saw pod success
Mar 18 08:44:07.443: INFO: Pod "pod-projected-configmaps-fcd2e7ee-4959-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:44:07.445: INFO: Trying to get logs from node worker01 pod pod-projected-configmaps-fcd2e7ee-4959-11e9-86d2-4ea95915efee container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 18 08:44:07.470: INFO: Waiting for pod pod-projected-configmaps-fcd2e7ee-4959-11e9-86d2-4ea95915efee to disappear
Mar 18 08:44:07.473: INFO: Pod pod-projected-configmaps-fcd2e7ee-4959-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:44:07.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qpf5r" for this suite.
Mar 18 08:44:13.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:44:13.541: INFO: namespace: e2e-tests-projected-qpf5r, resource: bindings, ignored listing per whitelist
Mar 18 08:44:13.596: INFO: namespace e2e-tests-projected-qpf5r deletion completed in 6.114516335s

â€¢ [SLOW TEST:8.287 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:44:13.596: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 18 08:44:13.724: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:44:14.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-vdbgq" for this suite.
Mar 18 08:44:20.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:44:20.875: INFO: namespace: e2e-tests-custom-resource-definition-vdbgq, resource: bindings, ignored listing per whitelist
Mar 18 08:44:20.906: INFO: namespace e2e-tests-custom-resource-definition-vdbgq deletion completed in 6.126196832s

â€¢ [SLOW TEST:7.310 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:44:20.906: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-061ddb9d-495a-11e9-86d2-4ea95915efee
STEP: Creating a pod to test consume secrets
Mar 18 08:44:21.013: INFO: Waiting up to 5m0s for pod "pod-secrets-061e7526-495a-11e9-86d2-4ea95915efee" in namespace "e2e-tests-secrets-wp442" to be "success or failure"
Mar 18 08:44:21.027: INFO: Pod "pod-secrets-061e7526-495a-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 13.556908ms
Mar 18 08:44:23.031: INFO: Pod "pod-secrets-061e7526-495a-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017422242s
STEP: Saw pod success
Mar 18 08:44:23.031: INFO: Pod "pod-secrets-061e7526-495a-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:44:23.033: INFO: Trying to get logs from node worker02 pod pod-secrets-061e7526-495a-11e9-86d2-4ea95915efee container secret-volume-test: <nil>
STEP: delete the pod
Mar 18 08:44:23.058: INFO: Waiting for pod pod-secrets-061e7526-495a-11e9-86d2-4ea95915efee to disappear
Mar 18 08:44:23.061: INFO: Pod pod-secrets-061e7526-495a-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:44:23.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-wp442" for this suite.
Mar 18 08:44:29.078: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:44:29.123: INFO: namespace: e2e-tests-secrets-wp442, resource: bindings, ignored listing per whitelist
Mar 18 08:44:29.180: INFO: namespace e2e-tests-secrets-wp442 deletion completed in 6.114648744s

â€¢ [SLOW TEST:8.274 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:44:29.180: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-8brcb/secret-test-0b0bd8aa-495a-11e9-86d2-4ea95915efee
STEP: Creating a pod to test consume secrets
Mar 18 08:44:29.285: INFO: Waiting up to 5m0s for pod "pod-configmaps-0b0c4e5c-495a-11e9-86d2-4ea95915efee" in namespace "e2e-tests-secrets-8brcb" to be "success or failure"
Mar 18 08:44:29.288: INFO: Pod "pod-configmaps-0b0c4e5c-495a-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 3.054582ms
Mar 18 08:44:31.295: INFO: Pod "pod-configmaps-0b0c4e5c-495a-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010362221s
STEP: Saw pod success
Mar 18 08:44:31.295: INFO: Pod "pod-configmaps-0b0c4e5c-495a-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:44:31.298: INFO: Trying to get logs from node worker01 pod pod-configmaps-0b0c4e5c-495a-11e9-86d2-4ea95915efee container env-test: <nil>
STEP: delete the pod
Mar 18 08:44:31.321: INFO: Waiting for pod pod-configmaps-0b0c4e5c-495a-11e9-86d2-4ea95915efee to disappear
Mar 18 08:44:31.323: INFO: Pod pod-configmaps-0b0c4e5c-495a-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:44:31.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-8brcb" for this suite.
Mar 18 08:44:37.338: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:44:37.410: INFO: namespace: e2e-tests-secrets-8brcb, resource: bindings, ignored listing per whitelist
Mar 18 08:44:37.445: INFO: namespace e2e-tests-secrets-8brcb deletion completed in 6.117526215s

â€¢ [SLOW TEST:8.265 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:44:37.446: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Mar 18 08:44:39.588: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:45:03.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-wx4sc" for this suite.
Mar 18 08:45:09.699: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:45:09.765: INFO: namespace: e2e-tests-namespaces-wx4sc, resource: bindings, ignored listing per whitelist
Mar 18 08:45:09.798: INFO: namespace e2e-tests-namespaces-wx4sc deletion completed in 6.158395151s
STEP: Destroying namespace "e2e-tests-nsdeletetest-dvppf" for this suite.
Mar 18 08:45:09.801: INFO: Namespace e2e-tests-nsdeletetest-dvppf was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-qs4qj" for this suite.
Mar 18 08:45:15.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:45:15.900: INFO: namespace: e2e-tests-nsdeletetest-qs4qj, resource: bindings, ignored listing per whitelist
Mar 18 08:45:15.912: INFO: namespace e2e-tests-nsdeletetest-qs4qj deletion completed in 6.11106583s

â€¢ [SLOW TEST:38.466 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:45:15.912: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-npll9
I0318 08:45:16.008492      18 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-npll9, replica count: 1
I0318 08:45:17.058948      18 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0318 08:45:18.059178      18 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0318 08:45:19.059415      18 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar 18 08:45:19.181: INFO: Created: latency-svc-bzlng
Mar 18 08:45:19.188: INFO: Got endpoints: latency-svc-bzlng [28.5299ms]
Mar 18 08:45:19.230: INFO: Created: latency-svc-nb57g
Mar 18 08:45:19.251: INFO: Got endpoints: latency-svc-nb57g [62.716438ms]
Mar 18 08:45:19.252: INFO: Created: latency-svc-ql8g9
Mar 18 08:45:19.268: INFO: Got endpoints: latency-svc-ql8g9 [79.245323ms]
Mar 18 08:45:19.270: INFO: Created: latency-svc-rjlrp
Mar 18 08:45:19.277: INFO: Got endpoints: latency-svc-rjlrp [87.995144ms]
Mar 18 08:45:19.289: INFO: Created: latency-svc-g76rz
Mar 18 08:45:19.291: INFO: Got endpoints: latency-svc-g76rz [102.231493ms]
Mar 18 08:45:19.312: INFO: Created: latency-svc-b8xkb
Mar 18 08:45:19.316: INFO: Got endpoints: latency-svc-b8xkb [126.629147ms]
Mar 18 08:45:19.328: INFO: Created: latency-svc-kvkvf
Mar 18 08:45:19.343: INFO: Got endpoints: latency-svc-kvkvf [154.482508ms]
Mar 18 08:45:19.347: INFO: Created: latency-svc-6cnbr
Mar 18 08:45:19.351: INFO: Got endpoints: latency-svc-6cnbr [161.515726ms]
Mar 18 08:45:19.373: INFO: Created: latency-svc-bxmx9
Mar 18 08:45:19.387: INFO: Created: latency-svc-fh46d
Mar 18 08:45:19.387: INFO: Got endpoints: latency-svc-bxmx9 [197.552374ms]
Mar 18 08:45:19.402: INFO: Got endpoints: latency-svc-fh46d [213.773141ms]
Mar 18 08:45:19.403: INFO: Created: latency-svc-pvgwm
Mar 18 08:45:19.405: INFO: Got endpoints: latency-svc-pvgwm [215.652753ms]
Mar 18 08:45:19.429: INFO: Created: latency-svc-nvbv5
Mar 18 08:45:19.433: INFO: Got endpoints: latency-svc-nvbv5 [242.912478ms]
Mar 18 08:45:19.504: INFO: Created: latency-svc-l4vrz
Mar 18 08:45:19.507: INFO: Got endpoints: latency-svc-l4vrz [317.025095ms]
Mar 18 08:45:19.523: INFO: Created: latency-svc-jmfft
Mar 18 08:45:19.528: INFO: Got endpoints: latency-svc-jmfft [338.557779ms]
Mar 18 08:45:19.542: INFO: Created: latency-svc-7q4wn
Mar 18 08:45:19.546: INFO: Got endpoints: latency-svc-7q4wn [356.612954ms]
Mar 18 08:45:19.567: INFO: Created: latency-svc-gqtw6
Mar 18 08:45:19.571: INFO: Got endpoints: latency-svc-gqtw6 [381.02991ms]
Mar 18 08:45:19.585: INFO: Created: latency-svc-tbztw
Mar 18 08:45:19.599: INFO: Got endpoints: latency-svc-tbztw [348.058145ms]
Mar 18 08:45:19.599: INFO: Created: latency-svc-4s69k
Mar 18 08:45:19.703: INFO: Got endpoints: latency-svc-4s69k [434.959324ms]
Mar 18 08:45:19.706: INFO: Created: latency-svc-q57zg
Mar 18 08:45:19.710: INFO: Got endpoints: latency-svc-q57zg [432.932803ms]
Mar 18 08:45:19.727: INFO: Created: latency-svc-2fxs8
Mar 18 08:45:19.732: INFO: Got endpoints: latency-svc-2fxs8 [440.541257ms]
Mar 18 08:45:19.744: INFO: Created: latency-svc-gwf97
Mar 18 08:45:19.747: INFO: Got endpoints: latency-svc-gwf97 [431.729131ms]
Mar 18 08:45:19.760: INFO: Created: latency-svc-bfxvs
Mar 18 08:45:19.768: INFO: Got endpoints: latency-svc-bfxvs [423.991871ms]
Mar 18 08:45:19.779: INFO: Created: latency-svc-9wgqg
Mar 18 08:45:19.781: INFO: Got endpoints: latency-svc-9wgqg [429.68461ms]
Mar 18 08:45:19.796: INFO: Created: latency-svc-r45l7
Mar 18 08:45:19.799: INFO: Got endpoints: latency-svc-r45l7 [412.198168ms]
Mar 18 08:45:19.863: INFO: Created: latency-svc-5gqgm
Mar 18 08:45:19.865: INFO: Got endpoints: latency-svc-5gqgm [462.097941ms]
Mar 18 08:45:19.890: INFO: Created: latency-svc-vqgxf
Mar 18 08:45:19.898: INFO: Got endpoints: latency-svc-vqgxf [493.035185ms]
Mar 18 08:45:19.916: INFO: Created: latency-svc-dz7c9
Mar 18 08:45:19.921: INFO: Got endpoints: latency-svc-dz7c9 [487.871178ms]
Mar 18 08:45:19.945: INFO: Created: latency-svc-rs2qk
Mar 18 08:45:19.949: INFO: Got endpoints: latency-svc-rs2qk [441.859735ms]
Mar 18 08:45:19.991: INFO: Created: latency-svc-h8fjd
Mar 18 08:45:19.994: INFO: Got endpoints: latency-svc-h8fjd [465.528546ms]
Mar 18 08:45:20.009: INFO: Created: latency-svc-cx652
Mar 18 08:45:20.017: INFO: Got endpoints: latency-svc-cx652 [470.234127ms]
Mar 18 08:45:20.034: INFO: Created: latency-svc-jxxnk
Mar 18 08:45:20.036: INFO: Got endpoints: latency-svc-jxxnk [465.215428ms]
Mar 18 08:45:20.113: INFO: Created: latency-svc-tlhrn
Mar 18 08:45:20.115: INFO: Got endpoints: latency-svc-tlhrn [516.335974ms]
Mar 18 08:45:20.129: INFO: Created: latency-svc-qvwkx
Mar 18 08:45:20.139: INFO: Got endpoints: latency-svc-qvwkx [436.536818ms]
Mar 18 08:45:20.196: INFO: Created: latency-svc-vjffg
Mar 18 08:45:20.198: INFO: Got endpoints: latency-svc-vjffg [487.986085ms]
Mar 18 08:45:20.239: INFO: Created: latency-svc-5ghtx
Mar 18 08:45:20.242: INFO: Got endpoints: latency-svc-5ghtx [510.477626ms]
Mar 18 08:45:20.260: INFO: Created: latency-svc-l766p
Mar 18 08:45:20.280: INFO: Got endpoints: latency-svc-l766p [532.235422ms]
Mar 18 08:45:20.281: INFO: Created: latency-svc-8qx25
Mar 18 08:45:20.290: INFO: Got endpoints: latency-svc-8qx25 [521.96341ms]
Mar 18 08:45:20.305: INFO: Created: latency-svc-cqpdj
Mar 18 08:45:20.312: INFO: Got endpoints: latency-svc-cqpdj [531.731492ms]
Mar 18 08:45:20.332: INFO: Created: latency-svc-gmhkh
Mar 18 08:45:20.363: INFO: Created: latency-svc-w2bxr
Mar 18 08:45:20.363: INFO: Got endpoints: latency-svc-gmhkh [563.381079ms]
Mar 18 08:45:20.377: INFO: Got endpoints: latency-svc-w2bxr [511.909911ms]
Mar 18 08:45:20.379: INFO: Created: latency-svc-ttnjt
Mar 18 08:45:20.385: INFO: Got endpoints: latency-svc-ttnjt [486.414891ms]
Mar 18 08:45:20.406: INFO: Created: latency-svc-tscpw
Mar 18 08:45:20.419: INFO: Got endpoints: latency-svc-tscpw [498.272197ms]
Mar 18 08:45:20.421: INFO: Created: latency-svc-xn2pw
Mar 18 08:45:20.423: INFO: Got endpoints: latency-svc-xn2pw [474.770097ms]
Mar 18 08:45:20.439: INFO: Created: latency-svc-jm8bt
Mar 18 08:45:20.444: INFO: Got endpoints: latency-svc-jm8bt [450.330841ms]
Mar 18 08:45:20.524: INFO: Created: latency-svc-mbhxp
Mar 18 08:45:20.528: INFO: Got endpoints: latency-svc-mbhxp [510.999757ms]
Mar 18 08:45:20.546: INFO: Created: latency-svc-gm5pq
Mar 18 08:45:20.549: INFO: Got endpoints: latency-svc-gm5pq [512.889369ms]
Mar 18 08:45:20.594: INFO: Created: latency-svc-gpwr6
Mar 18 08:45:20.608: INFO: Got endpoints: latency-svc-gpwr6 [492.379147ms]
Mar 18 08:45:20.609: INFO: Created: latency-svc-chtvc
Mar 18 08:45:20.611: INFO: Got endpoints: latency-svc-chtvc [471.988931ms]
Mar 18 08:45:20.643: INFO: Created: latency-svc-j8zmk
Mar 18 08:45:20.661: INFO: Got endpoints: latency-svc-j8zmk [463.56753ms]
Mar 18 08:45:20.662: INFO: Created: latency-svc-dxqjg
Mar 18 08:45:20.668: INFO: Got endpoints: latency-svc-dxqjg [425.519662ms]
Mar 18 08:45:20.727: INFO: Created: latency-svc-thxb8
Mar 18 08:45:20.733: INFO: Got endpoints: latency-svc-thxb8 [453.590735ms]
Mar 18 08:45:20.798: INFO: Created: latency-svc-hg7sc
Mar 18 08:45:20.818: INFO: Got endpoints: latency-svc-hg7sc [528.475998ms]
Mar 18 08:45:20.820: INFO: Created: latency-svc-v2tk7
Mar 18 08:45:20.829: INFO: Got endpoints: latency-svc-v2tk7 [516.618391ms]
Mar 18 08:45:20.842: INFO: Created: latency-svc-n9zj4
Mar 18 08:45:20.846: INFO: Got endpoints: latency-svc-n9zj4 [483.155997ms]
Mar 18 08:45:20.859: INFO: Created: latency-svc-2g4b4
Mar 18 08:45:20.862: INFO: Got endpoints: latency-svc-2g4b4 [485.012307ms]
Mar 18 08:45:20.898: INFO: Created: latency-svc-wsmvb
Mar 18 08:45:20.915: INFO: Got endpoints: latency-svc-wsmvb [529.913383ms]
Mar 18 08:45:20.918: INFO: Created: latency-svc-hjdnw
Mar 18 08:45:20.927: INFO: Got endpoints: latency-svc-hjdnw [508.159187ms]
Mar 18 08:45:20.943: INFO: Created: latency-svc-9p2hc
Mar 18 08:45:20.958: INFO: Created: latency-svc-8ksrx
Mar 18 08:45:20.959: INFO: Got endpoints: latency-svc-9p2hc [535.393811ms]
Mar 18 08:45:20.964: INFO: Got endpoints: latency-svc-8ksrx [519.581268ms]
Mar 18 08:45:20.978: INFO: Created: latency-svc-2w75h
Mar 18 08:45:20.981: INFO: Got endpoints: latency-svc-2w75h [453.675339ms]
Mar 18 08:45:20.995: INFO: Created: latency-svc-chdw2
Mar 18 08:45:21.003: INFO: Got endpoints: latency-svc-chdw2 [454.01046ms]
Mar 18 08:45:21.014: INFO: Created: latency-svc-cj5zt
Mar 18 08:45:21.038: INFO: Got endpoints: latency-svc-cj5zt [430.752974ms]
Mar 18 08:45:21.041: INFO: Created: latency-svc-k9fxk
Mar 18 08:45:21.045: INFO: Got endpoints: latency-svc-k9fxk [433.344928ms]
Mar 18 08:45:21.064: INFO: Created: latency-svc-rwfzm
Mar 18 08:45:21.082: INFO: Got endpoints: latency-svc-rwfzm [420.391956ms]
Mar 18 08:45:21.082: INFO: Created: latency-svc-vfkzw
Mar 18 08:45:21.092: INFO: Got endpoints: latency-svc-vfkzw [424.115378ms]
Mar 18 08:45:21.105: INFO: Created: latency-svc-c8lqk
Mar 18 08:45:21.121: INFO: Got endpoints: latency-svc-c8lqk [387.868118ms]
Mar 18 08:45:21.122: INFO: Created: latency-svc-8s96x
Mar 18 08:45:21.139: INFO: Created: latency-svc-94h4c
Mar 18 08:45:21.139: INFO: Got endpoints: latency-svc-8s96x [321.382355ms]
Mar 18 08:45:21.258: INFO: Got endpoints: latency-svc-94h4c [428.769556ms]
Mar 18 08:45:21.259: INFO: Created: latency-svc-xdntv
Mar 18 08:45:21.274: INFO: Created: latency-svc-2rm55
Mar 18 08:45:21.277: INFO: Got endpoints: latency-svc-xdntv [430.677369ms]
Mar 18 08:45:21.281: INFO: Got endpoints: latency-svc-2rm55 [418.970972ms]
Mar 18 08:45:21.293: INFO: Created: latency-svc-w98r7
Mar 18 08:45:21.307: INFO: Got endpoints: latency-svc-w98r7 [391.890157ms]
Mar 18 08:45:21.307: INFO: Created: latency-svc-qjjss
Mar 18 08:45:21.316: INFO: Got endpoints: latency-svc-qjjss [388.619562ms]
Mar 18 08:45:21.326: INFO: Created: latency-svc-tjx6f
Mar 18 08:45:21.339: INFO: Created: latency-svc-phldx
Mar 18 08:45:21.339: INFO: Got endpoints: latency-svc-tjx6f [380.254264ms]
Mar 18 08:45:21.368: INFO: Created: latency-svc-k2zpc
Mar 18 08:45:21.391: INFO: Got endpoints: latency-svc-phldx [427.612986ms]
Mar 18 08:45:21.391: INFO: Created: latency-svc-l6k25
Mar 18 08:45:21.408: INFO: Created: latency-svc-85bkt
Mar 18 08:45:21.422: INFO: Created: latency-svc-h486s
Mar 18 08:45:21.441: INFO: Created: latency-svc-qr7k7
Mar 18 08:45:21.441: INFO: Got endpoints: latency-svc-k2zpc [459.831907ms]
Mar 18 08:45:21.457: INFO: Created: latency-svc-vfmkr
Mar 18 08:45:21.511: INFO: Created: latency-svc-d4cqn
Mar 18 08:45:21.512: INFO: Got endpoints: latency-svc-l6k25 [509.263853ms]
Mar 18 08:45:21.539: INFO: Got endpoints: latency-svc-85bkt [500.894555ms]
Mar 18 08:45:21.540: INFO: Created: latency-svc-tqmvr
Mar 18 08:45:21.562: INFO: Created: latency-svc-f4mgj
Mar 18 08:45:21.573: INFO: Created: latency-svc-lrctk
Mar 18 08:45:21.595: INFO: Got endpoints: latency-svc-h486s [550.420406ms]
Mar 18 08:45:21.596: INFO: Created: latency-svc-s8ssk
Mar 18 08:45:21.628: INFO: Created: latency-svc-r7hq6
Mar 18 08:45:21.641: INFO: Created: latency-svc-2wxhw
Mar 18 08:45:21.642: INFO: Got endpoints: latency-svc-qr7k7 [560.148585ms]
Mar 18 08:45:21.661: INFO: Created: latency-svc-sftmd
Mar 18 08:45:21.674: INFO: Created: latency-svc-cjccv
Mar 18 08:45:21.688: INFO: Created: latency-svc-xrczv
Mar 18 08:45:21.688: INFO: Got endpoints: latency-svc-vfmkr [595.78651ms]
Mar 18 08:45:21.707: INFO: Created: latency-svc-8mtd2
Mar 18 08:45:21.722: INFO: Created: latency-svc-vzcpj
Mar 18 08:45:21.750: INFO: Got endpoints: latency-svc-d4cqn [628.531862ms]
Mar 18 08:45:21.753: INFO: Created: latency-svc-6n4hs
Mar 18 08:45:21.796: INFO: Got endpoints: latency-svc-tqmvr [656.367521ms]
Mar 18 08:45:21.810: INFO: Created: latency-svc-b4twh
Mar 18 08:45:21.875: INFO: Got endpoints: latency-svc-f4mgj [617.291992ms]
Mar 18 08:45:21.875: INFO: Created: latency-svc-2r2qs
Mar 18 08:45:21.891: INFO: Got endpoints: latency-svc-lrctk [614.24911ms]
Mar 18 08:45:21.891: INFO: Created: latency-svc-j4fnv
Mar 18 08:45:21.920: INFO: Created: latency-svc-6c96r
Mar 18 08:45:21.934: INFO: Created: latency-svc-kz68g
Mar 18 08:45:21.937: INFO: Got endpoints: latency-svc-s8ssk [655.976197ms]
Mar 18 08:45:21.953: INFO: Created: latency-svc-28nj7
Mar 18 08:45:21.966: INFO: Created: latency-svc-smwjf
Mar 18 08:45:22.000: INFO: Got endpoints: latency-svc-r7hq6 [693.145413ms]
Mar 18 08:45:22.020: INFO: Created: latency-svc-mvn9k
Mar 18 08:45:22.035: INFO: Got endpoints: latency-svc-2wxhw [718.890847ms]
Mar 18 08:45:22.052: INFO: Created: latency-svc-smfhp
Mar 18 08:45:22.088: INFO: Got endpoints: latency-svc-sftmd [748.835232ms]
Mar 18 08:45:22.116: INFO: Created: latency-svc-p5hdd
Mar 18 08:45:22.134: INFO: Got endpoints: latency-svc-cjccv [742.320843ms]
Mar 18 08:45:22.153: INFO: Created: latency-svc-bcqpd
Mar 18 08:45:22.184: INFO: Got endpoints: latency-svc-xrczv [742.405749ms]
Mar 18 08:45:22.211: INFO: Created: latency-svc-sr9cf
Mar 18 08:45:22.234: INFO: Got endpoints: latency-svc-8mtd2 [722.172442ms]
Mar 18 08:45:22.252: INFO: Created: latency-svc-68hp7
Mar 18 08:45:22.284: INFO: Got endpoints: latency-svc-vzcpj [744.529175ms]
Mar 18 08:45:22.301: INFO: Created: latency-svc-k6n9z
Mar 18 08:45:22.348: INFO: Got endpoints: latency-svc-6n4hs [753.259396ms]
Mar 18 08:45:22.368: INFO: Created: latency-svc-2nzgq
Mar 18 08:45:22.384: INFO: Got endpoints: latency-svc-b4twh [741.873717ms]
Mar 18 08:45:22.406: INFO: Created: latency-svc-dv6p5
Mar 18 08:45:22.434: INFO: Got endpoints: latency-svc-2r2qs [746.146972ms]
Mar 18 08:45:22.507: INFO: Got endpoints: latency-svc-j4fnv [756.916414ms]
Mar 18 08:45:22.507: INFO: Created: latency-svc-6t246
Mar 18 08:45:22.526: INFO: Created: latency-svc-8b69d
Mar 18 08:45:22.536: INFO: Got endpoints: latency-svc-6c96r [739.841696ms]
Mar 18 08:45:22.555: INFO: Created: latency-svc-cqxjh
Mar 18 08:45:22.585: INFO: Got endpoints: latency-svc-kz68g [709.507088ms]
Mar 18 08:45:22.624: INFO: Created: latency-svc-cd5s7
Mar 18 08:45:22.635: INFO: Got endpoints: latency-svc-28nj7 [743.792332ms]
Mar 18 08:45:22.757: INFO: Got endpoints: latency-svc-smwjf [820.092078ms]
Mar 18 08:45:22.758: INFO: Created: latency-svc-pbbfq
Mar 18 08:45:22.758: INFO: Got endpoints: latency-svc-mvn9k [757.86577ms]
Mar 18 08:45:22.775: INFO: Created: latency-svc-jh5sz
Mar 18 08:45:22.791: INFO: Got endpoints: latency-svc-smfhp [756.297677ms]
Mar 18 08:45:22.791: INFO: Created: latency-svc-lx5zf
Mar 18 08:45:22.812: INFO: Created: latency-svc-cpr2c
Mar 18 08:45:22.835: INFO: Got endpoints: latency-svc-p5hdd [746.621ms]
Mar 18 08:45:22.852: INFO: Created: latency-svc-vvfqm
Mar 18 08:45:22.885: INFO: Got endpoints: latency-svc-bcqpd [751.418986ms]
Mar 18 08:45:22.902: INFO: Created: latency-svc-vrtkg
Mar 18 08:45:22.934: INFO: Got endpoints: latency-svc-sr9cf [750.067905ms]
Mar 18 08:45:22.952: INFO: Created: latency-svc-vfnwp
Mar 18 08:45:23.004: INFO: Got endpoints: latency-svc-68hp7 [769.339453ms]
Mar 18 08:45:23.030: INFO: Created: latency-svc-qltnc
Mar 18 08:45:23.034: INFO: Got endpoints: latency-svc-k6n9z [749.768887ms]
Mar 18 08:45:23.053: INFO: Created: latency-svc-vv6t8
Mar 18 08:45:23.085: INFO: Got endpoints: latency-svc-2nzgq [736.126774ms]
Mar 18 08:45:23.123: INFO: Created: latency-svc-6cqxw
Mar 18 08:45:23.134: INFO: Got endpoints: latency-svc-dv6p5 [750.405726ms]
Mar 18 08:45:23.153: INFO: Created: latency-svc-bb4x7
Mar 18 08:45:23.185: INFO: Got endpoints: latency-svc-6t246 [750.774448ms]
Mar 18 08:45:23.203: INFO: Created: latency-svc-q48vh
Mar 18 08:45:23.243: INFO: Got endpoints: latency-svc-8b69d [736.007567ms]
Mar 18 08:45:23.261: INFO: Created: latency-svc-vxjbq
Mar 18 08:45:23.284: INFO: Got endpoints: latency-svc-cqxjh [748.123689ms]
Mar 18 08:45:23.307: INFO: Created: latency-svc-n4sgd
Mar 18 08:45:23.334: INFO: Got endpoints: latency-svc-cd5s7 [749.311461ms]
Mar 18 08:45:23.401: INFO: Created: latency-svc-pvfmw
Mar 18 08:45:23.402: INFO: Got endpoints: latency-svc-pbbfq [766.7598ms]
Mar 18 08:45:23.423: INFO: Created: latency-svc-b4r4q
Mar 18 08:45:23.434: INFO: Got endpoints: latency-svc-jh5sz [677.013251ms]
Mar 18 08:45:23.454: INFO: Created: latency-svc-dk2hn
Mar 18 08:45:23.484: INFO: Got endpoints: latency-svc-lx5zf [726.046474ms]
Mar 18 08:45:23.532: INFO: Created: latency-svc-95bck
Mar 18 08:45:23.534: INFO: Got endpoints: latency-svc-cpr2c [742.635562ms]
Mar 18 08:45:23.652: INFO: Created: latency-svc-p7t9x
Mar 18 08:45:23.652: INFO: Got endpoints: latency-svc-vrtkg [766.43118ms]
Mar 18 08:45:23.652: INFO: Got endpoints: latency-svc-vvfqm [816.947191ms]
Mar 18 08:45:23.670: INFO: Created: latency-svc-fl8b7
Mar 18 08:45:23.688: INFO: Got endpoints: latency-svc-vfnwp [754.031242ms]
Mar 18 08:45:23.688: INFO: Created: latency-svc-jsmb4
Mar 18 08:45:23.717: INFO: Created: latency-svc-2hvhf
Mar 18 08:45:23.743: INFO: Got endpoints: latency-svc-qltnc [738.703028ms]
Mar 18 08:45:23.774: INFO: Created: latency-svc-7f9mk
Mar 18 08:45:23.785: INFO: Got endpoints: latency-svc-vv6t8 [750.788848ms]
Mar 18 08:45:23.804: INFO: Created: latency-svc-pn4xg
Mar 18 08:45:23.834: INFO: Got endpoints: latency-svc-6cqxw [749.688983ms]
Mar 18 08:45:23.850: INFO: Created: latency-svc-k2dxl
Mar 18 08:45:23.943: INFO: Got endpoints: latency-svc-q48vh [758.621615ms]
Mar 18 08:45:23.943: INFO: Got endpoints: latency-svc-bb4x7 [809.109325ms]
Mar 18 08:45:23.964: INFO: Created: latency-svc-q6fx5
Mar 18 08:45:23.991: INFO: Got endpoints: latency-svc-vxjbq [747.659362ms]
Mar 18 08:45:24.001: INFO: Created: latency-svc-lf9dz
Mar 18 08:45:24.015: INFO: Created: latency-svc-29q7q
Mar 18 08:45:24.034: INFO: Got endpoints: latency-svc-n4sgd [749.884694ms]
Mar 18 08:45:24.091: INFO: Got endpoints: latency-svc-pvfmw [757.224832ms]
Mar 18 08:45:24.092: INFO: Created: latency-svc-59wmw
Mar 18 08:45:24.108: INFO: Created: latency-svc-hjg7g
Mar 18 08:45:24.135: INFO: Got endpoints: latency-svc-b4r4q [733.011189ms]
Mar 18 08:45:24.152: INFO: Created: latency-svc-94l8c
Mar 18 08:45:24.184: INFO: Got endpoints: latency-svc-dk2hn [750.100107ms]
Mar 18 08:45:24.200: INFO: Created: latency-svc-klpcp
Mar 18 08:45:24.237: INFO: Got endpoints: latency-svc-95bck [752.910374ms]
Mar 18 08:45:24.254: INFO: Created: latency-svc-hsmxv
Mar 18 08:45:24.301: INFO: Got endpoints: latency-svc-p7t9x [766.883407ms]
Mar 18 08:45:24.319: INFO: Created: latency-svc-hx78l
Mar 18 08:45:24.334: INFO: Got endpoints: latency-svc-fl8b7 [682.558682ms]
Mar 18 08:45:24.351: INFO: Created: latency-svc-tzlbd
Mar 18 08:45:24.384: INFO: Got endpoints: latency-svc-jsmb4 [732.671469ms]
Mar 18 08:45:24.422: INFO: Created: latency-svc-nc6jl
Mar 18 08:45:24.434: INFO: Got endpoints: latency-svc-2hvhf [746.471891ms]
Mar 18 08:45:24.456: INFO: Created: latency-svc-5xcl5
Mar 18 08:45:24.484: INFO: Got endpoints: latency-svc-7f9mk [741.616102ms]
Mar 18 08:45:24.501: INFO: Created: latency-svc-pldq7
Mar 18 08:45:24.542: INFO: Got endpoints: latency-svc-pn4xg [757.217332ms]
Mar 18 08:45:24.561: INFO: Created: latency-svc-rx5gk
Mar 18 08:45:24.584: INFO: Got endpoints: latency-svc-k2dxl [749.996901ms]
Mar 18 08:45:24.614: INFO: Created: latency-svc-g2672
Mar 18 08:45:24.637: INFO: Got endpoints: latency-svc-q6fx5 [693.467231ms]
Mar 18 08:45:24.702: INFO: Got endpoints: latency-svc-lf9dz [759.019239ms]
Mar 18 08:45:24.706: INFO: Created: latency-svc-5z5pq
Mar 18 08:45:24.723: INFO: Created: latency-svc-zc8tb
Mar 18 08:45:24.734: INFO: Got endpoints: latency-svc-29q7q [743.478413ms]
Mar 18 08:45:24.751: INFO: Created: latency-svc-8nw8v
Mar 18 08:45:24.785: INFO: Got endpoints: latency-svc-59wmw [751.128668ms]
Mar 18 08:45:24.830: INFO: Created: latency-svc-72bxj
Mar 18 08:45:24.835: INFO: Got endpoints: latency-svc-hjg7g [743.322203ms]
Mar 18 08:45:24.852: INFO: Created: latency-svc-st8g4
Mar 18 08:45:24.886: INFO: Got endpoints: latency-svc-94l8c [751.207773ms]
Mar 18 08:45:24.911: INFO: Created: latency-svc-hrgwh
Mar 18 08:45:25.040: INFO: Got endpoints: latency-svc-hx78l [739.189957ms]
Mar 18 08:45:25.040: INFO: Got endpoints: latency-svc-klpcp [856.160829ms]
Mar 18 08:45:25.040: INFO: Got endpoints: latency-svc-hsmxv [803.737504ms]
Mar 18 08:45:25.061: INFO: Created: latency-svc-9lls5
Mar 18 08:45:25.074: INFO: Created: latency-svc-9rrs5
Mar 18 08:45:25.088: INFO: Got endpoints: latency-svc-tzlbd [753.579415ms]
Mar 18 08:45:25.089: INFO: Created: latency-svc-lfs7f
Mar 18 08:45:25.113: INFO: Created: latency-svc-qkd9z
Mar 18 08:45:25.134: INFO: Got endpoints: latency-svc-nc6jl [749.955899ms]
Mar 18 08:45:25.159: INFO: Created: latency-svc-l5hm6
Mar 18 08:45:25.185: INFO: Got endpoints: latency-svc-5xcl5 [750.30592ms]
Mar 18 08:45:25.214: INFO: Created: latency-svc-t2x9q
Mar 18 08:45:25.234: INFO: Got endpoints: latency-svc-pldq7 [749.443469ms]
Mar 18 08:45:25.304: INFO: Got endpoints: latency-svc-rx5gk [761.793704ms]
Mar 18 08:45:25.304: INFO: Created: latency-svc-rfmb6
Mar 18 08:45:25.321: INFO: Created: latency-svc-255bc
Mar 18 08:45:25.334: INFO: Got endpoints: latency-svc-g2672 [749.828091ms]
Mar 18 08:45:25.356: INFO: Created: latency-svc-zgwhg
Mar 18 08:45:25.394: INFO: Got endpoints: latency-svc-5z5pq [756.86121ms]
Mar 18 08:45:25.422: INFO: Created: latency-svc-ftdp5
Mar 18 08:45:25.435: INFO: Got endpoints: latency-svc-zc8tb [732.466556ms]
Mar 18 08:45:25.459: INFO: Created: latency-svc-tctlr
Mar 18 08:45:25.484: INFO: Got endpoints: latency-svc-8nw8v [750.14791ms]
Mar 18 08:45:25.502: INFO: Created: latency-svc-22qzc
Mar 18 08:45:25.545: INFO: Got endpoints: latency-svc-72bxj [760.057101ms]
Mar 18 08:45:25.565: INFO: Created: latency-svc-q86gs
Mar 18 08:45:25.584: INFO: Got endpoints: latency-svc-st8g4 [749.628879ms]
Mar 18 08:45:25.605: INFO: Created: latency-svc-s62hk
Mar 18 08:45:25.634: INFO: Got endpoints: latency-svc-hrgwh [748.255497ms]
Mar 18 08:45:25.745: INFO: Got endpoints: latency-svc-9lls5 [704.707101ms]
Mar 18 08:45:25.745: INFO: Created: latency-svc-9fzks
Mar 18 08:45:25.746: INFO: Got endpoints: latency-svc-9rrs5 [705.451247ms]
Mar 18 08:45:25.794: INFO: Got endpoints: latency-svc-lfs7f [753.600316ms]
Mar 18 08:45:25.809: INFO: Created: latency-svc-82ccv
Mar 18 08:45:25.821: INFO: Created: latency-svc-m4scr
Mar 18 08:45:25.836: INFO: Created: latency-svc-qzgjk
Mar 18 08:45:25.838: INFO: Got endpoints: latency-svc-qkd9z [750.538834ms]
Mar 18 08:45:25.869: INFO: Created: latency-svc-zm7ml
Mar 18 08:45:25.884: INFO: Got endpoints: latency-svc-l5hm6 [749.438368ms]
Mar 18 08:45:25.908: INFO: Created: latency-svc-g4rtz
Mar 18 08:45:25.935: INFO: Got endpoints: latency-svc-t2x9q [749.871194ms]
Mar 18 08:45:25.953: INFO: Created: latency-svc-r7k8p
Mar 18 08:45:25.991: INFO: Got endpoints: latency-svc-rfmb6 [756.953916ms]
Mar 18 08:45:26.012: INFO: Created: latency-svc-7kwfp
Mar 18 08:45:26.034: INFO: Got endpoints: latency-svc-255bc [730.143417ms]
Mar 18 08:45:26.055: INFO: Created: latency-svc-r2fd4
Mar 18 08:45:26.088: INFO: Got endpoints: latency-svc-zgwhg [753.359802ms]
Mar 18 08:45:26.130: INFO: Created: latency-svc-jtq8v
Mar 18 08:45:26.134: INFO: Got endpoints: latency-svc-ftdp5 [740.649044ms]
Mar 18 08:45:26.155: INFO: Created: latency-svc-bpjzc
Mar 18 08:45:26.184: INFO: Got endpoints: latency-svc-tctlr [749.368163ms]
Mar 18 08:45:26.203: INFO: Created: latency-svc-rnzz8
Mar 18 08:45:26.246: INFO: Got endpoints: latency-svc-22qzc [761.517188ms]
Mar 18 08:45:26.263: INFO: Created: latency-svc-9fjw9
Mar 18 08:45:26.284: INFO: Got endpoints: latency-svc-q86gs [738.746231ms]
Mar 18 08:45:26.301: INFO: Created: latency-svc-sl8q8
Mar 18 08:45:26.334: INFO: Got endpoints: latency-svc-s62hk [749.259057ms]
Mar 18 08:45:26.362: INFO: Created: latency-svc-df7nn
Mar 18 08:45:26.385: INFO: Got endpoints: latency-svc-9fzks [750.98216ms]
Mar 18 08:45:26.404: INFO: Created: latency-svc-tkbzb
Mar 18 08:45:26.434: INFO: Got endpoints: latency-svc-82ccv [689.033267ms]
Mar 18 08:45:26.556: INFO: Created: latency-svc-6c6v5
Mar 18 08:45:26.556: INFO: Got endpoints: latency-svc-qzgjk [762.181227ms]
Mar 18 08:45:26.556: INFO: Got endpoints: latency-svc-m4scr [810.060381ms]
Mar 18 08:45:26.573: INFO: Created: latency-svc-j9sgn
Mar 18 08:45:26.603: INFO: Got endpoints: latency-svc-zm7ml [764.57657ms]
Mar 18 08:45:26.603: INFO: Created: latency-svc-n2hsb
Mar 18 08:45:26.619: INFO: Created: latency-svc-7p465
Mar 18 08:45:26.634: INFO: Got endpoints: latency-svc-g4rtz [750.209814ms]
Mar 18 08:45:26.650: INFO: Created: latency-svc-8ml5g
Mar 18 08:45:26.689: INFO: Got endpoints: latency-svc-r7k8p [754.220053ms]
Mar 18 08:45:26.717: INFO: Created: latency-svc-hx9pt
Mar 18 08:45:26.735: INFO: Got endpoints: latency-svc-7kwfp [744.11935ms]
Mar 18 08:45:26.755: INFO: Created: latency-svc-ff68m
Mar 18 08:45:26.785: INFO: Got endpoints: latency-svc-r2fd4 [750.642939ms]
Mar 18 08:45:26.808: INFO: Created: latency-svc-g5w9p
Mar 18 08:45:26.835: INFO: Got endpoints: latency-svc-jtq8v [747.455949ms]
Mar 18 08:45:26.857: INFO: Created: latency-svc-lqrbq
Mar 18 08:45:26.885: INFO: Got endpoints: latency-svc-bpjzc [750.119609ms]
Mar 18 08:45:26.906: INFO: Created: latency-svc-hrtn6
Mar 18 08:45:26.935: INFO: Got endpoints: latency-svc-rnzz8 [750.260117ms]
Mar 18 08:45:26.958: INFO: Created: latency-svc-pkzb6
Mar 18 08:45:26.984: INFO: Got endpoints: latency-svc-9fjw9 [737.812975ms]
Mar 18 08:45:27.003: INFO: Created: latency-svc-6vx54
Mar 18 08:45:27.059: INFO: Got endpoints: latency-svc-sl8q8 [775.128299ms]
Mar 18 08:45:27.084: INFO: Got endpoints: latency-svc-df7nn [750.48193ms]
Mar 18 08:45:27.135: INFO: Got endpoints: latency-svc-tkbzb [749.568075ms]
Mar 18 08:45:27.197: INFO: Got endpoints: latency-svc-6c6v5 [762.680757ms]
Mar 18 08:45:27.234: INFO: Got endpoints: latency-svc-j9sgn [678.363732ms]
Mar 18 08:45:27.284: INFO: Got endpoints: latency-svc-n2hsb [727.82018ms]
Mar 18 08:45:27.334: INFO: Got endpoints: latency-svc-7p465 [731.253184ms]
Mar 18 08:45:27.384: INFO: Got endpoints: latency-svc-8ml5g [750.14581ms]
Mar 18 08:45:27.435: INFO: Got endpoints: latency-svc-hx9pt [745.573337ms]
Mar 18 08:45:27.484: INFO: Got endpoints: latency-svc-ff68m [748.854933ms]
Mar 18 08:45:27.534: INFO: Got endpoints: latency-svc-g5w9p [749.677683ms]
Mar 18 08:45:27.584: INFO: Got endpoints: latency-svc-lqrbq [749.257757ms]
Mar 18 08:45:27.634: INFO: Got endpoints: latency-svc-hrtn6 [749.608078ms]
Mar 18 08:45:27.684: INFO: Got endpoints: latency-svc-pkzb6 [749.428267ms]
Mar 18 08:45:27.737: INFO: Got endpoints: latency-svc-6vx54 [753.076284ms]
Mar 18 08:45:27.737: INFO: Latencies: [62.716438ms 79.245323ms 87.995144ms 102.231493ms 126.629147ms 154.482508ms 161.515726ms 197.552374ms 213.773141ms 215.652753ms 242.912478ms 317.025095ms 321.382355ms 338.557779ms 348.058145ms 356.612954ms 380.254264ms 381.02991ms 387.868118ms 388.619562ms 391.890157ms 412.198168ms 418.970972ms 420.391956ms 423.991871ms 424.115378ms 425.519662ms 427.612986ms 428.769556ms 429.68461ms 430.677369ms 430.752974ms 431.729131ms 432.932803ms 433.344928ms 434.959324ms 436.536818ms 440.541257ms 441.859735ms 450.330841ms 453.590735ms 453.675339ms 454.01046ms 459.831907ms 462.097941ms 463.56753ms 465.215428ms 465.528546ms 470.234127ms 471.988931ms 474.770097ms 483.155997ms 485.012307ms 486.414891ms 487.871178ms 487.986085ms 492.379147ms 493.035185ms 498.272197ms 500.894555ms 508.159187ms 509.263853ms 510.477626ms 510.999757ms 511.909911ms 512.889369ms 516.335974ms 516.618391ms 519.581268ms 521.96341ms 528.475998ms 529.913383ms 531.731492ms 532.235422ms 535.393811ms 550.420406ms 560.148585ms 563.381079ms 595.78651ms 614.24911ms 617.291992ms 628.531862ms 655.976197ms 656.367521ms 677.013251ms 678.363732ms 682.558682ms 689.033267ms 693.145413ms 693.467231ms 704.707101ms 705.451247ms 709.507088ms 718.890847ms 722.172442ms 726.046474ms 727.82018ms 730.143417ms 731.253184ms 732.466556ms 732.671469ms 733.011189ms 736.007567ms 736.126774ms 737.812975ms 738.703028ms 738.746231ms 739.189957ms 739.841696ms 740.649044ms 741.616102ms 741.873717ms 742.320843ms 742.405749ms 742.635562ms 743.322203ms 743.478413ms 743.792332ms 744.11935ms 744.529175ms 745.573337ms 746.146972ms 746.471891ms 746.621ms 747.455949ms 747.659362ms 748.123689ms 748.255497ms 748.835232ms 748.854933ms 749.257757ms 749.259057ms 749.311461ms 749.368163ms 749.428267ms 749.438368ms 749.443469ms 749.568075ms 749.608078ms 749.628879ms 749.677683ms 749.688983ms 749.768887ms 749.828091ms 749.871194ms 749.884694ms 749.955899ms 749.996901ms 750.067905ms 750.100107ms 750.119609ms 750.14581ms 750.14791ms 750.209814ms 750.260117ms 750.30592ms 750.405726ms 750.48193ms 750.538834ms 750.642939ms 750.774448ms 750.788848ms 750.98216ms 751.128668ms 751.207773ms 751.418986ms 752.910374ms 753.076284ms 753.259396ms 753.359802ms 753.579415ms 753.600316ms 754.031242ms 754.220053ms 756.297677ms 756.86121ms 756.916414ms 756.953916ms 757.217332ms 757.224832ms 757.86577ms 758.621615ms 759.019239ms 760.057101ms 761.517188ms 761.793704ms 762.181227ms 762.680757ms 764.57657ms 766.43118ms 766.7598ms 766.883407ms 769.339453ms 775.128299ms 803.737504ms 809.109325ms 810.060381ms 816.947191ms 820.092078ms 856.160829ms]
Mar 18 08:45:27.737: INFO: 50 %ile: 732.671469ms
Mar 18 08:45:27.737: INFO: 90 %ile: 757.86577ms
Mar 18 08:45:27.737: INFO: 99 %ile: 820.092078ms
Mar 18 08:45:27.737: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:45:27.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-npll9" for this suite.
Mar 18 08:45:43.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:45:43.895: INFO: namespace: e2e-tests-svc-latency-npll9, resource: bindings, ignored listing per whitelist
Mar 18 08:45:43.911: INFO: namespace e2e-tests-svc-latency-npll9 deletion completed in 16.16683667s

â€¢ [SLOW TEST:27.999 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:45:43.911: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 18 08:45:44.005: INFO: Creating ReplicaSet my-hostname-basic-37973a25-495a-11e9-86d2-4ea95915efee
Mar 18 08:45:44.011: INFO: Pod name my-hostname-basic-37973a25-495a-11e9-86d2-4ea95915efee: Found 0 pods out of 1
Mar 18 08:45:49.014: INFO: Pod name my-hostname-basic-37973a25-495a-11e9-86d2-4ea95915efee: Found 1 pods out of 1
Mar 18 08:45:49.014: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-37973a25-495a-11e9-86d2-4ea95915efee" is running
Mar 18 08:45:49.017: INFO: Pod "my-hostname-basic-37973a25-495a-11e9-86d2-4ea95915efee-dtpsc" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-18 08:45:44 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-18 08:45:45 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-18 08:45:45 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-18 08:45:44 +0000 UTC Reason: Message:}])
Mar 18 08:45:49.018: INFO: Trying to dial the pod
Mar 18 08:45:54.032: INFO: Controller my-hostname-basic-37973a25-495a-11e9-86d2-4ea95915efee: Got expected result from replica 1 [my-hostname-basic-37973a25-495a-11e9-86d2-4ea95915efee-dtpsc]: "my-hostname-basic-37973a25-495a-11e9-86d2-4ea95915efee-dtpsc", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:45:54.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-hmcbm" for this suite.
Mar 18 08:46:00.049: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:46:00.113: INFO: namespace: e2e-tests-replicaset-hmcbm, resource: bindings, ignored listing per whitelist
Mar 18 08:46:00.150: INFO: namespace e2e-tests-replicaset-hmcbm deletion completed in 6.113617382s

â€¢ [SLOW TEST:16.239 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:46:00.151: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-m2rmv
Mar 18 08:46:02.251: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-m2rmv
STEP: checking the pod's current state and verifying that restartCount is present
Mar 18 08:46:02.254: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:50:02.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-m2rmv" for this suite.
Mar 18 08:50:08.774: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:50:08.850: INFO: namespace: e2e-tests-container-probe-m2rmv, resource: bindings, ignored listing per whitelist
Mar 18 08:50:08.887: INFO: namespace e2e-tests-container-probe-m2rmv deletion completed in 6.123882594s

â€¢ [SLOW TEST:248.737 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:50:08.888: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-pqd8j
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-pqd8j to expose endpoints map[]
Mar 18 08:50:08.999: INFO: Get endpoints failed (2.288936ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Mar 18 08:50:10.003: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-pqd8j exposes endpoints map[] (1.006383882s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-pqd8j
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-pqd8j to expose endpoints map[pod1:[100]]
Mar 18 08:50:13.042: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-pqd8j exposes endpoints map[pod1:[100]] (3.033846822s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-pqd8j
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-pqd8j to expose endpoints map[pod1:[100] pod2:[101]]
Mar 18 08:50:15.076: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-pqd8j exposes endpoints map[pod1:[100] pod2:[101]] (2.030516322s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-pqd8j
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-pqd8j to expose endpoints map[pod2:[101]]
Mar 18 08:50:15.091: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-pqd8j exposes endpoints map[pod2:[101]] (9.645775ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-pqd8j
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-pqd8j to expose endpoints map[]
Mar 18 08:50:16.109: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-pqd8j exposes endpoints map[] (1.01239954s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:50:16.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-pqd8j" for this suite.
Mar 18 08:50:36.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:50:36.239: INFO: namespace: e2e-tests-services-pqd8j, resource: bindings, ignored listing per whitelist
Mar 18 08:50:36.260: INFO: namespace e2e-tests-services-pqd8j deletion completed in 20.119015927s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

â€¢ [SLOW TEST:27.372 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:50:36.260: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-e5d8fd22-495a-11e9-86d2-4ea95915efee
Mar 18 08:50:36.365: INFO: Pod name my-hostname-basic-e5d8fd22-495a-11e9-86d2-4ea95915efee: Found 0 pods out of 1
Mar 18 08:50:41.369: INFO: Pod name my-hostname-basic-e5d8fd22-495a-11e9-86d2-4ea95915efee: Found 1 pods out of 1
Mar 18 08:50:41.369: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-e5d8fd22-495a-11e9-86d2-4ea95915efee" are running
Mar 18 08:50:41.372: INFO: Pod "my-hostname-basic-e5d8fd22-495a-11e9-86d2-4ea95915efee-6wkkk" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-18 08:50:36 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-18 08:50:38 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-18 08:50:38 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-18 08:50:36 +0000 UTC Reason: Message:}])
Mar 18 08:50:41.372: INFO: Trying to dial the pod
Mar 18 08:50:46.391: INFO: Controller my-hostname-basic-e5d8fd22-495a-11e9-86d2-4ea95915efee: Got expected result from replica 1 [my-hostname-basic-e5d8fd22-495a-11e9-86d2-4ea95915efee-6wkkk]: "my-hostname-basic-e5d8fd22-495a-11e9-86d2-4ea95915efee-6wkkk", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:50:46.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-qnxvn" for this suite.
Mar 18 08:50:52.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:50:52.426: INFO: namespace: e2e-tests-replication-controller-qnxvn, resource: bindings, ignored listing per whitelist
Mar 18 08:50:52.516: INFO: namespace e2e-tests-replication-controller-qnxvn deletion completed in 6.116407248s

â€¢ [SLOW TEST:16.257 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:50:52.517: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Mar 18 08:50:52.623: INFO: Waiting up to 5m0s for pod "pod-ef89d1d5-495a-11e9-86d2-4ea95915efee" in namespace "e2e-tests-emptydir-thjp6" to be "success or failure"
Mar 18 08:50:52.635: INFO: Pod "pod-ef89d1d5-495a-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 11.549888ms
Mar 18 08:50:54.638: INFO: Pod "pod-ef89d1d5-495a-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014720281s
STEP: Saw pod success
Mar 18 08:50:54.638: INFO: Pod "pod-ef89d1d5-495a-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:50:54.640: INFO: Trying to get logs from node worker02 pod pod-ef89d1d5-495a-11e9-86d2-4ea95915efee container test-container: <nil>
STEP: delete the pod
Mar 18 08:50:54.660: INFO: Waiting for pod pod-ef89d1d5-495a-11e9-86d2-4ea95915efee to disappear
Mar 18 08:50:54.664: INFO: Pod pod-ef89d1d5-495a-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:50:54.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-thjp6" for this suite.
Mar 18 08:51:00.679: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:51:00.737: INFO: namespace: e2e-tests-emptydir-thjp6, resource: bindings, ignored listing per whitelist
Mar 18 08:51:00.787: INFO: namespace e2e-tests-emptydir-thjp6 deletion completed in 6.11878529s

â€¢ [SLOW TEST:8.270 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:51:00.787: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-f4788982-495a-11e9-86d2-4ea95915efee
STEP: Creating configMap with name cm-test-opt-upd-f47889bf-495a-11e9-86d2-4ea95915efee
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-f4788982-495a-11e9-86d2-4ea95915efee
STEP: Updating configmap cm-test-opt-upd-f47889bf-495a-11e9-86d2-4ea95915efee
STEP: Creating configMap with name cm-test-opt-create-f47889dc-495a-11e9-86d2-4ea95915efee
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:52:07.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9ghm4" for this suite.
Mar 18 08:52:29.318: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:52:29.347: INFO: namespace: e2e-tests-configmap-9ghm4, resource: bindings, ignored listing per whitelist
Mar 18 08:52:29.421: INFO: namespace e2e-tests-configmap-9ghm4 deletion completed in 22.118800818s

â€¢ [SLOW TEST:88.634 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:52:29.422: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 18 08:52:29.560: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"294eba92-495b-11e9-b44d-0022480537ee", Controller:(*bool)(0xc001305306), BlockOwnerDeletion:(*bool)(0xc001305307)}}
Mar 18 08:52:29.565: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"294cb641-495b-11e9-b44d-0022480537ee", Controller:(*bool)(0xc0017442b2), BlockOwnerDeletion:(*bool)(0xc0017442b3)}}
Mar 18 08:52:29.577: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"294d350b-495b-11e9-b44d-0022480537ee", Controller:(*bool)(0xc00130550a), BlockOwnerDeletion:(*bool)(0xc00130550b)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:52:34.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-5w5dk" for this suite.
Mar 18 08:52:40.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:52:40.644: INFO: namespace: e2e-tests-gc-5w5dk, resource: bindings, ignored listing per whitelist
Mar 18 08:52:40.725: INFO: namespace e2e-tests-gc-5w5dk deletion completed in 6.126442647s

â€¢ [SLOW TEST:11.303 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:52:40.725: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-vrgz
STEP: Creating a pod to test atomic-volume-subpath
Mar 18 08:52:40.835: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-vrgz" in namespace "e2e-tests-subpath-8bslm" to be "success or failure"
Mar 18 08:52:40.843: INFO: Pod "pod-subpath-test-secret-vrgz": Phase="Pending", Reason="", readiness=false. Elapsed: 8.768023ms
Mar 18 08:52:42.847: INFO: Pod "pod-subpath-test-secret-vrgz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012077924s
Mar 18 08:52:44.850: INFO: Pod "pod-subpath-test-secret-vrgz": Phase="Running", Reason="", readiness=false. Elapsed: 4.015696043s
Mar 18 08:52:46.854: INFO: Pod "pod-subpath-test-secret-vrgz": Phase="Running", Reason="", readiness=false. Elapsed: 6.019320262s
Mar 18 08:52:48.859: INFO: Pod "pod-subpath-test-secret-vrgz": Phase="Running", Reason="", readiness=false. Elapsed: 8.02408845s
Mar 18 08:52:50.862: INFO: Pod "pod-subpath-test-secret-vrgz": Phase="Running", Reason="", readiness=false. Elapsed: 10.027758472s
Mar 18 08:52:52.867: INFO: Pod "pod-subpath-test-secret-vrgz": Phase="Running", Reason="", readiness=false. Elapsed: 12.031855819s
Mar 18 08:52:54.870: INFO: Pod "pod-subpath-test-secret-vrgz": Phase="Running", Reason="", readiness=false. Elapsed: 14.035777456s
Mar 18 08:52:56.875: INFO: Pod "pod-subpath-test-secret-vrgz": Phase="Running", Reason="", readiness=false. Elapsed: 16.040756356s
Mar 18 08:52:58.879: INFO: Pod "pod-subpath-test-secret-vrgz": Phase="Running", Reason="", readiness=false. Elapsed: 18.044323272s
Mar 18 08:53:00.882: INFO: Pod "pod-subpath-test-secret-vrgz": Phase="Running", Reason="", readiness=false. Elapsed: 20.047677276s
Mar 18 08:53:02.886: INFO: Pod "pod-subpath-test-secret-vrgz": Phase="Running", Reason="", readiness=false. Elapsed: 22.051429803s
Mar 18 08:53:04.890: INFO: Pod "pod-subpath-test-secret-vrgz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.055336339s
STEP: Saw pod success
Mar 18 08:53:04.890: INFO: Pod "pod-subpath-test-secret-vrgz" satisfied condition "success or failure"
Mar 18 08:53:04.893: INFO: Trying to get logs from node worker01 pod pod-subpath-test-secret-vrgz container test-container-subpath-secret-vrgz: <nil>
STEP: delete the pod
Mar 18 08:53:04.921: INFO: Waiting for pod pod-subpath-test-secret-vrgz to disappear
Mar 18 08:53:04.925: INFO: Pod pod-subpath-test-secret-vrgz no longer exists
STEP: Deleting pod pod-subpath-test-secret-vrgz
Mar 18 08:53:04.925: INFO: Deleting pod "pod-subpath-test-secret-vrgz" in namespace "e2e-tests-subpath-8bslm"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:53:04.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-8bslm" for this suite.
Mar 18 08:53:10.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:53:11.019: INFO: namespace: e2e-tests-subpath-8bslm, resource: bindings, ignored listing per whitelist
Mar 18 08:53:11.053: INFO: namespace e2e-tests-subpath-8bslm deletion completed in 6.118426168s

â€¢ [SLOW TEST:30.328 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:53:11.053: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Mar 18 08:53:11.672: INFO: created pod pod-service-account-defaultsa
Mar 18 08:53:11.672: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Mar 18 08:53:11.678: INFO: created pod pod-service-account-mountsa
Mar 18 08:53:11.678: INFO: pod pod-service-account-mountsa service account token volume mount: true
Mar 18 08:53:11.687: INFO: created pod pod-service-account-nomountsa
Mar 18 08:53:11.688: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Mar 18 08:53:11.693: INFO: created pod pod-service-account-defaultsa-mountspec
Mar 18 08:53:11.693: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Mar 18 08:53:11.706: INFO: created pod pod-service-account-mountsa-mountspec
Mar 18 08:53:11.706: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Mar 18 08:53:11.715: INFO: created pod pod-service-account-nomountsa-mountspec
Mar 18 08:53:11.715: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Mar 18 08:53:11.726: INFO: created pod pod-service-account-defaultsa-nomountspec
Mar 18 08:53:11.726: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Mar 18 08:53:11.739: INFO: created pod pod-service-account-mountsa-nomountspec
Mar 18 08:53:11.739: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Mar 18 08:53:11.794: INFO: created pod pod-service-account-nomountsa-nomountspec
Mar 18 08:53:11.794: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:53:11.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-9pxhb" for this suite.
Mar 18 08:53:17.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:53:17.942: INFO: namespace: e2e-tests-svcaccounts-9pxhb, resource: bindings, ignored listing per whitelist
Mar 18 08:53:17.944: INFO: namespace e2e-tests-svcaccounts-9pxhb deletion completed in 6.139660934s

â€¢ [SLOW TEST:6.892 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:53:17.945: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-kmdp
STEP: Creating a pod to test atomic-volume-subpath
Mar 18 08:53:18.051: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-kmdp" in namespace "e2e-tests-subpath-dp6xg" to be "success or failure"
Mar 18 08:53:18.061: INFO: Pod "pod-subpath-test-configmap-kmdp": Phase="Pending", Reason="", readiness=false. Elapsed: 9.020938ms
Mar 18 08:53:20.064: INFO: Pod "pod-subpath-test-configmap-kmdp": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01252615s
Mar 18 08:53:22.068: INFO: Pod "pod-subpath-test-configmap-kmdp": Phase="Running", Reason="", readiness=false. Elapsed: 4.016645699s
Mar 18 08:53:24.072: INFO: Pod "pod-subpath-test-configmap-kmdp": Phase="Running", Reason="", readiness=false. Elapsed: 6.020827952s
Mar 18 08:53:26.076: INFO: Pod "pod-subpath-test-configmap-kmdp": Phase="Running", Reason="", readiness=false. Elapsed: 8.024534376s
Mar 18 08:53:28.086: INFO: Pod "pod-subpath-test-configmap-kmdp": Phase="Running", Reason="", readiness=false. Elapsed: 10.034464271s
Mar 18 08:53:30.089: INFO: Pod "pod-subpath-test-configmap-kmdp": Phase="Running", Reason="", readiness=false. Elapsed: 12.037553959s
Mar 18 08:53:32.093: INFO: Pod "pod-subpath-test-configmap-kmdp": Phase="Running", Reason="", readiness=false. Elapsed: 14.041493297s
Mar 18 08:53:34.097: INFO: Pod "pod-subpath-test-configmap-kmdp": Phase="Running", Reason="", readiness=false. Elapsed: 16.045167019s
Mar 18 08:53:36.101: INFO: Pod "pod-subpath-test-configmap-kmdp": Phase="Running", Reason="", readiness=false. Elapsed: 18.049106358s
Mar 18 08:53:38.104: INFO: Pod "pod-subpath-test-configmap-kmdp": Phase="Running", Reason="", readiness=false. Elapsed: 20.05278238s
Mar 18 08:53:40.108: INFO: Pod "pod-subpath-test-configmap-kmdp": Phase="Running", Reason="", readiness=false. Elapsed: 22.056515406s
Mar 18 08:53:42.113: INFO: Pod "pod-subpath-test-configmap-kmdp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.060998177s
STEP: Saw pod success
Mar 18 08:53:42.113: INFO: Pod "pod-subpath-test-configmap-kmdp" satisfied condition "success or failure"
Mar 18 08:53:42.118: INFO: Trying to get logs from node worker01 pod pod-subpath-test-configmap-kmdp container test-container-subpath-configmap-kmdp: <nil>
STEP: delete the pod
Mar 18 08:53:42.147: INFO: Waiting for pod pod-subpath-test-configmap-kmdp to disappear
Mar 18 08:53:42.149: INFO: Pod pod-subpath-test-configmap-kmdp no longer exists
STEP: Deleting pod pod-subpath-test-configmap-kmdp
Mar 18 08:53:42.149: INFO: Deleting pod "pod-subpath-test-configmap-kmdp" in namespace "e2e-tests-subpath-dp6xg"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:53:42.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-dp6xg" for this suite.
Mar 18 08:53:48.172: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:53:48.274: INFO: namespace: e2e-tests-subpath-dp6xg, resource: bindings, ignored listing per whitelist
Mar 18 08:53:48.280: INFO: namespace e2e-tests-subpath-dp6xg deletion completed in 6.118887796s

â€¢ [SLOW TEST:30.336 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:53:48.281: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Mar 18 08:53:48.379: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 create -f - --namespace=e2e-tests-kubectl-h9rrb'
Mar 18 08:53:49.170: INFO: stderr: ""
Mar 18 08:53:49.170: INFO: stdout: "pod/pause created\n"
Mar 18 08:53:49.170: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Mar 18 08:53:49.170: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-h9rrb" to be "running and ready"
Mar 18 08:53:49.176: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 5.740342ms
Mar 18 08:53:51.180: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.009592575s
Mar 18 08:53:51.180: INFO: Pod "pause" satisfied condition "running and ready"
Mar 18 08:53:51.180: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Mar 18 08:53:51.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-h9rrb'
Mar 18 08:53:51.277: INFO: stderr: ""
Mar 18 08:53:51.277: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Mar 18 08:53:51.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pod pause -L testing-label --namespace=e2e-tests-kubectl-h9rrb'
Mar 18 08:53:51.378: INFO: stderr: ""
Mar 18 08:53:51.378: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Mar 18 08:53:51.378: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 label pods pause testing-label- --namespace=e2e-tests-kubectl-h9rrb'
Mar 18 08:53:51.461: INFO: stderr: ""
Mar 18 08:53:51.461: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Mar 18 08:53:51.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pod pause -L testing-label --namespace=e2e-tests-kubectl-h9rrb'
Mar 18 08:53:51.536: INFO: stderr: ""
Mar 18 08:53:51.536: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Mar 18 08:53:51.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-h9rrb'
Mar 18 08:53:51.624: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 18 08:53:51.624: INFO: stdout: "pod \"pause\" force deleted\n"
Mar 18 08:53:51.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-h9rrb'
Mar 18 08:53:51.734: INFO: stderr: "No resources found.\n"
Mar 18 08:53:51.734: INFO: stdout: ""
Mar 18 08:53:51.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods -l name=pause --namespace=e2e-tests-kubectl-h9rrb -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 18 08:53:51.825: INFO: stderr: ""
Mar 18 08:53:51.825: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:53:51.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-h9rrb" for this suite.
Mar 18 08:53:57.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:53:57.917: INFO: namespace: e2e-tests-kubectl-h9rrb, resource: bindings, ignored listing per whitelist
Mar 18 08:53:57.953: INFO: namespace e2e-tests-kubectl-h9rrb deletion completed in 6.123005741s

â€¢ [SLOW TEST:9.672 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:53:57.953: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Mar 18 08:54:00.066: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-5e0f5bd7-495b-11e9-86d2-4ea95915efee,GenerateName:,Namespace:e2e-tests-events-82kpz,SelfLink:/api/v1/namespaces/e2e-tests-events-82kpz/pods/send-events-5e0f5bd7-495b-11e9-86d2-4ea95915efee,UID:5e0f9040-495b-11e9-b44d-0022480537ee,ResourceVersion:205224,Generation:0,CreationTimestamp:2019-03-18 08:53:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 42731624,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-pqbkn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pqbkn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-pqbkn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker01,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000873820} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000873860}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:53:58 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:53:59 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:53:59 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-18 08:53:58 +0000 UTC  }],Message:,Reason:,HostIP:10.0.2.5,PodIP:10.32.0.5,StartTime:2019-03-18 08:53:58 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-03-18 08:53:59 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://9a112aecb7919e5f4550aa01ad4475251526c567d4e13daa054e7b3237595e64}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Mar 18 08:54:02.073: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Mar 18 08:54:04.077: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:54:04.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-82kpz" for this suite.
Mar 18 08:54:46.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:54:46.140: INFO: namespace: e2e-tests-events-82kpz, resource: bindings, ignored listing per whitelist
Mar 18 08:54:46.239: INFO: namespace e2e-tests-events-82kpz deletion completed in 42.144582188s

â€¢ [SLOW TEST:48.286 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:54:46.240: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Mar 18 08:54:46.346: INFO: Waiting up to 5m0s for pod "pod-7ad8fdcb-495b-11e9-86d2-4ea95915efee" in namespace "e2e-tests-emptydir-sj76f" to be "success or failure"
Mar 18 08:54:46.354: INFO: Pod "pod-7ad8fdcb-495b-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 8.73532ms
Mar 18 08:54:48.357: INFO: Pod "pod-7ad8fdcb-495b-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011782305s
STEP: Saw pod success
Mar 18 08:54:48.358: INFO: Pod "pod-7ad8fdcb-495b-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:54:48.373: INFO: Trying to get logs from node worker02 pod pod-7ad8fdcb-495b-11e9-86d2-4ea95915efee container test-container: <nil>
STEP: delete the pod
Mar 18 08:54:48.402: INFO: Waiting for pod pod-7ad8fdcb-495b-11e9-86d2-4ea95915efee to disappear
Mar 18 08:54:48.407: INFO: Pod pod-7ad8fdcb-495b-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:54:48.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-sj76f" for this suite.
Mar 18 08:54:54.428: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:54:54.529: INFO: namespace: e2e-tests-emptydir-sj76f, resource: bindings, ignored listing per whitelist
Mar 18 08:54:54.536: INFO: namespace e2e-tests-emptydir-sj76f deletion completed in 6.122779628s

â€¢ [SLOW TEST:8.296 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:54:54.536: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 18 08:54:54.631: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7fc976dc-495b-11e9-86d2-4ea95915efee" in namespace "e2e-tests-projected-svcrn" to be "success or failure"
Mar 18 08:54:54.642: INFO: Pod "downwardapi-volume-7fc976dc-495b-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 10.385319ms
Mar 18 08:54:56.645: INFO: Pod "downwardapi-volume-7fc976dc-495b-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013908532s
STEP: Saw pod success
Mar 18 08:54:56.645: INFO: Pod "downwardapi-volume-7fc976dc-495b-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:54:56.648: INFO: Trying to get logs from node worker01 pod downwardapi-volume-7fc976dc-495b-11e9-86d2-4ea95915efee container client-container: <nil>
STEP: delete the pod
Mar 18 08:54:56.753: INFO: Waiting for pod downwardapi-volume-7fc976dc-495b-11e9-86d2-4ea95915efee to disappear
Mar 18 08:54:56.755: INFO: Pod downwardapi-volume-7fc976dc-495b-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:54:56.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-svcrn" for this suite.
Mar 18 08:55:02.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:55:02.862: INFO: namespace: e2e-tests-projected-svcrn, resource: bindings, ignored listing per whitelist
Mar 18 08:55:02.887: INFO: namespace e2e-tests-projected-svcrn deletion completed in 6.127155389s

â€¢ [SLOW TEST:8.352 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:55:02.888: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-jfpw
STEP: Creating a pod to test atomic-volume-subpath
Mar 18 08:55:03.001: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-jfpw" in namespace "e2e-tests-subpath-f4c85" to be "success or failure"
Mar 18 08:55:03.007: INFO: Pod "pod-subpath-test-downwardapi-jfpw": Phase="Pending", Reason="", readiness=false. Elapsed: 6.477186ms
Mar 18 08:55:05.011: INFO: Pod "pod-subpath-test-downwardapi-jfpw": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009831889s
Mar 18 08:55:07.015: INFO: Pod "pod-subpath-test-downwardapi-jfpw": Phase="Running", Reason="", readiness=false. Elapsed: 4.013902235s
Mar 18 08:55:09.018: INFO: Pod "pod-subpath-test-downwardapi-jfpw": Phase="Running", Reason="", readiness=false. Elapsed: 6.017372646s
Mar 18 08:55:11.022: INFO: Pod "pod-subpath-test-downwardapi-jfpw": Phase="Running", Reason="", readiness=false. Elapsed: 8.021295583s
Mar 18 08:55:13.026: INFO: Pod "pod-subpath-test-downwardapi-jfpw": Phase="Running", Reason="", readiness=false. Elapsed: 10.025196719s
Mar 18 08:55:15.030: INFO: Pod "pod-subpath-test-downwardapi-jfpw": Phase="Running", Reason="", readiness=false. Elapsed: 12.029450176s
Mar 18 08:55:17.034: INFO: Pod "pod-subpath-test-downwardapi-jfpw": Phase="Running", Reason="", readiness=false. Elapsed: 14.033361712s
Mar 18 08:55:19.038: INFO: Pod "pod-subpath-test-downwardapi-jfpw": Phase="Running", Reason="", readiness=false. Elapsed: 16.036884925s
Mar 18 08:55:21.042: INFO: Pod "pod-subpath-test-downwardapi-jfpw": Phase="Running", Reason="", readiness=false. Elapsed: 18.04076016s
Mar 18 08:55:23.045: INFO: Pod "pod-subpath-test-downwardapi-jfpw": Phase="Running", Reason="", readiness=false. Elapsed: 20.043845547s
Mar 18 08:55:25.049: INFO: Pod "pod-subpath-test-downwardapi-jfpw": Phase="Running", Reason="", readiness=false. Elapsed: 22.048015799s
Mar 18 08:55:27.053: INFO: Pod "pod-subpath-test-downwardapi-jfpw": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.052053943s
STEP: Saw pod success
Mar 18 08:55:27.053: INFO: Pod "pod-subpath-test-downwardapi-jfpw" satisfied condition "success or failure"
Mar 18 08:55:27.063: INFO: Trying to get logs from node worker01 pod pod-subpath-test-downwardapi-jfpw container test-container-subpath-downwardapi-jfpw: <nil>
STEP: delete the pod
Mar 18 08:55:27.087: INFO: Waiting for pod pod-subpath-test-downwardapi-jfpw to disappear
Mar 18 08:55:27.090: INFO: Pod pod-subpath-test-downwardapi-jfpw no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-jfpw
Mar 18 08:55:27.090: INFO: Deleting pod "pod-subpath-test-downwardapi-jfpw" in namespace "e2e-tests-subpath-f4c85"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:55:27.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-f4c85" for this suite.
Mar 18 08:55:33.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:55:33.206: INFO: namespace: e2e-tests-subpath-f4c85, resource: bindings, ignored listing per whitelist
Mar 18 08:55:33.209: INFO: namespace e2e-tests-subpath-f4c85 deletion completed in 6.112556918s

â€¢ [SLOW TEST:30.321 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:55:33.209: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Mar 18 08:55:33.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 create -f - --namespace=e2e-tests-kubectl-jr9t6'
Mar 18 08:55:33.476: INFO: stderr: ""
Mar 18 08:55:33.476: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 18 08:55:33.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-jr9t6'
Mar 18 08:55:33.566: INFO: stderr: ""
Mar 18 08:55:33.566: INFO: stdout: "update-demo-nautilus-9m7nh update-demo-nautilus-mflgn "
Mar 18 08:55:33.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods update-demo-nautilus-9m7nh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jr9t6'
Mar 18 08:55:33.652: INFO: stderr: ""
Mar 18 08:55:33.652: INFO: stdout: ""
Mar 18 08:55:33.652: INFO: update-demo-nautilus-9m7nh is created but not running
Mar 18 08:55:38.652: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-jr9t6'
Mar 18 08:55:38.741: INFO: stderr: ""
Mar 18 08:55:38.741: INFO: stdout: "update-demo-nautilus-9m7nh update-demo-nautilus-mflgn "
Mar 18 08:55:38.741: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods update-demo-nautilus-9m7nh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jr9t6'
Mar 18 08:55:38.823: INFO: stderr: ""
Mar 18 08:55:38.823: INFO: stdout: "true"
Mar 18 08:55:38.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods update-demo-nautilus-9m7nh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jr9t6'
Mar 18 08:55:38.901: INFO: stderr: ""
Mar 18 08:55:38.901: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 18 08:55:38.901: INFO: validating pod update-demo-nautilus-9m7nh
Mar 18 08:55:38.910: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 18 08:55:38.910: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 18 08:55:38.910: INFO: update-demo-nautilus-9m7nh is verified up and running
Mar 18 08:55:38.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods update-demo-nautilus-mflgn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jr9t6'
Mar 18 08:55:38.986: INFO: stderr: ""
Mar 18 08:55:38.986: INFO: stdout: "true"
Mar 18 08:55:38.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods update-demo-nautilus-mflgn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jr9t6'
Mar 18 08:55:39.072: INFO: stderr: ""
Mar 18 08:55:39.072: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 18 08:55:39.072: INFO: validating pod update-demo-nautilus-mflgn
Mar 18 08:55:39.080: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 18 08:55:39.080: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 18 08:55:39.080: INFO: update-demo-nautilus-mflgn is verified up and running
STEP: scaling down the replication controller
Mar 18 08:55:39.082: INFO: scanned /root for discovery docs: <nil>
Mar 18 08:55:39.082: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-jr9t6'
Mar 18 08:55:40.206: INFO: stderr: ""
Mar 18 08:55:40.206: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 18 08:55:40.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-jr9t6'
Mar 18 08:55:40.294: INFO: stderr: ""
Mar 18 08:55:40.294: INFO: stdout: "update-demo-nautilus-9m7nh update-demo-nautilus-mflgn "
STEP: Replicas for name=update-demo: expected=1 actual=2
Mar 18 08:55:45.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-jr9t6'
Mar 18 08:55:45.378: INFO: stderr: ""
Mar 18 08:55:45.378: INFO: stdout: "update-demo-nautilus-9m7nh "
Mar 18 08:55:45.378: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods update-demo-nautilus-9m7nh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jr9t6'
Mar 18 08:55:45.463: INFO: stderr: ""
Mar 18 08:55:45.463: INFO: stdout: "true"
Mar 18 08:55:45.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods update-demo-nautilus-9m7nh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jr9t6'
Mar 18 08:55:45.541: INFO: stderr: ""
Mar 18 08:55:45.541: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 18 08:55:45.541: INFO: validating pod update-demo-nautilus-9m7nh
Mar 18 08:55:45.546: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 18 08:55:45.546: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 18 08:55:45.546: INFO: update-demo-nautilus-9m7nh is verified up and running
STEP: scaling up the replication controller
Mar 18 08:55:45.548: INFO: scanned /root for discovery docs: <nil>
Mar 18 08:55:45.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-jr9t6'
Mar 18 08:55:46.660: INFO: stderr: ""
Mar 18 08:55:46.660: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 18 08:55:46.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-jr9t6'
Mar 18 08:55:46.743: INFO: stderr: ""
Mar 18 08:55:46.743: INFO: stdout: "update-demo-nautilus-4njwh update-demo-nautilus-9m7nh "
Mar 18 08:55:46.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods update-demo-nautilus-4njwh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jr9t6'
Mar 18 08:55:46.821: INFO: stderr: ""
Mar 18 08:55:46.821: INFO: stdout: ""
Mar 18 08:55:46.821: INFO: update-demo-nautilus-4njwh is created but not running
Mar 18 08:55:51.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-jr9t6'
Mar 18 08:55:51.907: INFO: stderr: ""
Mar 18 08:55:51.907: INFO: stdout: "update-demo-nautilus-4njwh update-demo-nautilus-9m7nh "
Mar 18 08:55:51.907: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods update-demo-nautilus-4njwh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jr9t6'
Mar 18 08:55:51.994: INFO: stderr: ""
Mar 18 08:55:51.994: INFO: stdout: "true"
Mar 18 08:55:51.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods update-demo-nautilus-4njwh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jr9t6'
Mar 18 08:55:52.081: INFO: stderr: ""
Mar 18 08:55:52.081: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 18 08:55:52.081: INFO: validating pod update-demo-nautilus-4njwh
Mar 18 08:55:52.090: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 18 08:55:52.090: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 18 08:55:52.090: INFO: update-demo-nautilus-4njwh is verified up and running
Mar 18 08:55:52.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods update-demo-nautilus-9m7nh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jr9t6'
Mar 18 08:55:52.172: INFO: stderr: ""
Mar 18 08:55:52.172: INFO: stdout: "true"
Mar 18 08:55:52.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods update-demo-nautilus-9m7nh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jr9t6'
Mar 18 08:55:52.246: INFO: stderr: ""
Mar 18 08:55:52.246: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 18 08:55:52.246: INFO: validating pod update-demo-nautilus-9m7nh
Mar 18 08:55:52.250: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 18 08:55:52.250: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 18 08:55:52.250: INFO: update-demo-nautilus-9m7nh is verified up and running
STEP: using delete to clean up resources
Mar 18 08:55:52.250: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-jr9t6'
Mar 18 08:55:52.329: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 18 08:55:52.329: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Mar 18 08:55:52.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-jr9t6'
Mar 18 08:55:52.430: INFO: stderr: "No resources found.\n"
Mar 18 08:55:52.430: INFO: stdout: ""
Mar 18 08:55:52.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pods -l name=update-demo --namespace=e2e-tests-kubectl-jr9t6 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 18 08:55:52.519: INFO: stderr: ""
Mar 18 08:55:52.519: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:55:52.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jr9t6" for this suite.
Mar 18 08:55:58.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:55:58.601: INFO: namespace: e2e-tests-kubectl-jr9t6, resource: bindings, ignored listing per whitelist
Mar 18 08:55:58.657: INFO: namespace e2e-tests-kubectl-jr9t6 deletion completed in 6.133119944s

â€¢ [SLOW TEST:25.448 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:55:58.657: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Mar 18 08:55:58.771: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-cgcg5,SelfLink:/api/v1/namespaces/e2e-tests-watch-cgcg5/configmaps/e2e-watch-test-watch-closed,UID:a6036800-495b-11e9-b44d-0022480537ee,ResourceVersion:205599,Generation:0,CreationTimestamp:2019-03-18 08:55:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 18 08:55:58.771: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-cgcg5,SelfLink:/api/v1/namespaces/e2e-tests-watch-cgcg5/configmaps/e2e-watch-test-watch-closed,UID:a6036800-495b-11e9-b44d-0022480537ee,ResourceVersion:205600,Generation:0,CreationTimestamp:2019-03-18 08:55:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Mar 18 08:55:58.784: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-cgcg5,SelfLink:/api/v1/namespaces/e2e-tests-watch-cgcg5/configmaps/e2e-watch-test-watch-closed,UID:a6036800-495b-11e9-b44d-0022480537ee,ResourceVersion:205601,Generation:0,CreationTimestamp:2019-03-18 08:55:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 18 08:55:58.784: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-cgcg5,SelfLink:/api/v1/namespaces/e2e-tests-watch-cgcg5/configmaps/e2e-watch-test-watch-closed,UID:a6036800-495b-11e9-b44d-0022480537ee,ResourceVersion:205602,Generation:0,CreationTimestamp:2019-03-18 08:55:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:55:58.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-cgcg5" for this suite.
Mar 18 08:56:04.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:56:04.916: INFO: namespace: e2e-tests-watch-cgcg5, resource: bindings, ignored listing per whitelist
Mar 18 08:56:04.926: INFO: namespace e2e-tests-watch-cgcg5 deletion completed in 6.135839407s

â€¢ [SLOW TEST:6.269 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:56:04.926: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Mar 18 08:56:05.128: INFO: Waiting up to 5m0s for pod "var-expansion-a9ce4621-495b-11e9-86d2-4ea95915efee" in namespace "e2e-tests-var-expansion-dn68q" to be "success or failure"
Mar 18 08:56:05.131: INFO: Pod "var-expansion-a9ce4621-495b-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 3.291297ms
Mar 18 08:56:07.135: INFO: Pod "var-expansion-a9ce4621-495b-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007062625s
Mar 18 08:56:09.138: INFO: Pod "var-expansion-a9ce4621-495b-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010647742s
STEP: Saw pod success
Mar 18 08:56:09.138: INFO: Pod "var-expansion-a9ce4621-495b-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:56:09.141: INFO: Trying to get logs from node worker02 pod var-expansion-a9ce4621-495b-11e9-86d2-4ea95915efee container dapi-container: <nil>
STEP: delete the pod
Mar 18 08:56:09.196: INFO: Waiting for pod var-expansion-a9ce4621-495b-11e9-86d2-4ea95915efee to disappear
Mar 18 08:56:09.198: INFO: Pod var-expansion-a9ce4621-495b-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:56:09.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-dn68q" for this suite.
Mar 18 08:56:15.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:56:15.260: INFO: namespace: e2e-tests-var-expansion-dn68q, resource: bindings, ignored listing per whitelist
Mar 18 08:56:15.333: INFO: namespace e2e-tests-var-expansion-dn68q deletion completed in 6.130133966s

â€¢ [SLOW TEST:10.407 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:56:15.333: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Mar 18 08:56:15.437: INFO: Waiting up to 5m0s for pod "pod-aff2ba77-495b-11e9-86d2-4ea95915efee" in namespace "e2e-tests-emptydir-gkctl" to be "success or failure"
Mar 18 08:56:15.443: INFO: Pod "pod-aff2ba77-495b-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 5.736542ms
Mar 18 08:56:17.449: INFO: Pod "pod-aff2ba77-495b-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012373541s
STEP: Saw pod success
Mar 18 08:56:17.449: INFO: Pod "pod-aff2ba77-495b-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:56:17.452: INFO: Trying to get logs from node worker01 pod pod-aff2ba77-495b-11e9-86d2-4ea95915efee container test-container: <nil>
STEP: delete the pod
Mar 18 08:56:17.473: INFO: Waiting for pod pod-aff2ba77-495b-11e9-86d2-4ea95915efee to disappear
Mar 18 08:56:17.482: INFO: Pod pod-aff2ba77-495b-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:56:17.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-gkctl" for this suite.
Mar 18 08:56:23.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:56:23.566: INFO: namespace: e2e-tests-emptydir-gkctl, resource: bindings, ignored listing per whitelist
Mar 18 08:56:23.599: INFO: namespace e2e-tests-emptydir-gkctl deletion completed in 6.112942742s

â€¢ [SLOW TEST:8.266 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:56:23.599: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 18 08:56:23.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 version --client'
Mar 18 08:56:23.767: INFO: stderr: ""
Mar 18 08:56:23.767: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Mar 18 08:56:23.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 create -f - --namespace=e2e-tests-kubectl-bb5n9'
Mar 18 08:56:23.947: INFO: stderr: ""
Mar 18 08:56:23.947: INFO: stdout: "replicationcontroller/redis-master created\n"
Mar 18 08:56:23.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 create -f - --namespace=e2e-tests-kubectl-bb5n9'
Mar 18 08:56:24.140: INFO: stderr: ""
Mar 18 08:56:24.140: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar 18 08:56:25.145: INFO: Selector matched 1 pods for map[app:redis]
Mar 18 08:56:25.145: INFO: Found 0 / 1
Mar 18 08:56:26.144: INFO: Selector matched 1 pods for map[app:redis]
Mar 18 08:56:26.144: INFO: Found 1 / 1
Mar 18 08:56:26.144: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar 18 08:56:26.146: INFO: Selector matched 1 pods for map[app:redis]
Mar 18 08:56:26.146: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar 18 08:56:26.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 describe pod redis-master-z9dcq --namespace=e2e-tests-kubectl-bb5n9'
Mar 18 08:56:26.247: INFO: stderr: ""
Mar 18 08:56:26.247: INFO: stdout: "Name:               redis-master-z9dcq\nNamespace:          e2e-tests-kubectl-bb5n9\nPriority:           0\nPriorityClassName:  <none>\nNode:               worker02/10.0.2.4\nStart Time:         Mon, 18 Mar 2019 08:56:24 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.38.0.8\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://d02dc2eefbcf1f16bd4829d59783eaca77f9643db24ef06d24984ddc580f6b96\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 18 Mar 2019 08:56:25 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-mp65b (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-mp65b:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-mp65b\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned e2e-tests-kubectl-bb5n9/redis-master-z9dcq to worker02\n  Normal  Pulled     2s    kubelet, worker02  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, worker02  Created container\n  Normal  Started    1s    kubelet, worker02  Started container\n"
Mar 18 08:56:26.247: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 describe rc redis-master --namespace=e2e-tests-kubectl-bb5n9'
Mar 18 08:56:26.369: INFO: stderr: ""
Mar 18 08:56:26.369: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-bb5n9\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-z9dcq\n"
Mar 18 08:56:26.369: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 describe service redis-master --namespace=e2e-tests-kubectl-bb5n9'
Mar 18 08:56:26.471: INFO: stderr: ""
Mar 18 08:56:26.471: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-bb5n9\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.109.153.182\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.38.0.8:6379\nSession Affinity:  None\nEvents:            <none>\n"
Mar 18 08:56:26.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 describe node master01'
Mar 18 08:56:26.594: INFO: stderr: ""
Mar 18 08:56:26.594: INFO: stdout: "Name:               master01\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=Standard_D4s_v3\n                    beta.kubernetes.io/os=linux\n                    cube.acornsoft.io/clusterid=cluster.local\n                    cube.acornsoft.io/role=master\n                    failure-domain.beta.kubernetes.io/region=koreacentral\n                    failure-domain.beta.kubernetes.io/zone=0\n                    kubernetes.io/hostname=master01\n                    node-role.kubernetes.io/master=\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Thu, 14 Mar 2019 07:06:16 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Thu, 14 Mar 2019 07:08:27 +0000   Thu, 14 Mar 2019 07:08:27 +0000   RouteCreated                 RouteController created a route\n  MemoryPressure       False   Mon, 18 Mar 2019 08:56:23 +0000   Thu, 14 Mar 2019 07:06:09 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Mon, 18 Mar 2019 08:56:23 +0000   Thu, 14 Mar 2019 07:06:09 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Mon, 18 Mar 2019 08:56:23 +0000   Thu, 14 Mar 2019 07:06:09 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Mon, 18 Mar 2019 08:56:23 +0000   Thu, 14 Mar 2019 07:08:36 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  Hostname:    master01\n  InternalIP:  10.0.2.6\n  ExternalIP:  52.231.26.24\nCapacity:\n attachable-volumes-azure-disk:  8\n cpu:                            4\n ephemeral-storage:              103080888Ki\n hugepages-1Gi:                  0\n hugepages-2Mi:                  0\n memory:                         16414840Ki\n pods:                           110\nAllocatable:\n attachable-volumes-azure-disk:  8\n cpu:                            4\n ephemeral-storage:              94999346224\n hugepages-1Gi:                  0\n hugepages-2Mi:                  0\n memory:                         16312440Ki\n pods:                           110\nSystem Info:\n Machine ID:                 97da09219a2d42489c8b8f748e6d2fb7\n System UUID:                57D26C3A-FDC3-5D41-A6A2-BCA5381B9BDB\n Boot ID:                    99bdeac8-ad50-47c2-a959-ff43871b16c5\n Kernel Version:             3.10.0-862.11.6.el7.x86_64\n OS Image:                   CentOS Linux 7 (Core)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.1\n Kubelet Version:            v1.13.1\n Kube-Proxy Version:         v1.13.1\nPodCIDR:                     10.32.0.0/24\nProviderID:                  azure:///subscriptions/f77a9bb1-e9b5-4591-a8bd-e2dee40d9e62/resourceGroups/cocktail-cncf-test/providers/Microsoft.Compute/virtualMachines/master01\nNon-terminated Pods:         (25 in total)\n  Namespace                  Name                                         CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                         ------------  ----------  ---------------  -------------  ---\n  cocktail-addon             alertmanager-59f9774ff5-2r8kq                20m (0%)      20m (0%)    42Mi (0%)        42Mi (0%)      4d1h\n  cocktail-addon             disk-usage-exporter-pgshs                    100m (2%)     100m (2%)   100Mi (0%)       100Mi (0%)     4d1h\n  cocktail-addon             kube-state-metrics-7d6dc48b8d-gvfjx          10m (0%)      10m (0%)    32Mi (0%)        32Mi (0%)      85m\n  cocktail-addon             nginx-ingress-controller-7f4694f66c-lchbm    0 (0%)        0 (0%)      0 (0%)           0 (0%)         4d1h\n  cocktail-addon             node-exporter-9ksdc                          200m (5%)     200m (5%)   50Mi (0%)        50Mi (0%)      4d1h\n  cocktail-addon             prometheus-55685464b8-75wn4                  110m (2%)     110m (2%)   810Mi (5%)       810Mi (5%)     4d1h\n  cocktail-system            api-cmdb-74b4c74c65-lq9zw                    0 (0%)        0 (0%)      0 (0%)           0 (0%)         4d1h\n  cocktail-system            api-server-6b79d47db7-5c9xh                  0 (0%)        0 (0%)      0 (0%)           0 (0%)         4d1h\n  cocktail-system            build-api-67d4d84ff8-68mcz                   100m (2%)     200m (5%)   200Mi (1%)       400Mi (2%)     4d1h\n  cocktail-system            build-queue-7b6dfd4b7-2jbk7                  100m (2%)     0 (0%)      100Mi (0%)       0 (0%)         4d1h\n  cocktail-system            cloud-metering-64459665dc-6mpqw              100m (2%)     200m (5%)   64Mi (0%)        256Mi (1%)     4d1h\n  cocktail-system            cloud-metering-collector-65459c7d68-pp85j    300m (7%)     600m (15%)  192Mi (1%)       768Mi (4%)     4d1h\n  cocktail-system            dashboard-55cb8cf56d-hbz45                   100m (2%)     300m (7%)   100Mi (0%)       300Mi (1%)     4d1h\n  cocktail-system            dashboard-proxy-6c9c799585-5kpsn             100m (2%)     200m (5%)   100Mi (0%)       200Mi (1%)     4d1h\n  cocktail-system            dashboard-queue-796db8787-f2dzg              100m (2%)     200m (5%)   256Mi (1%)       512Mi (3%)     4d1h\n  cocktail-system            dashboard-session-568bbb54f9-bzktm           100m (2%)     200m (5%)   100Mi (0%)       300Mi (1%)     4d1h\n  cocktail-system            monitoring-587449c75b-kj62w                  100m (2%)     300m (7%)   200Mi (1%)       400Mi (2%)     4d1h\n  cocktail-system            monitoring-collector-5f797bdb55-2qsdg        200m (5%)     300m (7%)   100Mi (0%)       200Mi (1%)     4d1h\n  cocktail-system            monitoring-db-6dc67d5b5c-j4wh8               500m (12%)    1 (25%)     1Gi (6%)         2Gi (12%)      4d1h\n  kube-system                kube-apiserver-master01                      250m (6%)     0 (0%)      0 (0%)           0 (0%)         4d1h\n  kube-system                kube-controller-manager-master01             200m (5%)     0 (0%)      0 (0%)           0 (0%)         4d1h\n  kube-system                kube-proxy-rz9xl                             0 (0%)        0 (0%)      0 (0%)           0 (0%)         4d1h\n  kube-system                kube-scheduler-master01                      100m (2%)     0 (0%)      0 (0%)           0 (0%)         4d1h\n  kube-system                metrics-server-7f8c895b45-grh7k              100m (2%)     200m (5%)   256Mi (1%)       256Mi (1%)     4d1h\n  kube-system                weave-net-vnplp                              20m (0%)      0 (0%)      0 (0%)           0 (0%)         4d1h\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                       Requests      Limits\n  --------                       --------      ------\n  cpu                            2910m (72%)   4140m (103%)\n  memory                         3726Mi (23%)  6674Mi (41%)\n  ephemeral-storage              0 (0%)        0 (0%)\n  attachable-volumes-azure-disk  0             0\nEvents:                          <none>\n"
Mar 18 08:56:26.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 describe namespace e2e-tests-kubectl-bb5n9'
Mar 18 08:56:26.690: INFO: stderr: ""
Mar 18 08:56:26.690: INFO: stdout: "Name:         e2e-tests-kubectl-bb5n9\nLabels:       e2e-framework=kubectl\n              e2e-run=52cb4cad-4950-11e9-86d2-4ea95915efee\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:56:26.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bb5n9" for this suite.
Mar 18 08:56:48.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:56:48.799: INFO: namespace: e2e-tests-kubectl-bb5n9, resource: bindings, ignored listing per whitelist
Mar 18 08:56:48.818: INFO: namespace e2e-tests-kubectl-bb5n9 deletion completed in 22.123861219s

â€¢ [SLOW TEST:25.219 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:56:48.818: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-ghqnw
Mar 18 08:56:50.921: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-ghqnw
STEP: checking the pod's current state and verifying that restartCount is present
Mar 18 08:56:50.924: INFO: Initial restart count of pod liveness-http is 0
Mar 18 08:57:09.015: INFO: Restart count of pod e2e-tests-container-probe-ghqnw/liveness-http is now 1 (18.090588229s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:57:09.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-ghqnw" for this suite.
Mar 18 08:57:15.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:57:15.161: INFO: namespace: e2e-tests-container-probe-ghqnw, resource: bindings, ignored listing per whitelist
Mar 18 08:57:15.167: INFO: namespace e2e-tests-container-probe-ghqnw deletion completed in 6.130015759s

â€¢ [SLOW TEST:26.349 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:57:15.167: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 18 08:57:15.271: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d39d69e7-495b-11e9-86d2-4ea95915efee" in namespace "e2e-tests-projected-22xbz" to be "success or failure"
Mar 18 08:57:15.277: INFO: Pod "downwardapi-volume-d39d69e7-495b-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 5.173908ms
Mar 18 08:57:17.281: INFO: Pod "downwardapi-volume-d39d69e7-495b-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009408664s
Mar 18 08:57:19.284: INFO: Pod "downwardapi-volume-d39d69e7-495b-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012352042s
STEP: Saw pod success
Mar 18 08:57:19.284: INFO: Pod "downwardapi-volume-d39d69e7-495b-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:57:19.286: INFO: Trying to get logs from node worker02 pod downwardapi-volume-d39d69e7-495b-11e9-86d2-4ea95915efee container client-container: <nil>
STEP: delete the pod
Mar 18 08:57:19.303: INFO: Waiting for pod downwardapi-volume-d39d69e7-495b-11e9-86d2-4ea95915efee to disappear
Mar 18 08:57:19.306: INFO: Pod downwardapi-volume-d39d69e7-495b-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:57:19.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-22xbz" for this suite.
Mar 18 08:57:25.321: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:57:25.350: INFO: namespace: e2e-tests-projected-22xbz, resource: bindings, ignored listing per whitelist
Mar 18 08:57:25.425: INFO: namespace e2e-tests-projected-22xbz deletion completed in 6.114778951s

â€¢ [SLOW TEST:10.257 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:57:25.425: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 18 08:57:25.536: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d9bb8dbf-495b-11e9-86d2-4ea95915efee" in namespace "e2e-tests-projected-vv6z9" to be "success or failure"
Mar 18 08:57:25.548: INFO: Pod "downwardapi-volume-d9bb8dbf-495b-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 11.824404ms
Mar 18 08:57:27.551: INFO: Pod "downwardapi-volume-d9bb8dbf-495b-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015177008s
STEP: Saw pod success
Mar 18 08:57:27.551: INFO: Pod "downwardapi-volume-d9bb8dbf-495b-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:57:27.554: INFO: Trying to get logs from node worker01 pod downwardapi-volume-d9bb8dbf-495b-11e9-86d2-4ea95915efee container client-container: <nil>
STEP: delete the pod
Mar 18 08:57:27.573: INFO: Waiting for pod downwardapi-volume-d9bb8dbf-495b-11e9-86d2-4ea95915efee to disappear
Mar 18 08:57:27.576: INFO: Pod downwardapi-volume-d9bb8dbf-495b-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:57:27.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vv6z9" for this suite.
Mar 18 08:57:33.598: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:57:33.669: INFO: namespace: e2e-tests-projected-vv6z9, resource: bindings, ignored listing per whitelist
Mar 18 08:57:33.703: INFO: namespace e2e-tests-projected-vv6z9 deletion completed in 6.122052085s

â€¢ [SLOW TEST:8.278 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:57:33.703: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 18 08:57:33.799: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dea8855f-495b-11e9-86d2-4ea95915efee" in namespace "e2e-tests-downward-api-vflfh" to be "success or failure"
Mar 18 08:57:33.806: INFO: Pod "downwardapi-volume-dea8855f-495b-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 6.140166ms
Mar 18 08:57:35.810: INFO: Pod "downwardapi-volume-dea8855f-495b-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010136708s
STEP: Saw pod success
Mar 18 08:57:35.810: INFO: Pod "downwardapi-volume-dea8855f-495b-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:57:35.813: INFO: Trying to get logs from node worker02 pod downwardapi-volume-dea8855f-495b-11e9-86d2-4ea95915efee container client-container: <nil>
STEP: delete the pod
Mar 18 08:57:35.830: INFO: Waiting for pod downwardapi-volume-dea8855f-495b-11e9-86d2-4ea95915efee to disappear
Mar 18 08:57:35.833: INFO: Pod downwardapi-volume-dea8855f-495b-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:57:35.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-vflfh" for this suite.
Mar 18 08:57:41.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:57:41.963: INFO: namespace: e2e-tests-downward-api-vflfh, resource: bindings, ignored listing per whitelist
Mar 18 08:57:41.988: INFO: namespace e2e-tests-downward-api-vflfh deletion completed in 6.151193422s

â€¢ [SLOW TEST:8.285 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:57:41.989: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-e39b85cf-495b-11e9-86d2-4ea95915efee
STEP: Creating a pod to test consume secrets
Mar 18 08:57:42.107: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e39c1494-495b-11e9-86d2-4ea95915efee" in namespace "e2e-tests-projected-p95rl" to be "success or failure"
Mar 18 08:57:42.120: INFO: Pod "pod-projected-secrets-e39c1494-495b-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 13.021376ms
Mar 18 08:57:44.124: INFO: Pod "pod-projected-secrets-e39c1494-495b-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017210329s
STEP: Saw pod success
Mar 18 08:57:44.124: INFO: Pod "pod-projected-secrets-e39c1494-495b-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:57:44.128: INFO: Trying to get logs from node worker01 pod pod-projected-secrets-e39c1494-495b-11e9-86d2-4ea95915efee container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 18 08:57:44.153: INFO: Waiting for pod pod-projected-secrets-e39c1494-495b-11e9-86d2-4ea95915efee to disappear
Mar 18 08:57:44.158: INFO: Pod pod-projected-secrets-e39c1494-495b-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:57:44.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-p95rl" for this suite.
Mar 18 08:57:50.179: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:57:50.192: INFO: namespace: e2e-tests-projected-p95rl, resource: bindings, ignored listing per whitelist
Mar 18 08:57:50.286: INFO: namespace e2e-tests-projected-p95rl deletion completed in 6.117469711s

â€¢ [SLOW TEST:8.297 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:57:50.286: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 18 08:57:50.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-6w2m5'
Mar 18 08:57:50.462: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar 18 08:57:50.462: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Mar 18 08:57:50.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-6w2m5'
Mar 18 08:57:50.559: INFO: stderr: ""
Mar 18 08:57:50.559: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:57:50.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6w2m5" for this suite.
Mar 18 08:58:12.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:58:12.606: INFO: namespace: e2e-tests-kubectl-6w2m5, resource: bindings, ignored listing per whitelist
Mar 18 08:58:12.680: INFO: namespace e2e-tests-kubectl-6w2m5 deletion completed in 22.116418376s

â€¢ [SLOW TEST:22.394 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:58:12.680: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-f5e3d303-495b-11e9-86d2-4ea95915efee
STEP: Creating a pod to test consume configMaps
Mar 18 08:58:12.807: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f5e85c74-495b-11e9-86d2-4ea95915efee" in namespace "e2e-tests-projected-gnx9v" to be "success or failure"
Mar 18 08:58:12.817: INFO: Pod "pod-projected-configmaps-f5e85c74-495b-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 9.709079ms
Mar 18 08:58:14.820: INFO: Pod "pod-projected-configmaps-f5e85c74-495b-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01286357s
Mar 18 08:58:16.824: INFO: Pod "pod-projected-configmaps-f5e85c74-495b-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016104667s
STEP: Saw pod success
Mar 18 08:58:16.824: INFO: Pod "pod-projected-configmaps-f5e85c74-495b-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:58:16.826: INFO: Trying to get logs from node worker01 pod pod-projected-configmaps-f5e85c74-495b-11e9-86d2-4ea95915efee container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 18 08:58:16.853: INFO: Waiting for pod pod-projected-configmaps-f5e85c74-495b-11e9-86d2-4ea95915efee to disappear
Mar 18 08:58:16.895: INFO: Pod pod-projected-configmaps-f5e85c74-495b-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:58:16.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gnx9v" for this suite.
Mar 18 08:58:22.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:58:22.982: INFO: namespace: e2e-tests-projected-gnx9v, resource: bindings, ignored listing per whitelist
Mar 18 08:58:23.022: INFO: namespace e2e-tests-projected-gnx9v deletion completed in 6.122682122s

â€¢ [SLOW TEST:10.342 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:58:23.022: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Mar 18 08:58:23.130: INFO: Waiting up to 5m0s for pod "client-containers-fc0fcafb-495b-11e9-86d2-4ea95915efee" in namespace "e2e-tests-containers-6trzp" to be "success or failure"
Mar 18 08:58:23.133: INFO: Pod "client-containers-fc0fcafb-495b-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.660758ms
Mar 18 08:58:25.136: INFO: Pod "client-containers-fc0fcafb-495b-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00615237s
STEP: Saw pod success
Mar 18 08:58:25.137: INFO: Pod "client-containers-fc0fcafb-495b-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 08:58:25.140: INFO: Trying to get logs from node worker02 pod client-containers-fc0fcafb-495b-11e9-86d2-4ea95915efee container test-container: <nil>
STEP: delete the pod
Mar 18 08:58:25.157: INFO: Waiting for pod client-containers-fc0fcafb-495b-11e9-86d2-4ea95915efee to disappear
Mar 18 08:58:25.160: INFO: Pod client-containers-fc0fcafb-495b-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:58:25.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-6trzp" for this suite.
Mar 18 08:58:31.180: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:58:31.221: INFO: namespace: e2e-tests-containers-6trzp, resource: bindings, ignored listing per whitelist
Mar 18 08:58:31.297: INFO: namespace e2e-tests-containers-6trzp deletion completed in 6.132824027s

â€¢ [SLOW TEST:8.275 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:58:31.297: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 18 08:58:31.426: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Mar 18 08:58:31.434: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:58:31.438: INFO: Number of nodes with available pods: 0
Mar 18 08:58:31.439: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:58:32.444: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:58:32.447: INFO: Number of nodes with available pods: 0
Mar 18 08:58:32.447: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:58:33.443: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:58:33.447: INFO: Number of nodes with available pods: 0
Mar 18 08:58:33.447: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:58:34.444: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:58:34.447: INFO: Number of nodes with available pods: 2
Mar 18 08:58:34.447: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Mar 18 08:58:34.469: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:34.469: INFO: Wrong image for pod: daemon-set-v5sbh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:34.481: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:58:35.484: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:35.484: INFO: Wrong image for pod: daemon-set-v5sbh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:35.489: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:58:36.485: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:36.485: INFO: Wrong image for pod: daemon-set-v5sbh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:36.490: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:58:37.485: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:37.485: INFO: Wrong image for pod: daemon-set-v5sbh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:37.490: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:58:38.484: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:38.484: INFO: Wrong image for pod: daemon-set-v5sbh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:38.489: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:58:39.484: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:39.484: INFO: Wrong image for pod: daemon-set-v5sbh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:39.489: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:58:40.484: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:40.485: INFO: Wrong image for pod: daemon-set-v5sbh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:40.489: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:58:41.484: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:41.484: INFO: Wrong image for pod: daemon-set-v5sbh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:41.490: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:58:42.484: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:42.484: INFO: Wrong image for pod: daemon-set-v5sbh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:42.489: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:58:43.485: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:43.485: INFO: Wrong image for pod: daemon-set-v5sbh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:43.491: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:58:44.485: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:44.485: INFO: Wrong image for pod: daemon-set-v5sbh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:44.490: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:58:45.484: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:45.484: INFO: Wrong image for pod: daemon-set-v5sbh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:45.488: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:58:46.485: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:46.485: INFO: Wrong image for pod: daemon-set-v5sbh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:46.490: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:58:47.485: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:47.485: INFO: Wrong image for pod: daemon-set-v5sbh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:47.490: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:58:48.485: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:48.485: INFO: Wrong image for pod: daemon-set-v5sbh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:48.490: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:58:49.484: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:49.484: INFO: Wrong image for pod: daemon-set-v5sbh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:49.488: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:58:50.484: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:50.484: INFO: Wrong image for pod: daemon-set-v5sbh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:50.489: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:58:51.484: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:51.484: INFO: Wrong image for pod: daemon-set-v5sbh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:51.490: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:58:52.485: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:52.485: INFO: Wrong image for pod: daemon-set-v5sbh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:52.489: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:58:53.484: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:53.484: INFO: Wrong image for pod: daemon-set-v5sbh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:53.489: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:58:54.485: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:54.485: INFO: Wrong image for pod: daemon-set-v5sbh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:54.490: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:58:55.485: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:55.485: INFO: Wrong image for pod: daemon-set-v5sbh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:55.491: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:58:56.485: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:56.485: INFO: Wrong image for pod: daemon-set-v5sbh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:56.490: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:58:57.484: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:57.484: INFO: Wrong image for pod: daemon-set-v5sbh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:57.489: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:58:58.484: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:58.484: INFO: Wrong image for pod: daemon-set-v5sbh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:58.489: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:58:59.484: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:59.484: INFO: Wrong image for pod: daemon-set-v5sbh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:58:59.489: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:00.484: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:00.484: INFO: Wrong image for pod: daemon-set-v5sbh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:00.489: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:01.484: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:01.485: INFO: Wrong image for pod: daemon-set-v5sbh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:01.489: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:02.485: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:02.485: INFO: Wrong image for pod: daemon-set-v5sbh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:02.490: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:03.485: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:03.485: INFO: Wrong image for pod: daemon-set-v5sbh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:03.489: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:04.484: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:04.484: INFO: Wrong image for pod: daemon-set-v5sbh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:04.488: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:05.484: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:05.484: INFO: Wrong image for pod: daemon-set-v5sbh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:05.489: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:06.485: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:06.485: INFO: Wrong image for pod: daemon-set-v5sbh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:06.490: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:07.484: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:07.484: INFO: Wrong image for pod: daemon-set-v5sbh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:07.484: INFO: Pod daemon-set-v5sbh is not available
Mar 18 08:59:07.490: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:08.484: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:08.484: INFO: Pod daemon-set-qqnkj is not available
Mar 18 08:59:08.489: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:09.485: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:09.485: INFO: Pod daemon-set-qqnkj is not available
Mar 18 08:59:09.490: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:10.485: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:10.490: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:11.485: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:11.490: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:12.485: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:12.490: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:13.484: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:13.491: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:14.484: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:14.489: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:15.484: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:15.489: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:16.484: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:16.489: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:17.484: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:17.489: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:18.484: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:18.488: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:19.484: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:19.489: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:20.485: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:20.490: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:21.484: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:21.489: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:22.485: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:22.490: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:23.484: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:23.489: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:24.485: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:24.489: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:25.484: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:25.489: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:26.484: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:26.489: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:27.490: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:27.495: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:28.488: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:28.492: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:29.484: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:29.491: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:30.485: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:30.492: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:31.485: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:31.491: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:32.488: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:32.492: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:33.484: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:33.488: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:34.484: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:34.489: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:35.484: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:35.488: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:36.485: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:36.490: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:37.484: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:37.489: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:38.484: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:38.489: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:39.486: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:39.491: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:40.484: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:40.502: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:41.485: INFO: Wrong image for pod: daemon-set-2clj9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 18 08:59:41.485: INFO: Pod daemon-set-2clj9 is not available
Mar 18 08:59:41.489: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:42.485: INFO: Pod daemon-set-d6bdq is not available
Mar 18 08:59:42.489: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Mar 18 08:59:42.494: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:42.497: INFO: Number of nodes with available pods: 1
Mar 18 08:59:42.497: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:59:43.503: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:43.506: INFO: Number of nodes with available pods: 1
Mar 18 08:59:43.506: INFO: Node worker01 is running more than one daemon pod
Mar 18 08:59:44.503: INFO: DaemonSet pods can't tolerate node master01 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 18 08:59:44.506: INFO: Number of nodes with available pods: 2
Mar 18 08:59:44.506: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-fz5k7, will wait for the garbage collector to delete the pods
Mar 18 08:59:44.579: INFO: Deleting DaemonSet.extensions daemon-set took: 5.246313ms
Mar 18 08:59:44.679: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.193972ms
Mar 18 08:59:51.785: INFO: Number of nodes with available pods: 0
Mar 18 08:59:51.785: INFO: Number of running nodes: 0, number of available pods: 0
Mar 18 08:59:51.796: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-fz5k7/daemonsets","resourceVersion":"206341"},"items":null}

Mar 18 08:59:51.814: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-fz5k7/pods","resourceVersion":"206341"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 08:59:51.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-fz5k7" for this suite.
Mar 18 08:59:57.852: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 08:59:57.894: INFO: namespace: e2e-tests-daemonsets-fz5k7, resource: bindings, ignored listing per whitelist
Mar 18 08:59:57.958: INFO: namespace e2e-tests-daemonsets-fz5k7 deletion completed in 6.116897677s

â€¢ [SLOW TEST:86.661 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 08:59:57.958: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 18 08:59:58.057: INFO: Waiting up to 5m0s for pod "downwardapi-volume-34a48a15-495c-11e9-86d2-4ea95915efee" in namespace "e2e-tests-projected-k2c9g" to be "success or failure"
Mar 18 08:59:58.069: INFO: Pod "downwardapi-volume-34a48a15-495c-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 11.780202ms
Mar 18 09:00:00.074: INFO: Pod "downwardapi-volume-34a48a15-495c-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016766903s
STEP: Saw pod success
Mar 18 09:00:00.074: INFO: Pod "downwardapi-volume-34a48a15-495c-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 09:00:00.077: INFO: Trying to get logs from node worker01 pod downwardapi-volume-34a48a15-495c-11e9-86d2-4ea95915efee container client-container: <nil>
STEP: delete the pod
Mar 18 09:00:00.101: INFO: Waiting for pod downwardapi-volume-34a48a15-495c-11e9-86d2-4ea95915efee to disappear
Mar 18 09:00:00.105: INFO: Pod downwardapi-volume-34a48a15-495c-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 09:00:00.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-k2c9g" for this suite.
Mar 18 09:00:06.122: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 09:00:06.214: INFO: namespace: e2e-tests-projected-k2c9g, resource: bindings, ignored listing per whitelist
Mar 18 09:00:06.225: INFO: namespace e2e-tests-projected-k2c9g deletion completed in 6.114513035s

â€¢ [SLOW TEST:8.267 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 09:00:06.225: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-39923a7a-495c-11e9-86d2-4ea95915efee
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 09:00:10.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-drmk6" for this suite.
Mar 18 09:00:32.395: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 09:00:32.418: INFO: namespace: e2e-tests-configmap-drmk6, resource: bindings, ignored listing per whitelist
Mar 18 09:00:32.495: INFO: namespace e2e-tests-configmap-drmk6 deletion completed in 22.120382112s

â€¢ [SLOW TEST:26.270 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 09:00:32.496: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 09:00:32.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-6zwch" for this suite.
Mar 18 09:00:54.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 09:00:54.757: INFO: namespace: e2e-tests-kubelet-test-6zwch, resource: bindings, ignored listing per whitelist
Mar 18 09:00:54.762: INFO: namespace e2e-tests-kubelet-test-6zwch deletion completed in 22.145606216s

â€¢ [SLOW TEST:22.267 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 09:00:54.763: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-mqwb2
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-mqwb2 to expose endpoints map[]
Mar 18 09:00:54.886: INFO: Get endpoints failed (2.52015ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Mar 18 09:00:55.890: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-mqwb2 exposes endpoints map[] (1.006230773s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-mqwb2
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-mqwb2 to expose endpoints map[pod1:[80]]
Mar 18 09:00:57.915: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-mqwb2 exposes endpoints map[pod1:[80]] (2.019302154s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-mqwb2
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-mqwb2 to expose endpoints map[pod2:[80] pod1:[80]]
Mar 18 09:00:59.965: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-mqwb2 exposes endpoints map[pod2:[80] pod1:[80]] (2.043355788s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-mqwb2
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-mqwb2 to expose endpoints map[pod2:[80]]
Mar 18 09:00:59.978: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-mqwb2 exposes endpoints map[pod2:[80]] (7.070821ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-mqwb2
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-mqwb2 to expose endpoints map[]
Mar 18 09:00:59.995: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-mqwb2 exposes endpoints map[] (11.707297ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 09:01:00.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-mqwb2" for this suite.
Mar 18 09:01:22.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 09:01:22.103: INFO: namespace: e2e-tests-services-mqwb2, resource: bindings, ignored listing per whitelist
Mar 18 09:01:22.172: INFO: namespace e2e-tests-services-mqwb2 deletion completed in 22.124609064s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

â€¢ [SLOW TEST:27.409 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 09:01:22.172: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 18 09:01:22.288: INFO: (0) /api/v1/nodes/worker01:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="azure/">azure/</a>
<... (200; 6.776204ms)
Mar 18 09:01:22.292: INFO: (1) /api/v1/nodes/worker01:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="azure/">azure/</a>
<... (200; 4.185449ms)
Mar 18 09:01:22.297: INFO: (2) /api/v1/nodes/worker01:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="azure/">azure/</a>
<... (200; 4.940395ms)
Mar 18 09:01:22.303: INFO: (3) /api/v1/nodes/worker01:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="azure/">azure/</a>
<... (200; 5.781144ms)
Mar 18 09:01:22.309: INFO: (4) /api/v1/nodes/worker01:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="azure/">azure/</a>
<... (200; 6.083062ms)
Mar 18 09:01:22.313: INFO: (5) /api/v1/nodes/worker01:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="azure/">azure/</a>
<... (200; 4.120746ms)
Mar 18 09:01:22.317: INFO: (6) /api/v1/nodes/worker01:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="azure/">azure/</a>
<... (200; 3.903133ms)
Mar 18 09:01:22.322: INFO: (7) /api/v1/nodes/worker01:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="azure/">azure/</a>
<... (200; 4.295256ms)
Mar 18 09:01:22.326: INFO: (8) /api/v1/nodes/worker01:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="azure/">azure/</a>
<... (200; 4.283955ms)
Mar 18 09:01:22.330: INFO: (9) /api/v1/nodes/worker01:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="azure/">azure/</a>
<... (200; 4.221952ms)
Mar 18 09:01:22.335: INFO: (10) /api/v1/nodes/worker01:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="azure/">azure/</a>
<... (200; 4.742082ms)
Mar 18 09:01:22.340: INFO: (11) /api/v1/nodes/worker01:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="azure/">azure/</a>
<... (200; 4.733182ms)
Mar 18 09:01:22.344: INFO: (12) /api/v1/nodes/worker01:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="azure/">azure/</a>
<... (200; 4.53647ms)
Mar 18 09:01:22.352: INFO: (13) /api/v1/nodes/worker01:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="azure/">azure/</a>
<... (200; 7.673257ms)
Mar 18 09:01:22.360: INFO: (14) /api/v1/nodes/worker01:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="azure/">azure/</a>
<... (200; 8.032279ms)
Mar 18 09:01:22.365: INFO: (15) /api/v1/nodes/worker01:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="azure/">azure/</a>
<... (200; 4.777584ms)
Mar 18 09:01:22.369: INFO: (16) /api/v1/nodes/worker01:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="azure/">azure/</a>
<... (200; 4.165148ms)
Mar 18 09:01:22.373: INFO: (17) /api/v1/nodes/worker01:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="azure/">azure/</a>
<... (200; 4.294556ms)
Mar 18 09:01:22.389: INFO: (18) /api/v1/nodes/worker01:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="azure/">azure/</a>
<... (200; 15.527825ms)
Mar 18 09:01:22.394: INFO: (19) /api/v1/nodes/worker01:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="azure/">azure/</a>
<... (200; 5.0323ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 09:01:22.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-wr9pd" for this suite.
Mar 18 09:01:28.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 09:01:28.477: INFO: namespace: e2e-tests-proxy-wr9pd, resource: bindings, ignored listing per whitelist
Mar 18 09:01:28.529: INFO: namespace e2e-tests-proxy-wr9pd deletion completed in 6.130136166s

â€¢ [SLOW TEST:6.357 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 09:01:28.529: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar 18 09:01:28.629: INFO: Waiting up to 5m0s for pod "downward-api-6aa0b7b4-495c-11e9-86d2-4ea95915efee" in namespace "e2e-tests-downward-api-q2lzg" to be "success or failure"
Mar 18 09:01:28.644: INFO: Pod "downward-api-6aa0b7b4-495c-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 14.892888ms
Mar 18 09:01:30.649: INFO: Pod "downward-api-6aa0b7b4-495c-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019221849s
STEP: Saw pod success
Mar 18 09:01:30.649: INFO: Pod "downward-api-6aa0b7b4-495c-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 09:01:30.652: INFO: Trying to get logs from node worker02 pod downward-api-6aa0b7b4-495c-11e9-86d2-4ea95915efee container dapi-container: <nil>
STEP: delete the pod
Mar 18 09:01:30.672: INFO: Waiting for pod downward-api-6aa0b7b4-495c-11e9-86d2-4ea95915efee to disappear
Mar 18 09:01:30.674: INFO: Pod downward-api-6aa0b7b4-495c-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 09:01:30.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-q2lzg" for this suite.
Mar 18 09:01:36.694: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 09:01:36.824: INFO: namespace: e2e-tests-downward-api-q2lzg, resource: bindings, ignored listing per whitelist
Mar 18 09:01:36.836: INFO: namespace e2e-tests-downward-api-q2lzg deletion completed in 6.156816757s

â€¢ [SLOW TEST:8.307 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 09:01:36.836: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-d7z5g
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 18 09:01:36.931: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 18 09:01:59.021: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.32.0.6:8080/dial?request=hostName&protocol=udp&host=10.32.0.5&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-d7z5g PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 18 09:01:59.022: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
Mar 18 09:01:59.174: INFO: Waiting for endpoints: map[]
Mar 18 09:01:59.181: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.32.0.6:8080/dial?request=hostName&protocol=udp&host=10.38.0.8&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-d7z5g PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 18 09:01:59.181: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
Mar 18 09:01:59.335: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 09:01:59.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-d7z5g" for this suite.
Mar 18 09:02:21.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 09:02:21.413: INFO: namespace: e2e-tests-pod-network-test-d7z5g, resource: bindings, ignored listing per whitelist
Mar 18 09:02:21.452: INFO: namespace e2e-tests-pod-network-test-d7z5g deletion completed in 22.112536544s

â€¢ [SLOW TEST:44.617 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 09:02:21.453: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-8a2fd78f-495c-11e9-86d2-4ea95915efee
STEP: Creating a pod to test consume secrets
Mar 18 09:02:21.587: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8a303ea6-495c-11e9-86d2-4ea95915efee" in namespace "e2e-tests-projected-fq5gw" to be "success or failure"
Mar 18 09:02:21.593: INFO: Pod "pod-projected-secrets-8a303ea6-495c-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 5.728141ms
Mar 18 09:02:23.597: INFO: Pod "pod-projected-secrets-8a303ea6-495c-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009998699s
STEP: Saw pod success
Mar 18 09:02:23.597: INFO: Pod "pod-projected-secrets-8a303ea6-495c-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 09:02:23.600: INFO: Trying to get logs from node worker01 pod pod-projected-secrets-8a303ea6-495c-11e9-86d2-4ea95915efee container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 18 09:02:23.625: INFO: Waiting for pod pod-projected-secrets-8a303ea6-495c-11e9-86d2-4ea95915efee to disappear
Mar 18 09:02:23.631: INFO: Pod pod-projected-secrets-8a303ea6-495c-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 09:02:23.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fq5gw" for this suite.
Mar 18 09:02:29.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 09:02:29.762: INFO: namespace: e2e-tests-projected-fq5gw, resource: bindings, ignored listing per whitelist
Mar 18 09:02:29.762: INFO: namespace e2e-tests-projected-fq5gw deletion completed in 6.124513831s

â€¢ [SLOW TEST:8.309 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 09:02:29.763: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-g7gf
STEP: Creating a pod to test atomic-volume-subpath
Mar 18 09:02:29.901: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-g7gf" in namespace "e2e-tests-subpath-v7pvc" to be "success or failure"
Mar 18 09:02:29.909: INFO: Pod "pod-subpath-test-projected-g7gf": Phase="Pending", Reason="", readiness=false. Elapsed: 7.690758ms
Mar 18 09:02:31.912: INFO: Pod "pod-subpath-test-projected-g7gf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010948156s
Mar 18 09:02:33.916: INFO: Pod "pod-subpath-test-projected-g7gf": Phase="Running", Reason="", readiness=false. Elapsed: 4.014760387s
Mar 18 09:02:35.920: INFO: Pod "pod-subpath-test-projected-g7gf": Phase="Running", Reason="", readiness=false. Elapsed: 6.018573417s
Mar 18 09:02:37.924: INFO: Pod "pod-subpath-test-projected-g7gf": Phase="Running", Reason="", readiness=false. Elapsed: 8.022675865s
Mar 18 09:02:39.928: INFO: Pod "pod-subpath-test-projected-g7gf": Phase="Running", Reason="", readiness=false. Elapsed: 10.026844717s
Mar 18 09:02:41.932: INFO: Pod "pod-subpath-test-projected-g7gf": Phase="Running", Reason="", readiness=false. Elapsed: 12.03053784s
Mar 18 09:02:43.935: INFO: Pod "pod-subpath-test-projected-g7gf": Phase="Running", Reason="", readiness=false. Elapsed: 14.034286967s
Mar 18 09:02:45.939: INFO: Pod "pod-subpath-test-projected-g7gf": Phase="Running", Reason="", readiness=false. Elapsed: 16.037714175s
Mar 18 09:02:47.943: INFO: Pod "pod-subpath-test-projected-g7gf": Phase="Running", Reason="", readiness=false. Elapsed: 18.04176422s
Mar 18 09:02:49.946: INFO: Pod "pod-subpath-test-projected-g7gf": Phase="Running", Reason="", readiness=false. Elapsed: 20.04539644s
Mar 18 09:02:51.950: INFO: Pod "pod-subpath-test-projected-g7gf": Phase="Running", Reason="", readiness=false. Elapsed: 22.048766044s
Mar 18 09:02:53.953: INFO: Pod "pod-subpath-test-projected-g7gf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.052353761s
STEP: Saw pod success
Mar 18 09:02:53.953: INFO: Pod "pod-subpath-test-projected-g7gf" satisfied condition "success or failure"
Mar 18 09:02:53.956: INFO: Trying to get logs from node worker02 pod pod-subpath-test-projected-g7gf container test-container-subpath-projected-g7gf: <nil>
STEP: delete the pod
Mar 18 09:02:53.983: INFO: Waiting for pod pod-subpath-test-projected-g7gf to disappear
Mar 18 09:02:53.986: INFO: Pod pod-subpath-test-projected-g7gf no longer exists
STEP: Deleting pod pod-subpath-test-projected-g7gf
Mar 18 09:02:53.987: INFO: Deleting pod "pod-subpath-test-projected-g7gf" in namespace "e2e-tests-subpath-v7pvc"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 09:02:53.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-v7pvc" for this suite.
Mar 18 09:03:00.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 09:03:00.116: INFO: namespace: e2e-tests-subpath-v7pvc, resource: bindings, ignored listing per whitelist
Mar 18 09:03:00.135: INFO: namespace e2e-tests-subpath-v7pvc deletion completed in 6.141119421s

â€¢ [SLOW TEST:30.373 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 09:03:00.136: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-a13a2eb6-495c-11e9-86d2-4ea95915efee
STEP: Creating a pod to test consume secrets
Mar 18 09:03:00.239: INFO: Waiting up to 5m0s for pod "pod-secrets-a13b4114-495c-11e9-86d2-4ea95915efee" in namespace "e2e-tests-secrets-t8zck" to be "success or failure"
Mar 18 09:03:00.243: INFO: Pod "pod-secrets-a13b4114-495c-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 4.302156ms
Mar 18 09:03:02.247: INFO: Pod "pod-secrets-a13b4114-495c-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008027581s
STEP: Saw pod success
Mar 18 09:03:02.247: INFO: Pod "pod-secrets-a13b4114-495c-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 09:03:02.249: INFO: Trying to get logs from node worker01 pod pod-secrets-a13b4114-495c-11e9-86d2-4ea95915efee container secret-volume-test: <nil>
STEP: delete the pod
Mar 18 09:03:02.275: INFO: Waiting for pod pod-secrets-a13b4114-495c-11e9-86d2-4ea95915efee to disappear
Mar 18 09:03:02.285: INFO: Pod pod-secrets-a13b4114-495c-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 09:03:02.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-t8zck" for this suite.
Mar 18 09:03:08.307: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 09:03:08.331: INFO: namespace: e2e-tests-secrets-t8zck, resource: bindings, ignored listing per whitelist
Mar 18 09:03:08.416: INFO: namespace e2e-tests-secrets-t8zck deletion completed in 6.12534268s

â€¢ [SLOW TEST:8.281 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 09:03:08.416: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-a6284315-495c-11e9-86d2-4ea95915efee
STEP: Creating a pod to test consume secrets
Mar 18 09:03:08.511: INFO: Waiting up to 5m0s for pod "pod-secrets-a629859c-495c-11e9-86d2-4ea95915efee" in namespace "e2e-tests-secrets-l2r67" to be "success or failure"
Mar 18 09:03:08.515: INFO: Pod "pod-secrets-a629859c-495c-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 3.149388ms
Mar 18 09:03:10.518: INFO: Pod "pod-secrets-a629859c-495c-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007071525s
STEP: Saw pod success
Mar 18 09:03:10.518: INFO: Pod "pod-secrets-a629859c-495c-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 09:03:10.521: INFO: Trying to get logs from node worker02 pod pod-secrets-a629859c-495c-11e9-86d2-4ea95915efee container secret-volume-test: <nil>
STEP: delete the pod
Mar 18 09:03:10.539: INFO: Waiting for pod pod-secrets-a629859c-495c-11e9-86d2-4ea95915efee to disappear
Mar 18 09:03:10.554: INFO: Pod pod-secrets-a629859c-495c-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 09:03:10.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-l2r67" for this suite.
Mar 18 09:03:16.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 09:03:16.614: INFO: namespace: e2e-tests-secrets-l2r67, resource: bindings, ignored listing per whitelist
Mar 18 09:03:16.683: INFO: namespace e2e-tests-secrets-l2r67 deletion completed in 6.124029403s

â€¢ [SLOW TEST:8.266 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 09:03:16.683: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar 18 09:03:16.785: INFO: Waiting up to 5m0s for pod "downward-api-ab17a231-495c-11e9-86d2-4ea95915efee" in namespace "e2e-tests-downward-api-lwt42" to be "success or failure"
Mar 18 09:03:16.795: INFO: Pod "downward-api-ab17a231-495c-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 10.148105ms
Mar 18 09:03:18.798: INFO: Pod "downward-api-ab17a231-495c-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013420004s
STEP: Saw pod success
Mar 18 09:03:18.798: INFO: Pod "downward-api-ab17a231-495c-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 09:03:18.801: INFO: Trying to get logs from node worker01 pod downward-api-ab17a231-495c-11e9-86d2-4ea95915efee container dapi-container: <nil>
STEP: delete the pod
Mar 18 09:03:18.818: INFO: Waiting for pod downward-api-ab17a231-495c-11e9-86d2-4ea95915efee to disappear
Mar 18 09:03:18.821: INFO: Pod downward-api-ab17a231-495c-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 09:03:18.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-lwt42" for this suite.
Mar 18 09:03:24.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 09:03:24.916: INFO: namespace: e2e-tests-downward-api-lwt42, resource: bindings, ignored listing per whitelist
Mar 18 09:03:24.944: INFO: namespace e2e-tests-downward-api-lwt42 deletion completed in 6.117137392s

â€¢ [SLOW TEST:8.261 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 09:03:24.945: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 18 09:03:25.050: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b00480a6-495c-11e9-86d2-4ea95915efee" in namespace "e2e-tests-downward-api-tnh8q" to be "success or failure"
Mar 18 09:03:25.054: INFO: Pod "downwardapi-volume-b00480a6-495c-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 4.474966ms
Mar 18 09:03:27.058: INFO: Pod "downwardapi-volume-b00480a6-495c-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007939176s
STEP: Saw pod success
Mar 18 09:03:27.058: INFO: Pod "downwardapi-volume-b00480a6-495c-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 09:03:27.060: INFO: Trying to get logs from node worker02 pod downwardapi-volume-b00480a6-495c-11e9-86d2-4ea95915efee container client-container: <nil>
STEP: delete the pod
Mar 18 09:03:27.090: INFO: Waiting for pod downwardapi-volume-b00480a6-495c-11e9-86d2-4ea95915efee to disappear
Mar 18 09:03:27.093: INFO: Pod downwardapi-volume-b00480a6-495c-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 09:03:27.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-tnh8q" for this suite.
Mar 18 09:03:33.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 09:03:33.191: INFO: namespace: e2e-tests-downward-api-tnh8q, resource: bindings, ignored listing per whitelist
Mar 18 09:03:33.209: INFO: namespace e2e-tests-downward-api-tnh8q deletion completed in 6.111560759s

â€¢ [SLOW TEST:8.265 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 09:03:33.210: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Mar 18 09:03:33.304: INFO: Waiting up to 5m0s for pod "var-expansion-b4f087f0-495c-11e9-86d2-4ea95915efee" in namespace "e2e-tests-var-expansion-kk57r" to be "success or failure"
Mar 18 09:03:33.322: INFO: Pod "var-expansion-b4f087f0-495c-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 18.368695ms
Mar 18 09:03:35.326: INFO: Pod "var-expansion-b4f087f0-495c-11e9-86d2-4ea95915efee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021968813s
Mar 18 09:03:37.329: INFO: Pod "var-expansion-b4f087f0-495c-11e9-86d2-4ea95915efee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025748241s
STEP: Saw pod success
Mar 18 09:03:37.330: INFO: Pod "var-expansion-b4f087f0-495c-11e9-86d2-4ea95915efee" satisfied condition "success or failure"
Mar 18 09:03:37.332: INFO: Trying to get logs from node worker01 pod var-expansion-b4f087f0-495c-11e9-86d2-4ea95915efee container dapi-container: <nil>
STEP: delete the pod
Mar 18 09:03:37.359: INFO: Waiting for pod var-expansion-b4f087f0-495c-11e9-86d2-4ea95915efee to disappear
Mar 18 09:03:37.361: INFO: Pod var-expansion-b4f087f0-495c-11e9-86d2-4ea95915efee no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 09:03:37.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-kk57r" for this suite.
Mar 18 09:03:43.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 09:03:43.483: INFO: namespace: e2e-tests-var-expansion-kk57r, resource: bindings, ignored listing per whitelist
Mar 18 09:03:43.488: INFO: namespace e2e-tests-var-expansion-kk57r deletion completed in 6.122529913s

â€¢ [SLOW TEST:10.279 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 09:03:43.488: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-5hbcj
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 18 09:03:43.579: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 18 09:04:07.664: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.38.0.9:8080/dial?request=hostName&protocol=http&host=10.38.0.8&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-5hbcj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 18 09:04:07.664: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
Mar 18 09:04:07.799: INFO: Waiting for endpoints: map[]
Mar 18 09:04:07.802: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.38.0.9:8080/dial?request=hostName&protocol=http&host=10.32.0.5&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-5hbcj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 18 09:04:07.802: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
Mar 18 09:04:07.929: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 09:04:07.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-5hbcj" for this suite.
Mar 18 09:04:29.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 09:04:29.980: INFO: namespace: e2e-tests-pod-network-test-5hbcj, resource: bindings, ignored listing per whitelist
Mar 18 09:04:30.066: INFO: namespace e2e-tests-pod-network-test-5hbcj deletion completed in 22.131825394s

â€¢ [SLOW TEST:46.577 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 09:04:30.066: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 18 09:04:30.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-srm65'
Mar 18 09:04:30.851: INFO: stderr: ""
Mar 18 09:04:30.851: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Mar 18 09:04:30.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-srm65'
Mar 18 09:04:41.718: INFO: stderr: ""
Mar 18 09:04:41.718: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 09:04:41.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-srm65" for this suite.
Mar 18 09:04:47.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 09:04:47.829: INFO: namespace: e2e-tests-kubectl-srm65, resource: bindings, ignored listing per whitelist
Mar 18 09:04:47.837: INFO: namespace e2e-tests-kubectl-srm65 deletion completed in 6.113784691s

â€¢ [SLOW TEST:17.770 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 09:04:47.837: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar 18 09:04:50.475: INFO: Successfully updated pod "labelsupdatee16cdb06-495c-11e9-86d2-4ea95915efee"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 09:04:54.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-f6ddd" for this suite.
Mar 18 09:05:16.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 09:05:16.587: INFO: namespace: e2e-tests-projected-f6ddd, resource: bindings, ignored listing per whitelist
Mar 18 09:05:16.644: INFO: namespace e2e-tests-projected-f6ddd deletion completed in 22.130463913s

â€¢ [SLOW TEST:28.808 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 18 09:05:16.645: INFO: >>> kubeConfig: /tmp/kubeconfig-236863226
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 18 09:05:16.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-lk7mt'
Mar 18 09:05:16.848: INFO: stderr: ""
Mar 18 09:05:16.848: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Mar 18 09:05:21.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-lk7mt -o json'
Mar 18 09:05:21.986: INFO: stderr: ""
Mar 18 09:05:21.986: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-03-18T09:05:16Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-lk7mt\",\n        \"resourceVersion\": \"207417\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-lk7mt/pods/e2e-test-nginx-pod\",\n        \"uid\": \"f2a72966-495c-11e9-b44d-0022480537ee\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-8f76h\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"worker02\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-8f76h\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-8f76h\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-18T09:05:16Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-18T09:05:18Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-18T09:05:18Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-18T09:05:16Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://419ce7c66b0da3ce9f0ae46fe88d81f0b678fa890825be0305a6718049506624\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-03-18T09:05:17Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.0.2.4\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.38.0.8\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-03-18T09:05:16Z\"\n    }\n}\n"
STEP: replace the image in the pod
Mar 18 09:05:21.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 replace -f - --namespace=e2e-tests-kubectl-lk7mt'
Mar 18 09:05:22.160: INFO: stderr: ""
Mar 18 09:05:22.160: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Mar 18 09:05:22.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-236863226 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-lk7mt'
Mar 18 09:05:23.731: INFO: stderr: ""
Mar 18 09:05:23.731: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 18 09:05:23.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lk7mt" for this suite.
Mar 18 09:05:29.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 18 09:05:29.813: INFO: namespace: e2e-tests-kubectl-lk7mt, resource: bindings, ignored listing per whitelist
Mar 18 09:05:29.889: INFO: namespace e2e-tests-kubectl-lk7mt deletion completed in 6.152748615s

â€¢ [SLOW TEST:13.244 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSMar 18 09:05:29.890: INFO: Running AfterSuite actions on all nodes
Mar 18 09:05:29.890: INFO: Running AfterSuite actions on node 1
Mar 18 09:05:29.890: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 5434.442 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h30m35.298071242s
Test Suite Passed
