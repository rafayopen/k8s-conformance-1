I0531 02:10:28.309746      15 test_context.go:362] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-535705201
I0531 02:10:28.309885      15 e2e.go:224] Starting e2e run "41fbed49-8349-11e9-949c-223764f7eae1" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1559268627 - Will randomize all specs
Will run 201 of 2162 specs

May 31 02:10:28.533: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
May 31 02:10:28.536: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
May 31 02:10:28.559: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
May 31 02:10:28.591: INFO: 20 / 20 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
May 31 02:10:28.591: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
May 31 02:10:28.591: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
May 31 02:10:28.600: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'azure-ip-masq-agent' (0 seconds elapsed)
May 31 02:10:28.600: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds' (0 seconds elapsed)
May 31 02:10:28.600: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
May 31 02:10:28.600: INFO: e2e test version: v1.13.6
May 31 02:10:28.603: INFO: kube-apiserver version: v1.13.6
SSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:10:28.603: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename deployment
May 31 02:10:28.751: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 31 02:10:28.753: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
May 31 02:10:28.804: INFO: Pod name sample-pod: Found 0 pods out of 1
May 31 02:10:33.807: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May 31 02:10:35.812: INFO: Creating deployment "test-rolling-update-deployment"
May 31 02:10:35.816: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
May 31 02:10:35.821: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
May 31 02:10:37.826: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
May 31 02:10:37.828: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694865435, loc:(*time.Location)(0x7b6dbe0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694865435, loc:(*time.Location)(0x7b6dbe0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694865435, loc:(*time.Location)(0x7b6dbe0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694865435, loc:(*time.Location)(0x7b6dbe0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-68b55d7bc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 31 02:10:39.832: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694865435, loc:(*time.Location)(0x7b6dbe0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694865435, loc:(*time.Location)(0x7b6dbe0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694865435, loc:(*time.Location)(0x7b6dbe0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694865435, loc:(*time.Location)(0x7b6dbe0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-68b55d7bc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 31 02:10:41.832: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 31 02:10:41.838: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-kxmkr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-kxmkr/deployments/test-rolling-update-deployment,UID:46f9bfaa-8349-11e9-944d-001dd80c001b,ResourceVersion:1131,Generation:1,CreationTimestamp:2019-05-31 02:10:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-05-31 02:10:35 +0000 UTC 2019-05-31 02:10:35 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-05-31 02:10:40 +0000 UTC 2019-05-31 02:10:35 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

May 31 02:10:41.840: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-kxmkr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-kxmkr/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:46fc17fc-8349-11e9-944d-001dd80c001b,ResourceVersion:1122,Generation:1,CreationTimestamp:2019-05-31 02:10:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 46f9bfaa-8349-11e9-944d-001dd80c001b 0xc001595e87 0xc001595e88}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
May 31 02:10:41.840: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
May 31 02:10:41.840: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-kxmkr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-kxmkr/replicasets/test-rolling-update-controller,UID:42c4843a-8349-11e9-944d-001dd80c001b,ResourceVersion:1130,Generation:2,CreationTimestamp:2019-05-31 02:10:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 46f9bfaa-8349-11e9-944d-001dd80c001b 0xc001595dbf 0xc001595dd0}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 31 02:10:41.843: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-2mc5q" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-2mc5q,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-kxmkr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kxmkr/pods/test-rolling-update-deployment-68b55d7bc6-2mc5q,UID:46fcc711-8349-11e9-944d-001dd80c001b,ResourceVersion:1121,Generation:0,CreationTimestamp:2019-05-31 02:10:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 46fc17fc-8349-11e9-944d-001dd80c001b 0xc0015c8217 0xc0015c8218}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hnncc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hnncc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-hnncc true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-linuxpool-39082607-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0015c8280} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0015c82a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 02:10:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 02:10:39 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 02:10:39 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 02:10:35 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.4,PodIP:10.244.3.3,StartTime:2019-05-31 02:10:35 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-05-31 02:10:39 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://96775601463b9b8ab7fd2a2a400f771d69222d03a0c232556a9a8fd0773903e7}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:10:41.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-kxmkr" for this suite.
May 31 02:10:47.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:10:47.897: INFO: namespace: e2e-tests-deployment-kxmkr, resource: bindings, ignored listing per whitelist
May 31 02:10:47.936: INFO: namespace e2e-tests-deployment-kxmkr deletion completed in 6.090994094s

• [SLOW TEST:19.334 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:10:47.937: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
May 31 02:10:48.089: INFO: Waiting up to 5m0s for pod "client-containers-4e49ee8b-8349-11e9-949c-223764f7eae1" in namespace "e2e-tests-containers-2lvg5" to be "success or failure"
May 31 02:10:48.094: INFO: Pod "client-containers-4e49ee8b-8349-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.773664ms
May 31 02:10:50.097: INFO: Pod "client-containers-4e49ee8b-8349-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007396292s
May 31 02:10:52.100: INFO: Pod "client-containers-4e49ee8b-8349-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010706029s
STEP: Saw pod success
May 31 02:10:52.100: INFO: Pod "client-containers-4e49ee8b-8349-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 02:10:52.102: INFO: Trying to get logs from node k8s-linuxpool-39082607-2 pod client-containers-4e49ee8b-8349-11e9-949c-223764f7eae1 container test-container: <nil>
STEP: delete the pod
May 31 02:10:52.152: INFO: Waiting for pod client-containers-4e49ee8b-8349-11e9-949c-223764f7eae1 to disappear
May 31 02:10:52.155: INFO: Pod client-containers-4e49ee8b-8349-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:10:52.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-2lvg5" for this suite.
May 31 02:10:58.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:10:58.184: INFO: namespace: e2e-tests-containers-2lvg5, resource: bindings, ignored listing per whitelist
May 31 02:10:58.242: INFO: namespace e2e-tests-containers-2lvg5 deletion completed in 6.082931488s

• [SLOW TEST:10.305 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:10:58.242: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 31 02:10:58.419: INFO: Waiting up to 5m0s for pod "downwardapi-volume-546a29f0-8349-11e9-949c-223764f7eae1" in namespace "e2e-tests-downward-api-j4hlm" to be "success or failure"
May 31 02:10:58.429: INFO: Pod "downwardapi-volume-546a29f0-8349-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 9.419926ms
May 31 02:11:00.432: INFO: Pod "downwardapi-volume-546a29f0-8349-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012686964s
May 31 02:11:02.435: INFO: Pod "downwardapi-volume-546a29f0-8349-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015474195s
May 31 02:11:04.438: INFO: Pod "downwardapi-volume-546a29f0-8349-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.018723532s
May 31 02:11:06.441: INFO: Pod "downwardapi-volume-546a29f0-8349-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.021415863s
STEP: Saw pod success
May 31 02:11:06.441: INFO: Pod "downwardapi-volume-546a29f0-8349-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 02:11:06.443: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod downwardapi-volume-546a29f0-8349-11e9-949c-223764f7eae1 container client-container: <nil>
STEP: delete the pod
May 31 02:11:06.485: INFO: Waiting for pod downwardapi-volume-546a29f0-8349-11e9-949c-223764f7eae1 to disappear
May 31 02:11:06.487: INFO: Pod downwardapi-volume-546a29f0-8349-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:11:06.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-j4hlm" for this suite.
May 31 02:11:12.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:11:12.525: INFO: namespace: e2e-tests-downward-api-j4hlm, resource: bindings, ignored listing per whitelist
May 31 02:11:12.571: INFO: namespace e2e-tests-downward-api-j4hlm deletion completed in 6.082039478s

• [SLOW TEST:14.329 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:11:12.573: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-t8r8s
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 31 02:11:12.664: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 31 02:11:34.789: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.244.3.5 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-t8r8s PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 31 02:11:34.789: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
May 31 02:11:35.950: INFO: Found all expected endpoints: [netserver-0]
May 31 02:11:35.952: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.244.0.7 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-t8r8s PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 31 02:11:35.952: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
May 31 02:11:37.104: INFO: Found all expected endpoints: [netserver-1]
May 31 02:11:37.107: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.244.1.3 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-t8r8s PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 31 02:11:37.107: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
May 31 02:11:38.259: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:11:38.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-t8r8s" for this suite.
May 31 02:12:02.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:12:02.334: INFO: namespace: e2e-tests-pod-network-test-t8r8s, resource: bindings, ignored listing per whitelist
May 31 02:12:02.349: INFO: namespace e2e-tests-pod-network-test-t8r8s deletion completed in 24.086843898s

• [SLOW TEST:49.776 seconds]
[sig-network] Networking
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:12:02.350: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-4g6l5
May 31 02:12:08.434: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-4g6l5
STEP: checking the pod's current state and verifying that restartCount is present
May 31 02:12:08.436: INFO: Initial restart count of pod liveness-exec is 0
May 31 02:13:00.523: INFO: Restart count of pod e2e-tests-container-probe-4g6l5/liveness-exec is now 1 (52.086804338s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:13:00.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-4g6l5" for this suite.
May 31 02:13:06.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:13:06.584: INFO: namespace: e2e-tests-container-probe-4g6l5, resource: bindings, ignored listing per whitelist
May 31 02:13:06.623: INFO: namespace e2e-tests-container-probe-4g6l5 deletion completed in 6.089007674s

• [SLOW TEST:64.273 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:13:06.623: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-a0e80627-8349-11e9-949c-223764f7eae1
STEP: Creating secret with name secret-projected-all-test-volume-a0e80612-8349-11e9-949c-223764f7eae1
STEP: Creating a pod to test Check all projections for projected volume plugin
May 31 02:13:06.703: INFO: Waiting up to 5m0s for pod "projected-volume-a0e805df-8349-11e9-949c-223764f7eae1" in namespace "e2e-tests-projected-dr799" to be "success or failure"
May 31 02:13:06.710: INFO: Pod "projected-volume-a0e805df-8349-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.78619ms
May 31 02:13:08.713: INFO: Pod "projected-volume-a0e805df-8349-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009878027s
May 31 02:13:10.716: INFO: Pod "projected-volume-a0e805df-8349-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012867062s
May 31 02:13:12.719: INFO: Pod "projected-volume-a0e805df-8349-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.015674795s
STEP: Saw pod success
May 31 02:13:12.719: INFO: Pod "projected-volume-a0e805df-8349-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 02:13:12.721: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod projected-volume-a0e805df-8349-11e9-949c-223764f7eae1 container projected-all-volume-test: <nil>
STEP: delete the pod
May 31 02:13:12.734: INFO: Waiting for pod projected-volume-a0e805df-8349-11e9-949c-223764f7eae1 to disappear
May 31 02:13:12.741: INFO: Pod projected-volume-a0e805df-8349-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:13:12.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dr799" for this suite.
May 31 02:13:18.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:13:18.782: INFO: namespace: e2e-tests-projected-dr799, resource: bindings, ignored listing per whitelist
May 31 02:13:18.848: INFO: namespace e2e-tests-projected-dr799 deletion completed in 6.104305278s

• [SLOW TEST:12.225 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:13:18.849: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
May 31 02:13:18.920: INFO: Waiting up to 5m0s for pod "pod-a83107b9-8349-11e9-949c-223764f7eae1" in namespace "e2e-tests-emptydir-ctkj7" to be "success or failure"
May 31 02:13:18.925: INFO: Pod "pod-a83107b9-8349-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.882066ms
May 31 02:13:20.928: INFO: Pod "pod-a83107b9-8349-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007995902s
May 31 02:13:22.931: INFO: Pod "pod-a83107b9-8349-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01115164s
STEP: Saw pod success
May 31 02:13:22.931: INFO: Pod "pod-a83107b9-8349-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 02:13:22.934: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod pod-a83107b9-8349-11e9-949c-223764f7eae1 container test-container: <nil>
STEP: delete the pod
May 31 02:13:22.953: INFO: Waiting for pod pod-a83107b9-8349-11e9-949c-223764f7eae1 to disappear
May 31 02:13:22.956: INFO: Pod pod-a83107b9-8349-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:13:22.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-ctkj7" for this suite.
May 31 02:13:28.966: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:13:29.088: INFO: namespace: e2e-tests-emptydir-ctkj7, resource: bindings, ignored listing per whitelist
May 31 02:13:29.089: INFO: namespace e2e-tests-emptydir-ctkj7 deletion completed in 6.131240238s

• [SLOW TEST:10.241 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:13:29.089: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-std42
May 31 02:13:35.181: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-std42
STEP: checking the pod's current state and verifying that restartCount is present
May 31 02:13:35.183: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:17:35.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-std42" for this suite.
May 31 02:17:41.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:17:41.688: INFO: namespace: e2e-tests-container-probe-std42, resource: bindings, ignored listing per whitelist
May 31 02:17:41.747: INFO: namespace e2e-tests-container-probe-std42 deletion completed in 6.093232541s

• [SLOW TEST:252.658 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:17:41.747: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 31 02:17:41.824: INFO: Waiting up to 5m0s for pod "downwardapi-volume-44e4d166-834a-11e9-949c-223764f7eae1" in namespace "e2e-tests-downward-api-xx9zg" to be "success or failure"
May 31 02:17:41.827: INFO: Pod "downwardapi-volume-44e4d166-834a-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.58628ms
May 31 02:17:43.830: INFO: Pod "downwardapi-volume-44e4d166-834a-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006661843s
May 31 02:17:45.833: INFO: Pod "downwardapi-volume-44e4d166-834a-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009798585s
STEP: Saw pod success
May 31 02:17:45.833: INFO: Pod "downwardapi-volume-44e4d166-834a-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 02:17:45.836: INFO: Trying to get logs from node k8s-linuxpool-39082607-2 pod downwardapi-volume-44e4d166-834a-11e9-949c-223764f7eae1 container client-container: <nil>
STEP: delete the pod
May 31 02:17:45.857: INFO: Waiting for pod downwardapi-volume-44e4d166-834a-11e9-949c-223764f7eae1 to disappear
May 31 02:17:45.860: INFO: Pod downwardapi-volume-44e4d166-834a-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:17:45.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xx9zg" for this suite.
May 31 02:17:51.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:17:51.911: INFO: namespace: e2e-tests-downward-api-xx9zg, resource: bindings, ignored listing per whitelist
May 31 02:17:51.951: INFO: namespace e2e-tests-downward-api-xx9zg deletion completed in 6.088720252s

• [SLOW TEST:10.204 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:17:51.952: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
May 31 02:17:52.022: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:17:56.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-7tffc" for this suite.
May 31 02:18:18.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:18:18.408: INFO: namespace: e2e-tests-init-container-7tffc, resource: bindings, ignored listing per whitelist
May 31 02:18:18.455: INFO: namespace e2e-tests-init-container-7tffc deletion completed in 22.084525882s

• [SLOW TEST:26.503 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:18:18.455: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 31 02:18:18.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-qbmg5'
May 31 02:18:18.937: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 31 02:18:18.937: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
May 31 02:18:22.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-qbmg5'
May 31 02:18:23.059: INFO: stderr: ""
May 31 02:18:23.059: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:18:23.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qbmg5" for this suite.
May 31 02:18:45.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:18:45.143: INFO: namespace: e2e-tests-kubectl-qbmg5, resource: bindings, ignored listing per whitelist
May 31 02:18:45.161: INFO: namespace e2e-tests-kubectl-qbmg5 deletion completed in 22.097446532s

• [SLOW TEST:26.706 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:18:45.162: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-6ab07953-834a-11e9-949c-223764f7eae1
STEP: Creating a pod to test consume configMaps
May 31 02:18:45.239: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6ab13723-834a-11e9-949c-223764f7eae1" in namespace "e2e-tests-projected-5h9sd" to be "success or failure"
May 31 02:18:45.242: INFO: Pod "pod-projected-configmaps-6ab13723-834a-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.528452ms
May 31 02:18:47.245: INFO: Pod "pod-projected-configmaps-6ab13723-834a-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005404179s
May 31 02:18:49.247: INFO: Pod "pod-projected-configmaps-6ab13723-834a-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008054007s
STEP: Saw pod success
May 31 02:18:49.247: INFO: Pod "pod-projected-configmaps-6ab13723-834a-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 02:18:49.249: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod pod-projected-configmaps-6ab13723-834a-11e9-949c-223764f7eae1 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 31 02:18:49.269: INFO: Waiting for pod pod-projected-configmaps-6ab13723-834a-11e9-949c-223764f7eae1 to disappear
May 31 02:18:49.272: INFO: Pod pod-projected-configmaps-6ab13723-834a-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:18:49.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5h9sd" for this suite.
May 31 02:18:55.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:18:55.337: INFO: namespace: e2e-tests-projected-5h9sd, resource: bindings, ignored listing per whitelist
May 31 02:18:55.365: INFO: namespace e2e-tests-projected-5h9sd deletion completed in 6.090027891s

• [SLOW TEST:10.203 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:18:55.366: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 31 02:18:55.455: INFO: Creating deployment "test-recreate-deployment"
May 31 02:18:55.460: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
May 31 02:18:55.473: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
May 31 02:18:57.480: INFO: Waiting deployment "test-recreate-deployment" to complete
May 31 02:18:57.482: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694865935, loc:(*time.Location)(0x7b6dbe0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694865935, loc:(*time.Location)(0x7b6dbe0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694865935, loc:(*time.Location)(0x7b6dbe0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694865935, loc:(*time.Location)(0x7b6dbe0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-5dfdcc846d\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 31 02:18:59.485: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
May 31 02:18:59.492: INFO: Updating deployment test-recreate-deployment
May 31 02:18:59.492: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 31 02:18:59.564: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-zwhkp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-zwhkp/deployments/test-recreate-deployment,UID:70c927d4-834a-11e9-944d-001dd80c001b,ResourceVersion:2369,Generation:2,CreationTimestamp:2019-05-31 02:18:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-05-31 02:18:59 +0000 UTC 2019-05-31 02:18:59 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-05-31 02:18:59 +0000 UTC 2019-05-31 02:18:55 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

May 31 02:18:59.567: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-zwhkp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-zwhkp/replicasets/test-recreate-deployment-697fbf54bf,UID:73359947-834a-11e9-944d-001dd80c001b,ResourceVersion:2368,Generation:1,CreationTimestamp:2019-05-31 02:18:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 70c927d4-834a-11e9-944d-001dd80c001b 0xc0014d6077 0xc0014d6078}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 31 02:18:59.567: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
May 31 02:18:59.567: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-zwhkp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-zwhkp/replicasets/test-recreate-deployment-5dfdcc846d,UID:70ca5543-834a-11e9-944d-001dd80c001b,ResourceVersion:2358,Generation:2,CreationTimestamp:2019-05-31 02:18:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 70c927d4-834a-11e9-944d-001dd80c001b 0xc00179bf97 0xc00179bf98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 31 02:18:59.570: INFO: Pod "test-recreate-deployment-697fbf54bf-4dxss" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-4dxss,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-zwhkp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-zwhkp/pods/test-recreate-deployment-697fbf54bf-4dxss,UID:73362f7c-834a-11e9-944d-001dd80c001b,ResourceVersion:2370,Generation:0,CreationTimestamp:2019-05-31 02:18:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf 73359947-834a-11e9-944d-001dd80c001b 0xc001418ff7 0xc001418ff8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-742dt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-742dt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-742dt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-linuxpool-39082607-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001419060} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001419080}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 02:18:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-31 02:18:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-31 02:18:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 02:18:59 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.4,PodIP:,StartTime:2019-05-31 02:18:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:18:59.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-zwhkp" for this suite.
May 31 02:19:05.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:19:05.609: INFO: namespace: e2e-tests-deployment-zwhkp, resource: bindings, ignored listing per whitelist
May 31 02:19:05.717: INFO: namespace e2e-tests-deployment-zwhkp deletion completed in 6.144619965s

• [SLOW TEST:10.352 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:19:05.720: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
May 31 02:19:05.787: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 31 02:19:05.792: INFO: Waiting for terminating namespaces to be deleted...
May 31 02:19:05.794: INFO: 
Logging pods the kubelet thinks is on node k8s-linuxpool-39082607-0 before test
May 31 02:19:05.799: INFO: kube-flannel-ds-cvbsp from kube-system started at 2019-05-31 02:08:14 +0000 UTC (2 container statuses recorded)
May 31 02:19:05.799: INFO: 	Container install-cni ready: true, restart count 0
May 31 02:19:05.799: INFO: 	Container kube-flannel ready: true, restart count 0
May 31 02:19:05.799: INFO: azure-ip-masq-agent-wfzlh from kube-system started at 2019-05-31 02:08:17 +0000 UTC (1 container statuses recorded)
May 31 02:19:05.799: INFO: 	Container azure-ip-masq-agent ready: true, restart count 0
May 31 02:19:05.800: INFO: kube-proxy-b8mdx from kube-system started at 2019-05-31 02:08:18 +0000 UTC (1 container statuses recorded)
May 31 02:19:05.800: INFO: 	Container kube-proxy ready: true, restart count 0
May 31 02:19:05.800: INFO: sonobuoy from heptio-sonobuoy started at 2019-05-31 02:09:42 +0000 UTC (1 container statuses recorded)
May 31 02:19:05.800: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 31 02:19:05.800: INFO: sonobuoy-systemd-logs-daemon-set-c8cb41e9386c4a37-bvqmw from heptio-sonobuoy started at 2019-05-31 02:09:50 +0000 UTC (2 container statuses recorded)
May 31 02:19:05.800: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
May 31 02:19:05.800: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 31 02:19:05.800: INFO: 
Logging pods the kubelet thinks is on node k8s-linuxpool-39082607-1 before test
May 31 02:19:05.831: INFO: kube-proxy-vp4nc from kube-system started at 2019-05-31 02:08:17 +0000 UTC (1 container statuses recorded)
May 31 02:19:05.831: INFO: 	Container kube-proxy ready: true, restart count 0
May 31 02:19:05.831: INFO: kubernetes-dashboard-7947fffdf5-8hd5w from kube-system started at 2019-05-31 02:08:34 +0000 UTC (1 container statuses recorded)
May 31 02:19:05.831: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 31 02:19:05.831: INFO: sonobuoy-systemd-logs-daemon-set-c8cb41e9386c4a37-288hm from heptio-sonobuoy started at 2019-05-31 02:09:50 +0000 UTC (2 container statuses recorded)
May 31 02:19:05.831: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
May 31 02:19:05.831: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 31 02:19:05.831: INFO: kube-flannel-ds-46vq7 from kube-system started at 2019-05-31 02:08:14 +0000 UTC (2 container statuses recorded)
May 31 02:19:05.831: INFO: 	Container install-cni ready: true, restart count 0
May 31 02:19:05.831: INFO: 	Container kube-flannel ready: true, restart count 0
May 31 02:19:05.831: INFO: azure-ip-masq-agent-kk6xv from kube-system started at 2019-05-31 02:08:17 +0000 UTC (1 container statuses recorded)
May 31 02:19:05.831: INFO: 	Container azure-ip-masq-agent ready: true, restart count 0
May 31 02:19:05.831: INFO: 
Logging pods the kubelet thinks is on node k8s-linuxpool-39082607-2 before test
May 31 02:19:05.838: INFO: metrics-server-69b44566d5-rt27d from kube-system started at 2019-05-31 02:08:34 +0000 UTC (1 container statuses recorded)
May 31 02:19:05.838: INFO: 	Container metrics-server ready: true, restart count 0
May 31 02:19:05.838: INFO: tiller-deploy-74b7fb5bb9-w5db4 from kube-system started at 2019-05-31 02:08:34 +0000 UTC (1 container statuses recorded)
May 31 02:19:05.838: INFO: 	Container tiller ready: true, restart count 0
May 31 02:19:05.838: INFO: sonobuoy-systemd-logs-daemon-set-c8cb41e9386c4a37-cbt95 from heptio-sonobuoy started at 2019-05-31 02:09:50 +0000 UTC (2 container statuses recorded)
May 31 02:19:05.838: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
May 31 02:19:05.838: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 31 02:19:05.838: INFO: kube-flannel-ds-k5cj4 from kube-system started at 2019-05-31 02:08:14 +0000 UTC (2 container statuses recorded)
May 31 02:19:05.838: INFO: 	Container install-cni ready: true, restart count 0
May 31 02:19:05.838: INFO: 	Container kube-flannel ready: true, restart count 0
May 31 02:19:05.839: INFO: azure-ip-masq-agent-4gmjm from kube-system started at 2019-05-31 02:08:17 +0000 UTC (1 container statuses recorded)
May 31 02:19:05.839: INFO: 	Container azure-ip-masq-agent ready: true, restart count 0
May 31 02:19:05.839: INFO: kube-proxy-cq296 from kube-system started at 2019-05-31 02:08:18 +0000 UTC (1 container statuses recorded)
May 31 02:19:05.839: INFO: 	Container kube-proxy ready: true, restart count 0
May 31 02:19:05.839: INFO: coredns-59b998c9dd-g7djk from kube-system started at 2019-05-31 02:08:18 +0000 UTC (1 container statuses recorded)
May 31 02:19:05.839: INFO: 	Container coredns ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-795e9a72-834a-11e9-949c-223764f7eae1 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-795e9a72-834a-11e9-949c-223764f7eae1 off the node k8s-linuxpool-39082607-2
STEP: verifying the node doesn't have the label kubernetes.io/e2e-795e9a72-834a-11e9-949c-223764f7eae1
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:19:13.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-5bxmd" for this suite.
May 31 02:19:25.905: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:19:25.983: INFO: namespace: e2e-tests-sched-pred-5bxmd, resource: bindings, ignored listing per whitelist
May 31 02:19:25.985: INFO: namespace e2e-tests-sched-pred-5bxmd deletion completed in 12.087554238s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:20.265 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:19:25.985: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:19:30.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-9nssr" for this suite.
May 31 02:20:20.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:20:20.119: INFO: namespace: e2e-tests-kubelet-test-9nssr, resource: bindings, ignored listing per whitelist
May 31 02:20:20.181: INFO: namespace e2e-tests-kubelet-test-9nssr deletion completed in 50.10650746s

• [SLOW TEST:54.196 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:20:20.182: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0531 02:20:30.274296      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 31 02:20:30.274: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:20:30.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-lr8ns" for this suite.
May 31 02:20:36.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:20:36.390: INFO: namespace: e2e-tests-gc-lr8ns, resource: bindings, ignored listing per whitelist
May 31 02:20:36.394: INFO: namespace e2e-tests-gc-lr8ns deletion completed in 6.117497591s

• [SLOW TEST:16.213 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:20:36.394: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-ad01e4b5-834a-11e9-949c-223764f7eae1
STEP: Creating a pod to test consume configMaps
May 31 02:20:36.501: INFO: Waiting up to 5m0s for pod "pod-configmaps-ad024799-834a-11e9-949c-223764f7eae1" in namespace "e2e-tests-configmap-l2h8x" to be "success or failure"
May 31 02:20:36.507: INFO: Pod "pod-configmaps-ad024799-834a-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.639204ms
May 31 02:20:38.510: INFO: Pod "pod-configmaps-ad024799-834a-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009172144s
May 31 02:20:40.515: INFO: Pod "pod-configmaps-ad024799-834a-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01372794s
STEP: Saw pod success
May 31 02:20:40.515: INFO: Pod "pod-configmaps-ad024799-834a-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 02:20:40.518: INFO: Trying to get logs from node k8s-linuxpool-39082607-2 pod pod-configmaps-ad024799-834a-11e9-949c-223764f7eae1 container configmap-volume-test: <nil>
STEP: delete the pod
May 31 02:20:40.534: INFO: Waiting for pod pod-configmaps-ad024799-834a-11e9-949c-223764f7eae1 to disappear
May 31 02:20:40.536: INFO: Pod pod-configmaps-ad024799-834a-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:20:40.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-l2h8x" for this suite.
May 31 02:20:46.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:20:46.589: INFO: namespace: e2e-tests-configmap-l2h8x, resource: bindings, ignored listing per whitelist
May 31 02:20:46.625: INFO: namespace e2e-tests-configmap-l2h8x deletion completed in 6.085909448s

• [SLOW TEST:10.231 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:20:46.625: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
May 31 02:20:46.706: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-4tmmx,SelfLink:/api/v1/namespaces/e2e-tests-watch-4tmmx/configmaps/e2e-watch-test-label-changed,UID:b316a725-834a-11e9-944d-001dd80c001b,ResourceVersion:2719,Generation:0,CreationTimestamp:2019-05-31 02:20:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 31 02:20:46.706: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-4tmmx,SelfLink:/api/v1/namespaces/e2e-tests-watch-4tmmx/configmaps/e2e-watch-test-label-changed,UID:b316a725-834a-11e9-944d-001dd80c001b,ResourceVersion:2720,Generation:0,CreationTimestamp:2019-05-31 02:20:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
May 31 02:20:46.706: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-4tmmx,SelfLink:/api/v1/namespaces/e2e-tests-watch-4tmmx/configmaps/e2e-watch-test-label-changed,UID:b316a725-834a-11e9-944d-001dd80c001b,ResourceVersion:2721,Generation:0,CreationTimestamp:2019-05-31 02:20:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
May 31 02:20:56.725: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-4tmmx,SelfLink:/api/v1/namespaces/e2e-tests-watch-4tmmx/configmaps/e2e-watch-test-label-changed,UID:b316a725-834a-11e9-944d-001dd80c001b,ResourceVersion:2738,Generation:0,CreationTimestamp:2019-05-31 02:20:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 31 02:20:56.726: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-4tmmx,SelfLink:/api/v1/namespaces/e2e-tests-watch-4tmmx/configmaps/e2e-watch-test-label-changed,UID:b316a725-834a-11e9-944d-001dd80c001b,ResourceVersion:2739,Generation:0,CreationTimestamp:2019-05-31 02:20:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
May 31 02:20:56.726: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-4tmmx,SelfLink:/api/v1/namespaces/e2e-tests-watch-4tmmx/configmaps/e2e-watch-test-label-changed,UID:b316a725-834a-11e9-944d-001dd80c001b,ResourceVersion:2740,Generation:0,CreationTimestamp:2019-05-31 02:20:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:20:56.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-4tmmx" for this suite.
May 31 02:21:02.751: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:21:02.785: INFO: namespace: e2e-tests-watch-4tmmx, resource: bindings, ignored listing per whitelist
May 31 02:21:02.845: INFO: namespace e2e-tests-watch-4tmmx deletion completed in 6.110577061s

• [SLOW TEST:16.220 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:21:02.846: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-bcc14ea3-834a-11e9-949c-223764f7eae1
STEP: Creating configMap with name cm-test-opt-upd-bcc14eec-834a-11e9-949c-223764f7eae1
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-bcc14ea3-834a-11e9-949c-223764f7eae1
STEP: Updating configmap cm-test-opt-upd-bcc14eec-834a-11e9-949c-223764f7eae1
STEP: Creating configMap with name cm-test-opt-create-bcc14f02-834a-11e9-949c-223764f7eae1
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:21:10.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ksf8j" for this suite.
May 31 02:21:33.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:21:33.069: INFO: namespace: e2e-tests-projected-ksf8j, resource: bindings, ignored listing per whitelist
May 31 02:21:33.091: INFO: namespace e2e-tests-projected-ksf8j deletion completed in 22.089980797s

• [SLOW TEST:30.245 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:21:33.091: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
May 31 02:21:33.186: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-5cb7q,SelfLink:/api/v1/namespaces/e2e-tests-watch-5cb7q/configmaps/e2e-watch-test-resource-version,UID:cec91c09-834a-11e9-944d-001dd80c001b,ResourceVersion:2858,Generation:0,CreationTimestamp:2019-05-31 02:21:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 31 02:21:33.186: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-5cb7q,SelfLink:/api/v1/namespaces/e2e-tests-watch-5cb7q/configmaps/e2e-watch-test-resource-version,UID:cec91c09-834a-11e9-944d-001dd80c001b,ResourceVersion:2859,Generation:0,CreationTimestamp:2019-05-31 02:21:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:21:33.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-5cb7q" for this suite.
May 31 02:21:39.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:21:39.208: INFO: namespace: e2e-tests-watch-5cb7q, resource: bindings, ignored listing per whitelist
May 31 02:21:39.328: INFO: namespace e2e-tests-watch-5cb7q deletion completed in 6.13895063s

• [SLOW TEST:6.237 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:21:39.328: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
May 31 02:21:39.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 cluster-info'
May 31 02:21:39.527: INFO: stderr: ""
May 31 02:21:39.527: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.0.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.0.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://10.0.0.1:443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://10.0.0.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\x1b[0;32mtiller-deploy\x1b[0m is running at \x1b[0;33mhttps://10.0.0.1:443/api/v1/namespaces/kube-system/services/tiller-deploy:tiller/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:21:39.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-svv4z" for this suite.
May 31 02:21:45.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:21:45.564: INFO: namespace: e2e-tests-kubectl-svv4z, resource: bindings, ignored listing per whitelist
May 31 02:21:45.610: INFO: namespace e2e-tests-kubectl-svv4z deletion completed in 6.080536933s

• [SLOW TEST:6.282 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:21:45.612: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 31 02:21:45.705: INFO: (0) /api/v1/nodes/k8s-linuxpool-39082607-0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 4.432578ms)
May 31 02:21:45.708: INFO: (1) /api/v1/nodes/k8s-linuxpool-39082607-0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 2.776249ms)
May 31 02:21:45.711: INFO: (2) /api/v1/nodes/k8s-linuxpool-39082607-0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.040153ms)
May 31 02:21:45.714: INFO: (3) /api/v1/nodes/k8s-linuxpool-39082607-0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.283458ms)
May 31 02:21:45.717: INFO: (4) /api/v1/nodes/k8s-linuxpool-39082607-0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 2.909551ms)
May 31 02:21:45.720: INFO: (5) /api/v1/nodes/k8s-linuxpool-39082607-0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 2.921651ms)
May 31 02:21:45.723: INFO: (6) /api/v1/nodes/k8s-linuxpool-39082607-0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.45376ms)
May 31 02:21:45.728: INFO: (7) /api/v1/nodes/k8s-linuxpool-39082607-0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 4.068872ms)
May 31 02:21:45.731: INFO: (8) /api/v1/nodes/k8s-linuxpool-39082607-0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.827867ms)
May 31 02:21:45.734: INFO: (9) /api/v1/nodes/k8s-linuxpool-39082607-0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 2.880451ms)
May 31 02:21:45.737: INFO: (10) /api/v1/nodes/k8s-linuxpool-39082607-0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 2.946651ms)
May 31 02:21:45.740: INFO: (11) /api/v1/nodes/k8s-linuxpool-39082607-0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 2.808349ms)
May 31 02:21:45.743: INFO: (12) /api/v1/nodes/k8s-linuxpool-39082607-0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.086654ms)
May 31 02:21:45.746: INFO: (13) /api/v1/nodes/k8s-linuxpool-39082607-0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.063154ms)
May 31 02:21:45.749: INFO: (14) /api/v1/nodes/k8s-linuxpool-39082607-0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 2.899151ms)
May 31 02:21:45.753: INFO: (15) /api/v1/nodes/k8s-linuxpool-39082607-0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.398559ms)
May 31 02:21:45.756: INFO: (16) /api/v1/nodes/k8s-linuxpool-39082607-0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.132255ms)
May 31 02:21:45.759: INFO: (17) /api/v1/nodes/k8s-linuxpool-39082607-0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.186756ms)
May 31 02:21:45.762: INFO: (18) /api/v1/nodes/k8s-linuxpool-39082607-0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 2.698548ms)
May 31 02:21:45.765: INFO: (19) /api/v1/nodes/k8s-linuxpool-39082607-0:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 2.971452ms)
[AfterEach] version v1
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:21:45.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-j4dzv" for this suite.
May 31 02:21:51.776: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:21:51.813: INFO: namespace: e2e-tests-proxy-j4dzv, resource: bindings, ignored listing per whitelist
May 31 02:21:51.847: INFO: namespace e2e-tests-proxy-j4dzv deletion completed in 6.08015788s

• [SLOW TEST:6.235 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:21:51.847: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
May 31 02:21:51.922: INFO: Waiting up to 5m0s for pod "pod-d9f636f1-834a-11e9-949c-223764f7eae1" in namespace "e2e-tests-emptydir-n488g" to be "success or failure"
May 31 02:21:51.925: INFO: Pod "pod-d9f636f1-834a-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.780966ms
May 31 02:21:53.929: INFO: Pod "pod-d9f636f1-834a-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006949285s
May 31 02:21:55.931: INFO: Pod "pod-d9f636f1-834a-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009632948s
STEP: Saw pod success
May 31 02:21:55.932: INFO: Pod "pod-d9f636f1-834a-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 02:21:55.934: INFO: Trying to get logs from node k8s-linuxpool-39082607-2 pod pod-d9f636f1-834a-11e9-949c-223764f7eae1 container test-container: <nil>
STEP: delete the pod
May 31 02:21:55.948: INFO: Waiting for pod pod-d9f636f1-834a-11e9-949c-223764f7eae1 to disappear
May 31 02:21:55.950: INFO: Pod pod-d9f636f1-834a-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:21:55.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-n488g" for this suite.
May 31 02:22:01.961: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:22:02.038: INFO: namespace: e2e-tests-emptydir-n488g, resource: bindings, ignored listing per whitelist
May 31 02:22:02.042: INFO: namespace e2e-tests-emptydir-n488g deletion completed in 6.088440216s

• [SLOW TEST:10.195 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:22:02.042: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 31 02:22:02.117: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e00a9c9b-834a-11e9-949c-223764f7eae1" in namespace "e2e-tests-downward-api-62jgd" to be "success or failure"
May 31 02:22:02.126: INFO: Pod "downwardapi-volume-e00a9c9b-834a-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.296744ms
May 31 02:22:04.128: INFO: Pod "downwardapi-volume-e00a9c9b-834a-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010921424s
May 31 02:22:06.131: INFO: Pod "downwardapi-volume-e00a9c9b-834a-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013707762s
STEP: Saw pod success
May 31 02:22:06.131: INFO: Pod "downwardapi-volume-e00a9c9b-834a-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 02:22:06.133: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod downwardapi-volume-e00a9c9b-834a-11e9-949c-223764f7eae1 container client-container: <nil>
STEP: delete the pod
May 31 02:22:06.146: INFO: Waiting for pod downwardapi-volume-e00a9c9b-834a-11e9-949c-223764f7eae1 to disappear
May 31 02:22:06.153: INFO: Pod downwardapi-volume-e00a9c9b-834a-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:22:06.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-62jgd" for this suite.
May 31 02:22:12.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:22:12.230: INFO: namespace: e2e-tests-downward-api-62jgd, resource: bindings, ignored listing per whitelist
May 31 02:22:12.233: INFO: namespace e2e-tests-downward-api-62jgd deletion completed in 6.07829256s

• [SLOW TEST:10.191 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:22:12.234: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-fqhxh
May 31 02:22:16.317: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-fqhxh
STEP: checking the pod's current state and verifying that restartCount is present
May 31 02:22:16.320: INFO: Initial restart count of pod liveness-http is 0
May 31 02:22:28.338: INFO: Restart count of pod e2e-tests-container-probe-fqhxh/liveness-http is now 1 (12.018056371s elapsed)
May 31 02:22:48.365: INFO: Restart count of pod e2e-tests-container-probe-fqhxh/liveness-http is now 2 (32.045157935s elapsed)
May 31 02:23:06.397: INFO: Restart count of pod e2e-tests-container-probe-fqhxh/liveness-http is now 3 (50.076673288s elapsed)
May 31 02:23:28.430: INFO: Restart count of pod e2e-tests-container-probe-fqhxh/liveness-http is now 4 (1m12.109874209s elapsed)
May 31 02:24:36.639: INFO: Restart count of pod e2e-tests-container-probe-fqhxh/liveness-http is now 5 (2m20.319514099s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:24:36.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-fqhxh" for this suite.
May 31 02:24:42.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:24:42.722: INFO: namespace: e2e-tests-container-probe-fqhxh, resource: bindings, ignored listing per whitelist
May 31 02:24:42.751: INFO: namespace e2e-tests-container-probe-fqhxh deletion completed in 6.097155127s

• [SLOW TEST:150.517 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:24:42.751: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-mrgd6
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
May 31 02:24:42.866: INFO: Found 0 stateful pods, waiting for 3
May 31 02:24:52.869: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 31 02:24:52.869: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 31 02:24:52.869: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
May 31 02:25:02.870: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 31 02:25:02.870: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 31 02:25:02.870: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
May 31 02:25:02.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 exec --namespace=e2e-tests-statefulset-mrgd6 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 31 02:25:03.103: INFO: stderr: ""
May 31 02:25:03.103: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 31 02:25:03.103: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
May 31 02:25:13.128: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
May 31 02:25:23.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 exec --namespace=e2e-tests-statefulset-mrgd6 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 31 02:25:23.352: INFO: stderr: ""
May 31 02:25:23.352: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 31 02:25:23.352: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 31 02:25:33.367: INFO: Waiting for StatefulSet e2e-tests-statefulset-mrgd6/ss2 to complete update
May 31 02:25:33.367: INFO: Waiting for Pod e2e-tests-statefulset-mrgd6/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
May 31 02:25:33.367: INFO: Waiting for Pod e2e-tests-statefulset-mrgd6/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
May 31 02:25:33.367: INFO: Waiting for Pod e2e-tests-statefulset-mrgd6/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
May 31 02:25:43.372: INFO: Waiting for StatefulSet e2e-tests-statefulset-mrgd6/ss2 to complete update
May 31 02:25:43.372: INFO: Waiting for Pod e2e-tests-statefulset-mrgd6/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
May 31 02:25:43.372: INFO: Waiting for Pod e2e-tests-statefulset-mrgd6/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
May 31 02:25:53.372: INFO: Waiting for StatefulSet e2e-tests-statefulset-mrgd6/ss2 to complete update
May 31 02:25:53.372: INFO: Waiting for Pod e2e-tests-statefulset-mrgd6/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
May 31 02:26:03.372: INFO: Waiting for StatefulSet e2e-tests-statefulset-mrgd6/ss2 to complete update
STEP: Rolling back to a previous revision
May 31 02:26:13.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 exec --namespace=e2e-tests-statefulset-mrgd6 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 31 02:26:13.597: INFO: stderr: ""
May 31 02:26:13.597: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 31 02:26:13.597: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 31 02:26:23.623: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
May 31 02:26:33.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 exec --namespace=e2e-tests-statefulset-mrgd6 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 31 02:26:33.863: INFO: stderr: ""
May 31 02:26:33.863: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 31 02:26:33.863: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 31 02:26:43.877: INFO: Waiting for StatefulSet e2e-tests-statefulset-mrgd6/ss2 to complete update
May 31 02:26:43.877: INFO: Waiting for Pod e2e-tests-statefulset-mrgd6/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
May 31 02:26:43.877: INFO: Waiting for Pod e2e-tests-statefulset-mrgd6/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
May 31 02:26:43.877: INFO: Waiting for Pod e2e-tests-statefulset-mrgd6/ss2-2 to have revision ss2-787997d666 update revision ss2-c79899b9
May 31 02:26:53.882: INFO: Waiting for StatefulSet e2e-tests-statefulset-mrgd6/ss2 to complete update
May 31 02:26:53.882: INFO: Waiting for Pod e2e-tests-statefulset-mrgd6/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
May 31 02:26:53.882: INFO: Waiting for Pod e2e-tests-statefulset-mrgd6/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
May 31 02:27:03.883: INFO: Waiting for StatefulSet e2e-tests-statefulset-mrgd6/ss2 to complete update
May 31 02:27:03.883: INFO: Waiting for Pod e2e-tests-statefulset-mrgd6/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 31 02:27:13.884: INFO: Deleting all statefulset in ns e2e-tests-statefulset-mrgd6
May 31 02:27:13.886: INFO: Scaling statefulset ss2 to 0
May 31 02:27:33.902: INFO: Waiting for statefulset status.replicas updated to 0
May 31 02:27:33.904: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:27:33.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-mrgd6" for this suite.
May 31 02:27:39.936: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:27:39.993: INFO: namespace: e2e-tests-statefulset-mrgd6, resource: bindings, ignored listing per whitelist
May 31 02:27:40.025: INFO: namespace e2e-tests-statefulset-mrgd6 deletion completed in 6.104222686s

• [SLOW TEST:177.274 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:27:40.025: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-a97ee6ce-834b-11e9-949c-223764f7eae1
STEP: Creating a pod to test consume secrets
May 31 02:27:40.108: INFO: Waiting up to 5m0s for pod "pod-secrets-a97fad8f-834b-11e9-949c-223764f7eae1" in namespace "e2e-tests-secrets-s2hxn" to be "success or failure"
May 31 02:27:40.111: INFO: Pod "pod-secrets-a97fad8f-834b-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.23405ms
May 31 02:27:42.114: INFO: Pod "pod-secrets-a97fad8f-834b-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006671008s
May 31 02:27:44.117: INFO: Pod "pod-secrets-a97fad8f-834b-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009430743s
STEP: Saw pod success
May 31 02:27:44.117: INFO: Pod "pod-secrets-a97fad8f-834b-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 02:27:44.119: INFO: Trying to get logs from node k8s-linuxpool-39082607-2 pod pod-secrets-a97fad8f-834b-11e9-949c-223764f7eae1 container secret-volume-test: <nil>
STEP: delete the pod
May 31 02:27:44.135: INFO: Waiting for pod pod-secrets-a97fad8f-834b-11e9-949c-223764f7eae1 to disappear
May 31 02:27:44.139: INFO: Pod pod-secrets-a97fad8f-834b-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:27:44.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-s2hxn" for this suite.
May 31 02:27:50.149: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:27:50.206: INFO: namespace: e2e-tests-secrets-s2hxn, resource: bindings, ignored listing per whitelist
May 31 02:27:50.228: INFO: namespace e2e-tests-secrets-s2hxn deletion completed in 6.086358729s

• [SLOW TEST:10.203 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:27:50.229: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
May 31 02:27:50.301: INFO: Waiting up to 5m0s for pod "pod-af9327b4-834b-11e9-949c-223764f7eae1" in namespace "e2e-tests-emptydir-955kp" to be "success or failure"
May 31 02:27:50.305: INFO: Pod "pod-af9327b4-834b-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.531869ms
May 31 02:27:52.308: INFO: Pod "pod-af9327b4-834b-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006907052s
May 31 02:27:54.310: INFO: Pod "pod-af9327b4-834b-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009567628s
STEP: Saw pod success
May 31 02:27:54.310: INFO: Pod "pod-af9327b4-834b-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 02:27:54.312: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod pod-af9327b4-834b-11e9-949c-223764f7eae1 container test-container: <nil>
STEP: delete the pod
May 31 02:27:54.330: INFO: Waiting for pod pod-af9327b4-834b-11e9-949c-223764f7eae1 to disappear
May 31 02:27:54.334: INFO: Pod pod-af9327b4-834b-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:27:54.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-955kp" for this suite.
May 31 02:28:00.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:28:00.384: INFO: namespace: e2e-tests-emptydir-955kp, resource: bindings, ignored listing per whitelist
May 31 02:28:00.423: INFO: namespace e2e-tests-emptydir-955kp deletion completed in 6.087439572s

• [SLOW TEST:10.194 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:28:00.424: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
May 31 02:28:00.518: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 02:28:00.520: INFO: Number of nodes with available pods: 0
May 31 02:28:00.520: INFO: Node k8s-linuxpool-39082607-0 is running more than one daemon pod
May 31 02:28:01.523: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 02:28:01.526: INFO: Number of nodes with available pods: 0
May 31 02:28:01.526: INFO: Node k8s-linuxpool-39082607-0 is running more than one daemon pod
May 31 02:28:02.523: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 02:28:02.527: INFO: Number of nodes with available pods: 0
May 31 02:28:02.527: INFO: Node k8s-linuxpool-39082607-0 is running more than one daemon pod
May 31 02:28:03.523: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 02:28:03.526: INFO: Number of nodes with available pods: 3
May 31 02:28:03.526: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
May 31 02:28:03.537: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 02:28:03.540: INFO: Number of nodes with available pods: 2
May 31 02:28:03.540: INFO: Node k8s-linuxpool-39082607-2 is running more than one daemon pod
May 31 02:28:04.543: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 02:28:04.546: INFO: Number of nodes with available pods: 2
May 31 02:28:04.546: INFO: Node k8s-linuxpool-39082607-2 is running more than one daemon pod
May 31 02:28:05.544: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 02:28:05.547: INFO: Number of nodes with available pods: 2
May 31 02:28:05.547: INFO: Node k8s-linuxpool-39082607-2 is running more than one daemon pod
May 31 02:28:06.544: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 02:28:06.546: INFO: Number of nodes with available pods: 2
May 31 02:28:06.546: INFO: Node k8s-linuxpool-39082607-2 is running more than one daemon pod
May 31 02:28:07.543: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 02:28:07.546: INFO: Number of nodes with available pods: 2
May 31 02:28:07.546: INFO: Node k8s-linuxpool-39082607-2 is running more than one daemon pod
May 31 02:28:08.543: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 02:28:08.545: INFO: Number of nodes with available pods: 2
May 31 02:28:08.545: INFO: Node k8s-linuxpool-39082607-2 is running more than one daemon pod
May 31 02:28:09.544: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 02:28:09.547: INFO: Number of nodes with available pods: 2
May 31 02:28:09.547: INFO: Node k8s-linuxpool-39082607-2 is running more than one daemon pod
May 31 02:28:10.543: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 02:28:10.546: INFO: Number of nodes with available pods: 2
May 31 02:28:10.546: INFO: Node k8s-linuxpool-39082607-2 is running more than one daemon pod
May 31 02:28:11.543: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 02:28:11.546: INFO: Number of nodes with available pods: 2
May 31 02:28:11.546: INFO: Node k8s-linuxpool-39082607-2 is running more than one daemon pod
May 31 02:28:12.543: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 02:28:12.547: INFO: Number of nodes with available pods: 2
May 31 02:28:12.547: INFO: Node k8s-linuxpool-39082607-2 is running more than one daemon pod
May 31 02:28:13.543: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 02:28:13.547: INFO: Number of nodes with available pods: 2
May 31 02:28:13.547: INFO: Node k8s-linuxpool-39082607-2 is running more than one daemon pod
May 31 02:28:14.550: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 02:28:14.554: INFO: Number of nodes with available pods: 2
May 31 02:28:14.555: INFO: Node k8s-linuxpool-39082607-2 is running more than one daemon pod
May 31 02:28:15.549: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 02:28:15.551: INFO: Number of nodes with available pods: 2
May 31 02:28:15.552: INFO: Node k8s-linuxpool-39082607-2 is running more than one daemon pod
May 31 02:28:16.543: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 02:28:16.546: INFO: Number of nodes with available pods: 2
May 31 02:28:16.546: INFO: Node k8s-linuxpool-39082607-2 is running more than one daemon pod
May 31 02:28:17.543: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 02:28:17.546: INFO: Number of nodes with available pods: 2
May 31 02:28:17.546: INFO: Node k8s-linuxpool-39082607-2 is running more than one daemon pod
May 31 02:28:18.543: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 02:28:18.547: INFO: Number of nodes with available pods: 3
May 31 02:28:18.547: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-zqt2t, will wait for the garbage collector to delete the pods
May 31 02:28:18.607: INFO: Deleting DaemonSet.extensions daemon-set took: 5.94019ms
May 31 02:28:18.707: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.185223ms
May 31 02:28:27.710: INFO: Number of nodes with available pods: 0
May 31 02:28:27.710: INFO: Number of running nodes: 0, number of available pods: 0
May 31 02:28:27.713: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-zqt2t/daemonsets","resourceVersion":"4109"},"items":null}

May 31 02:28:27.715: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-zqt2t/pods","resourceVersion":"4109"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:28:27.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-zqt2t" for this suite.
May 31 02:28:33.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:28:33.802: INFO: namespace: e2e-tests-daemonsets-zqt2t, resource: bindings, ignored listing per whitelist
May 31 02:28:33.811: INFO: namespace e2e-tests-daemonsets-zqt2t deletion completed in 6.083989896s

• [SLOW TEST:33.388 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:28:33.812: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
May 31 02:28:33.899: INFO: Waiting up to 5m0s for pod "pod-c98f6c77-834b-11e9-949c-223764f7eae1" in namespace "e2e-tests-emptydir-2x4p5" to be "success or failure"
May 31 02:28:33.903: INFO: Pod "pod-c98f6c77-834b-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.97736ms
May 31 02:28:35.906: INFO: Pod "pod-c98f6c77-834b-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007018727s
May 31 02:28:37.908: INFO: Pod "pod-c98f6c77-834b-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009504776s
STEP: Saw pod success
May 31 02:28:37.909: INFO: Pod "pod-c98f6c77-834b-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 02:28:37.911: INFO: Trying to get logs from node k8s-linuxpool-39082607-2 pod pod-c98f6c77-834b-11e9-949c-223764f7eae1 container test-container: <nil>
STEP: delete the pod
May 31 02:28:37.928: INFO: Waiting for pod pod-c98f6c77-834b-11e9-949c-223764f7eae1 to disappear
May 31 02:28:37.930: INFO: Pod pod-c98f6c77-834b-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:28:37.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-2x4p5" for this suite.
May 31 02:28:43.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:28:43.959: INFO: namespace: e2e-tests-emptydir-2x4p5, resource: bindings, ignored listing per whitelist
May 31 02:28:44.051: INFO: namespace e2e-tests-emptydir-2x4p5 deletion completed in 6.118360369s

• [SLOW TEST:10.240 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:28:44.052: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 31 02:28:44.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 version --client'
May 31 02:28:44.198: INFO: stderr: ""
May 31 02:28:44.198: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.6\", GitCommit:\"abdda3f9fefa29172298a2e42f5102e777a8ec25\", GitTreeState:\"clean\", BuildDate:\"2019-05-08T13:53:53Z\", GoVersion:\"go1.11.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
May 31 02:28:44.199: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 create -f - --namespace=e2e-tests-kubectl-kbfb6'
May 31 02:28:44.851: INFO: stderr: ""
May 31 02:28:44.852: INFO: stdout: "replicationcontroller/redis-master created\n"
May 31 02:28:44.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 create -f - --namespace=e2e-tests-kubectl-kbfb6'
May 31 02:28:45.125: INFO: stderr: ""
May 31 02:28:45.125: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
May 31 02:28:46.128: INFO: Selector matched 1 pods for map[app:redis]
May 31 02:28:46.128: INFO: Found 0 / 1
May 31 02:28:47.129: INFO: Selector matched 1 pods for map[app:redis]
May 31 02:28:47.129: INFO: Found 1 / 1
May 31 02:28:47.129: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 31 02:28:47.135: INFO: Selector matched 1 pods for map[app:redis]
May 31 02:28:47.135: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 31 02:28:47.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 describe pod redis-master-z98hs --namespace=e2e-tests-kubectl-kbfb6'
May 31 02:28:47.299: INFO: stderr: ""
May 31 02:28:47.299: INFO: stdout: "Name:               redis-master-z98hs\nNamespace:          e2e-tests-kubectl-kbfb6\nPriority:           0\nPriorityClassName:  <none>\nNode:               k8s-linuxpool-39082607-0/10.240.0.4\nStart Time:         Fri, 31 May 2019 02:28:44 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.244.3.22\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://b6f16cffb5c8111a498d434fc5edfffcdb8b2f0577e16ee7eee8b16b657168c2\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Fri, 31 May 2019 02:28:46 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-hrs6q (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-hrs6q:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-hrs6q\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                               Message\n  ----    ------     ----  ----                               -------\n  Normal  Scheduled  3s    default-scheduler                  Successfully assigned e2e-tests-kubectl-kbfb6/redis-master-z98hs to k8s-linuxpool-39082607-0\n  Normal  Pulled     1s    kubelet, k8s-linuxpool-39082607-0  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, k8s-linuxpool-39082607-0  Created container\n  Normal  Started    1s    kubelet, k8s-linuxpool-39082607-0  Started container\n"
May 31 02:28:47.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 describe rc redis-master --namespace=e2e-tests-kubectl-kbfb6'
May 31 02:28:47.404: INFO: stderr: ""
May 31 02:28:47.404: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-kbfb6\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-z98hs\n"
May 31 02:28:47.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 describe service redis-master --namespace=e2e-tests-kubectl-kbfb6'
May 31 02:28:47.499: INFO: stderr: ""
May 31 02:28:47.499: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-kbfb6\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.0.20.57\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.244.3.22:6379\nSession Affinity:  None\nEvents:            <none>\n"
May 31 02:28:47.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 describe node k8s-linuxpool-39082607-0'
May 31 02:28:47.605: INFO: stderr: ""
May 31 02:28:47.605: INFO: stdout: "Name:               k8s-linuxpool-39082607-0\nRoles:              agent\nLabels:             agentpool=linuxpool\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=Standard_D2_v2\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=redmond\n                    failure-domain.beta.kubernetes.io/zone=0\n                    kubernetes.azure.com/cluster=rgk8s-70039\n                    kubernetes.io/hostname=k8s-linuxpool-39082607-0\n                    kubernetes.io/role=agent\n                    node-role.kubernetes.io/agent=\n                    storageprofile=managed\n                    storagetier=Standard_LRS\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"1e:23:04:9e:19:ff\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 10.240.0.4\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Fri, 31 May 2019 02:07:53 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Fri, 31 May 2019 02:28:42 +0000   Fri, 31 May 2019 02:07:48 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Fri, 31 May 2019 02:28:42 +0000   Fri, 31 May 2019 02:07:48 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Fri, 31 May 2019 02:28:42 +0000   Fri, 31 May 2019 02:07:48 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Fri, 31 May 2019 02:28:42 +0000   Fri, 31 May 2019 02:08:44 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.240.0.4\n  Hostname:    k8s-linuxpool-39082607-0\nCapacity:\n attachable-volumes-azure-disk:  8\n cpu:                            2\n ephemeral-storage:              203234980Ki\n hugepages-1Gi:                  0\n hugepages-2Mi:                  0\n memory:                         7137164Ki\n pods:                           110\nAllocatable:\n attachable-volumes-azure-disk:  8\n cpu:                            2\n ephemeral-storage:              187301357258\n hugepages-1Gi:                  0\n hugepages-2Mi:                  0\n memory:                         6369164Ki\n pods:                           110\nSystem Info:\n Machine ID:                 5583dfc2e6084aa78f22f8a0d6399620\n System UUID:                D6A45BB7-5436-9A42-A3AC-952A76D0CAC2\n Boot ID:                    f33bf3c1-8a00-4c02-b2c1-614bdc356b3c\n Kernel Version:             4.15.0-1022-azure\n OS Image:                   Ubuntu 16.04.6 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://3.0.5\n Kubelet Version:            v1.13.6\n Kube-Proxy Version:         v1.13.6\nPodCIDR:                     10.244.3.0/24\nProviderID:                  azure:///subscriptions/751df60b-8fe7-44ff-b2e7-b3a118855ea4/resourceGroups/rgk8s-70039/providers/Microsoft.Compute/virtualMachines/k8s-linuxpool-39082607-0\nNon-terminated Pods:         (6 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  e2e-tests-kubectl-kbfb6    redis-master-z98hs                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         3s\n  heptio-sonobuoy            sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         19m\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-c8cb41e9386c4a37-bvqmw    0 (0%)        0 (0%)      0 (0%)           0 (0%)         18m\n  kube-system                azure-ip-masq-agent-wfzlh                                  50m (2%)      50m (2%)    50Mi (0%)        250Mi (4%)     20m\n  kube-system                kube-flannel-ds-cvbsp                                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         20m\n  kube-system                kube-proxy-b8mdx                                           100m (5%)     0 (0%)      0 (0%)           0 (0%)         20m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                       Requests   Limits\n  --------                       --------   ------\n  cpu                            150m (7%)  50m (2%)\n  memory                         50Mi (0%)  250Mi (4%)\n  ephemeral-storage              0 (0%)     0 (0%)\n  attachable-volumes-azure-disk  0          0\nEvents:\n  Type    Reason                   Age                From                                  Message\n  ----    ------                   ----               ----                                  -------\n  Normal  Starting                 22m                kubelet, k8s-linuxpool-39082607-0     Starting kubelet.\n  Normal  NodeAllocatableEnforced  21m                kubelet, k8s-linuxpool-39082607-0     Updated Node Allocatable limit across pods\n  Normal  NodeHasSufficientPID     21m (x7 over 21m)  kubelet, k8s-linuxpool-39082607-0     Node k8s-linuxpool-39082607-0 status is now: NodeHasSufficientPID\n  Normal  NodeHasSufficientMemory  21m (x8 over 21m)  kubelet, k8s-linuxpool-39082607-0     Node k8s-linuxpool-39082607-0 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    21m (x8 over 21m)  kubelet, k8s-linuxpool-39082607-0     Node k8s-linuxpool-39082607-0 status is now: NodeHasNoDiskPressure\n  Normal  Starting                 20m                kube-proxy, k8s-linuxpool-39082607-0  Starting kube-proxy.\n"
May 31 02:28:47.606: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 describe namespace e2e-tests-kubectl-kbfb6'
May 31 02:28:47.706: INFO: stderr: ""
May 31 02:28:47.706: INFO: stdout: "Name:         e2e-tests-kubectl-kbfb6\nLabels:       e2e-framework=kubectl\n              e2e-run=41fbed49-8349-11e9-949c-223764f7eae1\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:28:47.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kbfb6" for this suite.
May 31 02:29:09.720: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:29:09.757: INFO: namespace: e2e-tests-kubectl-kbfb6, resource: bindings, ignored listing per whitelist
May 31 02:29:09.793: INFO: namespace e2e-tests-kubectl-kbfb6 deletion completed in 22.080696355s

• [SLOW TEST:25.741 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:29:09.793: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
May 31 02:29:09.869: INFO: Waiting up to 5m0s for pod "downward-api-df007545-834b-11e9-949c-223764f7eae1" in namespace "e2e-tests-downward-api-lk9l4" to be "success or failure"
May 31 02:29:09.872: INFO: Pod "downward-api-df007545-834b-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.929944ms
May 31 02:29:11.874: INFO: Pod "downward-api-df007545-834b-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005501443s
May 31 02:29:13.879: INFO: Pod "downward-api-df007545-834b-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010142066s
STEP: Saw pod success
May 31 02:29:13.879: INFO: Pod "downward-api-df007545-834b-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 02:29:13.882: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod downward-api-df007545-834b-11e9-949c-223764f7eae1 container dapi-container: <nil>
STEP: delete the pod
May 31 02:29:13.918: INFO: Waiting for pod downward-api-df007545-834b-11e9-949c-223764f7eae1 to disappear
May 31 02:29:13.930: INFO: Pod downward-api-df007545-834b-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:29:13.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-lk9l4" for this suite.
May 31 02:29:19.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:29:20.013: INFO: namespace: e2e-tests-downward-api-lk9l4, resource: bindings, ignored listing per whitelist
May 31 02:29:20.041: INFO: namespace e2e-tests-downward-api-lk9l4 deletion completed in 6.104479783s

• [SLOW TEST:10.248 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:29:20.044: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 31 02:29:20.118: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-4xv9m'
May 31 02:29:20.231: INFO: stderr: ""
May 31 02:29:20.231: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
May 31 02:29:25.282: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-4xv9m -o json'
May 31 02:29:25.366: INFO: stderr: ""
May 31 02:29:25.366: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-05-31T02:29:20Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-4xv9m\",\n        \"resourceVersion\": \"4324\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-4xv9m/pods/e2e-test-nginx-pod\",\n        \"uid\": \"e52af6a2-834b-11e9-944d-001dd80c001b\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-c2bdj\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"k8s-linuxpool-39082607-0\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-c2bdj\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-c2bdj\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-31T02:29:20Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-31T02:29:22Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-31T02:29:22Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-31T02:29:20Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://2ce016acda674a1cd8a7bea1f1d133ed74b15f9ba8cb097b218ffad19af65480\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-05-31T02:29:21Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.240.0.4\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.3.24\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-05-31T02:29:20Z\"\n    }\n}\n"
STEP: replace the image in the pod
May 31 02:29:25.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 replace -f - --namespace=e2e-tests-kubectl-4xv9m'
May 31 02:29:25.590: INFO: stderr: ""
May 31 02:29:25.590: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
May 31 02:29:25.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-4xv9m'
May 31 02:29:37.743: INFO: stderr: ""
May 31 02:29:37.743: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:29:37.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4xv9m" for this suite.
May 31 02:29:43.760: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:29:43.788: INFO: namespace: e2e-tests-kubectl-4xv9m, resource: bindings, ignored listing per whitelist
May 31 02:29:43.844: INFO: namespace e2e-tests-kubectl-4xv9m deletion completed in 6.092227618s

• [SLOW TEST:23.800 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:29:43.844: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-kgbcl
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 31 02:29:43.993: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 31 02:30:08.094: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.3.26:8080/dial?request=hostName&protocol=http&host=10.244.3.25&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-kgbcl PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 31 02:30:08.094: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
May 31 02:30:08.264: INFO: Waiting for endpoints: map[]
May 31 02:30:08.266: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.3.26:8080/dial?request=hostName&protocol=http&host=10.244.0.25&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-kgbcl PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 31 02:30:08.266: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
May 31 02:30:08.407: INFO: Waiting for endpoints: map[]
May 31 02:30:08.410: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.3.26:8080/dial?request=hostName&protocol=http&host=10.244.1.8&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-kgbcl PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 31 02:30:08.410: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
May 31 02:30:08.541: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:30:08.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-kgbcl" for this suite.
May 31 02:30:30.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:30:30.616: INFO: namespace: e2e-tests-pod-network-test-kgbcl, resource: bindings, ignored listing per whitelist
May 31 02:30:30.632: INFO: namespace e2e-tests-pod-network-test-kgbcl deletion completed in 22.088113353s

• [SLOW TEST:46.788 seconds]
[sig-network] Networking
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:30:30.633: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-0f3216f1-834c-11e9-949c-223764f7eae1
STEP: Creating a pod to test consume secrets
May 31 02:30:30.728: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-0f32768c-834c-11e9-949c-223764f7eae1" in namespace "e2e-tests-projected-ntshb" to be "success or failure"
May 31 02:30:30.734: INFO: Pod "pod-projected-secrets-0f32768c-834c-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.316195ms
May 31 02:30:32.737: INFO: Pod "pod-projected-secrets-0f32768c-834c-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009161912s
May 31 02:30:34.741: INFO: Pod "pod-projected-secrets-0f32768c-834c-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01247673s
STEP: Saw pod success
May 31 02:30:34.741: INFO: Pod "pod-projected-secrets-0f32768c-834c-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 02:30:34.743: INFO: Trying to get logs from node k8s-linuxpool-39082607-2 pod pod-projected-secrets-0f32768c-834c-11e9-949c-223764f7eae1 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 31 02:30:34.756: INFO: Waiting for pod pod-projected-secrets-0f32768c-834c-11e9-949c-223764f7eae1 to disappear
May 31 02:30:34.758: INFO: Pod pod-projected-secrets-0f32768c-834c-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:30:34.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ntshb" for this suite.
May 31 02:30:40.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:30:40.826: INFO: namespace: e2e-tests-projected-ntshb, resource: bindings, ignored listing per whitelist
May 31 02:30:40.850: INFO: namespace e2e-tests-projected-ntshb deletion completed in 6.088967998s

• [SLOW TEST:10.217 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:30:40.850: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
May 31 02:30:40.943: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 02:30:40.947: INFO: Number of nodes with available pods: 0
May 31 02:30:40.947: INFO: Node k8s-linuxpool-39082607-0 is running more than one daemon pod
May 31 02:30:41.950: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 02:30:41.954: INFO: Number of nodes with available pods: 0
May 31 02:30:41.954: INFO: Node k8s-linuxpool-39082607-0 is running more than one daemon pod
May 31 02:30:42.951: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 02:30:42.953: INFO: Number of nodes with available pods: 0
May 31 02:30:42.953: INFO: Node k8s-linuxpool-39082607-0 is running more than one daemon pod
May 31 02:30:43.951: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 02:30:43.954: INFO: Number of nodes with available pods: 3
May 31 02:30:43.954: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
May 31 02:30:43.981: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 02:30:43.990: INFO: Number of nodes with available pods: 3
May 31 02:30:43.990: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-f29dm, will wait for the garbage collector to delete the pods
May 31 02:30:45.057: INFO: Deleting DaemonSet.extensions daemon-set took: 5.222278ms
May 31 02:30:45.158: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.214294ms
May 31 02:30:57.760: INFO: Number of nodes with available pods: 0
May 31 02:30:57.760: INFO: Number of running nodes: 0, number of available pods: 0
May 31 02:30:57.762: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-f29dm/daemonsets","resourceVersion":"4668"},"items":null}

May 31 02:30:57.763: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-f29dm/pods","resourceVersion":"4668"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:30:57.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-f29dm" for this suite.
May 31 02:31:03.788: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:31:03.865: INFO: namespace: e2e-tests-daemonsets-f29dm, resource: bindings, ignored listing per whitelist
May 31 02:31:03.870: INFO: namespace e2e-tests-daemonsets-f29dm deletion completed in 6.090949831s

• [SLOW TEST:23.020 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:31:03.871: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-2305e89b-834c-11e9-949c-223764f7eae1
STEP: Creating a pod to test consume secrets
May 31 02:31:03.995: INFO: Waiting up to 5m0s for pod "pod-secrets-2306573f-834c-11e9-949c-223764f7eae1" in namespace "e2e-tests-secrets-nvnvh" to be "success or failure"
May 31 02:31:04.002: INFO: Pod "pod-secrets-2306573f-834c-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 7.515412ms
May 31 02:31:06.006: INFO: Pod "pod-secrets-2306573f-834c-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011261148s
May 31 02:31:08.009: INFO: Pod "pod-secrets-2306573f-834c-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014157967s
STEP: Saw pod success
May 31 02:31:08.009: INFO: Pod "pod-secrets-2306573f-834c-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 02:31:08.011: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod pod-secrets-2306573f-834c-11e9-949c-223764f7eae1 container secret-volume-test: <nil>
STEP: delete the pod
May 31 02:31:08.026: INFO: Waiting for pod pod-secrets-2306573f-834c-11e9-949c-223764f7eae1 to disappear
May 31 02:31:08.027: INFO: Pod pod-secrets-2306573f-834c-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:31:08.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-nvnvh" for this suite.
May 31 02:31:14.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:31:14.055: INFO: namespace: e2e-tests-secrets-nvnvh, resource: bindings, ignored listing per whitelist
May 31 02:31:14.212: INFO: namespace e2e-tests-secrets-nvnvh deletion completed in 6.181873301s

• [SLOW TEST:10.341 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:31:14.213: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-293a520d-834c-11e9-949c-223764f7eae1
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:31:18.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-kfrxn" for this suite.
May 31 02:31:40.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:31:40.506: INFO: namespace: e2e-tests-configmap-kfrxn, resource: bindings, ignored listing per whitelist
May 31 02:31:40.536: INFO: namespace e2e-tests-configmap-kfrxn deletion completed in 22.099050388s

• [SLOW TEST:26.323 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:31:40.536: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-gt8nc
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 31 02:31:40.621: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 31 02:32:06.693: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.3.30:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-gt8nc PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 31 02:32:06.694: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
May 31 02:32:06.823: INFO: Found all expected endpoints: [netserver-0]
May 31 02:32:06.826: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.1.10:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-gt8nc PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 31 02:32:06.826: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
May 31 02:32:06.951: INFO: Found all expected endpoints: [netserver-1]
May 31 02:32:06.954: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.0.29:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-gt8nc PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 31 02:32:06.954: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
May 31 02:32:07.081: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:32:07.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-gt8nc" for this suite.
May 31 02:32:29.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:32:29.143: INFO: namespace: e2e-tests-pod-network-test-gt8nc, resource: bindings, ignored listing per whitelist
May 31 02:32:29.169: INFO: namespace e2e-tests-pod-network-test-gt8nc deletion completed in 22.084516893s

• [SLOW TEST:48.633 seconds]
[sig-network] Networking
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:32:29.170: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
May 31 02:32:29.254: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 create -f - --namespace=e2e-tests-kubectl-9xfgr'
May 31 02:32:29.465: INFO: stderr: ""
May 31 02:32:29.465: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
May 31 02:32:30.469: INFO: Selector matched 1 pods for map[app:redis]
May 31 02:32:30.469: INFO: Found 0 / 1
May 31 02:32:31.468: INFO: Selector matched 1 pods for map[app:redis]
May 31 02:32:31.468: INFO: Found 0 / 1
May 31 02:32:32.468: INFO: Selector matched 1 pods for map[app:redis]
May 31 02:32:32.468: INFO: Found 1 / 1
May 31 02:32:32.468: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 31 02:32:32.471: INFO: Selector matched 1 pods for map[app:redis]
May 31 02:32:32.471: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
May 31 02:32:32.471: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 logs redis-master-ssr6p redis-master --namespace=e2e-tests-kubectl-9xfgr'
May 31 02:32:32.569: INFO: stderr: ""
May 31 02:32:32.569: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 31 May 02:32:31.223 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 31 May 02:32:31.223 # Server started, Redis version 3.2.12\n1:M 31 May 02:32:31.223 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 31 May 02:32:31.223 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
May 31 02:32:32.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 log redis-master-ssr6p redis-master --namespace=e2e-tests-kubectl-9xfgr --tail=1'
May 31 02:32:32.659: INFO: stderr: ""
May 31 02:32:32.659: INFO: stdout: "1:M 31 May 02:32:31.223 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
May 31 02:32:32.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 log redis-master-ssr6p redis-master --namespace=e2e-tests-kubectl-9xfgr --limit-bytes=1'
May 31 02:32:32.748: INFO: stderr: ""
May 31 02:32:32.748: INFO: stdout: " "
STEP: exposing timestamps
May 31 02:32:32.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 log redis-master-ssr6p redis-master --namespace=e2e-tests-kubectl-9xfgr --tail=1 --timestamps'
May 31 02:32:32.851: INFO: stderr: ""
May 31 02:32:32.851: INFO: stdout: "2019-05-31T02:32:31.223882802Z 1:M 31 May 02:32:31.223 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
May 31 02:32:35.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 log redis-master-ssr6p redis-master --namespace=e2e-tests-kubectl-9xfgr --since=1s'
May 31 02:32:35.453: INFO: stderr: ""
May 31 02:32:35.453: INFO: stdout: ""
May 31 02:32:35.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 log redis-master-ssr6p redis-master --namespace=e2e-tests-kubectl-9xfgr --since=24h'
May 31 02:32:35.553: INFO: stderr: ""
May 31 02:32:35.553: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 31 May 02:32:31.223 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 31 May 02:32:31.223 # Server started, Redis version 3.2.12\n1:M 31 May 02:32:31.223 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 31 May 02:32:31.223 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
May 31 02:32:35.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-9xfgr'
May 31 02:32:35.648: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 31 02:32:35.648: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
May 31 02:32:35.649: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-9xfgr'
May 31 02:32:35.739: INFO: stderr: "No resources found.\n"
May 31 02:32:35.739: INFO: stdout: ""
May 31 02:32:35.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods -l name=nginx --namespace=e2e-tests-kubectl-9xfgr -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 31 02:32:35.830: INFO: stderr: ""
May 31 02:32:35.830: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:32:35.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9xfgr" for this suite.
May 31 02:32:41.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:32:41.894: INFO: namespace: e2e-tests-kubectl-9xfgr, resource: bindings, ignored listing per whitelist
May 31 02:32:41.922: INFO: namespace e2e-tests-kubectl-9xfgr deletion completed in 6.088331126s

• [SLOW TEST:12.753 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:32:41.922: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-5d78b473-834c-11e9-949c-223764f7eae1
STEP: Creating a pod to test consume configMaps
May 31 02:32:42.055: INFO: Waiting up to 5m0s for pod "pod-configmaps-5d7937f5-834c-11e9-949c-223764f7eae1" in namespace "e2e-tests-configmap-dkgpz" to be "success or failure"
May 31 02:32:42.059: INFO: Pod "pod-configmaps-5d7937f5-834c-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.07886ms
May 31 02:32:44.063: INFO: Pod "pod-configmaps-5d7937f5-834c-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00768238s
May 31 02:32:46.067: INFO: Pod "pod-configmaps-5d7937f5-834c-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011727501s
STEP: Saw pod success
May 31 02:32:46.067: INFO: Pod "pod-configmaps-5d7937f5-834c-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 02:32:46.071: INFO: Trying to get logs from node k8s-linuxpool-39082607-2 pod pod-configmaps-5d7937f5-834c-11e9-949c-223764f7eae1 container configmap-volume-test: <nil>
STEP: delete the pod
May 31 02:32:46.091: INFO: Waiting for pod pod-configmaps-5d7937f5-834c-11e9-949c-223764f7eae1 to disappear
May 31 02:32:46.093: INFO: Pod pod-configmaps-5d7937f5-834c-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:32:46.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-dkgpz" for this suite.
May 31 02:32:52.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:32:52.180: INFO: namespace: e2e-tests-configmap-dkgpz, resource: bindings, ignored listing per whitelist
May 31 02:32:52.201: INFO: namespace e2e-tests-configmap-dkgpz deletion completed in 6.105153118s

• [SLOW TEST:10.278 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:32:52.201: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
May 31 02:32:52.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 create -f - --namespace=e2e-tests-kubectl-rp2wl'
May 31 02:32:52.480: INFO: stderr: ""
May 31 02:32:52.480: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
May 31 02:32:53.483: INFO: Selector matched 1 pods for map[app:redis]
May 31 02:32:53.483: INFO: Found 0 / 1
May 31 02:32:54.485: INFO: Selector matched 1 pods for map[app:redis]
May 31 02:32:54.485: INFO: Found 0 / 1
May 31 02:32:55.483: INFO: Selector matched 1 pods for map[app:redis]
May 31 02:32:55.483: INFO: Found 1 / 1
May 31 02:32:55.483: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
May 31 02:32:55.486: INFO: Selector matched 1 pods for map[app:redis]
May 31 02:32:55.487: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 31 02:32:55.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 patch pod redis-master-ffxsx --namespace=e2e-tests-kubectl-rp2wl -p {"metadata":{"annotations":{"x":"y"}}}'
May 31 02:32:55.597: INFO: stderr: ""
May 31 02:32:55.597: INFO: stdout: "pod/redis-master-ffxsx patched\n"
STEP: checking annotations
May 31 02:32:55.600: INFO: Selector matched 1 pods for map[app:redis]
May 31 02:32:55.600: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:32:55.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rp2wl" for this suite.
May 31 02:33:17.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:33:17.642: INFO: namespace: e2e-tests-kubectl-rp2wl, resource: bindings, ignored listing per whitelist
May 31 02:33:17.691: INFO: namespace e2e-tests-kubectl-rp2wl deletion completed in 22.088689988s

• [SLOW TEST:25.490 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:33:17.693: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-fml9p/secret-test-72c53180-834c-11e9-949c-223764f7eae1
STEP: Creating a pod to test consume secrets
May 31 02:33:17.789: INFO: Waiting up to 5m0s for pod "pod-configmaps-72c5c289-834c-11e9-949c-223764f7eae1" in namespace "e2e-tests-secrets-fml9p" to be "success or failure"
May 31 02:33:17.801: INFO: Pod "pod-configmaps-72c5c289-834c-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 12.802389ms
May 31 02:33:19.804: INFO: Pod "pod-configmaps-72c5c289-834c-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015613037s
May 31 02:33:21.807: INFO: Pod "pod-configmaps-72c5c289-834c-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018161077s
STEP: Saw pod success
May 31 02:33:21.807: INFO: Pod "pod-configmaps-72c5c289-834c-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 02:33:21.809: INFO: Trying to get logs from node k8s-linuxpool-39082607-2 pod pod-configmaps-72c5c289-834c-11e9-949c-223764f7eae1 container env-test: <nil>
STEP: delete the pod
May 31 02:33:21.827: INFO: Waiting for pod pod-configmaps-72c5c289-834c-11e9-949c-223764f7eae1 to disappear
May 31 02:33:21.829: INFO: Pod pod-configmaps-72c5c289-834c-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:33:21.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-fml9p" for this suite.
May 31 02:33:27.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:33:27.882: INFO: namespace: e2e-tests-secrets-fml9p, resource: bindings, ignored listing per whitelist
May 31 02:33:27.945: INFO: namespace e2e-tests-secrets-fml9p deletion completed in 6.113078257s

• [SLOW TEST:10.252 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:33:27.947: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 31 02:33:48.041: INFO: Container started at 2019-05-31 02:33:30 +0000 UTC, pod became ready at 2019-05-31 02:33:46 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:33:48.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-rdrzn" for this suite.
May 31 02:34:10.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:34:10.076: INFO: namespace: e2e-tests-container-probe-rdrzn, resource: bindings, ignored listing per whitelist
May 31 02:34:10.125: INFO: namespace e2e-tests-container-probe-rdrzn deletion completed in 22.081877885s

• [SLOW TEST:42.179 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:34:10.126: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-9210f6d2-834c-11e9-949c-223764f7eae1
STEP: Creating a pod to test consume secrets
May 31 02:34:10.293: INFO: Waiting up to 5m0s for pod "pod-secrets-92117d84-834c-11e9-949c-223764f7eae1" in namespace "e2e-tests-secrets-vngn2" to be "success or failure"
May 31 02:34:10.300: INFO: Pod "pod-secrets-92117d84-834c-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.903624ms
May 31 02:34:12.303: INFO: Pod "pod-secrets-92117d84-834c-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009721781s
May 31 02:34:14.307: INFO: Pod "pod-secrets-92117d84-834c-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01408534s
STEP: Saw pod success
May 31 02:34:14.307: INFO: Pod "pod-secrets-92117d84-834c-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 02:34:14.310: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod pod-secrets-92117d84-834c-11e9-949c-223764f7eae1 container secret-env-test: <nil>
STEP: delete the pod
May 31 02:34:14.328: INFO: Waiting for pod pod-secrets-92117d84-834c-11e9-949c-223764f7eae1 to disappear
May 31 02:34:14.331: INFO: Pod pod-secrets-92117d84-834c-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:34:14.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-vngn2" for this suite.
May 31 02:34:20.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:34:20.375: INFO: namespace: e2e-tests-secrets-vngn2, resource: bindings, ignored listing per whitelist
May 31 02:34:20.426: INFO: namespace e2e-tests-secrets-vngn2 deletion completed in 6.090868032s

• [SLOW TEST:10.299 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:34:20.427: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-49qwv
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 31 02:34:20.496: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 31 02:34:44.570: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.3.37:8080/dial?request=hostName&protocol=udp&host=10.244.3.36&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-49qwv PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 31 02:34:44.571: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
May 31 02:34:44.696: INFO: Waiting for endpoints: map[]
May 31 02:34:44.699: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.3.37:8080/dial?request=hostName&protocol=udp&host=10.244.1.11&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-49qwv PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 31 02:34:44.699: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
May 31 02:34:44.848: INFO: Waiting for endpoints: map[]
May 31 02:34:44.851: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.3.37:8080/dial?request=hostName&protocol=udp&host=10.244.0.32&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-49qwv PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 31 02:34:44.851: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
May 31 02:34:45.014: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:34:45.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-49qwv" for this suite.
May 31 02:35:07.033: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:35:07.101: INFO: namespace: e2e-tests-pod-network-test-49qwv, resource: bindings, ignored listing per whitelist
May 31 02:35:07.109: INFO: namespace e2e-tests-pod-network-test-49qwv deletion completed in 22.092031087s

• [SLOW TEST:46.683 seconds]
[sig-network] Networking
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:35:07.111: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
May 31 02:35:07.196: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-52wn6,SelfLink:/api/v1/namespaces/e2e-tests-watch-52wn6/configmaps/e2e-watch-test-configmap-a,UID:b3fc9e3a-834c-11e9-944d-001dd80c001b,ResourceVersion:5494,Generation:0,CreationTimestamp:2019-05-31 02:35:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 31 02:35:07.196: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-52wn6,SelfLink:/api/v1/namespaces/e2e-tests-watch-52wn6/configmaps/e2e-watch-test-configmap-a,UID:b3fc9e3a-834c-11e9-944d-001dd80c001b,ResourceVersion:5494,Generation:0,CreationTimestamp:2019-05-31 02:35:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
May 31 02:35:17.202: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-52wn6,SelfLink:/api/v1/namespaces/e2e-tests-watch-52wn6/configmaps/e2e-watch-test-configmap-a,UID:b3fc9e3a-834c-11e9-944d-001dd80c001b,ResourceVersion:5514,Generation:0,CreationTimestamp:2019-05-31 02:35:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
May 31 02:35:17.203: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-52wn6,SelfLink:/api/v1/namespaces/e2e-tests-watch-52wn6/configmaps/e2e-watch-test-configmap-a,UID:b3fc9e3a-834c-11e9-944d-001dd80c001b,ResourceVersion:5514,Generation:0,CreationTimestamp:2019-05-31 02:35:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
May 31 02:35:27.208: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-52wn6,SelfLink:/api/v1/namespaces/e2e-tests-watch-52wn6/configmaps/e2e-watch-test-configmap-a,UID:b3fc9e3a-834c-11e9-944d-001dd80c001b,ResourceVersion:5530,Generation:0,CreationTimestamp:2019-05-31 02:35:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 31 02:35:27.208: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-52wn6,SelfLink:/api/v1/namespaces/e2e-tests-watch-52wn6/configmaps/e2e-watch-test-configmap-a,UID:b3fc9e3a-834c-11e9-944d-001dd80c001b,ResourceVersion:5530,Generation:0,CreationTimestamp:2019-05-31 02:35:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
May 31 02:35:37.213: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-52wn6,SelfLink:/api/v1/namespaces/e2e-tests-watch-52wn6/configmaps/e2e-watch-test-configmap-a,UID:b3fc9e3a-834c-11e9-944d-001dd80c001b,ResourceVersion:5546,Generation:0,CreationTimestamp:2019-05-31 02:35:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 31 02:35:37.213: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-52wn6,SelfLink:/api/v1/namespaces/e2e-tests-watch-52wn6/configmaps/e2e-watch-test-configmap-a,UID:b3fc9e3a-834c-11e9-944d-001dd80c001b,ResourceVersion:5546,Generation:0,CreationTimestamp:2019-05-31 02:35:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
May 31 02:35:47.218: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-52wn6,SelfLink:/api/v1/namespaces/e2e-tests-watch-52wn6/configmaps/e2e-watch-test-configmap-b,UID:cbd73cf6-834c-11e9-944d-001dd80c001b,ResourceVersion:5561,Generation:0,CreationTimestamp:2019-05-31 02:35:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 31 02:35:47.218: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-52wn6,SelfLink:/api/v1/namespaces/e2e-tests-watch-52wn6/configmaps/e2e-watch-test-configmap-b,UID:cbd73cf6-834c-11e9-944d-001dd80c001b,ResourceVersion:5561,Generation:0,CreationTimestamp:2019-05-31 02:35:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
May 31 02:35:57.223: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-52wn6,SelfLink:/api/v1/namespaces/e2e-tests-watch-52wn6/configmaps/e2e-watch-test-configmap-b,UID:cbd73cf6-834c-11e9-944d-001dd80c001b,ResourceVersion:5577,Generation:0,CreationTimestamp:2019-05-31 02:35:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 31 02:35:57.224: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-52wn6,SelfLink:/api/v1/namespaces/e2e-tests-watch-52wn6/configmaps/e2e-watch-test-configmap-b,UID:cbd73cf6-834c-11e9-944d-001dd80c001b,ResourceVersion:5577,Generation:0,CreationTimestamp:2019-05-31 02:35:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:36:07.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-52wn6" for this suite.
May 31 02:36:13.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:36:13.291: INFO: namespace: e2e-tests-watch-52wn6, resource: bindings, ignored listing per whitelist
May 31 02:36:13.310: INFO: namespace e2e-tests-watch-52wn6 deletion completed in 6.08233319s

• [SLOW TEST:66.199 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:36:13.310: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-r6vnc/configmap-test-db6f6118-834c-11e9-949c-223764f7eae1
STEP: Creating a pod to test consume configMaps
May 31 02:36:13.387: INFO: Waiting up to 5m0s for pod "pod-configmaps-db6ffdec-834c-11e9-949c-223764f7eae1" in namespace "e2e-tests-configmap-r6vnc" to be "success or failure"
May 31 02:36:13.389: INFO: Pod "pod-configmaps-db6ffdec-834c-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.29394ms
May 31 02:36:15.393: INFO: Pod "pod-configmaps-db6ffdec-834c-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005578277s
May 31 02:36:17.396: INFO: Pod "pod-configmaps-db6ffdec-834c-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008541189s
STEP: Saw pod success
May 31 02:36:17.396: INFO: Pod "pod-configmaps-db6ffdec-834c-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 02:36:17.398: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod pod-configmaps-db6ffdec-834c-11e9-949c-223764f7eae1 container env-test: <nil>
STEP: delete the pod
May 31 02:36:17.414: INFO: Waiting for pod pod-configmaps-db6ffdec-834c-11e9-949c-223764f7eae1 to disappear
May 31 02:36:17.417: INFO: Pod pod-configmaps-db6ffdec-834c-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:36:17.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-r6vnc" for this suite.
May 31 02:36:23.428: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:36:23.488: INFO: namespace: e2e-tests-configmap-r6vnc, resource: bindings, ignored listing per whitelist
May 31 02:36:23.497: INFO: namespace e2e-tests-configmap-r6vnc deletion completed in 6.076979204s

• [SLOW TEST:10.186 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:36:23.498: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0531 02:36:33.623339      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 31 02:36:33.623: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:36:33.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-nz9q9" for this suite.
May 31 02:36:39.635: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:36:39.670: INFO: namespace: e2e-tests-gc-nz9q9, resource: bindings, ignored listing per whitelist
May 31 02:36:39.709: INFO: namespace e2e-tests-gc-nz9q9 deletion completed in 6.081655026s

• [SLOW TEST:16.211 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:36:39.710: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
May 31 02:36:39.773: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 31 02:36:39.781: INFO: Waiting for terminating namespaces to be deleted...
May 31 02:36:39.783: INFO: 
Logging pods the kubelet thinks is on node k8s-linuxpool-39082607-0 before test
May 31 02:36:39.789: INFO: kube-proxy-b8mdx from kube-system started at 2019-05-31 02:08:18 +0000 UTC (1 container statuses recorded)
May 31 02:36:39.789: INFO: 	Container kube-proxy ready: true, restart count 0
May 31 02:36:39.789: INFO: sonobuoy from heptio-sonobuoy started at 2019-05-31 02:09:42 +0000 UTC (1 container statuses recorded)
May 31 02:36:39.789: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 31 02:36:39.789: INFO: kube-flannel-ds-cvbsp from kube-system started at 2019-05-31 02:08:14 +0000 UTC (2 container statuses recorded)
May 31 02:36:39.789: INFO: 	Container install-cni ready: true, restart count 0
May 31 02:36:39.789: INFO: 	Container kube-flannel ready: true, restart count 0
May 31 02:36:39.789: INFO: azure-ip-masq-agent-wfzlh from kube-system started at 2019-05-31 02:08:17 +0000 UTC (1 container statuses recorded)
May 31 02:36:39.789: INFO: 	Container azure-ip-masq-agent ready: true, restart count 0
May 31 02:36:39.790: INFO: sonobuoy-systemd-logs-daemon-set-c8cb41e9386c4a37-bvqmw from heptio-sonobuoy started at 2019-05-31 02:09:50 +0000 UTC (2 container statuses recorded)
May 31 02:36:39.790: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
May 31 02:36:39.790: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 31 02:36:39.790: INFO: 
Logging pods the kubelet thinks is on node k8s-linuxpool-39082607-1 before test
May 31 02:36:39.796: INFO: kube-flannel-ds-46vq7 from kube-system started at 2019-05-31 02:08:14 +0000 UTC (2 container statuses recorded)
May 31 02:36:39.797: INFO: 	Container install-cni ready: true, restart count 0
May 31 02:36:39.797: INFO: 	Container kube-flannel ready: true, restart count 0
May 31 02:36:39.797: INFO: azure-ip-masq-agent-kk6xv from kube-system started at 2019-05-31 02:08:17 +0000 UTC (1 container statuses recorded)
May 31 02:36:39.797: INFO: 	Container azure-ip-masq-agent ready: true, restart count 0
May 31 02:36:39.797: INFO: kube-proxy-vp4nc from kube-system started at 2019-05-31 02:08:17 +0000 UTC (1 container statuses recorded)
May 31 02:36:39.797: INFO: 	Container kube-proxy ready: true, restart count 0
May 31 02:36:39.797: INFO: kubernetes-dashboard-7947fffdf5-8hd5w from kube-system started at 2019-05-31 02:08:34 +0000 UTC (1 container statuses recorded)
May 31 02:36:39.797: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 31 02:36:39.797: INFO: sonobuoy-systemd-logs-daemon-set-c8cb41e9386c4a37-288hm from heptio-sonobuoy started at 2019-05-31 02:09:50 +0000 UTC (2 container statuses recorded)
May 31 02:36:39.797: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
May 31 02:36:39.798: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 31 02:36:39.798: INFO: 
Logging pods the kubelet thinks is on node k8s-linuxpool-39082607-2 before test
May 31 02:36:39.803: INFO: coredns-59b998c9dd-g7djk from kube-system started at 2019-05-31 02:08:18 +0000 UTC (1 container statuses recorded)
May 31 02:36:39.803: INFO: 	Container coredns ready: true, restart count 0
May 31 02:36:39.803: INFO: metrics-server-69b44566d5-rt27d from kube-system started at 2019-05-31 02:08:34 +0000 UTC (1 container statuses recorded)
May 31 02:36:39.803: INFO: 	Container metrics-server ready: true, restart count 0
May 31 02:36:39.803: INFO: sonobuoy-systemd-logs-daemon-set-c8cb41e9386c4a37-cbt95 from heptio-sonobuoy started at 2019-05-31 02:09:50 +0000 UTC (2 container statuses recorded)
May 31 02:36:39.803: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
May 31 02:36:39.804: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 31 02:36:39.804: INFO: kube-flannel-ds-k5cj4 from kube-system started at 2019-05-31 02:08:14 +0000 UTC (2 container statuses recorded)
May 31 02:36:39.804: INFO: 	Container install-cni ready: true, restart count 0
May 31 02:36:39.804: INFO: 	Container kube-flannel ready: true, restart count 0
May 31 02:36:39.804: INFO: azure-ip-masq-agent-4gmjm from kube-system started at 2019-05-31 02:08:17 +0000 UTC (1 container statuses recorded)
May 31 02:36:39.804: INFO: 	Container azure-ip-masq-agent ready: true, restart count 0
May 31 02:36:39.804: INFO: kube-proxy-cq296 from kube-system started at 2019-05-31 02:08:18 +0000 UTC (1 container statuses recorded)
May 31 02:36:39.804: INFO: 	Container kube-proxy ready: true, restart count 0
May 31 02:36:39.804: INFO: tiller-deploy-74b7fb5bb9-w5db4 from kube-system started at 2019-05-31 02:08:34 +0000 UTC (1 container statuses recorded)
May 31 02:36:39.804: INFO: 	Container tiller ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15a3a3fc4141dfb5], Reason = [FailedScheduling], Message = [0/4 nodes are available: 4 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:36:40.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-xnzzm" for this suite.
May 31 02:36:46.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:36:46.888: INFO: namespace: e2e-tests-sched-pred-xnzzm, resource: bindings, ignored listing per whitelist
May 31 02:36:46.919: INFO: namespace e2e-tests-sched-pred-xnzzm deletion completed in 6.088616748s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.209 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:36:46.919: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
May 31 02:36:46.995: INFO: Waiting up to 5m0s for pod "downward-api-ef782d31-834c-11e9-949c-223764f7eae1" in namespace "e2e-tests-downward-api-5m5v9" to be "success or failure"
May 31 02:36:46.998: INFO: Pod "downward-api-ef782d31-834c-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.413259ms
May 31 02:36:49.001: INFO: Pod "downward-api-ef782d31-834c-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006244077s
May 31 02:36:51.005: INFO: Pod "downward-api-ef782d31-834c-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009938192s
STEP: Saw pod success
May 31 02:36:51.005: INFO: Pod "downward-api-ef782d31-834c-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 02:36:51.008: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod downward-api-ef782d31-834c-11e9-949c-223764f7eae1 container dapi-container: <nil>
STEP: delete the pod
May 31 02:36:51.025: INFO: Waiting for pod downward-api-ef782d31-834c-11e9-949c-223764f7eae1 to disappear
May 31 02:36:51.029: INFO: Pod downward-api-ef782d31-834c-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:36:51.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5m5v9" for this suite.
May 31 02:36:57.040: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:36:57.117: INFO: namespace: e2e-tests-downward-api-5m5v9, resource: bindings, ignored listing per whitelist
May 31 02:36:57.126: INFO: namespace e2e-tests-downward-api-5m5v9 deletion completed in 6.094265568s

• [SLOW TEST:10.207 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:36:57.129: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:36:57.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-xpnhw" for this suite.
May 31 02:37:03.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:37:03.236: INFO: namespace: e2e-tests-services-xpnhw, resource: bindings, ignored listing per whitelist
May 31 02:37:03.295: INFO: namespace e2e-tests-services-xpnhw deletion completed in 6.088775909s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:6.166 seconds]
[sig-network] Services
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:37:03.295: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
May 31 02:37:03.361: INFO: Waiting up to 5m0s for pod "var-expansion-f9398627-834c-11e9-949c-223764f7eae1" in namespace "e2e-tests-var-expansion-728fc" to be "success or failure"
May 31 02:37:03.365: INFO: Pod "var-expansion-f9398627-834c-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.744781ms
May 31 02:37:05.368: INFO: Pod "var-expansion-f9398627-834c-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007672757s
May 31 02:37:07.371: INFO: Pod "var-expansion-f9398627-834c-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010875221s
STEP: Saw pod success
May 31 02:37:07.372: INFO: Pod "var-expansion-f9398627-834c-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 02:37:07.374: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod var-expansion-f9398627-834c-11e9-949c-223764f7eae1 container dapi-container: <nil>
STEP: delete the pod
May 31 02:37:07.396: INFO: Waiting for pod var-expansion-f9398627-834c-11e9-949c-223764f7eae1 to disappear
May 31 02:37:07.398: INFO: Pod var-expansion-f9398627-834c-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:37:07.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-728fc" for this suite.
May 31 02:37:13.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:37:13.440: INFO: namespace: e2e-tests-var-expansion-728fc, resource: bindings, ignored listing per whitelist
May 31 02:37:13.481: INFO: namespace e2e-tests-var-expansion-728fc deletion completed in 6.079787788s

• [SLOW TEST:10.186 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:37:13.481: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
May 31 02:37:18.085: INFO: Successfully updated pod "annotationupdateff4c1642-834c-11e9-949c-223764f7eae1"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:37:20.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pb2fb" for this suite.
May 31 02:37:42.149: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:37:42.194: INFO: namespace: e2e-tests-projected-pb2fb, resource: bindings, ignored listing per whitelist
May 31 02:37:42.231: INFO: namespace e2e-tests-projected-pb2fb deletion completed in 22.094367212s

• [SLOW TEST:28.750 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:37:42.233: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
May 31 02:37:46.326: INFO: Pod pod-hostip-1070eeb7-834d-11e9-949c-223764f7eae1 has hostIP: 10.240.0.4
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:37:46.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-f9jpd" for this suite.
May 31 02:38:08.337: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:38:08.367: INFO: namespace: e2e-tests-pods-f9jpd, resource: bindings, ignored listing per whitelist
May 31 02:38:08.405: INFO: namespace e2e-tests-pods-f9jpd deletion completed in 22.076685701s

• [SLOW TEST:26.172 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:38:08.405: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 31 02:38:08.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-g7lkm'
May 31 02:38:08.781: INFO: stderr: ""
May 31 02:38:08.781: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
May 31 02:38:08.784: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-g7lkm'
May 31 02:38:15.527: INFO: stderr: ""
May 31 02:38:15.527: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:38:15.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-g7lkm" for this suite.
May 31 02:38:21.539: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:38:21.570: INFO: namespace: e2e-tests-kubectl-g7lkm, resource: bindings, ignored listing per whitelist
May 31 02:38:21.620: INFO: namespace e2e-tests-kubectl-g7lkm deletion completed in 6.089969804s

• [SLOW TEST:13.215 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:38:21.620: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-27ec56d7-834d-11e9-949c-223764f7eae1
STEP: Creating a pod to test consume configMaps
May 31 02:38:21.711: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-27ecb8ee-834d-11e9-949c-223764f7eae1" in namespace "e2e-tests-projected-mgfv4" to be "success or failure"
May 31 02:38:21.716: INFO: Pod "pod-projected-configmaps-27ecb8ee-834d-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.205971ms
May 31 02:38:23.719: INFO: Pod "pod-projected-configmaps-27ecb8ee-834d-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007206019s
May 31 02:38:25.721: INFO: Pod "pod-projected-configmaps-27ecb8ee-834d-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01003945s
STEP: Saw pod success
May 31 02:38:25.721: INFO: Pod "pod-projected-configmaps-27ecb8ee-834d-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 02:38:25.724: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod pod-projected-configmaps-27ecb8ee-834d-11e9-949c-223764f7eae1 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 31 02:38:25.737: INFO: Waiting for pod pod-projected-configmaps-27ecb8ee-834d-11e9-949c-223764f7eae1 to disappear
May 31 02:38:25.739: INFO: Pod pod-projected-configmaps-27ecb8ee-834d-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:38:25.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mgfv4" for this suite.
May 31 02:38:31.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:38:31.796: INFO: namespace: e2e-tests-projected-mgfv4, resource: bindings, ignored listing per whitelist
May 31 02:38:31.838: INFO: namespace e2e-tests-projected-mgfv4 deletion completed in 6.094072943s

• [SLOW TEST:10.218 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:38:31.839: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
May 31 02:38:32.092: INFO: Pod name wrapped-volume-race-2e1afa0d-834d-11e9-949c-223764f7eae1: Found 0 pods out of 5
May 31 02:38:37.098: INFO: Pod name wrapped-volume-race-2e1afa0d-834d-11e9-949c-223764f7eae1: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-2e1afa0d-834d-11e9-949c-223764f7eae1 in namespace e2e-tests-emptydir-wrapper-jztmw, will wait for the garbage collector to delete the pods
May 31 02:40:19.180: INFO: Deleting ReplicationController wrapped-volume-race-2e1afa0d-834d-11e9-949c-223764f7eae1 took: 6.300604ms
May 31 02:40:19.281: INFO: Terminating ReplicationController wrapped-volume-race-2e1afa0d-834d-11e9-949c-223764f7eae1 pods took: 100.310951ms
STEP: Creating RC which spawns configmap-volume pods
May 31 02:40:57.795: INFO: Pod name wrapped-volume-race-84f3fc9d-834d-11e9-949c-223764f7eae1: Found 0 pods out of 5
May 31 02:41:02.802: INFO: Pod name wrapped-volume-race-84f3fc9d-834d-11e9-949c-223764f7eae1: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-84f3fc9d-834d-11e9-949c-223764f7eae1 in namespace e2e-tests-emptydir-wrapper-jztmw, will wait for the garbage collector to delete the pods
May 31 02:42:48.892: INFO: Deleting ReplicationController wrapped-volume-race-84f3fc9d-834d-11e9-949c-223764f7eae1 took: 5.484889ms
May 31 02:42:48.993: INFO: Terminating ReplicationController wrapped-volume-race-84f3fc9d-834d-11e9-949c-223764f7eae1 pods took: 100.15921ms
STEP: Creating RC which spawns configmap-volume pods
May 31 02:43:28.706: INFO: Pod name wrapped-volume-race-dee753fc-834d-11e9-949c-223764f7eae1: Found 0 pods out of 5
May 31 02:43:33.712: INFO: Pod name wrapped-volume-race-dee753fc-834d-11e9-949c-223764f7eae1: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-dee753fc-834d-11e9-949c-223764f7eae1 in namespace e2e-tests-emptydir-wrapper-jztmw, will wait for the garbage collector to delete the pods
May 31 02:45:49.789: INFO: Deleting ReplicationController wrapped-volume-race-dee753fc-834d-11e9-949c-223764f7eae1 took: 7.237214ms
May 31 02:45:49.889: INFO: Terminating ReplicationController wrapped-volume-race-dee753fc-834d-11e9-949c-223764f7eae1 pods took: 100.455682ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:46:28.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-jztmw" for this suite.
May 31 02:46:34.107: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:46:34.164: INFO: namespace: e2e-tests-emptydir-wrapper-jztmw, resource: bindings, ignored listing per whitelist
May 31 02:46:34.193: INFO: namespace e2e-tests-emptydir-wrapper-jztmw deletion completed in 6.095121691s

• [SLOW TEST:482.355 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:46:34.194: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
May 31 02:46:38.791: INFO: Successfully updated pod "pod-update-activedeadlineseconds-4d836d51-834e-11e9-949c-223764f7eae1"
May 31 02:46:38.791: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-4d836d51-834e-11e9-949c-223764f7eae1" in namespace "e2e-tests-pods-skj2q" to be "terminated due to deadline exceeded"
May 31 02:46:38.793: INFO: Pod "pod-update-activedeadlineseconds-4d836d51-834e-11e9-949c-223764f7eae1": Phase="Running", Reason="", readiness=true. Elapsed: 1.767828ms
May 31 02:46:40.796: INFO: Pod "pod-update-activedeadlineseconds-4d836d51-834e-11e9-949c-223764f7eae1": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.004438812s
May 31 02:46:40.796: INFO: Pod "pod-update-activedeadlineseconds-4d836d51-834e-11e9-949c-223764f7eae1" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:46:40.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-skj2q" for this suite.
May 31 02:46:46.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:46:46.870: INFO: namespace: e2e-tests-pods-skj2q, resource: bindings, ignored listing per whitelist
May 31 02:46:46.891: INFO: namespace e2e-tests-pods-skj2q deletion completed in 6.092551241s

• [SLOW TEST:12.698 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:46:46.892: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 31 02:46:46.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 version'
May 31 02:46:47.050: INFO: stderr: ""
May 31 02:46:47.050: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.6\", GitCommit:\"abdda3f9fefa29172298a2e42f5102e777a8ec25\", GitTreeState:\"clean\", BuildDate:\"2019-05-08T13:53:53Z\", GoVersion:\"go1.11.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.6\", GitCommit:\"23662a5d709637ec0f93873b93a0f2f9adca9cbe\", GitTreeState:\"clean\", BuildDate:\"2019-05-22T02:27:56Z\", GoVersion:\"go1.11.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:46:47.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-k4dvx" for this suite.
May 31 02:46:53.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:46:53.111: INFO: namespace: e2e-tests-kubectl-k4dvx, resource: bindings, ignored listing per whitelist
May 31 02:46:53.136: INFO: namespace e2e-tests-kubectl-k4dvx deletion completed in 6.081416914s

• [SLOW TEST:6.245 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:46:53.139: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
May 31 02:46:53.215: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-l72b7" to be "success or failure"
May 31 02:46:53.221: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 5.11108ms
May 31 02:46:55.224: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008272231s
May 31 02:46:57.227: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011392676s
STEP: Saw pod success
May 31 02:46:57.227: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
May 31 02:46:57.229: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
May 31 02:46:57.244: INFO: Waiting for pod pod-host-path-test to disappear
May 31 02:46:57.248: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:46:57.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-l72b7" for this suite.
May 31 02:47:03.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:47:03.269: INFO: namespace: e2e-tests-hostpath-l72b7, resource: bindings, ignored listing per whitelist
May 31 02:47:03.330: INFO: namespace e2e-tests-hostpath-l72b7 deletion completed in 6.079088193s

• [SLOW TEST:10.191 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:47:03.330: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 31 02:47:03.449: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5ee79002-834e-11e9-949c-223764f7eae1" in namespace "e2e-tests-downward-api-hnfz4" to be "success or failure"
May 31 02:47:03.456: INFO: Pod "downwardapi-volume-5ee79002-834e-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.968309ms
May 31 02:47:05.459: INFO: Pod "downwardapi-volume-5ee79002-834e-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010268335s
May 31 02:47:07.462: INFO: Pod "downwardapi-volume-5ee79002-834e-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013465754s
STEP: Saw pod success
May 31 02:47:07.462: INFO: Pod "downwardapi-volume-5ee79002-834e-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 02:47:07.464: INFO: Trying to get logs from node k8s-linuxpool-39082607-2 pod downwardapi-volume-5ee79002-834e-11e9-949c-223764f7eae1 container client-container: <nil>
STEP: delete the pod
May 31 02:47:07.484: INFO: Waiting for pod downwardapi-volume-5ee79002-834e-11e9-949c-223764f7eae1 to disappear
May 31 02:47:07.487: INFO: Pod downwardapi-volume-5ee79002-834e-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:47:07.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-hnfz4" for this suite.
May 31 02:47:13.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:47:13.537: INFO: namespace: e2e-tests-downward-api-hnfz4, resource: bindings, ignored listing per whitelist
May 31 02:47:13.609: INFO: namespace e2e-tests-downward-api-hnfz4 deletion completed in 6.118421625s

• [SLOW TEST:10.279 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:47:13.609: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
May 31 02:47:17.718: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-6503bf91-834e-11e9-949c-223764f7eae1", GenerateName:"", Namespace:"e2e-tests-pods-g54fc", SelfLink:"/api/v1/namespaces/e2e-tests-pods-g54fc/pods/pod-submit-remove-6503bf91-834e-11e9-949c-223764f7eae1", UID:"6504b96b-834e-11e9-944d-001dd80c001b", ResourceVersion:"7616", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63694867633, loc:(*time.Location)(0x7b6dbe0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"694303419"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-kh75z", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0021b3380), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-kh75z", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0026a8998), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"k8s-linuxpool-39082607-0", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002672c60), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0026a89d0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0026a89f0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0026a89f8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0026a89fc)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694867633, loc:(*time.Location)(0x7b6dbe0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694867636, loc:(*time.Location)(0x7b6dbe0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694867636, loc:(*time.Location)(0x7b6dbe0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694867633, loc:(*time.Location)(0x7b6dbe0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.240.0.4", PodIP:"10.244.3.65", StartTime:(*v1.Time)(0xc002692dc0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc002692de0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7", ContainerID:"docker://fd7baa7e5f057bc791b53345250b9645313864cb084597b628de344ef716a291"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
May 31 02:47:22.730: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:47:22.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-g54fc" for this suite.
May 31 02:47:28.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:47:28.818: INFO: namespace: e2e-tests-pods-g54fc, resource: bindings, ignored listing per whitelist
May 31 02:47:28.842: INFO: namespace e2e-tests-pods-g54fc deletion completed in 6.106512118s

• [SLOW TEST:15.233 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:47:28.842: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
May 31 02:47:28.913: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-535705201 proxy --unix-socket=/tmp/kubectl-proxy-unix373407004/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:47:28.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vgvpx" for this suite.
May 31 02:47:35.040: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:47:35.084: INFO: namespace: e2e-tests-kubectl-vgvpx, resource: bindings, ignored listing per whitelist
May 31 02:47:35.122: INFO: namespace e2e-tests-kubectl-vgvpx deletion completed in 6.153477502s

• [SLOW TEST:6.280 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:47:35.123: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-kfz44.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-kfz44.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-kfz44.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-kfz44.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-kfz44.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-kfz44.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 31 02:47:55.268: INFO: DNS probes using e2e-tests-dns-kfz44/dns-test-71d30596-834e-11e9-949c-223764f7eae1 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:47:55.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-kfz44" for this suite.
May 31 02:48:01.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:48:01.313: INFO: namespace: e2e-tests-dns-kfz44, resource: bindings, ignored listing per whitelist
May 31 02:48:01.378: INFO: namespace e2e-tests-dns-kfz44 deletion completed in 6.087945882s

• [SLOW TEST:26.255 seconds]
[sig-network] DNS
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:48:01.378: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:49:01.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-78gvx" for this suite.
May 31 02:49:23.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:49:23.522: INFO: namespace: e2e-tests-container-probe-78gvx, resource: bindings, ignored listing per whitelist
May 31 02:49:23.546: INFO: namespace e2e-tests-container-probe-78gvx deletion completed in 22.083969888s

• [SLOW TEST:82.168 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:49:23.546: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-b273b5ac-834e-11e9-949c-223764f7eae1
STEP: Creating a pod to test consume secrets
May 31 02:49:23.621: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b2742d5f-834e-11e9-949c-223764f7eae1" in namespace "e2e-tests-projected-s2lhl" to be "success or failure"
May 31 02:49:23.623: INFO: Pod "pod-projected-secrets-b2742d5f-834e-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.188334ms
May 31 02:49:25.626: INFO: Pod "pod-projected-secrets-b2742d5f-834e-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005303629s
May 31 02:49:27.629: INFO: Pod "pod-projected-secrets-b2742d5f-834e-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008674323s
STEP: Saw pod success
May 31 02:49:27.629: INFO: Pod "pod-projected-secrets-b2742d5f-834e-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 02:49:27.632: INFO: Trying to get logs from node k8s-linuxpool-39082607-2 pod pod-projected-secrets-b2742d5f-834e-11e9-949c-223764f7eae1 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 31 02:49:27.648: INFO: Waiting for pod pod-projected-secrets-b2742d5f-834e-11e9-949c-223764f7eae1 to disappear
May 31 02:49:27.651: INFO: Pod pod-projected-secrets-b2742d5f-834e-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:49:27.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-s2lhl" for this suite.
May 31 02:49:33.719: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:49:33.744: INFO: namespace: e2e-tests-projected-s2lhl, resource: bindings, ignored listing per whitelist
May 31 02:49:33.803: INFO: namespace e2e-tests-projected-s2lhl deletion completed in 6.093470649s

• [SLOW TEST:10.257 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:49:33.805: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 31 02:49:33.904: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
May 31 02:49:33.909: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-lmwmz/daemonsets","resourceVersion":"7964"},"items":null}

May 31 02:49:33.912: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-lmwmz/pods","resourceVersion":"7964"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:49:33.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-lmwmz" for this suite.
May 31 02:49:39.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:49:40.000: INFO: namespace: e2e-tests-daemonsets-lmwmz, resource: bindings, ignored listing per whitelist
May 31 02:49:40.013: INFO: namespace e2e-tests-daemonsets-lmwmz deletion completed in 6.088139028s

S [SKIPPING] [6.208 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  May 31 02:49:33.904: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:49:40.014: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:49:40.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-j54gz" for this suite.
May 31 02:50:02.107: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:50:02.122: INFO: namespace: e2e-tests-pods-j54gz, resource: bindings, ignored listing per whitelist
May 31 02:50:02.185: INFO: namespace e2e-tests-pods-j54gz deletion completed in 22.091645351s

• [SLOW TEST:22.172 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:50:02.186: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-5sbcp
May 31 02:50:06.267: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-5sbcp
STEP: checking the pod's current state and verifying that restartCount is present
May 31 02:50:06.269: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:54:06.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-5sbcp" for this suite.
May 31 02:54:12.667: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:54:12.692: INFO: namespace: e2e-tests-container-probe-5sbcp, resource: bindings, ignored listing per whitelist
May 31 02:54:12.743: INFO: namespace e2e-tests-container-probe-5sbcp deletion completed in 6.083248977s

• [SLOW TEST:250.557 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:54:12.743: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
May 31 02:54:13.325: INFO: Waiting up to 5m0s for pod "pod-service-account-5f212f76-834f-11e9-949c-223764f7eae1-cnvcg" in namespace "e2e-tests-svcaccounts-qfzr5" to be "success or failure"
May 31 02:54:13.333: INFO: Pod "pod-service-account-5f212f76-834f-11e9-949c-223764f7eae1-cnvcg": Phase="Pending", Reason="", readiness=false. Elapsed: 8.691633ms
May 31 02:54:15.369: INFO: Pod "pod-service-account-5f212f76-834f-11e9-949c-223764f7eae1-cnvcg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044645578s
May 31 02:54:17.373: INFO: Pod "pod-service-account-5f212f76-834f-11e9-949c-223764f7eae1-cnvcg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048004624s
STEP: Saw pod success
May 31 02:54:17.373: INFO: Pod "pod-service-account-5f212f76-834f-11e9-949c-223764f7eae1-cnvcg" satisfied condition "success or failure"
May 31 02:54:17.377: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod pod-service-account-5f212f76-834f-11e9-949c-223764f7eae1-cnvcg container token-test: <nil>
STEP: delete the pod
May 31 02:54:17.397: INFO: Waiting for pod pod-service-account-5f212f76-834f-11e9-949c-223764f7eae1-cnvcg to disappear
May 31 02:54:17.399: INFO: Pod pod-service-account-5f212f76-834f-11e9-949c-223764f7eae1-cnvcg no longer exists
STEP: Creating a pod to test consume service account root CA
May 31 02:54:17.403: INFO: Waiting up to 5m0s for pod "pod-service-account-5f212f76-834f-11e9-949c-223764f7eae1-9cs4c" in namespace "e2e-tests-svcaccounts-qfzr5" to be "success or failure"
May 31 02:54:17.408: INFO: Pod "pod-service-account-5f212f76-834f-11e9-949c-223764f7eae1-9cs4c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.007177ms
May 31 02:54:19.411: INFO: Pod "pod-service-account-5f212f76-834f-11e9-949c-223764f7eae1-9cs4c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00835722s
May 31 02:54:21.414: INFO: Pod "pod-service-account-5f212f76-834f-11e9-949c-223764f7eae1-9cs4c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011046751s
STEP: Saw pod success
May 31 02:54:21.414: INFO: Pod "pod-service-account-5f212f76-834f-11e9-949c-223764f7eae1-9cs4c" satisfied condition "success or failure"
May 31 02:54:21.416: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod pod-service-account-5f212f76-834f-11e9-949c-223764f7eae1-9cs4c container root-ca-test: <nil>
STEP: delete the pod
May 31 02:54:21.428: INFO: Waiting for pod pod-service-account-5f212f76-834f-11e9-949c-223764f7eae1-9cs4c to disappear
May 31 02:54:21.431: INFO: Pod pod-service-account-5f212f76-834f-11e9-949c-223764f7eae1-9cs4c no longer exists
STEP: Creating a pod to test consume service account namespace
May 31 02:54:21.438: INFO: Waiting up to 5m0s for pod "pod-service-account-5f212f76-834f-11e9-949c-223764f7eae1-dc4hs" in namespace "e2e-tests-svcaccounts-qfzr5" to be "success or failure"
May 31 02:54:21.440: INFO: Pod "pod-service-account-5f212f76-834f-11e9-949c-223764f7eae1-dc4hs": Phase="Pending", Reason="", readiness=false. Elapsed: 1.864128ms
May 31 02:54:23.444: INFO: Pod "pod-service-account-5f212f76-834f-11e9-949c-223764f7eae1-dc4hs": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005133366s
May 31 02:54:25.447: INFO: Pod "pod-service-account-5f212f76-834f-11e9-949c-223764f7eae1-dc4hs": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0083126s
STEP: Saw pod success
May 31 02:54:25.447: INFO: Pod "pod-service-account-5f212f76-834f-11e9-949c-223764f7eae1-dc4hs" satisfied condition "success or failure"
May 31 02:54:25.454: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod pod-service-account-5f212f76-834f-11e9-949c-223764f7eae1-dc4hs container namespace-test: <nil>
STEP: delete the pod
May 31 02:54:25.524: INFO: Waiting for pod pod-service-account-5f212f76-834f-11e9-949c-223764f7eae1-dc4hs to disappear
May 31 02:54:25.526: INFO: Pod pod-service-account-5f212f76-834f-11e9-949c-223764f7eae1-dc4hs no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:54:25.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-qfzr5" for this suite.
May 31 02:54:31.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:54:31.582: INFO: namespace: e2e-tests-svcaccounts-qfzr5, resource: bindings, ignored listing per whitelist
May 31 02:54:31.623: INFO: namespace e2e-tests-svcaccounts-qfzr5 deletion completed in 6.093286565s

• [SLOW TEST:18.880 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:54:31.624: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 31 02:54:31.701: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:54:32.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-kh5p7" for this suite.
May 31 02:54:38.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:54:38.967: INFO: namespace: e2e-tests-custom-resource-definition-kh5p7, resource: bindings, ignored listing per whitelist
May 31 02:54:38.987: INFO: namespace e2e-tests-custom-resource-definition-kh5p7 deletion completed in 6.198100437s

• [SLOW TEST:7.363 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:54:38.988: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 31 02:54:39.058: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6e781d0b-834f-11e9-949c-223764f7eae1" in namespace "e2e-tests-projected-sqrtj" to be "success or failure"
May 31 02:54:39.061: INFO: Pod "downwardapi-volume-6e781d0b-834f-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.785342ms
May 31 02:54:41.064: INFO: Pod "downwardapi-volume-6e781d0b-834f-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005983959s
May 31 02:54:43.067: INFO: Pod "downwardapi-volume-6e781d0b-834f-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008872069s
STEP: Saw pod success
May 31 02:54:43.067: INFO: Pod "downwardapi-volume-6e781d0b-834f-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 02:54:43.069: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod downwardapi-volume-6e781d0b-834f-11e9-949c-223764f7eae1 container client-container: <nil>
STEP: delete the pod
May 31 02:54:43.083: INFO: Waiting for pod downwardapi-volume-6e781d0b-834f-11e9-949c-223764f7eae1 to disappear
May 31 02:54:43.084: INFO: Pod downwardapi-volume-6e781d0b-834f-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:54:43.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sqrtj" for this suite.
May 31 02:54:49.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:54:49.262: INFO: namespace: e2e-tests-projected-sqrtj, resource: bindings, ignored listing per whitelist
May 31 02:54:49.306: INFO: namespace e2e-tests-projected-sqrtj deletion completed in 6.21898262s

• [SLOW TEST:10.318 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:54:49.306: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
May 31 02:54:49.390: INFO: Waiting up to 5m0s for pod "pod-74a0a56b-834f-11e9-949c-223764f7eae1" in namespace "e2e-tests-emptydir-hx7mc" to be "success or failure"
May 31 02:54:49.402: INFO: Pod "pod-74a0a56b-834f-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 11.356573ms
May 31 02:54:51.404: INFO: Pod "pod-74a0a56b-834f-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014078172s
May 31 02:54:53.408: INFO: Pod "pod-74a0a56b-834f-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018097988s
STEP: Saw pod success
May 31 02:54:53.408: INFO: Pod "pod-74a0a56b-834f-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 02:54:53.411: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod pod-74a0a56b-834f-11e9-949c-223764f7eae1 container test-container: <nil>
STEP: delete the pod
May 31 02:54:53.433: INFO: Waiting for pod pod-74a0a56b-834f-11e9-949c-223764f7eae1 to disappear
May 31 02:54:53.436: INFO: Pod pod-74a0a56b-834f-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:54:53.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-hx7mc" for this suite.
May 31 02:54:59.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:54:59.513: INFO: namespace: e2e-tests-emptydir-hx7mc, resource: bindings, ignored listing per whitelist
May 31 02:54:59.528: INFO: namespace e2e-tests-emptydir-hx7mc deletion completed in 6.089531915s

• [SLOW TEST:10.221 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:54:59.528: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 31 02:54:59.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-88qrp'
May 31 02:55:00.075: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 31 02:55:00.075: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
May 31 02:55:00.092: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-gxrws]
May 31 02:55:00.092: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-gxrws" in namespace "e2e-tests-kubectl-88qrp" to be "running and ready"
May 31 02:55:00.099: INFO: Pod "e2e-test-nginx-rc-gxrws": Phase="Pending", Reason="", readiness=false. Elapsed: 7.539115ms
May 31 02:55:02.102: INFO: Pod "e2e-test-nginx-rc-gxrws": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0101605s
May 31 02:55:04.104: INFO: Pod "e2e-test-nginx-rc-gxrws": Phase="Running", Reason="", readiness=true. Elapsed: 4.012647882s
May 31 02:55:04.104: INFO: Pod "e2e-test-nginx-rc-gxrws" satisfied condition "running and ready"
May 31 02:55:04.104: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-gxrws]
May 31 02:55:04.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-88qrp'
May 31 02:55:04.226: INFO: stderr: ""
May 31 02:55:04.226: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
May 31 02:55:04.226: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-88qrp'
May 31 02:55:04.327: INFO: stderr: ""
May 31 02:55:04.327: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:55:04.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-88qrp" for this suite.
May 31 02:55:10.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:55:10.393: INFO: namespace: e2e-tests-kubectl-88qrp, resource: bindings, ignored listing per whitelist
May 31 02:55:10.427: INFO: namespace e2e-tests-kubectl-88qrp deletion completed in 6.094868361s

• [SLOW TEST:10.899 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:55:10.427: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-xv5bq
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-xv5bq
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-xv5bq
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-xv5bq
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-xv5bq
May 31 02:55:14.548: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-xv5bq, name: ss-0, uid: 814368fe-834f-11e9-944d-001dd80c001b, status phase: Pending. Waiting for statefulset controller to delete.
May 31 02:55:17.684: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-xv5bq, name: ss-0, uid: 814368fe-834f-11e9-944d-001dd80c001b, status phase: Failed. Waiting for statefulset controller to delete.
May 31 02:55:17.690: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-xv5bq, name: ss-0, uid: 814368fe-834f-11e9-944d-001dd80c001b, status phase: Failed. Waiting for statefulset controller to delete.
May 31 02:55:17.699: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-xv5bq
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-xv5bq
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-xv5bq and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 31 02:55:21.721: INFO: Deleting all statefulset in ns e2e-tests-statefulset-xv5bq
May 31 02:55:21.723: INFO: Scaling statefulset ss to 0
May 31 02:55:31.735: INFO: Waiting for statefulset status.replicas updated to 0
May 31 02:55:31.737: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:55:31.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-xv5bq" for this suite.
May 31 02:55:37.760: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:55:37.789: INFO: namespace: e2e-tests-statefulset-xv5bq, resource: bindings, ignored listing per whitelist
May 31 02:55:37.838: INFO: namespace e2e-tests-statefulset-xv5bq deletion completed in 6.08654735s

• [SLOW TEST:27.411 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:55:37.839: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
May 31 02:55:37.922: INFO: Pod name pod-release: Found 0 pods out of 1
May 31 02:55:42.925: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:55:42.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-9l6zl" for this suite.
May 31 02:55:48.976: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:55:49.012: INFO: namespace: e2e-tests-replication-controller-9l6zl, resource: bindings, ignored listing per whitelist
May 31 02:55:49.052: INFO: namespace e2e-tests-replication-controller-9l6zl deletion completed in 6.100625431s

• [SLOW TEST:11.214 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:55:49.053: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-x85rn
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
May 31 02:55:49.142: INFO: Found 0 stateful pods, waiting for 3
May 31 02:55:59.146: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 31 02:55:59.146: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 31 02:55:59.146: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
May 31 02:55:59.171: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
May 31 02:56:09.199: INFO: Updating stateful set ss2
May 31 02:56:09.204: INFO: Waiting for Pod e2e-tests-statefulset-x85rn/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
May 31 02:56:19.259: INFO: Found 1 stateful pods, waiting for 3
May 31 02:56:29.263: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 31 02:56:29.263: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 31 02:56:29.263: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
May 31 02:56:29.285: INFO: Updating stateful set ss2
May 31 02:56:29.291: INFO: Waiting for Pod e2e-tests-statefulset-x85rn/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
May 31 02:56:39.313: INFO: Updating stateful set ss2
May 31 02:56:39.326: INFO: Waiting for StatefulSet e2e-tests-statefulset-x85rn/ss2 to complete update
May 31 02:56:39.326: INFO: Waiting for Pod e2e-tests-statefulset-x85rn/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
May 31 02:56:49.333: INFO: Waiting for StatefulSet e2e-tests-statefulset-x85rn/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 31 02:56:59.331: INFO: Deleting all statefulset in ns e2e-tests-statefulset-x85rn
May 31 02:56:59.333: INFO: Scaling statefulset ss2 to 0
May 31 02:57:19.350: INFO: Waiting for statefulset status.replicas updated to 0
May 31 02:57:19.352: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:57:19.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-x85rn" for this suite.
May 31 02:57:25.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:57:25.431: INFO: namespace: e2e-tests-statefulset-x85rn, resource: bindings, ignored listing per whitelist
May 31 02:57:25.458: INFO: namespace e2e-tests-statefulset-x85rn deletion completed in 6.088706292s

• [SLOW TEST:96.405 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:57:25.460: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:57:30.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-xh2bk" for this suite.
May 31 02:57:52.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:57:52.576: INFO: namespace: e2e-tests-replication-controller-xh2bk, resource: bindings, ignored listing per whitelist
May 31 02:57:52.637: INFO: namespace e2e-tests-replication-controller-xh2bk deletion completed in 22.082698061s

• [SLOW TEST:27.177 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:57:52.637: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0531 02:58:32.728211      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 31 02:58:32.728: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:58:32.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-ks9bj" for this suite.
May 31 02:58:38.740: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:58:38.773: INFO: namespace: e2e-tests-gc-ks9bj, resource: bindings, ignored listing per whitelist
May 31 02:58:38.835: INFO: namespace e2e-tests-gc-ks9bj deletion completed in 6.104801469s

• [SLOW TEST:46.199 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:58:38.836: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
May 31 02:58:38.912: INFO: Waiting up to 5m0s for pod "pod-fd6ebf55-834f-11e9-949c-223764f7eae1" in namespace "e2e-tests-emptydir-zn8dl" to be "success or failure"
May 31 02:58:38.916: INFO: Pod "pod-fd6ebf55-834f-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.603155ms
May 31 02:58:40.918: INFO: Pod "pod-fd6ebf55-834f-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006334554s
May 31 02:58:42.921: INFO: Pod "pod-fd6ebf55-834f-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009047552s
STEP: Saw pod success
May 31 02:58:42.921: INFO: Pod "pod-fd6ebf55-834f-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 02:58:42.923: INFO: Trying to get logs from node k8s-linuxpool-39082607-2 pod pod-fd6ebf55-834f-11e9-949c-223764f7eae1 container test-container: <nil>
STEP: delete the pod
May 31 02:58:42.938: INFO: Waiting for pod pod-fd6ebf55-834f-11e9-949c-223764f7eae1 to disappear
May 31 02:58:42.940: INFO: Pod pod-fd6ebf55-834f-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:58:42.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-zn8dl" for this suite.
May 31 02:58:48.951: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:58:49.009: INFO: namespace: e2e-tests-emptydir-zn8dl, resource: bindings, ignored listing per whitelist
May 31 02:58:49.023: INFO: namespace e2e-tests-emptydir-zn8dl deletion completed in 6.079430364s

• [SLOW TEST:10.187 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:58:49.023: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-038bc76c-8350-11e9-949c-223764f7eae1
STEP: Creating a pod to test consume configMaps
May 31 02:58:49.173: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-038c3aa5-8350-11e9-949c-223764f7eae1" in namespace "e2e-tests-projected-lprjj" to be "success or failure"
May 31 02:58:49.178: INFO: Pod "pod-projected-configmaps-038c3aa5-8350-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.333981ms
May 31 02:58:51.181: INFO: Pod "pod-projected-configmaps-038c3aa5-8350-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008039273s
May 31 02:58:53.184: INFO: Pod "pod-projected-configmaps-038c3aa5-8350-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01116487s
STEP: Saw pod success
May 31 02:58:53.184: INFO: Pod "pod-projected-configmaps-038c3aa5-8350-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 02:58:53.187: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod pod-projected-configmaps-038c3aa5-8350-11e9-949c-223764f7eae1 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 31 02:58:53.205: INFO: Waiting for pod pod-projected-configmaps-038c3aa5-8350-11e9-949c-223764f7eae1 to disappear
May 31 02:58:53.207: INFO: Pod pod-projected-configmaps-038c3aa5-8350-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:58:53.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-lprjj" for this suite.
May 31 02:58:59.221: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:58:59.259: INFO: namespace: e2e-tests-projected-lprjj, resource: bindings, ignored listing per whitelist
May 31 02:58:59.294: INFO: namespace e2e-tests-projected-lprjj deletion completed in 6.084416019s

• [SLOW TEST:10.271 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:58:59.295: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
May 31 02:59:07.404: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 31 02:59:07.407: INFO: Pod pod-with-prestop-http-hook still exists
May 31 02:59:09.408: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 31 02:59:09.411: INFO: Pod pod-with-prestop-http-hook still exists
May 31 02:59:11.408: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 31 02:59:11.411: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:59:11.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-pckjc" for this suite.
May 31 02:59:33.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 02:59:33.451: INFO: namespace: e2e-tests-container-lifecycle-hook-pckjc, resource: bindings, ignored listing per whitelist
May 31 02:59:33.514: INFO: namespace e2e-tests-container-lifecycle-hook-pckjc deletion completed in 22.086120235s

• [SLOW TEST:34.219 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 02:59:33.514: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 31 02:59:33.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-hhndd'
May 31 02:59:33.714: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 31 02:59:33.714: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: rolling-update to same image controller
May 31 02:59:33.727: INFO: scanned /root for discovery docs: <nil>
May 31 02:59:33.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-hhndd'
May 31 02:59:49.502: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
May 31 02:59:49.502: INFO: stdout: "Created e2e-test-nginx-rc-cbec49eb74bbee166cde4982779f28b1\nScaling up e2e-test-nginx-rc-cbec49eb74bbee166cde4982779f28b1 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-cbec49eb74bbee166cde4982779f28b1 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-cbec49eb74bbee166cde4982779f28b1 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
May 31 02:59:49.502: INFO: stdout: "Created e2e-test-nginx-rc-cbec49eb74bbee166cde4982779f28b1\nScaling up e2e-test-nginx-rc-cbec49eb74bbee166cde4982779f28b1 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-cbec49eb74bbee166cde4982779f28b1 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-cbec49eb74bbee166cde4982779f28b1 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
May 31 02:59:49.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-hhndd'
May 31 02:59:49.642: INFO: stderr: ""
May 31 02:59:49.642: INFO: stdout: "e2e-test-nginx-rc-cbec49eb74bbee166cde4982779f28b1-4pk4c "
May 31 02:59:49.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods e2e-test-nginx-rc-cbec49eb74bbee166cde4982779f28b1-4pk4c -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hhndd'
May 31 02:59:49.733: INFO: stderr: ""
May 31 02:59:49.733: INFO: stdout: "true"
May 31 02:59:49.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods e2e-test-nginx-rc-cbec49eb74bbee166cde4982779f28b1-4pk4c -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hhndd'
May 31 02:59:49.812: INFO: stderr: ""
May 31 02:59:49.812: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
May 31 02:59:49.812: INFO: e2e-test-nginx-rc-cbec49eb74bbee166cde4982779f28b1-4pk4c is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
May 31 02:59:49.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-hhndd'
May 31 02:59:49.913: INFO: stderr: ""
May 31 02:59:49.913: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 02:59:49.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hhndd" for this suite.
May 31 03:00:11.931: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:00:11.952: INFO: namespace: e2e-tests-kubectl-hhndd, resource: bindings, ignored listing per whitelist
May 31 03:00:12.002: INFO: namespace e2e-tests-kubectl-hhndd deletion completed in 22.084013144s

• [SLOW TEST:38.488 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:00:12.002: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
May 31 03:00:16.605: INFO: Successfully updated pod "labelsupdate34f70642-8350-11e9-949c-223764f7eae1"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:00:18.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5mqnr" for this suite.
May 31 03:00:40.636: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:00:40.697: INFO: namespace: e2e-tests-downward-api-5mqnr, resource: bindings, ignored listing per whitelist
May 31 03:00:40.717: INFO: namespace e2e-tests-downward-api-5mqnr deletion completed in 22.089484146s

• [SLOW TEST:28.715 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:00:40.717: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:01:08.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-mh2mv" for this suite.
May 31 03:01:15.000: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:01:15.050: INFO: namespace: e2e-tests-container-runtime-mh2mv, resource: bindings, ignored listing per whitelist
May 31 03:01:15.103: INFO: namespace e2e-tests-container-runtime-mh2mv deletion completed in 6.11707537s

• [SLOW TEST:34.385 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:01:15.104: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
May 31 03:01:15.194: INFO: Waiting up to 5m0s for pod "pod-5a9545d8-8350-11e9-949c-223764f7eae1" in namespace "e2e-tests-emptydir-7jblq" to be "success or failure"
May 31 03:01:15.202: INFO: Pod "pod-5a9545d8-8350-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.083922ms
May 31 03:01:17.207: INFO: Pod "pod-5a9545d8-8350-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01283486s
May 31 03:01:19.210: INFO: Pod "pod-5a9545d8-8350-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016263176s
STEP: Saw pod success
May 31 03:01:19.210: INFO: Pod "pod-5a9545d8-8350-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:01:19.212: INFO: Trying to get logs from node k8s-linuxpool-39082607-2 pod pod-5a9545d8-8350-11e9-949c-223764f7eae1 container test-container: <nil>
STEP: delete the pod
May 31 03:01:19.229: INFO: Waiting for pod pod-5a9545d8-8350-11e9-949c-223764f7eae1 to disappear
May 31 03:01:19.231: INFO: Pod pod-5a9545d8-8350-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:01:19.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-7jblq" for this suite.
May 31 03:01:25.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:01:25.316: INFO: namespace: e2e-tests-emptydir-7jblq, resource: bindings, ignored listing per whitelist
May 31 03:01:25.323: INFO: namespace e2e-tests-emptydir-7jblq deletion completed in 6.088876729s

• [SLOW TEST:10.219 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:01:25.323: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 31 03:01:25.416: INFO: Waiting up to 5m0s for pod "downwardapi-volume-60ad2b8d-8350-11e9-949c-223764f7eae1" in namespace "e2e-tests-downward-api-5q8xk" to be "success or failure"
May 31 03:01:25.423: INFO: Pod "downwardapi-volume-60ad2b8d-8350-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.764602ms
May 31 03:01:27.426: INFO: Pod "downwardapi-volume-60ad2b8d-8350-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010191615s
May 31 03:01:29.429: INFO: Pod "downwardapi-volume-60ad2b8d-8350-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013159119s
STEP: Saw pod success
May 31 03:01:29.430: INFO: Pod "downwardapi-volume-60ad2b8d-8350-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:01:29.432: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod downwardapi-volume-60ad2b8d-8350-11e9-949c-223764f7eae1 container client-container: <nil>
STEP: delete the pod
May 31 03:01:29.450: INFO: Waiting for pod downwardapi-volume-60ad2b8d-8350-11e9-949c-223764f7eae1 to disappear
May 31 03:01:29.455: INFO: Pod downwardapi-volume-60ad2b8d-8350-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:01:29.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5q8xk" for this suite.
May 31 03:01:35.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:01:35.496: INFO: namespace: e2e-tests-downward-api-5q8xk, resource: bindings, ignored listing per whitelist
May 31 03:01:35.541: INFO: namespace e2e-tests-downward-api-5q8xk deletion completed in 6.08334153s

• [SLOW TEST:10.218 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:01:35.541: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 31 03:01:35.615: INFO: Waiting up to 5m0s for pod "downwardapi-volume-66c19109-8350-11e9-949c-223764f7eae1" in namespace "e2e-tests-projected-tdpk4" to be "success or failure"
May 31 03:01:35.617: INFO: Pod "downwardapi-volume-66c19109-8350-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.094332ms
May 31 03:01:37.620: INFO: Pod "downwardapi-volume-66c19109-8350-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004951631s
May 31 03:01:39.623: INFO: Pod "downwardapi-volume-66c19109-8350-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008216835s
STEP: Saw pod success
May 31 03:01:39.623: INFO: Pod "downwardapi-volume-66c19109-8350-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:01:39.626: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod downwardapi-volume-66c19109-8350-11e9-949c-223764f7eae1 container client-container: <nil>
STEP: delete the pod
May 31 03:01:39.640: INFO: Waiting for pod downwardapi-volume-66c19109-8350-11e9-949c-223764f7eae1 to disappear
May 31 03:01:39.646: INFO: Pod downwardapi-volume-66c19109-8350-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:01:39.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tdpk4" for this suite.
May 31 03:01:45.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:01:45.734: INFO: namespace: e2e-tests-projected-tdpk4, resource: bindings, ignored listing per whitelist
May 31 03:01:45.756: INFO: namespace e2e-tests-projected-tdpk4 deletion completed in 6.107133874s

• [SLOW TEST:10.215 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:01:45.757: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
May 31 03:01:45.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 create -f - --namespace=e2e-tests-kubectl-fglgf'
May 31 03:01:46.070: INFO: stderr: ""
May 31 03:01:46.070: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 31 03:01:46.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-fglgf'
May 31 03:01:46.185: INFO: stderr: ""
May 31 03:01:46.185: INFO: stdout: "update-demo-nautilus-fmgz9 update-demo-nautilus-n46l2 "
May 31 03:01:46.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods update-demo-nautilus-fmgz9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fglgf'
May 31 03:01:46.267: INFO: stderr: ""
May 31 03:01:46.267: INFO: stdout: ""
May 31 03:01:46.267: INFO: update-demo-nautilus-fmgz9 is created but not running
May 31 03:01:51.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-fglgf'
May 31 03:01:51.350: INFO: stderr: ""
May 31 03:01:51.350: INFO: stdout: "update-demo-nautilus-fmgz9 update-demo-nautilus-n46l2 "
May 31 03:01:51.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods update-demo-nautilus-fmgz9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fglgf'
May 31 03:01:51.428: INFO: stderr: ""
May 31 03:01:51.428: INFO: stdout: ""
May 31 03:01:51.428: INFO: update-demo-nautilus-fmgz9 is created but not running
May 31 03:01:56.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-fglgf'
May 31 03:01:56.526: INFO: stderr: ""
May 31 03:01:56.526: INFO: stdout: "update-demo-nautilus-fmgz9 update-demo-nautilus-n46l2 "
May 31 03:01:56.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods update-demo-nautilus-fmgz9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fglgf'
May 31 03:01:56.622: INFO: stderr: ""
May 31 03:01:56.622: INFO: stdout: "true"
May 31 03:01:56.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods update-demo-nautilus-fmgz9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fglgf'
May 31 03:01:56.706: INFO: stderr: ""
May 31 03:01:56.706: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 31 03:01:56.706: INFO: validating pod update-demo-nautilus-fmgz9
May 31 03:01:56.714: INFO: got data: {
  "image": "nautilus.jpg"
}

May 31 03:01:56.714: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 31 03:01:56.714: INFO: update-demo-nautilus-fmgz9 is verified up and running
May 31 03:01:56.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods update-demo-nautilus-n46l2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fglgf'
May 31 03:01:56.802: INFO: stderr: ""
May 31 03:01:56.802: INFO: stdout: "true"
May 31 03:01:56.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods update-demo-nautilus-n46l2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fglgf'
May 31 03:01:56.897: INFO: stderr: ""
May 31 03:01:56.898: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 31 03:01:56.898: INFO: validating pod update-demo-nautilus-n46l2
May 31 03:01:56.909: INFO: got data: {
  "image": "nautilus.jpg"
}

May 31 03:01:56.909: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 31 03:01:56.909: INFO: update-demo-nautilus-n46l2 is verified up and running
STEP: using delete to clean up resources
May 31 03:01:56.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-fglgf'
May 31 03:01:57.015: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 31 03:01:57.015: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May 31 03:01:57.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-fglgf'
May 31 03:01:57.113: INFO: stderr: "No resources found.\n"
May 31 03:01:57.113: INFO: stdout: ""
May 31 03:01:57.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods -l name=update-demo --namespace=e2e-tests-kubectl-fglgf -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 31 03:01:57.219: INFO: stderr: ""
May 31 03:01:57.219: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:01:57.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-fglgf" for this suite.
May 31 03:02:19.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:02:19.270: INFO: namespace: e2e-tests-kubectl-fglgf, resource: bindings, ignored listing per whitelist
May 31 03:02:19.307: INFO: namespace e2e-tests-kubectl-fglgf deletion completed in 22.083825413s

• [SLOW TEST:33.551 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:02:19.309: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-q7q68/configmap-test-80d9b27c-8350-11e9-949c-223764f7eae1
STEP: Creating a pod to test consume configMaps
May 31 03:02:19.398: INFO: Waiting up to 5m0s for pod "pod-configmaps-80da2834-8350-11e9-949c-223764f7eae1" in namespace "e2e-tests-configmap-q7q68" to be "success or failure"
May 31 03:02:19.400: INFO: Pod "pod-configmaps-80da2834-8350-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.225534ms
May 31 03:02:21.403: INFO: Pod "pod-configmaps-80da2834-8350-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00494441s
May 31 03:02:23.405: INFO: Pod "pod-configmaps-80da2834-8350-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007750087s
STEP: Saw pod success
May 31 03:02:23.405: INFO: Pod "pod-configmaps-80da2834-8350-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:02:23.408: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod pod-configmaps-80da2834-8350-11e9-949c-223764f7eae1 container env-test: <nil>
STEP: delete the pod
May 31 03:02:23.424: INFO: Waiting for pod pod-configmaps-80da2834-8350-11e9-949c-223764f7eae1 to disappear
May 31 03:02:23.427: INFO: Pod pod-configmaps-80da2834-8350-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:02:23.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-q7q68" for this suite.
May 31 03:02:29.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:02:29.525: INFO: namespace: e2e-tests-configmap-q7q68, resource: bindings, ignored listing per whitelist
May 31 03:02:29.528: INFO: namespace e2e-tests-configmap-q7q68 deletion completed in 6.097636769s

• [SLOW TEST:10.219 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:02:29.528: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
May 31 03:02:29.602: INFO: Waiting up to 5m0s for pod "pod-86ef94e8-8350-11e9-949c-223764f7eae1" in namespace "e2e-tests-emptydir-j8pgn" to be "success or failure"
May 31 03:02:29.608: INFO: Pod "pod-86ef94e8-8350-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.045176ms
May 31 03:02:31.612: INFO: Pod "pod-86ef94e8-8350-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008619761s
May 31 03:02:33.615: INFO: Pod "pod-86ef94e8-8350-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012140844s
STEP: Saw pod success
May 31 03:02:33.615: INFO: Pod "pod-86ef94e8-8350-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:02:33.617: INFO: Trying to get logs from node k8s-linuxpool-39082607-2 pod pod-86ef94e8-8350-11e9-949c-223764f7eae1 container test-container: <nil>
STEP: delete the pod
May 31 03:02:33.635: INFO: Waiting for pod pod-86ef94e8-8350-11e9-949c-223764f7eae1 to disappear
May 31 03:02:33.637: INFO: Pod pod-86ef94e8-8350-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:02:33.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-j8pgn" for this suite.
May 31 03:02:39.647: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:02:39.725: INFO: namespace: e2e-tests-emptydir-j8pgn, resource: bindings, ignored listing per whitelist
May 31 03:02:39.759: INFO: namespace e2e-tests-emptydir-j8pgn deletion completed in 6.118947977s

• [SLOW TEST:10.231 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:02:39.759: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
May 31 03:02:39.839: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-xr77r,SelfLink:/api/v1/namespaces/e2e-tests-watch-xr77r/configmaps/e2e-watch-test-watch-closed,UID:8d095ea9-8350-11e9-944d-001dd80c001b,ResourceVersion:10506,Generation:0,CreationTimestamp:2019-05-31 03:02:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 31 03:02:39.840: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-xr77r,SelfLink:/api/v1/namespaces/e2e-tests-watch-xr77r/configmaps/e2e-watch-test-watch-closed,UID:8d095ea9-8350-11e9-944d-001dd80c001b,ResourceVersion:10507,Generation:0,CreationTimestamp:2019-05-31 03:02:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
May 31 03:02:39.850: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-xr77r,SelfLink:/api/v1/namespaces/e2e-tests-watch-xr77r/configmaps/e2e-watch-test-watch-closed,UID:8d095ea9-8350-11e9-944d-001dd80c001b,ResourceVersion:10508,Generation:0,CreationTimestamp:2019-05-31 03:02:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 31 03:02:39.850: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-xr77r,SelfLink:/api/v1/namespaces/e2e-tests-watch-xr77r/configmaps/e2e-watch-test-watch-closed,UID:8d095ea9-8350-11e9-944d-001dd80c001b,ResourceVersion:10509,Generation:0,CreationTimestamp:2019-05-31 03:02:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:02:39.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-xr77r" for this suite.
May 31 03:02:45.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:02:45.898: INFO: namespace: e2e-tests-watch-xr77r, resource: bindings, ignored listing per whitelist
May 31 03:02:45.939: INFO: namespace e2e-tests-watch-xr77r deletion completed in 6.085965072s

• [SLOW TEST:6.180 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:02:45.939: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-90b77259-8350-11e9-949c-223764f7eae1
STEP: Creating a pod to test consume secrets
May 31 03:02:46.017: INFO: Waiting up to 5m0s for pod "pod-secrets-90b7f86d-8350-11e9-949c-223764f7eae1" in namespace "e2e-tests-secrets-p86cx" to be "success or failure"
May 31 03:02:46.027: INFO: Pod "pod-secrets-90b7f86d-8350-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.085052ms
May 31 03:02:48.030: INFO: Pod "pod-secrets-90b7f86d-8350-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012635914s
May 31 03:02:50.032: INFO: Pod "pod-secrets-90b7f86d-8350-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015169675s
STEP: Saw pod success
May 31 03:02:50.032: INFO: Pod "pod-secrets-90b7f86d-8350-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:02:50.034: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod pod-secrets-90b7f86d-8350-11e9-949c-223764f7eae1 container secret-volume-test: <nil>
STEP: delete the pod
May 31 03:02:50.048: INFO: Waiting for pod pod-secrets-90b7f86d-8350-11e9-949c-223764f7eae1 to disappear
May 31 03:02:50.052: INFO: Pod pod-secrets-90b7f86d-8350-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:02:50.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-p86cx" for this suite.
May 31 03:02:56.068: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:02:56.151: INFO: namespace: e2e-tests-secrets-p86cx, resource: bindings, ignored listing per whitelist
May 31 03:02:56.189: INFO: namespace e2e-tests-secrets-p86cx deletion completed in 6.133365172s

• [SLOW TEST:10.249 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:02:56.189: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
May 31 03:02:56.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 create -f - --namespace=e2e-tests-kubectl-h44pj'
May 31 03:02:56.566: INFO: stderr: ""
May 31 03:02:56.566: INFO: stdout: "pod/pause created\n"
May 31 03:02:56.566: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
May 31 03:02:56.566: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-h44pj" to be "running and ready"
May 31 03:02:56.571: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 4.278365ms
May 31 03:02:58.573: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007062026s
May 31 03:03:00.576: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.009352579s
May 31 03:03:00.576: INFO: Pod "pause" satisfied condition "running and ready"
May 31 03:03:00.576: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
May 31 03:03:00.576: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-h44pj'
May 31 03:03:00.667: INFO: stderr: ""
May 31 03:03:00.667: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
May 31 03:03:00.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pod pause -L testing-label --namespace=e2e-tests-kubectl-h44pj'
May 31 03:03:00.758: INFO: stderr: ""
May 31 03:03:00.758: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
May 31 03:03:00.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 label pods pause testing-label- --namespace=e2e-tests-kubectl-h44pj'
May 31 03:03:00.870: INFO: stderr: ""
May 31 03:03:00.870: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
May 31 03:03:00.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pod pause -L testing-label --namespace=e2e-tests-kubectl-h44pj'
May 31 03:03:00.964: INFO: stderr: ""
May 31 03:03:00.964: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
May 31 03:03:00.964: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-h44pj'
May 31 03:03:01.053: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 31 03:03:01.053: INFO: stdout: "pod \"pause\" force deleted\n"
May 31 03:03:01.053: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-h44pj'
May 31 03:03:01.190: INFO: stderr: "No resources found.\n"
May 31 03:03:01.190: INFO: stdout: ""
May 31 03:03:01.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods -l name=pause --namespace=e2e-tests-kubectl-h44pj -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 31 03:03:01.290: INFO: stderr: ""
May 31 03:03:01.290: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:03:01.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-h44pj" for this suite.
May 31 03:03:07.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:03:07.345: INFO: namespace: e2e-tests-kubectl-h44pj, resource: bindings, ignored listing per whitelist
May 31 03:03:07.373: INFO: namespace e2e-tests-kubectl-h44pj deletion completed in 6.080080156s

• [SLOW TEST:11.184 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:03:07.373: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 31 03:03:07.453: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9d7f0f40-8350-11e9-949c-223764f7eae1" in namespace "e2e-tests-projected-dqzhc" to be "success or failure"
May 31 03:03:07.457: INFO: Pod "downwardapi-volume-9d7f0f40-8350-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.30805ms
May 31 03:03:09.461: INFO: Pod "downwardapi-volume-9d7f0f40-8350-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007033721s
May 31 03:03:11.463: INFO: Pod "downwardapi-volume-9d7f0f40-8350-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009874078s
STEP: Saw pod success
May 31 03:03:11.463: INFO: Pod "downwardapi-volume-9d7f0f40-8350-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:03:11.466: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod downwardapi-volume-9d7f0f40-8350-11e9-949c-223764f7eae1 container client-container: <nil>
STEP: delete the pod
May 31 03:03:11.486: INFO: Waiting for pod downwardapi-volume-9d7f0f40-8350-11e9-949c-223764f7eae1 to disappear
May 31 03:03:11.487: INFO: Pod downwardapi-volume-9d7f0f40-8350-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:03:11.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dqzhc" for this suite.
May 31 03:03:17.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:03:17.573: INFO: namespace: e2e-tests-projected-dqzhc, resource: bindings, ignored listing per whitelist
May 31 03:03:17.577: INFO: namespace e2e-tests-projected-dqzhc deletion completed in 6.087504255s

• [SLOW TEST:10.204 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:03:17.577: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
May 31 03:03:17.700: INFO: Waiting up to 5m0s for pod "downward-api-a399f98e-8350-11e9-949c-223764f7eae1" in namespace "e2e-tests-downward-api-c4mhw" to be "success or failure"
May 31 03:03:17.706: INFO: Pod "downward-api-a399f98e-8350-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.697401ms
May 31 03:03:19.709: INFO: Pod "downward-api-a399f98e-8350-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009568655s
May 31 03:03:21.712: INFO: Pod "downward-api-a399f98e-8350-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012655712s
STEP: Saw pod success
May 31 03:03:21.712: INFO: Pod "downward-api-a399f98e-8350-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:03:21.715: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod downward-api-a399f98e-8350-11e9-949c-223764f7eae1 container dapi-container: <nil>
STEP: delete the pod
May 31 03:03:21.743: INFO: Waiting for pod downward-api-a399f98e-8350-11e9-949c-223764f7eae1 to disappear
May 31 03:03:21.746: INFO: Pod downward-api-a399f98e-8350-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:03:21.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-c4mhw" for this suite.
May 31 03:03:27.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:03:27.785: INFO: namespace: e2e-tests-downward-api-c4mhw, resource: bindings, ignored listing per whitelist
May 31 03:03:27.833: INFO: namespace e2e-tests-downward-api-c4mhw deletion completed in 6.0847133s

• [SLOW TEST:10.256 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:03:27.834: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 31 03:03:27.914: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
May 31 03:03:27.922: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 03:03:27.924: INFO: Number of nodes with available pods: 0
May 31 03:03:27.925: INFO: Node k8s-linuxpool-39082607-0 is running more than one daemon pod
May 31 03:03:28.928: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 03:03:28.932: INFO: Number of nodes with available pods: 0
May 31 03:03:28.932: INFO: Node k8s-linuxpool-39082607-0 is running more than one daemon pod
May 31 03:03:29.929: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 03:03:29.932: INFO: Number of nodes with available pods: 0
May 31 03:03:29.932: INFO: Node k8s-linuxpool-39082607-0 is running more than one daemon pod
May 31 03:03:30.929: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 03:03:30.932: INFO: Number of nodes with available pods: 3
May 31 03:03:30.932: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
May 31 03:03:30.964: INFO: Wrong image for pod: daemon-set-mc2mq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:30.964: INFO: Wrong image for pod: daemon-set-w7864. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:30.964: INFO: Wrong image for pod: daemon-set-xtl2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:30.973: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 03:03:31.986: INFO: Wrong image for pod: daemon-set-mc2mq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:31.987: INFO: Wrong image for pod: daemon-set-w7864. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:31.987: INFO: Wrong image for pod: daemon-set-xtl2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:31.989: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 03:03:32.977: INFO: Wrong image for pod: daemon-set-mc2mq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:32.977: INFO: Wrong image for pod: daemon-set-w7864. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:32.977: INFO: Wrong image for pod: daemon-set-xtl2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:32.981: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 03:03:33.977: INFO: Wrong image for pod: daemon-set-mc2mq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:33.977: INFO: Wrong image for pod: daemon-set-w7864. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:33.977: INFO: Pod daemon-set-w7864 is not available
May 31 03:03:33.977: INFO: Wrong image for pod: daemon-set-xtl2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:33.980: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 03:03:34.978: INFO: Wrong image for pod: daemon-set-mc2mq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:34.978: INFO: Wrong image for pod: daemon-set-w7864. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:34.978: INFO: Pod daemon-set-w7864 is not available
May 31 03:03:34.978: INFO: Wrong image for pod: daemon-set-xtl2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:34.981: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 03:03:35.978: INFO: Wrong image for pod: daemon-set-mc2mq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:35.978: INFO: Wrong image for pod: daemon-set-w7864. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:35.978: INFO: Pod daemon-set-w7864 is not available
May 31 03:03:35.978: INFO: Wrong image for pod: daemon-set-xtl2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:35.981: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 03:03:36.978: INFO: Wrong image for pod: daemon-set-mc2mq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:36.978: INFO: Wrong image for pod: daemon-set-w7864. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:36.978: INFO: Pod daemon-set-w7864 is not available
May 31 03:03:36.978: INFO: Wrong image for pod: daemon-set-xtl2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:36.981: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 03:03:37.979: INFO: Wrong image for pod: daemon-set-mc2mq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:37.979: INFO: Wrong image for pod: daemon-set-w7864. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:37.979: INFO: Pod daemon-set-w7864 is not available
May 31 03:03:37.979: INFO: Wrong image for pod: daemon-set-xtl2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:37.981: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 03:03:38.978: INFO: Wrong image for pod: daemon-set-mc2mq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:38.978: INFO: Wrong image for pod: daemon-set-w7864. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:38.978: INFO: Pod daemon-set-w7864 is not available
May 31 03:03:38.978: INFO: Wrong image for pod: daemon-set-xtl2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:38.982: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 03:03:39.977: INFO: Wrong image for pod: daemon-set-mc2mq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:39.977: INFO: Wrong image for pod: daemon-set-w7864. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:39.977: INFO: Pod daemon-set-w7864 is not available
May 31 03:03:39.977: INFO: Wrong image for pod: daemon-set-xtl2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:39.981: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 03:03:40.978: INFO: Wrong image for pod: daemon-set-mc2mq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:40.978: INFO: Wrong image for pod: daemon-set-w7864. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:40.978: INFO: Pod daemon-set-w7864 is not available
May 31 03:03:40.978: INFO: Wrong image for pod: daemon-set-xtl2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:40.984: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 03:03:41.977: INFO: Wrong image for pod: daemon-set-mc2mq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:41.977: INFO: Wrong image for pod: daemon-set-w7864. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:41.978: INFO: Pod daemon-set-w7864 is not available
May 31 03:03:41.978: INFO: Wrong image for pod: daemon-set-xtl2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:41.980: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 03:03:42.978: INFO: Wrong image for pod: daemon-set-mc2mq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:42.978: INFO: Wrong image for pod: daemon-set-w7864. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:42.978: INFO: Pod daemon-set-w7864 is not available
May 31 03:03:42.978: INFO: Wrong image for pod: daemon-set-xtl2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:42.981: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 03:03:43.977: INFO: Wrong image for pod: daemon-set-mc2mq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:43.978: INFO: Wrong image for pod: daemon-set-w7864. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:43.978: INFO: Pod daemon-set-w7864 is not available
May 31 03:03:43.978: INFO: Wrong image for pod: daemon-set-xtl2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:43.980: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 03:03:44.978: INFO: Wrong image for pod: daemon-set-mc2mq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:44.978: INFO: Wrong image for pod: daemon-set-w7864. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:44.978: INFO: Pod daemon-set-w7864 is not available
May 31 03:03:44.978: INFO: Wrong image for pod: daemon-set-xtl2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:44.980: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 03:03:45.977: INFO: Pod daemon-set-7lxdj is not available
May 31 03:03:45.978: INFO: Wrong image for pod: daemon-set-mc2mq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:45.978: INFO: Wrong image for pod: daemon-set-xtl2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:45.980: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 03:03:46.978: INFO: Pod daemon-set-7lxdj is not available
May 31 03:03:46.978: INFO: Wrong image for pod: daemon-set-mc2mq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:46.978: INFO: Wrong image for pod: daemon-set-xtl2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:46.981: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 03:03:47.977: INFO: Pod daemon-set-7lxdj is not available
May 31 03:03:47.977: INFO: Wrong image for pod: daemon-set-mc2mq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:47.977: INFO: Wrong image for pod: daemon-set-xtl2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:47.980: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 03:03:48.977: INFO: Wrong image for pod: daemon-set-mc2mq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:48.977: INFO: Wrong image for pod: daemon-set-xtl2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:48.981: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 03:03:49.977: INFO: Wrong image for pod: daemon-set-mc2mq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:49.978: INFO: Wrong image for pod: daemon-set-xtl2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:49.981: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 03:03:50.977: INFO: Wrong image for pod: daemon-set-mc2mq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:50.978: INFO: Wrong image for pod: daemon-set-xtl2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:50.978: INFO: Pod daemon-set-xtl2z is not available
May 31 03:03:50.981: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 03:03:51.978: INFO: Wrong image for pod: daemon-set-mc2mq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:51.978: INFO: Wrong image for pod: daemon-set-xtl2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:51.978: INFO: Pod daemon-set-xtl2z is not available
May 31 03:03:51.981: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 03:03:52.978: INFO: Wrong image for pod: daemon-set-mc2mq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:52.978: INFO: Wrong image for pod: daemon-set-xtl2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:52.978: INFO: Pod daemon-set-xtl2z is not available
May 31 03:03:52.981: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 03:03:53.980: INFO: Wrong image for pod: daemon-set-mc2mq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:53.980: INFO: Wrong image for pod: daemon-set-xtl2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:53.980: INFO: Pod daemon-set-xtl2z is not available
May 31 03:03:53.986: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 03:03:54.981: INFO: Wrong image for pod: daemon-set-mc2mq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:54.981: INFO: Wrong image for pod: daemon-set-xtl2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:54.981: INFO: Pod daemon-set-xtl2z is not available
May 31 03:03:54.989: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 03:03:55.978: INFO: Wrong image for pod: daemon-set-mc2mq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:55.978: INFO: Wrong image for pod: daemon-set-xtl2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:55.978: INFO: Pod daemon-set-xtl2z is not available
May 31 03:03:55.980: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 03:03:56.977: INFO: Wrong image for pod: daemon-set-mc2mq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:56.977: INFO: Wrong image for pod: daemon-set-xtl2z. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:56.977: INFO: Pod daemon-set-xtl2z is not available
May 31 03:03:56.980: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 03:03:57.977: INFO: Pod daemon-set-m8dz5 is not available
May 31 03:03:57.977: INFO: Wrong image for pod: daemon-set-mc2mq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:57.981: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 03:03:58.977: INFO: Pod daemon-set-m8dz5 is not available
May 31 03:03:58.978: INFO: Wrong image for pod: daemon-set-mc2mq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:58.980: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 03:03:59.977: INFO: Pod daemon-set-m8dz5 is not available
May 31 03:03:59.977: INFO: Wrong image for pod: daemon-set-mc2mq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:03:59.980: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 03:04:00.977: INFO: Wrong image for pod: daemon-set-mc2mq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:04:00.977: INFO: Pod daemon-set-mc2mq is not available
May 31 03:04:00.980: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 03:04:01.985: INFO: Wrong image for pod: daemon-set-mc2mq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 31 03:04:01.985: INFO: Pod daemon-set-mc2mq is not available
May 31 03:04:01.990: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 03:04:02.978: INFO: Pod daemon-set-sn7fk is not available
May 31 03:04:02.981: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
May 31 03:04:02.984: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 03:04:02.987: INFO: Number of nodes with available pods: 2
May 31 03:04:02.988: INFO: Node k8s-linuxpool-39082607-2 is running more than one daemon pod
May 31 03:04:03.991: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 03:04:03.994: INFO: Number of nodes with available pods: 2
May 31 03:04:03.994: INFO: Node k8s-linuxpool-39082607-2 is running more than one daemon pod
May 31 03:04:04.991: INFO: DaemonSet pods can't tolerate node k8s-master-39082607-0 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 31 03:04:04.994: INFO: Number of nodes with available pods: 3
May 31 03:04:04.994: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-k4wgj, will wait for the garbage collector to delete the pods
May 31 03:04:05.065: INFO: Deleting DaemonSet.extensions daemon-set took: 7.066306ms
May 31 03:04:05.166: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.278609ms
May 31 03:04:17.768: INFO: Number of nodes with available pods: 0
May 31 03:04:17.768: INFO: Number of running nodes: 0, number of available pods: 0
May 31 03:04:17.770: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-k4wgj/daemonsets","resourceVersion":"10888"},"items":null}

May 31 03:04:17.772: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-k4wgj/pods","resourceVersion":"10888"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:04:17.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-k4wgj" for this suite.
May 31 03:04:23.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:04:23.830: INFO: namespace: e2e-tests-daemonsets-k4wgj, resource: bindings, ignored listing per whitelist
May 31 03:04:23.870: INFO: namespace e2e-tests-daemonsets-k4wgj deletion completed in 6.086136458s

• [SLOW TEST:56.037 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:04:23.871: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 31 03:04:27.974: INFO: Waiting up to 5m0s for pod "client-envvars-cd7dae24-8350-11e9-949c-223764f7eae1" in namespace "e2e-tests-pods-t2t6j" to be "success or failure"
May 31 03:04:27.982: INFO: Pod "client-envvars-cd7dae24-8350-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 7.129307ms
May 31 03:04:29.987: INFO: Pod "client-envvars-cd7dae24-8350-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012582674s
May 31 03:04:31.990: INFO: Pod "client-envvars-cd7dae24-8350-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015018294s
STEP: Saw pod success
May 31 03:04:31.990: INFO: Pod "client-envvars-cd7dae24-8350-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:04:31.992: INFO: Trying to get logs from node k8s-linuxpool-39082607-2 pod client-envvars-cd7dae24-8350-11e9-949c-223764f7eae1 container env3cont: <nil>
STEP: delete the pod
May 31 03:04:32.012: INFO: Waiting for pod client-envvars-cd7dae24-8350-11e9-949c-223764f7eae1 to disappear
May 31 03:04:32.014: INFO: Pod client-envvars-cd7dae24-8350-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:04:32.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-t2t6j" for this suite.
May 31 03:05:12.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:05:12.060: INFO: namespace: e2e-tests-pods-t2t6j, resource: bindings, ignored listing per whitelist
May 31 03:05:12.103: INFO: namespace e2e-tests-pods-t2t6j deletion completed in 40.086190635s

• [SLOW TEST:48.233 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:05:12.103: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
May 31 03:05:12.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 create -f - --namespace=e2e-tests-kubectl-bmh4l'
May 31 03:05:12.789: INFO: stderr: ""
May 31 03:05:12.789: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 31 03:05:12.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bmh4l'
May 31 03:05:12.905: INFO: stderr: ""
May 31 03:05:12.905: INFO: stdout: "update-demo-nautilus-hv4bx update-demo-nautilus-jqpbd "
May 31 03:05:12.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods update-demo-nautilus-hv4bx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bmh4l'
May 31 03:05:12.998: INFO: stderr: ""
May 31 03:05:12.998: INFO: stdout: ""
May 31 03:05:12.998: INFO: update-demo-nautilus-hv4bx is created but not running
May 31 03:05:17.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bmh4l'
May 31 03:05:18.088: INFO: stderr: ""
May 31 03:05:18.088: INFO: stdout: "update-demo-nautilus-hv4bx update-demo-nautilus-jqpbd "
May 31 03:05:18.088: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods update-demo-nautilus-hv4bx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bmh4l'
May 31 03:05:18.177: INFO: stderr: ""
May 31 03:05:18.177: INFO: stdout: "true"
May 31 03:05:18.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods update-demo-nautilus-hv4bx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bmh4l'
May 31 03:05:18.258: INFO: stderr: ""
May 31 03:05:18.258: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 31 03:05:18.258: INFO: validating pod update-demo-nautilus-hv4bx
May 31 03:05:18.262: INFO: got data: {
  "image": "nautilus.jpg"
}

May 31 03:05:18.262: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 31 03:05:18.262: INFO: update-demo-nautilus-hv4bx is verified up and running
May 31 03:05:18.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods update-demo-nautilus-jqpbd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bmh4l'
May 31 03:05:18.356: INFO: stderr: ""
May 31 03:05:18.356: INFO: stdout: "true"
May 31 03:05:18.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods update-demo-nautilus-jqpbd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bmh4l'
May 31 03:05:18.446: INFO: stderr: ""
May 31 03:05:18.446: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 31 03:05:18.446: INFO: validating pod update-demo-nautilus-jqpbd
May 31 03:05:18.450: INFO: got data: {
  "image": "nautilus.jpg"
}

May 31 03:05:18.450: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 31 03:05:18.450: INFO: update-demo-nautilus-jqpbd is verified up and running
STEP: scaling down the replication controller
May 31 03:05:18.451: INFO: scanned /root for discovery docs: <nil>
May 31 03:05:18.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-bmh4l'
May 31 03:05:19.569: INFO: stderr: ""
May 31 03:05:19.569: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 31 03:05:19.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bmh4l'
May 31 03:05:19.663: INFO: stderr: ""
May 31 03:05:19.663: INFO: stdout: "update-demo-nautilus-hv4bx update-demo-nautilus-jqpbd "
STEP: Replicas for name=update-demo: expected=1 actual=2
May 31 03:05:24.663: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bmh4l'
May 31 03:05:24.757: INFO: stderr: ""
May 31 03:05:24.757: INFO: stdout: "update-demo-nautilus-hv4bx "
May 31 03:05:24.757: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods update-demo-nautilus-hv4bx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bmh4l'
May 31 03:05:24.858: INFO: stderr: ""
May 31 03:05:24.858: INFO: stdout: "true"
May 31 03:05:24.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods update-demo-nautilus-hv4bx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bmh4l'
May 31 03:05:24.943: INFO: stderr: ""
May 31 03:05:24.943: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 31 03:05:24.943: INFO: validating pod update-demo-nautilus-hv4bx
May 31 03:05:24.947: INFO: got data: {
  "image": "nautilus.jpg"
}

May 31 03:05:24.947: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 31 03:05:24.947: INFO: update-demo-nautilus-hv4bx is verified up and running
STEP: scaling up the replication controller
May 31 03:05:24.948: INFO: scanned /root for discovery docs: <nil>
May 31 03:05:24.948: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-bmh4l'
May 31 03:05:26.067: INFO: stderr: ""
May 31 03:05:26.067: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 31 03:05:26.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bmh4l'
May 31 03:05:26.160: INFO: stderr: ""
May 31 03:05:26.160: INFO: stdout: "update-demo-nautilus-hv4bx update-demo-nautilus-vrhs2 "
May 31 03:05:26.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods update-demo-nautilus-hv4bx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bmh4l'
May 31 03:05:26.251: INFO: stderr: ""
May 31 03:05:26.251: INFO: stdout: "true"
May 31 03:05:26.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods update-demo-nautilus-hv4bx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bmh4l'
May 31 03:05:26.343: INFO: stderr: ""
May 31 03:05:26.343: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 31 03:05:26.343: INFO: validating pod update-demo-nautilus-hv4bx
May 31 03:05:26.345: INFO: got data: {
  "image": "nautilus.jpg"
}

May 31 03:05:26.346: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 31 03:05:26.346: INFO: update-demo-nautilus-hv4bx is verified up and running
May 31 03:05:26.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods update-demo-nautilus-vrhs2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bmh4l'
May 31 03:05:26.429: INFO: stderr: ""
May 31 03:05:26.429: INFO: stdout: ""
May 31 03:05:26.429: INFO: update-demo-nautilus-vrhs2 is created but not running
May 31 03:05:31.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bmh4l'
May 31 03:05:31.542: INFO: stderr: ""
May 31 03:05:31.542: INFO: stdout: "update-demo-nautilus-hv4bx update-demo-nautilus-vrhs2 "
May 31 03:05:31.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods update-demo-nautilus-hv4bx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bmh4l'
May 31 03:05:31.637: INFO: stderr: ""
May 31 03:05:31.637: INFO: stdout: "true"
May 31 03:05:31.637: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods update-demo-nautilus-hv4bx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bmh4l'
May 31 03:05:31.728: INFO: stderr: ""
May 31 03:05:31.728: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 31 03:05:31.728: INFO: validating pod update-demo-nautilus-hv4bx
May 31 03:05:31.731: INFO: got data: {
  "image": "nautilus.jpg"
}

May 31 03:05:31.731: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 31 03:05:31.731: INFO: update-demo-nautilus-hv4bx is verified up and running
May 31 03:05:31.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods update-demo-nautilus-vrhs2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bmh4l'
May 31 03:05:31.814: INFO: stderr: ""
May 31 03:05:31.814: INFO: stdout: "true"
May 31 03:05:31.814: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods update-demo-nautilus-vrhs2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bmh4l'
May 31 03:05:31.895: INFO: stderr: ""
May 31 03:05:31.895: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 31 03:05:31.895: INFO: validating pod update-demo-nautilus-vrhs2
May 31 03:05:31.899: INFO: got data: {
  "image": "nautilus.jpg"
}

May 31 03:05:31.899: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 31 03:05:31.899: INFO: update-demo-nautilus-vrhs2 is verified up and running
STEP: using delete to clean up resources
May 31 03:05:31.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-bmh4l'
May 31 03:05:31.993: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 31 03:05:31.993: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May 31 03:05:31.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-bmh4l'
May 31 03:05:32.093: INFO: stderr: "No resources found.\n"
May 31 03:05:32.093: INFO: stdout: ""
May 31 03:05:32.093: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods -l name=update-demo --namespace=e2e-tests-kubectl-bmh4l -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 31 03:05:32.198: INFO: stderr: ""
May 31 03:05:32.198: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:05:32.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bmh4l" for this suite.
May 31 03:05:54.208: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:05:54.270: INFO: namespace: e2e-tests-kubectl-bmh4l, resource: bindings, ignored listing per whitelist
May 31 03:05:54.286: INFO: namespace e2e-tests-kubectl-bmh4l deletion completed in 22.085003346s

• [SLOW TEST:42.183 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:05:54.288: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
May 31 03:05:54.361: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:05:58.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-mrqgj" for this suite.
May 31 03:06:04.968: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:06:05.022: INFO: namespace: e2e-tests-init-container-mrqgj, resource: bindings, ignored listing per whitelist
May 31 03:06:05.058: INFO: namespace e2e-tests-init-container-mrqgj deletion completed in 6.098376944s

• [SLOW TEST:10.770 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:06:05.059: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
May 31 03:06:05.143: INFO: Waiting up to 5m0s for pod "var-expansion-07681b74-8351-11e9-949c-223764f7eae1" in namespace "e2e-tests-var-expansion-87mg4" to be "success or failure"
May 31 03:06:05.148: INFO: Pod "var-expansion-07681b74-8351-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.843873ms
May 31 03:06:07.151: INFO: Pod "var-expansion-07681b74-8351-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007864572s
May 31 03:06:09.154: INFO: Pod "var-expansion-07681b74-8351-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01081477s
STEP: Saw pod success
May 31 03:06:09.154: INFO: Pod "var-expansion-07681b74-8351-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:06:09.157: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod var-expansion-07681b74-8351-11e9-949c-223764f7eae1 container dapi-container: <nil>
STEP: delete the pod
May 31 03:06:09.180: INFO: Waiting for pod var-expansion-07681b74-8351-11e9-949c-223764f7eae1 to disappear
May 31 03:06:09.183: INFO: Pod var-expansion-07681b74-8351-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:06:09.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-87mg4" for this suite.
May 31 03:06:15.198: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:06:15.240: INFO: namespace: e2e-tests-var-expansion-87mg4, resource: bindings, ignored listing per whitelist
May 31 03:06:15.303: INFO: namespace e2e-tests-var-expansion-87mg4 deletion completed in 6.115551494s

• [SLOW TEST:10.244 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:06:15.303: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:06:19.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-rz4x8" for this suite.
May 31 03:07:09.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:07:09.423: INFO: namespace: e2e-tests-kubelet-test-rz4x8, resource: bindings, ignored listing per whitelist
May 31 03:07:09.478: INFO: namespace e2e-tests-kubelet-test-rz4x8 deletion completed in 50.086465986s

• [SLOW TEST:54.175 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:07:09.478: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-2dcc9df7-8351-11e9-949c-223764f7eae1
STEP: Creating a pod to test consume secrets
May 31 03:07:09.560: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2dcd5d39-8351-11e9-949c-223764f7eae1" in namespace "e2e-tests-projected-v8mlc" to be "success or failure"
May 31 03:07:09.571: INFO: Pod "pod-projected-secrets-2dcd5d39-8351-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 11.526073ms
May 31 03:07:11.574: INFO: Pod "pod-projected-secrets-2dcd5d39-8351-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014515355s
May 31 03:07:13.578: INFO: Pod "pod-projected-secrets-2dcd5d39-8351-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017660738s
STEP: Saw pod success
May 31 03:07:13.578: INFO: Pod "pod-projected-secrets-2dcd5d39-8351-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:07:13.583: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod pod-projected-secrets-2dcd5d39-8351-11e9-949c-223764f7eae1 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 31 03:07:13.600: INFO: Waiting for pod pod-projected-secrets-2dcd5d39-8351-11e9-949c-223764f7eae1 to disappear
May 31 03:07:13.605: INFO: Pod pod-projected-secrets-2dcd5d39-8351-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:07:13.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-v8mlc" for this suite.
May 31 03:07:19.616: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:07:19.667: INFO: namespace: e2e-tests-projected-v8mlc, resource: bindings, ignored listing per whitelist
May 31 03:07:19.689: INFO: namespace e2e-tests-projected-v8mlc deletion completed in 6.081152924s

• [SLOW TEST:10.211 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:07:19.690: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-33e3c6e9-8351-11e9-949c-223764f7eae1
STEP: Creating a pod to test consume configMaps
May 31 03:07:19.776: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-33e422d2-8351-11e9-949c-223764f7eae1" in namespace "e2e-tests-projected-56h6m" to be "success or failure"
May 31 03:07:19.782: INFO: Pod "pod-projected-configmaps-33e422d2-8351-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.234194ms
May 31 03:07:21.812: INFO: Pod "pod-projected-configmaps-33e422d2-8351-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035853373s
May 31 03:07:23.815: INFO: Pod "pod-projected-configmaps-33e422d2-8351-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039298158s
STEP: Saw pod success
May 31 03:07:23.815: INFO: Pod "pod-projected-configmaps-33e422d2-8351-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:07:23.818: INFO: Trying to get logs from node k8s-linuxpool-39082607-2 pod pod-projected-configmaps-33e422d2-8351-11e9-949c-223764f7eae1 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 31 03:07:23.834: INFO: Waiting for pod pod-projected-configmaps-33e422d2-8351-11e9-949c-223764f7eae1 to disappear
May 31 03:07:23.837: INFO: Pod pod-projected-configmaps-33e422d2-8351-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:07:23.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-56h6m" for this suite.
May 31 03:07:29.847: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:07:29.906: INFO: namespace: e2e-tests-projected-56h6m, resource: bindings, ignored listing per whitelist
May 31 03:07:29.926: INFO: namespace e2e-tests-projected-56h6m deletion completed in 6.086123291s

• [SLOW TEST:10.236 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:07:29.926: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 31 03:07:30.004: INFO: Creating deployment "nginx-deployment"
May 31 03:07:30.009: INFO: Waiting for observed generation 1
May 31 03:07:32.016: INFO: Waiting for all required pods to come up
May 31 03:07:32.019: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
May 31 03:07:36.034: INFO: Waiting for deployment "nginx-deployment" to complete
May 31 03:07:36.038: INFO: Updating deployment "nginx-deployment" with a non-existent image
May 31 03:07:36.043: INFO: Updating deployment nginx-deployment
May 31 03:07:36.043: INFO: Waiting for observed generation 2
May 31 03:07:38.048: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
May 31 03:07:38.050: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
May 31 03:07:38.052: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
May 31 03:07:38.058: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
May 31 03:07:38.058: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
May 31 03:07:38.060: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
May 31 03:07:38.064: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
May 31 03:07:38.064: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
May 31 03:07:38.069: INFO: Updating deployment nginx-deployment
May 31 03:07:38.069: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
May 31 03:07:38.080: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
May 31 03:07:38.085: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 31 03:07:38.112: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-xp446,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-xp446/deployments/nginx-deployment,UID:39fe1715-8351-11e9-944d-001dd80c001b,ResourceVersion:11698,Generation:3,CreationTimestamp:2019-05-31 03:07:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Progressing True 2019-05-31 03:07:36 +0000 UTC 2019-05-31 03:07:30 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.} {Available False 2019-05-31 03:07:38 +0000 UTC 2019-05-31 03:07:38 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

May 31 03:07:38.115: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-xp446,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-xp446/replicasets/nginx-deployment-65bbdb5f8,UID:3d9799cb-8351-11e9-944d-001dd80c001b,ResourceVersion:11692,Generation:3,CreationTimestamp:2019-05-31 03:07:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 39fe1715-8351-11e9-944d-001dd80c001b 0xc00360c727 0xc00360c728}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 31 03:07:38.115: INFO: All old ReplicaSets of Deployment "nginx-deployment":
May 31 03:07:38.115: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-xp446,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-xp446/replicasets/nginx-deployment-555b55d965,UID:39ff6432-8351-11e9-944d-001dd80c001b,ResourceVersion:11690,Generation:3,CreationTimestamp:2019-05-31 03:07:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 39fe1715-8351-11e9-944d-001dd80c001b 0xc00360c667 0xc00360c668}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
May 31 03:07:38.142: INFO: Pod "nginx-deployment-555b55d965-22k2b" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-22k2b,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xp446,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xp446/pods/nginx-deployment-555b55d965-22k2b,UID:3a051c10-8351-11e9-944d-001dd80c001b,ResourceVersion:11613,Generation:0,CreationTimestamp:2019-05-31 03:07:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 39ff6432-8351-11e9-944d-001dd80c001b 0xc00360d077 0xc00360d078}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4mkqq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4mkqq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4mkqq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-linuxpool-39082607-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00360d0e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00360d100}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:30 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:33 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:33 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:30 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.6,PodIP:10.244.0.66,StartTime:2019-05-31 03:07:30 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-31 03:07:33 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://efb177f16f7ffdd7d3620b2e02c6e55c3f096f3b98b8b14f0b7e143e8ab17f9d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 31 03:07:38.142: INFO: Pod "nginx-deployment-555b55d965-2z5kh" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-2z5kh,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xp446,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xp446/pods/nginx-deployment-555b55d965-2z5kh,UID:3a08fd08-8351-11e9-944d-001dd80c001b,ResourceVersion:11619,Generation:0,CreationTimestamp:2019-05-31 03:07:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 39ff6432-8351-11e9-944d-001dd80c001b 0xc00360d1c0 0xc00360d1c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4mkqq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4mkqq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4mkqq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-linuxpool-39082607-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00360d220} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00360d240}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:30 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:33 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:33 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:30 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.4,PodIP:10.244.3.104,StartTime:2019-05-31 03:07:30 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-31 03:07:33 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://ce7a7b92e7700ebdfb0b3d4d56c0440fd4c4ec317ffaff3c28229e83e3086ef1}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 31 03:07:38.142: INFO: Pod "nginx-deployment-555b55d965-8kvqq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-8kvqq,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xp446,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xp446/pods/nginx-deployment-555b55d965-8kvqq,UID:3ecf9984-8351-11e9-944d-001dd80c001b,ResourceVersion:11701,Generation:0,CreationTimestamp:2019-05-31 03:07:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 39ff6432-8351-11e9-944d-001dd80c001b 0xc00360d300 0xc00360d301}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4mkqq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4mkqq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4mkqq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-linuxpool-39082607-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00360d360} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00360d380}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:38 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 31 03:07:38.143: INFO: Pod "nginx-deployment-555b55d965-8lr62" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-8lr62,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xp446,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xp446/pods/nginx-deployment-555b55d965-8lr62,UID:3a093e39-8351-11e9-944d-001dd80c001b,ResourceVersion:11590,Generation:0,CreationTimestamp:2019-05-31 03:07:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 39ff6432-8351-11e9-944d-001dd80c001b 0xc00360d3f0 0xc00360d3f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4mkqq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4mkqq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4mkqq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-linuxpool-39082607-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00360d450} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00360d470}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:30 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:33 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:33 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:30 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.5,PodIP:10.244.1.25,StartTime:2019-05-31 03:07:30 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-31 03:07:33 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://8ca7e159c18be6b78d19cf725a55bcfe962ae93216772d3d9eec80b0a89a3838}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 31 03:07:38.143: INFO: Pod "nginx-deployment-555b55d965-9cqsc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-9cqsc,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xp446,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xp446/pods/nginx-deployment-555b55d965-9cqsc,UID:3ecf8b98-8351-11e9-944d-001dd80c001b,ResourceVersion:11704,Generation:0,CreationTimestamp:2019-05-31 03:07:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 39ff6432-8351-11e9-944d-001dd80c001b 0xc00360d530 0xc00360d531}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4mkqq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4mkqq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4mkqq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-linuxpool-39082607-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00360d590} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00360d5b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:38 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 31 03:07:38.143: INFO: Pod "nginx-deployment-555b55d965-9wr7h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-9wr7h,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xp446,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xp446/pods/nginx-deployment-555b55d965-9wr7h,UID:3ed27d1c-8351-11e9-944d-001dd80c001b,ResourceVersion:11711,Generation:0,CreationTimestamp:2019-05-31 03:07:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 39ff6432-8351-11e9-944d-001dd80c001b 0xc00360d620 0xc00360d621}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4mkqq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4mkqq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4mkqq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00360d680} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00360d6a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 31 03:07:38.144: INFO: Pod "nginx-deployment-555b55d965-blccq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-blccq,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xp446,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xp446/pods/nginx-deployment-555b55d965-blccq,UID:3a05106b-8351-11e9-944d-001dd80c001b,ResourceVersion:11592,Generation:0,CreationTimestamp:2019-05-31 03:07:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 39ff6432-8351-11e9-944d-001dd80c001b 0xc00360d6f7 0xc00360d6f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4mkqq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4mkqq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4mkqq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-linuxpool-39082607-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00360d760} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00360d780}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:30 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:33 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:33 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:30 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.5,PodIP:10.244.1.24,StartTime:2019-05-31 03:07:30 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-31 03:07:32 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://ceba2810b3684e3a7c6a547c33ddba108caf71c56e2a672d2e57abda6acc2ad9}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 31 03:07:38.145: INFO: Pod "nginx-deployment-555b55d965-j92kb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-j92kb,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xp446,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xp446/pods/nginx-deployment-555b55d965-j92kb,UID:3a0258c8-8351-11e9-944d-001dd80c001b,ResourceVersion:11610,Generation:0,CreationTimestamp:2019-05-31 03:07:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 39ff6432-8351-11e9-944d-001dd80c001b 0xc00360d840 0xc00360d841}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4mkqq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4mkqq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4mkqq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-linuxpool-39082607-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00360d8a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00360d8c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:30 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:33 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:33 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:30 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.6,PodIP:10.244.0.67,StartTime:2019-05-31 03:07:30 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-31 03:07:33 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://eaf1872d903e0721ac12e6c80febdae56bf1d2328caba2b9403405b31d6dc4e7}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 31 03:07:38.145: INFO: Pod "nginx-deployment-555b55d965-jcrcb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-jcrcb,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xp446,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xp446/pods/nginx-deployment-555b55d965-jcrcb,UID:3ed26d99-8351-11e9-944d-001dd80c001b,ResourceVersion:11708,Generation:0,CreationTimestamp:2019-05-31 03:07:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 39ff6432-8351-11e9-944d-001dd80c001b 0xc00360d980 0xc00360d981}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4mkqq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4mkqq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4mkqq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00360d9e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00360da00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 31 03:07:38.145: INFO: Pod "nginx-deployment-555b55d965-pmw44" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-pmw44,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xp446,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xp446/pods/nginx-deployment-555b55d965-pmw44,UID:3a01672c-8351-11e9-944d-001dd80c001b,ResourceVersion:11617,Generation:0,CreationTimestamp:2019-05-31 03:07:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 39ff6432-8351-11e9-944d-001dd80c001b 0xc00360da57 0xc00360da58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4mkqq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4mkqq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4mkqq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-linuxpool-39082607-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00360dac0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00360dae0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:30 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:33 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:33 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:30 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.4,PodIP:10.244.3.102,StartTime:2019-05-31 03:07:30 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-31 03:07:33 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://4da30ddc89664f6a3869352d33f74a14bf022012f6e7a839a4e330823cd6b3a4}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 31 03:07:38.148: INFO: Pod "nginx-deployment-555b55d965-pvbzg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-pvbzg,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xp446,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xp446/pods/nginx-deployment-555b55d965-pvbzg,UID:3a02d3f6-8351-11e9-944d-001dd80c001b,ResourceVersion:11595,Generation:0,CreationTimestamp:2019-05-31 03:07:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 39ff6432-8351-11e9-944d-001dd80c001b 0xc00360dba0 0xc00360dba1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4mkqq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4mkqq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4mkqq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-linuxpool-39082607-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00360dc00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00360dc20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:30 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:33 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:33 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:30 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.5,PodIP:10.244.1.23,StartTime:2019-05-31 03:07:30 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-31 03:07:32 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://604ab0444ae8000c6b1015fcb007e0e7cd498ba328c9c0a880336f3f750f470a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 31 03:07:38.148: INFO: Pod "nginx-deployment-555b55d965-q4rhl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-q4rhl,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xp446,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xp446/pods/nginx-deployment-555b55d965-q4rhl,UID:3ecddab6-8351-11e9-944d-001dd80c001b,ResourceVersion:11696,Generation:0,CreationTimestamp:2019-05-31 03:07:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 39ff6432-8351-11e9-944d-001dd80c001b 0xc00360dce0 0xc00360dce1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4mkqq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4mkqq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4mkqq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-linuxpool-39082607-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00360dd40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00360dd60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:38 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 31 03:07:38.148: INFO: Pod "nginx-deployment-555b55d965-rwzlp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-rwzlp,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xp446,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xp446/pods/nginx-deployment-555b55d965-rwzlp,UID:3ed281ea-8351-11e9-944d-001dd80c001b,ResourceVersion:11707,Generation:0,CreationTimestamp:2019-05-31 03:07:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 39ff6432-8351-11e9-944d-001dd80c001b 0xc00360ddd0 0xc00360ddd1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4mkqq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4mkqq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4mkqq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00360de40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00360de60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 31 03:07:38.148: INFO: Pod "nginx-deployment-555b55d965-wk449" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-wk449,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xp446,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xp446/pods/nginx-deployment-555b55d965-wk449,UID:3ed25d75-8351-11e9-944d-001dd80c001b,ResourceVersion:11706,Generation:0,CreationTimestamp:2019-05-31 03:07:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 39ff6432-8351-11e9-944d-001dd80c001b 0xc00360dec7 0xc00360dec8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4mkqq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4mkqq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4mkqq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00360df30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00360df50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 31 03:07:38.148: INFO: Pod "nginx-deployment-555b55d965-zv8rq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-zv8rq,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xp446,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xp446/pods/nginx-deployment-555b55d965-zv8rq,UID:3a09307b-8351-11e9-944d-001dd80c001b,ResourceVersion:11606,Generation:0,CreationTimestamp:2019-05-31 03:07:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 39ff6432-8351-11e9-944d-001dd80c001b 0xc00360dfa7 0xc00360dfa8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4mkqq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4mkqq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4mkqq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-linuxpool-39082607-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0035a8010} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0035a8030}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:30 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:33 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:33 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:30 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.6,PodIP:10.244.0.68,StartTime:2019-05-31 03:07:30 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-31 03:07:33 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://14372669434df8f4aa68f3d6e282d9b38c23f0b7da938342e4e2237fe8062745}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 31 03:07:38.149: INFO: Pod "nginx-deployment-65bbdb5f8-4dlhp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-4dlhp,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-xp446,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xp446/pods/nginx-deployment-65bbdb5f8-4dlhp,UID:3da2388c-8351-11e9-944d-001dd80c001b,ResourceVersion:11681,Generation:0,CreationTimestamp:2019-05-31 03:07:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 3d9799cb-8351-11e9-944d-001dd80c001b 0xc0035a80f0 0xc0035a80f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4mkqq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4mkqq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4mkqq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-linuxpool-39082607-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0035a8160} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0035a8180}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:36 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.4,PodIP:,StartTime:2019-05-31 03:07:36 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 31 03:07:38.149: INFO: Pod "nginx-deployment-65bbdb5f8-4fnnp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-4fnnp,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-xp446,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xp446/pods/nginx-deployment-65bbdb5f8-4fnnp,UID:3da08478-8351-11e9-944d-001dd80c001b,ResourceVersion:11679,Generation:0,CreationTimestamp:2019-05-31 03:07:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 3d9799cb-8351-11e9-944d-001dd80c001b 0xc0035a8240 0xc0035a8241}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4mkqq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4mkqq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4mkqq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-linuxpool-39082607-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0035a82b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0035a82d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:36 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.4,PodIP:,StartTime:2019-05-31 03:07:36 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 31 03:07:38.152: INFO: Pod "nginx-deployment-65bbdb5f8-7lfl7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-7lfl7,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-xp446,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xp446/pods/nginx-deployment-65bbdb5f8-7lfl7,UID:3d98e26b-8351-11e9-944d-001dd80c001b,ResourceVersion:11656,Generation:0,CreationTimestamp:2019-05-31 03:07:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 3d9799cb-8351-11e9-944d-001dd80c001b 0xc0035a8390 0xc0035a8391}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4mkqq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4mkqq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4mkqq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-linuxpool-39082607-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0035a8400} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0035a8420}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:36 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.4,PodIP:,StartTime:2019-05-31 03:07:36 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 31 03:07:38.153: INFO: Pod "nginx-deployment-65bbdb5f8-89x89" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-89x89,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-xp446,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xp446/pods/nginx-deployment-65bbdb5f8-89x89,UID:3ed2793e-8351-11e9-944d-001dd80c001b,ResourceVersion:11710,Generation:0,CreationTimestamp:2019-05-31 03:07:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 3d9799cb-8351-11e9-944d-001dd80c001b 0xc0035a84e0 0xc0035a84e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4mkqq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4mkqq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4mkqq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0035a8550} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0035a8570}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 31 03:07:38.153: INFO: Pod "nginx-deployment-65bbdb5f8-mghb2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-mghb2,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-xp446,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xp446/pods/nginx-deployment-65bbdb5f8-mghb2,UID:3d99e6ea-8351-11e9-944d-001dd80c001b,ResourceVersion:11662,Generation:0,CreationTimestamp:2019-05-31 03:07:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 3d9799cb-8351-11e9-944d-001dd80c001b 0xc0035a85c7 0xc0035a85c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4mkqq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4mkqq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4mkqq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-linuxpool-39082607-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0035a8630} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0035a8650}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:36 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.6,PodIP:,StartTime:2019-05-31 03:07:36 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 31 03:07:38.153: INFO: Pod "nginx-deployment-65bbdb5f8-tdm8t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-tdm8t,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-xp446,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xp446/pods/nginx-deployment-65bbdb5f8-tdm8t,UID:3ed27048-8351-11e9-944d-001dd80c001b,ResourceVersion:11709,Generation:0,CreationTimestamp:2019-05-31 03:07:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 3d9799cb-8351-11e9-944d-001dd80c001b 0xc0035a8710 0xc0035a8711}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4mkqq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4mkqq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4mkqq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0035a8780} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0035a87a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 31 03:07:38.153: INFO: Pod "nginx-deployment-65bbdb5f8-tqxsx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-tqxsx,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-xp446,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xp446/pods/nginx-deployment-65bbdb5f8-tqxsx,UID:3d9a0c26-8351-11e9-944d-001dd80c001b,ResourceVersion:11667,Generation:0,CreationTimestamp:2019-05-31 03:07:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 3d9799cb-8351-11e9-944d-001dd80c001b 0xc0035a87f7 0xc0035a87f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4mkqq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4mkqq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4mkqq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-linuxpool-39082607-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0035a8860} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0035a8880}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:36 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.5,PodIP:,StartTime:2019-05-31 03:07:36 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 31 03:07:38.153: INFO: Pod "nginx-deployment-65bbdb5f8-zwn94" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-zwn94,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-xp446,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xp446/pods/nginx-deployment-65bbdb5f8-zwn94,UID:3ecf52ad-8351-11e9-944d-001dd80c001b,ResourceVersion:11705,Generation:0,CreationTimestamp:2019-05-31 03:07:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 3d9799cb-8351-11e9-944d-001dd80c001b 0xc0035a8940 0xc0035a8941}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4mkqq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4mkqq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4mkqq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-linuxpool-39082607-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0035a89b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0035a89d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:07:38 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:07:38.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-xp446" for this suite.
May 31 03:07:44.226: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:07:44.303: INFO: namespace: e2e-tests-deployment-xp446, resource: bindings, ignored listing per whitelist
May 31 03:07:44.317: INFO: namespace e2e-tests-deployment-xp446 deletion completed in 6.141484411s

• [SLOW TEST:14.391 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:07:44.320: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-42935d2a-8351-11e9-949c-223764f7eae1
STEP: Creating a pod to test consume configMaps
May 31 03:07:44.414: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4293bf94-8351-11e9-949c-223764f7eae1" in namespace "e2e-tests-projected-ml5kf" to be "success or failure"
May 31 03:07:44.422: INFO: Pod "pod-projected-configmaps-4293bf94-8351-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 7.601114ms
May 31 03:07:46.425: INFO: Pod "pod-projected-configmaps-4293bf94-8351-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010062779s
May 31 03:07:48.427: INFO: Pod "pod-projected-configmaps-4293bf94-8351-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012643645s
May 31 03:07:50.430: INFO: Pod "pod-projected-configmaps-4293bf94-8351-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.01515931s
STEP: Saw pod success
May 31 03:07:50.430: INFO: Pod "pod-projected-configmaps-4293bf94-8351-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:07:50.432: INFO: Trying to get logs from node k8s-linuxpool-39082607-2 pod pod-projected-configmaps-4293bf94-8351-11e9-949c-223764f7eae1 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 31 03:07:50.449: INFO: Waiting for pod pod-projected-configmaps-4293bf94-8351-11e9-949c-223764f7eae1 to disappear
May 31 03:07:50.451: INFO: Pod pod-projected-configmaps-4293bf94-8351-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:07:50.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ml5kf" for this suite.
May 31 03:07:56.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:07:56.576: INFO: namespace: e2e-tests-projected-ml5kf, resource: bindings, ignored listing per whitelist
May 31 03:07:56.621: INFO: namespace e2e-tests-projected-ml5kf deletion completed in 6.166536479s

• [SLOW TEST:12.301 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:07:56.622: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-49e60c1e-8351-11e9-949c-223764f7eae1
STEP: Creating a pod to test consume configMaps
May 31 03:07:56.699: INFO: Waiting up to 5m0s for pod "pod-configmaps-49e67fdc-8351-11e9-949c-223764f7eae1" in namespace "e2e-tests-configmap-5b4z5" to be "success or failure"
May 31 03:07:56.702: INFO: Pod "pod-configmaps-49e67fdc-8351-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.084146ms
May 31 03:07:58.706: INFO: Pod "pod-configmaps-49e67fdc-8351-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006724726s
May 31 03:08:00.709: INFO: Pod "pod-configmaps-49e67fdc-8351-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009766487s
STEP: Saw pod success
May 31 03:08:00.709: INFO: Pod "pod-configmaps-49e67fdc-8351-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:08:00.711: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod pod-configmaps-49e67fdc-8351-11e9-949c-223764f7eae1 container configmap-volume-test: <nil>
STEP: delete the pod
May 31 03:08:00.731: INFO: Waiting for pod pod-configmaps-49e67fdc-8351-11e9-949c-223764f7eae1 to disappear
May 31 03:08:00.733: INFO: Pod pod-configmaps-49e67fdc-8351-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:08:00.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-5b4z5" for this suite.
May 31 03:08:06.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:08:06.774: INFO: namespace: e2e-tests-configmap-5b4z5, resource: bindings, ignored listing per whitelist
May 31 03:08:06.833: INFO: namespace e2e-tests-configmap-5b4z5 deletion completed in 6.097956414s

• [SLOW TEST:10.212 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:08:06.834: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-4ffc58d4-8351-11e9-949c-223764f7eae1
STEP: Creating a pod to test consume secrets
May 31 03:08:06.911: INFO: Waiting up to 5m0s for pod "pod-secrets-4ffcb502-8351-11e9-949c-223764f7eae1" in namespace "e2e-tests-secrets-7bt5f" to be "success or failure"
May 31 03:08:06.915: INFO: Pod "pod-secrets-4ffcb502-8351-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.493285ms
May 31 03:08:08.918: INFO: Pod "pod-secrets-4ffcb502-8351-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007324144s
May 31 03:08:10.921: INFO: Pod "pod-secrets-4ffcb502-8351-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010402981s
STEP: Saw pod success
May 31 03:08:10.922: INFO: Pod "pod-secrets-4ffcb502-8351-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:08:10.924: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod pod-secrets-4ffcb502-8351-11e9-949c-223764f7eae1 container secret-volume-test: <nil>
STEP: delete the pod
May 31 03:08:10.941: INFO: Waiting for pod pod-secrets-4ffcb502-8351-11e9-949c-223764f7eae1 to disappear
May 31 03:08:10.950: INFO: Pod pod-secrets-4ffcb502-8351-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:08:10.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-7bt5f" for this suite.
May 31 03:08:16.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:08:17.056: INFO: namespace: e2e-tests-secrets-7bt5f, resource: bindings, ignored listing per whitelist
May 31 03:08:17.069: INFO: namespace e2e-tests-secrets-7bt5f deletion completed in 6.090697779s

• [SLOW TEST:10.235 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:08:17.069: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 31 03:08:17.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-br9mj'
May 31 03:08:17.259: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 31 03:08:17.259: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
May 31 03:08:19.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-br9mj'
May 31 03:08:19.366: INFO: stderr: ""
May 31 03:08:19.367: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:08:19.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-br9mj" for this suite.
May 31 03:08:41.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:08:41.440: INFO: namespace: e2e-tests-kubectl-br9mj, resource: bindings, ignored listing per whitelist
May 31 03:08:41.458: INFO: namespace e2e-tests-kubectl-br9mj deletion completed in 22.087123486s

• [SLOW TEST:24.389 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:08:41.458: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 31 03:08:41.531: INFO: Waiting up to 5m0s for pod "downwardapi-volume-649f3b1f-8351-11e9-949c-223764f7eae1" in namespace "e2e-tests-projected-bq8t2" to be "success or failure"
May 31 03:08:41.539: INFO: Pod "downwardapi-volume-649f3b1f-8351-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 7.939748ms
May 31 03:08:43.543: INFO: Pod "downwardapi-volume-649f3b1f-8351-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011308858s
May 31 03:08:45.545: INFO: Pod "downwardapi-volume-649f3b1f-8351-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013672124s
STEP: Saw pod success
May 31 03:08:45.545: INFO: Pod "downwardapi-volume-649f3b1f-8351-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:08:45.547: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod downwardapi-volume-649f3b1f-8351-11e9-949c-223764f7eae1 container client-container: <nil>
STEP: delete the pod
May 31 03:08:45.565: INFO: Waiting for pod downwardapi-volume-649f3b1f-8351-11e9-949c-223764f7eae1 to disappear
May 31 03:08:45.567: INFO: Pod downwardapi-volume-649f3b1f-8351-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:08:45.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bq8t2" for this suite.
May 31 03:08:51.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:08:51.634: INFO: namespace: e2e-tests-projected-bq8t2, resource: bindings, ignored listing per whitelist
May 31 03:08:51.658: INFO: namespace e2e-tests-projected-bq8t2 deletion completed in 6.088251956s

• [SLOW TEST:10.200 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:08:51.658: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 31 03:08:51.735: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6ab445f4-8351-11e9-949c-223764f7eae1" in namespace "e2e-tests-downward-api-lckl9" to be "success or failure"
May 31 03:08:51.748: INFO: Pod "downwardapi-volume-6ab445f4-8351-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 12.31433ms
May 31 03:08:53.751: INFO: Pod "downwardapi-volume-6ab445f4-8351-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015496407s
May 31 03:08:55.753: INFO: Pod "downwardapi-volume-6ab445f4-8351-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018093948s
STEP: Saw pod success
May 31 03:08:55.754: INFO: Pod "downwardapi-volume-6ab445f4-8351-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:08:55.755: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod downwardapi-volume-6ab445f4-8351-11e9-949c-223764f7eae1 container client-container: <nil>
STEP: delete the pod
May 31 03:08:55.774: INFO: Waiting for pod downwardapi-volume-6ab445f4-8351-11e9-949c-223764f7eae1 to disappear
May 31 03:08:55.776: INFO: Pod downwardapi-volume-6ab445f4-8351-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:08:55.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-lckl9" for this suite.
May 31 03:09:01.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:09:01.839: INFO: namespace: e2e-tests-downward-api-lckl9, resource: bindings, ignored listing per whitelist
May 31 03:09:01.867: INFO: namespace e2e-tests-downward-api-lckl9 deletion completed in 6.088532872s

• [SLOW TEST:10.209 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:09:01.867: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-70ca6763-8351-11e9-949c-223764f7eae1
STEP: Creating a pod to test consume secrets
May 31 03:09:01.950: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-70cad5ab-8351-11e9-949c-223764f7eae1" in namespace "e2e-tests-projected-hfhpf" to be "success or failure"
May 31 03:09:01.952: INFO: Pod "pod-projected-secrets-70cad5ab-8351-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.230941ms
May 31 03:09:03.955: INFO: Pod "pod-projected-secrets-70cad5ab-8351-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004906682s
May 31 03:09:05.957: INFO: Pod "pod-projected-secrets-70cad5ab-8351-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007641099s
STEP: Saw pod success
May 31 03:09:05.957: INFO: Pod "pod-projected-secrets-70cad5ab-8351-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:09:05.960: INFO: Trying to get logs from node k8s-linuxpool-39082607-2 pod pod-projected-secrets-70cad5ab-8351-11e9-949c-223764f7eae1 container secret-volume-test: <nil>
STEP: delete the pod
May 31 03:09:05.978: INFO: Waiting for pod pod-projected-secrets-70cad5ab-8351-11e9-949c-223764f7eae1 to disappear
May 31 03:09:05.980: INFO: Pod pod-projected-secrets-70cad5ab-8351-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:09:05.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hfhpf" for this suite.
May 31 03:09:11.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:09:12.071: INFO: namespace: e2e-tests-projected-hfhpf, resource: bindings, ignored listing per whitelist
May 31 03:09:12.074: INFO: namespace e2e-tests-projected-hfhpf deletion completed in 6.090468426s

• [SLOW TEST:10.206 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:09:12.074: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
May 31 03:09:16.683: INFO: Successfully updated pod "annotationupdate76df6899-8351-11e9-949c-223764f7eae1"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:09:18.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-pcl5p" for this suite.
May 31 03:09:40.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:09:40.785: INFO: namespace: e2e-tests-downward-api-pcl5p, resource: bindings, ignored listing per whitelist
May 31 03:09:40.791: INFO: namespace e2e-tests-downward-api-pcl5p deletion completed in 22.089755326s

• [SLOW TEST:28.717 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:09:40.793: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-88005bb6-8351-11e9-949c-223764f7eae1
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-88005bb6-8351-11e9-949c-223764f7eae1
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:10:59.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qd9rc" for this suite.
May 31 03:11:21.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:11:21.445: INFO: namespace: e2e-tests-projected-qd9rc, resource: bindings, ignored listing per whitelist
May 31 03:11:21.462: INFO: namespace e2e-tests-projected-qd9rc deletion completed in 22.11916846s

• [SLOW TEST:100.669 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:11:21.462: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-9nbq
STEP: Creating a pod to test atomic-volume-subpath
May 31 03:11:21.546: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-9nbq" in namespace "e2e-tests-subpath-8cs47" to be "success or failure"
May 31 03:11:21.552: INFO: Pod "pod-subpath-test-downwardapi-9nbq": Phase="Pending", Reason="", readiness=false. Elapsed: 6.518616ms
May 31 03:11:23.555: INFO: Pod "pod-subpath-test-downwardapi-9nbq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009554258s
May 31 03:11:25.558: INFO: Pod "pod-subpath-test-downwardapi-9nbq": Phase="Running", Reason="", readiness=false. Elapsed: 4.012426678s
May 31 03:11:27.561: INFO: Pod "pod-subpath-test-downwardapi-9nbq": Phase="Running", Reason="", readiness=false. Elapsed: 6.015163076s
May 31 03:11:29.564: INFO: Pod "pod-subpath-test-downwardapi-9nbq": Phase="Running", Reason="", readiness=false. Elapsed: 8.01811986s
May 31 03:11:31.568: INFO: Pod "pod-subpath-test-downwardapi-9nbq": Phase="Running", Reason="", readiness=false. Elapsed: 10.021799039s
May 31 03:11:33.570: INFO: Pod "pod-subpath-test-downwardapi-9nbq": Phase="Running", Reason="", readiness=false. Elapsed: 12.024497781s
May 31 03:11:35.573: INFO: Pod "pod-subpath-test-downwardapi-9nbq": Phase="Running", Reason="", readiness=false. Elapsed: 14.027558611s
May 31 03:11:37.577: INFO: Pod "pod-subpath-test-downwardapi-9nbq": Phase="Running", Reason="", readiness=false. Elapsed: 16.030952229s
May 31 03:11:39.580: INFO: Pod "pod-subpath-test-downwardapi-9nbq": Phase="Running", Reason="", readiness=false. Elapsed: 18.033886521s
May 31 03:11:41.583: INFO: Pod "pod-subpath-test-downwardapi-9nbq": Phase="Running", Reason="", readiness=false. Elapsed: 20.037003698s
May 31 03:11:43.586: INFO: Pod "pod-subpath-test-downwardapi-9nbq": Phase="Running", Reason="", readiness=false. Elapsed: 22.039812151s
May 31 03:11:45.588: INFO: Pod "pod-subpath-test-downwardapi-9nbq": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.042327281s
STEP: Saw pod success
May 31 03:11:45.588: INFO: Pod "pod-subpath-test-downwardapi-9nbq" satisfied condition "success or failure"
May 31 03:11:45.593: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod pod-subpath-test-downwardapi-9nbq container test-container-subpath-downwardapi-9nbq: <nil>
STEP: delete the pod
May 31 03:11:45.609: INFO: Waiting for pod pod-subpath-test-downwardapi-9nbq to disappear
May 31 03:11:45.614: INFO: Pod pod-subpath-test-downwardapi-9nbq no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-9nbq
May 31 03:11:45.614: INFO: Deleting pod "pod-subpath-test-downwardapi-9nbq" in namespace "e2e-tests-subpath-8cs47"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:11:45.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-8cs47" for this suite.
May 31 03:11:51.629: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:11:51.696: INFO: namespace: e2e-tests-subpath-8cs47, resource: bindings, ignored listing per whitelist
May 31 03:11:51.714: INFO: namespace e2e-tests-subpath-8cs47 deletion completed in 6.094251313s

• [SLOW TEST:30.252 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:11:51.714: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 31 03:11:51.796: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d606d4e0-8351-11e9-949c-223764f7eae1" in namespace "e2e-tests-downward-api-zs7r8" to be "success or failure"
May 31 03:11:51.799: INFO: Pod "downwardapi-volume-d606d4e0-8351-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.725248ms
May 31 03:11:53.801: INFO: Pod "downwardapi-volume-d606d4e0-8351-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005356307s
May 31 03:11:55.804: INFO: Pod "downwardapi-volume-d606d4e0-8351-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008358954s
STEP: Saw pod success
May 31 03:11:55.804: INFO: Pod "downwardapi-volume-d606d4e0-8351-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:11:55.807: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod downwardapi-volume-d606d4e0-8351-11e9-949c-223764f7eae1 container client-container: <nil>
STEP: delete the pod
May 31 03:11:55.823: INFO: Waiting for pod downwardapi-volume-d606d4e0-8351-11e9-949c-223764f7eae1 to disappear
May 31 03:11:55.825: INFO: Pod downwardapi-volume-d606d4e0-8351-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:11:55.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-zs7r8" for this suite.
May 31 03:12:01.838: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:12:01.872: INFO: namespace: e2e-tests-downward-api-zs7r8, resource: bindings, ignored listing per whitelist
May 31 03:12:01.909: INFO: namespace e2e-tests-downward-api-zs7r8 deletion completed in 6.081427412s

• [SLOW TEST:10.195 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:12:01.909: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 31 03:12:01.973: INFO: Creating ReplicaSet my-hostname-basic-dc1923db-8351-11e9-949c-223764f7eae1
May 31 03:12:01.984: INFO: Pod name my-hostname-basic-dc1923db-8351-11e9-949c-223764f7eae1: Found 0 pods out of 1
May 31 03:12:06.987: INFO: Pod name my-hostname-basic-dc1923db-8351-11e9-949c-223764f7eae1: Found 1 pods out of 1
May 31 03:12:06.987: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-dc1923db-8351-11e9-949c-223764f7eae1" is running
May 31 03:12:06.989: INFO: Pod "my-hostname-basic-dc1923db-8351-11e9-949c-223764f7eae1-75nfn" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-31 03:12:02 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-31 03:12:04 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-31 03:12:04 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-31 03:12:01 +0000 UTC Reason: Message:}])
May 31 03:12:06.989: INFO: Trying to dial the pod
May 31 03:12:11.999: INFO: Controller my-hostname-basic-dc1923db-8351-11e9-949c-223764f7eae1: Got expected result from replica 1 [my-hostname-basic-dc1923db-8351-11e9-949c-223764f7eae1-75nfn]: "my-hostname-basic-dc1923db-8351-11e9-949c-223764f7eae1-75nfn", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:12:11.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-96rc7" for this suite.
May 31 03:12:18.010: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:12:18.095: INFO: namespace: e2e-tests-replicaset-96rc7, resource: bindings, ignored listing per whitelist
May 31 03:12:18.104: INFO: namespace e2e-tests-replicaset-96rc7 deletion completed in 6.102002851s

• [SLOW TEST:16.195 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:12:18.105: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-e5c1e7ed-8351-11e9-949c-223764f7eae1
STEP: Creating a pod to test consume secrets
May 31 03:12:18.223: INFO: Waiting up to 5m0s for pod "pod-secrets-e5c7da73-8351-11e9-949c-223764f7eae1" in namespace "e2e-tests-secrets-sl2xq" to be "success or failure"
May 31 03:12:18.226: INFO: Pod "pod-secrets-e5c7da73-8351-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.393159ms
May 31 03:12:20.229: INFO: Pod "pod-secrets-e5c7da73-8351-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00599829s
May 31 03:12:22.232: INFO: Pod "pod-secrets-e5c7da73-8351-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008761906s
STEP: Saw pod success
May 31 03:12:22.232: INFO: Pod "pod-secrets-e5c7da73-8351-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:12:22.234: INFO: Trying to get logs from node k8s-linuxpool-39082607-2 pod pod-secrets-e5c7da73-8351-11e9-949c-223764f7eae1 container secret-volume-test: <nil>
STEP: delete the pod
May 31 03:12:22.282: INFO: Waiting for pod pod-secrets-e5c7da73-8351-11e9-949c-223764f7eae1 to disappear
May 31 03:12:22.293: INFO: Pod pod-secrets-e5c7da73-8351-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:12:22.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-sl2xq" for this suite.
May 31 03:12:28.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:12:28.374: INFO: namespace: e2e-tests-secrets-sl2xq, resource: bindings, ignored listing per whitelist
May 31 03:12:28.394: INFO: namespace e2e-tests-secrets-sl2xq deletion completed in 6.09298443s
STEP: Destroying namespace "e2e-tests-secret-namespace-fdllg" for this suite.
May 31 03:12:34.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:12:34.438: INFO: namespace: e2e-tests-secret-namespace-fdllg, resource: bindings, ignored listing per whitelist
May 31 03:12:34.469: INFO: namespace e2e-tests-secret-namespace-fdllg deletion completed in 6.075642574s

• [SLOW TEST:16.365 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:12:34.471: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-ef81869a-8351-11e9-949c-223764f7eae1
STEP: Creating a pod to test consume configMaps
May 31 03:12:34.541: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ef81e994-8351-11e9-949c-223764f7eae1" in namespace "e2e-tests-projected-krcpj" to be "success or failure"
May 31 03:12:34.547: INFO: Pod "pod-projected-configmaps-ef81e994-8351-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.670799ms
May 31 03:12:36.549: INFO: Pod "pod-projected-configmaps-ef81e994-8351-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008521198s
May 31 03:12:38.552: INFO: Pod "pod-projected-configmaps-ef81e994-8351-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011471884s
STEP: Saw pod success
May 31 03:12:38.552: INFO: Pod "pod-projected-configmaps-ef81e994-8351-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:12:38.555: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod pod-projected-configmaps-ef81e994-8351-11e9-949c-223764f7eae1 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 31 03:12:38.645: INFO: Waiting for pod pod-projected-configmaps-ef81e994-8351-11e9-949c-223764f7eae1 to disappear
May 31 03:12:38.647: INFO: Pod pod-projected-configmaps-ef81e994-8351-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:12:38.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-krcpj" for this suite.
May 31 03:12:44.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:12:44.743: INFO: namespace: e2e-tests-projected-krcpj, resource: bindings, ignored listing per whitelist
May 31 03:12:44.757: INFO: namespace e2e-tests-projected-krcpj deletion completed in 6.107892084s

• [SLOW TEST:10.287 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:12:44.758: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-f5a63180-8351-11e9-949c-223764f7eae1
STEP: Creating a pod to test consume configMaps
May 31 03:12:44.852: INFO: Waiting up to 5m0s for pod "pod-configmaps-f5a69d18-8351-11e9-949c-223764f7eae1" in namespace "e2e-tests-configmap-9tnm7" to be "success or failure"
May 31 03:12:44.856: INFO: Pod "pod-configmaps-f5a69d18-8351-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.402959ms
May 31 03:12:46.861: INFO: Pod "pod-configmaps-f5a69d18-8351-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008393713s
May 31 03:12:48.863: INFO: Pod "pod-configmaps-f5a69d18-8351-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011144412s
STEP: Saw pod success
May 31 03:12:48.864: INFO: Pod "pod-configmaps-f5a69d18-8351-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:12:48.866: INFO: Trying to get logs from node k8s-linuxpool-39082607-2 pod pod-configmaps-f5a69d18-8351-11e9-949c-223764f7eae1 container configmap-volume-test: <nil>
STEP: delete the pod
May 31 03:12:48.884: INFO: Waiting for pod pod-configmaps-f5a69d18-8351-11e9-949c-223764f7eae1 to disappear
May 31 03:12:48.886: INFO: Pod pod-configmaps-f5a69d18-8351-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:12:48.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9tnm7" for this suite.
May 31 03:12:54.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:12:54.964: INFO: namespace: e2e-tests-configmap-9tnm7, resource: bindings, ignored listing per whitelist
May 31 03:12:54.976: INFO: namespace e2e-tests-configmap-9tnm7 deletion completed in 6.086634966s

• [SLOW TEST:10.218 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:12:54.976: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
May 31 03:12:55.060: INFO: Waiting up to 5m0s for pod "client-containers-fbbc70e3-8351-11e9-949c-223764f7eae1" in namespace "e2e-tests-containers-kc5v5" to be "success or failure"
May 31 03:12:55.076: INFO: Pod "client-containers-fbbc70e3-8351-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 15.739874ms
May 31 03:12:57.082: INFO: Pod "client-containers-fbbc70e3-8351-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021670263s
May 31 03:12:59.085: INFO: Pod "client-containers-fbbc70e3-8351-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024924391s
STEP: Saw pod success
May 31 03:12:59.085: INFO: Pod "client-containers-fbbc70e3-8351-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:12:59.087: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod client-containers-fbbc70e3-8351-11e9-949c-223764f7eae1 container test-container: <nil>
STEP: delete the pod
May 31 03:12:59.115: INFO: Waiting for pod client-containers-fbbc70e3-8351-11e9-949c-223764f7eae1 to disappear
May 31 03:12:59.118: INFO: Pod client-containers-fbbc70e3-8351-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:12:59.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-kc5v5" for this suite.
May 31 03:13:05.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:13:05.200: INFO: namespace: e2e-tests-containers-kc5v5, resource: bindings, ignored listing per whitelist
May 31 03:13:05.203: INFO: namespace e2e-tests-containers-kc5v5 deletion completed in 6.082325148s

• [SLOW TEST:10.227 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:13:05.203: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
May 31 03:13:05.275: INFO: Waiting up to 5m0s for pod "pod-01d370bd-8352-11e9-949c-223764f7eae1" in namespace "e2e-tests-emptydir-sz4pt" to be "success or failure"
May 31 03:13:05.286: INFO: Pod "pod-01d370bd-8352-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.700186ms
May 31 03:13:07.290: INFO: Pod "pod-01d370bd-8352-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014883966s
May 31 03:13:09.293: INFO: Pod "pod-01d370bd-8352-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017480204s
STEP: Saw pod success
May 31 03:13:09.293: INFO: Pod "pod-01d370bd-8352-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:13:09.295: INFO: Trying to get logs from node k8s-linuxpool-39082607-2 pod pod-01d370bd-8352-11e9-949c-223764f7eae1 container test-container: <nil>
STEP: delete the pod
May 31 03:13:09.308: INFO: Waiting for pod pod-01d370bd-8352-11e9-949c-223764f7eae1 to disappear
May 31 03:13:09.311: INFO: Pod pod-01d370bd-8352-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:13:09.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-sz4pt" for this suite.
May 31 03:13:15.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:13:15.456: INFO: namespace: e2e-tests-emptydir-sz4pt, resource: bindings, ignored listing per whitelist
May 31 03:13:15.469: INFO: namespace e2e-tests-emptydir-sz4pt deletion completed in 6.155285775s

• [SLOW TEST:10.266 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:13:15.469: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-07f7357c-8352-11e9-949c-223764f7eae1
STEP: Creating secret with name s-test-opt-upd-07f735bf-8352-11e9-949c-223764f7eae1
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-07f7357c-8352-11e9-949c-223764f7eae1
STEP: Updating secret s-test-opt-upd-07f735bf-8352-11e9-949c-223764f7eae1
STEP: Creating secret with name s-test-opt-create-07f735d6-8352-11e9-949c-223764f7eae1
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:13:23.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-5xh76" for this suite.
May 31 03:13:45.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:13:45.720: INFO: namespace: e2e-tests-secrets-5xh76, resource: bindings, ignored listing per whitelist
May 31 03:13:45.761: INFO: namespace e2e-tests-secrets-5xh76 deletion completed in 22.080048042s

• [SLOW TEST:30.292 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:13:45.762: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
May 31 03:13:53.884: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 31 03:13:53.889: INFO: Pod pod-with-poststart-http-hook still exists
May 31 03:13:55.889: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 31 03:13:55.893: INFO: Pod pod-with-poststart-http-hook still exists
May 31 03:13:57.889: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 31 03:13:57.892: INFO: Pod pod-with-poststart-http-hook still exists
May 31 03:13:59.889: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 31 03:13:59.893: INFO: Pod pod-with-poststart-http-hook still exists
May 31 03:14:01.889: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 31 03:14:01.894: INFO: Pod pod-with-poststart-http-hook still exists
May 31 03:14:03.889: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 31 03:14:03.892: INFO: Pod pod-with-poststart-http-hook still exists
May 31 03:14:05.889: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 31 03:14:05.892: INFO: Pod pod-with-poststart-http-hook still exists
May 31 03:14:07.889: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 31 03:14:07.892: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:14:07.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-49zpw" for this suite.
May 31 03:14:29.906: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:14:29.930: INFO: namespace: e2e-tests-container-lifecycle-hook-49zpw, resource: bindings, ignored listing per whitelist
May 31 03:14:29.982: INFO: namespace e2e-tests-container-lifecycle-hook-49zpw deletion completed in 22.087146778s

• [SLOW TEST:44.221 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:14:29.983: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
May 31 03:14:30.054: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:14:33.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-mc5bl" for this suite.
May 31 03:14:39.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:14:39.483: INFO: namespace: e2e-tests-init-container-mc5bl, resource: bindings, ignored listing per whitelist
May 31 03:14:39.490: INFO: namespace e2e-tests-init-container-mc5bl deletion completed in 6.125140558s

• [SLOW TEST:9.507 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:14:39.491: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-3a0c61a2-8352-11e9-949c-223764f7eae1
STEP: Creating a pod to test consume secrets
May 31 03:14:39.606: INFO: Waiting up to 5m0s for pod "pod-secrets-3a0ce9f4-8352-11e9-949c-223764f7eae1" in namespace "e2e-tests-secrets-t7g9t" to be "success or failure"
May 31 03:14:39.615: INFO: Pod "pod-secrets-3a0ce9f4-8352-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 9.049454ms
May 31 03:14:41.618: INFO: Pod "pod-secrets-3a0ce9f4-8352-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012153756s
May 31 03:14:43.621: INFO: Pod "pod-secrets-3a0ce9f4-8352-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015386147s
STEP: Saw pod success
May 31 03:14:43.621: INFO: Pod "pod-secrets-3a0ce9f4-8352-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:14:43.623: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod pod-secrets-3a0ce9f4-8352-11e9-949c-223764f7eae1 container secret-volume-test: <nil>
STEP: delete the pod
May 31 03:14:43.639: INFO: Waiting for pod pod-secrets-3a0ce9f4-8352-11e9-949c-223764f7eae1 to disappear
May 31 03:14:43.641: INFO: Pod pod-secrets-3a0ce9f4-8352-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:14:43.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-t7g9t" for this suite.
May 31 03:14:49.657: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:14:49.734: INFO: namespace: e2e-tests-secrets-t7g9t, resource: bindings, ignored listing per whitelist
May 31 03:14:49.754: INFO: namespace e2e-tests-secrets-t7g9t deletion completed in 6.110590112s

• [SLOW TEST:10.263 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:14:49.754: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-6k6r
STEP: Creating a pod to test atomic-volume-subpath
May 31 03:14:49.841: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-6k6r" in namespace "e2e-tests-subpath-5gkkp" to be "success or failure"
May 31 03:14:49.844: INFO: Pod "pod-subpath-test-projected-6k6r": Phase="Pending", Reason="", readiness=false. Elapsed: 2.619345ms
May 31 03:14:51.846: INFO: Pod "pod-subpath-test-projected-6k6r": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005193273s
May 31 03:14:53.850: INFO: Pod "pod-subpath-test-projected-6k6r": Phase="Running", Reason="", readiness=false. Elapsed: 4.008320998s
May 31 03:14:55.853: INFO: Pod "pod-subpath-test-projected-6k6r": Phase="Running", Reason="", readiness=false. Elapsed: 6.012225824s
May 31 03:14:57.856: INFO: Pod "pod-subpath-test-projected-6k6r": Phase="Running", Reason="", readiness=false. Elapsed: 8.014989218s
May 31 03:14:59.859: INFO: Pod "pod-subpath-test-projected-6k6r": Phase="Running", Reason="", readiness=false. Elapsed: 10.017971103s
May 31 03:15:01.862: INFO: Pod "pod-subpath-test-projected-6k6r": Phase="Running", Reason="", readiness=false. Elapsed: 12.020996677s
May 31 03:15:03.865: INFO: Pod "pod-subpath-test-projected-6k6r": Phase="Running", Reason="", readiness=false. Elapsed: 14.023923837s
May 31 03:15:05.868: INFO: Pod "pod-subpath-test-projected-6k6r": Phase="Running", Reason="", readiness=false. Elapsed: 16.027010287s
May 31 03:15:07.871: INFO: Pod "pod-subpath-test-projected-6k6r": Phase="Running", Reason="", readiness=false. Elapsed: 18.030000724s
May 31 03:15:09.875: INFO: Pod "pod-subpath-test-projected-6k6r": Phase="Running", Reason="", readiness=false. Elapsed: 20.033426356s
May 31 03:15:11.878: INFO: Pod "pod-subpath-test-projected-6k6r": Phase="Running", Reason="", readiness=false. Elapsed: 22.036956777s
May 31 03:15:13.881: INFO: Pod "pod-subpath-test-projected-6k6r": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.04011658s
STEP: Saw pod success
May 31 03:15:13.881: INFO: Pod "pod-subpath-test-projected-6k6r" satisfied condition "success or failure"
May 31 03:15:13.884: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod pod-subpath-test-projected-6k6r container test-container-subpath-projected-6k6r: <nil>
STEP: delete the pod
May 31 03:15:13.901: INFO: Waiting for pod pod-subpath-test-projected-6k6r to disappear
May 31 03:15:13.904: INFO: Pod pod-subpath-test-projected-6k6r no longer exists
STEP: Deleting pod pod-subpath-test-projected-6k6r
May 31 03:15:13.904: INFO: Deleting pod "pod-subpath-test-projected-6k6r" in namespace "e2e-tests-subpath-5gkkp"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:15:13.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-5gkkp" for this suite.
May 31 03:15:19.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:15:19.984: INFO: namespace: e2e-tests-subpath-5gkkp, resource: bindings, ignored listing per whitelist
May 31 03:15:20.012: INFO: namespace e2e-tests-subpath-5gkkp deletion completed in 6.103794232s

• [SLOW TEST:30.258 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:15:20.016: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 31 03:15:20.106: INFO: Waiting up to 5m0s for pod "downwardapi-volume-523095c1-8352-11e9-949c-223764f7eae1" in namespace "e2e-tests-projected-rq6l9" to be "success or failure"
May 31 03:15:20.113: INFO: Pod "downwardapi-volume-523095c1-8352-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.775415ms
May 31 03:15:22.116: INFO: Pod "downwardapi-volume-523095c1-8352-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010132072s
May 31 03:15:24.120: INFO: Pod "downwardapi-volume-523095c1-8352-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013326016s
STEP: Saw pod success
May 31 03:15:24.120: INFO: Pod "downwardapi-volume-523095c1-8352-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:15:24.122: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod downwardapi-volume-523095c1-8352-11e9-949c-223764f7eae1 container client-container: <nil>
STEP: delete the pod
May 31 03:15:24.136: INFO: Waiting for pod downwardapi-volume-523095c1-8352-11e9-949c-223764f7eae1 to disappear
May 31 03:15:24.138: INFO: Pod downwardapi-volume-523095c1-8352-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:15:24.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rq6l9" for this suite.
May 31 03:15:30.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:15:30.178: INFO: namespace: e2e-tests-projected-rq6l9, resource: bindings, ignored listing per whitelist
May 31 03:15:30.231: INFO: namespace e2e-tests-projected-rq6l9 deletion completed in 6.090865331s

• [SLOW TEST:10.216 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:15:30.232: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-qph86 in namespace e2e-tests-proxy-jjkjs
I0531 03:15:30.318197      15 runners.go:184] Created replication controller with name: proxy-service-qph86, namespace: e2e-tests-proxy-jjkjs, replica count: 1
I0531 03:15:31.369609      15 runners.go:184] proxy-service-qph86 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0531 03:15:32.369957      15 runners.go:184] proxy-service-qph86 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0531 03:15:33.370180      15 runners.go:184] proxy-service-qph86 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0531 03:15:34.370405      15 runners.go:184] proxy-service-qph86 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0531 03:15:35.370636      15 runners.go:184] proxy-service-qph86 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0531 03:15:36.370826      15 runners.go:184] proxy-service-qph86 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0531 03:15:37.371051      15 runners.go:184] proxy-service-qph86 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0531 03:15:38.371253      15 runners.go:184] proxy-service-qph86 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0531 03:15:39.371691      15 runners.go:184] proxy-service-qph86 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 31 03:15:39.377: INFO: setup took 9.076901044s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
May 31 03:15:39.385: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:160/proxy/: foo (200; 7.388125ms)
May 31 03:15:39.385: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp/proxy/rewriteme"... (200; 7.215622ms)
May 31 03:15:39.385: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:1080/proxy/rewri... (200; 7.558727ms)
May 31 03:15:39.389: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/http:proxy-service-qph86:portname1/proxy/: foo (200; 11.182788ms)
May 31 03:15:39.391: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/proxy-service-qph86:portname1/proxy/: foo (200; 13.107021ms)
May 31 03:15:39.391: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:1080/proxy/... (200; 13.231123ms)
May 31 03:15:39.391: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:160/proxy/: foo (200; 13.408826ms)
May 31 03:15:39.392: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:460/proxy/: tls baz (200; 14.125338ms)
May 31 03:15:39.399: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/proxy-service-qph86:portname2/proxy/: bar (200; 21.408161ms)
May 31 03:15:39.399: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:162/proxy/: bar (200; 21.292759ms)
May 31 03:15:39.402: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:162/proxy/: bar (200; 24.154707ms)
May 31 03:15:39.403: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/http:proxy-service-qph86:portname2/proxy/: bar (200; 25.381028ms)
May 31 03:15:39.404: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:462/proxy/: tls qux (200; 25.418829ms)
May 31 03:15:39.404: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:443/proxy/... (200; 26.457345ms)
May 31 03:15:39.405: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/https:proxy-service-qph86:tlsportname2/proxy/: tls qux (200; 27.30216ms)
May 31 03:15:39.407: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/https:proxy-service-qph86:tlsportname1/proxy/: tls baz (200; 28.849686ms)
May 31 03:15:39.420: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:460/proxy/: tls baz (200; 13.097921ms)
May 31 03:15:39.420: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:160/proxy/: foo (200; 12.746815ms)
May 31 03:15:39.420: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp/proxy/rewriteme"... (200; 12.903618ms)
May 31 03:15:39.420: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:1080/proxy/... (200; 12.865817ms)
May 31 03:15:39.420: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/proxy-service-qph86:portname2/proxy/: bar (200; 13.128021ms)
May 31 03:15:39.420: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:160/proxy/: foo (200; 12.750714ms)
May 31 03:15:39.420: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:162/proxy/: bar (200; 12.659614ms)
May 31 03:15:39.420: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/https:proxy-service-qph86:tlsportname2/proxy/: tls qux (200; 13.04972ms)
May 31 03:15:39.420: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/https:proxy-service-qph86:tlsportname1/proxy/: tls baz (200; 13.122421ms)
May 31 03:15:39.420: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:462/proxy/: tls qux (200; 12.664014ms)
May 31 03:15:39.420: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:162/proxy/: bar (200; 12.781615ms)
May 31 03:15:39.424: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:443/proxy/... (200; 15.917468ms)
May 31 03:15:39.424: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:1080/proxy/rewri... (200; 16.03637ms)
May 31 03:15:39.426: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/http:proxy-service-qph86:portname2/proxy/: bar (200; 18.377409ms)
May 31 03:15:39.426: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/http:proxy-service-qph86:portname1/proxy/: foo (200; 18.103505ms)
May 31 03:15:39.426: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/proxy-service-qph86:portname1/proxy/: foo (200; 18.204107ms)
May 31 03:15:39.433: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:160/proxy/: foo (200; 6.460909ms)
May 31 03:15:39.433: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:460/proxy/: tls baz (200; 6.654512ms)
May 31 03:15:39.434: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:160/proxy/: foo (200; 7.933033ms)
May 31 03:15:39.434: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/https:proxy-service-qph86:tlsportname1/proxy/: tls baz (200; 8.057036ms)
May 31 03:15:39.435: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/proxy-service-qph86:portname2/proxy/: bar (200; 9.283256ms)
May 31 03:15:39.436: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/https:proxy-service-qph86:tlsportname2/proxy/: tls qux (200; 9.302356ms)
May 31 03:15:39.437: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:1080/proxy/... (200; 10.380375ms)
May 31 03:15:39.437: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp/proxy/rewriteme"... (200; 10.490077ms)
May 31 03:15:39.437: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:162/proxy/: bar (200; 11.074486ms)
May 31 03:15:39.440: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:462/proxy/: tls qux (200; 13.65353ms)
May 31 03:15:39.440: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:162/proxy/: bar (200; 13.738531ms)
May 31 03:15:39.442: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/proxy-service-qph86:portname1/proxy/: foo (200; 16.050771ms)
May 31 03:15:39.443: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/http:proxy-service-qph86:portname2/proxy/: bar (200; 17.041087ms)
May 31 03:15:39.443: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:443/proxy/... (200; 16.909385ms)
May 31 03:15:39.443: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:1080/proxy/rewri... (200; 16.965885ms)
May 31 03:15:39.446: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/http:proxy-service-qph86:portname1/proxy/: foo (200; 19.711432ms)
May 31 03:15:39.470: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:1080/proxy/rewri... (200; 22.972187ms)
May 31 03:15:39.470: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:443/proxy/... (200; 23.378294ms)
May 31 03:15:39.470: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:160/proxy/: foo (200; 23.214892ms)
May 31 03:15:39.470: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp/proxy/rewriteme"... (200; 23.310593ms)
May 31 03:15:39.470: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:160/proxy/: foo (200; 23.418795ms)
May 31 03:15:39.470: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:1080/proxy/... (200; 23.534896ms)
May 31 03:15:39.470: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:162/proxy/: bar (200; 23.385794ms)
May 31 03:15:39.470: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:460/proxy/: tls baz (200; 23.452595ms)
May 31 03:15:39.470: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:462/proxy/: tls qux (200; 23.500696ms)
May 31 03:15:39.470: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:162/proxy/: bar (200; 23.449995ms)
May 31 03:15:39.473: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/http:proxy-service-qph86:portname2/proxy/: bar (200; 26.529447ms)
May 31 03:15:39.473: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/proxy-service-qph86:portname2/proxy/: bar (200; 27.055956ms)
May 31 03:15:39.474: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/http:proxy-service-qph86:portname1/proxy/: foo (200; 27.482963ms)
May 31 03:15:39.475: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/https:proxy-service-qph86:tlsportname2/proxy/: tls qux (200; 28.936988ms)
May 31 03:15:39.475: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/proxy-service-qph86:portname1/proxy/: foo (200; 28.790385ms)
May 31 03:15:39.475: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/https:proxy-service-qph86:tlsportname1/proxy/: tls baz (200; 29.028589ms)
May 31 03:15:39.483: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:1080/proxy/... (200; 6.832915ms)
May 31 03:15:39.483: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:460/proxy/: tls baz (200; 7.192121ms)
May 31 03:15:39.483: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:162/proxy/: bar (200; 6.710813ms)
May 31 03:15:39.483: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:160/proxy/: foo (200; 6.781814ms)
May 31 03:15:39.483: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:160/proxy/: foo (200; 6.912417ms)
May 31 03:15:39.485: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp/proxy/rewriteme"... (200; 9.434359ms)
May 31 03:15:39.490: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/proxy-service-qph86:portname1/proxy/: foo (200; 14.177439ms)
May 31 03:15:39.490: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/https:proxy-service-qph86:tlsportname1/proxy/: tls baz (200; 14.82625ms)
May 31 03:15:39.490: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:462/proxy/: tls qux (200; 14.404443ms)
May 31 03:15:39.490: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/proxy-service-qph86:portname2/proxy/: bar (200; 14.957952ms)
May 31 03:15:39.490: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/https:proxy-service-qph86:tlsportname2/proxy/: tls qux (200; 14.84965ms)
May 31 03:15:39.490: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:1080/proxy/rewri... (200; 14.28284ms)
May 31 03:15:39.490: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:162/proxy/: bar (200; 14.507844ms)
May 31 03:15:39.491: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/http:proxy-service-qph86:portname2/proxy/: bar (200; 14.682748ms)
May 31 03:15:39.491: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:443/proxy/... (200; 14.265541ms)
May 31 03:15:39.491: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/http:proxy-service-qph86:portname1/proxy/: foo (200; 14.392542ms)
May 31 03:15:39.495: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:162/proxy/: bar (200; 4.092469ms)
May 31 03:15:39.496: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:462/proxy/: tls qux (200; 4.758881ms)
May 31 03:15:39.502: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:162/proxy/: bar (200; 10.439476ms)
May 31 03:15:39.503: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/https:proxy-service-qph86:tlsportname2/proxy/: tls qux (200; 11.299291ms)
May 31 03:15:39.503: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/https:proxy-service-qph86:tlsportname1/proxy/: tls baz (200; 11.362491ms)
May 31 03:15:39.507: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:160/proxy/: foo (200; 15.228756ms)
May 31 03:15:39.507: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/proxy-service-qph86:portname1/proxy/: foo (200; 15.635763ms)
May 31 03:15:39.507: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:460/proxy/: tls baz (200; 15.337559ms)
May 31 03:15:39.507: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp/proxy/rewriteme"... (200; 15.315758ms)
May 31 03:15:39.507: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:1080/proxy/... (200; 15.312058ms)
May 31 03:15:39.508: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:443/proxy/... (200; 16.03067ms)
May 31 03:15:39.509: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/http:proxy-service-qph86:portname2/proxy/: bar (200; 17.155789ms)
May 31 03:15:39.509: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:160/proxy/: foo (200; 16.994786ms)
May 31 03:15:39.509: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:1080/proxy/rewri... (200; 17.181289ms)
May 31 03:15:39.511: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/http:proxy-service-qph86:portname1/proxy/: foo (200; 19.736233ms)
May 31 03:15:39.511: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/proxy-service-qph86:portname2/proxy/: bar (200; 19.62613ms)
May 31 03:15:39.521: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp/proxy/rewriteme"... (200; 9.262556ms)
May 31 03:15:39.521: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:1080/proxy/rewri... (200; 9.064952ms)
May 31 03:15:39.523: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:443/proxy/... (200; 10.964085ms)
May 31 03:15:39.524: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:460/proxy/: tls baz (200; 11.635396ms)
May 31 03:15:39.524: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/http:proxy-service-qph86:portname1/proxy/: foo (200; 12.522111ms)
May 31 03:15:39.525: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:162/proxy/: bar (200; 11.889001ms)
May 31 03:15:39.534: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:160/proxy/: foo (200; 21.303059ms)
May 31 03:15:39.534: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:162/proxy/: bar (200; 21.024155ms)
May 31 03:15:39.534: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:160/proxy/: foo (200; 21.230758ms)
May 31 03:15:39.534: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:1080/proxy/... (200; 21.307759ms)
May 31 03:15:39.534: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:462/proxy/: tls qux (200; 20.995353ms)
May 31 03:15:39.535: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/https:proxy-service-qph86:tlsportname1/proxy/: tls baz (200; 22.51638ms)
May 31 03:15:39.535: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/proxy-service-qph86:portname2/proxy/: bar (200; 22.490579ms)
May 31 03:15:39.535: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/https:proxy-service-qph86:tlsportname2/proxy/: tls qux (200; 23.237092ms)
May 31 03:15:39.536: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/http:proxy-service-qph86:portname2/proxy/: bar (200; 23.640698ms)
May 31 03:15:39.536: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/proxy-service-qph86:portname1/proxy/: foo (200; 24.293509ms)
May 31 03:15:39.543: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:462/proxy/: tls qux (200; 6.014401ms)
May 31 03:15:39.543: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:162/proxy/: bar (200; 6.196505ms)
May 31 03:15:39.545: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:160/proxy/: foo (200; 7.746831ms)
May 31 03:15:39.545: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:162/proxy/: bar (200; 7.551027ms)
May 31 03:15:39.549: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:1080/proxy/rewri... (200; 12.619913ms)
May 31 03:15:39.549: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/https:proxy-service-qph86:tlsportname1/proxy/: tls baz (200; 11.795398ms)
May 31 03:15:39.550: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/http:proxy-service-qph86:portname1/proxy/: foo (200; 12.209506ms)
May 31 03:15:39.550: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/http:proxy-service-qph86:portname2/proxy/: bar (200; 13.316324ms)
May 31 03:15:39.550: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/proxy-service-qph86:portname1/proxy/: foo (200; 13.126721ms)
May 31 03:15:39.553: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/proxy-service-qph86:portname2/proxy/: bar (200; 12.557311ms)
May 31 03:15:39.554: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp/proxy/rewriteme"... (200; 13.67863ms)
May 31 03:15:39.554: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:460/proxy/: tls baz (200; 13.549029ms)
May 31 03:15:39.554: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:1080/proxy/... (200; 13.589529ms)
May 31 03:15:39.555: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:443/proxy/... (200; 14.138838ms)
May 31 03:15:39.555: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:160/proxy/: foo (200; 18.636814ms)
May 31 03:15:39.557: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/https:proxy-service-qph86:tlsportname2/proxy/: tls qux (200; 16.659981ms)
May 31 03:15:39.572: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:460/proxy/: tls baz (200; 13.64203ms)
May 31 03:15:39.572: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:462/proxy/: tls qux (200; 13.941334ms)
May 31 03:15:39.572: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp/proxy/rewriteme"... (200; 14.389242ms)
May 31 03:15:39.572: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:443/proxy/... (200; 13.801832ms)
May 31 03:15:39.572: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:1080/proxy/rewri... (200; 14.674847ms)
May 31 03:15:39.575: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:162/proxy/: bar (200; 16.588079ms)
May 31 03:15:39.575: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:1080/proxy/... (200; 16.965086ms)
May 31 03:15:39.575: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:160/proxy/: foo (200; 16.942485ms)
May 31 03:15:39.577: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/https:proxy-service-qph86:tlsportname1/proxy/: tls baz (200; 19.272524ms)
May 31 03:15:39.577: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:160/proxy/: foo (200; 19.051221ms)
May 31 03:15:39.577: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/https:proxy-service-qph86:tlsportname2/proxy/: tls qux (200; 19.291425ms)
May 31 03:15:39.577: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/proxy-service-qph86:portname2/proxy/: bar (200; 19.420527ms)
May 31 03:15:39.577: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/http:proxy-service-qph86:portname2/proxy/: bar (200; 19.180424ms)
May 31 03:15:39.577: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/proxy-service-qph86:portname1/proxy/: foo (200; 18.956619ms)
May 31 03:15:39.577: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/http:proxy-service-qph86:portname1/proxy/: foo (200; 18.935419ms)
May 31 03:15:39.578: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:162/proxy/: bar (200; 19.527829ms)
May 31 03:15:39.590: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:160/proxy/: foo (200; 11.356492ms)
May 31 03:15:39.594: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:1080/proxy/... (200; 15.556162ms)
May 31 03:15:39.594: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/https:proxy-service-qph86:tlsportname1/proxy/: tls baz (200; 15.760066ms)
May 31 03:15:39.594: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp/proxy/rewriteme"... (200; 15.702065ms)
May 31 03:15:39.594: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/proxy-service-qph86:portname2/proxy/: bar (200; 15.897868ms)
May 31 03:15:39.594: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:1080/proxy/rewri... (200; 15.265058ms)
May 31 03:15:39.594: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:160/proxy/: foo (200; 15.685464ms)
May 31 03:15:39.594: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:460/proxy/: tls baz (200; 16.06107ms)
May 31 03:15:39.594: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:462/proxy/: tls qux (200; 15.480061ms)
May 31 03:15:39.594: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:162/proxy/: bar (200; 15.607163ms)
May 31 03:15:39.594: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:162/proxy/: bar (200; 15.582863ms)
May 31 03:15:39.594: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/http:proxy-service-qph86:portname2/proxy/: bar (200; 15.760766ms)
May 31 03:15:39.594: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/https:proxy-service-qph86:tlsportname2/proxy/: tls qux (200; 15.982869ms)
May 31 03:15:39.594: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/proxy-service-qph86:portname1/proxy/: foo (200; 15.557362ms)
May 31 03:15:39.594: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:443/proxy/... (200; 15.468661ms)
May 31 03:15:39.595: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/http:proxy-service-qph86:portname1/proxy/: foo (200; 16.318374ms)
May 31 03:15:39.611: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:160/proxy/: foo (200; 15.723465ms)
May 31 03:15:39.611: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp/proxy/rewriteme"... (200; 16.247874ms)
May 31 03:15:39.611: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:443/proxy/... (200; 15.719764ms)
May 31 03:15:39.611: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:1080/proxy/rewri... (200; 15.903868ms)
May 31 03:15:39.611: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:460/proxy/: tls baz (200; 15.837167ms)
May 31 03:15:39.611: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:462/proxy/: tls qux (200; 16.124772ms)
May 31 03:15:39.612: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:162/proxy/: bar (200; 16.255574ms)
May 31 03:15:39.612: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:1080/proxy/... (200; 16.523278ms)
May 31 03:15:39.612: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:162/proxy/: bar (200; 16.304975ms)
May 31 03:15:39.615: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/proxy-service-qph86:portname1/proxy/: foo (200; 18.902319ms)
May 31 03:15:39.615: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:160/proxy/: foo (200; 19.497928ms)
May 31 03:15:39.615: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/https:proxy-service-qph86:tlsportname1/proxy/: tls baz (200; 19.446727ms)
May 31 03:15:39.615: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/https:proxy-service-qph86:tlsportname2/proxy/: tls qux (200; 19.736133ms)
May 31 03:15:39.615: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/http:proxy-service-qph86:portname2/proxy/: bar (200; 19.274625ms)
May 31 03:15:39.615: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/http:proxy-service-qph86:portname1/proxy/: foo (200; 19.871335ms)
May 31 03:15:39.617: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/proxy-service-qph86:portname2/proxy/: bar (200; 22.287075ms)
May 31 03:15:39.625: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:462/proxy/: tls qux (200; 7.400625ms)
May 31 03:15:39.630: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:1080/proxy/... (200; 12.720415ms)
May 31 03:15:39.631: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:460/proxy/: tls baz (200; 12.969119ms)
May 31 03:15:39.631: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:1080/proxy/rewri... (200; 12.641813ms)
May 31 03:15:39.631: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:160/proxy/: foo (200; 13.03072ms)
May 31 03:15:39.631: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp/proxy/rewriteme"... (200; 12.913118ms)
May 31 03:15:39.631: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:160/proxy/: foo (200; 12.911217ms)
May 31 03:15:39.631: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:443/proxy/... (200; 12.771915ms)
May 31 03:15:39.631: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:162/proxy/: bar (200; 12.890817ms)
May 31 03:15:39.631: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:162/proxy/: bar (200; 12.951518ms)
May 31 03:15:39.634: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/https:proxy-service-qph86:tlsportname2/proxy/: tls qux (200; 15.99147ms)
May 31 03:15:39.634: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/http:proxy-service-qph86:portname2/proxy/: bar (200; 15.958869ms)
May 31 03:15:39.634: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/http:proxy-service-qph86:portname1/proxy/: foo (200; 15.944668ms)
May 31 03:15:39.634: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/proxy-service-qph86:portname2/proxy/: bar (200; 16.309675ms)
May 31 03:15:39.636: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/https:proxy-service-qph86:tlsportname1/proxy/: tls baz (200; 18.077305ms)
May 31 03:15:39.636: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/proxy-service-qph86:portname1/proxy/: foo (200; 17.997403ms)
May 31 03:15:39.648: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:160/proxy/: foo (200; 11.727297ms)
May 31 03:15:39.648: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp/proxy/rewriteme"... (200; 11.819299ms)
May 31 03:15:39.648: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:1080/proxy/... (200; 11.965702ms)
May 31 03:15:39.648: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:460/proxy/: tls baz (200; 11.966902ms)
May 31 03:15:39.648: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:160/proxy/: foo (200; 11.8823ms)
May 31 03:15:39.652: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/proxy-service-qph86:portname2/proxy/: bar (200; 15.651463ms)
May 31 03:15:39.652: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/http:proxy-service-qph86:portname1/proxy/: foo (200; 15.503761ms)
May 31 03:15:39.652: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:162/proxy/: bar (200; 15.413959ms)
May 31 03:15:39.652: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/https:proxy-service-qph86:tlsportname1/proxy/: tls baz (200; 15.759266ms)
May 31 03:15:39.653: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/http:proxy-service-qph86:portname2/proxy/: bar (200; 17.19579ms)
May 31 03:15:39.654: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:443/proxy/... (200; 17.317592ms)
May 31 03:15:39.654: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:462/proxy/: tls qux (200; 17.465495ms)
May 31 03:15:39.654: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/https:proxy-service-qph86:tlsportname2/proxy/: tls qux (200; 17.613796ms)
May 31 03:15:39.654: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:1080/proxy/rewri... (200; 17.475594ms)
May 31 03:15:39.654: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:162/proxy/: bar (200; 17.703198ms)
May 31 03:15:39.654: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/proxy-service-qph86:portname1/proxy/: foo (200; 18.336909ms)
May 31 03:15:39.665: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:160/proxy/: foo (200; 10.491677ms)
May 31 03:15:39.665: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:462/proxy/: tls qux (200; 10.803282ms)
May 31 03:15:39.665: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:160/proxy/: foo (200; 10.403776ms)
May 31 03:15:39.665: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:1080/proxy/... (200; 10.583778ms)
May 31 03:15:39.665: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp/proxy/rewriteme"... (200; 10.623079ms)
May 31 03:15:39.665: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:460/proxy/: tls baz (200; 10.195671ms)
May 31 03:15:39.665: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:1080/proxy/rewri... (200; 10.210872ms)
May 31 03:15:39.665: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:162/proxy/: bar (200; 10.454076ms)
May 31 03:15:39.665: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:443/proxy/... (200; 10.317274ms)
May 31 03:15:39.667: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/proxy-service-qph86:portname1/proxy/: foo (200; 12.634413ms)
May 31 03:15:39.667: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/https:proxy-service-qph86:tlsportname2/proxy/: tls qux (200; 12.782515ms)
May 31 03:15:39.667: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:162/proxy/: bar (200; 12.285007ms)
May 31 03:15:39.670: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/proxy-service-qph86:portname2/proxy/: bar (200; 14.587546ms)
May 31 03:15:39.671: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/https:proxy-service-qph86:tlsportname1/proxy/: tls baz (200; 15.314758ms)
May 31 03:15:39.671: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/http:proxy-service-qph86:portname2/proxy/: bar (200; 15.680064ms)
May 31 03:15:39.671: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/http:proxy-service-qph86:portname1/proxy/: foo (200; 15.892768ms)
May 31 03:15:39.682: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:1080/proxy/... (200; 10.578778ms)
May 31 03:15:39.682: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp/proxy/rewriteme"... (200; 10.641379ms)
May 31 03:15:39.682: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:160/proxy/: foo (200; 10.550977ms)
May 31 03:15:39.682: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:162/proxy/: bar (200; 10.838783ms)
May 31 03:15:39.683: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/https:proxy-service-qph86:tlsportname2/proxy/: tls qux (200; 11.736498ms)
May 31 03:15:39.683: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:462/proxy/: tls qux (200; 11.29319ms)
May 31 03:15:39.684: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:1080/proxy/rewri... (200; 12.426909ms)
May 31 03:15:39.685: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/proxy-service-qph86:portname2/proxy/: bar (200; 13.264823ms)
May 31 03:15:39.687: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:160/proxy/: foo (200; 15.487561ms)
May 31 03:15:39.689: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:460/proxy/: tls baz (200; 16.847284ms)
May 31 03:15:39.692: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:443/proxy/... (200; 19.717932ms)
May 31 03:15:39.695: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:162/proxy/: bar (200; 23.922003ms)
May 31 03:15:39.697: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/proxy-service-qph86:portname1/proxy/: foo (200; 25.132023ms)
May 31 03:15:39.697: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/http:proxy-service-qph86:portname2/proxy/: bar (200; 25.417328ms)
May 31 03:15:39.697: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/https:proxy-service-qph86:tlsportname1/proxy/: tls baz (200; 25.860936ms)
May 31 03:15:39.698: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/http:proxy-service-qph86:portname1/proxy/: foo (200; 27.075457ms)
May 31 03:15:39.705: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:460/proxy/: tls baz (200; 6.993418ms)
May 31 03:15:39.706: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:162/proxy/: bar (200; 6.666112ms)
May 31 03:15:39.706: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:162/proxy/: bar (200; 7.006718ms)
May 31 03:15:39.707: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:443/proxy/... (200; 7.633629ms)
May 31 03:15:39.707: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp/proxy/rewriteme"... (200; 8.530244ms)
May 31 03:15:39.707: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:462/proxy/: tls qux (200; 8.286139ms)
May 31 03:15:39.708: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:1080/proxy/rewri... (200; 8.447943ms)
May 31 03:15:39.715: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/proxy-service-qph86:portname1/proxy/: foo (200; 15.511361ms)
May 31 03:15:39.715: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:1080/proxy/... (200; 16.073271ms)
May 31 03:15:39.715: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/http:proxy-service-qph86:portname1/proxy/: foo (200; 16.001869ms)
May 31 03:15:39.715: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:160/proxy/: foo (200; 16.327776ms)
May 31 03:15:39.715: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/https:proxy-service-qph86:tlsportname1/proxy/: tls baz (200; 16.756883ms)
May 31 03:15:39.715: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/proxy-service-qph86:portname2/proxy/: bar (200; 17.059988ms)
May 31 03:15:39.716: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:160/proxy/: foo (200; 16.905085ms)
May 31 03:15:39.716: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/https:proxy-service-qph86:tlsportname2/proxy/: tls qux (200; 17.149489ms)
May 31 03:15:39.716: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/http:proxy-service-qph86:portname2/proxy/: bar (200; 17.097988ms)
May 31 03:15:39.724: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp/proxy/rewriteme"... (200; 7.442425ms)
May 31 03:15:39.724: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:1080/proxy/... (200; 7.883133ms)
May 31 03:15:39.725: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:160/proxy/: foo (200; 8.034535ms)
May 31 03:15:39.726: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/http:proxy-service-qph86:portname1/proxy/: foo (200; 9.810366ms)
May 31 03:15:39.728: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/https:proxy-service-qph86:tlsportname1/proxy/: tls baz (200; 12.087503ms)
May 31 03:15:39.729: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:460/proxy/: tls baz (200; 12.556811ms)
May 31 03:15:39.729: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/proxy-service-qph86:portname1/proxy/: foo (200; 12.070403ms)
May 31 03:15:39.729: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:162/proxy/: bar (200; 12.276607ms)
May 31 03:15:39.730: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:162/proxy/: bar (200; 13.147521ms)
May 31 03:15:39.730: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/https:proxy-service-qph86:tlsportname2/proxy/: tls qux (200; 13.199623ms)
May 31 03:15:39.730: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:462/proxy/: tls qux (200; 13.371825ms)
May 31 03:15:39.732: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:443/proxy/... (200; 15.130555ms)
May 31 03:15:39.732: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/proxy-service-qph86:portname2/proxy/: bar (200; 15.513461ms)
May 31 03:15:39.732: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/http:proxy-service-qph86:portname2/proxy/: bar (200; 15.565362ms)
May 31 03:15:39.732: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:1080/proxy/rewri... (200; 15.228956ms)
May 31 03:15:39.732: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:160/proxy/: foo (200; 15.594963ms)
May 31 03:15:39.740: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:162/proxy/: bar (200; 7.969434ms)
May 31 03:15:39.740: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:160/proxy/: foo (200; 8.408141ms)
May 31 03:15:39.745: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:462/proxy/: tls qux (200; 12.794416ms)
May 31 03:15:39.745: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:1080/proxy/rewri... (200; 13.164522ms)
May 31 03:15:39.747: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/http:proxy-service-qph86:portname1/proxy/: foo (200; 14.26754ms)
May 31 03:15:39.747: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:460/proxy/: tls baz (200; 14.275241ms)
May 31 03:15:39.747: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:1080/proxy/... (200; 14.377342ms)
May 31 03:15:39.747: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/proxy-service-qph86:portname1/proxy/: foo (200; 14.88245ms)
May 31 03:15:39.747: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/http:proxy-service-qph86:portname2/proxy/: bar (200; 15.211656ms)
May 31 03:15:39.748: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp/proxy/rewriteme"... (200; 15.111555ms)
May 31 03:15:39.748: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/https:proxy-service-qph86:tlsportname1/proxy/: tls baz (200; 15.39566ms)
May 31 03:15:39.748: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/proxy-service-qph86:portname2/proxy/: bar (200; 15.513261ms)
May 31 03:15:39.748: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:160/proxy/: foo (200; 15.924768ms)
May 31 03:15:39.748: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:162/proxy/: bar (200; 16.07347ms)
May 31 03:15:39.749: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:443/proxy/... (200; 16.181372ms)
May 31 03:15:39.749: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/https:proxy-service-qph86:tlsportname2/proxy/: tls qux (200; 16.103272ms)
May 31 03:15:39.758: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:162/proxy/: bar (200; 8.623645ms)
May 31 03:15:39.758: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:1080/proxy/... (200; 8.980752ms)
May 31 03:15:39.758: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:443/proxy/... (200; 9.046752ms)
May 31 03:15:39.758: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:1080/proxy/rewri... (200; 9.419659ms)
May 31 03:15:39.759: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp/proxy/rewriteme"... (200; 9.751264ms)
May 31 03:15:39.759: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:462/proxy/: tls qux (200; 10.09487ms)
May 31 03:15:39.761: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:160/proxy/: foo (200; 12.246906ms)
May 31 03:15:39.762: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:162/proxy/: bar (200; 12.554812ms)
May 31 03:15:39.762: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/proxy-service-qph86:portname2/proxy/: bar (200; 12.536311ms)
May 31 03:15:39.763: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/http:proxy-service-qph86:portname1/proxy/: foo (200; 14.272441ms)
May 31 03:15:39.763: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/https:proxy-service-qph86:tlsportname2/proxy/: tls qux (200; 14.529745ms)
May 31 03:15:39.763: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:460/proxy/: tls baz (200; 14.330942ms)
May 31 03:15:39.764: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/https:proxy-service-qph86:tlsportname1/proxy/: tls baz (200; 14.806949ms)
May 31 03:15:39.764: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/proxy-service-qph86:portname1/proxy/: foo (200; 15.068654ms)
May 31 03:15:39.764: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:160/proxy/: foo (200; 15.017753ms)
May 31 03:15:39.764: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/http:proxy-service-qph86:portname2/proxy/: bar (200; 15.039554ms)
May 31 03:15:39.774: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:160/proxy/: foo (200; 9.029452ms)
May 31 03:15:39.774: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:1080/proxy/rewri... (200; 9.262756ms)
May 31 03:15:39.776: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:462/proxy/: tls qux (200; 11.522294ms)
May 31 03:15:39.776: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:162/proxy/: bar (200; 11.706197ms)
May 31 03:15:39.777: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp:162/proxy/: bar (200; 11.950601ms)
May 31 03:15:39.779: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/http:proxy-service-qph86:portname1/proxy/: foo (200; 14.196639ms)
May 31 03:15:39.780: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:443/proxy/... (200; 14.459043ms)
May 31 03:15:39.780: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/https:proxy-service-qph86:tlsportname2/proxy/: tls qux (200; 14.373142ms)
May 31 03:15:39.780: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/https:proxy-service-qph86-brqvp:460/proxy/: tls baz (200; 14.631346ms)
May 31 03:15:39.780: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:160/proxy/: foo (200; 15.648363ms)
May 31 03:15:39.781: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/proxy-service-qph86:portname1/proxy/: foo (200; 15.895268ms)
May 31 03:15:39.781: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/proxy-service-qph86:portname2/proxy/: bar (200; 15.588562ms)
May 31 03:15:39.781: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/proxy-service-qph86-brqvp/proxy/rewriteme"... (200; 15.535662ms)
May 31 03:15:39.781: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jjkjs/pods/http:proxy-service-qph86-brqvp:1080/proxy/... (200; 15.41486ms)
May 31 03:15:39.781: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/http:proxy-service-qph86:portname2/proxy/: bar (200; 16.525279ms)
May 31 03:15:39.781: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jjkjs/services/https:proxy-service-qph86:tlsportname1/proxy/: tls baz (200; 16.03997ms)
STEP: deleting ReplicationController proxy-service-qph86 in namespace e2e-tests-proxy-jjkjs, will wait for the garbage collector to delete the pods
May 31 03:15:39.841: INFO: Deleting ReplicationController proxy-service-qph86 took: 6.395208ms
May 31 03:15:39.941: INFO: Terminating ReplicationController proxy-service-qph86 pods took: 100.208388ms
[AfterEach] version v1
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:15:45.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-jjkjs" for this suite.
May 31 03:15:51.552: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:15:51.610: INFO: namespace: e2e-tests-proxy-jjkjs, resource: bindings, ignored listing per whitelist
May 31 03:15:51.629: INFO: namespace e2e-tests-proxy-jjkjs deletion completed in 6.084661755s

• [SLOW TEST:21.397 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:15:51.629: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-b4jbq A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-b4jbq;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-b4jbq A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-b4jbq;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-b4jbq.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-b4jbq.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-b4jbq.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-b4jbq.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-b4jbq.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-b4jbq.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-b4jbq.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-b4jbq.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-b4jbq.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 193.142.0.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.0.142.193_udp@PTR;check="$$(dig +tcp +noall +answer +search 193.142.0.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.0.142.193_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-b4jbq A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-b4jbq;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-b4jbq A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-b4jbq;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-b4jbq.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-b4jbq.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-b4jbq.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-b4jbq.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-b4jbq.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-b4jbq.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-b4jbq.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-b4jbq.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-b4jbq.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 193.142.0.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.0.142.193_udp@PTR;check="$$(dig +tcp +noall +answer +search 193.142.0.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.0.142.193_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 31 03:15:55.769: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:15:55.772: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:15:55.779: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-b4jbq from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:15:55.792: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-b4jbq.svc from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:15:55.794: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:15:55.797: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:15:55.823: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:15:55.827: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:15:55.830: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-b4jbq from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:15:55.834: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-b4jbq from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:15:55.837: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-b4jbq.svc from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:15:55.839: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-b4jbq.svc from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:15:55.842: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:15:55.845: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:15:55.868: INFO: Lookups using e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-b4jbq wheezy_tcp@dns-test-service.e2e-tests-dns-b4jbq.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-b4jbq jessie_tcp@dns-test-service.e2e-tests-dns-b4jbq jessie_udp@dns-test-service.e2e-tests-dns-b4jbq.svc jessie_tcp@dns-test-service.e2e-tests-dns-b4jbq.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc]

May 31 03:16:00.873: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:00.876: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:00.884: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-b4jbq from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:00.890: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-b4jbq.svc from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:00.893: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:00.898: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:00.919: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:00.922: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:00.925: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-b4jbq from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:00.928: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-b4jbq from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:00.931: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-b4jbq.svc from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:00.933: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-b4jbq.svc from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:00.936: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:00.939: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:01.022: INFO: Lookups using e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-b4jbq wheezy_tcp@dns-test-service.e2e-tests-dns-b4jbq.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-b4jbq jessie_tcp@dns-test-service.e2e-tests-dns-b4jbq jessie_udp@dns-test-service.e2e-tests-dns-b4jbq.svc jessie_tcp@dns-test-service.e2e-tests-dns-b4jbq.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc]

May 31 03:16:05.872: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:05.874: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:05.881: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-b4jbq from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:05.886: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-b4jbq.svc from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:05.889: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:05.891: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:05.913: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:05.916: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:05.919: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-b4jbq from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:05.923: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-b4jbq from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:05.925: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-b4jbq.svc from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:05.928: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-b4jbq.svc from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:05.932: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:05.935: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:05.954: INFO: Lookups using e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-b4jbq wheezy_tcp@dns-test-service.e2e-tests-dns-b4jbq.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-b4jbq jessie_tcp@dns-test-service.e2e-tests-dns-b4jbq jessie_udp@dns-test-service.e2e-tests-dns-b4jbq.svc jessie_tcp@dns-test-service.e2e-tests-dns-b4jbq.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc]

May 31 03:16:10.872: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:10.876: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:10.881: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-b4jbq from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:10.886: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-b4jbq.svc from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:10.889: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:10.892: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:10.910: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:10.913: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:10.916: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-b4jbq from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:10.919: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-b4jbq from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:10.923: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-b4jbq.svc from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:10.930: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-b4jbq.svc from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:10.933: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:10.937: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:10.956: INFO: Lookups using e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-b4jbq wheezy_tcp@dns-test-service.e2e-tests-dns-b4jbq.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-b4jbq jessie_tcp@dns-test-service.e2e-tests-dns-b4jbq jessie_udp@dns-test-service.e2e-tests-dns-b4jbq.svc jessie_tcp@dns-test-service.e2e-tests-dns-b4jbq.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc]

May 31 03:16:15.877: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:15.880: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:15.885: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-b4jbq from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:15.905: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-b4jbq.svc from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:15.907: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:15.912: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:15.931: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:15.934: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:15.936: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-b4jbq from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:15.938: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-b4jbq from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:15.941: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-b4jbq.svc from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:15.943: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-b4jbq.svc from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:15.946: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:15.949: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:15.966: INFO: Lookups using e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-b4jbq wheezy_tcp@dns-test-service.e2e-tests-dns-b4jbq.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-b4jbq jessie_tcp@dns-test-service.e2e-tests-dns-b4jbq jessie_udp@dns-test-service.e2e-tests-dns-b4jbq.svc jessie_tcp@dns-test-service.e2e-tests-dns-b4jbq.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc]

May 31 03:16:20.872: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:20.875: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:20.881: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-b4jbq from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:20.886: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-b4jbq.svc from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:20.888: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:20.890: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:20.908: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:20.911: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:20.913: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-b4jbq from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:20.916: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-b4jbq from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:20.920: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-b4jbq.svc from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:20.922: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-b4jbq.svc from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:20.926: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:20.929: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc from pod e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1: the server could not find the requested resource (get pods dns-test-650a8731-8352-11e9-949c-223764f7eae1)
May 31 03:16:20.945: INFO: Lookups using e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-b4jbq wheezy_tcp@dns-test-service.e2e-tests-dns-b4jbq.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-b4jbq jessie_tcp@dns-test-service.e2e-tests-dns-b4jbq jessie_udp@dns-test-service.e2e-tests-dns-b4jbq.svc jessie_tcp@dns-test-service.e2e-tests-dns-b4jbq.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-b4jbq.svc]

May 31 03:16:25.953: INFO: DNS probes using e2e-tests-dns-b4jbq/dns-test-650a8731-8352-11e9-949c-223764f7eae1 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:16:26.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-b4jbq" for this suite.
May 31 03:16:32.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:16:32.072: INFO: namespace: e2e-tests-dns-b4jbq, resource: bindings, ignored listing per whitelist
May 31 03:16:32.118: INFO: namespace e2e-tests-dns-b4jbq deletion completed in 6.100761465s

• [SLOW TEST:40.489 seconds]
[sig-network] DNS
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:16:32.120: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-hdqdw
I0531 03:16:32.210872      15 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-hdqdw, replica count: 1
I0531 03:16:33.261387      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0531 03:16:34.263635      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0531 03:16:35.263846      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 31 03:16:35.374: INFO: Created: latency-svc-vnkpm
May 31 03:16:35.377: INFO: Got endpoints: latency-svc-vnkpm [13.680328ms]
May 31 03:16:35.390: INFO: Created: latency-svc-x8hd9
May 31 03:16:35.400: INFO: Created: latency-svc-jb788
May 31 03:16:35.404: INFO: Created: latency-svc-rkm7p
May 31 03:16:35.407: INFO: Got endpoints: latency-svc-x8hd9 [28.924483ms]
May 31 03:16:35.413: INFO: Got endpoints: latency-svc-jb788 [34.635778ms]
May 31 03:16:35.420: INFO: Got endpoints: latency-svc-rkm7p [42.186904ms]
May 31 03:16:35.441: INFO: Created: latency-svc-b8ff6
May 31 03:16:35.443: INFO: Got endpoints: latency-svc-b8ff6 [64.652379ms]
May 31 03:16:35.441: INFO: Created: latency-svc-kzdzv
May 31 03:16:35.444: INFO: Got endpoints: latency-svc-kzdzv [66.044602ms]
May 31 03:16:35.448: INFO: Created: latency-svc-sjdz4
May 31 03:16:35.454: INFO: Got endpoints: latency-svc-sjdz4 [75.219656ms]
May 31 03:16:35.462: INFO: Created: latency-svc-n7rsr
May 31 03:16:35.468: INFO: Got endpoints: latency-svc-n7rsr [90.035604ms]
May 31 03:16:35.471: INFO: Created: latency-svc-q6vp7
May 31 03:16:35.475: INFO: Got endpoints: latency-svc-q6vp7 [97.04492ms]
May 31 03:16:35.486: INFO: Created: latency-svc-f7865
May 31 03:16:35.493: INFO: Got endpoints: latency-svc-f7865 [114.908818ms]
May 31 03:16:35.499: INFO: Created: latency-svc-45nhd
May 31 03:16:35.506: INFO: Created: latency-svc-r6v8h
May 31 03:16:35.510: INFO: Got endpoints: latency-svc-r6v8h [131.818801ms]
May 31 03:16:35.511: INFO: Got endpoints: latency-svc-45nhd [132.533513ms]
May 31 03:16:35.518: INFO: Created: latency-svc-zhzp9
May 31 03:16:35.526: INFO: Got endpoints: latency-svc-zhzp9 [147.138357ms]
May 31 03:16:35.528: INFO: Created: latency-svc-nrpvc
May 31 03:16:35.531: INFO: Created: latency-svc-f6snj
May 31 03:16:35.538: INFO: Got endpoints: latency-svc-nrpvc [159.020855ms]
May 31 03:16:35.542: INFO: Got endpoints: latency-svc-f6snj [163.078923ms]
May 31 03:16:35.550: INFO: Created: latency-svc-77z5m
May 31 03:16:35.559: INFO: Created: latency-svc-9bk8n
May 31 03:16:35.562: INFO: Got endpoints: latency-svc-77z5m [182.784352ms]
May 31 03:16:35.563: INFO: Created: latency-svc-49bmw
May 31 03:16:35.577: INFO: Created: latency-svc-wz8z4
May 31 03:16:35.577: INFO: Got endpoints: latency-svc-49bmw [164.632049ms]
May 31 03:16:35.578: INFO: Got endpoints: latency-svc-9bk8n [171.170458ms]
May 31 03:16:35.588: INFO: Got endpoints: latency-svc-wz8z4 [168.239909ms]
May 31 03:16:35.590: INFO: Created: latency-svc-jwlss
May 31 03:16:35.600: INFO: Created: latency-svc-tqmsq
May 31 03:16:35.630: INFO: Created: latency-svc-fqvcv
May 31 03:16:35.640: INFO: Got endpoints: latency-svc-jwlss [197.150492ms]
May 31 03:16:35.643: INFO: Got endpoints: latency-svc-tqmsq [198.357912ms]
May 31 03:16:35.642: INFO: Created: latency-svc-z9pbq
May 31 03:16:35.649: INFO: Got endpoints: latency-svc-z9pbq [180.435913ms]
May 31 03:16:35.649: INFO: Got endpoints: latency-svc-fqvcv [195.048756ms]
May 31 03:16:35.651: INFO: Created: latency-svc-x8qwx
May 31 03:16:35.660: INFO: Created: latency-svc-5vnf6
May 31 03:16:35.664: INFO: Got endpoints: latency-svc-x8qwx [188.66765ms]
May 31 03:16:35.672: INFO: Created: latency-svc-dbwmh
May 31 03:16:35.672: INFO: Got endpoints: latency-svc-5vnf6 [178.814386ms]
May 31 03:16:35.679: INFO: Got endpoints: latency-svc-dbwmh [36.52181ms]
May 31 03:16:35.682: INFO: Created: latency-svc-94xr7
May 31 03:16:35.683: INFO: Got endpoints: latency-svc-94xr7 [171.429362ms]
May 31 03:16:35.692: INFO: Created: latency-svc-nb2t9
May 31 03:16:35.695: INFO: Created: latency-svc-z7b79
May 31 03:16:35.701: INFO: Got endpoints: latency-svc-z7b79 [175.035622ms]
May 31 03:16:35.701: INFO: Got endpoints: latency-svc-nb2t9 [190.267277ms]
May 31 03:16:35.709: INFO: Created: latency-svc-vz9s4
May 31 03:16:35.719: INFO: Got endpoints: latency-svc-vz9s4 [181.152924ms]
May 31 03:16:35.719: INFO: Created: latency-svc-8cjxg
May 31 03:16:35.727: INFO: Created: latency-svc-s6qh7
May 31 03:16:35.737: INFO: Created: latency-svc-s777s
May 31 03:16:35.742: INFO: Created: latency-svc-sbvng
May 31 03:16:35.748: INFO: Got endpoints: latency-svc-sbvng [169.957238ms]
May 31 03:16:35.748: INFO: Got endpoints: latency-svc-8cjxg [206.262244ms]
May 31 03:16:35.749: INFO: Got endpoints: latency-svc-s6qh7 [187.44463ms]
May 31 03:16:35.750: INFO: Got endpoints: latency-svc-s777s [172.757584ms]
May 31 03:16:35.752: INFO: Created: latency-svc-h68dd
May 31 03:16:35.765: INFO: Created: latency-svc-82q5p
May 31 03:16:35.767: INFO: Got endpoints: latency-svc-h68dd [178.249377ms]
May 31 03:16:35.775: INFO: Got endpoints: latency-svc-82q5p [135.601564ms]
May 31 03:16:35.781: INFO: Created: latency-svc-nlszr
May 31 03:16:35.784: INFO: Created: latency-svc-rgslq
May 31 03:16:35.790: INFO: Created: latency-svc-gp469
May 31 03:16:35.790: INFO: Got endpoints: latency-svc-rgslq [139.471029ms]
May 31 03:16:35.791: INFO: Got endpoints: latency-svc-nlszr [141.662266ms]
May 31 03:16:35.799: INFO: Created: latency-svc-ds75d
May 31 03:16:35.813: INFO: Created: latency-svc-ndkft
May 31 03:16:35.821: INFO: Created: latency-svc-4f67h
May 31 03:16:35.829: INFO: Created: latency-svc-vg8mb
May 31 03:16:35.832: INFO: Got endpoints: latency-svc-gp469 [167.363995ms]
May 31 03:16:35.844: INFO: Created: latency-svc-dqhz4
May 31 03:16:35.848: INFO: Created: latency-svc-dsvnd
May 31 03:16:35.855: INFO: Created: latency-svc-mcwpz
May 31 03:16:35.871: INFO: Created: latency-svc-7zhdd
May 31 03:16:35.877: INFO: Created: latency-svc-4f4nd
May 31 03:16:35.884: INFO: Got endpoints: latency-svc-ds75d [211.313229ms]
May 31 03:16:35.889: INFO: Created: latency-svc-dxqfc
May 31 03:16:35.898: INFO: Created: latency-svc-vpwqj
May 31 03:16:35.906: INFO: Created: latency-svc-jjgjf
May 31 03:16:35.915: INFO: Created: latency-svc-qpqgr
May 31 03:16:35.921: INFO: Created: latency-svc-f48nj
May 31 03:16:35.930: INFO: Created: latency-svc-fmrh4
May 31 03:16:35.934: INFO: Got endpoints: latency-svc-ndkft [252.093909ms]
May 31 03:16:35.940: INFO: Created: latency-svc-rtvjg
May 31 03:16:35.949: INFO: Created: latency-svc-8lszx
May 31 03:16:35.988: INFO: Got endpoints: latency-svc-4f67h [304.84069ms]
May 31 03:16:35.999: INFO: Created: latency-svc-xjw2m
May 31 03:16:36.027: INFO: Got endpoints: latency-svc-vg8mb [326.225947ms]
May 31 03:16:36.037: INFO: Created: latency-svc-p7tfm
May 31 03:16:36.081: INFO: Got endpoints: latency-svc-dqhz4 [380.367251ms]
May 31 03:16:36.093: INFO: Created: latency-svc-4wlt8
May 31 03:16:36.128: INFO: Got endpoints: latency-svc-dsvnd [408.574821ms]
May 31 03:16:36.138: INFO: Created: latency-svc-l566k
May 31 03:16:36.178: INFO: Got endpoints: latency-svc-mcwpz [429.735375ms]
May 31 03:16:36.198: INFO: Created: latency-svc-dmdbc
May 31 03:16:36.231: INFO: Got endpoints: latency-svc-7zhdd [482.529356ms]
May 31 03:16:36.240: INFO: Created: latency-svc-4m8z4
May 31 03:16:36.278: INFO: Got endpoints: latency-svc-4f4nd [527.960515ms]
May 31 03:16:36.298: INFO: Created: latency-svc-4hxxs
May 31 03:16:36.329: INFO: Got endpoints: latency-svc-dxqfc [579.303072ms]
May 31 03:16:36.341: INFO: Created: latency-svc-mrg7f
May 31 03:16:36.378: INFO: Got endpoints: latency-svc-vpwqj [611.339107ms]
May 31 03:16:36.390: INFO: Created: latency-svc-s5dp8
May 31 03:16:36.431: INFO: Got endpoints: latency-svc-jjgjf [655.407442ms]
May 31 03:16:36.444: INFO: Created: latency-svc-czlmh
May 31 03:16:36.478: INFO: Got endpoints: latency-svc-qpqgr [687.377976ms]
May 31 03:16:36.497: INFO: Created: latency-svc-rp2kg
May 31 03:16:36.529: INFO: Got endpoints: latency-svc-f48nj [738.244025ms]
May 31 03:16:36.539: INFO: Created: latency-svc-66gvp
May 31 03:16:36.578: INFO: Got endpoints: latency-svc-fmrh4 [746.405462ms]
May 31 03:16:36.591: INFO: Created: latency-svc-26lvx
May 31 03:16:36.627: INFO: Got endpoints: latency-svc-rtvjg [743.679316ms]
May 31 03:16:36.636: INFO: Created: latency-svc-5skzw
May 31 03:16:36.678: INFO: Got endpoints: latency-svc-8lszx [743.859919ms]
May 31 03:16:36.691: INFO: Created: latency-svc-fcrrv
May 31 03:16:36.729: INFO: Got endpoints: latency-svc-xjw2m [741.288375ms]
May 31 03:16:36.739: INFO: Created: latency-svc-v64vl
May 31 03:16:36.778: INFO: Got endpoints: latency-svc-p7tfm [750.53543ms]
May 31 03:16:36.788: INFO: Created: latency-svc-xc4r4
May 31 03:16:36.839: INFO: Got endpoints: latency-svc-4wlt8 [757.12744ms]
May 31 03:16:36.858: INFO: Created: latency-svc-jwz94
May 31 03:16:36.877: INFO: Got endpoints: latency-svc-l566k [749.705616ms]
May 31 03:16:36.888: INFO: Created: latency-svc-5h2m9
May 31 03:16:36.926: INFO: Got endpoints: latency-svc-dmdbc [748.081789ms]
May 31 03:16:36.944: INFO: Created: latency-svc-jdvxd
May 31 03:16:36.978: INFO: Got endpoints: latency-svc-4m8z4 [747.002971ms]
May 31 03:16:36.989: INFO: Created: latency-svc-l8n78
May 31 03:16:37.047: INFO: Got endpoints: latency-svc-4hxxs [768.258326ms]
May 31 03:16:37.090: INFO: Got endpoints: latency-svc-mrg7f [761.222308ms]
May 31 03:16:37.091: INFO: Created: latency-svc-mb2l2
May 31 03:16:37.106: INFO: Created: latency-svc-7p4m2
May 31 03:16:37.134: INFO: Got endpoints: latency-svc-s5dp8 [755.463912ms]
May 31 03:16:37.157: INFO: Created: latency-svc-dxknz
May 31 03:16:37.181: INFO: Got endpoints: latency-svc-czlmh [750.310926ms]
May 31 03:16:37.190: INFO: Created: latency-svc-dm55p
May 31 03:16:37.228: INFO: Got endpoints: latency-svc-rp2kg [749.998321ms]
May 31 03:16:37.244: INFO: Created: latency-svc-v7tp5
May 31 03:16:37.290: INFO: Got endpoints: latency-svc-66gvp [760.650798ms]
May 31 03:16:37.315: INFO: Created: latency-svc-csrzb
May 31 03:16:37.336: INFO: Got endpoints: latency-svc-26lvx [757.19794ms]
May 31 03:16:37.357: INFO: Created: latency-svc-mmrs9
May 31 03:16:37.376: INFO: Got endpoints: latency-svc-5skzw [748.411993ms]
May 31 03:16:37.390: INFO: Created: latency-svc-8z7w4
May 31 03:16:37.439: INFO: Got endpoints: latency-svc-fcrrv [761.016604ms]
May 31 03:16:37.453: INFO: Created: latency-svc-bn9t8
May 31 03:16:37.480: INFO: Got endpoints: latency-svc-v64vl [750.63113ms]
May 31 03:16:37.519: INFO: Created: latency-svc-kxqg7
May 31 03:16:37.540: INFO: Got endpoints: latency-svc-xc4r4 [761.682814ms]
May 31 03:16:37.556: INFO: Created: latency-svc-9vdt9
May 31 03:16:37.590: INFO: Got endpoints: latency-svc-jwz94 [751.655147ms]
May 31 03:16:37.608: INFO: Created: latency-svc-4ff5b
May 31 03:16:37.626: INFO: Got endpoints: latency-svc-5h2m9 [748.806499ms]
May 31 03:16:37.640: INFO: Created: latency-svc-fcpbc
May 31 03:16:37.701: INFO: Got endpoints: latency-svc-jdvxd [775.325042ms]
May 31 03:16:37.716: INFO: Created: latency-svc-w5wjw
May 31 03:16:37.727: INFO: Got endpoints: latency-svc-l8n78 [748.596095ms]
May 31 03:16:37.741: INFO: Created: latency-svc-qs7q7
May 31 03:16:37.777: INFO: Got endpoints: latency-svc-mb2l2 [727.28414ms]
May 31 03:16:37.788: INFO: Created: latency-svc-8d7z5
May 31 03:16:37.827: INFO: Got endpoints: latency-svc-7p4m2 [736.790399ms]
May 31 03:16:37.839: INFO: Created: latency-svc-rmv47
May 31 03:16:37.878: INFO: Got endpoints: latency-svc-dxknz [737.805715ms]
May 31 03:16:37.896: INFO: Created: latency-svc-8dk54
May 31 03:16:37.928: INFO: Got endpoints: latency-svc-dm55p [746.593662ms]
May 31 03:16:37.943: INFO: Created: latency-svc-gc4cs
May 31 03:16:37.978: INFO: Got endpoints: latency-svc-v7tp5 [749.782916ms]
May 31 03:16:37.996: INFO: Created: latency-svc-fft67
May 31 03:16:38.047: INFO: Got endpoints: latency-svc-csrzb [753.525477ms]
May 31 03:16:38.083: INFO: Got endpoints: latency-svc-mmrs9 [746.849466ms]
May 31 03:16:38.091: INFO: Created: latency-svc-4jlb2
May 31 03:16:38.100: INFO: Created: latency-svc-xtlfs
May 31 03:16:38.133: INFO: Got endpoints: latency-svc-8z7w4 [756.939135ms]
May 31 03:16:38.150: INFO: Created: latency-svc-fjnsr
May 31 03:16:38.178: INFO: Got endpoints: latency-svc-bn9t8 [738.306623ms]
May 31 03:16:38.220: INFO: Created: latency-svc-hbnmv
May 31 03:16:38.242: INFO: Got endpoints: latency-svc-kxqg7 [761.956318ms]
May 31 03:16:38.258: INFO: Created: latency-svc-44j4p
May 31 03:16:38.278: INFO: Got endpoints: latency-svc-9vdt9 [737.681813ms]
May 31 03:16:38.297: INFO: Created: latency-svc-r5f57
May 31 03:16:38.328: INFO: Got endpoints: latency-svc-4ff5b [737.666112ms]
May 31 03:16:38.345: INFO: Created: latency-svc-nt5wp
May 31 03:16:38.378: INFO: Got endpoints: latency-svc-fcpbc [751.757747ms]
May 31 03:16:38.393: INFO: Created: latency-svc-8h5nc
May 31 03:16:38.427: INFO: Got endpoints: latency-svc-w5wjw [725.51201ms]
May 31 03:16:38.450: INFO: Created: latency-svc-pslwc
May 31 03:16:38.477: INFO: Got endpoints: latency-svc-qs7q7 [750.467826ms]
May 31 03:16:38.490: INFO: Created: latency-svc-5rn84
May 31 03:16:38.530: INFO: Got endpoints: latency-svc-8d7z5 [753.187771ms]
May 31 03:16:38.546: INFO: Created: latency-svc-tstdd
May 31 03:16:38.578: INFO: Got endpoints: latency-svc-rmv47 [750.547426ms]
May 31 03:16:38.594: INFO: Created: latency-svc-46bhp
May 31 03:16:38.627: INFO: Got endpoints: latency-svc-8dk54 [748.9448ms]
May 31 03:16:38.642: INFO: Created: latency-svc-fhg9q
May 31 03:16:38.677: INFO: Got endpoints: latency-svc-gc4cs [748.36829ms]
May 31 03:16:38.693: INFO: Created: latency-svc-lzv95
May 31 03:16:38.728: INFO: Got endpoints: latency-svc-fft67 [749.977016ms]
May 31 03:16:38.742: INFO: Created: latency-svc-9hhfv
May 31 03:16:38.784: INFO: Got endpoints: latency-svc-4jlb2 [737.264405ms]
May 31 03:16:38.804: INFO: Created: latency-svc-59hqs
May 31 03:16:38.829: INFO: Got endpoints: latency-svc-xtlfs [746.038151ms]
May 31 03:16:38.839: INFO: Created: latency-svc-5gj4r
May 31 03:16:38.887: INFO: Got endpoints: latency-svc-fjnsr [754.175087ms]
May 31 03:16:38.921: INFO: Created: latency-svc-bk9zg
May 31 03:16:38.928: INFO: Got endpoints: latency-svc-hbnmv [750.483425ms]
May 31 03:16:38.949: INFO: Created: latency-svc-z4nzt
May 31 03:16:38.979: INFO: Got endpoints: latency-svc-44j4p [736.873898ms]
May 31 03:16:39.002: INFO: Created: latency-svc-snfqf
May 31 03:16:39.030: INFO: Got endpoints: latency-svc-r5f57 [752.285156ms]
May 31 03:16:39.045: INFO: Created: latency-svc-cl6cn
May 31 03:16:39.077: INFO: Got endpoints: latency-svc-nt5wp [748.095285ms]
May 31 03:16:39.091: INFO: Created: latency-svc-plb8b
May 31 03:16:39.131: INFO: Got endpoints: latency-svc-8h5nc [752.326456ms]
May 31 03:16:39.144: INFO: Created: latency-svc-zvrqm
May 31 03:16:39.178: INFO: Got endpoints: latency-svc-pslwc [750.782129ms]
May 31 03:16:39.195: INFO: Created: latency-svc-gkxk2
May 31 03:16:39.228: INFO: Got endpoints: latency-svc-5rn84 [750.419024ms]
May 31 03:16:39.239: INFO: Created: latency-svc-rmn6s
May 31 03:16:39.281: INFO: Got endpoints: latency-svc-tstdd [749.918715ms]
May 31 03:16:39.294: INFO: Created: latency-svc-hl2f6
May 31 03:16:39.328: INFO: Got endpoints: latency-svc-46bhp [749.675311ms]
May 31 03:16:39.341: INFO: Created: latency-svc-vklfd
May 31 03:16:39.377: INFO: Got endpoints: latency-svc-fhg9q [750.26622ms]
May 31 03:16:39.391: INFO: Created: latency-svc-2hs7q
May 31 03:16:39.427: INFO: Got endpoints: latency-svc-lzv95 [750.218019ms]
May 31 03:16:39.441: INFO: Created: latency-svc-4pl2l
May 31 03:16:39.499: INFO: Got endpoints: latency-svc-9hhfv [770.954266ms]
May 31 03:16:39.508: INFO: Created: latency-svc-57dq8
May 31 03:16:39.549: INFO: Got endpoints: latency-svc-59hqs [764.301554ms]
May 31 03:16:39.559: INFO: Created: latency-svc-pzrgk
May 31 03:16:39.577: INFO: Got endpoints: latency-svc-5gj4r [748.061783ms]
May 31 03:16:39.593: INFO: Created: latency-svc-xhw2h
May 31 03:16:39.632: INFO: Got endpoints: latency-svc-bk9zg [744.120817ms]
May 31 03:16:39.653: INFO: Created: latency-svc-jd4fx
May 31 03:16:39.677: INFO: Got endpoints: latency-svc-z4nzt [749.0915ms]
May 31 03:16:39.732: INFO: Created: latency-svc-g6rw2
May 31 03:16:39.734: INFO: Got endpoints: latency-svc-snfqf [754.107584ms]
May 31 03:16:39.752: INFO: Created: latency-svc-vsw8p
May 31 03:16:39.777: INFO: Got endpoints: latency-svc-cl6cn [746.947864ms]
May 31 03:16:39.800: INFO: Created: latency-svc-hpqwf
May 31 03:16:39.853: INFO: Got endpoints: latency-svc-plb8b [776.136552ms]
May 31 03:16:39.875: INFO: Created: latency-svc-q2bkj
May 31 03:16:39.884: INFO: Got endpoints: latency-svc-zvrqm [753.321871ms]
May 31 03:16:39.910: INFO: Created: latency-svc-qd9nb
May 31 03:16:39.928: INFO: Got endpoints: latency-svc-gkxk2 [749.940214ms]
May 31 03:16:39.942: INFO: Created: latency-svc-lvt5n
May 31 03:16:39.977: INFO: Got endpoints: latency-svc-rmn6s [748.920997ms]
May 31 03:16:39.987: INFO: Created: latency-svc-4hmfn
May 31 03:16:40.027: INFO: Got endpoints: latency-svc-hl2f6 [746.248952ms]
May 31 03:16:40.039: INFO: Created: latency-svc-gdlvw
May 31 03:16:40.082: INFO: Got endpoints: latency-svc-vklfd [754.785795ms]
May 31 03:16:40.099: INFO: Created: latency-svc-9dfb8
May 31 03:16:40.128: INFO: Got endpoints: latency-svc-2hs7q [750.447623ms]
May 31 03:16:40.139: INFO: Created: latency-svc-7p77q
May 31 03:16:40.178: INFO: Got endpoints: latency-svc-4pl2l [750.552424ms]
May 31 03:16:40.189: INFO: Created: latency-svc-6q4qt
May 31 03:16:40.227: INFO: Got endpoints: latency-svc-57dq8 [727.52594ms]
May 31 03:16:40.242: INFO: Created: latency-svc-ds928
May 31 03:16:40.278: INFO: Got endpoints: latency-svc-pzrgk [729.695176ms]
May 31 03:16:40.293: INFO: Created: latency-svc-ks9f6
May 31 03:16:40.326: INFO: Got endpoints: latency-svc-xhw2h [749.1328ms]
May 31 03:16:40.338: INFO: Created: latency-svc-lqcws
May 31 03:16:40.377: INFO: Got endpoints: latency-svc-jd4fx [745.284836ms]
May 31 03:16:40.388: INFO: Created: latency-svc-wj8rd
May 31 03:16:40.438: INFO: Got endpoints: latency-svc-g6rw2 [759.91938ms]
May 31 03:16:40.458: INFO: Created: latency-svc-hrzxz
May 31 03:16:40.478: INFO: Got endpoints: latency-svc-vsw8p [744.209517ms]
May 31 03:16:40.494: INFO: Created: latency-svc-l7tfv
May 31 03:16:40.538: INFO: Got endpoints: latency-svc-hpqwf [760.279885ms]
May 31 03:16:40.557: INFO: Created: latency-svc-vdzss
May 31 03:16:40.579: INFO: Got endpoints: latency-svc-q2bkj [725.276401ms]
May 31 03:16:40.592: INFO: Created: latency-svc-kll6v
May 31 03:16:40.627: INFO: Got endpoints: latency-svc-qd9nb [742.767393ms]
May 31 03:16:40.641: INFO: Created: latency-svc-ngm72
May 31 03:16:40.680: INFO: Got endpoints: latency-svc-lvt5n [751.292035ms]
May 31 03:16:40.708: INFO: Created: latency-svc-rzqmm
May 31 03:16:40.728: INFO: Got endpoints: latency-svc-4hmfn [750.36902ms]
May 31 03:16:40.745: INFO: Created: latency-svc-s7tlc
May 31 03:16:40.778: INFO: Got endpoints: latency-svc-gdlvw [751.245234ms]
May 31 03:16:40.801: INFO: Created: latency-svc-dnmlf
May 31 03:16:40.849: INFO: Got endpoints: latency-svc-9dfb8 [766.209583ms]
May 31 03:16:40.865: INFO: Created: latency-svc-hznck
May 31 03:16:40.878: INFO: Got endpoints: latency-svc-7p77q [750.40382ms]
May 31 03:16:40.896: INFO: Created: latency-svc-ldkbm
May 31 03:16:40.927: INFO: Got endpoints: latency-svc-6q4qt [749.2266ms]
May 31 03:16:40.950: INFO: Created: latency-svc-pk6v7
May 31 03:16:40.977: INFO: Got endpoints: latency-svc-ds928 [749.916912ms]
May 31 03:16:40.990: INFO: Created: latency-svc-ns8w2
May 31 03:16:41.028: INFO: Got endpoints: latency-svc-ks9f6 [749.720809ms]
May 31 03:16:41.051: INFO: Created: latency-svc-rjr2m
May 31 03:16:41.078: INFO: Got endpoints: latency-svc-lqcws [751.756742ms]
May 31 03:16:41.091: INFO: Created: latency-svc-shlmg
May 31 03:16:41.128: INFO: Got endpoints: latency-svc-wj8rd [750.739125ms]
May 31 03:16:41.152: INFO: Created: latency-svc-7r44z
May 31 03:16:41.178: INFO: Got endpoints: latency-svc-hrzxz [739.65824ms]
May 31 03:16:41.200: INFO: Created: latency-svc-b7pnw
May 31 03:16:41.228: INFO: Got endpoints: latency-svc-l7tfv [749.882511ms]
May 31 03:16:41.244: INFO: Created: latency-svc-9rrnh
May 31 03:16:41.279: INFO: Got endpoints: latency-svc-vdzss [741.383869ms]
May 31 03:16:41.296: INFO: Created: latency-svc-nfknn
May 31 03:16:41.331: INFO: Got endpoints: latency-svc-kll6v [751.789042ms]
May 31 03:16:41.370: INFO: Created: latency-svc-z87xh
May 31 03:16:41.377: INFO: Got endpoints: latency-svc-ngm72 [749.490604ms]
May 31 03:16:41.392: INFO: Created: latency-svc-xppk9
May 31 03:16:41.432: INFO: Got endpoints: latency-svc-rzqmm [752.106047ms]
May 31 03:16:41.458: INFO: Created: latency-svc-44jp6
May 31 03:16:41.479: INFO: Got endpoints: latency-svc-s7tlc [748.483387ms]
May 31 03:16:41.492: INFO: Created: latency-svc-6wks5
May 31 03:16:41.602: INFO: Got endpoints: latency-svc-hznck [752.926461ms]
May 31 03:16:41.603: INFO: Got endpoints: latency-svc-dnmlf [822.039114ms]
May 31 03:16:41.626: INFO: Created: latency-svc-vscqk
May 31 03:16:41.633: INFO: Got endpoints: latency-svc-ldkbm [753.963978ms]
May 31 03:16:41.633: INFO: Created: latency-svc-jx7bk
May 31 03:16:41.650: INFO: Created: latency-svc-kzv5k
May 31 03:16:41.677: INFO: Got endpoints: latency-svc-pk6v7 [748.671589ms]
May 31 03:16:41.700: INFO: Created: latency-svc-jxmnk
May 31 03:16:41.729: INFO: Got endpoints: latency-svc-ns8w2 [750.827126ms]
May 31 03:16:41.743: INFO: Created: latency-svc-bhrdx
May 31 03:16:41.779: INFO: Got endpoints: latency-svc-rjr2m [750.259815ms]
May 31 03:16:41.806: INFO: Created: latency-svc-2kbtw
May 31 03:16:41.828: INFO: Got endpoints: latency-svc-shlmg [749.736007ms]
May 31 03:16:41.846: INFO: Created: latency-svc-r2qkr
May 31 03:16:41.887: INFO: Got endpoints: latency-svc-7r44z [758.952461ms]
May 31 03:16:41.905: INFO: Created: latency-svc-2466d
May 31 03:16:41.927: INFO: Got endpoints: latency-svc-b7pnw [749.493503ms]
May 31 03:16:41.944: INFO: Created: latency-svc-gvr8n
May 31 03:16:41.980: INFO: Got endpoints: latency-svc-9rrnh [752.011345ms]
May 31 03:16:41.994: INFO: Created: latency-svc-j9r2v
May 31 03:16:42.028: INFO: Got endpoints: latency-svc-nfknn [748.359084ms]
May 31 03:16:42.049: INFO: Created: latency-svc-rtnpj
May 31 03:16:42.078: INFO: Got endpoints: latency-svc-z87xh [746.629955ms]
May 31 03:16:42.089: INFO: Created: latency-svc-pq856
May 31 03:16:42.132: INFO: Got endpoints: latency-svc-xppk9 [754.565987ms]
May 31 03:16:42.148: INFO: Created: latency-svc-txwjt
May 31 03:16:42.178: INFO: Got endpoints: latency-svc-44jp6 [745.418435ms]
May 31 03:16:42.194: INFO: Created: latency-svc-8x7t6
May 31 03:16:42.228: INFO: Got endpoints: latency-svc-6wks5 [748.526586ms]
May 31 03:16:42.259: INFO: Created: latency-svc-9mwrl
May 31 03:16:42.278: INFO: Got endpoints: latency-svc-vscqk [675.61427ms]
May 31 03:16:42.290: INFO: Created: latency-svc-4fnjr
May 31 03:16:42.328: INFO: Got endpoints: latency-svc-jx7bk [725.098896ms]
May 31 03:16:42.348: INFO: Created: latency-svc-xwd7g
May 31 03:16:42.378: INFO: Got endpoints: latency-svc-kzv5k [745.231231ms]
May 31 03:16:42.393: INFO: Created: latency-svc-2b6dv
May 31 03:16:42.426: INFO: Got endpoints: latency-svc-jxmnk [748.702189ms]
May 31 03:16:42.444: INFO: Created: latency-svc-4jszw
May 31 03:16:42.478: INFO: Got endpoints: latency-svc-bhrdx [748.727289ms]
May 31 03:16:42.490: INFO: Created: latency-svc-7cdbr
May 31 03:16:42.528: INFO: Got endpoints: latency-svc-2kbtw [748.986993ms]
May 31 03:16:42.541: INFO: Created: latency-svc-g9wqc
May 31 03:16:42.577: INFO: Got endpoints: latency-svc-r2qkr [749.044894ms]
May 31 03:16:42.590: INFO: Created: latency-svc-t6mss
May 31 03:16:42.628: INFO: Got endpoints: latency-svc-2466d [740.906158ms]
May 31 03:16:42.643: INFO: Created: latency-svc-x97zz
May 31 03:16:42.683: INFO: Got endpoints: latency-svc-gvr8n [755.313499ms]
May 31 03:16:42.704: INFO: Created: latency-svc-n6mqw
May 31 03:16:42.727: INFO: Got endpoints: latency-svc-j9r2v [746.720355ms]
May 31 03:16:42.740: INFO: Created: latency-svc-7smlm
May 31 03:16:42.777: INFO: Got endpoints: latency-svc-rtnpj [748.427183ms]
May 31 03:16:42.788: INFO: Created: latency-svc-8z49d
May 31 03:16:42.831: INFO: Got endpoints: latency-svc-pq856 [752.858857ms]
May 31 03:16:42.856: INFO: Created: latency-svc-56zwd
May 31 03:16:42.878: INFO: Got endpoints: latency-svc-txwjt [745.851041ms]
May 31 03:16:42.895: INFO: Created: latency-svc-6h28h
May 31 03:16:42.929: INFO: Got endpoints: latency-svc-8x7t6 [751.333132ms]
May 31 03:16:42.948: INFO: Created: latency-svc-5hb8q
May 31 03:16:43.001: INFO: Got endpoints: latency-svc-9mwrl [773.3881ms]
May 31 03:16:43.013: INFO: Created: latency-svc-m7vvw
May 31 03:16:43.027: INFO: Got endpoints: latency-svc-4fnjr [748.931392ms]
May 31 03:16:43.040: INFO: Created: latency-svc-kqhkp
May 31 03:16:43.077: INFO: Got endpoints: latency-svc-xwd7g [748.713388ms]
May 31 03:16:43.094: INFO: Created: latency-svc-nq4w5
May 31 03:16:43.127: INFO: Got endpoints: latency-svc-2b6dv [749.275097ms]
May 31 03:16:43.139: INFO: Created: latency-svc-95bln
May 31 03:16:43.181: INFO: Got endpoints: latency-svc-4jszw [754.898791ms]
May 31 03:16:43.193: INFO: Created: latency-svc-xtkkc
May 31 03:16:43.228: INFO: Got endpoints: latency-svc-7cdbr [749.534402ms]
May 31 03:16:43.279: INFO: Got endpoints: latency-svc-g9wqc [751.24083ms]
May 31 03:16:43.327: INFO: Got endpoints: latency-svc-t6mss [748.789088ms]
May 31 03:16:43.378: INFO: Got endpoints: latency-svc-x97zz [749.729204ms]
May 31 03:16:43.426: INFO: Got endpoints: latency-svc-n6mqw [743.564502ms]
May 31 03:16:43.478: INFO: Got endpoints: latency-svc-7smlm [750.484516ms]
May 31 03:16:43.527: INFO: Got endpoints: latency-svc-8z49d [749.5032ms]
May 31 03:16:43.579: INFO: Got endpoints: latency-svc-56zwd [748.597685ms]
May 31 03:16:43.641: INFO: Got endpoints: latency-svc-6h28h [762.987124ms]
May 31 03:16:43.692: INFO: Got endpoints: latency-svc-5hb8q [762.455616ms]
May 31 03:16:43.750: INFO: Got endpoints: latency-svc-m7vvw [749.044691ms]
May 31 03:16:43.778: INFO: Got endpoints: latency-svc-kqhkp [750.667919ms]
May 31 03:16:43.830: INFO: Got endpoints: latency-svc-nq4w5 [752.450749ms]
May 31 03:16:43.889: INFO: Got endpoints: latency-svc-95bln [761.677102ms]
May 31 03:16:43.930: INFO: Got endpoints: latency-svc-xtkkc [747.798671ms]
May 31 03:16:43.930: INFO: Latencies: [28.924483ms 34.635778ms 36.52181ms 42.186904ms 64.652379ms 66.044602ms 75.219656ms 90.035604ms 97.04492ms 114.908818ms 131.818801ms 132.533513ms 135.601564ms 139.471029ms 141.662266ms 147.138357ms 159.020855ms 163.078923ms 164.632049ms 167.363995ms 168.239909ms 169.957238ms 171.170458ms 171.429362ms 172.757584ms 175.035622ms 178.249377ms 178.814386ms 180.435913ms 181.152924ms 182.784352ms 187.44463ms 188.66765ms 190.267277ms 195.048756ms 197.150492ms 198.357912ms 206.262244ms 211.313229ms 252.093909ms 304.84069ms 326.225947ms 380.367251ms 408.574821ms 429.735375ms 482.529356ms 527.960515ms 579.303072ms 611.339107ms 655.407442ms 675.61427ms 687.377976ms 725.098896ms 725.276401ms 725.51201ms 727.28414ms 727.52594ms 729.695176ms 736.790399ms 736.873898ms 737.264405ms 737.666112ms 737.681813ms 737.805715ms 738.244025ms 738.306623ms 739.65824ms 740.906158ms 741.288375ms 741.383869ms 742.767393ms 743.564502ms 743.679316ms 743.859919ms 744.120817ms 744.209517ms 745.231231ms 745.284836ms 745.418435ms 745.851041ms 746.038151ms 746.248952ms 746.405462ms 746.593662ms 746.629955ms 746.720355ms 746.849466ms 746.947864ms 747.002971ms 747.798671ms 748.061783ms 748.081789ms 748.095285ms 748.359084ms 748.36829ms 748.411993ms 748.427183ms 748.483387ms 748.526586ms 748.596095ms 748.597685ms 748.671589ms 748.702189ms 748.713388ms 748.727289ms 748.789088ms 748.806499ms 748.920997ms 748.931392ms 748.9448ms 748.986993ms 749.044691ms 749.044894ms 749.0915ms 749.1328ms 749.2266ms 749.275097ms 749.490604ms 749.493503ms 749.5032ms 749.534402ms 749.675311ms 749.705616ms 749.720809ms 749.729204ms 749.736007ms 749.782916ms 749.882511ms 749.916912ms 749.918715ms 749.940214ms 749.977016ms 749.998321ms 750.218019ms 750.259815ms 750.26622ms 750.310926ms 750.36902ms 750.40382ms 750.419024ms 750.447623ms 750.467826ms 750.483425ms 750.484516ms 750.53543ms 750.547426ms 750.552424ms 750.63113ms 750.667919ms 750.739125ms 750.782129ms 750.827126ms 751.24083ms 751.245234ms 751.292035ms 751.333132ms 751.655147ms 751.756742ms 751.757747ms 751.789042ms 752.011345ms 752.106047ms 752.285156ms 752.326456ms 752.450749ms 752.858857ms 752.926461ms 753.187771ms 753.321871ms 753.525477ms 753.963978ms 754.107584ms 754.175087ms 754.565987ms 754.785795ms 754.898791ms 755.313499ms 755.463912ms 756.939135ms 757.12744ms 757.19794ms 758.952461ms 759.91938ms 760.279885ms 760.650798ms 761.016604ms 761.222308ms 761.677102ms 761.682814ms 761.956318ms 762.455616ms 762.987124ms 764.301554ms 766.209583ms 768.258326ms 770.954266ms 773.3881ms 775.325042ms 776.136552ms 822.039114ms]
May 31 03:16:43.930: INFO: 50 %ile: 748.597685ms
May 31 03:16:43.930: INFO: 90 %ile: 757.19794ms
May 31 03:16:43.930: INFO: 99 %ile: 776.136552ms
May 31 03:16:43.930: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:16:43.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-hdqdw" for this suite.
May 31 03:16:55.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:16:55.987: INFO: namespace: e2e-tests-svc-latency-hdqdw, resource: bindings, ignored listing per whitelist
May 31 03:16:56.030: INFO: namespace e2e-tests-svc-latency-hdqdw deletion completed in 12.090733841s

• [SLOW TEST:23.910 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:16:56.033: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-8b6a242d-8352-11e9-949c-223764f7eae1
STEP: Creating a pod to test consume configMaps
May 31 03:16:56.114: INFO: Waiting up to 5m0s for pod "pod-configmaps-8b6a98e7-8352-11e9-949c-223764f7eae1" in namespace "e2e-tests-configmap-t5mq8" to be "success or failure"
May 31 03:16:56.120: INFO: Pod "pod-configmaps-8b6a98e7-8352-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.82008ms
May 31 03:16:58.122: INFO: Pod "pod-configmaps-8b6a98e7-8352-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007575513s
May 31 03:17:00.125: INFO: Pod "pod-configmaps-8b6a98e7-8352-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010208433s
STEP: Saw pod success
May 31 03:17:00.125: INFO: Pod "pod-configmaps-8b6a98e7-8352-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:17:00.127: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod pod-configmaps-8b6a98e7-8352-11e9-949c-223764f7eae1 container configmap-volume-test: <nil>
STEP: delete the pod
May 31 03:17:00.141: INFO: Waiting for pod pod-configmaps-8b6a98e7-8352-11e9-949c-223764f7eae1 to disappear
May 31 03:17:00.143: INFO: Pod pod-configmaps-8b6a98e7-8352-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:17:00.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-t5mq8" for this suite.
May 31 03:17:06.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:17:06.228: INFO: namespace: e2e-tests-configmap-t5mq8, resource: bindings, ignored listing per whitelist
May 31 03:17:06.237: INFO: namespace e2e-tests-configmap-t5mq8 deletion completed in 6.091850099s

• [SLOW TEST:10.205 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:17:06.238: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 31 03:17:06.335: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"917fef4c-8352-11e9-944d-001dd80c001b", Controller:(*bool)(0xc0035a9552), BlockOwnerDeletion:(*bool)(0xc0035a9553)}}
May 31 03:17:06.347: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"917e61a7-8352-11e9-944d-001dd80c001b", Controller:(*bool)(0xc001de9986), BlockOwnerDeletion:(*bool)(0xc001de9987)}}
May 31 03:17:06.351: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"917f4893-8352-11e9-944d-001dd80c001b", Controller:(*bool)(0xc0035a974e), BlockOwnerDeletion:(*bool)(0xc0035a974f)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:17:11.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-r7794" for this suite.
May 31 03:17:17.373: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:17:17.426: INFO: namespace: e2e-tests-gc-r7794, resource: bindings, ignored listing per whitelist
May 31 03:17:17.449: INFO: namespace e2e-tests-gc-r7794 deletion completed in 6.08426381s

• [SLOW TEST:11.212 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:17:17.451: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
May 31 03:17:17.552: INFO: Waiting up to 5m0s for pod "client-containers-9831876b-8352-11e9-949c-223764f7eae1" in namespace "e2e-tests-containers-rhgjn" to be "success or failure"
May 31 03:17:17.556: INFO: Pod "client-containers-9831876b-8352-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.360956ms
May 31 03:17:19.559: INFO: Pod "client-containers-9831876b-8352-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006254688s
May 31 03:17:21.561: INFO: Pod "client-containers-9831876b-8352-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008715004s
STEP: Saw pod success
May 31 03:17:21.561: INFO: Pod "client-containers-9831876b-8352-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:17:21.564: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod client-containers-9831876b-8352-11e9-949c-223764f7eae1 container test-container: <nil>
STEP: delete the pod
May 31 03:17:21.577: INFO: Waiting for pod client-containers-9831876b-8352-11e9-949c-223764f7eae1 to disappear
May 31 03:17:21.580: INFO: Pod client-containers-9831876b-8352-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:17:21.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-rhgjn" for this suite.
May 31 03:17:27.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:17:27.656: INFO: namespace: e2e-tests-containers-rhgjn, resource: bindings, ignored listing per whitelist
May 31 03:17:27.667: INFO: namespace e2e-tests-containers-rhgjn deletion completed in 6.083532954s

• [SLOW TEST:10.216 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:17:27.667: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 31 03:17:27.744: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9e44e288-8352-11e9-949c-223764f7eae1" in namespace "e2e-tests-downward-api-5ngln" to be "success or failure"
May 31 03:17:27.752: INFO: Pod "downwardapi-volume-9e44e288-8352-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 7.652026ms
May 31 03:17:29.755: INFO: Pod "downwardapi-volume-9e44e288-8352-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01042741s
May 31 03:17:31.764: INFO: Pod "downwardapi-volume-9e44e288-8352-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019283984s
STEP: Saw pod success
May 31 03:17:31.764: INFO: Pod "downwardapi-volume-9e44e288-8352-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:17:31.767: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod downwardapi-volume-9e44e288-8352-11e9-949c-223764f7eae1 container client-container: <nil>
STEP: delete the pod
May 31 03:17:31.787: INFO: Waiting for pod downwardapi-volume-9e44e288-8352-11e9-949c-223764f7eae1 to disappear
May 31 03:17:31.789: INFO: Pod downwardapi-volume-9e44e288-8352-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:17:31.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5ngln" for this suite.
May 31 03:17:37.801: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:17:37.873: INFO: namespace: e2e-tests-downward-api-5ngln, resource: bindings, ignored listing per whitelist
May 31 03:17:37.880: INFO: namespace e2e-tests-downward-api-5ngln deletion completed in 6.088032386s

• [SLOW TEST:10.213 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:17:37.881: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
May 31 03:17:37.989: INFO: Waiting up to 5m0s for pod "pod-a46043e3-8352-11e9-949c-223764f7eae1" in namespace "e2e-tests-emptydir-nmxs6" to be "success or failure"
May 31 03:17:37.998: INFO: Pod "pod-a46043e3-8352-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.344139ms
May 31 03:17:40.007: INFO: Pod "pod-a46043e3-8352-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017125675s
May 31 03:17:42.010: INFO: Pod "pod-a46043e3-8352-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019955503s
STEP: Saw pod success
May 31 03:17:42.010: INFO: Pod "pod-a46043e3-8352-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:17:42.012: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod pod-a46043e3-8352-11e9-949c-223764f7eae1 container test-container: <nil>
STEP: delete the pod
May 31 03:17:42.035: INFO: Waiting for pod pod-a46043e3-8352-11e9-949c-223764f7eae1 to disappear
May 31 03:17:42.037: INFO: Pod pod-a46043e3-8352-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:17:42.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-nmxs6" for this suite.
May 31 03:17:48.049: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:17:48.140: INFO: namespace: e2e-tests-emptydir-nmxs6, resource: bindings, ignored listing per whitelist
May 31 03:17:48.162: INFO: namespace e2e-tests-emptydir-nmxs6 deletion completed in 6.122295812s

• [SLOW TEST:10.281 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:17:48.164: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
May 31 03:17:48.238: INFO: PodSpec: initContainers in spec.initContainers
May 31 03:18:29.390: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-aa7cef19-8352-11e9-949c-223764f7eae1", GenerateName:"", Namespace:"e2e-tests-init-container-zjmh2", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-zjmh2/pods/pod-init-aa7cef19-8352-11e9-949c-223764f7eae1", UID:"aa7d64d0-8352-11e9-944d-001dd80c001b", ResourceVersion:"16193", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63694869468, loc:(*time.Location)(0x7b6dbe0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"238215360"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-4h7vs", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001cb7040), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-4h7vs", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-4h7vs", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-4h7vs", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0004a11a8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"k8s-linuxpool-39082607-0", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc000a9dd40), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0004a12b0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0004a12f0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0004a12f8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0004a12fc)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694869468, loc:(*time.Location)(0x7b6dbe0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694869468, loc:(*time.Location)(0x7b6dbe0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694869468, loc:(*time.Location)(0x7b6dbe0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694869468, loc:(*time.Location)(0x7b6dbe0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.240.0.4", PodIP:"10.244.3.139", StartTime:(*v1.Time)(0xc001b06320), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001b49730)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001b497a0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://c9fd54ac080ec203fc7f8dd0f62d4d2a3fba9f3a9a2d421e373241dacfd89489"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001b06360), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001b06340), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:18:29.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-zjmh2" for this suite.
May 31 03:18:51.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:18:51.466: INFO: namespace: e2e-tests-init-container-zjmh2, resource: bindings, ignored listing per whitelist
May 31 03:18:51.485: INFO: namespace e2e-tests-init-container-zjmh2 deletion completed in 22.090349325s

• [SLOW TEST:63.321 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:18:51.485: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
May 31 03:18:56.088: INFO: Successfully updated pod "pod-update-d03acaed-8352-11e9-949c-223764f7eae1"
STEP: verifying the updated pod is in kubernetes
May 31 03:18:56.092: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:18:56.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-km6gs" for this suite.
May 31 03:19:18.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:19:18.183: INFO: namespace: e2e-tests-pods-km6gs, resource: bindings, ignored listing per whitelist
May 31 03:19:18.200: INFO: namespace e2e-tests-pods-km6gs deletion completed in 22.10438441s

• [SLOW TEST:26.714 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:19:18.203: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
May 31 03:19:26.322: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 31 03:19:26.324: INFO: Pod pod-with-poststart-exec-hook still exists
May 31 03:19:28.325: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 31 03:19:28.328: INFO: Pod pod-with-poststart-exec-hook still exists
May 31 03:19:30.325: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 31 03:19:30.327: INFO: Pod pod-with-poststart-exec-hook still exists
May 31 03:19:32.325: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 31 03:19:32.328: INFO: Pod pod-with-poststart-exec-hook still exists
May 31 03:19:34.325: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 31 03:19:34.327: INFO: Pod pod-with-poststart-exec-hook still exists
May 31 03:19:36.325: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 31 03:19:36.328: INFO: Pod pod-with-poststart-exec-hook still exists
May 31 03:19:38.325: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 31 03:19:38.328: INFO: Pod pod-with-poststart-exec-hook still exists
May 31 03:19:40.325: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 31 03:19:40.328: INFO: Pod pod-with-poststart-exec-hook still exists
May 31 03:19:42.325: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 31 03:19:42.328: INFO: Pod pod-with-poststart-exec-hook still exists
May 31 03:19:44.325: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 31 03:19:44.328: INFO: Pod pod-with-poststart-exec-hook still exists
May 31 03:19:46.325: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 31 03:19:46.328: INFO: Pod pod-with-poststart-exec-hook still exists
May 31 03:19:48.325: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 31 03:19:48.328: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:19:48.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-5hqbm" for this suite.
May 31 03:20:10.342: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:20:10.377: INFO: namespace: e2e-tests-container-lifecycle-hook-5hqbm, resource: bindings, ignored listing per whitelist
May 31 03:20:10.417: INFO: namespace e2e-tests-container-lifecycle-hook-5hqbm deletion completed in 22.085676432s

• [SLOW TEST:52.214 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:20:10.417: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 31 03:20:10.489: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ff45eeef-8352-11e9-949c-223764f7eae1" in namespace "e2e-tests-downward-api-lzdcg" to be "success or failure"
May 31 03:20:10.494: INFO: Pod "downwardapi-volume-ff45eeef-8352-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.660192ms
May 31 03:20:12.497: INFO: Pod "downwardapi-volume-ff45eeef-8352-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008192132s
May 31 03:20:14.500: INFO: Pod "downwardapi-volume-ff45eeef-8352-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011331275s
STEP: Saw pod success
May 31 03:20:14.500: INFO: Pod "downwardapi-volume-ff45eeef-8352-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:20:14.504: INFO: Trying to get logs from node k8s-linuxpool-39082607-2 pod downwardapi-volume-ff45eeef-8352-11e9-949c-223764f7eae1 container client-container: <nil>
STEP: delete the pod
May 31 03:20:14.538: INFO: Waiting for pod downwardapi-volume-ff45eeef-8352-11e9-949c-223764f7eae1 to disappear
May 31 03:20:14.543: INFO: Pod downwardapi-volume-ff45eeef-8352-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:20:14.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-lzdcg" for this suite.
May 31 03:20:20.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:20:20.582: INFO: namespace: e2e-tests-downward-api-lzdcg, resource: bindings, ignored listing per whitelist
May 31 03:20:20.644: INFO: namespace e2e-tests-downward-api-lzdcg deletion completed in 6.093528355s

• [SLOW TEST:10.227 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:20:20.644: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-dcnsc
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-dcnsc to expose endpoints map[]
May 31 03:20:20.740: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-dcnsc exposes endpoints map[] (12.010995ms elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-dcnsc
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-dcnsc to expose endpoints map[pod1:[80]]
May 31 03:20:23.789: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-dcnsc exposes endpoints map[pod1:[80]] (3.037784708s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-dcnsc
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-dcnsc to expose endpoints map[pod2:[80] pod1:[80]]
May 31 03:20:26.837: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-dcnsc exposes endpoints map[pod1:[80] pod2:[80]] (3.042137564s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-dcnsc
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-dcnsc to expose endpoints map[pod2:[80]]
May 31 03:20:26.858: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-dcnsc exposes endpoints map[pod2:[80]] (17.29408ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-dcnsc
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-dcnsc to expose endpoints map[]
May 31 03:20:27.872: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-dcnsc exposes endpoints map[] (1.008173056s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:20:27.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-dcnsc" for this suite.
May 31 03:20:49.916: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:20:49.978: INFO: namespace: e2e-tests-services-dcnsc, resource: bindings, ignored listing per whitelist
May 31 03:20:49.993: INFO: namespace e2e-tests-services-dcnsc deletion completed in 22.100784043s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:29.349 seconds]
[sig-network] Services
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:20:49.993: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-tx5n8
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-tx5n8
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-tx5n8
May 31 03:20:50.075: INFO: Found 0 stateful pods, waiting for 1
May 31 03:21:00.078: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
May 31 03:21:00.081: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 exec --namespace=e2e-tests-statefulset-tx5n8 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 31 03:21:00.318: INFO: stderr: ""
May 31 03:21:00.318: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 31 03:21:00.318: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 31 03:21:00.321: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May 31 03:21:10.324: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 31 03:21:10.324: INFO: Waiting for statefulset status.replicas updated to 0
May 31 03:21:10.341: INFO: POD   NODE                      PHASE    GRACE  CONDITIONS
May 31 03:21:10.341: INFO: ss-0  k8s-linuxpool-39082607-0  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:20:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:21:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:21:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:20:50 +0000 UTC  }]
May 31 03:21:10.341: INFO: 
May 31 03:21:10.341: INFO: StatefulSet ss has not reached scale 3, at 1
May 31 03:21:11.344: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.98982918s
May 31 03:21:12.348: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.98642707s
May 31 03:21:13.352: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.982942961s
May 31 03:21:14.356: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.978780342s
May 31 03:21:15.361: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.974703126s
May 31 03:21:16.364: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.9699108s
May 31 03:21:17.368: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.966476797s
May 31 03:21:18.376: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.96268379s
May 31 03:21:19.380: INFO: Verifying statefulset ss doesn't scale past 3 for another 954.560515ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-tx5n8
May 31 03:21:20.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 exec --namespace=e2e-tests-statefulset-tx5n8 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 31 03:21:20.605: INFO: stderr: ""
May 31 03:21:20.605: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 31 03:21:20.605: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 31 03:21:20.605: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 exec --namespace=e2e-tests-statefulset-tx5n8 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 31 03:21:20.830: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
May 31 03:21:20.830: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 31 03:21:20.830: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 31 03:21:20.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 exec --namespace=e2e-tests-statefulset-tx5n8 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 31 03:21:21.047: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
May 31 03:21:21.047: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 31 03:21:21.047: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 31 03:21:21.049: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
May 31 03:21:31.053: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May 31 03:21:31.053: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May 31 03:21:31.053: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
May 31 03:21:31.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 exec --namespace=e2e-tests-statefulset-tx5n8 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 31 03:21:31.276: INFO: stderr: ""
May 31 03:21:31.276: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 31 03:21:31.276: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 31 03:21:31.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 exec --namespace=e2e-tests-statefulset-tx5n8 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 31 03:21:31.529: INFO: stderr: ""
May 31 03:21:31.529: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 31 03:21:31.529: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 31 03:21:31.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 exec --namespace=e2e-tests-statefulset-tx5n8 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 31 03:21:31.773: INFO: stderr: ""
May 31 03:21:31.773: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 31 03:21:31.773: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 31 03:21:31.773: INFO: Waiting for statefulset status.replicas updated to 0
May 31 03:21:31.776: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
May 31 03:21:41.784: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 31 03:21:41.784: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May 31 03:21:41.784: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May 31 03:21:41.803: INFO: POD   NODE                      PHASE    GRACE  CONDITIONS
May 31 03:21:41.803: INFO: ss-0  k8s-linuxpool-39082607-0  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:20:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:21:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:21:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:20:50 +0000 UTC  }]
May 31 03:21:41.803: INFO: ss-1  k8s-linuxpool-39082607-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:21:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:21:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:21:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:21:10 +0000 UTC  }]
May 31 03:21:41.803: INFO: ss-2  k8s-linuxpool-39082607-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:21:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:21:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:21:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:21:10 +0000 UTC  }]
May 31 03:21:41.803: INFO: 
May 31 03:21:41.803: INFO: StatefulSet ss has not reached scale 0, at 3
May 31 03:21:42.806: INFO: POD   NODE                      PHASE    GRACE  CONDITIONS
May 31 03:21:42.806: INFO: ss-0  k8s-linuxpool-39082607-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:20:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:21:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:21:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:20:50 +0000 UTC  }]
May 31 03:21:42.806: INFO: ss-1  k8s-linuxpool-39082607-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:21:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:21:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:21:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:21:10 +0000 UTC  }]
May 31 03:21:42.806: INFO: ss-2  k8s-linuxpool-39082607-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:21:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:21:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:21:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:21:10 +0000 UTC  }]
May 31 03:21:42.806: INFO: 
May 31 03:21:42.806: INFO: StatefulSet ss has not reached scale 0, at 3
May 31 03:21:43.811: INFO: POD   NODE                      PHASE    GRACE  CONDITIONS
May 31 03:21:43.811: INFO: ss-1  k8s-linuxpool-39082607-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:21:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:21:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:21:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:21:10 +0000 UTC  }]
May 31 03:21:43.811: INFO: ss-2  k8s-linuxpool-39082607-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:21:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:21:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:21:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:21:10 +0000 UTC  }]
May 31 03:21:43.811: INFO: 
May 31 03:21:43.811: INFO: StatefulSet ss has not reached scale 0, at 2
May 31 03:21:44.814: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.984778626s
May 31 03:21:45.817: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.981772471s
May 31 03:21:46.820: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.978784918s
May 31 03:21:47.822: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.975824767s
May 31 03:21:48.825: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.973466526s
May 31 03:21:49.827: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.971089387s
May 31 03:21:50.830: INFO: Verifying statefulset ss doesn't scale past 0 for another 968.664948ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-tx5n8
May 31 03:21:51.832: INFO: Scaling statefulset ss to 0
May 31 03:21:51.839: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 31 03:21:51.841: INFO: Deleting all statefulset in ns e2e-tests-statefulset-tx5n8
May 31 03:21:51.843: INFO: Scaling statefulset ss to 0
May 31 03:21:51.849: INFO: Waiting for statefulset status.replicas updated to 0
May 31 03:21:51.851: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:21:51.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-tx5n8" for this suite.
May 31 03:21:57.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:21:57.946: INFO: namespace: e2e-tests-statefulset-tx5n8, resource: bindings, ignored listing per whitelist
May 31 03:21:57.950: INFO: namespace e2e-tests-statefulset-tx5n8 deletion completed in 6.085308633s

• [SLOW TEST:67.956 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:21:57.950: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-3f5f6b76-8353-11e9-949c-223764f7eae1
STEP: Creating configMap with name cm-test-opt-upd-3f5f6bb2-8353-11e9-949c-223764f7eae1
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-3f5f6b76-8353-11e9-949c-223764f7eae1
STEP: Updating configmap cm-test-opt-upd-3f5f6bb2-8353-11e9-949c-223764f7eae1
STEP: Creating configMap with name cm-test-opt-create-3f5f6bca-8353-11e9-949c-223764f7eae1
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:22:06.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-f5m58" for this suite.
May 31 03:22:28.122: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:22:28.183: INFO: namespace: e2e-tests-configmap-f5m58, resource: bindings, ignored listing per whitelist
May 31 03:22:28.204: INFO: namespace e2e-tests-configmap-f5m58 deletion completed in 22.090950567s

• [SLOW TEST:30.254 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:22:28.205: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:22:32.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-p5jjs" for this suite.
May 31 03:22:38.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:22:38.396: INFO: namespace: e2e-tests-kubelet-test-p5jjs, resource: bindings, ignored listing per whitelist
May 31 03:22:38.409: INFO: namespace e2e-tests-kubelet-test-p5jjs deletion completed in 6.09831942s

• [SLOW TEST:10.205 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:22:38.409: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
May 31 03:22:38.489: INFO: Waiting up to 5m0s for pod "client-containers-577cf124-8353-11e9-949c-223764f7eae1" in namespace "e2e-tests-containers-694tn" to be "success or failure"
May 31 03:22:38.519: INFO: Pod "client-containers-577cf124-8353-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 29.94298ms
May 31 03:22:40.543: INFO: Pod "client-containers-577cf124-8353-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054312342s
May 31 03:22:42.559: INFO: Pod "client-containers-577cf124-8353-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.069751155s
STEP: Saw pod success
May 31 03:22:42.559: INFO: Pod "client-containers-577cf124-8353-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:22:42.563: INFO: Trying to get logs from node k8s-linuxpool-39082607-2 pod client-containers-577cf124-8353-11e9-949c-223764f7eae1 container test-container: <nil>
STEP: delete the pod
May 31 03:22:42.585: INFO: Waiting for pod client-containers-577cf124-8353-11e9-949c-223764f7eae1 to disappear
May 31 03:22:42.587: INFO: Pod client-containers-577cf124-8353-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:22:42.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-694tn" for this suite.
May 31 03:22:48.598: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:22:48.656: INFO: namespace: e2e-tests-containers-694tn, resource: bindings, ignored listing per whitelist
May 31 03:22:48.684: INFO: namespace e2e-tests-containers-694tn deletion completed in 6.094300678s

• [SLOW TEST:10.275 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:22:48.687: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 31 03:22:48.763: INFO: Pod name cleanup-pod: Found 0 pods out of 1
May 31 03:22:53.767: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May 31 03:22:53.767: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 31 03:22:53.784: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-lgkzn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lgkzn/deployments/test-cleanup-deployment,UID:60999adc-8353-11e9-944d-001dd80c001b,ResourceVersion:17043,Generation:1,CreationTimestamp:2019-05-31 03:22:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

May 31 03:22:53.786: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
May 31 03:22:53.787: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
May 31 03:22:53.788: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-lgkzn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lgkzn/replicasets/test-cleanup-controller,UID:5d9c8239-8353-11e9-944d-001dd80c001b,ResourceVersion:17044,Generation:1,CreationTimestamp:2019-05-31 03:22:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 60999adc-8353-11e9-944d-001dd80c001b 0xc001ac7ac7 0xc001ac7ac8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
May 31 03:22:53.792: INFO: Pod "test-cleanup-controller-dr826" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-dr826,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-lgkzn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lgkzn/pods/test-cleanup-controller-dr826,UID:5d9e037f-8353-11e9-944d-001dd80c001b,ResourceVersion:17035,Generation:0,CreationTimestamp:2019-05-31 03:22:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 5d9c8239-8353-11e9-944d-001dd80c001b 0xc001afa077 0xc001afa078}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mc2wg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mc2wg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mc2wg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-linuxpool-39082607-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001afa0f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001afa110}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:22:48 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:22:51 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:22:51 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:22:48 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.4,PodIP:10.244.3.146,StartTime:2019-05-31 03:22:48 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-31 03:22:50 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://1b2358de82e8058957872ef3b8361b953c2b793b6522909f45a404a61f3bf593}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:22:53.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-lgkzn" for this suite.
May 31 03:22:59.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:22:59.865: INFO: namespace: e2e-tests-deployment-lgkzn, resource: bindings, ignored listing per whitelist
May 31 03:22:59.901: INFO: namespace e2e-tests-deployment-lgkzn deletion completed in 6.103890348s

• [SLOW TEST:11.214 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:22:59.902: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-644bd0bc-8353-11e9-949c-223764f7eae1
STEP: Creating a pod to test consume secrets
May 31 03:22:59.980: INFO: Waiting up to 5m0s for pod "pod-secrets-644c3d4a-8353-11e9-949c-223764f7eae1" in namespace "e2e-tests-secrets-tfhrk" to be "success or failure"
May 31 03:22:59.984: INFO: Pod "pod-secrets-644c3d4a-8353-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.127866ms
May 31 03:23:01.987: INFO: Pod "pod-secrets-644c3d4a-8353-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006840228s
May 31 03:23:03.990: INFO: Pod "pod-secrets-644c3d4a-8353-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009864089s
STEP: Saw pod success
May 31 03:23:03.990: INFO: Pod "pod-secrets-644c3d4a-8353-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:23:03.992: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod pod-secrets-644c3d4a-8353-11e9-949c-223764f7eae1 container secret-volume-test: <nil>
STEP: delete the pod
May 31 03:23:04.012: INFO: Waiting for pod pod-secrets-644c3d4a-8353-11e9-949c-223764f7eae1 to disappear
May 31 03:23:04.016: INFO: Pod pod-secrets-644c3d4a-8353-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:23:04.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-tfhrk" for this suite.
May 31 03:23:10.029: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:23:10.069: INFO: namespace: e2e-tests-secrets-tfhrk, resource: bindings, ignored listing per whitelist
May 31 03:23:10.122: INFO: namespace e2e-tests-secrets-tfhrk deletion completed in 6.101281132s

• [SLOW TEST:10.220 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:23:10.122: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 31 03:23:10.228: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6a66b660-8353-11e9-949c-223764f7eae1" in namespace "e2e-tests-projected-sj44f" to be "success or failure"
May 31 03:23:10.232: INFO: Pod "downwardapi-volume-6a66b660-8353-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.543572ms
May 31 03:23:12.235: INFO: Pod "downwardapi-volume-6a66b660-8353-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007338811s
May 31 03:23:14.242: INFO: Pod "downwardapi-volume-6a66b660-8353-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014682018s
STEP: Saw pod success
May 31 03:23:14.242: INFO: Pod "downwardapi-volume-6a66b660-8353-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:23:14.244: INFO: Trying to get logs from node k8s-linuxpool-39082607-2 pod downwardapi-volume-6a66b660-8353-11e9-949c-223764f7eae1 container client-container: <nil>
STEP: delete the pod
May 31 03:23:14.265: INFO: Waiting for pod downwardapi-volume-6a66b660-8353-11e9-949c-223764f7eae1 to disappear
May 31 03:23:14.269: INFO: Pod downwardapi-volume-6a66b660-8353-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:23:14.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sj44f" for this suite.
May 31 03:23:20.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:23:20.329: INFO: namespace: e2e-tests-projected-sj44f, resource: bindings, ignored listing per whitelist
May 31 03:23:20.371: INFO: namespace e2e-tests-projected-sj44f deletion completed in 6.089829176s

• [SLOW TEST:10.249 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:23:20.371: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
May 31 03:23:27.472: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:23:27.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-p4tm5" for this suite.
May 31 03:23:49.502: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:23:49.567: INFO: namespace: e2e-tests-replicaset-p4tm5, resource: bindings, ignored listing per whitelist
May 31 03:23:49.581: INFO: namespace e2e-tests-replicaset-p4tm5 deletion completed in 22.090791299s

• [SLOW TEST:29.210 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:23:49.582: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
May 31 03:23:49.725: INFO: Waiting up to 5m0s for pod "pod-81f2312e-8353-11e9-949c-223764f7eae1" in namespace "e2e-tests-emptydir-z4htc" to be "success or failure"
May 31 03:23:49.729: INFO: Pod "pod-81f2312e-8353-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.38567ms
May 31 03:23:51.732: INFO: Pod "pod-81f2312e-8353-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007003117s
May 31 03:23:53.735: INFO: Pod "pod-81f2312e-8353-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009749361s
STEP: Saw pod success
May 31 03:23:53.735: INFO: Pod "pod-81f2312e-8353-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:23:53.737: INFO: Trying to get logs from node k8s-linuxpool-39082607-2 pod pod-81f2312e-8353-11e9-949c-223764f7eae1 container test-container: <nil>
STEP: delete the pod
May 31 03:23:53.754: INFO: Waiting for pod pod-81f2312e-8353-11e9-949c-223764f7eae1 to disappear
May 31 03:23:53.756: INFO: Pod pod-81f2312e-8353-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:23:53.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-z4htc" for this suite.
May 31 03:23:59.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:23:59.814: INFO: namespace: e2e-tests-emptydir-z4htc, resource: bindings, ignored listing per whitelist
May 31 03:23:59.849: INFO: namespace e2e-tests-emptydir-z4htc deletion completed in 6.089917409s

• [SLOW TEST:10.267 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:23:59.851: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
May 31 03:23:59.925: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

May 31 03:23:59.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 create -f - --namespace=e2e-tests-kubectl-hfdkk'
May 31 03:24:00.568: INFO: stderr: ""
May 31 03:24:00.568: INFO: stdout: "service/redis-slave created\n"
May 31 03:24:00.568: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

May 31 03:24:00.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 create -f - --namespace=e2e-tests-kubectl-hfdkk'
May 31 03:24:00.880: INFO: stderr: ""
May 31 03:24:00.880: INFO: stdout: "service/redis-master created\n"
May 31 03:24:00.880: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

May 31 03:24:00.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 create -f - --namespace=e2e-tests-kubectl-hfdkk'
May 31 03:24:01.181: INFO: stderr: ""
May 31 03:24:01.181: INFO: stdout: "service/frontend created\n"
May 31 03:24:01.181: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

May 31 03:24:01.181: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 create -f - --namespace=e2e-tests-kubectl-hfdkk'
May 31 03:24:01.466: INFO: stderr: ""
May 31 03:24:01.466: INFO: stdout: "deployment.extensions/frontend created\n"
May 31 03:24:01.466: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

May 31 03:24:01.466: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 create -f - --namespace=e2e-tests-kubectl-hfdkk'
May 31 03:24:01.767: INFO: stderr: ""
May 31 03:24:01.767: INFO: stdout: "deployment.extensions/redis-master created\n"
May 31 03:24:01.767: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

May 31 03:24:01.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 create -f - --namespace=e2e-tests-kubectl-hfdkk'
May 31 03:24:02.037: INFO: stderr: ""
May 31 03:24:02.037: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
May 31 03:24:02.037: INFO: Waiting for all frontend pods to be Running.
May 31 03:24:37.089: INFO: Waiting for frontend to serve content.
May 31 03:24:37.101: INFO: Trying to add a new entry to the guestbook.
May 31 03:24:37.119: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
May 31 03:24:37.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hfdkk'
May 31 03:24:37.230: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 31 03:24:37.230: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
May 31 03:24:37.231: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hfdkk'
May 31 03:24:37.365: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 31 03:24:37.365: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
May 31 03:24:37.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hfdkk'
May 31 03:24:37.497: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 31 03:24:37.497: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
May 31 03:24:37.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hfdkk'
May 31 03:24:37.608: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 31 03:24:37.608: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
May 31 03:24:37.608: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hfdkk'
May 31 03:24:37.718: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 31 03:24:37.718: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
May 31 03:24:37.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hfdkk'
May 31 03:24:37.819: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 31 03:24:37.819: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:24:37.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hfdkk" for this suite.
May 31 03:25:19.838: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:25:19.877: INFO: namespace: e2e-tests-kubectl-hfdkk, resource: bindings, ignored listing per whitelist
May 31 03:25:19.922: INFO: namespace e2e-tests-kubectl-hfdkk deletion completed in 42.099233177s

• [SLOW TEST:80.072 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:25:19.924: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-b7c1f767-8353-11e9-949c-223764f7eae1
STEP: Creating secret with name s-test-opt-upd-b7c1f7a0-8353-11e9-949c-223764f7eae1
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-b7c1f767-8353-11e9-949c-223764f7eae1
STEP: Updating secret s-test-opt-upd-b7c1f7a0-8353-11e9-949c-223764f7eae1
STEP: Creating secret with name s-test-opt-create-b7c1f7b7-8353-11e9-949c-223764f7eae1
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:25:28.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6fqmz" for this suite.
May 31 03:25:50.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:25:50.206: INFO: namespace: e2e-tests-projected-6fqmz, resource: bindings, ignored listing per whitelist
May 31 03:25:50.232: INFO: namespace e2e-tests-projected-6fqmz deletion completed in 22.082876535s

• [SLOW TEST:30.308 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:25:50.233: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
May 31 03:25:50.874: INFO: created pod pod-service-account-defaultsa
May 31 03:25:50.874: INFO: pod pod-service-account-defaultsa service account token volume mount: true
May 31 03:25:50.881: INFO: created pod pod-service-account-mountsa
May 31 03:25:50.881: INFO: pod pod-service-account-mountsa service account token volume mount: true
May 31 03:25:50.951: INFO: created pod pod-service-account-nomountsa
May 31 03:25:50.951: INFO: pod pod-service-account-nomountsa service account token volume mount: false
May 31 03:25:50.961: INFO: created pod pod-service-account-defaultsa-mountspec
May 31 03:25:50.961: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
May 31 03:25:50.978: INFO: created pod pod-service-account-mountsa-mountspec
May 31 03:25:50.978: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
May 31 03:25:50.986: INFO: created pod pod-service-account-nomountsa-mountspec
May 31 03:25:50.986: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
May 31 03:25:50.992: INFO: created pod pod-service-account-defaultsa-nomountspec
May 31 03:25:50.992: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
May 31 03:25:50.998: INFO: created pod pod-service-account-mountsa-nomountspec
May 31 03:25:50.998: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
May 31 03:25:51.016: INFO: created pod pod-service-account-nomountsa-nomountspec
May 31 03:25:51.016: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:25:51.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-cq8sp" for this suite.
May 31 03:26:13.044: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:26:13.122: INFO: namespace: e2e-tests-svcaccounts-cq8sp, resource: bindings, ignored listing per whitelist
May 31 03:26:13.122: INFO: namespace e2e-tests-svcaccounts-cq8sp deletion completed in 22.096445316s

• [SLOW TEST:22.889 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:26:13.123: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
May 31 03:26:13.195: INFO: Waiting up to 5m0s for pod "downward-api-d77694af-8353-11e9-949c-223764f7eae1" in namespace "e2e-tests-downward-api-5b2z5" to be "success or failure"
May 31 03:26:13.198: INFO: Pod "downward-api-d77694af-8353-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.53244ms
May 31 03:26:15.202: INFO: Pod "downward-api-d77694af-8353-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006671539s
May 31 03:26:17.205: INFO: Pod "downward-api-d77694af-8353-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009603216s
STEP: Saw pod success
May 31 03:26:17.205: INFO: Pod "downward-api-d77694af-8353-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:26:17.207: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod downward-api-d77694af-8353-11e9-949c-223764f7eae1 container dapi-container: <nil>
STEP: delete the pod
May 31 03:26:17.222: INFO: Waiting for pod downward-api-d77694af-8353-11e9-949c-223764f7eae1 to disappear
May 31 03:26:17.224: INFO: Pod downward-api-d77694af-8353-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:26:17.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5b2z5" for this suite.
May 31 03:26:23.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:26:23.270: INFO: namespace: e2e-tests-downward-api-5b2z5, resource: bindings, ignored listing per whitelist
May 31 03:26:23.333: INFO: namespace e2e-tests-downward-api-5b2z5 deletion completed in 6.106020847s

• [SLOW TEST:10.210 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:26:23.333: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-dd8d7d6c-8353-11e9-949c-223764f7eae1
May 31 03:26:23.421: INFO: Pod name my-hostname-basic-dd8d7d6c-8353-11e9-949c-223764f7eae1: Found 0 pods out of 1
May 31 03:26:28.425: INFO: Pod name my-hostname-basic-dd8d7d6c-8353-11e9-949c-223764f7eae1: Found 1 pods out of 1
May 31 03:26:28.425: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-dd8d7d6c-8353-11e9-949c-223764f7eae1" are running
May 31 03:26:28.427: INFO: Pod "my-hostname-basic-dd8d7d6c-8353-11e9-949c-223764f7eae1-v74lb" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-31 03:26:23 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-31 03:26:27 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-31 03:26:27 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-31 03:26:23 +0000 UTC Reason: Message:}])
May 31 03:26:28.427: INFO: Trying to dial the pod
May 31 03:26:33.436: INFO: Controller my-hostname-basic-dd8d7d6c-8353-11e9-949c-223764f7eae1: Got expected result from replica 1 [my-hostname-basic-dd8d7d6c-8353-11e9-949c-223764f7eae1-v74lb]: "my-hostname-basic-dd8d7d6c-8353-11e9-949c-223764f7eae1-v74lb", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:26:33.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-x9gj5" for this suite.
May 31 03:26:39.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:26:39.500: INFO: namespace: e2e-tests-replication-controller-x9gj5, resource: bindings, ignored listing per whitelist
May 31 03:26:39.522: INFO: namespace e2e-tests-replication-controller-x9gj5 deletion completed in 6.082784601s

• [SLOW TEST:16.189 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:26:39.523: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
May 31 03:26:43.647: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:27:07.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-z9kr2" for this suite.
May 31 03:27:13.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:27:13.841: INFO: namespace: e2e-tests-namespaces-z9kr2, resource: bindings, ignored listing per whitelist
May 31 03:27:13.877: INFO: namespace e2e-tests-namespaces-z9kr2 deletion completed in 6.173210169s
STEP: Destroying namespace "e2e-tests-nsdeletetest-gqlrk" for this suite.
May 31 03:27:13.879: INFO: Namespace e2e-tests-nsdeletetest-gqlrk was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-8qkks" for this suite.
May 31 03:27:19.888: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:27:19.914: INFO: namespace: e2e-tests-nsdeletetest-8qkks, resource: bindings, ignored listing per whitelist
May 31 03:27:19.965: INFO: namespace e2e-tests-nsdeletetest-8qkks deletion completed in 6.085821263s

• [SLOW TEST:40.443 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:27:19.966: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
May 31 03:27:20.045: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-535705201 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:27:20.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-txm4w" for this suite.
May 31 03:27:26.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:27:26.177: INFO: namespace: e2e-tests-kubectl-txm4w, resource: bindings, ignored listing per whitelist
May 31 03:27:26.220: INFO: namespace e2e-tests-kubectl-txm4w deletion completed in 6.089414792s

• [SLOW TEST:6.254 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:27:26.221: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:27:32.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-kgwzq" for this suite.
May 31 03:27:38.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:27:38.493: INFO: namespace: e2e-tests-namespaces-kgwzq, resource: bindings, ignored listing per whitelist
May 31 03:27:38.515: INFO: namespace e2e-tests-namespaces-kgwzq deletion completed in 6.116229562s
STEP: Destroying namespace "e2e-tests-nsdeletetest-45kz6" for this suite.
May 31 03:27:38.519: INFO: Namespace e2e-tests-nsdeletetest-45kz6 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-4hcfq" for this suite.
May 31 03:27:44.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:27:44.555: INFO: namespace: e2e-tests-nsdeletetest-4hcfq, resource: bindings, ignored listing per whitelist
May 31 03:27:44.601: INFO: namespace e2e-tests-nsdeletetest-4hcfq deletion completed in 6.0822055s

• [SLOW TEST:18.380 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:27:44.601: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
May 31 03:27:52.709: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 31 03:27:52.717: INFO: Pod pod-with-prestop-exec-hook still exists
May 31 03:27:54.718: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 31 03:27:54.720: INFO: Pod pod-with-prestop-exec-hook still exists
May 31 03:27:56.718: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 31 03:27:56.720: INFO: Pod pod-with-prestop-exec-hook still exists
May 31 03:27:58.717: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 31 03:27:58.723: INFO: Pod pod-with-prestop-exec-hook still exists
May 31 03:28:00.717: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 31 03:28:00.720: INFO: Pod pod-with-prestop-exec-hook still exists
May 31 03:28:02.717: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 31 03:28:02.721: INFO: Pod pod-with-prestop-exec-hook still exists
May 31 03:28:04.717: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 31 03:28:04.721: INFO: Pod pod-with-prestop-exec-hook still exists
May 31 03:28:06.717: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 31 03:28:06.720: INFO: Pod pod-with-prestop-exec-hook still exists
May 31 03:28:08.717: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 31 03:28:08.720: INFO: Pod pod-with-prestop-exec-hook still exists
May 31 03:28:10.718: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 31 03:28:10.721: INFO: Pod pod-with-prestop-exec-hook still exists
May 31 03:28:12.717: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 31 03:28:12.720: INFO: Pod pod-with-prestop-exec-hook still exists
May 31 03:28:14.717: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 31 03:28:14.721: INFO: Pod pod-with-prestop-exec-hook still exists
May 31 03:28:16.717: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 31 03:28:16.722: INFO: Pod pod-with-prestop-exec-hook still exists
May 31 03:28:18.717: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 31 03:28:18.720: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:28:18.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-4jjv7" for this suite.
May 31 03:28:40.740: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:28:40.760: INFO: namespace: e2e-tests-container-lifecycle-hook-4jjv7, resource: bindings, ignored listing per whitelist
May 31 03:28:40.821: INFO: namespace e2e-tests-container-lifecycle-hook-4jjv7 deletion completed in 22.088842316s

• [SLOW TEST:56.220 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:28:40.821: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:28:44.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-nm6mr" for this suite.
May 31 03:29:22.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:29:22.958: INFO: namespace: e2e-tests-kubelet-test-nm6mr, resource: bindings, ignored listing per whitelist
May 31 03:29:23.001: INFO: namespace e2e-tests-kubelet-test-nm6mr deletion completed in 38.075477722s

• [SLOW TEST:42.180 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:29:23.002: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-sn5k
STEP: Creating a pod to test atomic-volume-subpath
May 31 03:29:23.152: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-sn5k" in namespace "e2e-tests-subpath-ck9mn" to be "success or failure"
May 31 03:29:23.182: INFO: Pod "pod-subpath-test-secret-sn5k": Phase="Pending", Reason="", readiness=false. Elapsed: 30.464978ms
May 31 03:29:25.188: INFO: Pod "pod-subpath-test-secret-sn5k": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036194141s
May 31 03:29:27.191: INFO: Pod "pod-subpath-test-secret-sn5k": Phase="Running", Reason="", readiness=false. Elapsed: 4.03922736s
May 31 03:29:29.194: INFO: Pod "pod-subpath-test-secret-sn5k": Phase="Running", Reason="", readiness=false. Elapsed: 6.042217075s
May 31 03:29:31.197: INFO: Pod "pod-subpath-test-secret-sn5k": Phase="Running", Reason="", readiness=false. Elapsed: 8.045205589s
May 31 03:29:33.201: INFO: Pod "pod-subpath-test-secret-sn5k": Phase="Running", Reason="", readiness=false. Elapsed: 10.049616122s
May 31 03:29:35.204: INFO: Pod "pod-subpath-test-secret-sn5k": Phase="Running", Reason="", readiness=false. Elapsed: 12.05254283s
May 31 03:29:37.208: INFO: Pod "pod-subpath-test-secret-sn5k": Phase="Running", Reason="", readiness=false. Elapsed: 14.056047945s
May 31 03:29:39.211: INFO: Pod "pod-subpath-test-secret-sn5k": Phase="Running", Reason="", readiness=false. Elapsed: 16.058934148s
May 31 03:29:41.214: INFO: Pod "pod-subpath-test-secret-sn5k": Phase="Running", Reason="", readiness=false. Elapsed: 18.062277155s
May 31 03:29:43.218: INFO: Pod "pod-subpath-test-secret-sn5k": Phase="Running", Reason="", readiness=false. Elapsed: 20.066698378s
May 31 03:29:45.221: INFO: Pod "pod-subpath-test-secret-sn5k": Phase="Running", Reason="", readiness=false. Elapsed: 22.069536173s
May 31 03:29:47.224: INFO: Pod "pod-subpath-test-secret-sn5k": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.072508269s
STEP: Saw pod success
May 31 03:29:47.224: INFO: Pod "pod-subpath-test-secret-sn5k" satisfied condition "success or failure"
May 31 03:29:47.227: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod pod-subpath-test-secret-sn5k container test-container-subpath-secret-sn5k: <nil>
STEP: delete the pod
May 31 03:29:47.243: INFO: Waiting for pod pod-subpath-test-secret-sn5k to disappear
May 31 03:29:47.245: INFO: Pod pod-subpath-test-secret-sn5k no longer exists
STEP: Deleting pod pod-subpath-test-secret-sn5k
May 31 03:29:47.246: INFO: Deleting pod "pod-subpath-test-secret-sn5k" in namespace "e2e-tests-subpath-ck9mn"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:29:47.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-ck9mn" for this suite.
May 31 03:29:53.261: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:29:53.321: INFO: namespace: e2e-tests-subpath-ck9mn, resource: bindings, ignored listing per whitelist
May 31 03:29:53.342: INFO: namespace e2e-tests-subpath-ck9mn deletion completed in 6.091746071s

• [SLOW TEST:30.341 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:29:53.344: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 31 03:29:53.449: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
May 31 03:29:53.455: INFO: Number of nodes with available pods: 0
May 31 03:29:53.455: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
May 31 03:29:53.543: INFO: Number of nodes with available pods: 0
May 31 03:29:53.543: INFO: Node k8s-linuxpool-39082607-0 is running more than one daemon pod
May 31 03:29:54.546: INFO: Number of nodes with available pods: 0
May 31 03:29:54.547: INFO: Node k8s-linuxpool-39082607-0 is running more than one daemon pod
May 31 03:29:55.546: INFO: Number of nodes with available pods: 0
May 31 03:29:55.546: INFO: Node k8s-linuxpool-39082607-0 is running more than one daemon pod
May 31 03:29:56.546: INFO: Number of nodes with available pods: 1
May 31 03:29:56.547: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
May 31 03:29:56.562: INFO: Number of nodes with available pods: 1
May 31 03:29:56.562: INFO: Number of running nodes: 0, number of available pods: 1
May 31 03:29:57.565: INFO: Number of nodes with available pods: 0
May 31 03:29:57.565: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
May 31 03:29:57.573: INFO: Number of nodes with available pods: 0
May 31 03:29:57.573: INFO: Node k8s-linuxpool-39082607-0 is running more than one daemon pod
May 31 03:29:58.577: INFO: Number of nodes with available pods: 0
May 31 03:29:58.577: INFO: Node k8s-linuxpool-39082607-0 is running more than one daemon pod
May 31 03:29:59.577: INFO: Number of nodes with available pods: 0
May 31 03:29:59.577: INFO: Node k8s-linuxpool-39082607-0 is running more than one daemon pod
May 31 03:30:00.576: INFO: Number of nodes with available pods: 0
May 31 03:30:00.576: INFO: Node k8s-linuxpool-39082607-0 is running more than one daemon pod
May 31 03:30:01.576: INFO: Number of nodes with available pods: 0
May 31 03:30:01.577: INFO: Node k8s-linuxpool-39082607-0 is running more than one daemon pod
May 31 03:30:02.577: INFO: Number of nodes with available pods: 1
May 31 03:30:02.577: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-tfpqh, will wait for the garbage collector to delete the pods
May 31 03:30:02.639: INFO: Deleting DaemonSet.extensions daemon-set took: 4.866176ms
May 31 03:30:02.739: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.17907ms
May 31 03:30:06.242: INFO: Number of nodes with available pods: 0
May 31 03:30:06.242: INFO: Number of running nodes: 0, number of available pods: 0
May 31 03:30:06.244: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-tfpqh/daemonsets","resourceVersion":"18559"},"items":null}

May 31 03:30:06.246: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-tfpqh/pods","resourceVersion":"18559"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:30:06.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-tfpqh" for this suite.
May 31 03:30:12.338: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:30:12.358: INFO: namespace: e2e-tests-daemonsets-tfpqh, resource: bindings, ignored listing per whitelist
May 31 03:30:12.414: INFO: namespace e2e-tests-daemonsets-tfpqh deletion completed in 6.086223723s

• [SLOW TEST:19.070 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:30:12.414: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0531 03:30:18.509675      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 31 03:30:18.509: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:30:18.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-46n6m" for this suite.
May 31 03:30:24.521: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:30:24.544: INFO: namespace: e2e-tests-gc-46n6m, resource: bindings, ignored listing per whitelist
May 31 03:30:24.608: INFO: namespace e2e-tests-gc-46n6m deletion completed in 6.095335928s

• [SLOW TEST:12.194 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:30:24.608: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
May 31 03:30:24.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 --namespace=e2e-tests-kubectl-z8mld run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
May 31 03:30:27.574: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
May 31 03:30:27.574: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:30:29.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-z8mld" for this suite.
May 31 03:30:39.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:30:39.605: INFO: namespace: e2e-tests-kubectl-z8mld, resource: bindings, ignored listing per whitelist
May 31 03:30:39.664: INFO: namespace e2e-tests-kubectl-z8mld deletion completed in 10.082010578s

• [SLOW TEST:15.056 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:30:39.665: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:30:39.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-8k9x8" for this suite.
May 31 03:30:45.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:30:45.794: INFO: namespace: e2e-tests-kubelet-test-8k9x8, resource: bindings, ignored listing per whitelist
May 31 03:30:45.843: INFO: namespace e2e-tests-kubelet-test-8k9x8 deletion completed in 6.08863696s

• [SLOW TEST:6.179 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:30:45.844: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
May 31 03:30:45.931: INFO: Waiting up to 5m0s for pod "downward-api-7a068224-8354-11e9-949c-223764f7eae1" in namespace "e2e-tests-downward-api-trvlt" to be "success or failure"
May 31 03:30:45.942: INFO: Pod "downward-api-7a068224-8354-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.556265ms
May 31 03:30:47.944: INFO: Pod "downward-api-7a068224-8354-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013145492s
May 31 03:30:49.947: INFO: Pod "downward-api-7a068224-8354-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015986622s
STEP: Saw pod success
May 31 03:30:49.947: INFO: Pod "downward-api-7a068224-8354-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:30:49.950: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod downward-api-7a068224-8354-11e9-949c-223764f7eae1 container dapi-container: <nil>
STEP: delete the pod
May 31 03:30:49.964: INFO: Waiting for pod downward-api-7a068224-8354-11e9-949c-223764f7eae1 to disappear
May 31 03:30:49.967: INFO: Pod downward-api-7a068224-8354-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:30:49.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-trvlt" for this suite.
May 31 03:30:55.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:30:56.061: INFO: namespace: e2e-tests-downward-api-trvlt, resource: bindings, ignored listing per whitelist
May 31 03:30:56.067: INFO: namespace e2e-tests-downward-api-trvlt deletion completed in 6.097196064s

• [SLOW TEST:10.223 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:30:56.068: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-bpd8g
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-bpd8g
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-bpd8g
May 31 03:30:56.189: INFO: Found 0 stateful pods, waiting for 1
May 31 03:31:06.192: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
May 31 03:31:06.194: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 exec --namespace=e2e-tests-statefulset-bpd8g ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 31 03:31:06.490: INFO: stderr: ""
May 31 03:31:06.490: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 31 03:31:06.490: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 31 03:31:06.493: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May 31 03:31:16.495: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 31 03:31:16.495: INFO: Waiting for statefulset status.replicas updated to 0
May 31 03:31:16.508: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.9999997s
May 31 03:31:17.511: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.994698088s
May 31 03:31:18.514: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.991213304s
May 31 03:31:19.518: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.987924125s
May 31 03:31:20.521: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.984205238s
May 31 03:31:21.576: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.92914615s
May 31 03:31:22.580: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.925827671s
May 31 03:31:23.583: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.922373891s
May 31 03:31:24.586: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.919259416s
May 31 03:31:25.589: INFO: Verifying statefulset ss doesn't scale past 1 for another 916.299144ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-bpd8g
May 31 03:31:26.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 exec --namespace=e2e-tests-statefulset-bpd8g ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 31 03:31:26.820: INFO: stderr: ""
May 31 03:31:26.820: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 31 03:31:26.820: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 31 03:31:26.824: INFO: Found 1 stateful pods, waiting for 3
May 31 03:31:36.828: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May 31 03:31:36.828: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May 31 03:31:36.828: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
May 31 03:31:36.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 exec --namespace=e2e-tests-statefulset-bpd8g ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 31 03:31:37.034: INFO: stderr: ""
May 31 03:31:37.034: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 31 03:31:37.034: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 31 03:31:37.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 exec --namespace=e2e-tests-statefulset-bpd8g ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 31 03:31:37.266: INFO: stderr: ""
May 31 03:31:37.266: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 31 03:31:37.266: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 31 03:31:37.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 exec --namespace=e2e-tests-statefulset-bpd8g ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 31 03:31:37.480: INFO: stderr: ""
May 31 03:31:37.480: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 31 03:31:37.480: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 31 03:31:37.480: INFO: Waiting for statefulset status.replicas updated to 0
May 31 03:31:37.482: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
May 31 03:31:47.488: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 31 03:31:47.488: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May 31 03:31:47.488: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May 31 03:31:47.499: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.9999997s
May 31 03:31:48.502: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.994489498s
May 31 03:31:49.506: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.990875026s
May 31 03:31:50.509: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.987391257s
May 31 03:31:51.513: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.98405709s
May 31 03:31:52.516: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.980343118s
May 31 03:31:53.520: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.976812449s
May 31 03:31:54.524: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.972931876s
May 31 03:31:55.528: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.968590395s
May 31 03:31:56.536: INFO: Verifying statefulset ss doesn't scale past 3 for another 965.069828ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-bpd8g
May 31 03:31:57.540: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 exec --namespace=e2e-tests-statefulset-bpd8g ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 31 03:31:57.768: INFO: stderr: ""
May 31 03:31:57.768: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 31 03:31:57.768: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 31 03:31:57.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 exec --namespace=e2e-tests-statefulset-bpd8g ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 31 03:31:57.993: INFO: stderr: ""
May 31 03:31:57.993: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 31 03:31:57.993: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 31 03:31:57.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 exec --namespace=e2e-tests-statefulset-bpd8g ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 31 03:31:58.221: INFO: stderr: ""
May 31 03:31:58.221: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 31 03:31:58.221: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 31 03:31:58.221: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 31 03:32:28.233: INFO: Deleting all statefulset in ns e2e-tests-statefulset-bpd8g
May 31 03:32:28.235: INFO: Scaling statefulset ss to 0
May 31 03:32:28.241: INFO: Waiting for statefulset status.replicas updated to 0
May 31 03:32:28.243: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:32:28.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-bpd8g" for this suite.
May 31 03:32:34.264: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:32:34.298: INFO: namespace: e2e-tests-statefulset-bpd8g, resource: bindings, ignored listing per whitelist
May 31 03:32:34.349: INFO: namespace e2e-tests-statefulset-bpd8g deletion completed in 6.093024039s

• [SLOW TEST:98.281 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:32:34.350: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-bab0df27-8354-11e9-949c-223764f7eae1
STEP: Creating a pod to test consume secrets
May 31 03:32:34.423: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-bab15224-8354-11e9-949c-223764f7eae1" in namespace "e2e-tests-projected-5qv5s" to be "success or failure"
May 31 03:32:34.427: INFO: Pod "pod-projected-secrets-bab15224-8354-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.315168ms
May 31 03:32:36.430: INFO: Pod "pod-projected-secrets-bab15224-8354-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006766199s
May 31 03:32:38.433: INFO: Pod "pod-projected-secrets-bab15224-8354-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009827238s
STEP: Saw pod success
May 31 03:32:38.433: INFO: Pod "pod-projected-secrets-bab15224-8354-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:32:38.435: INFO: Trying to get logs from node k8s-linuxpool-39082607-2 pod pod-projected-secrets-bab15224-8354-11e9-949c-223764f7eae1 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 31 03:32:38.449: INFO: Waiting for pod pod-projected-secrets-bab15224-8354-11e9-949c-223764f7eae1 to disappear
May 31 03:32:38.452: INFO: Pod pod-projected-secrets-bab15224-8354-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:32:38.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5qv5s" for this suite.
May 31 03:32:44.464: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:32:44.549: INFO: namespace: e2e-tests-projected-5qv5s, resource: bindings, ignored listing per whitelist
May 31 03:32:44.559: INFO: namespace e2e-tests-projected-5qv5s deletion completed in 6.103749282s

• [SLOW TEST:10.210 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:32:44.560: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
May 31 03:32:44.628: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 31 03:32:44.634: INFO: Waiting for terminating namespaces to be deleted...
May 31 03:32:44.636: INFO: 
Logging pods the kubelet thinks is on node k8s-linuxpool-39082607-0 before test
May 31 03:32:44.641: INFO: kube-flannel-ds-cvbsp from kube-system started at 2019-05-31 02:08:14 +0000 UTC (2 container statuses recorded)
May 31 03:32:44.641: INFO: 	Container install-cni ready: true, restart count 0
May 31 03:32:44.641: INFO: 	Container kube-flannel ready: true, restart count 0
May 31 03:32:44.641: INFO: kube-proxy-b8mdx from kube-system started at 2019-05-31 02:08:18 +0000 UTC (1 container statuses recorded)
May 31 03:32:44.641: INFO: 	Container kube-proxy ready: true, restart count 0
May 31 03:32:44.641: INFO: sonobuoy from heptio-sonobuoy started at 2019-05-31 02:09:42 +0000 UTC (1 container statuses recorded)
May 31 03:32:44.642: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 31 03:32:44.642: INFO: azure-ip-masq-agent-wfzlh from kube-system started at 2019-05-31 02:08:17 +0000 UTC (1 container statuses recorded)
May 31 03:32:44.642: INFO: 	Container azure-ip-masq-agent ready: true, restart count 0
May 31 03:32:44.642: INFO: sonobuoy-systemd-logs-daemon-set-c8cb41e9386c4a37-bvqmw from heptio-sonobuoy started at 2019-05-31 02:09:50 +0000 UTC (2 container statuses recorded)
May 31 03:32:44.642: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
May 31 03:32:44.642: INFO: 	Container sonobuoy-worker ready: true, restart count 1
May 31 03:32:44.642: INFO: 
Logging pods the kubelet thinks is on node k8s-linuxpool-39082607-1 before test
May 31 03:32:44.650: INFO: kube-proxy-vp4nc from kube-system started at 2019-05-31 02:08:17 +0000 UTC (1 container statuses recorded)
May 31 03:32:44.650: INFO: 	Container kube-proxy ready: true, restart count 0
May 31 03:32:44.650: INFO: kubernetes-dashboard-7947fffdf5-8hd5w from kube-system started at 2019-05-31 02:08:34 +0000 UTC (1 container statuses recorded)
May 31 03:32:44.650: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 31 03:32:44.650: INFO: sonobuoy-systemd-logs-daemon-set-c8cb41e9386c4a37-288hm from heptio-sonobuoy started at 2019-05-31 02:09:50 +0000 UTC (2 container statuses recorded)
May 31 03:32:44.650: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
May 31 03:32:44.650: INFO: 	Container sonobuoy-worker ready: true, restart count 1
May 31 03:32:44.650: INFO: kube-flannel-ds-46vq7 from kube-system started at 2019-05-31 02:08:14 +0000 UTC (2 container statuses recorded)
May 31 03:32:44.650: INFO: 	Container install-cni ready: true, restart count 0
May 31 03:32:44.650: INFO: 	Container kube-flannel ready: true, restart count 0
May 31 03:32:44.650: INFO: azure-ip-masq-agent-kk6xv from kube-system started at 2019-05-31 02:08:17 +0000 UTC (1 container statuses recorded)
May 31 03:32:44.650: INFO: 	Container azure-ip-masq-agent ready: true, restart count 2
May 31 03:32:44.650: INFO: 
Logging pods the kubelet thinks is on node k8s-linuxpool-39082607-2 before test
May 31 03:32:44.656: INFO: tiller-deploy-74b7fb5bb9-w5db4 from kube-system started at 2019-05-31 02:08:34 +0000 UTC (1 container statuses recorded)
May 31 03:32:44.656: INFO: 	Container tiller ready: true, restart count 0
May 31 03:32:44.656: INFO: kube-flannel-ds-k5cj4 from kube-system started at 2019-05-31 02:08:14 +0000 UTC (2 container statuses recorded)
May 31 03:32:44.656: INFO: 	Container install-cni ready: true, restart count 0
May 31 03:32:44.656: INFO: 	Container kube-flannel ready: true, restart count 0
May 31 03:32:44.656: INFO: azure-ip-masq-agent-4gmjm from kube-system started at 2019-05-31 02:08:17 +0000 UTC (1 container statuses recorded)
May 31 03:32:44.656: INFO: 	Container azure-ip-masq-agent ready: true, restart count 0
May 31 03:32:44.656: INFO: kube-proxy-cq296 from kube-system started at 2019-05-31 02:08:18 +0000 UTC (1 container statuses recorded)
May 31 03:32:44.656: INFO: 	Container kube-proxy ready: true, restart count 0
May 31 03:32:44.656: INFO: coredns-59b998c9dd-g7djk from kube-system started at 2019-05-31 02:08:18 +0000 UTC (1 container statuses recorded)
May 31 03:32:44.656: INFO: 	Container coredns ready: true, restart count 0
May 31 03:32:44.656: INFO: metrics-server-69b44566d5-rt27d from kube-system started at 2019-05-31 02:08:34 +0000 UTC (1 container statuses recorded)
May 31 03:32:44.656: INFO: 	Container metrics-server ready: true, restart count 0
May 31 03:32:44.657: INFO: sonobuoy-systemd-logs-daemon-set-c8cb41e9386c4a37-cbt95 from heptio-sonobuoy started at 2019-05-31 02:09:50 +0000 UTC (2 container statuses recorded)
May 31 03:32:44.657: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
May 31 03:32:44.657: INFO: 	Container sonobuoy-worker ready: true, restart count 1
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node k8s-linuxpool-39082607-0
STEP: verifying the node has the label node k8s-linuxpool-39082607-1
STEP: verifying the node has the label node k8s-linuxpool-39082607-2
May 31 03:32:44.701: INFO: Pod sonobuoy requesting resource cpu=0m on Node k8s-linuxpool-39082607-0
May 31 03:32:44.701: INFO: Pod sonobuoy-systemd-logs-daemon-set-c8cb41e9386c4a37-288hm requesting resource cpu=0m on Node k8s-linuxpool-39082607-1
May 31 03:32:44.701: INFO: Pod sonobuoy-systemd-logs-daemon-set-c8cb41e9386c4a37-bvqmw requesting resource cpu=0m on Node k8s-linuxpool-39082607-0
May 31 03:32:44.701: INFO: Pod sonobuoy-systemd-logs-daemon-set-c8cb41e9386c4a37-cbt95 requesting resource cpu=0m on Node k8s-linuxpool-39082607-2
May 31 03:32:44.701: INFO: Pod azure-ip-masq-agent-4gmjm requesting resource cpu=50m on Node k8s-linuxpool-39082607-2
May 31 03:32:44.701: INFO: Pod azure-ip-masq-agent-kk6xv requesting resource cpu=50m on Node k8s-linuxpool-39082607-1
May 31 03:32:44.701: INFO: Pod azure-ip-masq-agent-wfzlh requesting resource cpu=50m on Node k8s-linuxpool-39082607-0
May 31 03:32:44.701: INFO: Pod coredns-59b998c9dd-g7djk requesting resource cpu=100m on Node k8s-linuxpool-39082607-2
May 31 03:32:44.701: INFO: Pod kube-flannel-ds-46vq7 requesting resource cpu=0m on Node k8s-linuxpool-39082607-1
May 31 03:32:44.701: INFO: Pod kube-flannel-ds-cvbsp requesting resource cpu=0m on Node k8s-linuxpool-39082607-0
May 31 03:32:44.701: INFO: Pod kube-flannel-ds-k5cj4 requesting resource cpu=0m on Node k8s-linuxpool-39082607-2
May 31 03:32:44.702: INFO: Pod kube-proxy-b8mdx requesting resource cpu=100m on Node k8s-linuxpool-39082607-0
May 31 03:32:44.702: INFO: Pod kube-proxy-cq296 requesting resource cpu=100m on Node k8s-linuxpool-39082607-2
May 31 03:32:44.702: INFO: Pod kube-proxy-vp4nc requesting resource cpu=100m on Node k8s-linuxpool-39082607-1
May 31 03:32:44.702: INFO: Pod kubernetes-dashboard-7947fffdf5-8hd5w requesting resource cpu=300m on Node k8s-linuxpool-39082607-1
May 31 03:32:44.702: INFO: Pod metrics-server-69b44566d5-rt27d requesting resource cpu=0m on Node k8s-linuxpool-39082607-2
May 31 03:32:44.702: INFO: Pod tiller-deploy-74b7fb5bb9-w5db4 requesting resource cpu=50m on Node k8s-linuxpool-39082607-2
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c0d27fcd-8354-11e9-949c-223764f7eae1.15a3a70bb448b5da], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-z5vdm/filler-pod-c0d27fcd-8354-11e9-949c-223764f7eae1 to k8s-linuxpool-39082607-0]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c0d27fcd-8354-11e9-949c-223764f7eae1.15a3a70c0041b8a1], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c0d27fcd-8354-11e9-949c-223764f7eae1.15a3a70c16e9ea59], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c0d27fcd-8354-11e9-949c-223764f7eae1.15a3a70c21aca6b3], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c0d33136-8354-11e9-949c-223764f7eae1.15a3a70bb4dc2ae1], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-z5vdm/filler-pod-c0d33136-8354-11e9-949c-223764f7eae1 to k8s-linuxpool-39082607-1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c0d33136-8354-11e9-949c-223764f7eae1.15a3a70c0bbbf2a2], Reason = [Pulling], Message = [pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c0d33136-8354-11e9-949c-223764f7eae1.15a3a70c3243650c], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c0d33136-8354-11e9-949c-223764f7eae1.15a3a70c4b8b3759], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c0d33136-8354-11e9-949c-223764f7eae1.15a3a70c55385226], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c0d4ce74-8354-11e9-949c-223764f7eae1.15a3a70bb55c2133], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-z5vdm/filler-pod-c0d4ce74-8354-11e9-949c-223764f7eae1 to k8s-linuxpool-39082607-2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c0d4ce74-8354-11e9-949c-223764f7eae1.15a3a70c02c61007], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c0d4ce74-8354-11e9-949c-223764f7eae1.15a3a70c1b0942ec], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c0d4ce74-8354-11e9-949c-223764f7eae1.15a3a70c29e2ce74], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15a3a70ca4af49cd], Reason = [FailedScheduling], Message = [0/4 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 3 Insufficient cpu.]
STEP: removing the label node off the node k8s-linuxpool-39082607-0
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node k8s-linuxpool-39082607-1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node k8s-linuxpool-39082607-2
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:32:49.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-z5vdm" for this suite.
May 31 03:32:55.843: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:32:55.942: INFO: namespace: e2e-tests-sched-pred-z5vdm, resource: bindings, ignored listing per whitelist
May 31 03:32:55.945: INFO: namespace e2e-tests-sched-pred-z5vdm deletion completed in 6.137492982s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:11.386 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:32:55.948: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 31 03:32:56.024: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:33:00.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-vfkcf" for this suite.
May 31 03:33:40.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:33:40.099: INFO: namespace: e2e-tests-pods-vfkcf, resource: bindings, ignored listing per whitelist
May 31 03:33:40.145: INFO: namespace e2e-tests-pods-vfkcf deletion completed in 40.078251311s

• [SLOW TEST:44.197 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:33:40.145: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-6zlv
STEP: Creating a pod to test atomic-volume-subpath
May 31 03:33:40.227: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-6zlv" in namespace "e2e-tests-subpath-h9gxt" to be "success or failure"
May 31 03:33:40.231: INFO: Pod "pod-subpath-test-configmap-6zlv": Phase="Pending", Reason="", readiness=false. Elapsed: 4.249666ms
May 31 03:33:42.234: INFO: Pod "pod-subpath-test-configmap-6zlv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007149856s
May 31 03:33:44.237: INFO: Pod "pod-subpath-test-configmap-6zlv": Phase="Running", Reason="", readiness=false. Elapsed: 4.009814141s
May 31 03:33:46.240: INFO: Pod "pod-subpath-test-configmap-6zlv": Phase="Running", Reason="", readiness=false. Elapsed: 6.012734628s
May 31 03:33:48.243: INFO: Pod "pod-subpath-test-configmap-6zlv": Phase="Running", Reason="", readiness=false. Elapsed: 8.015606814s
May 31 03:33:50.246: INFO: Pod "pod-subpath-test-configmap-6zlv": Phase="Running", Reason="", readiness=false. Elapsed: 10.018807003s
May 31 03:33:52.249: INFO: Pod "pod-subpath-test-configmap-6zlv": Phase="Running", Reason="", readiness=false. Elapsed: 12.021886089s
May 31 03:33:54.252: INFO: Pod "pod-subpath-test-configmap-6zlv": Phase="Running", Reason="", readiness=false. Elapsed: 14.025132276s
May 31 03:33:56.255: INFO: Pod "pod-subpath-test-configmap-6zlv": Phase="Running", Reason="", readiness=false. Elapsed: 16.028428863s
May 31 03:33:58.258: INFO: Pod "pod-subpath-test-configmap-6zlv": Phase="Running", Reason="", readiness=false. Elapsed: 18.031303141s
May 31 03:34:00.262: INFO: Pod "pod-subpath-test-configmap-6zlv": Phase="Running", Reason="", readiness=false. Elapsed: 20.034574825s
May 31 03:34:02.265: INFO: Pod "pod-subpath-test-configmap-6zlv": Phase="Running", Reason="", readiness=false. Elapsed: 22.03806491s
May 31 03:34:04.268: INFO: Pod "pod-subpath-test-configmap-6zlv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.041104888s
STEP: Saw pod success
May 31 03:34:04.268: INFO: Pod "pod-subpath-test-configmap-6zlv" satisfied condition "success or failure"
May 31 03:34:04.270: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod pod-subpath-test-configmap-6zlv container test-container-subpath-configmap-6zlv: <nil>
STEP: delete the pod
May 31 03:34:04.290: INFO: Waiting for pod pod-subpath-test-configmap-6zlv to disappear
May 31 03:34:04.294: INFO: Pod pod-subpath-test-configmap-6zlv no longer exists
STEP: Deleting pod pod-subpath-test-configmap-6zlv
May 31 03:34:04.294: INFO: Deleting pod "pod-subpath-test-configmap-6zlv" in namespace "e2e-tests-subpath-h9gxt"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:34:04.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-h9gxt" for this suite.
May 31 03:34:10.307: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:34:10.326: INFO: namespace: e2e-tests-subpath-h9gxt, resource: bindings, ignored listing per whitelist
May 31 03:34:10.385: INFO: namespace e2e-tests-subpath-h9gxt deletion completed in 6.086250124s

• [SLOW TEST:30.240 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:34:10.385: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-gwnml
May 31 03:34:14.480: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-gwnml
STEP: checking the pod's current state and verifying that restartCount is present
May 31 03:34:14.482: INFO: Initial restart count of pod liveness-http is 0
May 31 03:34:34.537: INFO: Restart count of pod e2e-tests-container-probe-gwnml/liveness-http is now 1 (20.055125521s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:34:34.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-gwnml" for this suite.
May 31 03:34:40.554: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:34:40.607: INFO: namespace: e2e-tests-container-probe-gwnml, resource: bindings, ignored listing per whitelist
May 31 03:34:40.625: INFO: namespace e2e-tests-container-probe-gwnml deletion completed in 6.078550147s

• [SLOW TEST:30.239 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:34:40.625: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-05f43b9e-8355-11e9-949c-223764f7eae1
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-05f43b9e-8355-11e9-949c-223764f7eae1
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:36:11.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-jcwkf" for this suite.
May 31 03:36:33.179: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:36:33.195: INFO: namespace: e2e-tests-configmap-jcwkf, resource: bindings, ignored listing per whitelist
May 31 03:36:33.261: INFO: namespace e2e-tests-configmap-jcwkf deletion completed in 22.094827725s

• [SLOW TEST:112.636 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:36:33.261: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-491a57b1-8355-11e9-949c-223764f7eae1
STEP: Creating a pod to test consume configMaps
May 31 03:36:33.350: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-491abcfa-8355-11e9-949c-223764f7eae1" in namespace "e2e-tests-projected-ppkrz" to be "success or failure"
May 31 03:36:33.357: INFO: Pod "pod-projected-configmaps-491abcfa-8355-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 7.126411ms
May 31 03:36:35.360: INFO: Pod "pod-projected-configmaps-491abcfa-8355-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010414406s
May 31 03:36:37.363: INFO: Pod "pod-projected-configmaps-491abcfa-8355-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013255993s
STEP: Saw pod success
May 31 03:36:37.363: INFO: Pod "pod-projected-configmaps-491abcfa-8355-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:36:37.365: INFO: Trying to get logs from node k8s-linuxpool-39082607-2 pod pod-projected-configmaps-491abcfa-8355-11e9-949c-223764f7eae1 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 31 03:36:37.382: INFO: Waiting for pod pod-projected-configmaps-491abcfa-8355-11e9-949c-223764f7eae1 to disappear
May 31 03:36:37.388: INFO: Pod pod-projected-configmaps-491abcfa-8355-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:36:37.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ppkrz" for this suite.
May 31 03:36:43.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:36:43.422: INFO: namespace: e2e-tests-projected-ppkrz, resource: bindings, ignored listing per whitelist
May 31 03:36:43.485: INFO: namespace e2e-tests-projected-ppkrz deletion completed in 6.092764963s

• [SLOW TEST:10.224 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:36:43.485: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
May 31 03:36:48.114: INFO: Successfully updated pod "labelsupdate4f31ae4c-8355-11e9-949c-223764f7eae1"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:36:50.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9mr77" for this suite.
May 31 03:37:12.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:37:12.206: INFO: namespace: e2e-tests-projected-9mr77, resource: bindings, ignored listing per whitelist
May 31 03:37:12.233: INFO: namespace e2e-tests-projected-9mr77 deletion completed in 22.099711894s

• [SLOW TEST:28.748 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:37:12.234: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-fzm7
STEP: Creating a pod to test atomic-volume-subpath
May 31 03:37:12.328: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-fzm7" in namespace "e2e-tests-subpath-nvhd4" to be "success or failure"
May 31 03:37:12.336: INFO: Pod "pod-subpath-test-configmap-fzm7": Phase="Pending", Reason="", readiness=false. Elapsed: 7.662219ms
May 31 03:37:14.345: INFO: Pod "pod-subpath-test-configmap-fzm7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016586983s
May 31 03:37:16.348: INFO: Pod "pod-subpath-test-configmap-fzm7": Phase="Running", Reason="", readiness=false. Elapsed: 4.019708257s
May 31 03:37:18.351: INFO: Pod "pod-subpath-test-configmap-fzm7": Phase="Running", Reason="", readiness=false. Elapsed: 6.022769828s
May 31 03:37:20.354: INFO: Pod "pod-subpath-test-configmap-fzm7": Phase="Running", Reason="", readiness=false. Elapsed: 8.025533094s
May 31 03:37:22.357: INFO: Pod "pod-subpath-test-configmap-fzm7": Phase="Running", Reason="", readiness=false. Elapsed: 10.028487763s
May 31 03:37:24.360: INFO: Pod "pod-subpath-test-configmap-fzm7": Phase="Running", Reason="", readiness=false. Elapsed: 12.03146943s
May 31 03:37:26.363: INFO: Pod "pod-subpath-test-configmap-fzm7": Phase="Running", Reason="", readiness=false. Elapsed: 14.034697901s
May 31 03:37:28.366: INFO: Pod "pod-subpath-test-configmap-fzm7": Phase="Running", Reason="", readiness=false. Elapsed: 16.037697067s
May 31 03:37:30.369: INFO: Pod "pod-subpath-test-configmap-fzm7": Phase="Running", Reason="", readiness=false. Elapsed: 18.040865335s
May 31 03:37:32.372: INFO: Pod "pod-subpath-test-configmap-fzm7": Phase="Running", Reason="", readiness=false. Elapsed: 20.043919001s
May 31 03:37:34.376: INFO: Pod "pod-subpath-test-configmap-fzm7": Phase="Running", Reason="", readiness=false. Elapsed: 22.047324271s
May 31 03:37:36.379: INFO: Pod "pod-subpath-test-configmap-fzm7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.050577037s
STEP: Saw pod success
May 31 03:37:36.379: INFO: Pod "pod-subpath-test-configmap-fzm7" satisfied condition "success or failure"
May 31 03:37:36.381: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod pod-subpath-test-configmap-fzm7 container test-container-subpath-configmap-fzm7: <nil>
STEP: delete the pod
May 31 03:37:36.395: INFO: Waiting for pod pod-subpath-test-configmap-fzm7 to disappear
May 31 03:37:36.398: INFO: Pod pod-subpath-test-configmap-fzm7 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-fzm7
May 31 03:37:36.398: INFO: Deleting pod "pod-subpath-test-configmap-fzm7" in namespace "e2e-tests-subpath-nvhd4"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:37:36.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-nvhd4" for this suite.
May 31 03:37:42.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:37:42.477: INFO: namespace: e2e-tests-subpath-nvhd4, resource: bindings, ignored listing per whitelist
May 31 03:37:42.487: INFO: namespace e2e-tests-subpath-nvhd4 deletion completed in 6.084572555s

• [SLOW TEST:30.254 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:37:42.491: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 31 03:37:42.571: INFO: Pod name rollover-pod: Found 0 pods out of 1
May 31 03:37:47.574: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May 31 03:37:47.574: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
May 31 03:37:49.577: INFO: Creating deployment "test-rollover-deployment"
May 31 03:37:49.584: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
May 31 03:37:51.592: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
May 31 03:37:51.596: INFO: Ensure that both replica sets have 1 created replica
May 31 03:37:51.600: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
May 31 03:37:51.605: INFO: Updating deployment test-rollover-deployment
May 31 03:37:51.605: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
May 31 03:37:53.613: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
May 31 03:37:53.617: INFO: Make sure deployment "test-rollover-deployment" is complete
May 31 03:37:53.621: INFO: all replica sets need to contain the pod-template-hash label
May 31 03:37:53.621: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694870669, loc:(*time.Location)(0x7b6dbe0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694870669, loc:(*time.Location)(0x7b6dbe0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694870671, loc:(*time.Location)(0x7b6dbe0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694870669, loc:(*time.Location)(0x7b6dbe0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 31 03:37:55.626: INFO: all replica sets need to contain the pod-template-hash label
May 31 03:37:55.626: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694870669, loc:(*time.Location)(0x7b6dbe0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694870669, loc:(*time.Location)(0x7b6dbe0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694870674, loc:(*time.Location)(0x7b6dbe0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694870669, loc:(*time.Location)(0x7b6dbe0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 31 03:37:57.626: INFO: all replica sets need to contain the pod-template-hash label
May 31 03:37:57.626: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694870669, loc:(*time.Location)(0x7b6dbe0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694870669, loc:(*time.Location)(0x7b6dbe0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694870674, loc:(*time.Location)(0x7b6dbe0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694870669, loc:(*time.Location)(0x7b6dbe0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 31 03:37:59.626: INFO: all replica sets need to contain the pod-template-hash label
May 31 03:37:59.627: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694870669, loc:(*time.Location)(0x7b6dbe0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694870669, loc:(*time.Location)(0x7b6dbe0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694870674, loc:(*time.Location)(0x7b6dbe0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694870669, loc:(*time.Location)(0x7b6dbe0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 31 03:38:01.626: INFO: all replica sets need to contain the pod-template-hash label
May 31 03:38:01.626: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694870669, loc:(*time.Location)(0x7b6dbe0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694870669, loc:(*time.Location)(0x7b6dbe0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694870674, loc:(*time.Location)(0x7b6dbe0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694870669, loc:(*time.Location)(0x7b6dbe0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 31 03:38:03.628: INFO: all replica sets need to contain the pod-template-hash label
May 31 03:38:03.628: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694870669, loc:(*time.Location)(0x7b6dbe0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694870669, loc:(*time.Location)(0x7b6dbe0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694870674, loc:(*time.Location)(0x7b6dbe0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694870669, loc:(*time.Location)(0x7b6dbe0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 31 03:38:05.626: INFO: 
May 31 03:38:05.627: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 31 03:38:05.633: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-vcwj7,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-vcwj7/deployments/test-rollover-deployment,UID:768ae1eb-8355-11e9-944d-001dd80c001b,ResourceVersion:20190,Generation:2,CreationTimestamp:2019-05-31 03:37:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-05-31 03:37:49 +0000 UTC 2019-05-31 03:37:49 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-05-31 03:38:04 +0000 UTC 2019-05-31 03:37:49 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

May 31 03:38:05.636: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-vcwj7,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-vcwj7/replicasets/test-rollover-deployment-6b7f9d6597,UID:77c07c77-8355-11e9-944d-001dd80c001b,ResourceVersion:20181,Generation:2,CreationTimestamp:2019-05-31 03:37:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 768ae1eb-8355-11e9-944d-001dd80c001b 0xc001c441c7 0xc001c441c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
May 31 03:38:05.636: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
May 31 03:38:05.636: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-vcwj7,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-vcwj7/replicasets/test-rollover-controller,UID:725c64c4-8355-11e9-944d-001dd80c001b,ResourceVersion:20189,Generation:2,CreationTimestamp:2019-05-31 03:37:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 768ae1eb-8355-11e9-944d-001dd80c001b 0xc001c44037 0xc001c44038}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 31 03:38:05.637: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-vcwj7,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-vcwj7/replicasets/test-rollover-deployment-6586df867b,UID:768d760c-8355-11e9-944d-001dd80c001b,ResourceVersion:20145,Generation:2,CreationTimestamp:2019-05-31 03:37:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 768ae1eb-8355-11e9-944d-001dd80c001b 0xc001c440f7 0xc001c440f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 31 03:38:05.639: INFO: Pod "test-rollover-deployment-6b7f9d6597-smcsm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-smcsm,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-vcwj7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-vcwj7/pods/test-rollover-deployment-6b7f9d6597-smcsm,UID:77c58d66-8355-11e9-944d-001dd80c001b,ResourceVersion:20163,Generation:0,CreationTimestamp:2019-05-31 03:37:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 77c07c77-8355-11e9-944d-001dd80c001b 0xc001c44d47 0xc001c44d48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-79m5f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-79m5f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-79m5f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-linuxpool-39082607-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c44db0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c44dd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:37:51 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:37:54 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:37:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:37:51 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.4,PodIP:10.244.3.178,StartTime:2019-05-31 03:37:51 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-05-31 03:37:53 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://d8becdf116fcbf16a8eb23d76c08a137f4076e4aaa9f029be04b2a90dc54d3b9}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:38:05.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-vcwj7" for this suite.
May 31 03:38:11.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:38:11.726: INFO: namespace: e2e-tests-deployment-vcwj7, resource: bindings, ignored listing per whitelist
May 31 03:38:11.737: INFO: namespace e2e-tests-deployment-vcwj7 deletion completed in 6.094701675s

• [SLOW TEST:29.247 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:38:11.742: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 pods, got 2 pods
STEP: expected 0 rs, got 1 rs
STEP: Gathering metrics
W0531 03:38:12.376222      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 31 03:38:12.376: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:38:12.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-k5fnz" for this suite.
May 31 03:38:18.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:38:18.419: INFO: namespace: e2e-tests-gc-k5fnz, resource: bindings, ignored listing per whitelist
May 31 03:38:18.503: INFO: namespace e2e-tests-gc-k5fnz deletion completed in 6.124501529s

• [SLOW TEST:6.762 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:38:18.506: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 31 03:38:18.630: INFO: Waiting up to 5m0s for pod "downwardapi-volume-87da7ad6-8355-11e9-949c-223764f7eae1" in namespace "e2e-tests-projected-8w7sd" to be "success or failure"
May 31 03:38:18.639: INFO: Pod "downwardapi-volume-87da7ad6-8355-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.500332ms
May 31 03:38:20.642: INFO: Pod "downwardapi-volume-87da7ad6-8355-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011504376s
May 31 03:38:22.692: INFO: Pod "downwardapi-volume-87da7ad6-8355-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.061362846s
STEP: Saw pod success
May 31 03:38:22.692: INFO: Pod "downwardapi-volume-87da7ad6-8355-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:38:22.695: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod downwardapi-volume-87da7ad6-8355-11e9-949c-223764f7eae1 container client-container: <nil>
STEP: delete the pod
May 31 03:38:22.714: INFO: Waiting for pod downwardapi-volume-87da7ad6-8355-11e9-949c-223764f7eae1 to disappear
May 31 03:38:22.716: INFO: Pod downwardapi-volume-87da7ad6-8355-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:38:22.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8w7sd" for this suite.
May 31 03:38:28.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:38:28.766: INFO: namespace: e2e-tests-projected-8w7sd, resource: bindings, ignored listing per whitelist
May 31 03:38:28.803: INFO: namespace e2e-tests-projected-8w7sd deletion completed in 6.083156275s

• [SLOW TEST:10.297 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:38:28.803: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-lf7gf
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-lf7gf to expose endpoints map[]
May 31 03:38:28.901: INFO: Get endpoints failed (13.018802ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
May 31 03:38:29.904: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-lf7gf exposes endpoints map[] (1.015492537s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-lf7gf
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-lf7gf to expose endpoints map[pod1:[100]]
May 31 03:38:32.934: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-lf7gf exposes endpoints map[pod1:[100]] (3.02456537s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-lf7gf
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-lf7gf to expose endpoints map[pod1:[100] pod2:[101]]
May 31 03:38:35.968: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-lf7gf exposes endpoints map[pod1:[100] pod2:[101]] (3.031005168s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-lf7gf
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-lf7gf to expose endpoints map[pod2:[101]]
May 31 03:38:35.983: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-lf7gf exposes endpoints map[pod2:[101]] (9.420746ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-lf7gf
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-lf7gf to expose endpoints map[]
May 31 03:38:36.995: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-lf7gf exposes endpoints map[] (1.006811001s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:38:37.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-lf7gf" for this suite.
May 31 03:38:43.027: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:38:43.077: INFO: namespace: e2e-tests-services-lf7gf, resource: bindings, ignored listing per whitelist
May 31 03:38:43.107: INFO: namespace e2e-tests-services-lf7gf deletion completed in 6.094148529s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:14.305 seconds]
[sig-network] Services
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:38:43.109: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-967fbb13-8355-11e9-949c-223764f7eae1
STEP: Creating a pod to test consume configMaps
May 31 03:38:43.204: INFO: Waiting up to 5m0s for pod "pod-configmaps-96806d7d-8355-11e9-949c-223764f7eae1" in namespace "e2e-tests-configmap-sg9hr" to be "success or failure"
May 31 03:38:43.207: INFO: Pod "pod-configmaps-96806d7d-8355-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.258951ms
May 31 03:38:45.210: INFO: Pod "pod-configmaps-96806d7d-8355-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006062082s
May 31 03:38:47.213: INFO: Pod "pod-configmaps-96806d7d-8355-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008599909s
STEP: Saw pod success
May 31 03:38:47.213: INFO: Pod "pod-configmaps-96806d7d-8355-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:38:47.215: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod pod-configmaps-96806d7d-8355-11e9-949c-223764f7eae1 container configmap-volume-test: <nil>
STEP: delete the pod
May 31 03:38:47.233: INFO: Waiting for pod pod-configmaps-96806d7d-8355-11e9-949c-223764f7eae1 to disappear
May 31 03:38:47.236: INFO: Pod pod-configmaps-96806d7d-8355-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:38:47.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-sg9hr" for this suite.
May 31 03:38:53.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:38:53.294: INFO: namespace: e2e-tests-configmap-sg9hr, resource: bindings, ignored listing per whitelist
May 31 03:38:53.324: INFO: namespace e2e-tests-configmap-sg9hr deletion completed in 6.084237263s

• [SLOW TEST:10.215 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:38:53.324: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 31 03:38:53.391: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9c93577a-8355-11e9-949c-223764f7eae1" in namespace "e2e-tests-projected-xdfc7" to be "success or failure"
May 31 03:38:53.394: INFO: Pod "downwardapi-volume-9c93577a-8355-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.660042ms
May 31 03:38:55.396: INFO: Pod "downwardapi-volume-9c93577a-8355-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004955962s
May 31 03:38:57.399: INFO: Pod "downwardapi-volume-9c93577a-8355-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00780719s
STEP: Saw pod success
May 31 03:38:57.399: INFO: Pod "downwardapi-volume-9c93577a-8355-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:38:57.401: INFO: Trying to get logs from node k8s-linuxpool-39082607-2 pod downwardapi-volume-9c93577a-8355-11e9-949c-223764f7eae1 container client-container: <nil>
STEP: delete the pod
May 31 03:38:57.418: INFO: Waiting for pod downwardapi-volume-9c93577a-8355-11e9-949c-223764f7eae1 to disappear
May 31 03:38:57.420: INFO: Pod downwardapi-volume-9c93577a-8355-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:38:57.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xdfc7" for this suite.
May 31 03:39:03.432: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:39:03.489: INFO: namespace: e2e-tests-projected-xdfc7, resource: bindings, ignored listing per whitelist
May 31 03:39:03.509: INFO: namespace e2e-tests-projected-xdfc7 deletion completed in 6.085814977s

• [SLOW TEST:10.185 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:39:03.509: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-a2a5cde2-8355-11e9-949c-223764f7eae1
STEP: Creating a pod to test consume secrets
May 31 03:39:03.588: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a2a6a077-8355-11e9-949c-223764f7eae1" in namespace "e2e-tests-projected-dkf78" to be "success or failure"
May 31 03:39:03.591: INFO: Pod "pod-projected-secrets-a2a6a077-8355-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.768443ms
May 31 03:39:05.594: INFO: Pod "pod-projected-secrets-a2a6a077-8355-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005320963s
May 31 03:39:07.597: INFO: Pod "pod-projected-secrets-a2a6a077-8355-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008607694s
STEP: Saw pod success
May 31 03:39:07.597: INFO: Pod "pod-projected-secrets-a2a6a077-8355-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:39:07.599: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod pod-projected-secrets-a2a6a077-8355-11e9-949c-223764f7eae1 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 31 03:39:07.617: INFO: Waiting for pod pod-projected-secrets-a2a6a077-8355-11e9-949c-223764f7eae1 to disappear
May 31 03:39:07.619: INFO: Pod pod-projected-secrets-a2a6a077-8355-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:39:07.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dkf78" for this suite.
May 31 03:39:13.632: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:39:13.651: INFO: namespace: e2e-tests-projected-dkf78, resource: bindings, ignored listing per whitelist
May 31 03:39:13.713: INFO: namespace e2e-tests-projected-dkf78 deletion completed in 6.09059654s

• [SLOW TEST:10.204 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:39:13.714: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
May 31 03:39:13.783: INFO: namespace e2e-tests-kubectl-snhzt
May 31 03:39:13.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 create -f - --namespace=e2e-tests-kubectl-snhzt'
May 31 03:39:14.971: INFO: stderr: ""
May 31 03:39:14.972: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
May 31 03:39:15.977: INFO: Selector matched 1 pods for map[app:redis]
May 31 03:39:15.977: INFO: Found 0 / 1
May 31 03:39:16.975: INFO: Selector matched 1 pods for map[app:redis]
May 31 03:39:16.975: INFO: Found 0 / 1
May 31 03:39:17.975: INFO: Selector matched 1 pods for map[app:redis]
May 31 03:39:17.975: INFO: Found 1 / 1
May 31 03:39:17.975: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 31 03:39:17.977: INFO: Selector matched 1 pods for map[app:redis]
May 31 03:39:17.977: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 31 03:39:17.977: INFO: wait on redis-master startup in e2e-tests-kubectl-snhzt 
May 31 03:39:17.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 logs redis-master-4f25l redis-master --namespace=e2e-tests-kubectl-snhzt'
May 31 03:39:18.082: INFO: stderr: ""
May 31 03:39:18.082: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 31 May 03:39:17.021 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 31 May 03:39:17.021 # Server started, Redis version 3.2.12\n1:M 31 May 03:39:17.021 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 31 May 03:39:17.021 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
May 31 03:39:18.083: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-snhzt'
May 31 03:39:18.204: INFO: stderr: ""
May 31 03:39:18.204: INFO: stdout: "service/rm2 exposed\n"
May 31 03:39:18.208: INFO: Service rm2 in namespace e2e-tests-kubectl-snhzt found.
STEP: exposing service
May 31 03:39:20.213: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-snhzt'
May 31 03:39:20.341: INFO: stderr: ""
May 31 03:39:20.341: INFO: stdout: "service/rm3 exposed\n"
May 31 03:39:20.348: INFO: Service rm3 in namespace e2e-tests-kubectl-snhzt found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:39:22.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-snhzt" for this suite.
May 31 03:39:44.364: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:39:44.410: INFO: namespace: e2e-tests-kubectl-snhzt, resource: bindings, ignored listing per whitelist
May 31 03:39:44.435: INFO: namespace e2e-tests-kubectl-snhzt deletion completed in 22.078753097s

• [SLOW TEST:30.722 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:39:44.435: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
May 31 03:39:44.505: INFO: Waiting up to 5m0s for pod "pod-bb0ab65a-8355-11e9-949c-223764f7eae1" in namespace "e2e-tests-emptydir-zgrnr" to be "success or failure"
May 31 03:39:44.513: INFO: Pod "pod-bb0ab65a-8355-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 7.14591ms
May 31 03:39:46.516: INFO: Pod "pod-bb0ab65a-8355-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010177624s
May 31 03:39:48.519: INFO: Pod "pod-bb0ab65a-8355-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013389039s
STEP: Saw pod success
May 31 03:39:48.519: INFO: Pod "pod-bb0ab65a-8355-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:39:48.521: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod pod-bb0ab65a-8355-11e9-949c-223764f7eae1 container test-container: <nil>
STEP: delete the pod
May 31 03:39:48.539: INFO: Waiting for pod pod-bb0ab65a-8355-11e9-949c-223764f7eae1 to disappear
May 31 03:39:48.541: INFO: Pod pod-bb0ab65a-8355-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:39:48.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-zgrnr" for this suite.
May 31 03:39:54.554: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:39:54.612: INFO: namespace: e2e-tests-emptydir-zgrnr, resource: bindings, ignored listing per whitelist
May 31 03:39:54.635: INFO: namespace e2e-tests-emptydir-zgrnr deletion completed in 6.090342892s

• [SLOW TEST:10.199 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:39:54.635: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
May 31 03:40:02.736: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-l2sh4 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 31 03:40:02.736: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
May 31 03:40:02.860: INFO: Exec stderr: ""
May 31 03:40:02.860: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-l2sh4 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 31 03:40:02.860: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
May 31 03:40:02.979: INFO: Exec stderr: ""
May 31 03:40:02.979: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-l2sh4 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 31 03:40:02.979: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
May 31 03:40:03.116: INFO: Exec stderr: ""
May 31 03:40:03.117: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-l2sh4 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 31 03:40:03.117: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
May 31 03:40:03.243: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
May 31 03:40:03.244: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-l2sh4 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 31 03:40:03.244: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
May 31 03:40:03.367: INFO: Exec stderr: ""
May 31 03:40:03.367: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-l2sh4 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 31 03:40:03.367: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
May 31 03:40:03.498: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
May 31 03:40:03.498: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-l2sh4 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 31 03:40:03.498: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
May 31 03:40:03.643: INFO: Exec stderr: ""
May 31 03:40:03.643: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-l2sh4 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 31 03:40:03.643: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
May 31 03:40:03.764: INFO: Exec stderr: ""
May 31 03:40:03.764: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-l2sh4 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 31 03:40:03.764: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
May 31 03:40:03.883: INFO: Exec stderr: ""
May 31 03:40:03.883: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-l2sh4 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 31 03:40:03.883: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
May 31 03:40:04.063: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:40:04.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-l2sh4" for this suite.
May 31 03:40:50.085: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:40:50.137: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-l2sh4, resource: bindings, ignored listing per whitelist
May 31 03:40:50.160: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-l2sh4 deletion completed in 46.091936846s

• [SLOW TEST:55.525 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:40:50.162: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
May 31 03:40:50.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 create -f - --namespace=e2e-tests-kubectl-b4kkf'
May 31 03:40:50.466: INFO: stderr: ""
May 31 03:40:50.466: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 31 03:40:50.466: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-b4kkf'
May 31 03:40:50.580: INFO: stderr: ""
May 31 03:40:50.580: INFO: stdout: "update-demo-nautilus-cgx74 update-demo-nautilus-qjqkv "
May 31 03:40:50.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods update-demo-nautilus-cgx74 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b4kkf'
May 31 03:40:50.672: INFO: stderr: ""
May 31 03:40:50.672: INFO: stdout: ""
May 31 03:40:50.672: INFO: update-demo-nautilus-cgx74 is created but not running
May 31 03:40:55.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-b4kkf'
May 31 03:40:55.766: INFO: stderr: ""
May 31 03:40:55.766: INFO: stdout: "update-demo-nautilus-cgx74 update-demo-nautilus-qjqkv "
May 31 03:40:55.766: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods update-demo-nautilus-cgx74 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b4kkf'
May 31 03:40:55.843: INFO: stderr: ""
May 31 03:40:55.843: INFO: stdout: "true"
May 31 03:40:55.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods update-demo-nautilus-cgx74 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b4kkf'
May 31 03:40:55.930: INFO: stderr: ""
May 31 03:40:55.930: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 31 03:40:55.930: INFO: validating pod update-demo-nautilus-cgx74
May 31 03:40:55.935: INFO: got data: {
  "image": "nautilus.jpg"
}

May 31 03:40:55.936: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 31 03:40:55.936: INFO: update-demo-nautilus-cgx74 is verified up and running
May 31 03:40:55.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods update-demo-nautilus-qjqkv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b4kkf'
May 31 03:40:56.013: INFO: stderr: ""
May 31 03:40:56.014: INFO: stdout: "true"
May 31 03:40:56.014: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods update-demo-nautilus-qjqkv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b4kkf'
May 31 03:40:56.108: INFO: stderr: ""
May 31 03:40:56.109: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 31 03:40:56.109: INFO: validating pod update-demo-nautilus-qjqkv
May 31 03:40:56.114: INFO: got data: {
  "image": "nautilus.jpg"
}

May 31 03:40:56.114: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 31 03:40:56.114: INFO: update-demo-nautilus-qjqkv is verified up and running
STEP: rolling-update to new replication controller
May 31 03:40:56.116: INFO: scanned /root for discovery docs: <nil>
May 31 03:40:56.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-b4kkf'
May 31 03:41:19.542: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
May 31 03:41:19.542: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 31 03:41:19.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-b4kkf'
May 31 03:41:19.647: INFO: stderr: ""
May 31 03:41:19.647: INFO: stdout: "update-demo-kitten-cxlcs update-demo-kitten-l7xnm "
May 31 03:41:19.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods update-demo-kitten-cxlcs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b4kkf'
May 31 03:41:19.729: INFO: stderr: ""
May 31 03:41:19.729: INFO: stdout: "true"
May 31 03:41:19.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods update-demo-kitten-cxlcs -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b4kkf'
May 31 03:41:19.809: INFO: stderr: ""
May 31 03:41:19.809: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
May 31 03:41:19.809: INFO: validating pod update-demo-kitten-cxlcs
May 31 03:41:19.813: INFO: got data: {
  "image": "kitten.jpg"
}

May 31 03:41:19.813: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
May 31 03:41:19.813: INFO: update-demo-kitten-cxlcs is verified up and running
May 31 03:41:19.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods update-demo-kitten-l7xnm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b4kkf'
May 31 03:41:19.907: INFO: stderr: ""
May 31 03:41:19.907: INFO: stdout: "true"
May 31 03:41:19.907: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 get pods update-demo-kitten-l7xnm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b4kkf'
May 31 03:41:19.998: INFO: stderr: ""
May 31 03:41:19.998: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
May 31 03:41:19.998: INFO: validating pod update-demo-kitten-l7xnm
May 31 03:41:20.002: INFO: got data: {
  "image": "kitten.jpg"
}

May 31 03:41:20.002: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
May 31 03:41:20.002: INFO: update-demo-kitten-l7xnm is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:41:20.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-b4kkf" for this suite.
May 31 03:41:42.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:41:42.058: INFO: namespace: e2e-tests-kubectl-b4kkf, resource: bindings, ignored listing per whitelist
May 31 03:41:42.096: INFO: namespace e2e-tests-kubectl-b4kkf deletion completed in 22.091122689s

• [SLOW TEST:51.935 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:41:42.097: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 31 03:41:42.178: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:41:46.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-m6vzw" for this suite.
May 31 03:42:26.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:42:26.388: INFO: namespace: e2e-tests-pods-m6vzw, resource: bindings, ignored listing per whitelist
May 31 03:42:26.402: INFO: namespace e2e-tests-pods-m6vzw deletion completed in 40.086147644s

• [SLOW TEST:44.306 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:42:26.403: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
May 31 03:42:30.503: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-1b96622e-8356-11e9-949c-223764f7eae1,GenerateName:,Namespace:e2e-tests-events-wdtf7,SelfLink:/api/v1/namespaces/e2e-tests-events-wdtf7/pods/send-events-1b96622e-8356-11e9-949c-223764f7eae1,UID:1b96ed09-8356-11e9-944d-001dd80c001b,ResourceVersion:21128,Generation:0,CreationTimestamp:2019-05-31 03:42:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 477730184,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9nnl5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9nnl5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-9nnl5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-linuxpool-39082607-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001e87100} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001e87120}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:42:26 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:42:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:42:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-31 03:42:26 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.4,PodIP:10.244.3.187,StartTime:2019-05-31 03:42:26 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-05-31 03:42:28 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://359b48a8609bcc82df91a0a50e446ed70285694c4d089e8e4d8126f6920308eb}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
May 31 03:42:32.507: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
May 31 03:42:34.509: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:42:34.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-wdtf7" for this suite.
May 31 03:43:20.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:43:20.553: INFO: namespace: e2e-tests-events-wdtf7, resource: bindings, ignored listing per whitelist
May 31 03:43:20.607: INFO: namespace e2e-tests-events-wdtf7 deletion completed in 46.08865208s

• [SLOW TEST:54.204 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:43:20.607: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0531 03:43:51.208090      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 31 03:43:51.208: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:43:51.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-9jzgg" for this suite.
May 31 03:43:57.221: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:43:57.239: INFO: namespace: e2e-tests-gc-9jzgg, resource: bindings, ignored listing per whitelist
May 31 03:43:57.298: INFO: namespace e2e-tests-gc-9jzgg deletion completed in 6.087423253s

• [SLOW TEST:36.691 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:43:57.299: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-d4rzf
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-d4rzf
STEP: Deleting pre-stop pod
May 31 03:44:12.398: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:44:12.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-d4rzf" for this suite.
May 31 03:44:50.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:44:50.490: INFO: namespace: e2e-tests-prestop-d4rzf, resource: bindings, ignored listing per whitelist
May 31 03:44:50.499: INFO: namespace e2e-tests-prestop-d4rzf deletion completed in 38.089937404s

• [SLOW TEST:53.200 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:44:50.499: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 31 03:44:50.620: INFO: Waiting up to 5m0s for pod "downwardapi-volume-717fe52c-8356-11e9-949c-223764f7eae1" in namespace "e2e-tests-projected-mjwtf" to be "success or failure"
May 31 03:44:50.624: INFO: Pod "downwardapi-volume-717fe52c-8356-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.397573ms
May 31 03:44:52.627: INFO: Pod "downwardapi-volume-717fe52c-8356-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007502703s
May 31 03:44:54.631: INFO: Pod "downwardapi-volume-717fe52c-8356-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010719226s
STEP: Saw pod success
May 31 03:44:54.631: INFO: Pod "downwardapi-volume-717fe52c-8356-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:44:54.633: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod downwardapi-volume-717fe52c-8356-11e9-949c-223764f7eae1 container client-container: <nil>
STEP: delete the pod
May 31 03:44:54.653: INFO: Waiting for pod downwardapi-volume-717fe52c-8356-11e9-949c-223764f7eae1 to disappear
May 31 03:44:54.655: INFO: Pod downwardapi-volume-717fe52c-8356-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:44:54.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mjwtf" for this suite.
May 31 03:45:00.705: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:45:00.769: INFO: namespace: e2e-tests-projected-mjwtf, resource: bindings, ignored listing per whitelist
May 31 03:45:00.782: INFO: namespace e2e-tests-projected-mjwtf deletion completed in 6.123571712s

• [SLOW TEST:10.283 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:45:00.784: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
May 31 03:45:00.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 api-versions'
May 31 03:45:00.954: INFO: stderr: ""
May 31 03:45:00.954: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:45:00.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-d9wd8" for this suite.
May 31 03:45:06.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:45:07.028: INFO: namespace: e2e-tests-kubectl-d9wd8, resource: bindings, ignored listing per whitelist
May 31 03:45:07.037: INFO: namespace e2e-tests-kubectl-d9wd8 deletion completed in 6.080458918s

• [SLOW TEST:6.253 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:45:07.037: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
May 31 03:45:07.110: INFO: Waiting up to 5m0s for pod "var-expansion-7b5430ee-8356-11e9-949c-223764f7eae1" in namespace "e2e-tests-var-expansion-b4wvl" to be "success or failure"
May 31 03:45:07.114: INFO: Pod "var-expansion-7b5430ee-8356-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.60326ms
May 31 03:45:09.118: INFO: Pod "var-expansion-7b5430ee-8356-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00719783s
May 31 03:45:11.120: INFO: Pod "var-expansion-7b5430ee-8356-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010010379s
STEP: Saw pod success
May 31 03:45:11.121: INFO: Pod "var-expansion-7b5430ee-8356-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:45:11.123: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod var-expansion-7b5430ee-8356-11e9-949c-223764f7eae1 container dapi-container: <nil>
STEP: delete the pod
May 31 03:45:11.142: INFO: Waiting for pod var-expansion-7b5430ee-8356-11e9-949c-223764f7eae1 to disappear
May 31 03:45:11.143: INFO: Pod var-expansion-7b5430ee-8356-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:45:11.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-b4wvl" for this suite.
May 31 03:45:17.155: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:45:17.198: INFO: namespace: e2e-tests-var-expansion-b4wvl, resource: bindings, ignored listing per whitelist
May 31 03:45:17.238: INFO: namespace e2e-tests-var-expansion-b4wvl deletion completed in 6.090882866s

• [SLOW TEST:10.200 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:45:17.238: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 31 03:45:17.315: INFO: (0) /api/v1/nodes/k8s-linuxpool-39082607-0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 4.476974ms)
May 31 03:45:17.317: INFO: (1) /api/v1/nodes/k8s-linuxpool-39082607-0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 2.699044ms)
May 31 03:45:17.320: INFO: (2) /api/v1/nodes/k8s-linuxpool-39082607-0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 2.631244ms)
May 31 03:45:17.323: INFO: (3) /api/v1/nodes/k8s-linuxpool-39082607-0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 2.694745ms)
May 31 03:45:17.326: INFO: (4) /api/v1/nodes/k8s-linuxpool-39082607-0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 2.608943ms)
May 31 03:45:17.329: INFO: (5) /api/v1/nodes/k8s-linuxpool-39082607-0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 2.851347ms)
May 31 03:45:17.332: INFO: (6) /api/v1/nodes/k8s-linuxpool-39082607-0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 2.821647ms)
May 31 03:45:17.335: INFO: (7) /api/v1/nodes/k8s-linuxpool-39082607-0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 2.645643ms)
May 31 03:45:17.338: INFO: (8) /api/v1/nodes/k8s-linuxpool-39082607-0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 2.97865ms)
May 31 03:45:17.341: INFO: (9) /api/v1/nodes/k8s-linuxpool-39082607-0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 2.989249ms)
May 31 03:45:17.344: INFO: (10) /api/v1/nodes/k8s-linuxpool-39082607-0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.189053ms)
May 31 03:45:17.347: INFO: (11) /api/v1/nodes/k8s-linuxpool-39082607-0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 2.965349ms)
May 31 03:45:17.351: INFO: (12) /api/v1/nodes/k8s-linuxpool-39082607-0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.433857ms)
May 31 03:45:17.356: INFO: (13) /api/v1/nodes/k8s-linuxpool-39082607-0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 5.007683ms)
May 31 03:45:17.359: INFO: (14) /api/v1/nodes/k8s-linuxpool-39082607-0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.00935ms)
May 31 03:45:17.363: INFO: (15) /api/v1/nodes/k8s-linuxpool-39082607-0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.110451ms)
May 31 03:45:17.366: INFO: (16) /api/v1/nodes/k8s-linuxpool-39082607-0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 2.945749ms)
May 31 03:45:17.369: INFO: (17) /api/v1/nodes/k8s-linuxpool-39082607-0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.305255ms)
May 31 03:45:17.373: INFO: (18) /api/v1/nodes/k8s-linuxpool-39082607-0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.858764ms)
May 31 03:45:17.377: INFO: (19) /api/v1/nodes/k8s-linuxpool-39082607-0/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit/">au... (200; 3.076551ms)
[AfterEach] version v1
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:45:17.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-2shqh" for this suite.
May 31 03:45:23.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:45:23.454: INFO: namespace: e2e-tests-proxy-2shqh, resource: bindings, ignored listing per whitelist
May 31 03:45:23.459: INFO: namespace e2e-tests-proxy-2shqh deletion completed in 6.079617205s

• [SLOW TEST:6.221 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:45:23.461: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
May 31 03:45:23.528: INFO: Waiting up to 5m0s for pod "pod-851d7e43-8356-11e9-949c-223764f7eae1" in namespace "e2e-tests-emptydir-p2kkd" to be "success or failure"
May 31 03:45:23.532: INFO: Pod "pod-851d7e43-8356-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.97215ms
May 31 03:45:25.535: INFO: Pod "pod-851d7e43-8356-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006315751s
May 31 03:45:27.538: INFO: Pod "pod-851d7e43-8356-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009316638s
STEP: Saw pod success
May 31 03:45:27.538: INFO: Pod "pod-851d7e43-8356-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:45:27.540: INFO: Trying to get logs from node k8s-linuxpool-39082607-2 pod pod-851d7e43-8356-11e9-949c-223764f7eae1 container test-container: <nil>
STEP: delete the pod
May 31 03:45:27.558: INFO: Waiting for pod pod-851d7e43-8356-11e9-949c-223764f7eae1 to disappear
May 31 03:45:27.561: INFO: Pod pod-851d7e43-8356-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:45:27.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-p2kkd" for this suite.
May 31 03:45:33.574: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:45:33.627: INFO: namespace: e2e-tests-emptydir-p2kkd, resource: bindings, ignored listing per whitelist
May 31 03:45:33.654: INFO: namespace e2e-tests-emptydir-p2kkd deletion completed in 6.089088142s

• [SLOW TEST:10.193 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:45:33.655: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-8b3333a4-8356-11e9-949c-223764f7eae1
STEP: Creating a pod to test consume configMaps
May 31 03:45:33.744: INFO: Waiting up to 5m0s for pod "pod-configmaps-8b33b38e-8356-11e9-949c-223764f7eae1" in namespace "e2e-tests-configmap-fxgvd" to be "success or failure"
May 31 03:45:33.747: INFO: Pod "pod-configmaps-8b33b38e-8356-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.719062ms
May 31 03:45:35.749: INFO: Pod "pod-configmaps-8b33b38e-8356-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005865903s
May 31 03:45:37.753: INFO: Pod "pod-configmaps-8b33b38e-8356-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008991754s
STEP: Saw pod success
May 31 03:45:37.753: INFO: Pod "pod-configmaps-8b33b38e-8356-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:45:37.755: INFO: Trying to get logs from node k8s-linuxpool-39082607-0 pod pod-configmaps-8b33b38e-8356-11e9-949c-223764f7eae1 container configmap-volume-test: <nil>
STEP: delete the pod
May 31 03:45:37.771: INFO: Waiting for pod pod-configmaps-8b33b38e-8356-11e9-949c-223764f7eae1 to disappear
May 31 03:45:37.774: INFO: Pod pod-configmaps-8b33b38e-8356-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:45:37.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-fxgvd" for this suite.
May 31 03:45:43.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:45:43.876: INFO: namespace: e2e-tests-configmap-fxgvd, resource: bindings, ignored listing per whitelist
May 31 03:45:43.880: INFO: namespace e2e-tests-configmap-fxgvd deletion completed in 6.097863069s

• [SLOW TEST:10.226 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:45:43.881: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
May 31 03:45:43.969: INFO: Waiting up to 5m0s for pod "pod-914bfc56-8356-11e9-949c-223764f7eae1" in namespace "e2e-tests-emptydir-jzpp6" to be "success or failure"
May 31 03:45:43.973: INFO: Pod "pod-914bfc56-8356-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.123668ms
May 31 03:45:45.976: INFO: Pod "pod-914bfc56-8356-11e9-949c-223764f7eae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006994383s
May 31 03:45:47.979: INFO: Pod "pod-914bfc56-8356-11e9-949c-223764f7eae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010277498s
STEP: Saw pod success
May 31 03:45:47.979: INFO: Pod "pod-914bfc56-8356-11e9-949c-223764f7eae1" satisfied condition "success or failure"
May 31 03:45:47.982: INFO: Trying to get logs from node k8s-linuxpool-39082607-2 pod pod-914bfc56-8356-11e9-949c-223764f7eae1 container test-container: <nil>
STEP: delete the pod
May 31 03:45:47.995: INFO: Waiting for pod pod-914bfc56-8356-11e9-949c-223764f7eae1 to disappear
May 31 03:45:47.999: INFO: Pod pod-914bfc56-8356-11e9-949c-223764f7eae1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:45:47.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jzpp6" for this suite.
May 31 03:45:54.010: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:45:54.096: INFO: namespace: e2e-tests-emptydir-jzpp6, resource: bindings, ignored listing per whitelist
May 31 03:45:54.104: INFO: namespace e2e-tests-emptydir-jzpp6 deletion completed in 6.101790617s

• [SLOW TEST:10.223 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:45:54.104: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 31 03:45:54.173: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-ffcvc'
May 31 03:45:54.268: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 31 03:45:54.268: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
May 31 03:45:54.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535705201 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-ffcvc'
May 31 03:45:54.382: INFO: stderr: ""
May 31 03:45:54.382: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:45:54.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ffcvc" for this suite.
May 31 03:46:16.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:46:16.489: INFO: namespace: e2e-tests-kubectl-ffcvc, resource: bindings, ignored listing per whitelist
May 31 03:46:16.505: INFO: namespace e2e-tests-kubectl-ffcvc deletion completed in 22.117095954s

• [SLOW TEST:22.401 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 31 03:46:16.509: INFO: >>> kubeConfig: /tmp/kubeconfig-535705201
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 31 03:46:20.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-dtf78" for this suite.
May 31 03:46:26.666: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 31 03:46:26.755: INFO: namespace: e2e-tests-emptydir-wrapper-dtf78, resource: bindings, ignored listing per whitelist
May 31 03:46:26.761: INFO: namespace e2e-tests-emptydir-wrapper-dtf78 deletion completed in 6.105149217s

• [SLOW TEST:10.252 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.6-beta.0.111+abdda3f9fefa29/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSMay 31 03:46:26.763: INFO: Running AfterSuite actions on all nodes
May 31 03:46:26.763: INFO: Running AfterSuite actions on node 1
May 31 03:46:26.763: INFO: Skipping dumping logs from cluster

Ran 200 of 2162 Specs in 5758.231 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1962 Skipped PASS

Ginkgo ran 1 suite in 1h35m59.525571932s
Test Suite Passed
