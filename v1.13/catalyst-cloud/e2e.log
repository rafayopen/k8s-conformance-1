I0802 10:05:30.960345      18 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-983173982
I0802 10:05:30.960475      18 e2e.go:224] Starting e2e run "0f17542e-b50d-11e9-b8f5-0a4acaace53e" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1564740330 - Will randomize all specs
Will run 201 of 1946 specs

Aug  2 10:05:31.114: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
Aug  2 10:05:31.116: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Aug  2 10:05:31.150: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Aug  2 10:05:31.184: INFO: 12 / 12 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Aug  2 10:05:31.184: INFO: expected 6 pod replicas in namespace 'kube-system', 6 are Running and Ready.
Aug  2 10:05:31.184: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Aug  2 10:05:31.198: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Aug  2 10:05:31.198: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'k8s-keystone-auth' (0 seconds elapsed)
Aug  2 10:05:31.198: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'npd' (0 seconds elapsed)
Aug  2 10:05:31.198: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'openstack-cloud-controller-manager' (0 seconds elapsed)
Aug  2 10:05:31.198: INFO: e2e test version: v1.13.0
Aug  2 10:05:31.201: INFO: kube-apiserver version: v1.13.7
S
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:05:31.201: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename hostpath
Aug  2 10:05:31.335: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Aug  2 10:05:31.346: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-x9l6t" to be "success or failure"
Aug  2 10:05:31.357: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 11.164206ms
Aug  2 10:05:33.361: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014670253s
Aug  2 10:05:35.365: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018926743s
Aug  2 10:05:37.369: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 6.02284932s
Aug  2 10:05:40.241: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 8.895138532s
Aug  2 10:05:43.255: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 11.909148627s
Aug  2 10:05:45.259: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 13.912737902s
Aug  2 10:05:47.262: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 15.916548958s
Aug  2 10:05:49.266: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 17.920310117s
Aug  2 10:05:51.271: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 19.925115717s
Aug  2 10:05:53.275: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 21.929386923s
Aug  2 10:05:55.281: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 23.934807331s
Aug  2 10:05:57.285: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 25.939060974s
Aug  2 10:05:59.289: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 27.942840023s
Aug  2 10:06:01.293: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 29.94666792s
Aug  2 10:06:03.297: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 31.951189634s
Aug  2 10:06:05.301: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 33.954795107s
STEP: Saw pod success
Aug  2 10:06:05.301: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Aug  2 10:06:05.303: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Aug  2 10:06:05.376: INFO: Waiting for pod pod-host-path-test to disappear
Aug  2 10:06:05.382: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:06:05.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-x9l6t" for this suite.
Aug  2 10:06:13.401: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:06:13.425: INFO: namespace: e2e-tests-hostpath-x9l6t, resource: bindings, ignored listing per whitelist
Aug  2 10:06:13.547: INFO: namespace e2e-tests-hostpath-x9l6t deletion completed in 8.159257857s

• [SLOW TEST:42.346 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:06:13.548: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug  2 10:06:13.707: INFO: Waiting up to 5m0s for pod "downwardapi-volume-28e6f868-b50d-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-projected-9bbv8" to be "success or failure"
Aug  2 10:06:13.714: INFO: Pod "downwardapi-volume-28e6f868-b50d-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 7.325792ms
Aug  2 10:06:15.718: INFO: Pod "downwardapi-volume-28e6f868-b50d-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01150106s
STEP: Saw pod success
Aug  2 10:06:15.718: INFO: Pod "downwardapi-volume-28e6f868-b50d-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 10:06:15.720: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod downwardapi-volume-28e6f868-b50d-11e9-b8f5-0a4acaace53e container client-container: <nil>
STEP: delete the pod
Aug  2 10:06:15.746: INFO: Waiting for pod downwardapi-volume-28e6f868-b50d-11e9-b8f5-0a4acaace53e to disappear
Aug  2 10:06:15.751: INFO: Pod downwardapi-volume-28e6f868-b50d-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:06:15.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9bbv8" for this suite.
Aug  2 10:06:21.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:06:21.859: INFO: namespace: e2e-tests-projected-9bbv8, resource: bindings, ignored listing per whitelist
Aug  2 10:06:21.882: INFO: namespace e2e-tests-projected-9bbv8 deletion completed in 6.127728707s

• [SLOW TEST:8.334 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:06:21.882: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-mxt9v
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-mxt9v
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-mxt9v
Aug  2 10:06:22.147: INFO: Found 0 stateful pods, waiting for 1
Aug  2 10:06:32.151: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Aug  2 10:06:42.150: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Aug  2 10:06:42.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-mxt9v ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug  2 10:06:42.421: INFO: stderr: ""
Aug  2 10:06:42.421: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug  2 10:06:42.421: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug  2 10:06:42.424: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug  2 10:06:52.568: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug  2 10:06:52.568: INFO: Waiting for statefulset status.replicas updated to 0
Aug  2 10:06:52.585: INFO: POD   NODE                                PHASE    GRACE  CONDITIONS
Aug  2 10:06:52.585: INFO: ss-0  test-v1-13-7-gipwxthqfdpj-minion-0  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:06:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:06:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:06:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:06:22 +0000 UTC  }]
Aug  2 10:06:52.585: INFO: 
Aug  2 10:06:52.585: INFO: StatefulSet ss has not reached scale 3, at 1
Aug  2 10:06:53.590: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997040517s
Aug  2 10:06:54.594: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.991467631s
Aug  2 10:06:55.598: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.987914962s
Aug  2 10:06:56.602: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.984290492s
Aug  2 10:06:57.606: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.98007002s
Aug  2 10:06:58.610: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.976365568s
Aug  2 10:06:59.947: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.971855317s
Aug  2 10:07:00.954: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.634960467s
Aug  2 10:07:02.192: INFO: Verifying statefulset ss doesn't scale past 3 for another 627.723128ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-mxt9v
Aug  2 10:07:03.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-mxt9v ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  2 10:07:03.440: INFO: stderr: ""
Aug  2 10:07:03.440: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug  2 10:07:03.440: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug  2 10:07:03.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-mxt9v ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  2 10:07:03.709: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Aug  2 10:07:03.709: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug  2 10:07:03.709: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug  2 10:07:03.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-mxt9v ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  2 10:07:03.960: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Aug  2 10:07:03.960: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug  2 10:07:03.961: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug  2 10:07:03.964: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Aug  2 10:07:14.028: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug  2 10:07:14.028: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug  2 10:07:14.028: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Aug  2 10:07:14.035: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-mxt9v ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug  2 10:07:14.272: INFO: stderr: ""
Aug  2 10:07:14.272: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug  2 10:07:14.272: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug  2 10:07:14.272: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-mxt9v ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug  2 10:07:14.543: INFO: stderr: ""
Aug  2 10:07:14.543: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug  2 10:07:14.543: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug  2 10:07:14.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-mxt9v ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug  2 10:07:14.783: INFO: stderr: ""
Aug  2 10:07:14.783: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug  2 10:07:14.783: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug  2 10:07:14.783: INFO: Waiting for statefulset status.replicas updated to 0
Aug  2 10:07:14.786: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Aug  2 10:07:24.797: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug  2 10:07:24.797: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug  2 10:07:24.797: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug  2 10:07:24.815: INFO: POD   NODE                                PHASE    GRACE  CONDITIONS
Aug  2 10:07:24.815: INFO: ss-0  test-v1-13-7-gipwxthqfdpj-minion-0  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:06:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:07:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:07:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:06:22 +0000 UTC  }]
Aug  2 10:07:24.815: INFO: ss-1  test-v1-13-7-gipwxthqfdpj-minion-0  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:06:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:07:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:07:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:06:52 +0000 UTC  }]
Aug  2 10:07:24.815: INFO: ss-2  test-v1-13-7-gipwxthqfdpj-minion-0  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:06:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:07:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:07:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:06:52 +0000 UTC  }]
Aug  2 10:07:24.815: INFO: 
Aug  2 10:07:24.815: INFO: StatefulSet ss has not reached scale 0, at 3
Aug  2 10:07:25.908: INFO: POD   NODE                                PHASE    GRACE  CONDITIONS
Aug  2 10:07:25.908: INFO: ss-0  test-v1-13-7-gipwxthqfdpj-minion-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:06:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:07:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:07:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:06:22 +0000 UTC  }]
Aug  2 10:07:25.908: INFO: ss-1  test-v1-13-7-gipwxthqfdpj-minion-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:06:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:07:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:07:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:06:52 +0000 UTC  }]
Aug  2 10:07:25.908: INFO: ss-2  test-v1-13-7-gipwxthqfdpj-minion-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:06:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:07:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:07:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:06:52 +0000 UTC  }]
Aug  2 10:07:25.908: INFO: 
Aug  2 10:07:25.908: INFO: StatefulSet ss has not reached scale 0, at 3
Aug  2 10:07:26.912: INFO: POD   NODE                                PHASE    GRACE  CONDITIONS
Aug  2 10:07:26.912: INFO: ss-0  test-v1-13-7-gipwxthqfdpj-minion-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:06:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:07:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:07:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:06:22 +0000 UTC  }]
Aug  2 10:07:26.912: INFO: ss-1  test-v1-13-7-gipwxthqfdpj-minion-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:06:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:07:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:07:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:06:52 +0000 UTC  }]
Aug  2 10:07:26.912: INFO: ss-2  test-v1-13-7-gipwxthqfdpj-minion-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:06:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:07:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:07:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:06:52 +0000 UTC  }]
Aug  2 10:07:26.912: INFO: 
Aug  2 10:07:26.912: INFO: StatefulSet ss has not reached scale 0, at 3
Aug  2 10:07:27.916: INFO: POD   NODE                                PHASE    GRACE  CONDITIONS
Aug  2 10:07:27.916: INFO: ss-0  test-v1-13-7-gipwxthqfdpj-minion-0  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:06:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:07:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:07:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:06:22 +0000 UTC  }]
Aug  2 10:07:27.916: INFO: ss-1  test-v1-13-7-gipwxthqfdpj-minion-0  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:06:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:07:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:07:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:06:52 +0000 UTC  }]
Aug  2 10:07:27.916: INFO: ss-2  test-v1-13-7-gipwxthqfdpj-minion-0  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:06:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:07:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:07:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:06:52 +0000 UTC  }]
Aug  2 10:07:27.916: INFO: 
Aug  2 10:07:27.916: INFO: StatefulSet ss has not reached scale 0, at 3
Aug  2 10:07:28.920: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.888039306s
Aug  2 10:07:29.923: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.88443126s
Aug  2 10:07:30.927: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.881019625s
Aug  2 10:07:31.930: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.877485012s
Aug  2 10:07:32.933: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.874198452s
Aug  2 10:07:33.936: INFO: Verifying statefulset ss doesn't scale past 0 for another 870.87702ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-mxt9v
Aug  2 10:07:34.940: INFO: Scaling statefulset ss to 0
Aug  2 10:07:34.949: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Aug  2 10:07:34.952: INFO: Deleting all statefulset in ns e2e-tests-statefulset-mxt9v
Aug  2 10:07:34.955: INFO: Scaling statefulset ss to 0
Aug  2 10:07:34.962: INFO: Waiting for statefulset status.replicas updated to 0
Aug  2 10:07:34.964: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:07:34.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-mxt9v" for this suite.
Aug  2 10:07:40.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:07:41.100: INFO: namespace: e2e-tests-statefulset-mxt9v, resource: bindings, ignored listing per whitelist
Aug  2 10:07:41.117: INFO: namespace e2e-tests-statefulset-mxt9v deletion completed in 6.132751953s

• [SLOW TEST:79.235 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:07:41.118: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Aug  2 10:07:41.372: INFO: Waiting up to 5m0s for pod "pod-5d28bbc7-b50d-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-emptydir-c7tt5" to be "success or failure"
Aug  2 10:07:41.401: INFO: Pod "pod-5d28bbc7-b50d-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 28.989396ms
Aug  2 10:07:43.405: INFO: Pod "pod-5d28bbc7-b50d-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032621647s
Aug  2 10:07:45.409: INFO: Pod "pod-5d28bbc7-b50d-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037431003s
STEP: Saw pod success
Aug  2 10:07:45.409: INFO: Pod "pod-5d28bbc7-b50d-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 10:07:45.412: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-5d28bbc7-b50d-11e9-b8f5-0a4acaace53e container test-container: <nil>
STEP: delete the pod
Aug  2 10:07:45.432: INFO: Waiting for pod pod-5d28bbc7-b50d-11e9-b8f5-0a4acaace53e to disappear
Aug  2 10:07:45.440: INFO: Pod pod-5d28bbc7-b50d-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:07:45.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-c7tt5" for this suite.
Aug  2 10:07:51.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:07:51.542: INFO: namespace: e2e-tests-emptydir-c7tt5, resource: bindings, ignored listing per whitelist
Aug  2 10:07:51.553: INFO: namespace e2e-tests-emptydir-c7tt5 deletion completed in 6.108516481s

• [SLOW TEST:10.435 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:07:51.554: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-4dvrl
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-4dvrl
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-4dvrl
Aug  2 10:07:51.685: INFO: Found 0 stateful pods, waiting for 1
Aug  2 10:08:01.690: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Aug  2 10:08:01.692: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug  2 10:08:01.938: INFO: stderr: ""
Aug  2 10:08:01.938: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug  2 10:08:01.938: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug  2 10:08:01.941: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug  2 10:08:11.945: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug  2 10:08:11.945: INFO: Waiting for statefulset status.replicas updated to 0
Aug  2 10:08:12.282: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999682s
Aug  2 10:08:13.374: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.674407956s
Aug  2 10:08:14.378: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.582288557s
Aug  2 10:08:15.381: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.578276772s
Aug  2 10:08:16.385: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.574890706s
Aug  2 10:08:17.388: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.571288204s
Aug  2 10:08:18.392: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.568008211s
Aug  2 10:08:19.396: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.5645491s
Aug  2 10:08:20.399: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.560645788s
Aug  2 10:08:21.403: INFO: Verifying statefulset ss doesn't scale past 1 for another 556.745837ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-4dvrl
Aug  2 10:08:22.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  2 10:08:22.688: INFO: stderr: ""
Aug  2 10:08:22.688: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug  2 10:08:22.688: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug  2 10:08:22.691: INFO: Found 1 stateful pods, waiting for 3
Aug  2 10:08:32.696: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug  2 10:08:32.696: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug  2 10:08:32.696: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Aug  2 10:08:32.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug  2 10:08:32.968: INFO: stderr: ""
Aug  2 10:08:32.968: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug  2 10:08:32.968: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug  2 10:08:32.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug  2 10:08:33.922: INFO: stderr: ""
Aug  2 10:08:33.922: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug  2 10:08:33.922: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug  2 10:08:33.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug  2 10:08:34.267: INFO: stderr: ""
Aug  2 10:08:34.267: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug  2 10:08:34.267: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug  2 10:08:34.267: INFO: Waiting for statefulset status.replicas updated to 0
Aug  2 10:08:34.270: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Aug  2 10:08:44.278: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug  2 10:08:44.278: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug  2 10:08:44.278: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug  2 10:08:44.287: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999719s
Aug  2 10:08:45.291: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995522366s
Aug  2 10:08:46.295: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.9914581s
Aug  2 10:08:47.299: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.987165569s
Aug  2 10:08:48.303: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.983409285s
Aug  2 10:08:49.307: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.979572134s
Aug  2 10:08:50.311: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.975829937s
Aug  2 10:08:51.315: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.971707252s
Aug  2 10:08:52.319: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.967837089s
Aug  2 10:08:53.325: INFO: Verifying statefulset ss doesn't scale past 3 for another 964.109482ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-4dvrl
Aug  2 10:08:54.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  2 10:08:54.553: INFO: stderr: ""
Aug  2 10:08:54.553: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug  2 10:08:54.553: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug  2 10:08:54.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  2 10:08:54.786: INFO: stderr: ""
Aug  2 10:08:54.786: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug  2 10:08:54.786: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug  2 10:08:54.786: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  2 10:08:55.029: INFO: rc: 1
Aug  2 10:08:55.029: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc0015a3e90 exit status 1 <nil> <nil> true [0xc000e0df20 0xc000e0df40 0xc000e0df60] [0xc000e0df20 0xc000e0df40 0xc000e0df60] [0xc000e0df38 0xc000e0df58] [0x92f8e0 0x92f8e0] 0xc000d506c0 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Aug  2 10:09:05.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  2 10:09:05.303: INFO: rc: 1
Aug  2 10:09:05.303: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000fe7680 exit status 1 <nil> <nil> true [0xc000166838 0xc000166860 0xc000166898] [0xc000166838 0xc000166860 0xc000166898] [0xc000166850 0xc000166880] [0x92f8e0 0x92f8e0] 0xc0018cf860 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Aug  2 10:09:15.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  2 10:09:15.418: INFO: rc: 1
Aug  2 10:09:15.418: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0010b0d80 exit status 1 <nil> <nil> true [0xc00000e470 0xc00000e4e8 0xc00000e520] [0xc00000e470 0xc00000e4e8 0xc00000e520] [0xc00000e4a8 0xc00000e518] [0x92f8e0 0x92f8e0] 0xc00154b800 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Aug  2 10:09:25.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  2 10:09:25.534: INFO: rc: 1
Aug  2 10:09:25.534: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000fe7a40 exit status 1 <nil> <nil> true [0xc0001668a0 0xc000166c58 0xc0011d6010] [0xc0001668a0 0xc000166c58 0xc0011d6010] [0xc0001669e0 0xc0011d6008] [0x92f8e0 0x92f8e0] 0xc0018cfb60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Aug  2 10:09:35.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  2 10:09:35.651: INFO: rc: 1
Aug  2 10:09:35.651: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000fe7e30 exit status 1 <nil> <nil> true [0xc0011d6018 0xc0011d6058 0xc0011d6098] [0xc0011d6018 0xc0011d6058 0xc0011d6098] [0xc0011d6038 0xc0011d6090] [0x92f8e0 0x92f8e0] 0xc0018cfe60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Aug  2 10:09:45.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  2 10:09:45.778: INFO: rc: 1
Aug  2 10:09:45.778: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0010b1140 exit status 1 <nil> <nil> true [0xc00000e538 0xc00000e580 0xc00000e628] [0xc00000e538 0xc00000e580 0xc00000e628] [0xc00000e568 0xc00000e5f8] [0x92f8e0 0x92f8e0] 0xc00154bb00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Aug  2 10:09:55.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  2 10:09:55.899: INFO: rc: 1
Aug  2 10:09:55.899: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0006882d0 exit status 1 <nil> <nil> true [0xc0011d60a8 0xc0011d60c0 0xc0011d60d8] [0xc0011d60a8 0xc0011d60c0 0xc0011d60d8] [0xc0011d60b8 0xc0011d60d0] [0x92f8e0 0x92f8e0] 0xc0019342a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Aug  2 10:10:05.900: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  2 10:10:05.999: INFO: rc: 1
Aug  2 10:10:05.999: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0017503f0 exit status 1 <nil> <nil> true [0xc0000ca120 0xc0000ca278 0xc0000cbcb8] [0xc0000ca120 0xc0000ca278 0xc0000cbcb8] [0xc0000ca218 0xc0000ca2d8] [0x92f8e0 0x92f8e0] 0xc001544780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Aug  2 10:10:15.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  2 10:10:16.108: INFO: rc: 1
Aug  2 10:10:16.108: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000fe63c0 exit status 1 <nil> <nil> true [0xc000166000 0xc000166080 0xc0001660b8] [0xc000166000 0xc000166080 0xc0001660b8] [0xc000166068 0xc000166098] [0x92f8e0 0x92f8e0] 0xc0018ce240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Aug  2 10:10:26.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  2 10:10:26.218: INFO: rc: 1
Aug  2 10:10:26.218: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0007603f0 exit status 1 <nil> <nil> true [0xc000d00000 0xc000d00030 0xc000d00050] [0xc000d00000 0xc000d00030 0xc000d00050] [0xc000d00028 0xc000d00048] [0x92f8e0 0x92f8e0] 0xc0016aa240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Aug  2 10:10:36.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  2 10:10:36.305: INFO: rc: 1
Aug  2 10:10:36.305: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000fe67b0 exit status 1 <nil> <nil> true [0xc0001660c8 0xc0001661c8 0xc0001661f8] [0xc0001660c8 0xc0001661c8 0xc0001661f8] [0xc000166128 0xc0001661f0] [0x92f8e0 0x92f8e0] 0xc0018ce5a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Aug  2 10:10:46.305: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  2 10:10:46.411: INFO: rc: 1
Aug  2 10:10:46.411: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000fe6ba0 exit status 1 <nil> <nil> true [0xc000166218 0xc000166278 0xc0001662c0] [0xc000166218 0xc000166278 0xc0001662c0] [0xc000166270 0xc0001662a0] [0x92f8e0 0x92f8e0] 0xc0018ce8a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Aug  2 10:10:56.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  2 10:10:56.504: INFO: rc: 1
Aug  2 10:10:56.504: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000fe6f60 exit status 1 <nil> <nil> true [0xc0001662d8 0xc000166318 0xc000166388] [0xc0001662d8 0xc000166318 0xc000166388] [0xc000166308 0xc000166380] [0x92f8e0 0x92f8e0] 0xc0018ceba0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Aug  2 10:11:06.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  2 10:11:06.615: INFO: rc: 1
Aug  2 10:11:06.615: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000fe7350 exit status 1 <nil> <nil> true [0xc0001663a8 0xc0001663d0 0xc0001663f0] [0xc0001663a8 0xc0001663d0 0xc0001663f0] [0xc0001663c0 0xc0001663e0] [0x92f8e0 0x92f8e0] 0xc0018ceea0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Aug  2 10:11:16.615: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  2 10:11:16.708: INFO: rc: 1
Aug  2 10:11:16.708: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0017507b0 exit status 1 <nil> <nil> true [0xc0000cbd00 0xc0000cbdb8 0xc0000cbde8] [0xc0000cbd00 0xc0000cbdb8 0xc0000cbde8] [0xc0000cbd80 0xc0000cbde0] [0x92f8e0 0x92f8e0] 0xc001544d80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Aug  2 10:11:26.709: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  2 10:11:26.822: INFO: rc: 1
Aug  2 10:11:26.822: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001750bd0 exit status 1 <nil> <nil> true [0xc0000cbdf8 0xc0000cbe20 0xc0000cbec0] [0xc0000cbdf8 0xc0000cbe20 0xc0000cbec0] [0xc0000cbe18 0xc0000cbe88] [0x92f8e0 0x92f8e0] 0xc0015453e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Aug  2 10:11:36.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  2 10:11:36.919: INFO: rc: 1
Aug  2 10:11:36.919: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000fe7770 exit status 1 <nil> <nil> true [0xc0001663f8 0xc000166418 0xc000166458] [0xc0001663f8 0xc000166418 0xc000166458] [0xc000166410 0xc000166450] [0x92f8e0 0x92f8e0] 0xc0018cf200 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Aug  2 10:11:46.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  2 10:11:47.038: INFO: rc: 1
Aug  2 10:11:47.039: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001750fc0 exit status 1 <nil> <nil> true [0xc0000cbed8 0xc0000cbf00 0xc0000cbf68] [0xc0000cbed8 0xc0000cbf00 0xc0000cbf68] [0xc0000cbef8 0xc0000cbf50] [0x92f8e0 0x92f8e0] 0xc0015456e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Aug  2 10:11:57.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  2 10:11:57.141: INFO: rc: 1
Aug  2 10:11:57.141: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0007603c0 exit status 1 <nil> <nil> true [0xc000d00020 0xc000d00038 0xc000d00068] [0xc000d00020 0xc000d00038 0xc000d00068] [0xc000d00030 0xc000d00050] [0x92f8e0 0x92f8e0] 0xc0016aa240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Aug  2 10:12:07.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  2 10:12:07.263: INFO: rc: 1
Aug  2 10:12:07.263: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0007607e0 exit status 1 <nil> <nil> true [0xc000d00088 0xc000d000b0 0xc000d000c8] [0xc000d00088 0xc000d000b0 0xc000d000c8] [0xc000d000a8 0xc000d000c0] [0x92f8e0 0x92f8e0] 0xc0016aa5a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Aug  2 10:12:17.263: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  2 10:12:17.371: INFO: rc: 1
Aug  2 10:12:17.371: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000fe63f0 exit status 1 <nil> <nil> true [0xc000166000 0xc000166080 0xc0001660b8] [0xc000166000 0xc000166080 0xc0001660b8] [0xc000166068 0xc000166098] [0x92f8e0 0x92f8e0] 0xc0018ce240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Aug  2 10:12:27.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  2 10:12:27.463: INFO: rc: 1
Aug  2 10:12:27.463: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000760bd0 exit status 1 <nil> <nil> true [0xc000d000d0 0xc000d000e8 0xc000d00100] [0xc000d000d0 0xc000d000e8 0xc000d00100] [0xc000d000e0 0xc000d000f8] [0x92f8e0 0x92f8e0] 0xc0016aa8a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Aug  2 10:12:37.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  2 10:12:37.573: INFO: rc: 1
Aug  2 10:12:37.573: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001750420 exit status 1 <nil> <nil> true [0xc0000ca120 0xc0000ca278 0xc0000cbcb8] [0xc0000ca120 0xc0000ca278 0xc0000cbcb8] [0xc0000ca218 0xc0000ca2d8] [0x92f8e0 0x92f8e0] 0xc001544780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Aug  2 10:12:47.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  2 10:12:47.674: INFO: rc: 1
Aug  2 10:12:47.675: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001750840 exit status 1 <nil> <nil> true [0xc0000cbd00 0xc0000cbdb8 0xc0000cbde8] [0xc0000cbd00 0xc0000cbdb8 0xc0000cbde8] [0xc0000cbd80 0xc0000cbde0] [0x92f8e0 0x92f8e0] 0xc001544d80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Aug  2 10:12:57.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  2 10:12:57.808: INFO: rc: 1
Aug  2 10:12:57.808: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001750c60 exit status 1 <nil> <nil> true [0xc0000cbdf8 0xc0000cbe20 0xc0000cbec0] [0xc0000cbdf8 0xc0000cbe20 0xc0000cbec0] [0xc0000cbe18 0xc0000cbe88] [0x92f8e0 0x92f8e0] 0xc0015453e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Aug  2 10:13:07.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  2 10:13:07.917: INFO: rc: 1
Aug  2 10:13:07.917: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001751080 exit status 1 <nil> <nil> true [0xc0000cbed8 0xc0000cbf00 0xc0000cbf68] [0xc0000cbed8 0xc0000cbf00 0xc0000cbf68] [0xc0000cbef8 0xc0000cbf50] [0x92f8e0 0x92f8e0] 0xc0015456e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Aug  2 10:13:17.918: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  2 10:13:18.020: INFO: rc: 1
Aug  2 10:13:18.020: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000eaa540 exit status 1 <nil> <nil> true [0xc00000e0b8 0xc00000e1e8 0xc00000e250] [0xc00000e0b8 0xc00000e1e8 0xc00000e250] [0xc00000e1b8 0xc00000e238] [0x92f8e0 0x92f8e0] 0xc001cf6240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Aug  2 10:13:28.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  2 10:13:28.154: INFO: rc: 1
Aug  2 10:13:28.155: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000fe6840 exit status 1 <nil> <nil> true [0xc0001660c8 0xc0001661c8 0xc0001661f8] [0xc0001660c8 0xc0001661c8 0xc0001661f8] [0xc000166128 0xc0001661f0] [0x92f8e0 0x92f8e0] 0xc0018ce5a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Aug  2 10:13:38.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  2 10:13:38.251: INFO: rc: 1
Aug  2 10:13:38.251: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000eaa900 exit status 1 <nil> <nil> true [0xc00000e258 0xc00000e2d8 0xc00000e358] [0xc00000e258 0xc00000e2d8 0xc00000e358] [0xc00000e2b8 0xc00000e310] [0x92f8e0 0x92f8e0] 0xc001cf6540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Aug  2 10:13:48.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  2 10:13:48.350: INFO: rc: 1
Aug  2 10:13:48.350: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000eaad20 exit status 1 <nil> <nil> true [0xc00000e360 0xc00000e3b0 0xc00000e458] [0xc00000e360 0xc00000e3b0 0xc00000e458] [0xc00000e398 0xc00000e3f8] [0x92f8e0 0x92f8e0] 0xc001cf6840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Aug  2 10:13:58.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-4dvrl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  2 10:13:58.446: INFO: rc: 1
Aug  2 10:13:58.446: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Aug  2 10:13:58.446: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Aug  2 10:13:58.458: INFO: Deleting all statefulset in ns e2e-tests-statefulset-4dvrl
Aug  2 10:13:58.461: INFO: Scaling statefulset ss to 0
Aug  2 10:13:58.468: INFO: Waiting for statefulset status.replicas updated to 0
Aug  2 10:13:58.473: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:13:58.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-4dvrl" for this suite.
Aug  2 10:14:04.501: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:14:04.559: INFO: namespace: e2e-tests-statefulset-4dvrl, resource: bindings, ignored listing per whitelist
Aug  2 10:14:04.658: INFO: namespace e2e-tests-statefulset-4dvrl deletion completed in 6.166668s

• [SLOW TEST:373.104 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:14:04.659: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Aug  2 10:14:04.740: INFO: Waiting up to 5m0s for pod "downward-api-41a9e5a1-b50e-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-downward-api-vrpmw" to be "success or failure"
Aug  2 10:14:04.746: INFO: Pod "downward-api-41a9e5a1-b50e-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.662576ms
Aug  2 10:14:06.750: INFO: Pod "downward-api-41a9e5a1-b50e-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01083231s
Aug  2 10:14:08.755: INFO: Pod "downward-api-41a9e5a1-b50e-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015513029s
Aug  2 10:14:10.759: INFO: Pod "downward-api-41a9e5a1-b50e-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.019047797s
Aug  2 10:14:12.763: INFO: Pod "downward-api-41a9e5a1-b50e-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.023424687s
Aug  2 10:14:14.768: INFO: Pod "downward-api-41a9e5a1-b50e-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.028083764s
Aug  2 10:14:16.771: INFO: Pod "downward-api-41a9e5a1-b50e-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 12.031864491s
Aug  2 10:14:18.775: INFO: Pod "downward-api-41a9e5a1-b50e-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.035823622s
STEP: Saw pod success
Aug  2 10:14:18.776: INFO: Pod "downward-api-41a9e5a1-b50e-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 10:14:18.778: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod downward-api-41a9e5a1-b50e-11e9-b8f5-0a4acaace53e container dapi-container: <nil>
STEP: delete the pod
Aug  2 10:14:18.805: INFO: Waiting for pod downward-api-41a9e5a1-b50e-11e9-b8f5-0a4acaace53e to disappear
Aug  2 10:14:18.808: INFO: Pod downward-api-41a9e5a1-b50e-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:14:18.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-vrpmw" for this suite.
Aug  2 10:14:24.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:14:24.951: INFO: namespace: e2e-tests-downward-api-vrpmw, resource: bindings, ignored listing per whitelist
Aug  2 10:14:24.965: INFO: namespace e2e-tests-downward-api-vrpmw deletion completed in 6.154357282s

• [SLOW TEST:20.307 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:14:24.968: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:14:25.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-ps75f" for this suite.
Aug  2 10:14:47.149: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:14:47.262: INFO: namespace: e2e-tests-pods-ps75f, resource: bindings, ignored listing per whitelist
Aug  2 10:14:47.276: INFO: namespace e2e-tests-pods-ps75f deletion completed in 22.138890682s

• [SLOW TEST:22.308 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:14:47.278: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug  2 10:14:47.447: INFO: (0) /api/v1/nodes/test-v1-13-7-gipwxthqfdpj-minion-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 9.736568ms)
Aug  2 10:14:47.452: INFO: (1) /api/v1/nodes/test-v1-13-7-gipwxthqfdpj-minion-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 4.271278ms)
Aug  2 10:14:47.455: INFO: (2) /api/v1/nodes/test-v1-13-7-gipwxthqfdpj-minion-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 3.178681ms)
Aug  2 10:14:47.457: INFO: (3) /api/v1/nodes/test-v1-13-7-gipwxthqfdpj-minion-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.573582ms)
Aug  2 10:14:47.460: INFO: (4) /api/v1/nodes/test-v1-13-7-gipwxthqfdpj-minion-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.610461ms)
Aug  2 10:14:47.462: INFO: (5) /api/v1/nodes/test-v1-13-7-gipwxthqfdpj-minion-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.139735ms)
Aug  2 10:14:47.465: INFO: (6) /api/v1/nodes/test-v1-13-7-gipwxthqfdpj-minion-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.485208ms)
Aug  2 10:14:47.468: INFO: (7) /api/v1/nodes/test-v1-13-7-gipwxthqfdpj-minion-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 3.116506ms)
Aug  2 10:14:47.472: INFO: (8) /api/v1/nodes/test-v1-13-7-gipwxthqfdpj-minion-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 4.007711ms)
Aug  2 10:14:47.476: INFO: (9) /api/v1/nodes/test-v1-13-7-gipwxthqfdpj-minion-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 3.589476ms)
Aug  2 10:14:47.482: INFO: (10) /api/v1/nodes/test-v1-13-7-gipwxthqfdpj-minion-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 5.518507ms)
Aug  2 10:14:47.485: INFO: (11) /api/v1/nodes/test-v1-13-7-gipwxthqfdpj-minion-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 3.287562ms)
Aug  2 10:14:47.488: INFO: (12) /api/v1/nodes/test-v1-13-7-gipwxthqfdpj-minion-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.716214ms)
Aug  2 10:14:47.490: INFO: (13) /api/v1/nodes/test-v1-13-7-gipwxthqfdpj-minion-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.791061ms)
Aug  2 10:14:47.499: INFO: (14) /api/v1/nodes/test-v1-13-7-gipwxthqfdpj-minion-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 8.722004ms)
Aug  2 10:14:47.503: INFO: (15) /api/v1/nodes/test-v1-13-7-gipwxthqfdpj-minion-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 3.534536ms)
Aug  2 10:14:47.506: INFO: (16) /api/v1/nodes/test-v1-13-7-gipwxthqfdpj-minion-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.920318ms)
Aug  2 10:14:47.509: INFO: (17) /api/v1/nodes/test-v1-13-7-gipwxthqfdpj-minion-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.961211ms)
Aug  2 10:14:47.512: INFO: (18) /api/v1/nodes/test-v1-13-7-gipwxthqfdpj-minion-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.81888ms)
Aug  2 10:14:47.515: INFO: (19) /api/v1/nodes/test-v1-13-7-gipwxthqfdpj-minion-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 3.277018ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:14:47.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-wtwlx" for this suite.
Aug  2 10:14:53.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:14:53.624: INFO: namespace: e2e-tests-proxy-wtwlx, resource: bindings, ignored listing per whitelist
Aug  2 10:14:53.635: INFO: namespace e2e-tests-proxy-wtwlx deletion completed in 6.116184308s

• [SLOW TEST:6.357 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:14:53.635: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Aug  2 10:14:53.770: INFO: Waiting up to 5m0s for pod "downward-api-5ee2ef17-b50e-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-downward-api-v9j4d" to be "success or failure"
Aug  2 10:14:53.777: INFO: Pod "downward-api-5ee2ef17-b50e-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.882334ms
Aug  2 10:14:55.783: INFO: Pod "downward-api-5ee2ef17-b50e-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012405484s
Aug  2 10:14:57.787: INFO: Pod "downward-api-5ee2ef17-b50e-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017209765s
STEP: Saw pod success
Aug  2 10:14:57.788: INFO: Pod "downward-api-5ee2ef17-b50e-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 10:14:57.791: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod downward-api-5ee2ef17-b50e-11e9-b8f5-0a4acaace53e container dapi-container: <nil>
STEP: delete the pod
Aug  2 10:14:57.889: INFO: Waiting for pod downward-api-5ee2ef17-b50e-11e9-b8f5-0a4acaace53e to disappear
Aug  2 10:14:57.900: INFO: Pod downward-api-5ee2ef17-b50e-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:14:57.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-v9j4d" for this suite.
Aug  2 10:15:03.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:15:04.058: INFO: namespace: e2e-tests-downward-api-v9j4d, resource: bindings, ignored listing per whitelist
Aug  2 10:15:04.104: INFO: namespace e2e-tests-downward-api-v9j4d deletion completed in 6.201101527s

• [SLOW TEST:10.469 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:15:04.104: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-651c342d-b50e-11e9-b8f5-0a4acaace53e
STEP: Creating a pod to test consume configMaps
Aug  2 10:15:04.228: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-651da5b0-b50e-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-projected-jd2jb" to be "success or failure"
Aug  2 10:15:04.236: INFO: Pod "pod-projected-configmaps-651da5b0-b50e-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.36871ms
Aug  2 10:15:06.240: INFO: Pod "pod-projected-configmaps-651da5b0-b50e-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012489137s
Aug  2 10:15:08.244: INFO: Pod "pod-projected-configmaps-651da5b0-b50e-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016673642s
STEP: Saw pod success
Aug  2 10:15:08.244: INFO: Pod "pod-projected-configmaps-651da5b0-b50e-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 10:15:08.248: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-projected-configmaps-651da5b0-b50e-11e9-b8f5-0a4acaace53e container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug  2 10:15:08.273: INFO: Waiting for pod pod-projected-configmaps-651da5b0-b50e-11e9-b8f5-0a4acaace53e to disappear
Aug  2 10:15:08.295: INFO: Pod pod-projected-configmaps-651da5b0-b50e-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:15:08.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jd2jb" for this suite.
Aug  2 10:15:14.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:15:14.391: INFO: namespace: e2e-tests-projected-jd2jb, resource: bindings, ignored listing per whitelist
Aug  2 10:15:14.417: INFO: namespace e2e-tests-projected-jd2jb deletion completed in 6.118338394s

• [SLOW TEST:10.313 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:15:14.417: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-6b45fabd-b50e-11e9-b8f5-0a4acaace53e
Aug  2 10:15:14.560: INFO: Pod name my-hostname-basic-6b45fabd-b50e-11e9-b8f5-0a4acaace53e: Found 1 pods out of 1
Aug  2 10:15:14.560: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-6b45fabd-b50e-11e9-b8f5-0a4acaace53e" are running
Aug  2 10:15:30.569: INFO: Pod "my-hostname-basic-6b45fabd-b50e-11e9-b8f5-0a4acaace53e-kmf2h" is running (conditions: [{Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-02 10:15:14 +0000 UTC Reason: Message:}])
Aug  2 10:15:30.569: INFO: Trying to dial the pod
Aug  2 10:15:35.579: INFO: Controller my-hostname-basic-6b45fabd-b50e-11e9-b8f5-0a4acaace53e: Got expected result from replica 1 [my-hostname-basic-6b45fabd-b50e-11e9-b8f5-0a4acaace53e-kmf2h]: "my-hostname-basic-6b45fabd-b50e-11e9-b8f5-0a4acaace53e-kmf2h", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:15:35.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-6gpdm" for this suite.
Aug  2 10:15:41.594: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:15:41.702: INFO: namespace: e2e-tests-replication-controller-6gpdm, resource: bindings, ignored listing per whitelist
Aug  2 10:15:41.714: INFO: namespace e2e-tests-replication-controller-6gpdm deletion completed in 6.131421007s

• [SLOW TEST:27.297 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:15:41.716: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Aug  2 10:15:41.807: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 --namespace=e2e-tests-kubectl-ldb6g run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Aug  2 10:15:44.317: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Aug  2 10:15:44.317: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:15:46.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ldb6g" for this suite.
Aug  2 10:15:53.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:15:53.642: INFO: namespace: e2e-tests-kubectl-ldb6g, resource: bindings, ignored listing per whitelist
Aug  2 10:15:53.681: INFO: namespace e2e-tests-kubectl-ldb6g deletion completed in 7.352281061s

• [SLOW TEST:11.965 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:15:53.681: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug  2 10:15:54.282: INFO: Waiting up to 5m0s for pod "downwardapi-volume-82f44f58-b50e-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-downward-api-zn866" to be "success or failure"
Aug  2 10:15:54.501: INFO: Pod "downwardapi-volume-82f44f58-b50e-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 219.490991ms
Aug  2 10:15:56.509: INFO: Pod "downwardapi-volume-82f44f58-b50e-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.22703611s
STEP: Saw pod success
Aug  2 10:15:56.509: INFO: Pod "downwardapi-volume-82f44f58-b50e-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 10:15:56.515: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod downwardapi-volume-82f44f58-b50e-11e9-b8f5-0a4acaace53e container client-container: <nil>
STEP: delete the pod
Aug  2 10:15:56.539: INFO: Waiting for pod downwardapi-volume-82f44f58-b50e-11e9-b8f5-0a4acaace53e to disappear
Aug  2 10:15:56.557: INFO: Pod downwardapi-volume-82f44f58-b50e-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:15:56.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-zn866" for this suite.
Aug  2 10:16:02.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:16:02.593: INFO: namespace: e2e-tests-downward-api-zn866, resource: bindings, ignored listing per whitelist
Aug  2 10:16:02.695: INFO: namespace e2e-tests-downward-api-zn866 deletion completed in 6.13488972s

• [SLOW TEST:9.014 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:16:02.695: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-nvv49/configmap-test-880e741b-b50e-11e9-b8f5-0a4acaace53e
STEP: Creating a pod to test consume configMaps
Aug  2 10:16:02.842: INFO: Waiting up to 5m0s for pod "pod-configmaps-880f0c35-b50e-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-configmap-nvv49" to be "success or failure"
Aug  2 10:16:02.894: INFO: Pod "pod-configmaps-880f0c35-b50e-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 52.579034ms
Aug  2 10:16:04.898: INFO: Pod "pod-configmaps-880f0c35-b50e-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.056123893s
Aug  2 10:16:06.901: INFO: Pod "pod-configmaps-880f0c35-b50e-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.059632471s
STEP: Saw pod success
Aug  2 10:16:06.901: INFO: Pod "pod-configmaps-880f0c35-b50e-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 10:16:06.903: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-configmaps-880f0c35-b50e-11e9-b8f5-0a4acaace53e container env-test: <nil>
STEP: delete the pod
Aug  2 10:16:06.963: INFO: Waiting for pod pod-configmaps-880f0c35-b50e-11e9-b8f5-0a4acaace53e to disappear
Aug  2 10:16:06.967: INFO: Pod pod-configmaps-880f0c35-b50e-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:16:06.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-nvv49" for this suite.
Aug  2 10:16:12.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:16:13.038: INFO: namespace: e2e-tests-configmap-nvv49, resource: bindings, ignored listing per whitelist
Aug  2 10:16:13.135: INFO: namespace e2e-tests-configmap-nvv49 deletion completed in 6.164982331s

• [SLOW TEST:10.439 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:16:13.135: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-8e42eaf4-b50e-11e9-b8f5-0a4acaace53e
STEP: Creating a pod to test consume secrets
Aug  2 10:16:13.252: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8e43970a-b50e-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-projected-j9nqt" to be "success or failure"
Aug  2 10:16:13.258: INFO: Pod "pod-projected-secrets-8e43970a-b50e-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.587861ms
Aug  2 10:16:15.262: INFO: Pod "pod-projected-secrets-8e43970a-b50e-11e9-b8f5-0a4acaace53e": Phase="Running", Reason="", readiness=true. Elapsed: 2.010241163s
Aug  2 10:16:17.265: INFO: Pod "pod-projected-secrets-8e43970a-b50e-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013409197s
STEP: Saw pod success
Aug  2 10:16:17.265: INFO: Pod "pod-projected-secrets-8e43970a-b50e-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 10:16:17.267: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-projected-secrets-8e43970a-b50e-11e9-b8f5-0a4acaace53e container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug  2 10:16:17.333: INFO: Waiting for pod pod-projected-secrets-8e43970a-b50e-11e9-b8f5-0a4acaace53e to disappear
Aug  2 10:16:17.336: INFO: Pod pod-projected-secrets-8e43970a-b50e-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:16:17.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-j9nqt" for this suite.
Aug  2 10:16:23.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:16:23.397: INFO: namespace: e2e-tests-projected-j9nqt, resource: bindings, ignored listing per whitelist
Aug  2 10:16:23.460: INFO: namespace e2e-tests-projected-j9nqt deletion completed in 6.120410155s

• [SLOW TEST:10.325 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:16:23.461: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Aug  2 10:16:23.537: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:16:38.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-gjlr2" for this suite.
Aug  2 10:17:00.340: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:17:00.464: INFO: namespace: e2e-tests-init-container-gjlr2, resource: bindings, ignored listing per whitelist
Aug  2 10:17:00.566: INFO: namespace e2e-tests-init-container-gjlr2 deletion completed in 22.23948695s

• [SLOW TEST:37.106 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:17:00.567: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-s5rxr
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug  2 10:17:00.646: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug  2 10:17:44.716: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.232.28:8080/dial?request=hostName&protocol=udp&host=192.168.232.27&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-s5rxr PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  2 10:17:44.717: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
Aug  2 10:17:44.861: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:17:44.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-s5rxr" for this suite.
Aug  2 10:18:06.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:18:06.977: INFO: namespace: e2e-tests-pod-network-test-s5rxr, resource: bindings, ignored listing per whitelist
Aug  2 10:18:07.018: INFO: namespace e2e-tests-pod-network-test-s5rxr deletion completed in 22.150916434s

• [SLOW TEST:66.451 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:18:07.020: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Aug  2 10:18:07.126: INFO: Waiting up to 5m0s for pod "pod-d2234791-b50e-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-emptydir-6ghzh" to be "success or failure"
Aug  2 10:18:07.132: INFO: Pod "pod-d2234791-b50e-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.103503ms
Aug  2 10:18:09.136: INFO: Pod "pod-d2234791-b50e-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009391939s
STEP: Saw pod success
Aug  2 10:18:09.136: INFO: Pod "pod-d2234791-b50e-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 10:18:09.138: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-d2234791-b50e-11e9-b8f5-0a4acaace53e container test-container: <nil>
STEP: delete the pod
Aug  2 10:18:09.225: INFO: Waiting for pod pod-d2234791-b50e-11e9-b8f5-0a4acaace53e to disappear
Aug  2 10:18:09.231: INFO: Pod pod-d2234791-b50e-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:18:09.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-6ghzh" for this suite.
Aug  2 10:18:15.257: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:18:15.372: INFO: namespace: e2e-tests-emptydir-6ghzh, resource: bindings, ignored listing per whitelist
Aug  2 10:18:15.375: INFO: namespace e2e-tests-emptydir-6ghzh deletion completed in 6.133436343s

• [SLOW TEST:8.355 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:18:15.376: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug  2 10:18:16.039: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Aug  2 10:18:16.053: INFO: Number of nodes with available pods: 0
Aug  2 10:18:16.053: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Aug  2 10:18:16.112: INFO: Number of nodes with available pods: 0
Aug  2 10:18:16.112: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:18:17.120: INFO: Number of nodes with available pods: 0
Aug  2 10:18:17.120: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:18:18.116: INFO: Number of nodes with available pods: 0
Aug  2 10:18:18.116: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:18:19.116: INFO: Number of nodes with available pods: 1
Aug  2 10:18:19.116: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Aug  2 10:18:19.156: INFO: Number of nodes with available pods: 1
Aug  2 10:18:19.156: INFO: Number of running nodes: 0, number of available pods: 1
Aug  2 10:18:20.160: INFO: Number of nodes with available pods: 0
Aug  2 10:18:20.160: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Aug  2 10:18:20.175: INFO: Number of nodes with available pods: 0
Aug  2 10:18:20.175: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:18:21.179: INFO: Number of nodes with available pods: 0
Aug  2 10:18:21.179: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:18:22.179: INFO: Number of nodes with available pods: 0
Aug  2 10:18:22.179: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:18:23.179: INFO: Number of nodes with available pods: 0
Aug  2 10:18:23.179: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:18:24.179: INFO: Number of nodes with available pods: 0
Aug  2 10:18:24.179: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:18:25.179: INFO: Number of nodes with available pods: 0
Aug  2 10:18:25.180: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:18:26.179: INFO: Number of nodes with available pods: 0
Aug  2 10:18:26.179: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:18:27.180: INFO: Number of nodes with available pods: 0
Aug  2 10:18:27.180: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:18:28.179: INFO: Number of nodes with available pods: 0
Aug  2 10:18:28.179: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:18:29.179: INFO: Number of nodes with available pods: 0
Aug  2 10:18:29.179: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:18:30.179: INFO: Number of nodes with available pods: 0
Aug  2 10:18:30.179: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:18:31.179: INFO: Number of nodes with available pods: 0
Aug  2 10:18:31.179: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:18:32.181: INFO: Number of nodes with available pods: 0
Aug  2 10:18:32.181: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:18:33.179: INFO: Number of nodes with available pods: 0
Aug  2 10:18:33.179: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:18:34.179: INFO: Number of nodes with available pods: 0
Aug  2 10:18:34.179: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:18:35.264: INFO: Number of nodes with available pods: 0
Aug  2 10:18:35.264: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:18:36.179: INFO: Number of nodes with available pods: 0
Aug  2 10:18:36.179: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:18:37.244: INFO: Number of nodes with available pods: 0
Aug  2 10:18:37.244: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:18:38.179: INFO: Number of nodes with available pods: 0
Aug  2 10:18:38.179: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:18:39.180: INFO: Number of nodes with available pods: 0
Aug  2 10:18:39.180: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:18:40.265: INFO: Number of nodes with available pods: 0
Aug  2 10:18:40.266: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:18:41.179: INFO: Number of nodes with available pods: 0
Aug  2 10:18:41.179: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:18:42.179: INFO: Number of nodes with available pods: 0
Aug  2 10:18:42.179: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:18:43.179: INFO: Number of nodes with available pods: 0
Aug  2 10:18:43.179: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:18:44.180: INFO: Number of nodes with available pods: 0
Aug  2 10:18:44.180: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:18:45.179: INFO: Number of nodes with available pods: 0
Aug  2 10:18:45.179: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:18:46.665: INFO: Number of nodes with available pods: 0
Aug  2 10:18:46.665: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:18:47.337: INFO: Number of nodes with available pods: 0
Aug  2 10:18:47.337: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:18:48.179: INFO: Number of nodes with available pods: 0
Aug  2 10:18:48.179: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:18:49.179: INFO: Number of nodes with available pods: 0
Aug  2 10:18:49.179: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:18:50.179: INFO: Number of nodes with available pods: 0
Aug  2 10:18:50.179: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:18:51.316: INFO: Number of nodes with available pods: 0
Aug  2 10:18:51.316: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:18:52.256: INFO: Number of nodes with available pods: 0
Aug  2 10:18:52.256: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:18:53.179: INFO: Number of nodes with available pods: 0
Aug  2 10:18:53.180: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:18:54.179: INFO: Number of nodes with available pods: 0
Aug  2 10:18:54.179: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:18:55.363: INFO: Number of nodes with available pods: 1
Aug  2 10:18:55.363: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-hmcfd, will wait for the garbage collector to delete the pods
Aug  2 10:18:55.626: INFO: Deleting DaemonSet.extensions daemon-set took: 136.060348ms
Aug  2 10:18:55.727: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.515228ms
Aug  2 10:19:30.831: INFO: Number of nodes with available pods: 0
Aug  2 10:19:30.831: INFO: Number of running nodes: 0, number of available pods: 0
Aug  2 10:19:30.835: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-hmcfd/daemonsets","resourceVersion":"9371"},"items":null}

Aug  2 10:19:30.837: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-hmcfd/pods","resourceVersion":"9371"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:19:30.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-hmcfd" for this suite.
Aug  2 10:19:36.866: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:19:36.973: INFO: namespace: e2e-tests-daemonsets-hmcfd, resource: bindings, ignored listing per whitelist
Aug  2 10:19:37.012: INFO: namespace e2e-tests-daemonsets-hmcfd deletion completed in 6.157101638s

• [SLOW TEST:81.636 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:19:37.012: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug  2 10:19:37.105: INFO: (0) /api/v1/nodes/test-v1-13-7-gipwxthqfdpj-minion-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 7.075202ms)
Aug  2 10:19:37.109: INFO: (1) /api/v1/nodes/test-v1-13-7-gipwxthqfdpj-minion-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 4.078681ms)
Aug  2 10:19:37.113: INFO: (2) /api/v1/nodes/test-v1-13-7-gipwxthqfdpj-minion-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 3.622297ms)
Aug  2 10:19:37.117: INFO: (3) /api/v1/nodes/test-v1-13-7-gipwxthqfdpj-minion-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 3.29685ms)
Aug  2 10:19:37.120: INFO: (4) /api/v1/nodes/test-v1-13-7-gipwxthqfdpj-minion-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 3.480407ms)
Aug  2 10:19:37.124: INFO: (5) /api/v1/nodes/test-v1-13-7-gipwxthqfdpj-minion-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 3.680553ms)
Aug  2 10:19:37.129: INFO: (6) /api/v1/nodes/test-v1-13-7-gipwxthqfdpj-minion-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 4.700607ms)
Aug  2 10:19:37.132: INFO: (7) /api/v1/nodes/test-v1-13-7-gipwxthqfdpj-minion-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 3.226185ms)
Aug  2 10:19:37.136: INFO: (8) /api/v1/nodes/test-v1-13-7-gipwxthqfdpj-minion-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 3.889817ms)
Aug  2 10:19:37.138: INFO: (9) /api/v1/nodes/test-v1-13-7-gipwxthqfdpj-minion-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.670986ms)
Aug  2 10:19:37.142: INFO: (10) /api/v1/nodes/test-v1-13-7-gipwxthqfdpj-minion-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 3.246302ms)
Aug  2 10:19:37.146: INFO: (11) /api/v1/nodes/test-v1-13-7-gipwxthqfdpj-minion-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 4.331143ms)
Aug  2 10:19:37.150: INFO: (12) /api/v1/nodes/test-v1-13-7-gipwxthqfdpj-minion-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 3.449474ms)
Aug  2 10:19:37.153: INFO: (13) /api/v1/nodes/test-v1-13-7-gipwxthqfdpj-minion-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 3.162131ms)
Aug  2 10:19:37.156: INFO: (14) /api/v1/nodes/test-v1-13-7-gipwxthqfdpj-minion-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 3.21028ms)
Aug  2 10:19:37.163: INFO: (15) /api/v1/nodes/test-v1-13-7-gipwxthqfdpj-minion-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 6.702699ms)
Aug  2 10:19:37.171: INFO: (16) /api/v1/nodes/test-v1-13-7-gipwxthqfdpj-minion-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 7.899681ms)
Aug  2 10:19:37.174: INFO: (17) /api/v1/nodes/test-v1-13-7-gipwxthqfdpj-minion-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 3.153816ms)
Aug  2 10:19:37.178: INFO: (18) /api/v1/nodes/test-v1-13-7-gipwxthqfdpj-minion-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 3.656634ms)
Aug  2 10:19:37.185: INFO: (19) /api/v1/nodes/test-v1-13-7-gipwxthqfdpj-minion-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 6.94361ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:19:37.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-p677b" for this suite.
Aug  2 10:19:43.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:19:43.297: INFO: namespace: e2e-tests-proxy-p677b, resource: bindings, ignored listing per whitelist
Aug  2 10:19:43.319: INFO: namespace e2e-tests-proxy-p677b deletion completed in 6.131211702s

• [SLOW TEST:6.307 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:19:43.320: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Aug  2 10:19:44.029: INFO: created pod pod-service-account-defaultsa
Aug  2 10:19:44.029: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Aug  2 10:19:44.037: INFO: created pod pod-service-account-mountsa
Aug  2 10:19:44.037: INFO: pod pod-service-account-mountsa service account token volume mount: true
Aug  2 10:19:44.047: INFO: created pod pod-service-account-nomountsa
Aug  2 10:19:44.047: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Aug  2 10:19:44.051: INFO: created pod pod-service-account-defaultsa-mountspec
Aug  2 10:19:44.051: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Aug  2 10:19:44.057: INFO: created pod pod-service-account-mountsa-mountspec
Aug  2 10:19:44.057: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Aug  2 10:19:44.064: INFO: created pod pod-service-account-nomountsa-mountspec
Aug  2 10:19:44.064: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Aug  2 10:19:44.072: INFO: created pod pod-service-account-defaultsa-nomountspec
Aug  2 10:19:44.072: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Aug  2 10:19:44.085: INFO: created pod pod-service-account-mountsa-nomountspec
Aug  2 10:19:44.085: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Aug  2 10:19:44.090: INFO: created pod pod-service-account-nomountsa-nomountspec
Aug  2 10:19:44.090: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:19:44.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-kbmpp" for this suite.
Aug  2 10:20:06.113: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:20:06.178: INFO: namespace: e2e-tests-svcaccounts-kbmpp, resource: bindings, ignored listing per whitelist
Aug  2 10:20:06.215: INFO: namespace e2e-tests-svcaccounts-kbmpp deletion completed in 22.119810285s

• [SLOW TEST:22.895 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:20:06.216: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Aug  2 10:20:06.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 api-versions'
Aug  2 10:20:06.578: INFO: stderr: ""
Aug  2 10:20:06.578: INFO: stdout: "admissionregistration.k8s.io/v1alpha1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauditregistration.k8s.io/v1alpha1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1alpha1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1alpha1\nscheduling.k8s.io/v1beta1\nsettings.k8s.io/v1alpha1\nstorage.k8s.io/v1\nstorage.k8s.io/v1alpha1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:20:06.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-p7j5q" for this suite.
Aug  2 10:20:12.592: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:20:12.652: INFO: namespace: e2e-tests-kubectl-p7j5q, resource: bindings, ignored listing per whitelist
Aug  2 10:20:12.717: INFO: namespace e2e-tests-kubectl-p7j5q deletion completed in 6.135639481s

• [SLOW TEST:6.501 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:20:12.718: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-bf975
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug  2 10:20:12.792: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug  2 10:20:30.862: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 192.168.232.41 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-bf975 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  2 10:20:30.862: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
Aug  2 10:20:32.012: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:20:32.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-bf975" for this suite.
Aug  2 10:20:54.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:20:54.066: INFO: namespace: e2e-tests-pod-network-test-bf975, resource: bindings, ignored listing per whitelist
Aug  2 10:20:54.150: INFO: namespace e2e-tests-pod-network-test-bf975 deletion completed in 22.133675161s

• [SLOW TEST:41.432 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:20:54.152: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:21:54.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-d4bvf" for this suite.
Aug  2 10:22:12.326: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:22:12.409: INFO: namespace: e2e-tests-container-probe-d4bvf, resource: bindings, ignored listing per whitelist
Aug  2 10:22:12.457: INFO: namespace e2e-tests-container-probe-d4bvf deletion completed in 18.144918227s

• [SLOW TEST:78.306 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:22:12.458: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug  2 10:22:12.552: INFO: Waiting up to 5m0s for pod "downwardapi-volume-646bb880-b50f-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-projected-n2q9l" to be "success or failure"
Aug  2 10:22:12.567: INFO: Pod "downwardapi-volume-646bb880-b50f-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 15.417725ms
Aug  2 10:22:14.571: INFO: Pod "downwardapi-volume-646bb880-b50f-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019213575s
Aug  2 10:22:16.575: INFO: Pod "downwardapi-volume-646bb880-b50f-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022766612s
STEP: Saw pod success
Aug  2 10:22:16.575: INFO: Pod "downwardapi-volume-646bb880-b50f-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 10:22:16.577: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod downwardapi-volume-646bb880-b50f-11e9-b8f5-0a4acaace53e container client-container: <nil>
STEP: delete the pod
Aug  2 10:22:16.601: INFO: Waiting for pod downwardapi-volume-646bb880-b50f-11e9-b8f5-0a4acaace53e to disappear
Aug  2 10:22:16.605: INFO: Pod downwardapi-volume-646bb880-b50f-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:22:16.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-n2q9l" for this suite.
Aug  2 10:22:22.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:22:22.638: INFO: namespace: e2e-tests-projected-n2q9l, resource: bindings, ignored listing per whitelist
Aug  2 10:22:22.738: INFO: namespace e2e-tests-projected-n2q9l deletion completed in 6.130745988s

• [SLOW TEST:10.281 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:22:22.740: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Aug  2 10:22:22.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 cluster-info'
Aug  2 10:22:22.941: INFO: stderr: ""
Aug  2 10:22:22.941: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.254.0.1:443\x1b[0m\n\x1b[0;32mHeapster\x1b[0m is running at \x1b[0;33mhttps://10.254.0.1:443/api/v1/namespaces/kube-system/services/heapster/proxy\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.254.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:22:22.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qg4vz" for this suite.
Aug  2 10:22:28.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:22:29.053: INFO: namespace: e2e-tests-kubectl-qg4vz, resource: bindings, ignored listing per whitelist
Aug  2 10:22:29.064: INFO: namespace e2e-tests-kubectl-qg4vz deletion completed in 6.119996455s

• [SLOW TEST:6.324 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:22:29.065: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Aug  2 10:22:31.693: INFO: Successfully updated pod "labelsupdate6e4ef7f4-b50f-11e9-b8f5-0a4acaace53e"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:22:33.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-l9dc8" for this suite.
Aug  2 10:22:55.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:22:55.828: INFO: namespace: e2e-tests-downward-api-l9dc8, resource: bindings, ignored listing per whitelist
Aug  2 10:22:55.855: INFO: namespace e2e-tests-downward-api-l9dc8 deletion completed in 22.130588284s

• [SLOW TEST:26.790 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:22:55.856: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Aug  2 10:22:55.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 create -f - --namespace=e2e-tests-kubectl-9cjth'
Aug  2 10:22:56.317: INFO: stderr: ""
Aug  2 10:22:56.317: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug  2 10:22:57.324: INFO: Selector matched 1 pods for map[app:redis]
Aug  2 10:22:57.324: INFO: Found 0 / 1
Aug  2 10:22:58.321: INFO: Selector matched 1 pods for map[app:redis]
Aug  2 10:22:58.321: INFO: Found 0 / 1
Aug  2 10:22:59.322: INFO: Selector matched 1 pods for map[app:redis]
Aug  2 10:22:59.322: INFO: Found 0 / 1
Aug  2 10:23:00.321: INFO: Selector matched 1 pods for map[app:redis]
Aug  2 10:23:00.321: INFO: Found 0 / 1
Aug  2 10:23:01.685: INFO: Selector matched 1 pods for map[app:redis]
Aug  2 10:23:01.685: INFO: Found 0 / 1
Aug  2 10:23:02.321: INFO: Selector matched 1 pods for map[app:redis]
Aug  2 10:23:02.321: INFO: Found 0 / 1
Aug  2 10:23:03.322: INFO: Selector matched 1 pods for map[app:redis]
Aug  2 10:23:03.322: INFO: Found 0 / 1
Aug  2 10:23:04.322: INFO: Selector matched 1 pods for map[app:redis]
Aug  2 10:23:04.322: INFO: Found 0 / 1
Aug  2 10:23:05.320: INFO: Selector matched 1 pods for map[app:redis]
Aug  2 10:23:05.320: INFO: Found 0 / 1
Aug  2 10:23:06.321: INFO: Selector matched 1 pods for map[app:redis]
Aug  2 10:23:06.321: INFO: Found 0 / 1
Aug  2 10:23:07.323: INFO: Selector matched 1 pods for map[app:redis]
Aug  2 10:23:07.323: INFO: Found 0 / 1
Aug  2 10:23:08.321: INFO: Selector matched 1 pods for map[app:redis]
Aug  2 10:23:08.321: INFO: Found 0 / 1
Aug  2 10:23:09.321: INFO: Selector matched 1 pods for map[app:redis]
Aug  2 10:23:09.321: INFO: Found 1 / 1
Aug  2 10:23:09.321: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Aug  2 10:23:09.324: INFO: Selector matched 1 pods for map[app:redis]
Aug  2 10:23:09.324: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug  2 10:23:09.324: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 patch pod redis-master-xsd7m --namespace=e2e-tests-kubectl-9cjth -p {"metadata":{"annotations":{"x":"y"}}}'
Aug  2 10:23:09.463: INFO: stderr: ""
Aug  2 10:23:09.463: INFO: stdout: "pod/redis-master-xsd7m patched\n"
STEP: checking annotations
Aug  2 10:23:09.466: INFO: Selector matched 1 pods for map[app:redis]
Aug  2 10:23:09.466: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:23:09.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9cjth" for this suite.
Aug  2 10:23:31.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:23:31.578: INFO: namespace: e2e-tests-kubectl-9cjth, resource: bindings, ignored listing per whitelist
Aug  2 10:23:31.588: INFO: namespace e2e-tests-kubectl-9cjth deletion completed in 22.11628283s

• [SLOW TEST:35.732 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:23:31.590: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-q7mfx
Aug  2 10:23:45.689: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-q7mfx
STEP: checking the pod's current state and verifying that restartCount is present
Aug  2 10:23:45.691: INFO: Initial restart count of pod liveness-http is 0
Aug  2 10:24:03.786: INFO: Restart count of pod e2e-tests-container-probe-q7mfx/liveness-http is now 1 (18.094893953s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:24:03.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-q7mfx" for this suite.
Aug  2 10:24:09.813: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:24:09.974: INFO: namespace: e2e-tests-container-probe-q7mfx, resource: bindings, ignored listing per whitelist
Aug  2 10:24:09.994: INFO: namespace e2e-tests-container-probe-q7mfx deletion completed in 6.192189772s

• [SLOW TEST:38.404 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:24:09.995: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug  2 10:24:10.245: INFO: Creating ReplicaSet my-hostname-basic-aa93b335-b50f-11e9-b8f5-0a4acaace53e
Aug  2 10:24:10.255: INFO: Pod name my-hostname-basic-aa93b335-b50f-11e9-b8f5-0a4acaace53e: Found 0 pods out of 1
Aug  2 10:24:15.259: INFO: Pod name my-hostname-basic-aa93b335-b50f-11e9-b8f5-0a4acaace53e: Found 1 pods out of 1
Aug  2 10:24:15.259: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-aa93b335-b50f-11e9-b8f5-0a4acaace53e" is running
Aug  2 10:24:15.263: INFO: Pod "my-hostname-basic-aa93b335-b50f-11e9-b8f5-0a4acaace53e-skrrd" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-02 10:24:10 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-02 10:24:12 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-02 10:24:12 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-02 10:24:10 +0000 UTC Reason: Message:}])
Aug  2 10:24:15.263: INFO: Trying to dial the pod
Aug  2 10:24:20.276: INFO: Controller my-hostname-basic-aa93b335-b50f-11e9-b8f5-0a4acaace53e: Got expected result from replica 1 [my-hostname-basic-aa93b335-b50f-11e9-b8f5-0a4acaace53e-skrrd]: "my-hostname-basic-aa93b335-b50f-11e9-b8f5-0a4acaace53e-skrrd", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:24:20.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-wdzxx" for this suite.
Aug  2 10:24:26.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:24:26.406: INFO: namespace: e2e-tests-replicaset-wdzxx, resource: bindings, ignored listing per whitelist
Aug  2 10:24:26.406: INFO: namespace e2e-tests-replicaset-wdzxx deletion completed in 6.124872247s

• [SLOW TEST:16.411 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:24:26.407: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-b4424925-b50f-11e9-b8f5-0a4acaace53e
STEP: Creating a pod to test consume secrets
Aug  2 10:24:26.498: INFO: Waiting up to 5m0s for pod "pod-secrets-b442dd6f-b50f-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-secrets-zqpl6" to be "success or failure"
Aug  2 10:24:26.505: INFO: Pod "pod-secrets-b442dd6f-b50f-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 7.019078ms
Aug  2 10:24:28.509: INFO: Pod "pod-secrets-b442dd6f-b50f-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010544644s
STEP: Saw pod success
Aug  2 10:24:28.509: INFO: Pod "pod-secrets-b442dd6f-b50f-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 10:24:28.511: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-secrets-b442dd6f-b50f-11e9-b8f5-0a4acaace53e container secret-volume-test: <nil>
STEP: delete the pod
Aug  2 10:24:28.567: INFO: Waiting for pod pod-secrets-b442dd6f-b50f-11e9-b8f5-0a4acaace53e to disappear
Aug  2 10:24:28.577: INFO: Pod pod-secrets-b442dd6f-b50f-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:24:28.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-zqpl6" for this suite.
Aug  2 10:24:34.596: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:24:34.626: INFO: namespace: e2e-tests-secrets-zqpl6, resource: bindings, ignored listing per whitelist
Aug  2 10:24:34.704: INFO: namespace e2e-tests-secrets-zqpl6 deletion completed in 6.124676548s

• [SLOW TEST:8.298 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:24:34.706: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Aug  2 10:24:34.793: INFO: Waiting up to 5m0s for pod "pod-b934476a-b50f-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-emptydir-lpvxd" to be "success or failure"
Aug  2 10:24:34.799: INFO: Pod "pod-b934476a-b50f-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.545927ms
Aug  2 10:24:36.803: INFO: Pod "pod-b934476a-b50f-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010696743s
STEP: Saw pod success
Aug  2 10:24:36.804: INFO: Pod "pod-b934476a-b50f-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 10:24:36.809: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-b934476a-b50f-11e9-b8f5-0a4acaace53e container test-container: <nil>
STEP: delete the pod
Aug  2 10:24:37.006: INFO: Waiting for pod pod-b934476a-b50f-11e9-b8f5-0a4acaace53e to disappear
Aug  2 10:24:37.012: INFO: Pod pod-b934476a-b50f-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:24:37.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-lpvxd" for this suite.
Aug  2 10:24:43.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:24:43.104: INFO: namespace: e2e-tests-emptydir-lpvxd, resource: bindings, ignored listing per whitelist
Aug  2 10:24:43.152: INFO: namespace e2e-tests-emptydir-lpvxd deletion completed in 6.135586404s

• [SLOW TEST:8.446 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:24:43.153: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:24:50.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-hmqgq" for this suite.
Aug  2 10:24:56.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:24:56.250: INFO: namespace: e2e-tests-namespaces-hmqgq, resource: bindings, ignored listing per whitelist
Aug  2 10:24:56.292: INFO: namespace e2e-tests-namespaces-hmqgq deletion completed in 6.157568783s
STEP: Destroying namespace "e2e-tests-nsdeletetest-5gdcw" for this suite.
Aug  2 10:24:56.294: INFO: Namespace e2e-tests-nsdeletetest-5gdcw was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-48w2q" for this suite.
Aug  2 10:25:02.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:25:02.425: INFO: namespace: e2e-tests-nsdeletetest-48w2q, resource: bindings, ignored listing per whitelist
Aug  2 10:25:02.437: INFO: namespace e2e-tests-nsdeletetest-48w2q deletion completed in 6.142244679s

• [SLOW TEST:19.284 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:25:02.439: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-rc2wd
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-rc2wd
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-rc2wd
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-rc2wd
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-rc2wd
Aug  2 10:25:06.613: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-rc2wd, name: ss-0, uid: ca639737-b50f-11e9-9105-fa163e46117c, status phase: Pending. Waiting for statefulset controller to delete.
Aug  2 10:25:12.161: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-rc2wd, name: ss-0, uid: ca639737-b50f-11e9-9105-fa163e46117c, status phase: Failed. Waiting for statefulset controller to delete.
Aug  2 10:25:12.166: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-rc2wd, name: ss-0, uid: ca639737-b50f-11e9-9105-fa163e46117c, status phase: Failed. Waiting for statefulset controller to delete.
Aug  2 10:25:12.170: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-rc2wd
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-rc2wd
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-rc2wd and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Aug  2 10:25:16.230: INFO: Deleting all statefulset in ns e2e-tests-statefulset-rc2wd
Aug  2 10:25:16.235: INFO: Scaling statefulset ss to 0
Aug  2 10:25:26.261: INFO: Waiting for statefulset status.replicas updated to 0
Aug  2 10:25:26.263: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:25:26.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-rc2wd" for this suite.
Aug  2 10:25:32.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:25:32.469: INFO: namespace: e2e-tests-statefulset-rc2wd, resource: bindings, ignored listing per whitelist
Aug  2 10:25:32.488: INFO: namespace e2e-tests-statefulset-rc2wd deletion completed in 6.205931657s

• [SLOW TEST:30.049 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:25:32.488: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-sbp6
STEP: Creating a pod to test atomic-volume-subpath
Aug  2 10:25:32.652: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-sbp6" in namespace "e2e-tests-subpath-ljtcf" to be "success or failure"
Aug  2 10:25:32.662: INFO: Pod "pod-subpath-test-secret-sbp6": Phase="Pending", Reason="", readiness=false. Elapsed: 9.715695ms
Aug  2 10:25:34.666: INFO: Pod "pod-subpath-test-secret-sbp6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013335626s
Aug  2 10:25:36.718: INFO: Pod "pod-subpath-test-secret-sbp6": Phase="Running", Reason="", readiness=false. Elapsed: 4.066096439s
Aug  2 10:25:38.722: INFO: Pod "pod-subpath-test-secret-sbp6": Phase="Running", Reason="", readiness=false. Elapsed: 6.069618663s
Aug  2 10:25:40.726: INFO: Pod "pod-subpath-test-secret-sbp6": Phase="Running", Reason="", readiness=false. Elapsed: 8.073290221s
Aug  2 10:25:42.729: INFO: Pod "pod-subpath-test-secret-sbp6": Phase="Running", Reason="", readiness=false. Elapsed: 10.076610829s
Aug  2 10:25:44.733: INFO: Pod "pod-subpath-test-secret-sbp6": Phase="Running", Reason="", readiness=false. Elapsed: 12.080120991s
Aug  2 10:25:46.736: INFO: Pod "pod-subpath-test-secret-sbp6": Phase="Running", Reason="", readiness=false. Elapsed: 14.083732342s
Aug  2 10:25:48.739: INFO: Pod "pod-subpath-test-secret-sbp6": Phase="Running", Reason="", readiness=false. Elapsed: 16.086920796s
Aug  2 10:25:50.743: INFO: Pod "pod-subpath-test-secret-sbp6": Phase="Running", Reason="", readiness=false. Elapsed: 18.090313373s
Aug  2 10:25:52.746: INFO: Pod "pod-subpath-test-secret-sbp6": Phase="Running", Reason="", readiness=false. Elapsed: 20.093494584s
Aug  2 10:25:54.750: INFO: Pod "pod-subpath-test-secret-sbp6": Phase="Running", Reason="", readiness=false. Elapsed: 22.097285086s
Aug  2 10:25:56.753: INFO: Pod "pod-subpath-test-secret-sbp6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.100889996s
STEP: Saw pod success
Aug  2 10:25:56.753: INFO: Pod "pod-subpath-test-secret-sbp6" satisfied condition "success or failure"
Aug  2 10:25:56.756: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-subpath-test-secret-sbp6 container test-container-subpath-secret-sbp6: <nil>
STEP: delete the pod
Aug  2 10:25:56.889: INFO: Waiting for pod pod-subpath-test-secret-sbp6 to disappear
Aug  2 10:25:56.893: INFO: Pod pod-subpath-test-secret-sbp6 no longer exists
STEP: Deleting pod pod-subpath-test-secret-sbp6
Aug  2 10:25:56.893: INFO: Deleting pod "pod-subpath-test-secret-sbp6" in namespace "e2e-tests-subpath-ljtcf"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:25:56.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-ljtcf" for this suite.
Aug  2 10:26:03.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:26:03.116: INFO: namespace: e2e-tests-subpath-ljtcf, resource: bindings, ignored listing per whitelist
Aug  2 10:26:03.156: INFO: namespace e2e-tests-subpath-ljtcf deletion completed in 6.257755451s

• [SLOW TEST:30.667 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:26:03.157: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Aug  2 10:26:03.263: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-6b55x,SelfLink:/api/v1/namespaces/e2e-tests-watch-6b55x/configmaps/e2e-watch-test-configmap-a,UID:edf13a4c-b50f-11e9-9105-fa163e46117c,ResourceVersion:10723,Generation:0,CreationTimestamp:2019-08-02 10:26:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug  2 10:26:03.263: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-6b55x,SelfLink:/api/v1/namespaces/e2e-tests-watch-6b55x/configmaps/e2e-watch-test-configmap-a,UID:edf13a4c-b50f-11e9-9105-fa163e46117c,ResourceVersion:10723,Generation:0,CreationTimestamp:2019-08-02 10:26:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Aug  2 10:26:13.273: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-6b55x,SelfLink:/api/v1/namespaces/e2e-tests-watch-6b55x/configmaps/e2e-watch-test-configmap-a,UID:edf13a4c-b50f-11e9-9105-fa163e46117c,ResourceVersion:10742,Generation:0,CreationTimestamp:2019-08-02 10:26:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Aug  2 10:26:13.273: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-6b55x,SelfLink:/api/v1/namespaces/e2e-tests-watch-6b55x/configmaps/e2e-watch-test-configmap-a,UID:edf13a4c-b50f-11e9-9105-fa163e46117c,ResourceVersion:10742,Generation:0,CreationTimestamp:2019-08-02 10:26:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Aug  2 10:26:23.281: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-6b55x,SelfLink:/api/v1/namespaces/e2e-tests-watch-6b55x/configmaps/e2e-watch-test-configmap-a,UID:edf13a4c-b50f-11e9-9105-fa163e46117c,ResourceVersion:10761,Generation:0,CreationTimestamp:2019-08-02 10:26:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug  2 10:26:23.281: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-6b55x,SelfLink:/api/v1/namespaces/e2e-tests-watch-6b55x/configmaps/e2e-watch-test-configmap-a,UID:edf13a4c-b50f-11e9-9105-fa163e46117c,ResourceVersion:10761,Generation:0,CreationTimestamp:2019-08-02 10:26:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Aug  2 10:26:33.288: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-6b55x,SelfLink:/api/v1/namespaces/e2e-tests-watch-6b55x/configmaps/e2e-watch-test-configmap-a,UID:edf13a4c-b50f-11e9-9105-fa163e46117c,ResourceVersion:10780,Generation:0,CreationTimestamp:2019-08-02 10:26:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug  2 10:26:33.288: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-6b55x,SelfLink:/api/v1/namespaces/e2e-tests-watch-6b55x/configmaps/e2e-watch-test-configmap-a,UID:edf13a4c-b50f-11e9-9105-fa163e46117c,ResourceVersion:10780,Generation:0,CreationTimestamp:2019-08-02 10:26:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Aug  2 10:26:43.296: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-6b55x,SelfLink:/api/v1/namespaces/e2e-tests-watch-6b55x/configmaps/e2e-watch-test-configmap-b,UID:05cd6736-b510-11e9-9105-fa163e46117c,ResourceVersion:10800,Generation:0,CreationTimestamp:2019-08-02 10:26:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug  2 10:26:43.296: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-6b55x,SelfLink:/api/v1/namespaces/e2e-tests-watch-6b55x/configmaps/e2e-watch-test-configmap-b,UID:05cd6736-b510-11e9-9105-fa163e46117c,ResourceVersion:10800,Generation:0,CreationTimestamp:2019-08-02 10:26:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Aug  2 10:26:53.304: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-6b55x,SelfLink:/api/v1/namespaces/e2e-tests-watch-6b55x/configmaps/e2e-watch-test-configmap-b,UID:05cd6736-b510-11e9-9105-fa163e46117c,ResourceVersion:10820,Generation:0,CreationTimestamp:2019-08-02 10:26:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug  2 10:26:53.304: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-6b55x,SelfLink:/api/v1/namespaces/e2e-tests-watch-6b55x/configmaps/e2e-watch-test-configmap-b,UID:05cd6736-b510-11e9-9105-fa163e46117c,ResourceVersion:10820,Generation:0,CreationTimestamp:2019-08-02 10:26:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:27:03.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-6b55x" for this suite.
Aug  2 10:27:09.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:27:09.436: INFO: namespace: e2e-tests-watch-6b55x, resource: bindings, ignored listing per whitelist
Aug  2 10:27:09.537: INFO: namespace e2e-tests-watch-6b55x deletion completed in 6.180888607s

• [SLOW TEST:66.380 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:27:09.538: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-qtq6
STEP: Creating a pod to test atomic-volume-subpath
Aug  2 10:27:09.738: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-qtq6" in namespace "e2e-tests-subpath-54544" to be "success or failure"
Aug  2 10:27:09.745: INFO: Pod "pod-subpath-test-projected-qtq6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.774632ms
Aug  2 10:27:11.750: INFO: Pod "pod-subpath-test-projected-qtq6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011798168s
Aug  2 10:27:13.754: INFO: Pod "pod-subpath-test-projected-qtq6": Phase="Running", Reason="", readiness=false. Elapsed: 4.015556234s
Aug  2 10:27:15.757: INFO: Pod "pod-subpath-test-projected-qtq6": Phase="Running", Reason="", readiness=false. Elapsed: 6.019191111s
Aug  2 10:27:17.761: INFO: Pod "pod-subpath-test-projected-qtq6": Phase="Running", Reason="", readiness=false. Elapsed: 8.023097533s
Aug  2 10:27:19.764: INFO: Pod "pod-subpath-test-projected-qtq6": Phase="Running", Reason="", readiness=false. Elapsed: 10.026143227s
Aug  2 10:27:21.767: INFO: Pod "pod-subpath-test-projected-qtq6": Phase="Running", Reason="", readiness=false. Elapsed: 12.029135113s
Aug  2 10:27:23.772: INFO: Pod "pod-subpath-test-projected-qtq6": Phase="Running", Reason="", readiness=false. Elapsed: 14.03331102s
Aug  2 10:27:25.775: INFO: Pod "pod-subpath-test-projected-qtq6": Phase="Running", Reason="", readiness=false. Elapsed: 16.036995947s
Aug  2 10:27:27.792: INFO: Pod "pod-subpath-test-projected-qtq6": Phase="Running", Reason="", readiness=false. Elapsed: 18.053309133s
Aug  2 10:27:29.795: INFO: Pod "pod-subpath-test-projected-qtq6": Phase="Running", Reason="", readiness=false. Elapsed: 20.057042004s
Aug  2 10:27:31.799: INFO: Pod "pod-subpath-test-projected-qtq6": Phase="Running", Reason="", readiness=false. Elapsed: 22.060401721s
Aug  2 10:27:33.803: INFO: Pod "pod-subpath-test-projected-qtq6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.064574003s
STEP: Saw pod success
Aug  2 10:27:33.803: INFO: Pod "pod-subpath-test-projected-qtq6" satisfied condition "success or failure"
Aug  2 10:27:33.807: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-subpath-test-projected-qtq6 container test-container-subpath-projected-qtq6: <nil>
STEP: delete the pod
Aug  2 10:27:33.857: INFO: Waiting for pod pod-subpath-test-projected-qtq6 to disappear
Aug  2 10:27:33.860: INFO: Pod pod-subpath-test-projected-qtq6 no longer exists
STEP: Deleting pod pod-subpath-test-projected-qtq6
Aug  2 10:27:33.860: INFO: Deleting pod "pod-subpath-test-projected-qtq6" in namespace "e2e-tests-subpath-54544"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:27:33.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-54544" for this suite.
Aug  2 10:27:39.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:27:39.952: INFO: namespace: e2e-tests-subpath-54544, resource: bindings, ignored listing per whitelist
Aug  2 10:27:40.006: INFO: namespace e2e-tests-subpath-54544 deletion completed in 6.139144432s

• [SLOW TEST:30.468 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:27:40.007: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-vz5zw/secret-test-27ab72ac-b510-11e9-b8f5-0a4acaace53e
STEP: Creating a pod to test consume secrets
Aug  2 10:27:40.126: INFO: Waiting up to 5m0s for pod "pod-configmaps-27ac24bd-b510-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-secrets-vz5zw" to be "success or failure"
Aug  2 10:27:40.134: INFO: Pod "pod-configmaps-27ac24bd-b510-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 7.500989ms
Aug  2 10:27:42.137: INFO: Pod "pod-configmaps-27ac24bd-b510-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011026968s
Aug  2 10:27:44.143: INFO: Pod "pod-configmaps-27ac24bd-b510-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017315913s
Aug  2 10:27:46.147: INFO: Pod "pod-configmaps-27ac24bd-b510-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.020976404s
STEP: Saw pod success
Aug  2 10:27:46.147: INFO: Pod "pod-configmaps-27ac24bd-b510-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 10:27:46.150: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-configmaps-27ac24bd-b510-11e9-b8f5-0a4acaace53e container env-test: <nil>
STEP: delete the pod
Aug  2 10:27:46.174: INFO: Waiting for pod pod-configmaps-27ac24bd-b510-11e9-b8f5-0a4acaace53e to disappear
Aug  2 10:27:46.186: INFO: Pod pod-configmaps-27ac24bd-b510-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:27:46.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-vz5zw" for this suite.
Aug  2 10:27:52.199: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:27:52.231: INFO: namespace: e2e-tests-secrets-vz5zw, resource: bindings, ignored listing per whitelist
Aug  2 10:27:52.314: INFO: namespace e2e-tests-secrets-vz5zw deletion completed in 6.124620447s

• [SLOW TEST:12.307 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:27:52.317: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug  2 10:27:52.392: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2efbbead-b510-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-projected-jft4j" to be "success or failure"
Aug  2 10:27:52.397: INFO: Pod "downwardapi-volume-2efbbead-b510-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.522462ms
Aug  2 10:27:54.402: INFO: Pod "downwardapi-volume-2efbbead-b510-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009887135s
Aug  2 10:27:56.406: INFO: Pod "downwardapi-volume-2efbbead-b510-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014756643s
STEP: Saw pod success
Aug  2 10:27:56.407: INFO: Pod "downwardapi-volume-2efbbead-b510-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 10:27:56.409: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod downwardapi-volume-2efbbead-b510-11e9-b8f5-0a4acaace53e container client-container: <nil>
STEP: delete the pod
Aug  2 10:27:56.432: INFO: Waiting for pod downwardapi-volume-2efbbead-b510-11e9-b8f5-0a4acaace53e to disappear
Aug  2 10:27:56.438: INFO: Pod downwardapi-volume-2efbbead-b510-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:27:56.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jft4j" for this suite.
Aug  2 10:28:02.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:28:02.524: INFO: namespace: e2e-tests-projected-jft4j, resource: bindings, ignored listing per whitelist
Aug  2 10:28:02.573: INFO: namespace e2e-tests-projected-jft4j deletion completed in 6.132649722s

• [SLOW TEST:10.257 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:28:02.574: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug  2 10:28:02.704: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:28:08.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-8k96z" for this suite.
Aug  2 10:28:54.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:28:54.873: INFO: namespace: e2e-tests-pods-8k96z, resource: bindings, ignored listing per whitelist
Aug  2 10:28:54.905: INFO: namespace e2e-tests-pods-8k96z deletion completed in 46.139985446s

• [SLOW TEST:52.332 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:28:54.907: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug  2 10:28:55.059: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-bfgrk'
Aug  2 10:28:55.947: INFO: stderr: ""
Aug  2 10:28:55.947: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Aug  2 10:29:00.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-bfgrk -o json'
Aug  2 10:29:01.108: INFO: stderr: ""
Aug  2 10:29:01.108: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-08-02T10:28:55Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-bfgrk\",\n        \"resourceVersion\": \"11179\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-bfgrk/pods/e2e-test-nginx-pod\",\n        \"uid\": \"54dc23bf-b510-11e9-9105-fa163e46117c\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-lbb7q\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"test-v1-13-7-gipwxthqfdpj-minion-0\",\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-lbb7q\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-lbb7q\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-02T10:28:55Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-02T10:28:57Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-02T10:28:57Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-02T10:28:55Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://7769828a6ce16f7acc27e63644bff715b56656bbb97d9f77c784454ace3d936d\",\n                \"image\": \"docker.io/nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-08-02T10:28:57Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.0.0.11\",\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.232.58\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-08-02T10:28:55Z\"\n    }\n}\n"
STEP: replace the image in the pod
Aug  2 10:29:01.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 replace -f - --namespace=e2e-tests-kubectl-bfgrk'
Aug  2 10:29:01.401: INFO: stderr: ""
Aug  2 10:29:01.401: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Aug  2 10:29:01.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-bfgrk'
Aug  2 10:29:03.701: INFO: stderr: ""
Aug  2 10:29:03.701: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:29:03.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bfgrk" for this suite.
Aug  2 10:29:09.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:29:09.846: INFO: namespace: e2e-tests-kubectl-bfgrk, resource: bindings, ignored listing per whitelist
Aug  2 10:29:09.846: INFO: namespace e2e-tests-kubectl-bfgrk deletion completed in 6.140970767s

• [SLOW TEST:14.940 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:29:09.848: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-5d325918-b510-11e9-b8f5-0a4acaace53e
STEP: Creating a pod to test consume configMaps
Aug  2 10:29:09.929: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5d32e51f-b510-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-projected-vj2dq" to be "success or failure"
Aug  2 10:29:09.934: INFO: Pod "pod-projected-configmaps-5d32e51f-b510-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.407607ms
Aug  2 10:29:11.938: INFO: Pod "pod-projected-configmaps-5d32e51f-b510-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009206675s
Aug  2 10:29:13.942: INFO: Pod "pod-projected-configmaps-5d32e51f-b510-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012745548s
STEP: Saw pod success
Aug  2 10:29:13.942: INFO: Pod "pod-projected-configmaps-5d32e51f-b510-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 10:29:13.944: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-projected-configmaps-5d32e51f-b510-11e9-b8f5-0a4acaace53e container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug  2 10:29:13.967: INFO: Waiting for pod pod-projected-configmaps-5d32e51f-b510-11e9-b8f5-0a4acaace53e to disappear
Aug  2 10:29:13.971: INFO: Pod pod-projected-configmaps-5d32e51f-b510-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:29:13.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vj2dq" for this suite.
Aug  2 10:29:19.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:29:20.060: INFO: namespace: e2e-tests-projected-vj2dq, resource: bindings, ignored listing per whitelist
Aug  2 10:29:20.092: INFO: namespace e2e-tests-projected-vj2dq deletion completed in 6.117889995s

• [SLOW TEST:10.244 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:29:20.094: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug  2 10:29:20.186: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:29:20.198: INFO: Number of nodes with available pods: 0
Aug  2 10:29:20.198: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:29:21.202: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:29:21.204: INFO: Number of nodes with available pods: 0
Aug  2 10:29:21.204: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:29:22.237: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:29:22.240: INFO: Number of nodes with available pods: 0
Aug  2 10:29:22.240: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:29:23.204: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:29:23.206: INFO: Number of nodes with available pods: 1
Aug  2 10:29:23.206: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Aug  2 10:29:23.353: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:29:23.360: INFO: Number of nodes with available pods: 0
Aug  2 10:29:23.360: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:29:24.661: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:29:24.664: INFO: Number of nodes with available pods: 0
Aug  2 10:29:24.664: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:29:25.364: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:29:25.367: INFO: Number of nodes with available pods: 0
Aug  2 10:29:25.367: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:29:26.364: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:29:26.366: INFO: Number of nodes with available pods: 1
Aug  2 10:29:26.366: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-tcjhr, will wait for the garbage collector to delete the pods
Aug  2 10:29:26.433: INFO: Deleting DaemonSet.extensions daemon-set took: 8.47728ms
Aug  2 10:29:26.533: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.516957ms
Aug  2 10:30:00.738: INFO: Number of nodes with available pods: 0
Aug  2 10:30:00.738: INFO: Number of running nodes: 0, number of available pods: 0
Aug  2 10:30:00.742: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-tcjhr/daemonsets","resourceVersion":"11385"},"items":null}

Aug  2 10:30:00.744: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-tcjhr/pods","resourceVersion":"11385"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:30:00.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-tcjhr" for this suite.
Aug  2 10:30:06.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:30:06.899: INFO: namespace: e2e-tests-daemonsets-tcjhr, resource: bindings, ignored listing per whitelist
Aug  2 10:30:06.952: INFO: namespace e2e-tests-daemonsets-tcjhr deletion completed in 6.197484674s

• [SLOW TEST:46.859 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:30:06.953: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug  2 10:30:07.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-74z98'
Aug  2 10:30:07.190: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug  2 10:30:07.190: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Aug  2 10:30:07.207: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Aug  2 10:30:07.216: INFO: scanned /root for discovery docs: <nil>
Aug  2 10:30:07.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-74z98'
Aug  2 10:30:23.019: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Aug  2 10:30:23.019: INFO: stdout: "Created e2e-test-nginx-rc-78c8150978394d818c0a2810d8d32695\nScaling up e2e-test-nginx-rc-78c8150978394d818c0a2810d8d32695 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-78c8150978394d818c0a2810d8d32695 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-78c8150978394d818c0a2810d8d32695 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Aug  2 10:30:23.019: INFO: stdout: "Created e2e-test-nginx-rc-78c8150978394d818c0a2810d8d32695\nScaling up e2e-test-nginx-rc-78c8150978394d818c0a2810d8d32695 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-78c8150978394d818c0a2810d8d32695 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-78c8150978394d818c0a2810d8d32695 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Aug  2 10:30:23.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-74z98'
Aug  2 10:30:23.159: INFO: stderr: ""
Aug  2 10:30:23.159: INFO: stdout: "e2e-test-nginx-rc-78c8150978394d818c0a2810d8d32695-524wn "
Aug  2 10:30:23.159: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods e2e-test-nginx-rc-78c8150978394d818c0a2810d8d32695-524wn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-74z98'
Aug  2 10:30:23.267: INFO: stderr: ""
Aug  2 10:30:23.267: INFO: stdout: "true"
Aug  2 10:30:23.267: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods e2e-test-nginx-rc-78c8150978394d818c0a2810d8d32695-524wn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-74z98'
Aug  2 10:30:23.387: INFO: stderr: ""
Aug  2 10:30:23.387: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Aug  2 10:30:23.387: INFO: e2e-test-nginx-rc-78c8150978394d818c0a2810d8d32695-524wn is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Aug  2 10:30:23.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-74z98'
Aug  2 10:30:23.499: INFO: stderr: ""
Aug  2 10:30:23.499: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:30:23.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-74z98" for this suite.
Aug  2 10:30:29.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:30:29.697: INFO: namespace: e2e-tests-kubectl-74z98, resource: bindings, ignored listing per whitelist
Aug  2 10:30:29.705: INFO: namespace e2e-tests-kubectl-74z98 deletion completed in 6.202992324s

• [SLOW TEST:22.752 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:30:29.706: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Aug  2 10:30:29.890: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-fj2cr,SelfLink:/api/v1/namespaces/e2e-tests-watch-fj2cr/configmaps/e2e-watch-test-resource-version,UID:8ccc84c4-b510-11e9-9105-fa163e46117c,ResourceVersion:11550,Generation:0,CreationTimestamp:2019-08-02 10:30:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug  2 10:30:29.890: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-fj2cr,SelfLink:/api/v1/namespaces/e2e-tests-watch-fj2cr/configmaps/e2e-watch-test-resource-version,UID:8ccc84c4-b510-11e9-9105-fa163e46117c,ResourceVersion:11551,Generation:0,CreationTimestamp:2019-08-02 10:30:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:30:29.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-fj2cr" for this suite.
Aug  2 10:30:35.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:30:35.980: INFO: namespace: e2e-tests-watch-fj2cr, resource: bindings, ignored listing per whitelist
Aug  2 10:30:36.043: INFO: namespace e2e-tests-watch-fj2cr deletion completed in 6.150473293s

• [SLOW TEST:6.336 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:30:36.043: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-90fd0f1c-b510-11e9-b8f5-0a4acaace53e
STEP: Creating a pod to test consume configMaps
Aug  2 10:30:36.824: INFO: Waiting up to 5m0s for pod "pod-configmaps-90fdda12-b510-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-configmap-8fkdb" to be "success or failure"
Aug  2 10:30:36.831: INFO: Pod "pod-configmaps-90fdda12-b510-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.524566ms
Aug  2 10:30:38.835: INFO: Pod "pod-configmaps-90fdda12-b510-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010319471s
Aug  2 10:30:40.838: INFO: Pod "pod-configmaps-90fdda12-b510-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013802525s
STEP: Saw pod success
Aug  2 10:30:40.838: INFO: Pod "pod-configmaps-90fdda12-b510-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 10:30:40.840: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-configmaps-90fdda12-b510-11e9-b8f5-0a4acaace53e container configmap-volume-test: <nil>
STEP: delete the pod
Aug  2 10:30:40.861: INFO: Waiting for pod pod-configmaps-90fdda12-b510-11e9-b8f5-0a4acaace53e to disappear
Aug  2 10:30:40.864: INFO: Pod pod-configmaps-90fdda12-b510-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:30:40.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-8fkdb" for this suite.
Aug  2 10:30:46.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:30:46.969: INFO: namespace: e2e-tests-configmap-8fkdb, resource: bindings, ignored listing per whitelist
Aug  2 10:30:47.016: INFO: namespace e2e-tests-configmap-8fkdb deletion completed in 6.147104807s

• [SLOW TEST:10.973 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:30:47.019: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug  2 10:30:47.136: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-cjhqr'
Aug  2 10:30:47.264: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug  2 10:30:47.264: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Aug  2 10:30:47.273: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-cjhqr'
Aug  2 10:30:47.384: INFO: stderr: ""
Aug  2 10:30:47.385: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:30:47.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-cjhqr" for this suite.
Aug  2 10:30:53.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:30:53.487: INFO: namespace: e2e-tests-kubectl-cjhqr, resource: bindings, ignored listing per whitelist
Aug  2 10:30:53.502: INFO: namespace e2e-tests-kubectl-cjhqr deletion completed in 6.114290472s

• [SLOW TEST:6.483 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:30:53.503: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Aug  2 10:30:55.948: INFO: Pod pod-hostip-9afb4200-b510-11e9-b8f5-0a4acaace53e has hostIP: 10.0.0.11
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:30:55.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-xl4kr" for this suite.
Aug  2 10:31:17.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:31:18.028: INFO: namespace: e2e-tests-pods-xl4kr, resource: bindings, ignored listing per whitelist
Aug  2 10:31:18.071: INFO: namespace e2e-tests-pods-xl4kr deletion completed in 22.120446165s

• [SLOW TEST:24.568 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:31:18.071: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Aug  2 10:31:18.155: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-983173982 proxy --unix-socket=/tmp/kubectl-proxy-unix002530597/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:31:18.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-h9bqw" for this suite.
Aug  2 10:31:24.280: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:31:24.357: INFO: namespace: e2e-tests-kubectl-h9bqw, resource: bindings, ignored listing per whitelist
Aug  2 10:31:24.383: INFO: namespace e2e-tests-kubectl-h9bqw deletion completed in 6.115695338s

• [SLOW TEST:6.312 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:31:24.384: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-ad7702e2-b510-11e9-b8f5-0a4acaace53e
STEP: Creating a pod to test consume configMaps
Aug  2 10:31:24.601: INFO: Waiting up to 5m0s for pod "pod-configmaps-ad77db09-b510-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-configmap-8w7sf" to be "success or failure"
Aug  2 10:31:24.630: INFO: Pod "pod-configmaps-ad77db09-b510-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 29.551287ms
Aug  2 10:31:26.635: INFO: Pod "pod-configmaps-ad77db09-b510-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033790615s
Aug  2 10:31:28.637: INFO: Pod "pod-configmaps-ad77db09-b510-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036658734s
STEP: Saw pod success
Aug  2 10:31:28.637: INFO: Pod "pod-configmaps-ad77db09-b510-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 10:31:28.639: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-configmaps-ad77db09-b510-11e9-b8f5-0a4acaace53e container configmap-volume-test: <nil>
STEP: delete the pod
Aug  2 10:31:28.664: INFO: Waiting for pod pod-configmaps-ad77db09-b510-11e9-b8f5-0a4acaace53e to disappear
Aug  2 10:31:28.672: INFO: Pod pod-configmaps-ad77db09-b510-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:31:28.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-8w7sf" for this suite.
Aug  2 10:31:34.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:31:34.731: INFO: namespace: e2e-tests-configmap-8w7sf, resource: bindings, ignored listing per whitelist
Aug  2 10:31:34.798: INFO: namespace e2e-tests-configmap-8w7sf deletion completed in 6.116728381s

• [SLOW TEST:10.414 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:31:34.799: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug  2 10:31:34.934: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Aug  2 10:31:34.940: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-qwcnk/daemonsets","resourceVersion":"11788"},"items":null}

Aug  2 10:31:34.943: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-qwcnk/pods","resourceVersion":"11788"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:31:34.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-qwcnk" for this suite.
Aug  2 10:31:40.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:31:40.985: INFO: namespace: e2e-tests-daemonsets-qwcnk, resource: bindings, ignored listing per whitelist
Aug  2 10:31:41.066: INFO: namespace e2e-tests-daemonsets-qwcnk deletion completed in 6.115079043s

S [SKIPPING] [6.267 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Aug  2 10:31:34.934: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:31:41.067: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:31:45.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-dp7r7" for this suite.
Aug  2 10:31:51.199: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:31:51.321: INFO: namespace: e2e-tests-emptydir-wrapper-dp7r7, resource: bindings, ignored listing per whitelist
Aug  2 10:31:51.339: INFO: namespace e2e-tests-emptydir-wrapper-dp7r7 deletion completed in 6.150347554s

• [SLOW TEST:10.272 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:31:51.340: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Aug  2 10:31:51.414: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:31:55.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-bkkc2" for this suite.
Aug  2 10:32:01.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:32:01.932: INFO: namespace: e2e-tests-init-container-bkkc2, resource: bindings, ignored listing per whitelist
Aug  2 10:32:01.998: INFO: namespace e2e-tests-init-container-bkkc2 deletion completed in 6.127981898s

• [SLOW TEST:10.659 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:32:02.001: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Aug  2 10:32:02.544: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug  2 10:32:02.551: INFO: Waiting for terminating namespaces to be deleted...
Aug  2 10:32:02.555: INFO: 
Logging pods the kubelet thinks is on node test-v1-13-7-gipwxthqfdpj-minion-0 before test
Aug  2 10:32:02.565: INFO: sonobuoy-e2e-job-3e746bac374b400e from heptio-sonobuoy started at 2019-08-02 10:04:24 +0000 UTC (2 container statuses recorded)
Aug  2 10:32:02.565: INFO: 	Container e2e ready: true, restart count 0
Aug  2 10:32:02.565: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug  2 10:32:02.565: INFO: kube-dns-autoscaler-7745486984-65d84 from kube-system started at 2019-08-02 09:12:12 +0000 UTC (1 container statuses recorded)
Aug  2 10:32:02.565: INFO: 	Container autoscaler ready: true, restart count 0
Aug  2 10:32:02.565: INFO: coredns-d9c54b456-4j4d9 from kube-system started at 2019-08-02 09:13:00 +0000 UTC (1 container statuses recorded)
Aug  2 10:32:02.565: INFO: 	Container coredns ready: true, restart count 0
Aug  2 10:32:02.565: INFO: calico-kube-controllers-7fbc9d65bb-nzhzn from kube-system started at 2019-08-02 09:12:12 +0000 UTC (1 container statuses recorded)
Aug  2 10:32:02.565: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Aug  2 10:32:02.565: INFO: npd-7m9j6 from kube-system started at 2019-08-02 09:12:12 +0000 UTC (1 container statuses recorded)
Aug  2 10:32:02.565: INFO: 	Container node-problem-detector ready: true, restart count 0
Aug  2 10:32:02.565: INFO: calico-node-m4lm9 from kube-system started at 2019-08-02 09:11:32 +0000 UTC (2 container statuses recorded)
Aug  2 10:32:02.565: INFO: 	Container calico-node ready: true, restart count 0
Aug  2 10:32:02.565: INFO: 	Container install-cni ready: true, restart count 0
Aug  2 10:32:02.565: INFO: kubernetes-dashboard-76894767d-7xvg4 from kube-system started at 2019-08-02 09:12:12 +0000 UTC (1 container statuses recorded)
Aug  2 10:32:02.565: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Aug  2 10:32:02.565: INFO: sonobuoy from heptio-sonobuoy started at 2019-08-02 10:04:09 +0000 UTC (1 container statuses recorded)
Aug  2 10:32:02.565: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug  2 10:32:02.565: INFO: sonobuoy-systemd-logs-daemon-set-a44350f5542845ed-2k4ng from heptio-sonobuoy started at 2019-08-02 10:04:24 +0000 UTC (2 container statuses recorded)
Aug  2 10:32:02.565: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Aug  2 10:32:02.565: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug  2 10:32:02.565: INFO: heapster-9d5d7fffd-6gk8p from kube-system started at 2019-08-02 09:12:12 +0000 UTC (1 container statuses recorded)
Aug  2 10:32:02.565: INFO: 	Container heapster ready: true, restart count 0
Aug  2 10:32:02.565: INFO: coredns-d9c54b456-2shsm from kube-system started at 2019-08-02 09:12:12 +0000 UTC (1 container statuses recorded)
Aug  2 10:32:02.565: INFO: 	Container coredns ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-c68131d2-b510-11e9-b8f5-0a4acaace53e 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-c68131d2-b510-11e9-b8f5-0a4acaace53e off the node test-v1-13-7-gipwxthqfdpj-minion-0
STEP: verifying the node doesn't have the label kubernetes.io/e2e-c68131d2-b510-11e9-b8f5-0a4acaace53e
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:32:16.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-sx5gf" for this suite.
Aug  2 10:32:24.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:32:24.728: INFO: namespace: e2e-tests-sched-pred-sx5gf, resource: bindings, ignored listing per whitelist
Aug  2 10:32:24.811: INFO: namespace e2e-tests-sched-pred-sx5gf deletion completed in 8.159052885s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:22.811 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:32:24.812: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Aug  2 10:32:24.903: INFO: Waiting up to 5m0s for pod "pod-d169786a-b510-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-emptydir-ftqjh" to be "success or failure"
Aug  2 10:32:24.908: INFO: Pod "pod-d169786a-b510-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.45357ms
Aug  2 10:32:26.912: INFO: Pod "pod-d169786a-b510-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008802263s
Aug  2 10:32:28.915: INFO: Pod "pod-d169786a-b510-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012279973s
STEP: Saw pod success
Aug  2 10:32:28.915: INFO: Pod "pod-d169786a-b510-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 10:32:28.917: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-d169786a-b510-11e9-b8f5-0a4acaace53e container test-container: <nil>
STEP: delete the pod
Aug  2 10:32:28.939: INFO: Waiting for pod pod-d169786a-b510-11e9-b8f5-0a4acaace53e to disappear
Aug  2 10:32:28.951: INFO: Pod pod-d169786a-b510-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:32:28.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-ftqjh" for this suite.
Aug  2 10:32:34.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:32:35.061: INFO: namespace: e2e-tests-emptydir-ftqjh, resource: bindings, ignored listing per whitelist
Aug  2 10:32:35.083: INFO: namespace e2e-tests-emptydir-ftqjh deletion completed in 6.128119097s

• [SLOW TEST:10.272 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:32:35.084: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-7nkz4
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-7nkz4
STEP: Deleting pre-stop pod
Aug  2 10:32:56.206: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:32:56.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-7nkz4" for this suite.
Aug  2 10:33:34.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:33:34.309: INFO: namespace: e2e-tests-prestop-7nkz4, resource: bindings, ignored listing per whitelist
Aug  2 10:33:34.352: INFO: namespace e2e-tests-prestop-7nkz4 deletion completed in 38.134873448s

• [SLOW TEST:59.269 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:33:34.354: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug  2 10:33:34.463: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"fadf3284-b510-11e9-9105-fa163e46117c", Controller:(*bool)(0xc00083f822), BlockOwnerDeletion:(*bool)(0xc00083f823)}}
Aug  2 10:33:34.473: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"fadd5de1-b510-11e9-9105-fa163e46117c", Controller:(*bool)(0xc0009ccb2e), BlockOwnerDeletion:(*bool)(0xc0009ccb2f)}}
Aug  2 10:33:34.484: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"fade9e7e-b510-11e9-9105-fa163e46117c", Controller:(*bool)(0xc00083fde6), BlockOwnerDeletion:(*bool)(0xc00083fde7)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:33:39.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-vtxjh" for this suite.
Aug  2 10:33:45.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:33:45.591: INFO: namespace: e2e-tests-gc-vtxjh, resource: bindings, ignored listing per whitelist
Aug  2 10:33:45.628: INFO: namespace e2e-tests-gc-vtxjh deletion completed in 6.127356645s

• [SLOW TEST:11.275 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:33:45.629: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug  2 10:33:45.715: INFO: Waiting up to 5m0s for pod "downwardapi-volume-01946861-b511-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-downward-api-gdqw6" to be "success or failure"
Aug  2 10:33:45.719: INFO: Pod "downwardapi-volume-01946861-b511-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.798888ms
Aug  2 10:33:47.806: INFO: Pod "downwardapi-volume-01946861-b511-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.091186005s
Aug  2 10:33:49.812: INFO: Pod "downwardapi-volume-01946861-b511-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.096732962s
STEP: Saw pod success
Aug  2 10:33:49.812: INFO: Pod "downwardapi-volume-01946861-b511-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 10:33:49.815: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod downwardapi-volume-01946861-b511-11e9-b8f5-0a4acaace53e container client-container: <nil>
STEP: delete the pod
Aug  2 10:33:49.847: INFO: Waiting for pod downwardapi-volume-01946861-b511-11e9-b8f5-0a4acaace53e to disappear
Aug  2 10:33:49.850: INFO: Pod downwardapi-volume-01946861-b511-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:33:49.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-gdqw6" for this suite.
Aug  2 10:33:55.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:33:55.948: INFO: namespace: e2e-tests-downward-api-gdqw6, resource: bindings, ignored listing per whitelist
Aug  2 10:33:55.996: INFO: namespace e2e-tests-downward-api-gdqw6 deletion completed in 6.143511114s

• [SLOW TEST:10.368 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:33:55.998: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-07c2352d-b511-11e9-b8f5-0a4acaace53e
STEP: Creating a pod to test consume configMaps
Aug  2 10:33:56.084: INFO: Waiting up to 5m0s for pod "pod-configmaps-07c2cb8c-b511-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-configmap-nkp7n" to be "success or failure"
Aug  2 10:33:56.090: INFO: Pod "pod-configmaps-07c2cb8c-b511-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.468826ms
Aug  2 10:33:58.258: INFO: Pod "pod-configmaps-07c2cb8c-b511-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.173989845s
STEP: Saw pod success
Aug  2 10:33:58.258: INFO: Pod "pod-configmaps-07c2cb8c-b511-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 10:33:58.264: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-configmaps-07c2cb8c-b511-11e9-b8f5-0a4acaace53e container configmap-volume-test: <nil>
STEP: delete the pod
Aug  2 10:33:58.354: INFO: Waiting for pod pod-configmaps-07c2cb8c-b511-11e9-b8f5-0a4acaace53e to disappear
Aug  2 10:33:58.366: INFO: Pod pod-configmaps-07c2cb8c-b511-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:33:58.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-nkp7n" for this suite.
Aug  2 10:34:04.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:34:04.472: INFO: namespace: e2e-tests-configmap-nkp7n, resource: bindings, ignored listing per whitelist
Aug  2 10:34:04.515: INFO: namespace e2e-tests-configmap-nkp7n deletion completed in 6.146620843s

• [SLOW TEST:8.518 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:34:04.516: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug  2 10:34:04.610: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0cd7975e-b511-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-projected-6jxzc" to be "success or failure"
Aug  2 10:34:04.619: INFO: Pod "downwardapi-volume-0cd7975e-b511-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.721345ms
Aug  2 10:34:06.622: INFO: Pod "downwardapi-volume-0cd7975e-b511-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012118267s
Aug  2 10:34:08.626: INFO: Pod "downwardapi-volume-0cd7975e-b511-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015840381s
STEP: Saw pod success
Aug  2 10:34:08.626: INFO: Pod "downwardapi-volume-0cd7975e-b511-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 10:34:08.628: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod downwardapi-volume-0cd7975e-b511-11e9-b8f5-0a4acaace53e container client-container: <nil>
STEP: delete the pod
Aug  2 10:34:08.647: INFO: Waiting for pod downwardapi-volume-0cd7975e-b511-11e9-b8f5-0a4acaace53e to disappear
Aug  2 10:34:08.650: INFO: Pod downwardapi-volume-0cd7975e-b511-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:34:08.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6jxzc" for this suite.
Aug  2 10:34:14.666: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:34:14.720: INFO: namespace: e2e-tests-projected-6jxzc, resource: bindings, ignored listing per whitelist
Aug  2 10:34:14.772: INFO: namespace e2e-tests-projected-6jxzc deletion completed in 6.117829647s

• [SLOW TEST:10.256 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:34:14.773: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Aug  2 10:34:14.853: INFO: Waiting up to 5m0s for pod "pod-12f28928-b511-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-emptydir-vggfv" to be "success or failure"
Aug  2 10:34:14.859: INFO: Pod "pod-12f28928-b511-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.986446ms
Aug  2 10:34:16.863: INFO: Pod "pod-12f28928-b511-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010147809s
Aug  2 10:34:18.867: INFO: Pod "pod-12f28928-b511-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.0137332s
Aug  2 10:34:20.871: INFO: Pod "pod-12f28928-b511-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018270648s
STEP: Saw pod success
Aug  2 10:34:20.872: INFO: Pod "pod-12f28928-b511-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 10:34:20.880: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-12f28928-b511-11e9-b8f5-0a4acaace53e container test-container: <nil>
STEP: delete the pod
Aug  2 10:34:20.911: INFO: Waiting for pod pod-12f28928-b511-11e9-b8f5-0a4acaace53e to disappear
Aug  2 10:34:20.917: INFO: Pod pod-12f28928-b511-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:34:20.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-vggfv" for this suite.
Aug  2 10:34:26.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:34:26.978: INFO: namespace: e2e-tests-emptydir-vggfv, resource: bindings, ignored listing per whitelist
Aug  2 10:34:27.062: INFO: namespace e2e-tests-emptydir-vggfv deletion completed in 6.139167611s

• [SLOW TEST:12.289 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:34:27.062: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Aug  2 10:34:27.143: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 create -f - --namespace=e2e-tests-kubectl-6gbnq'
Aug  2 10:34:27.418: INFO: stderr: ""
Aug  2 10:34:27.418: INFO: stdout: "pod/pause created\n"
Aug  2 10:34:27.418: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Aug  2 10:34:27.418: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-6gbnq" to be "running and ready"
Aug  2 10:34:27.430: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 11.732325ms
Aug  2 10:34:29.433: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.015068986s
Aug  2 10:34:29.433: INFO: Pod "pause" satisfied condition "running and ready"
Aug  2 10:34:29.433: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Aug  2 10:34:29.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-6gbnq'
Aug  2 10:34:29.551: INFO: stderr: ""
Aug  2 10:34:29.551: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Aug  2 10:34:29.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pod pause -L testing-label --namespace=e2e-tests-kubectl-6gbnq'
Aug  2 10:34:29.673: INFO: stderr: ""
Aug  2 10:34:29.673: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Aug  2 10:34:29.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 label pods pause testing-label- --namespace=e2e-tests-kubectl-6gbnq'
Aug  2 10:34:29.806: INFO: stderr: ""
Aug  2 10:34:29.806: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Aug  2 10:34:29.806: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pod pause -L testing-label --namespace=e2e-tests-kubectl-6gbnq'
Aug  2 10:34:29.922: INFO: stderr: ""
Aug  2 10:34:29.922: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Aug  2 10:34:29.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-6gbnq'
Aug  2 10:34:30.230: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  2 10:34:30.230: INFO: stdout: "pod \"pause\" force deleted\n"
Aug  2 10:34:30.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-6gbnq'
Aug  2 10:34:30.371: INFO: stderr: "No resources found.\n"
Aug  2 10:34:30.371: INFO: stdout: ""
Aug  2 10:34:30.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods -l name=pause --namespace=e2e-tests-kubectl-6gbnq -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug  2 10:34:30.508: INFO: stderr: ""
Aug  2 10:34:30.508: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:34:30.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6gbnq" for this suite.
Aug  2 10:34:36.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:34:36.591: INFO: namespace: e2e-tests-kubectl-6gbnq, resource: bindings, ignored listing per whitelist
Aug  2 10:34:36.637: INFO: namespace e2e-tests-kubectl-6gbnq deletion completed in 6.126459147s

• [SLOW TEST:9.575 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:34:36.638: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Aug  2 10:34:36.772: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug  2 10:34:36.779: INFO: Waiting for terminating namespaces to be deleted...
Aug  2 10:34:36.785: INFO: 
Logging pods the kubelet thinks is on node test-v1-13-7-gipwxthqfdpj-minion-0 before test
Aug  2 10:34:36.794: INFO: kube-dns-autoscaler-7745486984-65d84 from kube-system started at 2019-08-02 09:12:12 +0000 UTC (1 container statuses recorded)
Aug  2 10:34:36.794: INFO: 	Container autoscaler ready: true, restart count 0
Aug  2 10:34:36.794: INFO: coredns-d9c54b456-4j4d9 from kube-system started at 2019-08-02 09:13:00 +0000 UTC (1 container statuses recorded)
Aug  2 10:34:36.794: INFO: 	Container coredns ready: true, restart count 0
Aug  2 10:34:36.794: INFO: sonobuoy-e2e-job-3e746bac374b400e from heptio-sonobuoy started at 2019-08-02 10:04:24 +0000 UTC (2 container statuses recorded)
Aug  2 10:34:36.794: INFO: 	Container e2e ready: true, restart count 0
Aug  2 10:34:36.794: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug  2 10:34:36.794: INFO: calico-kube-controllers-7fbc9d65bb-nzhzn from kube-system started at 2019-08-02 09:12:12 +0000 UTC (1 container statuses recorded)
Aug  2 10:34:36.794: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Aug  2 10:34:36.794: INFO: npd-7m9j6 from kube-system started at 2019-08-02 09:12:12 +0000 UTC (1 container statuses recorded)
Aug  2 10:34:36.794: INFO: 	Container node-problem-detector ready: true, restart count 0
Aug  2 10:34:36.794: INFO: calico-node-m4lm9 from kube-system started at 2019-08-02 09:11:32 +0000 UTC (2 container statuses recorded)
Aug  2 10:34:36.794: INFO: 	Container calico-node ready: true, restart count 0
Aug  2 10:34:36.794: INFO: 	Container install-cni ready: true, restart count 0
Aug  2 10:34:36.794: INFO: sonobuoy-systemd-logs-daemon-set-a44350f5542845ed-2k4ng from heptio-sonobuoy started at 2019-08-02 10:04:24 +0000 UTC (2 container statuses recorded)
Aug  2 10:34:36.794: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Aug  2 10:34:36.794: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug  2 10:34:36.794: INFO: heapster-9d5d7fffd-6gk8p from kube-system started at 2019-08-02 09:12:12 +0000 UTC (1 container statuses recorded)
Aug  2 10:34:36.794: INFO: 	Container heapster ready: true, restart count 0
Aug  2 10:34:36.794: INFO: coredns-d9c54b456-2shsm from kube-system started at 2019-08-02 09:12:12 +0000 UTC (1 container statuses recorded)
Aug  2 10:34:36.794: INFO: 	Container coredns ready: true, restart count 0
Aug  2 10:34:36.794: INFO: kubernetes-dashboard-76894767d-7xvg4 from kube-system started at 2019-08-02 09:12:12 +0000 UTC (1 container statuses recorded)
Aug  2 10:34:36.794: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Aug  2 10:34:36.794: INFO: sonobuoy from heptio-sonobuoy started at 2019-08-02 10:04:09 +0000 UTC (1 container statuses recorded)
Aug  2 10:34:36.794: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node test-v1-13-7-gipwxthqfdpj-minion-0
Aug  2 10:34:36.820: INFO: Pod sonobuoy requesting resource cpu=0m on Node test-v1-13-7-gipwxthqfdpj-minion-0
Aug  2 10:34:36.820: INFO: Pod sonobuoy-e2e-job-3e746bac374b400e requesting resource cpu=0m on Node test-v1-13-7-gipwxthqfdpj-minion-0
Aug  2 10:34:36.820: INFO: Pod sonobuoy-systemd-logs-daemon-set-a44350f5542845ed-2k4ng requesting resource cpu=0m on Node test-v1-13-7-gipwxthqfdpj-minion-0
Aug  2 10:34:36.820: INFO: Pod calico-kube-controllers-7fbc9d65bb-nzhzn requesting resource cpu=0m on Node test-v1-13-7-gipwxthqfdpj-minion-0
Aug  2 10:34:36.820: INFO: Pod calico-node-m4lm9 requesting resource cpu=250m on Node test-v1-13-7-gipwxthqfdpj-minion-0
Aug  2 10:34:36.820: INFO: Pod coredns-d9c54b456-2shsm requesting resource cpu=0m on Node test-v1-13-7-gipwxthqfdpj-minion-0
Aug  2 10:34:36.820: INFO: Pod coredns-d9c54b456-4j4d9 requesting resource cpu=0m on Node test-v1-13-7-gipwxthqfdpj-minion-0
Aug  2 10:34:36.820: INFO: Pod heapster-9d5d7fffd-6gk8p requesting resource cpu=0m on Node test-v1-13-7-gipwxthqfdpj-minion-0
Aug  2 10:34:36.820: INFO: Pod kube-dns-autoscaler-7745486984-65d84 requesting resource cpu=20m on Node test-v1-13-7-gipwxthqfdpj-minion-0
Aug  2 10:34:36.820: INFO: Pod kubernetes-dashboard-76894767d-7xvg4 requesting resource cpu=0m on Node test-v1-13-7-gipwxthqfdpj-minion-0
Aug  2 10:34:36.820: INFO: Pod npd-7m9j6 requesting resource cpu=20m on Node test-v1-13-7-gipwxthqfdpj-minion-0
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-200b6af4-b511-11e9-b8f5-0a4acaace53e.15b714a0e70908bf], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-jtj92/filler-pod-200b6af4-b511-11e9-b8f5-0a4acaace53e to test-v1-13-7-gipwxthqfdpj-minion-0]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-200b6af4-b511-11e9-b8f5-0a4acaace53e.15b714a1281634d3], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-200b6af4-b511-11e9-b8f5-0a4acaace53e.15b714a12f2ec0af], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-200b6af4-b511-11e9-b8f5-0a4acaace53e.15b714a13571523b], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15b714a15f2f2612], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node test-v1-13-7-gipwxthqfdpj-minion-0
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:34:39.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-jtj92" for this suite.
Aug  2 10:34:45.888: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:34:45.924: INFO: namespace: e2e-tests-sched-pred-jtj92, resource: bindings, ignored listing per whitelist
Aug  2 10:34:46.033: INFO: namespace e2e-tests-sched-pred-jtj92 deletion completed in 6.161173449s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:9.396 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:34:46.035: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Aug  2 10:34:50.712: INFO: Successfully updated pod "pod-update-activedeadlineseconds-259f661d-b511-11e9-b8f5-0a4acaace53e"
Aug  2 10:34:50.712: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-259f661d-b511-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-pods-8p4ft" to be "terminated due to deadline exceeded"
Aug  2 10:34:50.714: INFO: Pod "pod-update-activedeadlineseconds-259f661d-b511-11e9-b8f5-0a4acaace53e": Phase="Running", Reason="", readiness=true. Elapsed: 1.996646ms
Aug  2 10:34:52.718: INFO: Pod "pod-update-activedeadlineseconds-259f661d-b511-11e9-b8f5-0a4acaace53e": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.005397638s
Aug  2 10:34:52.718: INFO: Pod "pod-update-activedeadlineseconds-259f661d-b511-11e9-b8f5-0a4acaace53e" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:34:52.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-8p4ft" for this suite.
Aug  2 10:34:58.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:34:58.827: INFO: namespace: e2e-tests-pods-8p4ft, resource: bindings, ignored listing per whitelist
Aug  2 10:34:58.873: INFO: namespace e2e-tests-pods-8p4ft deletion completed in 6.150267152s

• [SLOW TEST:12.838 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:34:58.873: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug  2 10:34:58.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 version'
Aug  2 10:34:59.055: INFO: stderr: ""
Aug  2 10:34:59.055: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.7\", GitCommit:\"4683545293d792934a7a7e12f2cc47d20b2dd01b\", GitTreeState:\"clean\", BuildDate:\"2019-06-06T01:39:30Z\", GoVersion:\"go1.11.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:34:59.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6krlg" for this suite.
Aug  2 10:35:05.071: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:35:05.112: INFO: namespace: e2e-tests-kubectl-6krlg, resource: bindings, ignored listing per whitelist
Aug  2 10:35:05.207: INFO: namespace e2e-tests-kubectl-6krlg deletion completed in 6.149080607s

• [SLOW TEST:6.334 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:35:05.208: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Aug  2 10:35:07.891: INFO: Successfully updated pod "annotationupdate310bf76d-b511-11e9-b8f5-0a4acaace53e"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:35:11.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-v5wwz" for this suite.
Aug  2 10:35:34.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:35:34.869: INFO: namespace: e2e-tests-projected-v5wwz, resource: bindings, ignored listing per whitelist
Aug  2 10:35:34.956: INFO: namespace e2e-tests-projected-v5wwz deletion completed in 23.026225608s

• [SLOW TEST:29.748 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:35:34.957: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-42c90099-b511-11e9-b8f5-0a4acaace53e
STEP: Creating a pod to test consume secrets
Aug  2 10:35:35.116: INFO: Waiting up to 5m0s for pod "pod-secrets-42c9a5f9-b511-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-secrets-xkfql" to be "success or failure"
Aug  2 10:35:35.129: INFO: Pod "pod-secrets-42c9a5f9-b511-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 12.972255ms
Aug  2 10:35:37.133: INFO: Pod "pod-secrets-42c9a5f9-b511-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016546234s
Aug  2 10:35:39.283: INFO: Pod "pod-secrets-42c9a5f9-b511-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.167071073s
STEP: Saw pod success
Aug  2 10:35:39.284: INFO: Pod "pod-secrets-42c9a5f9-b511-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 10:35:39.287: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-secrets-42c9a5f9-b511-11e9-b8f5-0a4acaace53e container secret-volume-test: <nil>
STEP: delete the pod
Aug  2 10:35:39.307: INFO: Waiting for pod pod-secrets-42c9a5f9-b511-11e9-b8f5-0a4acaace53e to disappear
Aug  2 10:35:39.310: INFO: Pod pod-secrets-42c9a5f9-b511-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:35:39.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-xkfql" for this suite.
Aug  2 10:35:45.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:35:45.365: INFO: namespace: e2e-tests-secrets-xkfql, resource: bindings, ignored listing per whitelist
Aug  2 10:35:45.431: INFO: namespace e2e-tests-secrets-xkfql deletion completed in 6.118163451s

• [SLOW TEST:10.474 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:35:45.433: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-48fd25e1-b511-11e9-b8f5-0a4acaace53e
STEP: Creating a pod to test consume secrets
Aug  2 10:35:45.522: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-48fdda9a-b511-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-projected-28x9v" to be "success or failure"
Aug  2 10:35:45.530: INFO: Pod "pod-projected-secrets-48fdda9a-b511-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 7.758415ms
Aug  2 10:35:47.588: INFO: Pod "pod-projected-secrets-48fdda9a-b511-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.065351878s
Aug  2 10:35:49.694: INFO: Pod "pod-projected-secrets-48fdda9a-b511-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.172021325s
STEP: Saw pod success
Aug  2 10:35:49.695: INFO: Pod "pod-projected-secrets-48fdda9a-b511-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 10:35:49.700: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-projected-secrets-48fdda9a-b511-11e9-b8f5-0a4acaace53e container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug  2 10:35:49.734: INFO: Waiting for pod pod-projected-secrets-48fdda9a-b511-11e9-b8f5-0a4acaace53e to disappear
Aug  2 10:35:49.739: INFO: Pod pod-projected-secrets-48fdda9a-b511-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:35:49.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-28x9v" for this suite.
Aug  2 10:35:55.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:35:55.770: INFO: namespace: e2e-tests-projected-28x9v, resource: bindings, ignored listing per whitelist
Aug  2 10:35:55.870: INFO: namespace e2e-tests-projected-28x9v deletion completed in 6.126178266s

• [SLOW TEST:10.437 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:35:55.871: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug  2 10:35:55.956: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4f3593da-b511-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-downward-api-2nvcz" to be "success or failure"
Aug  2 10:35:56.050: INFO: Pod "downwardapi-volume-4f3593da-b511-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 93.857249ms
Aug  2 10:35:58.054: INFO: Pod "downwardapi-volume-4f3593da-b511-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.09749623s
Aug  2 10:36:00.057: INFO: Pod "downwardapi-volume-4f3593da-b511-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.101017495s
STEP: Saw pod success
Aug  2 10:36:00.057: INFO: Pod "downwardapi-volume-4f3593da-b511-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 10:36:00.060: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod downwardapi-volume-4f3593da-b511-11e9-b8f5-0a4acaace53e container client-container: <nil>
STEP: delete the pod
Aug  2 10:36:00.081: INFO: Waiting for pod downwardapi-volume-4f3593da-b511-11e9-b8f5-0a4acaace53e to disappear
Aug  2 10:36:00.085: INFO: Pod downwardapi-volume-4f3593da-b511-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:36:00.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2nvcz" for this suite.
Aug  2 10:36:06.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:36:06.225: INFO: namespace: e2e-tests-downward-api-2nvcz, resource: bindings, ignored listing per whitelist
Aug  2 10:36:06.245: INFO: namespace e2e-tests-downward-api-2nvcz deletion completed in 6.157059026s

• [SLOW TEST:10.375 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:36:06.246: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Aug  2 10:36:06.388: INFO: Waiting up to 5m0s for pod "client-containers-556d8b65-b511-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-containers-d88gb" to be "success or failure"
Aug  2 10:36:06.395: INFO: Pod "client-containers-556d8b65-b511-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.744645ms
Aug  2 10:36:08.399: INFO: Pod "client-containers-556d8b65-b511-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010515867s
Aug  2 10:36:10.402: INFO: Pod "client-containers-556d8b65-b511-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014101393s
Aug  2 10:36:12.406: INFO: Pod "client-containers-556d8b65-b511-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.017549605s
Aug  2 10:36:14.410: INFO: Pod "client-containers-556d8b65-b511-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.021778988s
Aug  2 10:36:16.415: INFO: Pod "client-containers-556d8b65-b511-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.026396077s
Aug  2 10:36:18.420: INFO: Pod "client-containers-556d8b65-b511-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.03132789s
STEP: Saw pod success
Aug  2 10:36:18.420: INFO: Pod "client-containers-556d8b65-b511-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 10:36:18.423: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod client-containers-556d8b65-b511-11e9-b8f5-0a4acaace53e container test-container: <nil>
STEP: delete the pod
Aug  2 10:36:18.450: INFO: Waiting for pod client-containers-556d8b65-b511-11e9-b8f5-0a4acaace53e to disappear
Aug  2 10:36:18.459: INFO: Pod client-containers-556d8b65-b511-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:36:18.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-d88gb" for this suite.
Aug  2 10:36:24.474: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:36:24.596: INFO: namespace: e2e-tests-containers-d88gb, resource: bindings, ignored listing per whitelist
Aug  2 10:36:24.605: INFO: namespace e2e-tests-containers-d88gb deletion completed in 6.141692122s

• [SLOW TEST:18.359 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:36:24.606: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Aug  2 10:36:32.828: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug  2 10:36:32.832: INFO: Pod pod-with-poststart-http-hook still exists
Aug  2 10:36:34.832: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug  2 10:36:34.836: INFO: Pod pod-with-poststart-http-hook still exists
Aug  2 10:36:36.832: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug  2 10:36:36.836: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:36:36.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-s7mzb" for this suite.
Aug  2 10:36:58.852: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:36:58.927: INFO: namespace: e2e-tests-container-lifecycle-hook-s7mzb, resource: bindings, ignored listing per whitelist
Aug  2 10:36:59.002: INFO: namespace e2e-tests-container-lifecycle-hook-s7mzb deletion completed in 22.163477039s

• [SLOW TEST:34.397 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:36:59.005: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-jrl8c
Aug  2 10:37:01.148: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-jrl8c
STEP: checking the pod's current state and verifying that restartCount is present
Aug  2 10:37:01.150: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:41:02.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-jrl8c" for this suite.
Aug  2 10:41:08.651: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:41:08.736: INFO: namespace: e2e-tests-container-probe-jrl8c, resource: bindings, ignored listing per whitelist
Aug  2 10:41:08.775: INFO: namespace e2e-tests-container-probe-jrl8c deletion completed in 6.146044265s

• [SLOW TEST:249.771 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:41:08.775: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:41:08.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-hr6b9" for this suite.
Aug  2 10:41:14.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:41:14.929: INFO: namespace: e2e-tests-services-hr6b9, resource: bindings, ignored listing per whitelist
Aug  2 10:41:14.984: INFO: namespace e2e-tests-services-hr6b9 deletion completed in 6.125044735s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:6.208 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:41:14.984: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug  2 10:41:21.173: INFO: Waiting up to 5m0s for pod "client-envvars-110d9d7a-b512-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-pods-m5nsc" to be "success or failure"
Aug  2 10:41:21.183: INFO: Pod "client-envvars-110d9d7a-b512-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 9.812757ms
Aug  2 10:41:23.187: INFO: Pod "client-envvars-110d9d7a-b512-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013134107s
Aug  2 10:41:25.252: INFO: Pod "client-envvars-110d9d7a-b512-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.078049669s
Aug  2 10:41:27.255: INFO: Pod "client-envvars-110d9d7a-b512-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.081672228s
STEP: Saw pod success
Aug  2 10:41:27.256: INFO: Pod "client-envvars-110d9d7a-b512-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 10:41:27.258: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod client-envvars-110d9d7a-b512-11e9-b8f5-0a4acaace53e container env3cont: <nil>
STEP: delete the pod
Aug  2 10:41:27.285: INFO: Waiting for pod client-envvars-110d9d7a-b512-11e9-b8f5-0a4acaace53e to disappear
Aug  2 10:41:27.289: INFO: Pod client-envvars-110d9d7a-b512-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:41:27.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-m5nsc" for this suite.
Aug  2 10:42:05.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:42:05.427: INFO: namespace: e2e-tests-pods-m5nsc, resource: bindings, ignored listing per whitelist
Aug  2 10:42:05.466: INFO: namespace e2e-tests-pods-m5nsc deletion completed in 38.174629988s

• [SLOW TEST:50.482 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:42:05.467: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Aug  2 10:42:09.597: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:42:33.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-dgdld" for this suite.
Aug  2 10:42:39.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:42:39.756: INFO: namespace: e2e-tests-namespaces-dgdld, resource: bindings, ignored listing per whitelist
Aug  2 10:42:39.769: INFO: namespace e2e-tests-namespaces-dgdld deletion completed in 6.127640597s
STEP: Destroying namespace "e2e-tests-nsdeletetest-dv9sk" for this suite.
Aug  2 10:42:39.772: INFO: Namespace e2e-tests-nsdeletetest-dv9sk was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-xtnfd" for this suite.
Aug  2 10:42:45.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:42:45.861: INFO: namespace: e2e-tests-nsdeletetest-xtnfd, resource: bindings, ignored listing per whitelist
Aug  2 10:42:45.883: INFO: namespace e2e-tests-nsdeletetest-xtnfd deletion completed in 6.111359507s

• [SLOW TEST:40.416 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:42:45.884: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-8gz8n
Aug  2 10:42:49.972: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-8gz8n
STEP: checking the pod's current state and verifying that restartCount is present
Aug  2 10:42:49.975: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:46:50.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-8gz8n" for this suite.
Aug  2 10:46:56.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:46:56.498: INFO: namespace: e2e-tests-container-probe-8gz8n, resource: bindings, ignored listing per whitelist
Aug  2 10:46:56.533: INFO: namespace e2e-tests-container-probe-8gz8n deletion completed in 6.159208513s

• [SLOW TEST:250.649 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:46:56.534: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Aug  2 10:46:56.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 create -f - --namespace=e2e-tests-kubectl-qdzrd'
Aug  2 10:46:57.912: INFO: stderr: ""
Aug  2 10:46:57.912: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Aug  2 10:46:58.917: INFO: Selector matched 1 pods for map[app:redis]
Aug  2 10:46:58.917: INFO: Found 0 / 1
Aug  2 10:46:59.916: INFO: Selector matched 1 pods for map[app:redis]
Aug  2 10:46:59.916: INFO: Found 1 / 1
Aug  2 10:46:59.916: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug  2 10:46:59.918: INFO: Selector matched 1 pods for map[app:redis]
Aug  2 10:46:59.918: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Aug  2 10:46:59.918: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 logs redis-master-jmscf redis-master --namespace=e2e-tests-kubectl-qdzrd'
Aug  2 10:47:00.054: INFO: stderr: ""
Aug  2 10:47:00.054: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 02 Aug 10:46:59.089 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 02 Aug 10:46:59.089 # Server started, Redis version 3.2.12\n1:M 02 Aug 10:46:59.090 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 02 Aug 10:46:59.090 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Aug  2 10:47:00.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 log redis-master-jmscf redis-master --namespace=e2e-tests-kubectl-qdzrd --tail=1'
Aug  2 10:47:00.191: INFO: stderr: ""
Aug  2 10:47:00.191: INFO: stdout: "1:M 02 Aug 10:46:59.090 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Aug  2 10:47:00.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 log redis-master-jmscf redis-master --namespace=e2e-tests-kubectl-qdzrd --limit-bytes=1'
Aug  2 10:47:00.329: INFO: stderr: ""
Aug  2 10:47:00.329: INFO: stdout: " "
STEP: exposing timestamps
Aug  2 10:47:00.330: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 log redis-master-jmscf redis-master --namespace=e2e-tests-kubectl-qdzrd --tail=1 --timestamps'
Aug  2 10:47:00.479: INFO: stderr: ""
Aug  2 10:47:00.479: INFO: stdout: "2019-08-02T10:46:59.090631727Z 1:M 02 Aug 10:46:59.090 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Aug  2 10:47:02.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 log redis-master-jmscf redis-master --namespace=e2e-tests-kubectl-qdzrd --since=1s'
Aug  2 10:47:03.109: INFO: stderr: ""
Aug  2 10:47:03.109: INFO: stdout: ""
Aug  2 10:47:03.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 log redis-master-jmscf redis-master --namespace=e2e-tests-kubectl-qdzrd --since=24h'
Aug  2 10:47:03.235: INFO: stderr: ""
Aug  2 10:47:03.235: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 02 Aug 10:46:59.089 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 02 Aug 10:46:59.089 # Server started, Redis version 3.2.12\n1:M 02 Aug 10:46:59.090 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 02 Aug 10:46:59.090 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Aug  2 10:47:03.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-qdzrd'
Aug  2 10:47:03.350: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  2 10:47:03.350: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Aug  2 10:47:03.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-qdzrd'
Aug  2 10:47:03.521: INFO: stderr: "No resources found.\n"
Aug  2 10:47:03.521: INFO: stdout: ""
Aug  2 10:47:03.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods -l name=nginx --namespace=e2e-tests-kubectl-qdzrd -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug  2 10:47:03.631: INFO: stderr: ""
Aug  2 10:47:03.631: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:47:03.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qdzrd" for this suite.
Aug  2 10:47:09.651: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:47:09.721: INFO: namespace: e2e-tests-kubectl-qdzrd, resource: bindings, ignored listing per whitelist
Aug  2 10:47:09.759: INFO: namespace e2e-tests-kubectl-qdzrd deletion completed in 6.120866583s

• [SLOW TEST:13.226 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:47:09.763: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-mkzqv
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug  2 10:47:09.841: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug  2 10:47:27.894: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.232.38:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-mkzqv PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  2 10:47:27.894: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
Aug  2 10:47:28.039: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:47:28.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-mkzqv" for this suite.
Aug  2 10:47:50.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:47:50.148: INFO: namespace: e2e-tests-pod-network-test-mkzqv, resource: bindings, ignored listing per whitelist
Aug  2 10:47:50.175: INFO: namespace e2e-tests-pod-network-test-mkzqv deletion completed in 22.131808205s

• [SLOW TEST:40.413 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:47:50.176: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug  2 10:47:50.264: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-hrwmt'
Aug  2 10:47:50.428: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug  2 10:47:50.428: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Aug  2 10:47:50.442: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-9rbdd]
Aug  2 10:47:50.442: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-9rbdd" in namespace "e2e-tests-kubectl-hrwmt" to be "running and ready"
Aug  2 10:47:50.445: INFO: Pod "e2e-test-nginx-rc-9rbdd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.612414ms
Aug  2 10:47:52.449: INFO: Pod "e2e-test-nginx-rc-9rbdd": Phase="Running", Reason="", readiness=true. Elapsed: 2.006842559s
Aug  2 10:47:52.449: INFO: Pod "e2e-test-nginx-rc-9rbdd" satisfied condition "running and ready"
Aug  2 10:47:52.449: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-9rbdd]
Aug  2 10:47:52.449: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-hrwmt'
Aug  2 10:47:52.621: INFO: stderr: ""
Aug  2 10:47:52.621: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Aug  2 10:47:52.621: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-hrwmt'
Aug  2 10:47:52.766: INFO: stderr: ""
Aug  2 10:47:52.766: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:47:52.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hrwmt" for this suite.
Aug  2 10:47:58.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:47:58.863: INFO: namespace: e2e-tests-kubectl-hrwmt, resource: bindings, ignored listing per whitelist
Aug  2 10:47:58.908: INFO: namespace e2e-tests-kubectl-hrwmt deletion completed in 6.137962601s

• [SLOW TEST:8.733 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:47:58.913: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug  2 10:48:17.043: INFO: Container started at 2019-08-02 10:48:00 +0000 UTC, pod became ready at 2019-08-02 10:48:16 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:48:17.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-8tvp5" for this suite.
Aug  2 10:48:39.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:48:39.159: INFO: namespace: e2e-tests-container-probe-8tvp5, resource: bindings, ignored listing per whitelist
Aug  2 10:48:39.223: INFO: namespace e2e-tests-container-probe-8tvp5 deletion completed in 22.174970696s

• [SLOW TEST:40.311 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:48:39.229: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:49:00.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-lb6fq" for this suite.
Aug  2 10:49:22.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:49:22.441: INFO: namespace: e2e-tests-replication-controller-lb6fq, resource: bindings, ignored listing per whitelist
Aug  2 10:49:22.504: INFO: namespace e2e-tests-replication-controller-lb6fq deletion completed in 22.146826434s

• [SLOW TEST:43.276 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:49:22.505: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug  2 10:49:22.633: INFO: Creating deployment "nginx-deployment"
Aug  2 10:49:22.640: INFO: Waiting for observed generation 1
Aug  2 10:49:24.918: INFO: Waiting for all required pods to come up
Aug  2 10:49:24.942: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Aug  2 10:49:34.985: INFO: Waiting for deployment "nginx-deployment" to complete
Aug  2 10:49:34.992: INFO: Updating deployment "nginx-deployment" with a non-existent image
Aug  2 10:49:34.999: INFO: Updating deployment nginx-deployment
Aug  2 10:49:34.999: INFO: Waiting for observed generation 2
Aug  2 10:49:37.013: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Aug  2 10:49:37.017: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Aug  2 10:49:37.020: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Aug  2 10:49:37.026: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Aug  2 10:49:37.026: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Aug  2 10:49:37.029: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Aug  2 10:49:37.034: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Aug  2 10:49:37.034: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Aug  2 10:49:37.046: INFO: Updating deployment nginx-deployment
Aug  2 10:49:37.046: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Aug  2 10:49:37.061: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Aug  2 10:49:39.095: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Aug  2 10:49:39.099: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-7ff4v,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-7ff4v/deployments/nginx-deployment,UID:3008fb70-b513-11e9-9105-fa163e46117c,ResourceVersion:14919,Generation:3,CreationTimestamp:2019-08-02 10:49:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-08-02 10:49:37 +0000 UTC 2019-08-02 10:49:37 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-08-02 10:49:37 +0000 UTC 2019-08-02 10:49:22 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Aug  2 10:49:39.102: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-7ff4v,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-7ff4v/replicasets/nginx-deployment-65bbdb5f8,UID:37677c2f-b513-11e9-9105-fa163e46117c,ResourceVersion:14915,Generation:3,CreationTimestamp:2019-08-02 10:49:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 3008fb70-b513-11e9-9105-fa163e46117c 0xc001ad21b7 0xc001ad21b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug  2 10:49:39.102: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Aug  2 10:49:39.102: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-7ff4v,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-7ff4v/replicasets/nginx-deployment-555b55d965,UID:3009951c-b513-11e9-9105-fa163e46117c,ResourceVersion:14904,Generation:3,CreationTimestamp:2019-08-02 10:49:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 3008fb70-b513-11e9-9105-fa163e46117c 0xc001ad20f7 0xc001ad20f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Aug  2 10:49:39.107: INFO: Pod "nginx-deployment-555b55d965-4zx7d" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-4zx7d,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-7ff4v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7ff4v/pods/nginx-deployment-555b55d965-4zx7d,UID:38af1350-b513-11e9-9105-fa163e46117c,ResourceVersion:14907,Generation:0,CreationTimestamp:2019-08-02 10:49:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3009951c-b513-11e9-9105-fa163e46117c 0xc00168a1f7 0xc00168a1f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-crcsd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-crcsd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-crcsd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test-v1-13-7-gipwxthqfdpj-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00168a260} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00168a280}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:37 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  2 10:49:39.107: INFO: Pod "nginx-deployment-555b55d965-59dt7" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-59dt7,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-7ff4v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7ff4v/pods/nginx-deployment-555b55d965-59dt7,UID:300a8cf1-b513-11e9-9105-fa163e46117c,ResourceVersion:14738,Generation:0,CreationTimestamp:2019-08-02 10:49:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3009951c-b513-11e9-9105-fa163e46117c 0xc00168a2e0 0xc00168a2e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-crcsd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-crcsd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-crcsd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test-v1-13-7-gipwxthqfdpj-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00168a340} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00168a390}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:25 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:25 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:22 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.11,PodIP:192.168.232.44,StartTime:2019-08-02 10:49:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-02 10:49:24 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://00b35abbc2827b7aa7a27ba1e691ae15fda505d7f3262d34b5dfb2b4a4e56e34}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  2 10:49:39.107: INFO: Pod "nginx-deployment-555b55d965-6qzz5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-6qzz5,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-7ff4v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7ff4v/pods/nginx-deployment-555b55d965-6qzz5,UID:300c77ef-b513-11e9-9105-fa163e46117c,ResourceVersion:14775,Generation:0,CreationTimestamp:2019-08-02 10:49:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3009951c-b513-11e9-9105-fa163e46117c 0xc00168a440 0xc00168a441}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-crcsd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-crcsd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-crcsd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test-v1-13-7-gipwxthqfdpj-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00168a4a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00168a4c0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:22 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.11,PodIP:192.168.232.49,StartTime:2019-08-02 10:49:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-02 10:49:27 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://dfdbd06cd2c3017163dee12d71a19b7de84fcdbb0fc963368e55d3dc2d913c50}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  2 10:49:39.107: INFO: Pod "nginx-deployment-555b55d965-b5v5r" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-b5v5r,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-7ff4v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7ff4v/pods/nginx-deployment-555b55d965-b5v5r,UID:38a9887c-b513-11e9-9105-fa163e46117c,ResourceVersion:14878,Generation:0,CreationTimestamp:2019-08-02 10:49:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3009951c-b513-11e9-9105-fa163e46117c 0xc00168a570 0xc00168a571}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-crcsd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-crcsd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-crcsd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test-v1-13-7-gipwxthqfdpj-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00168a5d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00168a5f0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:37 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  2 10:49:39.107: INFO: Pod "nginx-deployment-555b55d965-cb8qk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-cb8qk,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-7ff4v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7ff4v/pods/nginx-deployment-555b55d965-cb8qk,UID:300eb919-b513-11e9-9105-fa163e46117c,ResourceVersion:14757,Generation:0,CreationTimestamp:2019-08-02 10:49:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3009951c-b513-11e9-9105-fa163e46117c 0xc00168a650 0xc00168a651}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-crcsd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-crcsd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-crcsd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test-v1-13-7-gipwxthqfdpj-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00168a6b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00168a6d0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:22 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.11,PodIP:192.168.232.47,StartTime:2019-08-02 10:49:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-02 10:49:25 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://e47666a54b90f47ef3bc60b4210e023d9cacad6eb1181f254d2f4febaf65b32c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  2 10:49:39.108: INFO: Pod "nginx-deployment-555b55d965-cjq5f" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-cjq5f,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-7ff4v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7ff4v/pods/nginx-deployment-555b55d965-cjq5f,UID:300ed43d-b513-11e9-9105-fa163e46117c,ResourceVersion:14754,Generation:0,CreationTimestamp:2019-08-02 10:49:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3009951c-b513-11e9-9105-fa163e46117c 0xc00168a780 0xc00168a781}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-crcsd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-crcsd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-crcsd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test-v1-13-7-gipwxthqfdpj-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00168a7e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00168a800}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:22 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.11,PodIP:192.168.232.46,StartTime:2019-08-02 10:49:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-02 10:49:25 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://9b7f71d974d0180988e71cdd9326a041a08a4e489c4820290db19f38a3499f39}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  2 10:49:39.108: INFO: Pod "nginx-deployment-555b55d965-cpn7n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-cpn7n,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-7ff4v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7ff4v/pods/nginx-deployment-555b55d965-cpn7n,UID:38af181a-b513-11e9-9105-fa163e46117c,ResourceVersion:14908,Generation:0,CreationTimestamp:2019-08-02 10:49:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3009951c-b513-11e9-9105-fa163e46117c 0xc00168a8b0 0xc00168a8b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-crcsd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-crcsd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-crcsd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test-v1-13-7-gipwxthqfdpj-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00168a910} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00168a930}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:37 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  2 10:49:39.108: INFO: Pod "nginx-deployment-555b55d965-ddbxt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-ddbxt,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-7ff4v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7ff4v/pods/nginx-deployment-555b55d965-ddbxt,UID:38a35b53-b513-11e9-9105-fa163e46117c,ResourceVersion:14859,Generation:0,CreationTimestamp:2019-08-02 10:49:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3009951c-b513-11e9-9105-fa163e46117c 0xc00168a990 0xc00168a991}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-crcsd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-crcsd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-crcsd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test-v1-13-7-gipwxthqfdpj-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00168a9f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00168aa10}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:37 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  2 10:49:39.108: INFO: Pod "nginx-deployment-555b55d965-dqnnj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-dqnnj,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-7ff4v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7ff4v/pods/nginx-deployment-555b55d965-dqnnj,UID:300cd338-b513-11e9-9105-fa163e46117c,ResourceVersion:14780,Generation:0,CreationTimestamp:2019-08-02 10:49:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3009951c-b513-11e9-9105-fa163e46117c 0xc00168aa70 0xc00168aa71}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-crcsd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-crcsd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-crcsd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test-v1-13-7-gipwxthqfdpj-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00168aad0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00168aaf0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:29 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:29 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:22 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.11,PodIP:192.168.232.52,StartTime:2019-08-02 10:49:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-02 10:49:29 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://f0b0911c43c86f1d1929dfb58c33771e0875376d94cd450d934b872863d84f69}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  2 10:49:39.108: INFO: Pod "nginx-deployment-555b55d965-fjkv5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-fjkv5,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-7ff4v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7ff4v/pods/nginx-deployment-555b55d965-fjkv5,UID:38af2532-b513-11e9-9105-fa163e46117c,ResourceVersion:14898,Generation:0,CreationTimestamp:2019-08-02 10:49:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3009951c-b513-11e9-9105-fa163e46117c 0xc00168ac00 0xc00168ac01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-crcsd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-crcsd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-crcsd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test-v1-13-7-gipwxthqfdpj-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00168ac70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00168ac90}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:37 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  2 10:49:39.108: INFO: Pod "nginx-deployment-555b55d965-gfmkz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-gfmkz,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-7ff4v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7ff4v/pods/nginx-deployment-555b55d965-gfmkz,UID:38ae7fa7-b513-11e9-9105-fa163e46117c,ResourceVersion:14902,Generation:0,CreationTimestamp:2019-08-02 10:49:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3009951c-b513-11e9-9105-fa163e46117c 0xc00168acf0 0xc00168acf1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-crcsd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-crcsd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-crcsd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test-v1-13-7-gipwxthqfdpj-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00168ad50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00168ad70}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:37 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  2 10:49:39.108: INFO: Pod "nginx-deployment-555b55d965-h8xrs" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-h8xrs,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-7ff4v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7ff4v/pods/nginx-deployment-555b55d965-h8xrs,UID:300c6889-b513-11e9-9105-fa163e46117c,ResourceVersion:14785,Generation:0,CreationTimestamp:2019-08-02 10:49:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3009951c-b513-11e9-9105-fa163e46117c 0xc00168ae20 0xc00168ae21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-crcsd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-crcsd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-crcsd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test-v1-13-7-gipwxthqfdpj-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00168ae80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00168aea0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:29 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:29 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:22 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.11,PodIP:192.168.232.51,StartTime:2019-08-02 10:49:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-02 10:49:29 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://e85def4b3d04cf0921b1a057dcc2c8749762423b34c29e5ac4cde0f3cc4f480a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  2 10:49:39.108: INFO: Pod "nginx-deployment-555b55d965-jtgfg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-jtgfg,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-7ff4v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7ff4v/pods/nginx-deployment-555b55d965-jtgfg,UID:38af0e6c-b513-11e9-9105-fa163e46117c,ResourceVersion:14906,Generation:0,CreationTimestamp:2019-08-02 10:49:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3009951c-b513-11e9-9105-fa163e46117c 0xc00168af50 0xc00168af51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-crcsd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-crcsd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-crcsd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test-v1-13-7-gipwxthqfdpj-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00168afb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00168afd0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:37 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  2 10:49:39.109: INFO: Pod "nginx-deployment-555b55d965-k68pk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-k68pk,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-7ff4v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7ff4v/pods/nginx-deployment-555b55d965-k68pk,UID:38a52d0a-b513-11e9-9105-fa163e46117c,ResourceVersion:14866,Generation:0,CreationTimestamp:2019-08-02 10:49:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3009951c-b513-11e9-9105-fa163e46117c 0xc00168b030 0xc00168b031}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-crcsd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-crcsd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-crcsd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test-v1-13-7-gipwxthqfdpj-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00168b090} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00168b0b0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:37 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  2 10:49:39.109: INFO: Pod "nginx-deployment-555b55d965-llcn7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-llcn7,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-7ff4v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7ff4v/pods/nginx-deployment-555b55d965-llcn7,UID:38a5e9a3-b513-11e9-9105-fa163e46117c,ResourceVersion:14875,Generation:0,CreationTimestamp:2019-08-02 10:49:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3009951c-b513-11e9-9105-fa163e46117c 0xc00168b110 0xc00168b111}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-crcsd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-crcsd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-crcsd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test-v1-13-7-gipwxthqfdpj-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00168b170} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00168b190}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:37 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  2 10:49:39.109: INFO: Pod "nginx-deployment-555b55d965-r6px5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-r6px5,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-7ff4v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7ff4v/pods/nginx-deployment-555b55d965-r6px5,UID:300b9339-b513-11e9-9105-fa163e46117c,ResourceVersion:14770,Generation:0,CreationTimestamp:2019-08-02 10:49:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3009951c-b513-11e9-9105-fa163e46117c 0xc00168b1f0 0xc00168b1f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-crcsd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-crcsd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-crcsd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test-v1-13-7-gipwxthqfdpj-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00168b250} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00168b2e0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:22 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.11,PodIP:192.168.232.48,StartTime:2019-08-02 10:49:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-02 10:49:27 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://6197a4fc8bbc92181d3f6a5da1518328a4ac7453ae3966a872c149599d107bbc}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  2 10:49:39.109: INFO: Pod "nginx-deployment-555b55d965-trtdw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-trtdw,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-7ff4v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7ff4v/pods/nginx-deployment-555b55d965-trtdw,UID:38a97aa8-b513-11e9-9105-fa163e46117c,ResourceVersion:14881,Generation:0,CreationTimestamp:2019-08-02 10:49:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3009951c-b513-11e9-9105-fa163e46117c 0xc00168b390 0xc00168b391}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-crcsd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-crcsd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-crcsd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test-v1-13-7-gipwxthqfdpj-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00168b3f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00168b410}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:37 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  2 10:49:39.109: INFO: Pod "nginx-deployment-555b55d965-ttlf6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-ttlf6,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-7ff4v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7ff4v/pods/nginx-deployment-555b55d965-ttlf6,UID:300cb6b4-b513-11e9-9105-fa163e46117c,ResourceVersion:14744,Generation:0,CreationTimestamp:2019-08-02 10:49:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3009951c-b513-11e9-9105-fa163e46117c 0xc00168b470 0xc00168b471}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-crcsd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-crcsd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-crcsd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test-v1-13-7-gipwxthqfdpj-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00168b4d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00168b4f0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:22 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.11,PodIP:192.168.232.45,StartTime:2019-08-02 10:49:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-02 10:49:24 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://ca326bfe84327f2264bce8ac720040302d38d6bbf529b43e5853dc0b37ed416f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  2 10:49:39.110: INFO: Pod "nginx-deployment-555b55d965-wlw6p" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-wlw6p,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-7ff4v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7ff4v/pods/nginx-deployment-555b55d965-wlw6p,UID:38a94645-b513-11e9-9105-fa163e46117c,ResourceVersion:14890,Generation:0,CreationTimestamp:2019-08-02 10:49:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3009951c-b513-11e9-9105-fa163e46117c 0xc00168b5a0 0xc00168b5a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-crcsd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-crcsd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-crcsd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test-v1-13-7-gipwxthqfdpj-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00168b600} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00168b680}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:37 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  2 10:49:39.110: INFO: Pod "nginx-deployment-555b55d965-z9lr8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-z9lr8,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-7ff4v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7ff4v/pods/nginx-deployment-555b55d965-z9lr8,UID:38a928df-b513-11e9-9105-fa163e46117c,ResourceVersion:14877,Generation:0,CreationTimestamp:2019-08-02 10:49:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3009951c-b513-11e9-9105-fa163e46117c 0xc00168b6f0 0xc00168b6f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-crcsd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-crcsd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-crcsd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test-v1-13-7-gipwxthqfdpj-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00168b750} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00168b770}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:37 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  2 10:49:39.110: INFO: Pod "nginx-deployment-65bbdb5f8-46q6m" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-46q6m,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-7ff4v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7ff4v/pods/nginx-deployment-65bbdb5f8-46q6m,UID:38ae18d4-b513-11e9-9105-fa163e46117c,ResourceVersion:14901,Generation:0,CreationTimestamp:2019-08-02 10:49:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 37677c2f-b513-11e9-9105-fa163e46117c 0xc00168b7d0 0xc00168b7d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-crcsd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-crcsd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-crcsd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test-v1-13-7-gipwxthqfdpj-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00168b840} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00168b860}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:37 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  2 10:49:39.110: INFO: Pod "nginx-deployment-65bbdb5f8-4l8tt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-4l8tt,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-7ff4v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7ff4v/pods/nginx-deployment-65bbdb5f8-4l8tt,UID:38b340d9-b513-11e9-9105-fa163e46117c,ResourceVersion:14911,Generation:0,CreationTimestamp:2019-08-02 10:49:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 37677c2f-b513-11e9-9105-fa163e46117c 0xc00168b920 0xc00168b921}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-crcsd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-crcsd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-crcsd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test-v1-13-7-gipwxthqfdpj-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00168b990} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00168b9b0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:37 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  2 10:49:39.110: INFO: Pod "nginx-deployment-65bbdb5f8-57rl7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-57rl7,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-7ff4v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7ff4v/pods/nginx-deployment-65bbdb5f8-57rl7,UID:3771d222-b513-11e9-9105-fa163e46117c,ResourceVersion:14951,Generation:0,CreationTimestamp:2019-08-02 10:49:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 37677c2f-b513-11e9-9105-fa163e46117c 0xc00168ba10 0xc00168ba11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-crcsd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-crcsd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-crcsd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test-v1-13-7-gipwxthqfdpj-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00168ba80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00168baa0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:35 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.11,PodIP:,StartTime:2019-08-02 10:49:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  2 10:49:39.110: INFO: Pod "nginx-deployment-65bbdb5f8-6rbkk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-6rbkk,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-7ff4v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7ff4v/pods/nginx-deployment-65bbdb5f8-6rbkk,UID:38ae9176-b513-11e9-9105-fa163e46117c,ResourceVersion:14896,Generation:0,CreationTimestamp:2019-08-02 10:49:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 37677c2f-b513-11e9-9105-fa163e46117c 0xc00168bbc0 0xc00168bbc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-crcsd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-crcsd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-crcsd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test-v1-13-7-gipwxthqfdpj-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00168bc30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00168bc50}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:37 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  2 10:49:39.111: INFO: Pod "nginx-deployment-65bbdb5f8-b4vs2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-b4vs2,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-7ff4v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7ff4v/pods/nginx-deployment-65bbdb5f8-b4vs2,UID:38ae4c2f-b513-11e9-9105-fa163e46117c,ResourceVersion:14899,Generation:0,CreationTimestamp:2019-08-02 10:49:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 37677c2f-b513-11e9-9105-fa163e46117c 0xc00168bcb0 0xc00168bcb1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-crcsd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-crcsd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-crcsd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test-v1-13-7-gipwxthqfdpj-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00168bd20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00168bd40}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:37 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  2 10:49:39.111: INFO: Pod "nginx-deployment-65bbdb5f8-gzbtp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-gzbtp,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-7ff4v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7ff4v/pods/nginx-deployment-65bbdb5f8-gzbtp,UID:38adfadc-b513-11e9-9105-fa163e46117c,ResourceVersion:14897,Generation:0,CreationTimestamp:2019-08-02 10:49:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 37677c2f-b513-11e9-9105-fa163e46117c 0xc00168bda0 0xc00168bda1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-crcsd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-crcsd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-crcsd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test-v1-13-7-gipwxthqfdpj-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00168be10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00168be30}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:37 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  2 10:49:39.111: INFO: Pod "nginx-deployment-65bbdb5f8-j2pnp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-j2pnp,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-7ff4v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7ff4v/pods/nginx-deployment-65bbdb5f8-j2pnp,UID:376952d5-b513-11e9-9105-fa163e46117c,ResourceVersion:14849,Generation:0,CreationTimestamp:2019-08-02 10:49:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 37677c2f-b513-11e9-9105-fa163e46117c 0xc00168be90 0xc00168be91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-crcsd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-crcsd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-crcsd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test-v1-13-7-gipwxthqfdpj-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00168bf00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00168bf20}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:35 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.11,PodIP:,StartTime:2019-08-02 10:49:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  2 10:49:39.111: INFO: Pod "nginx-deployment-65bbdb5f8-k7fcq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-k7fcq,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-7ff4v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7ff4v/pods/nginx-deployment-65bbdb5f8-k7fcq,UID:3772d4f9-b513-11e9-9105-fa163e46117c,ResourceVersion:14834,Generation:0,CreationTimestamp:2019-08-02 10:49:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 37677c2f-b513-11e9-9105-fa163e46117c 0xc00168bfd0 0xc00168bfd1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-crcsd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-crcsd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-crcsd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test-v1-13-7-gipwxthqfdpj-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001bc2040} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001bc2060}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:35 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  2 10:49:39.111: INFO: Pod "nginx-deployment-65bbdb5f8-lsf9k" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-lsf9k,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-7ff4v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7ff4v/pods/nginx-deployment-65bbdb5f8-lsf9k,UID:376934a2-b513-11e9-9105-fa163e46117c,ResourceVersion:14846,Generation:0,CreationTimestamp:2019-08-02 10:49:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 37677c2f-b513-11e9-9105-fa163e46117c 0xc001bc20d0 0xc001bc20d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-crcsd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-crcsd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-crcsd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test-v1-13-7-gipwxthqfdpj-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001bc21c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001bc21e0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:35 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.11,PodIP:,StartTime:2019-08-02 10:49:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  2 10:49:39.111: INFO: Pod "nginx-deployment-65bbdb5f8-w9x9z" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-w9x9z,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-7ff4v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7ff4v/pods/nginx-deployment-65bbdb5f8-w9x9z,UID:38a75e1b-b513-11e9-9105-fa163e46117c,ResourceVersion:14874,Generation:0,CreationTimestamp:2019-08-02 10:49:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 37677c2f-b513-11e9-9105-fa163e46117c 0xc001bc2290 0xc001bc2291}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-crcsd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-crcsd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-crcsd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test-v1-13-7-gipwxthqfdpj-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001bc2300} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001bc2320}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:37 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  2 10:49:39.112: INFO: Pod "nginx-deployment-65bbdb5f8-x65pf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-x65pf,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-7ff4v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7ff4v/pods/nginx-deployment-65bbdb5f8-x65pf,UID:38a8f59b-b513-11e9-9105-fa163e46117c,ResourceVersion:14879,Generation:0,CreationTimestamp:2019-08-02 10:49:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 37677c2f-b513-11e9-9105-fa163e46117c 0xc001bc2380 0xc001bc2381}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-crcsd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-crcsd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-crcsd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test-v1-13-7-gipwxthqfdpj-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001bc2400} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001bc2420}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:37 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  2 10:49:39.112: INFO: Pod "nginx-deployment-65bbdb5f8-z2hjm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-z2hjm,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-7ff4v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7ff4v/pods/nginx-deployment-65bbdb5f8-z2hjm,UID:3767f744-b513-11e9-9105-fa163e46117c,ResourceVersion:14830,Generation:0,CreationTimestamp:2019-08-02 10:49:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 37677c2f-b513-11e9-9105-fa163e46117c 0xc001bc2480 0xc001bc2481}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-crcsd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-crcsd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-crcsd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test-v1-13-7-gipwxthqfdpj-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001bc24f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001bc2510}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:35 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.11,PodIP:,StartTime:2019-08-02 10:49:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  2 10:49:39.113: INFO: Pod "nginx-deployment-65bbdb5f8-zvjtg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-zvjtg,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-7ff4v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7ff4v/pods/nginx-deployment-65bbdb5f8-zvjtg,UID:38a8e300-b513-11e9-9105-fa163e46117c,ResourceVersion:14883,Generation:0,CreationTimestamp:2019-08-02 10:49:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 37677c2f-b513-11e9-9105-fa163e46117c 0xc001bc25c0 0xc001bc25c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-crcsd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-crcsd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-crcsd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test-v1-13-7-gipwxthqfdpj-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001bc2630} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001bc2650}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:37 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:49:39.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-7ff4v" for this suite.
Aug  2 10:49:47.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:49:47.250: INFO: namespace: e2e-tests-deployment-7ff4v, resource: bindings, ignored listing per whitelist
Aug  2 10:49:47.395: INFO: namespace e2e-tests-deployment-7ff4v deletion completed in 8.270361114s

• [SLOW TEST:24.891 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:49:47.396: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-3f08c337-b513-11e9-b8f5-0a4acaace53e
STEP: Creating a pod to test consume secrets
Aug  2 10:49:48.694: INFO: Waiting up to 5m0s for pod "pod-secrets-3f85b303-b513-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-secrets-84ncb" to be "success or failure"
Aug  2 10:49:48.756: INFO: Pod "pod-secrets-3f85b303-b513-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 61.653611ms
Aug  2 10:49:50.762: INFO: Pod "pod-secrets-3f85b303-b513-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.067798967s
Aug  2 10:49:52.766: INFO: Pod "pod-secrets-3f85b303-b513-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.071231665s
STEP: Saw pod success
Aug  2 10:49:52.766: INFO: Pod "pod-secrets-3f85b303-b513-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 10:49:52.767: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-secrets-3f85b303-b513-11e9-b8f5-0a4acaace53e container secret-volume-test: <nil>
STEP: delete the pod
Aug  2 10:49:52.790: INFO: Waiting for pod pod-secrets-3f85b303-b513-11e9-b8f5-0a4acaace53e to disappear
Aug  2 10:49:52.794: INFO: Pod pod-secrets-3f85b303-b513-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:49:52.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-84ncb" for this suite.
Aug  2 10:49:58.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:49:58.924: INFO: namespace: e2e-tests-secrets-84ncb, resource: bindings, ignored listing per whitelist
Aug  2 10:49:58.939: INFO: namespace e2e-tests-secrets-84ncb deletion completed in 6.140701313s

• [SLOW TEST:11.543 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:49:58.940: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Aug  2 10:50:07.093: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-45bdbca8-b513-11e9-b8f5-0a4acaace53e,GenerateName:,Namespace:e2e-tests-events-zfgw9,SelfLink:/api/v1/namespaces/e2e-tests-events-zfgw9/pods/send-events-45bdbca8-b513-11e9-b8f5-0a4acaace53e,UID:45bf6db4-b513-11e9-9105-fa163e46117c,ResourceVersion:15216,Generation:0,CreationTimestamp:2019-08-02 10:49:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 57945782,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zvsl2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zvsl2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-zvsl2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test-v1-13-7-gipwxthqfdpj-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00233d6c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00233d6e0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:59 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:50:02 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:50:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:49:59 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.11,PodIP:192.168.232.14,StartTime:2019-08-02 10:49:59 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-08-02 10:50:01 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://540a0d3459b66977722024b9b3add04b418db6dc9b027d0656f9191e882fb450}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Aug  2 10:50:09.381: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Aug  2 10:50:11.565: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:50:11.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-zfgw9" for this suite.
Aug  2 10:50:49.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:50:49.629: INFO: namespace: e2e-tests-events-zfgw9, resource: bindings, ignored listing per whitelist
Aug  2 10:50:49.707: INFO: namespace e2e-tests-events-zfgw9 deletion completed in 38.1305791s

• [SLOW TEST:50.767 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:50:49.707: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug  2 10:50:49.787: INFO: Waiting up to 5m0s for pod "downwardapi-volume-63f987d0-b513-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-downward-api-4mgmf" to be "success or failure"
Aug  2 10:50:49.791: INFO: Pod "downwardapi-volume-63f987d0-b513-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.114311ms
Aug  2 10:50:51.799: INFO: Pod "downwardapi-volume-63f987d0-b513-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011586694s
STEP: Saw pod success
Aug  2 10:50:51.799: INFO: Pod "downwardapi-volume-63f987d0-b513-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 10:50:51.801: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod downwardapi-volume-63f987d0-b513-11e9-b8f5-0a4acaace53e container client-container: <nil>
STEP: delete the pod
Aug  2 10:50:51.832: INFO: Waiting for pod downwardapi-volume-63f987d0-b513-11e9-b8f5-0a4acaace53e to disappear
Aug  2 10:50:51.836: INFO: Pod downwardapi-volume-63f987d0-b513-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:50:51.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4mgmf" for this suite.
Aug  2 10:50:57.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:50:57.953: INFO: namespace: e2e-tests-downward-api-4mgmf, resource: bindings, ignored listing per whitelist
Aug  2 10:50:57.955: INFO: namespace e2e-tests-downward-api-4mgmf deletion completed in 6.114114456s

• [SLOW TEST:8.248 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:50:57.956: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-68ec0ddd-b513-11e9-b8f5-0a4acaace53e
STEP: Creating configMap with name cm-test-opt-upd-68ec0e1b-b513-11e9-b8f5-0a4acaace53e
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-68ec0ddd-b513-11e9-b8f5-0a4acaace53e
STEP: Updating configmap cm-test-opt-upd-68ec0e1b-b513-11e9-b8f5-0a4acaace53e
STEP: Creating configMap with name cm-test-opt-create-68ec0e2e-b513-11e9-b8f5-0a4acaace53e
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:52:17.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-g82jz" for this suite.
Aug  2 10:52:41.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:52:41.512: INFO: namespace: e2e-tests-configmap-g82jz, resource: bindings, ignored listing per whitelist
Aug  2 10:52:41.614: INFO: namespace e2e-tests-configmap-g82jz deletion completed in 24.464623262s

• [SLOW TEST:103.658 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:52:41.614: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-a6b4ea86-b513-11e9-b8f5-0a4acaace53e
STEP: Creating a pod to test consume configMaps
Aug  2 10:52:41.749: INFO: Waiting up to 5m0s for pod "pod-configmaps-a6b5885d-b513-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-configmap-tlz74" to be "success or failure"
Aug  2 10:52:41.752: INFO: Pod "pod-configmaps-a6b5885d-b513-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.449182ms
Aug  2 10:52:43.757: INFO: Pod "pod-configmaps-a6b5885d-b513-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008216039s
Aug  2 10:52:45.761: INFO: Pod "pod-configmaps-a6b5885d-b513-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011804188s
STEP: Saw pod success
Aug  2 10:52:45.761: INFO: Pod "pod-configmaps-a6b5885d-b513-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 10:52:45.763: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-configmaps-a6b5885d-b513-11e9-b8f5-0a4acaace53e container configmap-volume-test: <nil>
STEP: delete the pod
Aug  2 10:52:45.781: INFO: Waiting for pod pod-configmaps-a6b5885d-b513-11e9-b8f5-0a4acaace53e to disappear
Aug  2 10:52:45.787: INFO: Pod pod-configmaps-a6b5885d-b513-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:52:45.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-tlz74" for this suite.
Aug  2 10:52:51.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:52:51.844: INFO: namespace: e2e-tests-configmap-tlz74, resource: bindings, ignored listing per whitelist
Aug  2 10:52:51.914: INFO: namespace e2e-tests-configmap-tlz74 deletion completed in 6.124817531s

• [SLOW TEST:10.300 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:52:51.915: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug  2 10:52:52.042: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:52:52.045: INFO: Number of nodes with available pods: 0
Aug  2 10:52:52.045: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:52:53.051: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:52:53.053: INFO: Number of nodes with available pods: 0
Aug  2 10:52:53.053: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:52:54.049: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:52:54.052: INFO: Number of nodes with available pods: 0
Aug  2 10:52:54.052: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:52:55.049: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:52:55.051: INFO: Number of nodes with available pods: 1
Aug  2 10:52:55.051: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Stop a daemon pod, check that the daemon pod is revived.
Aug  2 10:52:55.064: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:52:55.067: INFO: Number of nodes with available pods: 0
Aug  2 10:52:55.067: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:52:56.070: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:52:56.072: INFO: Number of nodes with available pods: 0
Aug  2 10:52:56.072: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:52:57.071: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:52:57.074: INFO: Number of nodes with available pods: 0
Aug  2 10:52:57.074: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:52:58.289: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:52:58.293: INFO: Number of nodes with available pods: 0
Aug  2 10:52:58.293: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:52:59.070: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:52:59.073: INFO: Number of nodes with available pods: 0
Aug  2 10:52:59.073: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:53:00.156: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:53:00.159: INFO: Number of nodes with available pods: 0
Aug  2 10:53:00.159: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:53:01.071: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:53:01.073: INFO: Number of nodes with available pods: 0
Aug  2 10:53:01.074: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:53:02.070: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:53:02.072: INFO: Number of nodes with available pods: 0
Aug  2 10:53:02.072: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:53:03.304: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:53:03.306: INFO: Number of nodes with available pods: 0
Aug  2 10:53:03.306: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:53:04.071: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:53:04.076: INFO: Number of nodes with available pods: 0
Aug  2 10:53:04.077: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:53:05.070: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:53:05.072: INFO: Number of nodes with available pods: 0
Aug  2 10:53:05.072: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:53:06.070: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:53:06.074: INFO: Number of nodes with available pods: 0
Aug  2 10:53:06.074: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:53:07.071: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:53:07.073: INFO: Number of nodes with available pods: 0
Aug  2 10:53:07.073: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:53:08.757: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:53:08.763: INFO: Number of nodes with available pods: 0
Aug  2 10:53:08.763: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:53:09.070: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:53:09.073: INFO: Number of nodes with available pods: 0
Aug  2 10:53:09.073: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:53:11.568: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:53:11.576: INFO: Number of nodes with available pods: 0
Aug  2 10:53:11.576: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:53:12.071: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:53:12.073: INFO: Number of nodes with available pods: 0
Aug  2 10:53:12.073: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:53:13.070: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:53:13.073: INFO: Number of nodes with available pods: 0
Aug  2 10:53:13.073: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:53:14.071: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:53:14.074: INFO: Number of nodes with available pods: 0
Aug  2 10:53:14.074: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:53:15.071: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:53:15.074: INFO: Number of nodes with available pods: 0
Aug  2 10:53:15.075: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:53:16.434: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:53:16.438: INFO: Number of nodes with available pods: 0
Aug  2 10:53:16.438: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:53:17.071: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:53:17.074: INFO: Number of nodes with available pods: 0
Aug  2 10:53:17.074: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:53:18.071: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:53:18.075: INFO: Number of nodes with available pods: 0
Aug  2 10:53:18.075: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:53:19.071: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:53:19.074: INFO: Number of nodes with available pods: 0
Aug  2 10:53:19.074: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:53:20.071: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:53:20.074: INFO: Number of nodes with available pods: 0
Aug  2 10:53:20.074: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:53:21.071: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:53:21.075: INFO: Number of nodes with available pods: 0
Aug  2 10:53:21.075: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:53:22.072: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:53:22.075: INFO: Number of nodes with available pods: 0
Aug  2 10:53:22.075: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:53:23.072: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:53:23.076: INFO: Number of nodes with available pods: 0
Aug  2 10:53:23.076: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:53:24.070: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:53:24.072: INFO: Number of nodes with available pods: 0
Aug  2 10:53:24.073: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:53:26.394: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:53:26.411: INFO: Number of nodes with available pods: 0
Aug  2 10:53:26.411: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:53:27.070: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:53:27.072: INFO: Number of nodes with available pods: 0
Aug  2 10:53:27.072: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:53:28.112: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:53:28.115: INFO: Number of nodes with available pods: 0
Aug  2 10:53:28.115: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:53:29.071: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:53:29.074: INFO: Number of nodes with available pods: 0
Aug  2 10:53:29.074: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:53:30.071: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:53:30.073: INFO: Number of nodes with available pods: 0
Aug  2 10:53:30.073: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 10:53:31.070: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 10:53:31.072: INFO: Number of nodes with available pods: 1
Aug  2 10:53:31.072: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-x8dvn, will wait for the garbage collector to delete the pods
Aug  2 10:53:31.137: INFO: Deleting DaemonSet.extensions daemon-set took: 8.309025ms
Aug  2 10:53:31.237: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.284978ms
Aug  2 10:54:12.846: INFO: Number of nodes with available pods: 0
Aug  2 10:54:12.846: INFO: Number of running nodes: 0, number of available pods: 0
Aug  2 10:54:12.853: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-x8dvn/daemonsets","resourceVersion":"15814"},"items":null}

Aug  2 10:54:12.855: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-x8dvn/pods","resourceVersion":"15814"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:54:12.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-x8dvn" for this suite.
Aug  2 10:54:18.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:54:18.910: INFO: namespace: e2e-tests-daemonsets-x8dvn, resource: bindings, ignored listing per whitelist
Aug  2 10:54:18.991: INFO: namespace e2e-tests-daemonsets-x8dvn deletion completed in 6.127967734s

• [SLOW TEST:87.076 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:54:18.992: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Aug  2 10:54:19.083: INFO: Waiting up to 5m0s for pod "pod-e0b99f06-b513-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-emptydir-phv5s" to be "success or failure"
Aug  2 10:54:19.088: INFO: Pod "pod-e0b99f06-b513-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.803054ms
Aug  2 10:54:21.093: INFO: Pod "pod-e0b99f06-b513-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009256954s
Aug  2 10:54:23.206: INFO: Pod "pod-e0b99f06-b513-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.122907948s
Aug  2 10:54:25.210: INFO: Pod "pod-e0b99f06-b513-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.12631302s
Aug  2 10:54:27.213: INFO: Pod "pod-e0b99f06-b513-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.129892639s
Aug  2 10:54:29.217: INFO: Pod "pod-e0b99f06-b513-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.133991058s
Aug  2 10:54:31.220: INFO: Pod "pod-e0b99f06-b513-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 12.137051143s
Aug  2 10:54:33.225: INFO: Pod "pod-e0b99f06-b513-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.141485869s
STEP: Saw pod success
Aug  2 10:54:33.225: INFO: Pod "pod-e0b99f06-b513-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 10:54:33.227: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-e0b99f06-b513-11e9-b8f5-0a4acaace53e container test-container: <nil>
STEP: delete the pod
Aug  2 10:54:33.252: INFO: Waiting for pod pod-e0b99f06-b513-11e9-b8f5-0a4acaace53e to disappear
Aug  2 10:54:33.256: INFO: Pod pod-e0b99f06-b513-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:54:33.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-phv5s" for this suite.
Aug  2 10:54:40.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:54:40.101: INFO: namespace: e2e-tests-emptydir-phv5s, resource: bindings, ignored listing per whitelist
Aug  2 10:54:40.124: INFO: namespace e2e-tests-emptydir-phv5s deletion completed in 6.859095976s

• [SLOW TEST:21.132 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:54:40.125: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug  2 10:54:40.199: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Aug  2 10:54:40.219: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug  2 10:54:42.231: INFO: Creating deployment "test-rolling-update-deployment"
Aug  2 10:54:42.236: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Aug  2 10:54:42.250: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Aug  2 10:54:44.257: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Aug  2 10:54:44.259: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Aug  2 10:54:44.266: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-n95zz,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-n95zz/deployments/test-rolling-update-deployment,UID:ee878cc4-b513-11e9-9105-fa163e46117c,ResourceVersion:15959,Generation:1,CreationTimestamp:2019-08-02 10:54:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-08-02 10:54:42 +0000 UTC 2019-08-02 10:54:42 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-08-02 10:54:44 +0000 UTC 2019-08-02 10:54:42 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Aug  2 10:54:44.269: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-n95zz,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-n95zz/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:ee89bd9f-b513-11e9-9105-fa163e46117c,ResourceVersion:15948,Generation:1,CreationTimestamp:2019-08-02 10:54:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment ee878cc4-b513-11e9-9105-fa163e46117c 0xc001e60367 0xc001e60368}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug  2 10:54:44.269: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Aug  2 10:54:44.270: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-n95zz,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-n95zz/replicasets/test-rolling-update-controller,UID:ed5198c9-b513-11e9-9105-fa163e46117c,ResourceVersion:15958,Generation:2,CreationTimestamp:2019-08-02 10:54:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment ee878cc4-b513-11e9-9105-fa163e46117c 0xc001e601f7 0xc001e601f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug  2 10:54:44.272: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-8r966" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-8r966,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-n95zz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-n95zz/pods/test-rolling-update-deployment-68b55d7bc6-8r966,UID:ee8a6eeb-b513-11e9-9105-fa163e46117c,ResourceVersion:15947,Generation:0,CreationTimestamp:2019-08-02 10:54:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 ee89bd9f-b513-11e9-9105-fa163e46117c 0xc001e60ea7 0xc001e60ea8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nh7s2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nh7s2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-nh7s2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test-v1-13-7-gipwxthqfdpj-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001e60f10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001e60f30}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:54:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:54:43 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:54:43 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 10:54:42 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.11,PodIP:192.168.232.24,StartTime:2019-08-02 10:54:42 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-08-02 10:54:43 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://310f83893e933812010d68512aeff868ab832a3f3363e879265427b91d54e30f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:54:44.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-n95zz" for this suite.
Aug  2 10:54:50.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:54:50.364: INFO: namespace: e2e-tests-deployment-n95zz, resource: bindings, ignored listing per whitelist
Aug  2 10:54:50.461: INFO: namespace e2e-tests-deployment-n95zz deletion completed in 6.184956186s

• [SLOW TEST:10.336 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:54:50.463: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-h7dlt
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug  2 10:54:50.578: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug  2 10:55:08.667: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.232.26:8080/dial?request=hostName&protocol=http&host=192.168.232.25&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-h7dlt PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  2 10:55:08.667: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
Aug  2 10:55:08.816: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:55:08.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-h7dlt" for this suite.
Aug  2 10:55:30.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:55:30.937: INFO: namespace: e2e-tests-pod-network-test-h7dlt, resource: bindings, ignored listing per whitelist
Aug  2 10:55:30.978: INFO: namespace e2e-tests-pod-network-test-h7dlt deletion completed in 22.159148682s

• [SLOW TEST:40.515 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:55:30.979: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Aug  2 10:55:39.107: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug  2 10:55:39.111: INFO: Pod pod-with-prestop-http-hook still exists
Aug  2 10:55:41.111: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug  2 10:55:41.114: INFO: Pod pod-with-prestop-http-hook still exists
Aug  2 10:55:43.111: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug  2 10:55:43.114: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:55:43.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-29g9f" for this suite.
Aug  2 10:56:05.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:56:05.215: INFO: namespace: e2e-tests-container-lifecycle-hook-29g9f, resource: bindings, ignored listing per whitelist
Aug  2 10:56:05.344: INFO: namespace e2e-tests-container-lifecycle-hook-29g9f deletion completed in 22.215288204s

• [SLOW TEST:34.365 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:56:05.344: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Aug  2 10:56:05.422: INFO: Waiting up to 5m0s for pod "pod-201bc335-b514-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-emptydir-59x2l" to be "success or failure"
Aug  2 10:56:05.429: INFO: Pod "pod-201bc335-b514-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.347255ms
Aug  2 10:56:07.432: INFO: Pod "pod-201bc335-b514-11e9-b8f5-0a4acaace53e": Phase="Running", Reason="", readiness=true. Elapsed: 2.009896628s
Aug  2 10:56:09.436: INFO: Pod "pod-201bc335-b514-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013835622s
STEP: Saw pod success
Aug  2 10:56:09.436: INFO: Pod "pod-201bc335-b514-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 10:56:09.439: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-201bc335-b514-11e9-b8f5-0a4acaace53e container test-container: <nil>
STEP: delete the pod
Aug  2 10:56:09.470: INFO: Waiting for pod pod-201bc335-b514-11e9-b8f5-0a4acaace53e to disappear
Aug  2 10:56:09.482: INFO: Pod pod-201bc335-b514-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:56:09.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-59x2l" for this suite.
Aug  2 10:56:15.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:56:15.521: INFO: namespace: e2e-tests-emptydir-59x2l, resource: bindings, ignored listing per whitelist
Aug  2 10:56:15.601: INFO: namespace e2e-tests-emptydir-59x2l deletion completed in 6.11510263s

• [SLOW TEST:10.257 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:56:15.602: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug  2 10:56:15.675: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2637eec0-b514-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-projected-zxntx" to be "success or failure"
Aug  2 10:56:15.680: INFO: Pod "downwardapi-volume-2637eec0-b514-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.258718ms
Aug  2 10:56:17.683: INFO: Pod "downwardapi-volume-2637eec0-b514-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007771855s
Aug  2 10:56:19.687: INFO: Pod "downwardapi-volume-2637eec0-b514-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01143387s
STEP: Saw pod success
Aug  2 10:56:19.687: INFO: Pod "downwardapi-volume-2637eec0-b514-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 10:56:19.689: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod downwardapi-volume-2637eec0-b514-11e9-b8f5-0a4acaace53e container client-container: <nil>
STEP: delete the pod
Aug  2 10:56:19.711: INFO: Waiting for pod downwardapi-volume-2637eec0-b514-11e9-b8f5-0a4acaace53e to disappear
Aug  2 10:56:19.715: INFO: Pod downwardapi-volume-2637eec0-b514-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:56:19.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zxntx" for this suite.
Aug  2 10:56:25.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:56:25.763: INFO: namespace: e2e-tests-projected-zxntx, resource: bindings, ignored listing per whitelist
Aug  2 10:56:25.833: INFO: namespace e2e-tests-projected-zxntx deletion completed in 6.113956419s

• [SLOW TEST:10.232 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:56:25.834: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Aug  2 10:56:25.915: INFO: Waiting up to 5m0s for pod "var-expansion-2c5241c8-b514-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-var-expansion-szfl5" to be "success or failure"
Aug  2 10:56:25.921: INFO: Pod "var-expansion-2c5241c8-b514-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.889935ms
Aug  2 10:56:27.924: INFO: Pod "var-expansion-2c5241c8-b514-11e9-b8f5-0a4acaace53e": Phase="Running", Reason="", readiness=true. Elapsed: 2.009547896s
Aug  2 10:56:29.929: INFO: Pod "var-expansion-2c5241c8-b514-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01388314s
STEP: Saw pod success
Aug  2 10:56:29.929: INFO: Pod "var-expansion-2c5241c8-b514-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 10:56:29.931: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod var-expansion-2c5241c8-b514-11e9-b8f5-0a4acaace53e container dapi-container: <nil>
STEP: delete the pod
Aug  2 10:56:29.951: INFO: Waiting for pod var-expansion-2c5241c8-b514-11e9-b8f5-0a4acaace53e to disappear
Aug  2 10:56:29.955: INFO: Pod var-expansion-2c5241c8-b514-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:56:29.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-szfl5" for this suite.
Aug  2 10:56:35.971: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:56:36.043: INFO: namespace: e2e-tests-var-expansion-szfl5, resource: bindings, ignored listing per whitelist
Aug  2 10:56:36.103: INFO: namespace e2e-tests-var-expansion-szfl5 deletion completed in 6.145707817s

• [SLOW TEST:10.268 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:56:36.103: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Aug  2 10:56:36.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 create -f - --namespace=e2e-tests-kubectl-zwx7x'
Aug  2 10:56:36.435: INFO: stderr: ""
Aug  2 10:56:36.436: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug  2 10:56:36.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zwx7x'
Aug  2 10:56:36.558: INFO: stderr: ""
Aug  2 10:56:36.558: INFO: stdout: "update-demo-nautilus-7sgsc update-demo-nautilus-nwfzn "
Aug  2 10:56:36.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods update-demo-nautilus-7sgsc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zwx7x'
Aug  2 10:56:36.675: INFO: stderr: ""
Aug  2 10:56:36.675: INFO: stdout: ""
Aug  2 10:56:36.675: INFO: update-demo-nautilus-7sgsc is created but not running
Aug  2 10:56:41.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zwx7x'
Aug  2 10:56:41.794: INFO: stderr: ""
Aug  2 10:56:41.794: INFO: stdout: "update-demo-nautilus-7sgsc update-demo-nautilus-nwfzn "
Aug  2 10:56:41.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods update-demo-nautilus-7sgsc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zwx7x'
Aug  2 10:56:41.925: INFO: stderr: ""
Aug  2 10:56:41.926: INFO: stdout: ""
Aug  2 10:56:41.926: INFO: update-demo-nautilus-7sgsc is created but not running
Aug  2 10:56:46.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zwx7x'
Aug  2 10:56:47.047: INFO: stderr: ""
Aug  2 10:56:47.048: INFO: stdout: "update-demo-nautilus-7sgsc update-demo-nautilus-nwfzn "
Aug  2 10:56:47.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods update-demo-nautilus-7sgsc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zwx7x'
Aug  2 10:56:47.162: INFO: stderr: ""
Aug  2 10:56:47.162: INFO: stdout: ""
Aug  2 10:56:47.162: INFO: update-demo-nautilus-7sgsc is created but not running
Aug  2 10:56:52.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zwx7x'
Aug  2 10:56:52.289: INFO: stderr: ""
Aug  2 10:56:52.289: INFO: stdout: "update-demo-nautilus-7sgsc update-demo-nautilus-nwfzn "
Aug  2 10:56:52.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods update-demo-nautilus-7sgsc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zwx7x'
Aug  2 10:56:52.453: INFO: stderr: ""
Aug  2 10:56:52.453: INFO: stdout: "true"
Aug  2 10:56:52.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods update-demo-nautilus-7sgsc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zwx7x'
Aug  2 10:56:52.578: INFO: stderr: ""
Aug  2 10:56:52.578: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug  2 10:56:52.578: INFO: validating pod update-demo-nautilus-7sgsc
Aug  2 10:56:52.584: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  2 10:56:52.584: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  2 10:56:52.584: INFO: update-demo-nautilus-7sgsc is verified up and running
Aug  2 10:56:52.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods update-demo-nautilus-nwfzn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zwx7x'
Aug  2 10:56:52.719: INFO: stderr: ""
Aug  2 10:56:52.719: INFO: stdout: ""
Aug  2 10:56:52.719: INFO: update-demo-nautilus-nwfzn is created but not running
Aug  2 10:56:57.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zwx7x'
Aug  2 10:56:58.126: INFO: stderr: ""
Aug  2 10:56:58.126: INFO: stdout: "update-demo-nautilus-7sgsc update-demo-nautilus-nwfzn "
Aug  2 10:56:58.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods update-demo-nautilus-7sgsc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zwx7x'
Aug  2 10:56:58.251: INFO: stderr: ""
Aug  2 10:56:58.251: INFO: stdout: "true"
Aug  2 10:56:58.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods update-demo-nautilus-7sgsc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zwx7x'
Aug  2 10:56:58.403: INFO: stderr: ""
Aug  2 10:56:58.403: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug  2 10:56:58.403: INFO: validating pod update-demo-nautilus-7sgsc
Aug  2 10:56:58.407: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  2 10:56:58.407: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  2 10:56:58.407: INFO: update-demo-nautilus-7sgsc is verified up and running
Aug  2 10:56:58.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods update-demo-nautilus-nwfzn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zwx7x'
Aug  2 10:56:58.524: INFO: stderr: ""
Aug  2 10:56:58.524: INFO: stdout: "true"
Aug  2 10:56:58.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods update-demo-nautilus-nwfzn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zwx7x'
Aug  2 10:56:58.631: INFO: stderr: ""
Aug  2 10:56:58.631: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug  2 10:56:58.631: INFO: validating pod update-demo-nautilus-nwfzn
Aug  2 10:56:58.640: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  2 10:56:58.640: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  2 10:56:58.640: INFO: update-demo-nautilus-nwfzn is verified up and running
STEP: using delete to clean up resources
Aug  2 10:56:58.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-zwx7x'
Aug  2 10:56:58.778: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  2 10:56:58.778: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug  2 10:56:58.778: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-zwx7x'
Aug  2 10:56:58.936: INFO: stderr: "No resources found.\n"
Aug  2 10:56:58.936: INFO: stdout: ""
Aug  2 10:56:58.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods -l name=update-demo --namespace=e2e-tests-kubectl-zwx7x -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug  2 10:56:59.080: INFO: stderr: ""
Aug  2 10:56:59.080: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:56:59.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zwx7x" for this suite.
Aug  2 10:57:05.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:57:05.164: INFO: namespace: e2e-tests-kubectl-zwx7x, resource: bindings, ignored listing per whitelist
Aug  2 10:57:05.203: INFO: namespace e2e-tests-kubectl-zwx7x deletion completed in 6.116959817s

• [SLOW TEST:29.100 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:57:05.203: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Aug  2 10:57:05.318: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:57:08.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-bwvsm" for this suite.
Aug  2 10:57:14.170: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:57:14.287: INFO: namespace: e2e-tests-init-container-bwvsm, resource: bindings, ignored listing per whitelist
Aug  2 10:57:14.306: INFO: namespace e2e-tests-init-container-bwvsm deletion completed in 6.149575101s

• [SLOW TEST:9.103 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:57:14.307: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-jbcbx
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-jbcbx to expose endpoints map[]
Aug  2 10:57:14.406: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-jbcbx exposes endpoints map[] (14.602094ms elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-jbcbx
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-jbcbx to expose endpoints map[pod1:[100]]
Aug  2 10:57:16.444: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-jbcbx exposes endpoints map[pod1:[100]] (2.025166631s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-jbcbx
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-jbcbx to expose endpoints map[pod1:[100] pod2:[101]]
Aug  2 10:57:19.497: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-jbcbx exposes endpoints map[pod1:[100] pod2:[101]] (3.049415705s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-jbcbx
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-jbcbx to expose endpoints map[pod2:[101]]
Aug  2 10:57:19.517: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-jbcbx exposes endpoints map[pod2:[101]] (12.915842ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-jbcbx
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-jbcbx to expose endpoints map[]
Aug  2 10:57:20.531: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-jbcbx exposes endpoints map[] (1.008603779s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:57:20.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-jbcbx" for this suite.
Aug  2 10:57:42.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:57:42.653: INFO: namespace: e2e-tests-services-jbcbx, resource: bindings, ignored listing per whitelist
Aug  2 10:57:42.672: INFO: namespace e2e-tests-services-jbcbx deletion completed in 22.120979159s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:28.366 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:57:42.674: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug  2 10:57:42.761: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5a20405c-b514-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-downward-api-4xp8c" to be "success or failure"
Aug  2 10:57:42.767: INFO: Pod "downwardapi-volume-5a20405c-b514-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.497236ms
Aug  2 10:57:44.771: INFO: Pod "downwardapi-volume-5a20405c-b514-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01033741s
Aug  2 10:57:46.775: INFO: Pod "downwardapi-volume-5a20405c-b514-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013713311s
STEP: Saw pod success
Aug  2 10:57:46.775: INFO: Pod "downwardapi-volume-5a20405c-b514-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 10:57:46.777: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod downwardapi-volume-5a20405c-b514-11e9-b8f5-0a4acaace53e container client-container: <nil>
STEP: delete the pod
Aug  2 10:57:46.800: INFO: Waiting for pod downwardapi-volume-5a20405c-b514-11e9-b8f5-0a4acaace53e to disappear
Aug  2 10:57:46.803: INFO: Pod downwardapi-volume-5a20405c-b514-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:57:46.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4xp8c" for this suite.
Aug  2 10:57:52.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:57:52.946: INFO: namespace: e2e-tests-downward-api-4xp8c, resource: bindings, ignored listing per whitelist
Aug  2 10:57:52.956: INFO: namespace e2e-tests-downward-api-4xp8c deletion completed in 6.149813289s

• [SLOW TEST:10.283 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:57:52.956: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-rg2sl.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-rg2sl.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-rg2sl.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-rg2sl.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-rg2sl.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-rg2sl.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug  2 10:58:27.082: INFO: Unable to read wheezy_udp@PodARecord from pod e2e-tests-dns-rg2sl/dns-test-60411bf0-b514-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-60411bf0-b514-11e9-b8f5-0a4acaace53e)
Aug  2 10:58:27.085: INFO: Unable to read wheezy_tcp@PodARecord from pod e2e-tests-dns-rg2sl/dns-test-60411bf0-b514-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-60411bf0-b514-11e9-b8f5-0a4acaace53e)
Aug  2 10:58:27.114: INFO: Unable to read jessie_udp@PodARecord from pod e2e-tests-dns-rg2sl/dns-test-60411bf0-b514-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-60411bf0-b514-11e9-b8f5-0a4acaace53e)
Aug  2 10:58:27.119: INFO: Unable to read jessie_tcp@PodARecord from pod e2e-tests-dns-rg2sl/dns-test-60411bf0-b514-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-60411bf0-b514-11e9-b8f5-0a4acaace53e)
Aug  2 10:58:27.119: INFO: Lookups using e2e-tests-dns-rg2sl/dns-test-60411bf0-b514-11e9-b8f5-0a4acaace53e failed for: [wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@PodARecord jessie_tcp@PodARecord]

Aug  2 10:58:32.153: INFO: Unable to read wheezy_udp@PodARecord from pod e2e-tests-dns-rg2sl/dns-test-60411bf0-b514-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-60411bf0-b514-11e9-b8f5-0a4acaace53e)
Aug  2 10:58:32.156: INFO: Unable to read wheezy_tcp@PodARecord from pod e2e-tests-dns-rg2sl/dns-test-60411bf0-b514-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-60411bf0-b514-11e9-b8f5-0a4acaace53e)
Aug  2 10:58:32.181: INFO: Unable to read jessie_udp@PodARecord from pod e2e-tests-dns-rg2sl/dns-test-60411bf0-b514-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-60411bf0-b514-11e9-b8f5-0a4acaace53e)
Aug  2 10:58:32.185: INFO: Unable to read jessie_tcp@PodARecord from pod e2e-tests-dns-rg2sl/dns-test-60411bf0-b514-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-60411bf0-b514-11e9-b8f5-0a4acaace53e)
Aug  2 10:58:32.185: INFO: Lookups using e2e-tests-dns-rg2sl/dns-test-60411bf0-b514-11e9-b8f5-0a4acaace53e failed for: [wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@PodARecord jessie_tcp@PodARecord]

Aug  2 10:58:37.184: INFO: DNS probes using e2e-tests-dns-rg2sl/dns-test-60411bf0-b514-11e9-b8f5-0a4acaace53e succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:58:37.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-rg2sl" for this suite.
Aug  2 10:58:43.223: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:58:43.345: INFO: namespace: e2e-tests-dns-rg2sl, resource: bindings, ignored listing per whitelist
Aug  2 10:58:43.370: INFO: namespace e2e-tests-dns-rg2sl deletion completed in 6.159208646s

• [SLOW TEST:50.414 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:58:43.371: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:58:45.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-2kml4" for this suite.
Aug  2 10:59:23.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:59:23.531: INFO: namespace: e2e-tests-kubelet-test-2kml4, resource: bindings, ignored listing per whitelist
Aug  2 10:59:23.596: INFO: namespace e2e-tests-kubelet-test-2kml4 deletion completed in 38.119998478s

• [SLOW TEST:40.225 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:59:23.596: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-9647b9f3-b514-11e9-b8f5-0a4acaace53e
STEP: Creating a pod to test consume secrets
Aug  2 10:59:23.688: INFO: Waiting up to 5m0s for pod "pod-secrets-964876cd-b514-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-secrets-kf4ht" to be "success or failure"
Aug  2 10:59:23.695: INFO: Pod "pod-secrets-964876cd-b514-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 7.441109ms
Aug  2 10:59:25.699: INFO: Pod "pod-secrets-964876cd-b514-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011341523s
Aug  2 10:59:28.004: INFO: Pod "pod-secrets-964876cd-b514-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.316697787s
STEP: Saw pod success
Aug  2 10:59:28.004: INFO: Pod "pod-secrets-964876cd-b514-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 10:59:28.007: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-secrets-964876cd-b514-11e9-b8f5-0a4acaace53e container secret-volume-test: <nil>
STEP: delete the pod
Aug  2 10:59:28.027: INFO: Waiting for pod pod-secrets-964876cd-b514-11e9-b8f5-0a4acaace53e to disappear
Aug  2 10:59:28.031: INFO: Pod pod-secrets-964876cd-b514-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 10:59:28.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-kf4ht" for this suite.
Aug  2 10:59:34.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 10:59:34.102: INFO: namespace: e2e-tests-secrets-kf4ht, resource: bindings, ignored listing per whitelist
Aug  2 10:59:34.155: INFO: namespace e2e-tests-secrets-kf4ht deletion completed in 6.120740158s

• [SLOW TEST:10.559 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 10:59:34.156: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-gp8mn
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Aug  2 10:59:34.306: INFO: Found 0 stateful pods, waiting for 3
Aug  2 10:59:44.310: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug  2 10:59:44.310: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug  2 10:59:44.310: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Aug  2 10:59:44.334: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Aug  2 10:59:54.366: INFO: Updating stateful set ss2
Aug  2 10:59:54.384: INFO: Waiting for Pod e2e-tests-statefulset-gp8mn/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Aug  2 11:00:04.464: INFO: Found 1 stateful pods, waiting for 3
Aug  2 11:00:14.469: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug  2 11:00:14.469: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug  2 11:00:14.469: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Aug  2 11:00:14.497: INFO: Updating stateful set ss2
Aug  2 11:00:14.510: INFO: Waiting for Pod e2e-tests-statefulset-gp8mn/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Aug  2 11:00:24.539: INFO: Updating stateful set ss2
Aug  2 11:00:24.555: INFO: Waiting for StatefulSet e2e-tests-statefulset-gp8mn/ss2 to complete update
Aug  2 11:00:24.556: INFO: Waiting for Pod e2e-tests-statefulset-gp8mn/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Aug  2 11:00:34.833: INFO: Deleting all statefulset in ns e2e-tests-statefulset-gp8mn
Aug  2 11:00:34.837: INFO: Scaling statefulset ss2 to 0
Aug  2 11:00:44.857: INFO: Waiting for statefulset status.replicas updated to 0
Aug  2 11:00:44.860: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:00:44.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-gp8mn" for this suite.
Aug  2 11:00:50.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:00:50.958: INFO: namespace: e2e-tests-statefulset-gp8mn, resource: bindings, ignored listing per whitelist
Aug  2 11:00:51.038: INFO: namespace e2e-tests-statefulset-gp8mn deletion completed in 6.155425963s

• [SLOW TEST:76.882 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:00:51.040: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Aug  2 11:00:51.142: INFO: Waiting up to 5m0s for pod "pod-ca691229-b514-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-emptydir-jpbk9" to be "success or failure"
Aug  2 11:00:51.151: INFO: Pod "pod-ca691229-b514-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.607201ms
Aug  2 11:00:53.154: INFO: Pod "pod-ca691229-b514-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011859933s
STEP: Saw pod success
Aug  2 11:00:53.154: INFO: Pod "pod-ca691229-b514-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 11:00:53.156: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-ca691229-b514-11e9-b8f5-0a4acaace53e container test-container: <nil>
STEP: delete the pod
Aug  2 11:00:53.175: INFO: Waiting for pod pod-ca691229-b514-11e9-b8f5-0a4acaace53e to disappear
Aug  2 11:00:53.179: INFO: Pod pod-ca691229-b514-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:00:53.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jpbk9" for this suite.
Aug  2 11:00:59.192: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:00:59.268: INFO: namespace: e2e-tests-emptydir-jpbk9, resource: bindings, ignored listing per whitelist
Aug  2 11:00:59.320: INFO: namespace e2e-tests-emptydir-jpbk9 deletion completed in 6.138762774s

• [SLOW TEST:8.281 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:00:59.321: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug  2 11:00:59.453: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Aug  2 11:01:04.457: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug  2 11:01:04.457: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Aug  2 11:01:08.506: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-th47b,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-th47b/deployments/test-cleanup-deployment,UID:d25ce789-b514-11e9-9105-fa163e46117c,ResourceVersion:17414,Generation:1,CreationTimestamp:2019-08-02 11:01:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-08-02 11:01:04 +0000 UTC 2019-08-02 11:01:04 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-08-02 11:01:06 +0000 UTC 2019-08-02 11:01:04 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-7dbbfcf846" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Aug  2 11:01:08.509: INFO: New ReplicaSet "test-cleanup-deployment-7dbbfcf846" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-7dbbfcf846,GenerateName:,Namespace:e2e-tests-deployment-th47b,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-th47b/replicasets/test-cleanup-deployment-7dbbfcf846,UID:d25fca07-b514-11e9-9105-fa163e46117c,ResourceVersion:17405,Generation:1,CreationTimestamp:2019-08-02 11:01:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment d25ce789-b514-11e9-9105-fa163e46117c 0xc002533047 0xc002533048}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug  2 11:01:08.514: INFO: Pod "test-cleanup-deployment-7dbbfcf846-d72gp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-7dbbfcf846-d72gp,GenerateName:test-cleanup-deployment-7dbbfcf846-,Namespace:e2e-tests-deployment-th47b,SelfLink:/api/v1/namespaces/e2e-tests-deployment-th47b/pods/test-cleanup-deployment-7dbbfcf846-d72gp,UID:d2605897-b514-11e9-9105-fa163e46117c,ResourceVersion:17404,Generation:0,CreationTimestamp:2019-08-02 11:01:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-7dbbfcf846 d25fca07-b514-11e9-9105-fa163e46117c 0xc0021d2287 0xc0021d2288}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-m69mt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-m69mt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-m69mt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test-v1-13-7-gipwxthqfdpj-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021d22f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021d2310}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 11:01:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 11:01:06 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 11:01:06 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 11:01:04 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.11,PodIP:192.168.232.63,StartTime:2019-08-02 11:01:04 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-08-02 11:01:05 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://4591d983e15445010bdd55af9b0db130a3fe8bfa12ce0611db50e86e88e16e58}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:01:08.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-th47b" for this suite.
Aug  2 11:01:14.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:01:14.579: INFO: namespace: e2e-tests-deployment-th47b, resource: bindings, ignored listing per whitelist
Aug  2 11:01:14.652: INFO: namespace e2e-tests-deployment-th47b deletion completed in 6.125652319s

• [SLOW TEST:15.331 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:01:14.652: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Aug  2 11:01:14.746: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:01:15.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-ggf9s" for this suite.
Aug  2 11:01:21.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:01:21.864: INFO: namespace: e2e-tests-replication-controller-ggf9s, resource: bindings, ignored listing per whitelist
Aug  2 11:01:21.934: INFO: namespace e2e-tests-replication-controller-ggf9s deletion completed in 6.142986084s

• [SLOW TEST:7.282 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:01:21.935: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-dccfe287-b514-11e9-b8f5-0a4acaace53e
STEP: Creating a pod to test consume configMaps
Aug  2 11:01:22.019: INFO: Waiting up to 5m0s for pod "pod-configmaps-dcd0957c-b514-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-configmap-mjjh6" to be "success or failure"
Aug  2 11:01:22.025: INFO: Pod "pod-configmaps-dcd0957c-b514-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.9015ms
Aug  2 11:01:24.028: INFO: Pod "pod-configmaps-dcd0957c-b514-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009347108s
STEP: Saw pod success
Aug  2 11:01:24.029: INFO: Pod "pod-configmaps-dcd0957c-b514-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 11:01:24.031: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-configmaps-dcd0957c-b514-11e9-b8f5-0a4acaace53e container configmap-volume-test: <nil>
STEP: delete the pod
Aug  2 11:01:24.054: INFO: Waiting for pod pod-configmaps-dcd0957c-b514-11e9-b8f5-0a4acaace53e to disappear
Aug  2 11:01:24.060: INFO: Pod pod-configmaps-dcd0957c-b514-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:01:24.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-mjjh6" for this suite.
Aug  2 11:01:30.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:01:30.095: INFO: namespace: e2e-tests-configmap-mjjh6, resource: bindings, ignored listing per whitelist
Aug  2 11:01:30.193: INFO: namespace e2e-tests-configmap-mjjh6 deletion completed in 6.129030491s

• [SLOW TEST:8.258 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:01:30.193: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-e1bb37ae-b514-11e9-b8f5-0a4acaace53e
STEP: Creating a pod to test consume configMaps
Aug  2 11:01:30.271: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e1bbb757-b514-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-projected-m2v2c" to be "success or failure"
Aug  2 11:01:30.287: INFO: Pod "pod-projected-configmaps-e1bbb757-b514-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 15.72333ms
Aug  2 11:01:32.307: INFO: Pod "pod-projected-configmaps-e1bbb757-b514-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.035999795s
STEP: Saw pod success
Aug  2 11:01:32.307: INFO: Pod "pod-projected-configmaps-e1bbb757-b514-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 11:01:32.310: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-projected-configmaps-e1bbb757-b514-11e9-b8f5-0a4acaace53e container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug  2 11:01:32.338: INFO: Waiting for pod pod-projected-configmaps-e1bbb757-b514-11e9-b8f5-0a4acaace53e to disappear
Aug  2 11:01:32.342: INFO: Pod pod-projected-configmaps-e1bbb757-b514-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:01:32.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-m2v2c" for this suite.
Aug  2 11:01:38.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:01:38.387: INFO: namespace: e2e-tests-projected-m2v2c, resource: bindings, ignored listing per whitelist
Aug  2 11:01:38.479: INFO: namespace e2e-tests-projected-m2v2c deletion completed in 6.13433842s

• [SLOW TEST:8.286 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:01:38.479: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-fdrct
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-fdrct to expose endpoints map[]
Aug  2 11:01:38.565: INFO: Get endpoints failed (5.684553ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Aug  2 11:01:39.569: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-fdrct exposes endpoints map[] (1.009349953s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-fdrct
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-fdrct to expose endpoints map[pod1:[80]]
Aug  2 11:01:42.607: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-fdrct exposes endpoints map[pod1:[80]] (3.031610448s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-fdrct
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-fdrct to expose endpoints map[pod1:[80] pod2:[80]]
Aug  2 11:01:45.638: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-fdrct exposes endpoints map[pod1:[80] pod2:[80]] (3.028529401s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-fdrct
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-fdrct to expose endpoints map[pod2:[80]]
Aug  2 11:01:45.651: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-fdrct exposes endpoints map[pod2:[80]] (8.120162ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-fdrct
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-fdrct to expose endpoints map[]
Aug  2 11:01:46.664: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-fdrct exposes endpoints map[] (1.007128722s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:01:46.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-fdrct" for this suite.
Aug  2 11:02:08.696: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:02:08.724: INFO: namespace: e2e-tests-services-fdrct, resource: bindings, ignored listing per whitelist
Aug  2 11:02:09.513: INFO: namespace e2e-tests-services-fdrct deletion completed in 22.827759579s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:31.034 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:02:09.515: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:02:13.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-xd2vg" for this suite.
Aug  2 11:02:51.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:02:51.718: INFO: namespace: e2e-tests-kubelet-test-xd2vg, resource: bindings, ignored listing per whitelist
Aug  2 11:02:51.765: INFO: namespace e2e-tests-kubelet-test-xd2vg deletion completed in 38.137989542s

• [SLOW TEST:42.251 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:02:51.766: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Aug  2 11:02:58.103: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  2 11:02:58.109: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  2 11:03:00.110: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  2 11:03:00.113: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  2 11:03:02.110: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  2 11:03:02.114: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  2 11:03:04.110: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  2 11:03:04.113: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  2 11:03:06.110: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  2 11:03:06.113: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  2 11:03:08.110: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  2 11:03:08.115: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  2 11:03:10.110: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  2 11:03:10.113: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  2 11:03:12.110: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  2 11:03:12.114: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  2 11:03:14.110: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  2 11:03:14.113: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  2 11:03:16.110: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  2 11:03:16.114: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:03:16.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-wjjdx" for this suite.
Aug  2 11:03:38.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:03:38.209: INFO: namespace: e2e-tests-container-lifecycle-hook-wjjdx, resource: bindings, ignored listing per whitelist
Aug  2 11:03:38.279: INFO: namespace e2e-tests-container-lifecycle-hook-wjjdx deletion completed in 22.160975032s

• [SLOW TEST:46.513 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:03:38.280: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0802 11:03:48.432205      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug  2 11:03:48.432: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:03:48.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-2w254" for this suite.
Aug  2 11:03:54.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:03:54.527: INFO: namespace: e2e-tests-gc-2w254, resource: bindings, ignored listing per whitelist
Aug  2 11:03:54.591: INFO: namespace e2e-tests-gc-2w254 deletion completed in 6.154906835s

• [SLOW TEST:16.311 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:03:54.591: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug  2 11:03:54.820: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:03:56.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-vmfzw" for this suite.
Aug  2 11:04:36.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:04:37.034: INFO: namespace: e2e-tests-pods-vmfzw, resource: bindings, ignored listing per whitelist
Aug  2 11:04:37.103: INFO: namespace e2e-tests-pods-vmfzw deletion completed in 40.141119118s

• [SLOW TEST:42.512 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:04:37.104: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Aug  2 11:04:37.182: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-9w6nm,SelfLink:/api/v1/namespaces/e2e-tests-watch-9w6nm/configmaps/e2e-watch-test-watch-closed,UID:51247956-b515-11e9-9105-fa163e46117c,ResourceVersion:18111,Generation:0,CreationTimestamp:2019-08-02 11:04:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug  2 11:04:37.182: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-9w6nm,SelfLink:/api/v1/namespaces/e2e-tests-watch-9w6nm/configmaps/e2e-watch-test-watch-closed,UID:51247956-b515-11e9-9105-fa163e46117c,ResourceVersion:18112,Generation:0,CreationTimestamp:2019-08-02 11:04:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Aug  2 11:04:37.197: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-9w6nm,SelfLink:/api/v1/namespaces/e2e-tests-watch-9w6nm/configmaps/e2e-watch-test-watch-closed,UID:51247956-b515-11e9-9105-fa163e46117c,ResourceVersion:18113,Generation:0,CreationTimestamp:2019-08-02 11:04:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug  2 11:04:37.197: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-9w6nm,SelfLink:/api/v1/namespaces/e2e-tests-watch-9w6nm/configmaps/e2e-watch-test-watch-closed,UID:51247956-b515-11e9-9105-fa163e46117c,ResourceVersion:18114,Generation:0,CreationTimestamp:2019-08-02 11:04:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:04:37.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-9w6nm" for this suite.
Aug  2 11:04:43.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:04:43.294: INFO: namespace: e2e-tests-watch-9w6nm, resource: bindings, ignored listing per whitelist
Aug  2 11:04:43.330: INFO: namespace e2e-tests-watch-9w6nm deletion completed in 6.127293258s

• [SLOW TEST:6.226 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:04:43.331: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-647wg
Aug  2 11:04:45.424: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-647wg
STEP: checking the pod's current state and verifying that restartCount is present
Aug  2 11:04:45.426: INFO: Initial restart count of pod liveness-http is 0
Aug  2 11:05:01.456: INFO: Restart count of pod e2e-tests-container-probe-647wg/liveness-http is now 1 (16.029919605s elapsed)
Aug  2 11:05:20.484: INFO: Restart count of pod e2e-tests-container-probe-647wg/liveness-http is now 2 (35.058169252s elapsed)
Aug  2 11:05:41.130: INFO: Restart count of pod e2e-tests-container-probe-647wg/liveness-http is now 3 (55.704045917s elapsed)
Aug  2 11:06:01.180: INFO: Restart count of pod e2e-tests-container-probe-647wg/liveness-http is now 4 (1m15.753667133s elapsed)
Aug  2 11:07:11.467: INFO: Restart count of pod e2e-tests-container-probe-647wg/liveness-http is now 5 (2m26.041068838s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:07:11.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-647wg" for this suite.
Aug  2 11:07:17.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:07:17.596: INFO: namespace: e2e-tests-container-probe-647wg, resource: bindings, ignored listing per whitelist
Aug  2 11:07:17.630: INFO: namespace e2e-tests-container-probe-647wg deletion completed in 6.144028686s

• [SLOW TEST:154.299 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:07:17.630: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0802 11:07:23.768653      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug  2 11:07:23.768: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:07:23.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-nlfcv" for this suite.
Aug  2 11:07:29.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:07:29.885: INFO: namespace: e2e-tests-gc-nlfcv, resource: bindings, ignored listing per whitelist
Aug  2 11:07:29.900: INFO: namespace e2e-tests-gc-nlfcv deletion completed in 6.122703172s

• [SLOW TEST:12.270 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:07:29.901: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Aug  2 11:07:29.974: INFO: Waiting up to 5m0s for pod "var-expansion-b821e787-b515-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-var-expansion-7lnw9" to be "success or failure"
Aug  2 11:07:29.985: INFO: Pod "var-expansion-b821e787-b515-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.280601ms
Aug  2 11:07:31.989: INFO: Pod "var-expansion-b821e787-b515-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014224529s
Aug  2 11:07:33.993: INFO: Pod "var-expansion-b821e787-b515-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018343728s
STEP: Saw pod success
Aug  2 11:07:33.993: INFO: Pod "var-expansion-b821e787-b515-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 11:07:33.995: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod var-expansion-b821e787-b515-11e9-b8f5-0a4acaace53e container dapi-container: <nil>
STEP: delete the pod
Aug  2 11:07:34.019: INFO: Waiting for pod var-expansion-b821e787-b515-11e9-b8f5-0a4acaace53e to disappear
Aug  2 11:07:34.022: INFO: Pod var-expansion-b821e787-b515-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:07:34.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-7lnw9" for this suite.
Aug  2 11:07:40.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:07:40.142: INFO: namespace: e2e-tests-var-expansion-7lnw9, resource: bindings, ignored listing per whitelist
Aug  2 11:07:40.153: INFO: namespace e2e-tests-var-expansion-7lnw9 deletion completed in 6.127411011s

• [SLOW TEST:10.253 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:07:40.155: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Aug  2 11:07:42.813: INFO: Successfully updated pod "pod-update-be4712c6-b515-11e9-b8f5-0a4acaace53e"
STEP: verifying the updated pod is in kubernetes
Aug  2 11:07:42.824: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:07:42.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-tghht" for this suite.
Aug  2 11:08:04.843: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:08:04.927: INFO: namespace: e2e-tests-pods-tghht, resource: bindings, ignored listing per whitelist
Aug  2 11:08:04.996: INFO: namespace e2e-tests-pods-tghht deletion completed in 22.166230409s

• [SLOW TEST:24.840 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:08:04.996: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Aug  2 11:08:05.096: INFO: namespace e2e-tests-kubectl-tnx4f
Aug  2 11:08:05.096: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 create -f - --namespace=e2e-tests-kubectl-tnx4f'
Aug  2 11:08:05.703: INFO: stderr: ""
Aug  2 11:08:05.703: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug  2 11:08:06.708: INFO: Selector matched 1 pods for map[app:redis]
Aug  2 11:08:06.708: INFO: Found 0 / 1
Aug  2 11:08:07.707: INFO: Selector matched 1 pods for map[app:redis]
Aug  2 11:08:07.707: INFO: Found 0 / 1
Aug  2 11:08:08.707: INFO: Selector matched 1 pods for map[app:redis]
Aug  2 11:08:08.707: INFO: Found 1 / 1
Aug  2 11:08:08.707: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug  2 11:08:08.709: INFO: Selector matched 1 pods for map[app:redis]
Aug  2 11:08:08.709: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug  2 11:08:08.709: INFO: wait on redis-master startup in e2e-tests-kubectl-tnx4f 
Aug  2 11:08:08.709: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 logs redis-master-w2zx6 redis-master --namespace=e2e-tests-kubectl-tnx4f'
Aug  2 11:08:08.857: INFO: stderr: ""
Aug  2 11:08:08.857: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 02 Aug 11:08:06.884 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 02 Aug 11:08:06.884 # Server started, Redis version 3.2.12\n1:M 02 Aug 11:08:06.885 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 02 Aug 11:08:06.885 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Aug  2 11:08:08.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-tnx4f'
Aug  2 11:08:08.986: INFO: stderr: ""
Aug  2 11:08:08.986: INFO: stdout: "service/rm2 exposed\n"
Aug  2 11:08:08.990: INFO: Service rm2 in namespace e2e-tests-kubectl-tnx4f found.
STEP: exposing service
Aug  2 11:08:10.997: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-tnx4f'
Aug  2 11:08:11.172: INFO: stderr: ""
Aug  2 11:08:11.172: INFO: stdout: "service/rm3 exposed\n"
Aug  2 11:08:11.179: INFO: Service rm3 in namespace e2e-tests-kubectl-tnx4f found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:08:13.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tnx4f" for this suite.
Aug  2 11:08:35.201: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:08:35.339: INFO: namespace: e2e-tests-kubectl-tnx4f, resource: bindings, ignored listing per whitelist
Aug  2 11:08:35.341: INFO: namespace e2e-tests-kubectl-tnx4f deletion completed in 22.152052421s

• [SLOW TEST:30.346 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:08:35.342: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:08:39.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-k4cpj" for this suite.
Aug  2 11:09:17.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:09:17.929: INFO: namespace: e2e-tests-kubelet-test-k4cpj, resource: bindings, ignored listing per whitelist
Aug  2 11:09:17.933: INFO: namespace e2e-tests-kubelet-test-k4cpj deletion completed in 38.161166111s

• [SLOW TEST:42.591 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:09:17.935: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug  2 11:09:18.010: INFO: Creating deployment "test-recreate-deployment"
Aug  2 11:09:18.016: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Aug  2 11:09:18.043: INFO: Waiting deployment "test-recreate-deployment" to complete
Aug  2 11:09:18.049: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700340958, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700340958, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700340958, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700340958, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-5dfdcc846d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  2 11:09:20.052: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Aug  2 11:09:20.059: INFO: Updating deployment test-recreate-deployment
Aug  2 11:09:20.059: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Aug  2 11:09:20.206: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-h4csf,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-h4csf/deployments/test-recreate-deployment,UID:f888d154-b515-11e9-9105-fa163e46117c,ResourceVersion:19064,Generation:2,CreationTimestamp:2019-08-02 11:09:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-08-02 11:09:20 +0000 UTC 2019-08-02 11:09:20 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-08-02 11:09:20 +0000 UTC 2019-08-02 11:09:18 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Aug  2 11:09:20.209: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-h4csf,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-h4csf/replicasets/test-recreate-deployment-697fbf54bf,UID:f9d29cc7-b515-11e9-9105-fa163e46117c,ResourceVersion:19063,Generation:1,CreationTimestamp:2019-08-02 11:09:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment f888d154-b515-11e9-9105-fa163e46117c 0xc0022bb377 0xc0022bb378}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug  2 11:09:20.209: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Aug  2 11:09:20.209: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-h4csf,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-h4csf/replicasets/test-recreate-deployment-5dfdcc846d,UID:f889462d-b515-11e9-9105-fa163e46117c,ResourceVersion:19053,Generation:2,CreationTimestamp:2019-08-02 11:09:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment f888d154-b515-11e9-9105-fa163e46117c 0xc0022bb2a7 0xc0022bb2a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug  2 11:09:20.213: INFO: Pod "test-recreate-deployment-697fbf54bf-r24p5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-r24p5,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-h4csf,SelfLink:/api/v1/namespaces/e2e-tests-deployment-h4csf/pods/test-recreate-deployment-697fbf54bf-r24p5,UID:f9d2f74f-b515-11e9-9105-fa163e46117c,ResourceVersion:19065,Generation:0,CreationTimestamp:2019-08-02 11:09:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf f9d29cc7-b515-11e9-9105-fa163e46117c 0xc0021d25e7 0xc0021d25e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zqgh8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zqgh8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-zqgh8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test-v1-13-7-gipwxthqfdpj-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021d2650} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021d26d0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 11:09:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-02 11:09:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-02 11:09:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 11:09:20 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.11,PodIP:,StartTime:2019-08-02 11:09:20 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:09:20.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-h4csf" for this suite.
Aug  2 11:09:26.227: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:09:26.238: INFO: namespace: e2e-tests-deployment-h4csf, resource: bindings, ignored listing per whitelist
Aug  2 11:09:27.266: INFO: namespace e2e-tests-deployment-h4csf deletion completed in 7.049866354s

• [SLOW TEST:9.331 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:09:27.267: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Aug  2 11:09:27.361: INFO: Waiting up to 5m0s for pod "downward-api-fe196f2f-b515-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-downward-api-8p5km" to be "success or failure"
Aug  2 11:09:27.366: INFO: Pod "downward-api-fe196f2f-b515-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.492098ms
Aug  2 11:09:29.370: INFO: Pod "downward-api-fe196f2f-b515-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009480316s
STEP: Saw pod success
Aug  2 11:09:29.370: INFO: Pod "downward-api-fe196f2f-b515-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 11:09:29.372: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod downward-api-fe196f2f-b515-11e9-b8f5-0a4acaace53e container dapi-container: <nil>
STEP: delete the pod
Aug  2 11:09:29.402: INFO: Waiting for pod downward-api-fe196f2f-b515-11e9-b8f5-0a4acaace53e to disappear
Aug  2 11:09:29.405: INFO: Pod downward-api-fe196f2f-b515-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:09:29.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-8p5km" for this suite.
Aug  2 11:09:35.424: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:09:35.445: INFO: namespace: e2e-tests-downward-api-8p5km, resource: bindings, ignored listing per whitelist
Aug  2 11:09:35.540: INFO: namespace e2e-tests-downward-api-8p5km deletion completed in 6.127927834s

• [SLOW TEST:8.274 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:09:35.541: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-nk2p
STEP: Creating a pod to test atomic-volume-subpath
Aug  2 11:09:35.642: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-nk2p" in namespace "e2e-tests-subpath-vjmgh" to be "success or failure"
Aug  2 11:09:35.648: INFO: Pod "pod-subpath-test-configmap-nk2p": Phase="Pending", Reason="", readiness=false. Elapsed: 5.916659ms
Aug  2 11:09:37.690: INFO: Pod "pod-subpath-test-configmap-nk2p": Phase="Pending", Reason="", readiness=false. Elapsed: 2.047556274s
Aug  2 11:09:39.694: INFO: Pod "pod-subpath-test-configmap-nk2p": Phase="Running", Reason="", readiness=false. Elapsed: 4.051795024s
Aug  2 11:09:41.699: INFO: Pod "pod-subpath-test-configmap-nk2p": Phase="Running", Reason="", readiness=false. Elapsed: 6.056609401s
Aug  2 11:09:43.713: INFO: Pod "pod-subpath-test-configmap-nk2p": Phase="Running", Reason="", readiness=false. Elapsed: 8.0704235s
Aug  2 11:09:45.718: INFO: Pod "pod-subpath-test-configmap-nk2p": Phase="Running", Reason="", readiness=false. Elapsed: 10.075519794s
Aug  2 11:09:47.722: INFO: Pod "pod-subpath-test-configmap-nk2p": Phase="Running", Reason="", readiness=false. Elapsed: 12.079323792s
Aug  2 11:09:51.030: INFO: Pod "pod-subpath-test-configmap-nk2p": Phase="Running", Reason="", readiness=false. Elapsed: 15.387397732s
Aug  2 11:09:53.034: INFO: Pod "pod-subpath-test-configmap-nk2p": Phase="Running", Reason="", readiness=false. Elapsed: 17.391777759s
Aug  2 11:09:55.038: INFO: Pod "pod-subpath-test-configmap-nk2p": Phase="Running", Reason="", readiness=false. Elapsed: 19.395570282s
Aug  2 11:09:57.041: INFO: Pod "pod-subpath-test-configmap-nk2p": Phase="Running", Reason="", readiness=false. Elapsed: 21.398987693s
Aug  2 11:09:59.046: INFO: Pod "pod-subpath-test-configmap-nk2p": Phase="Succeeded", Reason="", readiness=false. Elapsed: 23.403967896s
STEP: Saw pod success
Aug  2 11:09:59.046: INFO: Pod "pod-subpath-test-configmap-nk2p" satisfied condition "success or failure"
Aug  2 11:09:59.051: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-subpath-test-configmap-nk2p container test-container-subpath-configmap-nk2p: <nil>
STEP: delete the pod
Aug  2 11:09:59.099: INFO: Waiting for pod pod-subpath-test-configmap-nk2p to disappear
Aug  2 11:09:59.108: INFO: Pod pod-subpath-test-configmap-nk2p no longer exists
STEP: Deleting pod pod-subpath-test-configmap-nk2p
Aug  2 11:09:59.109: INFO: Deleting pod "pod-subpath-test-configmap-nk2p" in namespace "e2e-tests-subpath-vjmgh"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:09:59.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-vjmgh" for this suite.
Aug  2 11:10:05.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:10:05.257: INFO: namespace: e2e-tests-subpath-vjmgh, resource: bindings, ignored listing per whitelist
Aug  2 11:10:05.257: INFO: namespace e2e-tests-subpath-vjmgh deletion completed in 6.142733604s

• [SLOW TEST:29.716 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:10:05.258: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug  2 11:10:05.676: INFO: Waiting up to 5m0s for pod "downwardapi-volume-14f00815-b516-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-projected-plfcg" to be "success or failure"
Aug  2 11:10:05.680: INFO: Pod "downwardapi-volume-14f00815-b516-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.588928ms
Aug  2 11:10:07.684: INFO: Pod "downwardapi-volume-14f00815-b516-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007806175s
Aug  2 11:10:09.755: INFO: Pod "downwardapi-volume-14f00815-b516-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.078834604s
STEP: Saw pod success
Aug  2 11:10:09.755: INFO: Pod "downwardapi-volume-14f00815-b516-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 11:10:09.760: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod downwardapi-volume-14f00815-b516-11e9-b8f5-0a4acaace53e container client-container: <nil>
STEP: delete the pod
Aug  2 11:10:09.834: INFO: Waiting for pod downwardapi-volume-14f00815-b516-11e9-b8f5-0a4acaace53e to disappear
Aug  2 11:10:09.839: INFO: Pod downwardapi-volume-14f00815-b516-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:10:09.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-plfcg" for this suite.
Aug  2 11:10:15.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:10:15.937: INFO: namespace: e2e-tests-projected-plfcg, resource: bindings, ignored listing per whitelist
Aug  2 11:10:15.989: INFO: namespace e2e-tests-projected-plfcg deletion completed in 6.146963371s

• [SLOW TEST:10.731 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:10:15.989: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-1b23724e-b516-11e9-b8f5-0a4acaace53e
STEP: Creating a pod to test consume configMaps
Aug  2 11:10:16.091: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1b245c42-b516-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-projected-47c2f" to be "success or failure"
Aug  2 11:10:16.102: INFO: Pod "pod-projected-configmaps-1b245c42-b516-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.701011ms
Aug  2 11:10:18.109: INFO: Pod "pod-projected-configmaps-1b245c42-b516-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017193192s
STEP: Saw pod success
Aug  2 11:10:18.109: INFO: Pod "pod-projected-configmaps-1b245c42-b516-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 11:10:18.111: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-projected-configmaps-1b245c42-b516-11e9-b8f5-0a4acaace53e container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug  2 11:10:18.148: INFO: Waiting for pod pod-projected-configmaps-1b245c42-b516-11e9-b8f5-0a4acaace53e to disappear
Aug  2 11:10:18.153: INFO: Pod pod-projected-configmaps-1b245c42-b516-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:10:18.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-47c2f" for this suite.
Aug  2 11:10:24.179: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:10:24.266: INFO: namespace: e2e-tests-projected-47c2f, resource: bindings, ignored listing per whitelist
Aug  2 11:10:24.741: INFO: namespace e2e-tests-projected-47c2f deletion completed in 6.5855356s

• [SLOW TEST:8.752 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:10:24.743: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:10:24.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-5zcz7" for this suite.
Aug  2 11:10:32.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:10:32.941: INFO: namespace: e2e-tests-kubelet-test-5zcz7, resource: bindings, ignored listing per whitelist
Aug  2 11:10:33.004: INFO: namespace e2e-tests-kubelet-test-5zcz7 deletion completed in 8.149687719s

• [SLOW TEST:8.261 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:10:33.005: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug  2 11:10:33.130: INFO: Waiting up to 5m0s for pod "downwardapi-volume-254d4c15-b516-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-downward-api-8fm9h" to be "success or failure"
Aug  2 11:10:33.137: INFO: Pod "downwardapi-volume-254d4c15-b516-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 7.452194ms
Aug  2 11:10:35.141: INFO: Pod "downwardapi-volume-254d4c15-b516-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010897533s
STEP: Saw pod success
Aug  2 11:10:35.141: INFO: Pod "downwardapi-volume-254d4c15-b516-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 11:10:35.144: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod downwardapi-volume-254d4c15-b516-11e9-b8f5-0a4acaace53e container client-container: <nil>
STEP: delete the pod
Aug  2 11:10:35.167: INFO: Waiting for pod downwardapi-volume-254d4c15-b516-11e9-b8f5-0a4acaace53e to disappear
Aug  2 11:10:35.171: INFO: Pod downwardapi-volume-254d4c15-b516-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:10:35.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-8fm9h" for this suite.
Aug  2 11:10:41.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:10:41.353: INFO: namespace: e2e-tests-downward-api-8fm9h, resource: bindings, ignored listing per whitelist
Aug  2 11:10:41.356: INFO: namespace e2e-tests-downward-api-8fm9h deletion completed in 6.180230622s

• [SLOW TEST:8.351 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:10:41.356: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-gcrhl/configmap-test-2a4157c3-b516-11e9-b8f5-0a4acaace53e
STEP: Creating a pod to test consume configMaps
Aug  2 11:10:41.448: INFO: Waiting up to 5m0s for pod "pod-configmaps-2a42052d-b516-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-configmap-gcrhl" to be "success or failure"
Aug  2 11:10:41.465: INFO: Pod "pod-configmaps-2a42052d-b516-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 16.606108ms
Aug  2 11:10:43.790: INFO: Pod "pod-configmaps-2a42052d-b516-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.342450641s
STEP: Saw pod success
Aug  2 11:10:43.791: INFO: Pod "pod-configmaps-2a42052d-b516-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 11:10:43.799: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-configmaps-2a42052d-b516-11e9-b8f5-0a4acaace53e container env-test: <nil>
STEP: delete the pod
Aug  2 11:10:43.820: INFO: Waiting for pod pod-configmaps-2a42052d-b516-11e9-b8f5-0a4acaace53e to disappear
Aug  2 11:10:43.824: INFO: Pod pod-configmaps-2a42052d-b516-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:10:43.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-gcrhl" for this suite.
Aug  2 11:10:49.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:10:49.936: INFO: namespace: e2e-tests-configmap-gcrhl, resource: bindings, ignored listing per whitelist
Aug  2 11:10:49.961: INFO: namespace e2e-tests-configmap-gcrhl deletion completed in 6.134665505s

• [SLOW TEST:8.605 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:10:49.964: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Aug  2 11:10:50.093: INFO: Waiting up to 5m0s for pod "pod-2f69b38f-b516-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-emptydir-z8kbm" to be "success or failure"
Aug  2 11:10:50.099: INFO: Pod "pod-2f69b38f-b516-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.959539ms
Aug  2 11:10:52.103: INFO: Pod "pod-2f69b38f-b516-11e9-b8f5-0a4acaace53e": Phase="Running", Reason="", readiness=true. Elapsed: 2.00986956s
Aug  2 11:10:54.106: INFO: Pod "pod-2f69b38f-b516-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013224226s
STEP: Saw pod success
Aug  2 11:10:54.106: INFO: Pod "pod-2f69b38f-b516-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 11:10:54.108: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-2f69b38f-b516-11e9-b8f5-0a4acaace53e container test-container: <nil>
STEP: delete the pod
Aug  2 11:10:54.141: INFO: Waiting for pod pod-2f69b38f-b516-11e9-b8f5-0a4acaace53e to disappear
Aug  2 11:10:54.144: INFO: Pod pod-2f69b38f-b516-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:10:54.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-z8kbm" for this suite.
Aug  2 11:11:00.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:11:00.196: INFO: namespace: e2e-tests-emptydir-z8kbm, resource: bindings, ignored listing per whitelist
Aug  2 11:11:00.283: INFO: namespace e2e-tests-emptydir-z8kbm deletion completed in 6.136957732s

• [SLOW TEST:10.320 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:11:00.284: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:11:04.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-8gvlr" for this suite.
Aug  2 11:11:10.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:11:10.490: INFO: namespace: e2e-tests-kubelet-test-8gvlr, resource: bindings, ignored listing per whitelist
Aug  2 11:11:10.616: INFO: namespace e2e-tests-kubelet-test-8gvlr deletion completed in 6.155942665s

• [SLOW TEST:10.332 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:11:10.616: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-3bb2b1c5-b516-11e9-b8f5-0a4acaace53e
STEP: Creating a pod to test consume configMaps
Aug  2 11:11:10.709: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3bb36609-b516-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-projected-hxnl6" to be "success or failure"
Aug  2 11:11:10.713: INFO: Pod "pod-projected-configmaps-3bb36609-b516-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.590217ms
Aug  2 11:11:12.717: INFO: Pod "pod-projected-configmaps-3bb36609-b516-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007592621s
Aug  2 11:11:14.721: INFO: Pod "pod-projected-configmaps-3bb36609-b516-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011803398s
STEP: Saw pod success
Aug  2 11:11:14.721: INFO: Pod "pod-projected-configmaps-3bb36609-b516-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 11:11:14.725: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-projected-configmaps-3bb36609-b516-11e9-b8f5-0a4acaace53e container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug  2 11:11:14.747: INFO: Waiting for pod pod-projected-configmaps-3bb36609-b516-11e9-b8f5-0a4acaace53e to disappear
Aug  2 11:11:14.752: INFO: Pod pod-projected-configmaps-3bb36609-b516-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:11:14.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hxnl6" for this suite.
Aug  2 11:11:20.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:11:20.822: INFO: namespace: e2e-tests-projected-hxnl6, resource: bindings, ignored listing per whitelist
Aug  2 11:11:20.903: INFO: namespace e2e-tests-projected-hxnl6 deletion completed in 6.144992522s

• [SLOW TEST:10.287 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:11:20.905: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-41d44c8e-b516-11e9-b8f5-0a4acaace53e
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-41d44c8e-b516-11e9-b8f5-0a4acaace53e
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:12:55.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9jcw4" for this suite.
Aug  2 11:13:17.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:13:17.551: INFO: namespace: e2e-tests-configmap-9jcw4, resource: bindings, ignored listing per whitelist
Aug  2 11:13:17.613: INFO: namespace e2e-tests-configmap-9jcw4 deletion completed in 22.163575326s

• [SLOW TEST:116.708 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:13:17.615: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-2q9pt
I0802 11:13:17.694663      18 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-2q9pt, replica count: 1
I0802 11:13:18.745343      18 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0802 11:13:19.745590      18 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0802 11:13:20.745847      18 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug  2 11:13:20.856: INFO: Created: latency-svc-tckzt
Aug  2 11:13:20.868: INFO: Got endpoints: latency-svc-tckzt [22.56934ms]
Aug  2 11:13:20.904: INFO: Created: latency-svc-49qqx
Aug  2 11:13:20.914: INFO: Got endpoints: latency-svc-49qqx [45.722812ms]
Aug  2 11:13:20.914: INFO: Created: latency-svc-7snt5
Aug  2 11:13:20.924: INFO: Got endpoints: latency-svc-7snt5 [53.278481ms]
Aug  2 11:13:20.925: INFO: Created: latency-svc-r9tg7
Aug  2 11:13:20.935: INFO: Created: latency-svc-f75mj
Aug  2 11:13:20.940: INFO: Created: latency-svc-92fxc
Aug  2 11:13:20.948: INFO: Got endpoints: latency-svc-r9tg7 [77.60445ms]
Aug  2 11:13:20.956: INFO: Got endpoints: latency-svc-92fxc [86.172344ms]
Aug  2 11:13:20.956: INFO: Got endpoints: latency-svc-f75mj [86.295761ms]
Aug  2 11:13:20.958: INFO: Created: latency-svc-rlfgz
Aug  2 11:13:20.972: INFO: Created: latency-svc-sxmgr
Aug  2 11:13:20.974: INFO: Got endpoints: latency-svc-rlfgz [104.005823ms]
Aug  2 11:13:20.978: INFO: Got endpoints: latency-svc-sxmgr [107.41292ms]
Aug  2 11:13:20.978: INFO: Created: latency-svc-wdjjz
Aug  2 11:13:20.982: INFO: Got endpoints: latency-svc-wdjjz [111.083657ms]
Aug  2 11:13:20.988: INFO: Created: latency-svc-kzppb
Aug  2 11:13:20.994: INFO: Created: latency-svc-k28g2
Aug  2 11:13:20.996: INFO: Got endpoints: latency-svc-kzppb [125.528451ms]
Aug  2 11:13:21.005: INFO: Got endpoints: latency-svc-k28g2 [133.830606ms]
Aug  2 11:13:21.005: INFO: Created: latency-svc-vgs89
Aug  2 11:13:21.011: INFO: Got endpoints: latency-svc-vgs89 [140.501277ms]
Aug  2 11:13:21.011: INFO: Created: latency-svc-5x7sz
Aug  2 11:13:21.016: INFO: Created: latency-svc-jmlqh
Aug  2 11:13:21.023: INFO: Created: latency-svc-lhn2q
Aug  2 11:13:21.025: INFO: Got endpoints: latency-svc-jmlqh [153.868427ms]
Aug  2 11:13:21.025: INFO: Got endpoints: latency-svc-5x7sz [154.767796ms]
Aug  2 11:13:21.029: INFO: Created: latency-svc-fcd96
Aug  2 11:13:21.032: INFO: Got endpoints: latency-svc-lhn2q [21.180794ms]
Aug  2 11:13:21.037: INFO: Got endpoints: latency-svc-fcd96 [165.416061ms]
Aug  2 11:13:21.038: INFO: Created: latency-svc-z49xr
Aug  2 11:13:21.045: INFO: Created: latency-svc-bfnvw
Aug  2 11:13:21.045: INFO: Got endpoints: latency-svc-z49xr [174.22891ms]
Aug  2 11:13:21.051: INFO: Created: latency-svc-5d4hv
Aug  2 11:13:21.054: INFO: Got endpoints: latency-svc-bfnvw [139.531437ms]
Aug  2 11:13:21.064: INFO: Created: latency-svc-xg9wg
Aug  2 11:13:21.066: INFO: Got endpoints: latency-svc-5d4hv [142.644946ms]
Aug  2 11:13:21.071: INFO: Created: latency-svc-cj9j6
Aug  2 11:13:21.074: INFO: Got endpoints: latency-svc-xg9wg [126.112289ms]
Aug  2 11:13:21.080: INFO: Created: latency-svc-wzw9k
Aug  2 11:13:21.083: INFO: Got endpoints: latency-svc-cj9j6 [126.02224ms]
Aug  2 11:13:21.096: INFO: Created: latency-svc-fnkgs
Aug  2 11:13:21.096: INFO: Got endpoints: latency-svc-wzw9k [139.806673ms]
Aug  2 11:13:21.100: INFO: Created: latency-svc-zdksn
Aug  2 11:13:21.104: INFO: Got endpoints: latency-svc-fnkgs [130.004535ms]
Aug  2 11:13:21.106: INFO: Got endpoints: latency-svc-zdksn [126.813079ms]
Aug  2 11:13:21.111: INFO: Created: latency-svc-j4zpn
Aug  2 11:13:21.119: INFO: Got endpoints: latency-svc-j4zpn [137.148763ms]
Aug  2 11:13:21.126: INFO: Created: latency-svc-pkl8n
Aug  2 11:13:21.133: INFO: Created: latency-svc-z6t6z
Aug  2 11:13:21.134: INFO: Got endpoints: latency-svc-pkl8n [138.314076ms]
Aug  2 11:13:21.144: INFO: Got endpoints: latency-svc-z6t6z [138.560488ms]
Aug  2 11:13:21.144: INFO: Created: latency-svc-s6bg9
Aug  2 11:13:21.150: INFO: Got endpoints: latency-svc-s6bg9 [124.941896ms]
Aug  2 11:13:21.152: INFO: Created: latency-svc-p24bk
Aug  2 11:13:21.156: INFO: Got endpoints: latency-svc-p24bk [131.837192ms]
Aug  2 11:13:21.166: INFO: Created: latency-svc-fdqwq
Aug  2 11:13:21.171: INFO: Got endpoints: latency-svc-fdqwq [138.943024ms]
Aug  2 11:13:21.184: INFO: Created: latency-svc-zvk27
Aug  2 11:13:21.187: INFO: Created: latency-svc-zc5x9
Aug  2 11:13:21.189: INFO: Got endpoints: latency-svc-zc5x9 [152.757666ms]
Aug  2 11:13:21.192: INFO: Got endpoints: latency-svc-zvk27 [146.616926ms]
Aug  2 11:13:21.196: INFO: Created: latency-svc-b6glw
Aug  2 11:13:21.199: INFO: Created: latency-svc-68ncq
Aug  2 11:13:21.201: INFO: Got endpoints: latency-svc-68ncq [134.846954ms]
Aug  2 11:13:21.203: INFO: Got endpoints: latency-svc-b6glw [149.103692ms]
Aug  2 11:13:21.209: INFO: Created: latency-svc-hw49k
Aug  2 11:13:21.213: INFO: Got endpoints: latency-svc-hw49k [138.790248ms]
Aug  2 11:13:21.215: INFO: Created: latency-svc-bhk4q
Aug  2 11:13:21.217: INFO: Created: latency-svc-8v5c2
Aug  2 11:13:21.220: INFO: Got endpoints: latency-svc-bhk4q [137.444572ms]
Aug  2 11:13:21.223: INFO: Got endpoints: latency-svc-8v5c2 [126.164971ms]
Aug  2 11:13:21.228: INFO: Created: latency-svc-jln7d
Aug  2 11:13:21.231: INFO: Created: latency-svc-xxpdr
Aug  2 11:13:21.237: INFO: Created: latency-svc-7xtw8
Aug  2 11:13:21.240: INFO: Created: latency-svc-fk66x
Aug  2 11:13:21.249: INFO: Created: latency-svc-xlcjg
Aug  2 11:13:21.254: INFO: Created: latency-svc-2dggf
Aug  2 11:13:21.259: INFO: Created: latency-svc-4fxtv
Aug  2 11:13:21.263: INFO: Created: latency-svc-jbh9n
Aug  2 11:13:21.270: INFO: Got endpoints: latency-svc-jln7d [165.199121ms]
Aug  2 11:13:21.271: INFO: Created: latency-svc-4hwcn
Aug  2 11:13:21.279: INFO: Created: latency-svc-772dv
Aug  2 11:13:21.288: INFO: Created: latency-svc-2bnp8
Aug  2 11:13:21.299: INFO: Created: latency-svc-pksw2
Aug  2 11:13:21.301: INFO: Created: latency-svc-9r25d
Aug  2 11:13:21.304: INFO: Created: latency-svc-bwk5m
Aug  2 11:13:21.308: INFO: Created: latency-svc-lb2v9
Aug  2 11:13:21.311: INFO: Created: latency-svc-676jb
Aug  2 11:13:21.314: INFO: Got endpoints: latency-svc-xxpdr [208.173006ms]
Aug  2 11:13:21.322: INFO: Created: latency-svc-22nhq
Aug  2 11:13:21.363: INFO: Got endpoints: latency-svc-7xtw8 [243.646363ms]
Aug  2 11:13:21.371: INFO: Created: latency-svc-r47xd
Aug  2 11:13:21.413: INFO: Got endpoints: latency-svc-fk66x [278.892126ms]
Aug  2 11:13:21.423: INFO: Created: latency-svc-9cbnz
Aug  2 11:13:21.464: INFO: Got endpoints: latency-svc-xlcjg [320.112448ms]
Aug  2 11:13:21.472: INFO: Created: latency-svc-5whf8
Aug  2 11:13:21.513: INFO: Got endpoints: latency-svc-2dggf [363.292696ms]
Aug  2 11:13:21.521: INFO: Created: latency-svc-6tm4g
Aug  2 11:13:21.562: INFO: Got endpoints: latency-svc-4fxtv [405.77953ms]
Aug  2 11:13:21.573: INFO: Created: latency-svc-ns9r6
Aug  2 11:13:22.313: INFO: Got endpoints: latency-svc-jbh9n [1.141902904s]
Aug  2 11:13:22.323: INFO: Got endpoints: latency-svc-4hwcn [1.133429781s]
Aug  2 11:13:22.329: INFO: Got endpoints: latency-svc-9r25d [1.11624211s]
Aug  2 11:13:22.330: INFO: Got endpoints: latency-svc-2bnp8 [1.128207127s]
Aug  2 11:13:22.330: INFO: Got endpoints: latency-svc-pksw2 [1.126537485s]
Aug  2 11:13:22.330: INFO: Got endpoints: latency-svc-772dv [1.137765372s]
Aug  2 11:13:22.331: INFO: Got endpoints: latency-svc-bwk5m [1.111090781s]
Aug  2 11:13:22.339: INFO: Created: latency-svc-txhjh
Aug  2 11:13:22.347: INFO: Got endpoints: latency-svc-22nhq [1.03285926s]
Aug  2 11:13:22.347: INFO: Got endpoints: latency-svc-r47xd [984.160812ms]
Aug  2 11:13:22.347: INFO: Got endpoints: latency-svc-lb2v9 [1.124538332s]
Aug  2 11:13:22.348: INFO: Got endpoints: latency-svc-676jb [1.078369387s]
Aug  2 11:13:22.348: INFO: Got endpoints: latency-svc-9cbnz [934.713295ms]
Aug  2 11:13:22.352: INFO: Got endpoints: latency-svc-5whf8 [887.622315ms]
Aug  2 11:13:22.352: INFO: Got endpoints: latency-svc-6tm4g [838.506718ms]
Aug  2 11:13:22.358: INFO: Got endpoints: latency-svc-ns9r6 [794.98728ms]
Aug  2 11:13:22.359: INFO: Created: latency-svc-kw4x2
Aug  2 11:13:22.367: INFO: Got endpoints: latency-svc-txhjh [53.524819ms]
Aug  2 11:13:22.369: INFO: Created: latency-svc-n2ghb
Aug  2 11:13:22.378: INFO: Created: latency-svc-cxpbf
Aug  2 11:13:22.381: INFO: Created: latency-svc-ppsgl
Aug  2 11:13:22.386: INFO: Created: latency-svc-9mhg6
Aug  2 11:13:22.393: INFO: Created: latency-svc-2h5rq
Aug  2 11:13:22.400: INFO: Created: latency-svc-7l76t
Aug  2 11:13:22.414: INFO: Created: latency-svc-chvs2
Aug  2 11:13:22.454: INFO: Created: latency-svc-6mk25
Aug  2 11:13:22.458: INFO: Got endpoints: latency-svc-kw4x2 [134.969095ms]
Aug  2 11:13:22.465: INFO: Got endpoints: latency-svc-n2ghb [112.751117ms]
Aug  2 11:13:22.469: INFO: Created: latency-svc-xtfnn
Aug  2 11:13:22.473: INFO: Created: latency-svc-st7bf
Aug  2 11:13:22.474: INFO: Created: latency-svc-9gfg2
Aug  2 11:13:22.480: INFO: Created: latency-svc-fw7jq
Aug  2 11:13:22.491: INFO: Created: latency-svc-qskdw
Aug  2 11:13:22.498: INFO: Created: latency-svc-zxg5g
Aug  2 11:13:22.504: INFO: Created: latency-svc-8j6dc
Aug  2 11:13:22.508: INFO: Created: latency-svc-p5jzx
Aug  2 11:13:22.513: INFO: Got endpoints: latency-svc-cxpbf [184.047269ms]
Aug  2 11:13:22.539: INFO: Created: latency-svc-xbk9x
Aug  2 11:13:22.567: INFO: Got endpoints: latency-svc-ppsgl [237.118121ms]
Aug  2 11:13:22.578: INFO: Created: latency-svc-dwt57
Aug  2 11:13:22.613: INFO: Got endpoints: latency-svc-9mhg6 [282.983395ms]
Aug  2 11:13:22.620: INFO: Created: latency-svc-ntqmh
Aug  2 11:13:22.664: INFO: Got endpoints: latency-svc-2h5rq [333.716758ms]
Aug  2 11:13:22.682: INFO: Created: latency-svc-hj6sq
Aug  2 11:13:22.713: INFO: Got endpoints: latency-svc-7l76t [381.719371ms]
Aug  2 11:13:22.721: INFO: Created: latency-svc-nq26n
Aug  2 11:13:22.767: INFO: Got endpoints: latency-svc-chvs2 [420.361802ms]
Aug  2 11:13:22.789: INFO: Created: latency-svc-vmvhc
Aug  2 11:13:22.813: INFO: Got endpoints: latency-svc-6mk25 [465.690682ms]
Aug  2 11:13:22.823: INFO: Created: latency-svc-9xmfj
Aug  2 11:13:22.862: INFO: Got endpoints: latency-svc-9gfg2 [515.199132ms]
Aug  2 11:13:22.872: INFO: Created: latency-svc-jrxrw
Aug  2 11:13:22.915: INFO: Got endpoints: latency-svc-xtfnn [566.854648ms]
Aug  2 11:13:22.924: INFO: Created: latency-svc-x7f2b
Aug  2 11:13:22.963: INFO: Got endpoints: latency-svc-st7bf [613.407826ms]
Aug  2 11:13:22.973: INFO: Created: latency-svc-mgsgf
Aug  2 11:13:23.012: INFO: Got endpoints: latency-svc-fw7jq [660.798578ms]
Aug  2 11:13:23.019: INFO: Created: latency-svc-p9sx8
Aug  2 11:13:23.062: INFO: Got endpoints: latency-svc-qskdw [703.974075ms]
Aug  2 11:13:23.069: INFO: Created: latency-svc-2mn2k
Aug  2 11:13:23.112: INFO: Got endpoints: latency-svc-zxg5g [744.587054ms]
Aug  2 11:13:23.120: INFO: Created: latency-svc-lltjs
Aug  2 11:13:23.163: INFO: Got endpoints: latency-svc-8j6dc [704.933692ms]
Aug  2 11:13:23.172: INFO: Created: latency-svc-794ds
Aug  2 11:13:23.213: INFO: Got endpoints: latency-svc-p5jzx [748.682439ms]
Aug  2 11:13:23.222: INFO: Created: latency-svc-5r646
Aug  2 11:13:23.263: INFO: Got endpoints: latency-svc-xbk9x [749.675385ms]
Aug  2 11:13:23.273: INFO: Created: latency-svc-t6nvb
Aug  2 11:13:23.566: INFO: Got endpoints: latency-svc-vmvhc [798.62563ms]
Aug  2 11:13:23.566: INFO: Got endpoints: latency-svc-hj6sq [902.577018ms]
Aug  2 11:13:23.566: INFO: Got endpoints: latency-svc-nq26n [853.367852ms]
Aug  2 11:13:23.566: INFO: Got endpoints: latency-svc-dwt57 [999.485676ms]
Aug  2 11:13:23.566: INFO: Got endpoints: latency-svc-ntqmh [953.365471ms]
Aug  2 11:13:23.572: INFO: Got endpoints: latency-svc-9xmfj [758.593259ms]
Aug  2 11:13:23.580: INFO: Created: latency-svc-st57s
Aug  2 11:13:23.590: INFO: Created: latency-svc-dqfv8
Aug  2 11:13:23.600: INFO: Created: latency-svc-2lhnb
Aug  2 11:13:23.608: INFO: Created: latency-svc-kxthw
Aug  2 11:13:23.614: INFO: Created: latency-svc-vzlkl
Aug  2 11:13:23.621: INFO: Got endpoints: latency-svc-jrxrw [758.752267ms]
Aug  2 11:13:23.622: INFO: Created: latency-svc-kwxpp
Aug  2 11:13:23.633: INFO: Created: latency-svc-xf495
Aug  2 11:13:23.673: INFO: Got endpoints: latency-svc-x7f2b [757.881454ms]
Aug  2 11:13:23.683: INFO: Created: latency-svc-wk2n2
Aug  2 11:13:23.713: INFO: Got endpoints: latency-svc-mgsgf [750.351682ms]
Aug  2 11:13:23.721: INFO: Created: latency-svc-m9xkd
Aug  2 11:13:23.762: INFO: Got endpoints: latency-svc-p9sx8 [749.818545ms]
Aug  2 11:13:23.771: INFO: Created: latency-svc-g76hs
Aug  2 11:13:23.813: INFO: Got endpoints: latency-svc-2mn2k [751.342626ms]
Aug  2 11:13:23.822: INFO: Created: latency-svc-xtzbc
Aug  2 11:13:23.863: INFO: Got endpoints: latency-svc-lltjs [751.440426ms]
Aug  2 11:13:23.872: INFO: Created: latency-svc-sscbs
Aug  2 11:13:24.144: INFO: Got endpoints: latency-svc-5r646 [930.379761ms]
Aug  2 11:13:24.144: INFO: Got endpoints: latency-svc-794ds [980.875968ms]
Aug  2 11:13:24.153: INFO: Got endpoints: latency-svc-dqfv8 [586.52262ms]
Aug  2 11:13:24.154: INFO: Got endpoints: latency-svc-t6nvb [890.531914ms]
Aug  2 11:13:24.154: INFO: Got endpoints: latency-svc-st57s [587.738116ms]
Aug  2 11:13:24.157: INFO: Created: latency-svc-w5hlx
Aug  2 11:13:24.164: INFO: Got endpoints: latency-svc-2lhnb [597.000973ms]
Aug  2 11:13:24.167: INFO: Created: latency-svc-g5hvr
Aug  2 11:13:24.174: INFO: Created: latency-svc-jdc5m
Aug  2 11:13:24.183: INFO: Created: latency-svc-7bkm7
Aug  2 11:13:24.189: INFO: Created: latency-svc-nt6nb
Aug  2 11:13:24.194: INFO: Created: latency-svc-l57z9
Aug  2 11:13:24.213: INFO: Got endpoints: latency-svc-kxthw [646.476532ms]
Aug  2 11:13:24.225: INFO: Created: latency-svc-nkpv2
Aug  2 11:13:24.263: INFO: Got endpoints: latency-svc-vzlkl [696.285556ms]
Aug  2 11:13:24.272: INFO: Created: latency-svc-hmcsf
Aug  2 11:13:24.313: INFO: Got endpoints: latency-svc-kwxpp [740.805186ms]
Aug  2 11:13:24.320: INFO: Created: latency-svc-qhkmr
Aug  2 11:13:24.368: INFO: Got endpoints: latency-svc-xf495 [746.154416ms]
Aug  2 11:13:24.377: INFO: Created: latency-svc-w8wll
Aug  2 11:13:24.413: INFO: Got endpoints: latency-svc-wk2n2 [739.391747ms]
Aug  2 11:13:24.420: INFO: Created: latency-svc-7dqzx
Aug  2 11:13:24.463: INFO: Got endpoints: latency-svc-m9xkd [749.08914ms]
Aug  2 11:13:24.480: INFO: Created: latency-svc-862hk
Aug  2 11:13:24.514: INFO: Got endpoints: latency-svc-g76hs [751.398659ms]
Aug  2 11:13:24.522: INFO: Created: latency-svc-fts8t
Aug  2 11:13:24.562: INFO: Got endpoints: latency-svc-xtzbc [749.107313ms]
Aug  2 11:13:24.571: INFO: Created: latency-svc-mvsmm
Aug  2 11:13:24.613: INFO: Got endpoints: latency-svc-sscbs [749.387933ms]
Aug  2 11:13:24.620: INFO: Created: latency-svc-fwkmc
Aug  2 11:13:24.662: INFO: Got endpoints: latency-svc-w5hlx [518.572932ms]
Aug  2 11:13:24.670: INFO: Created: latency-svc-z9w96
Aug  2 11:13:24.713: INFO: Got endpoints: latency-svc-g5hvr [568.862141ms]
Aug  2 11:13:24.722: INFO: Created: latency-svc-fjw8w
Aug  2 11:13:24.763: INFO: Got endpoints: latency-svc-jdc5m [609.768734ms]
Aug  2 11:13:24.771: INFO: Created: latency-svc-6dqdz
Aug  2 11:13:24.815: INFO: Got endpoints: latency-svc-7bkm7 [661.18578ms]
Aug  2 11:13:24.825: INFO: Created: latency-svc-q2672
Aug  2 11:13:24.864: INFO: Got endpoints: latency-svc-nt6nb [710.29281ms]
Aug  2 11:13:24.875: INFO: Created: latency-svc-j7vmj
Aug  2 11:13:24.919: INFO: Got endpoints: latency-svc-l57z9 [755.540431ms]
Aug  2 11:13:24.933: INFO: Created: latency-svc-p5crw
Aug  2 11:13:24.963: INFO: Got endpoints: latency-svc-nkpv2 [749.402593ms]
Aug  2 11:13:24.971: INFO: Created: latency-svc-gtqvm
Aug  2 11:13:25.013: INFO: Got endpoints: latency-svc-hmcsf [749.681698ms]
Aug  2 11:13:25.035: INFO: Created: latency-svc-vrwm4
Aug  2 11:13:25.063: INFO: Got endpoints: latency-svc-qhkmr [750.31843ms]
Aug  2 11:13:25.071: INFO: Created: latency-svc-kkn67
Aug  2 11:13:25.114: INFO: Got endpoints: latency-svc-w8wll [746.671378ms]
Aug  2 11:13:25.129: INFO: Created: latency-svc-fh2hg
Aug  2 11:13:25.162: INFO: Got endpoints: latency-svc-7dqzx [749.607218ms]
Aug  2 11:13:25.172: INFO: Created: latency-svc-lpqjh
Aug  2 11:13:25.214: INFO: Got endpoints: latency-svc-862hk [750.896678ms]
Aug  2 11:13:25.224: INFO: Created: latency-svc-djv2h
Aug  2 11:13:25.286: INFO: Got endpoints: latency-svc-fts8t [772.295835ms]
Aug  2 11:13:25.295: INFO: Created: latency-svc-hhp9k
Aug  2 11:13:25.313: INFO: Got endpoints: latency-svc-mvsmm [750.675372ms]
Aug  2 11:13:25.322: INFO: Created: latency-svc-qs2s5
Aug  2 11:13:25.363: INFO: Got endpoints: latency-svc-fwkmc [750.667917ms]
Aug  2 11:13:25.375: INFO: Created: latency-svc-8mlp9
Aug  2 11:13:25.490: INFO: Got endpoints: latency-svc-fjw8w [777.113415ms]
Aug  2 11:13:25.490: INFO: Got endpoints: latency-svc-z9w96 [827.555966ms]
Aug  2 11:13:25.501: INFO: Created: latency-svc-fl2xm
Aug  2 11:13:25.507: INFO: Created: latency-svc-gr6n4
Aug  2 11:13:25.512: INFO: Got endpoints: latency-svc-6dqdz [749.477922ms]
Aug  2 11:13:25.521: INFO: Created: latency-svc-72l4r
Aug  2 11:13:25.565: INFO: Got endpoints: latency-svc-q2672 [749.794808ms]
Aug  2 11:13:25.573: INFO: Created: latency-svc-qhwf7
Aug  2 11:13:25.613: INFO: Got endpoints: latency-svc-j7vmj [748.690316ms]
Aug  2 11:13:25.622: INFO: Created: latency-svc-fjrrz
Aug  2 11:13:25.663: INFO: Got endpoints: latency-svc-p5crw [743.119575ms]
Aug  2 11:13:25.672: INFO: Created: latency-svc-d4qn6
Aug  2 11:13:25.718: INFO: Got endpoints: latency-svc-gtqvm [754.931052ms]
Aug  2 11:13:25.729: INFO: Created: latency-svc-rv8wl
Aug  2 11:13:25.763: INFO: Got endpoints: latency-svc-vrwm4 [749.600744ms]
Aug  2 11:13:25.774: INFO: Created: latency-svc-5wnzz
Aug  2 11:13:25.812: INFO: Got endpoints: latency-svc-kkn67 [748.932093ms]
Aug  2 11:13:25.826: INFO: Created: latency-svc-7ch6l
Aug  2 11:13:25.863: INFO: Got endpoints: latency-svc-fh2hg [748.184715ms]
Aug  2 11:13:25.872: INFO: Created: latency-svc-cs6m2
Aug  2 11:13:25.913: INFO: Got endpoints: latency-svc-lpqjh [750.24717ms]
Aug  2 11:13:25.921: INFO: Created: latency-svc-6rb4h
Aug  2 11:13:25.963: INFO: Got endpoints: latency-svc-djv2h [749.572985ms]
Aug  2 11:13:25.971: INFO: Created: latency-svc-2zrb9
Aug  2 11:13:26.014: INFO: Got endpoints: latency-svc-hhp9k [728.207555ms]
Aug  2 11:13:26.028: INFO: Created: latency-svc-5grcc
Aug  2 11:13:26.063: INFO: Got endpoints: latency-svc-qs2s5 [749.784891ms]
Aug  2 11:13:26.072: INFO: Created: latency-svc-4ngq5
Aug  2 11:13:26.113: INFO: Got endpoints: latency-svc-8mlp9 [749.46409ms]
Aug  2 11:13:26.121: INFO: Created: latency-svc-wwh7r
Aug  2 11:13:26.164: INFO: Got endpoints: latency-svc-fl2xm [674.39706ms]
Aug  2 11:13:26.174: INFO: Created: latency-svc-vdtzf
Aug  2 11:13:26.213: INFO: Got endpoints: latency-svc-gr6n4 [722.421409ms]
Aug  2 11:13:26.223: INFO: Created: latency-svc-dqww9
Aug  2 11:13:26.268: INFO: Got endpoints: latency-svc-72l4r [755.20596ms]
Aug  2 11:13:26.276: INFO: Created: latency-svc-kj8zm
Aug  2 11:13:26.312: INFO: Got endpoints: latency-svc-qhwf7 [747.360524ms]
Aug  2 11:13:26.322: INFO: Created: latency-svc-lsbzb
Aug  2 11:13:26.365: INFO: Got endpoints: latency-svc-fjrrz [751.723849ms]
Aug  2 11:13:26.380: INFO: Created: latency-svc-c25f2
Aug  2 11:13:26.413: INFO: Got endpoints: latency-svc-d4qn6 [749.901595ms]
Aug  2 11:13:26.425: INFO: Created: latency-svc-srsjq
Aug  2 11:13:26.463: INFO: Got endpoints: latency-svc-rv8wl [744.536358ms]
Aug  2 11:13:26.472: INFO: Created: latency-svc-nzxns
Aug  2 11:13:26.514: INFO: Got endpoints: latency-svc-5wnzz [751.061753ms]
Aug  2 11:13:26.523: INFO: Created: latency-svc-ds2wq
Aug  2 11:13:26.563: INFO: Got endpoints: latency-svc-7ch6l [750.438632ms]
Aug  2 11:13:26.572: INFO: Created: latency-svc-mpmd7
Aug  2 11:13:26.612: INFO: Got endpoints: latency-svc-cs6m2 [749.834951ms]
Aug  2 11:13:26.621: INFO: Created: latency-svc-vd5f8
Aug  2 11:13:26.663: INFO: Got endpoints: latency-svc-6rb4h [750.140841ms]
Aug  2 11:13:26.767: INFO: Got endpoints: latency-svc-2zrb9 [803.23556ms]
Aug  2 11:13:26.769: INFO: Created: latency-svc-hp5hd
Aug  2 11:13:26.776: INFO: Got endpoints: latency-svc-5grcc [761.475489ms]
Aug  2 11:13:26.778: INFO: Created: latency-svc-4smt4
Aug  2 11:13:26.786: INFO: Created: latency-svc-dxxdd
Aug  2 11:13:26.813: INFO: Got endpoints: latency-svc-4ngq5 [750.184988ms]
Aug  2 11:13:26.824: INFO: Created: latency-svc-hqxz2
Aug  2 11:13:26.932: INFO: Got endpoints: latency-svc-vdtzf [767.741675ms]
Aug  2 11:13:26.933: INFO: Got endpoints: latency-svc-wwh7r [819.554994ms]
Aug  2 11:13:26.952: INFO: Created: latency-svc-5ftq2
Aug  2 11:13:26.955: INFO: Created: latency-svc-xgr64
Aug  2 11:13:26.963: INFO: Got endpoints: latency-svc-dqww9 [750.113975ms]
Aug  2 11:13:26.972: INFO: Created: latency-svc-5mf7s
Aug  2 11:13:27.014: INFO: Got endpoints: latency-svc-kj8zm [745.712315ms]
Aug  2 11:13:27.029: INFO: Created: latency-svc-hdpqh
Aug  2 11:13:27.192: INFO: Got endpoints: latency-svc-c25f2 [827.295229ms]
Aug  2 11:13:27.192: INFO: Got endpoints: latency-svc-lsbzb [879.875405ms]
Aug  2 11:13:27.196: INFO: Got endpoints: latency-svc-srsjq [783.181368ms]
Aug  2 11:13:27.207: INFO: Created: latency-svc-cqz2f
Aug  2 11:13:27.215: INFO: Created: latency-svc-ctm4h
Aug  2 11:13:27.216: INFO: Got endpoints: latency-svc-nzxns [752.472555ms]
Aug  2 11:13:27.223: INFO: Created: latency-svc-8w8zw
Aug  2 11:13:27.229: INFO: Created: latency-svc-cd7cq
Aug  2 11:13:27.263: INFO: Got endpoints: latency-svc-ds2wq [748.533071ms]
Aug  2 11:13:27.273: INFO: Created: latency-svc-7n7v5
Aug  2 11:13:27.354: INFO: Got endpoints: latency-svc-mpmd7 [791.169895ms]
Aug  2 11:13:27.363: INFO: Created: latency-svc-z2pnt
Aug  2 11:13:27.364: INFO: Got endpoints: latency-svc-vd5f8 [751.122228ms]
Aug  2 11:13:27.373: INFO: Created: latency-svc-b98nt
Aug  2 11:13:27.413: INFO: Got endpoints: latency-svc-hp5hd [750.13243ms]
Aug  2 11:13:27.423: INFO: Created: latency-svc-t685z
Aug  2 11:13:27.466: INFO: Got endpoints: latency-svc-4smt4 [699.119991ms]
Aug  2 11:13:27.475: INFO: Created: latency-svc-47cs8
Aug  2 11:13:27.512: INFO: Got endpoints: latency-svc-dxxdd [736.034507ms]
Aug  2 11:13:27.519: INFO: Created: latency-svc-l6sqw
Aug  2 11:13:27.563: INFO: Got endpoints: latency-svc-hqxz2 [749.722756ms]
Aug  2 11:13:27.578: INFO: Created: latency-svc-7sr59
Aug  2 11:13:27.613: INFO: Got endpoints: latency-svc-5ftq2 [680.990176ms]
Aug  2 11:13:27.622: INFO: Created: latency-svc-xn2ps
Aug  2 11:13:27.664: INFO: Got endpoints: latency-svc-xgr64 [731.525628ms]
Aug  2 11:13:27.674: INFO: Created: latency-svc-k5n6z
Aug  2 11:13:27.713: INFO: Got endpoints: latency-svc-5mf7s [749.693192ms]
Aug  2 11:13:27.722: INFO: Created: latency-svc-gsmdz
Aug  2 11:13:27.763: INFO: Got endpoints: latency-svc-hdpqh [749.531954ms]
Aug  2 11:13:27.775: INFO: Created: latency-svc-c6zkk
Aug  2 11:13:27.812: INFO: Got endpoints: latency-svc-cqz2f [619.698021ms]
Aug  2 11:13:27.821: INFO: Created: latency-svc-rnrmh
Aug  2 11:13:27.863: INFO: Got endpoints: latency-svc-ctm4h [670.219765ms]
Aug  2 11:13:27.872: INFO: Created: latency-svc-28wfx
Aug  2 11:13:27.913: INFO: Got endpoints: latency-svc-8w8zw [717.207517ms]
Aug  2 11:13:27.922: INFO: Created: latency-svc-xbh2s
Aug  2 11:13:27.962: INFO: Got endpoints: latency-svc-cd7cq [746.600235ms]
Aug  2 11:13:27.970: INFO: Created: latency-svc-pthqg
Aug  2 11:13:28.013: INFO: Got endpoints: latency-svc-7n7v5 [750.718498ms]
Aug  2 11:13:28.022: INFO: Created: latency-svc-97cvj
Aug  2 11:13:28.063: INFO: Got endpoints: latency-svc-z2pnt [709.439805ms]
Aug  2 11:13:28.072: INFO: Created: latency-svc-khddw
Aug  2 11:13:28.112: INFO: Got endpoints: latency-svc-b98nt [748.709555ms]
Aug  2 11:13:28.121: INFO: Created: latency-svc-d9xwn
Aug  2 11:13:28.163: INFO: Got endpoints: latency-svc-t685z [749.386127ms]
Aug  2 11:13:28.172: INFO: Created: latency-svc-4thh6
Aug  2 11:13:28.213: INFO: Got endpoints: latency-svc-47cs8 [747.083702ms]
Aug  2 11:13:28.228: INFO: Created: latency-svc-skdgn
Aug  2 11:13:28.262: INFO: Got endpoints: latency-svc-l6sqw [749.805827ms]
Aug  2 11:13:28.273: INFO: Created: latency-svc-jmgbr
Aug  2 11:13:28.313: INFO: Got endpoints: latency-svc-7sr59 [749.734133ms]
Aug  2 11:13:28.368: INFO: Created: latency-svc-jr6f8
Aug  2 11:13:28.371: INFO: Got endpoints: latency-svc-xn2ps [757.89131ms]
Aug  2 11:13:28.382: INFO: Created: latency-svc-8nkrl
Aug  2 11:13:28.413: INFO: Got endpoints: latency-svc-k5n6z [748.454287ms]
Aug  2 11:13:28.420: INFO: Created: latency-svc-pn9sk
Aug  2 11:13:28.620: INFO: Got endpoints: latency-svc-c6zkk [856.520064ms]
Aug  2 11:13:28.620: INFO: Got endpoints: latency-svc-rnrmh [807.612499ms]
Aug  2 11:13:28.620: INFO: Got endpoints: latency-svc-gsmdz [907.413361ms]
Aug  2 11:13:28.620: INFO: Got endpoints: latency-svc-28wfx [756.755122ms]
Aug  2 11:13:28.638: INFO: Created: latency-svc-xxkrx
Aug  2 11:13:28.644: INFO: Created: latency-svc-fk947
Aug  2 11:13:28.648: INFO: Created: latency-svc-7km44
Aug  2 11:13:28.655: INFO: Created: latency-svc-gj9ll
Aug  2 11:13:28.663: INFO: Got endpoints: latency-svc-xbh2s [750.228061ms]
Aug  2 11:13:28.673: INFO: Created: latency-svc-snxbk
Aug  2 11:13:28.712: INFO: Got endpoints: latency-svc-pthqg [749.875651ms]
Aug  2 11:13:29.319: INFO: Got endpoints: latency-svc-khddw [1.255580403s]
Aug  2 11:13:29.319: INFO: Got endpoints: latency-svc-97cvj [1.305536272s]
Aug  2 11:13:29.319: INFO: Got endpoints: latency-svc-d9xwn [1.206511877s]
Aug  2 11:13:29.319: INFO: Got endpoints: latency-svc-4thh6 [1.156713164s]
Aug  2 11:13:29.320: INFO: Got endpoints: latency-svc-skdgn [1.106468958s]
Aug  2 11:13:29.326: INFO: Got endpoints: latency-svc-jmgbr [1.063999885s]
Aug  2 11:13:29.328: INFO: Got endpoints: latency-svc-8nkrl [956.693578ms]
Aug  2 11:13:29.331: INFO: Got endpoints: latency-svc-xxkrx [711.183957ms]
Aug  2 11:13:29.331: INFO: Got endpoints: latency-svc-jr6f8 [1.018346183s]
Aug  2 11:13:29.331: INFO: Got endpoints: latency-svc-pn9sk [918.208771ms]
Aug  2 11:13:29.334: INFO: Got endpoints: latency-svc-7km44 [713.816605ms]
Aug  2 11:13:29.334: INFO: Got endpoints: latency-svc-fk947 [713.565471ms]
Aug  2 11:13:29.365: INFO: Got endpoints: latency-svc-gj9ll [744.397429ms]
Aug  2 11:13:29.412: INFO: Got endpoints: latency-svc-snxbk [748.743355ms]
Aug  2 11:13:29.412: INFO: Latencies: [21.180794ms 45.722812ms 53.278481ms 53.524819ms 77.60445ms 86.172344ms 86.295761ms 104.005823ms 107.41292ms 111.083657ms 112.751117ms 124.941896ms 125.528451ms 126.02224ms 126.112289ms 126.164971ms 126.813079ms 130.004535ms 131.837192ms 133.830606ms 134.846954ms 134.969095ms 137.148763ms 137.444572ms 138.314076ms 138.560488ms 138.790248ms 138.943024ms 139.531437ms 139.806673ms 140.501277ms 142.644946ms 146.616926ms 149.103692ms 152.757666ms 153.868427ms 154.767796ms 165.199121ms 165.416061ms 174.22891ms 184.047269ms 208.173006ms 237.118121ms 243.646363ms 278.892126ms 282.983395ms 320.112448ms 333.716758ms 363.292696ms 381.719371ms 405.77953ms 420.361802ms 465.690682ms 515.199132ms 518.572932ms 566.854648ms 568.862141ms 586.52262ms 587.738116ms 597.000973ms 609.768734ms 613.407826ms 619.698021ms 646.476532ms 660.798578ms 661.18578ms 670.219765ms 674.39706ms 680.990176ms 696.285556ms 699.119991ms 703.974075ms 704.933692ms 709.439805ms 710.29281ms 711.183957ms 713.565471ms 713.816605ms 717.207517ms 722.421409ms 728.207555ms 731.525628ms 736.034507ms 739.391747ms 740.805186ms 743.119575ms 744.397429ms 744.536358ms 744.587054ms 745.712315ms 746.154416ms 746.600235ms 746.671378ms 747.083702ms 747.360524ms 748.184715ms 748.454287ms 748.533071ms 748.682439ms 748.690316ms 748.709555ms 748.743355ms 748.932093ms 749.08914ms 749.107313ms 749.386127ms 749.387933ms 749.402593ms 749.46409ms 749.477922ms 749.531954ms 749.572985ms 749.600744ms 749.607218ms 749.675385ms 749.681698ms 749.693192ms 749.722756ms 749.734133ms 749.784891ms 749.794808ms 749.805827ms 749.818545ms 749.834951ms 749.875651ms 749.901595ms 750.113975ms 750.13243ms 750.140841ms 750.184988ms 750.228061ms 750.24717ms 750.31843ms 750.351682ms 750.438632ms 750.667917ms 750.675372ms 750.718498ms 750.896678ms 751.061753ms 751.122228ms 751.342626ms 751.398659ms 751.440426ms 751.723849ms 752.472555ms 754.931052ms 755.20596ms 755.540431ms 756.755122ms 757.881454ms 757.89131ms 758.593259ms 758.752267ms 761.475489ms 767.741675ms 772.295835ms 777.113415ms 783.181368ms 791.169895ms 794.98728ms 798.62563ms 803.23556ms 807.612499ms 819.554994ms 827.295229ms 827.555966ms 838.506718ms 853.367852ms 856.520064ms 879.875405ms 887.622315ms 890.531914ms 902.577018ms 907.413361ms 918.208771ms 930.379761ms 934.713295ms 953.365471ms 956.693578ms 980.875968ms 984.160812ms 999.485676ms 1.018346183s 1.03285926s 1.063999885s 1.078369387s 1.106468958s 1.111090781s 1.11624211s 1.124538332s 1.126537485s 1.128207127s 1.133429781s 1.137765372s 1.141902904s 1.156713164s 1.206511877s 1.255580403s 1.305536272s]
Aug  2 11:13:29.413: INFO: 50 %ile: 748.709555ms
Aug  2 11:13:29.413: INFO: 90 %ile: 980.875968ms
Aug  2 11:13:29.413: INFO: 99 %ile: 1.255580403s
Aug  2 11:13:29.413: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:13:29.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-2q9pt" for this suite.
Aug  2 11:13:39.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:13:40.070: INFO: namespace: e2e-tests-svc-latency-2q9pt, resource: bindings, ignored listing per whitelist
Aug  2 11:13:40.129: INFO: namespace e2e-tests-svc-latency-2q9pt deletion completed in 10.712036373s

• [SLOW TEST:22.514 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:13:40.129: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-94d0f7c0-b516-11e9-b8f5-0a4acaace53e
STEP: Creating configMap with name cm-test-opt-upd-94d0f803-b516-11e9-b8f5-0a4acaace53e
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-94d0f7c0-b516-11e9-b8f5-0a4acaace53e
STEP: Updating configmap cm-test-opt-upd-94d0f803-b516-11e9-b8f5-0a4acaace53e
STEP: Creating configMap with name cm-test-opt-create-94d0f81e-b516-11e9-b8f5-0a4acaace53e
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:13:44.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wfs88" for this suite.
Aug  2 11:14:06.348: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:14:06.395: INFO: namespace: e2e-tests-projected-wfs88, resource: bindings, ignored listing per whitelist
Aug  2 11:14:06.474: INFO: namespace e2e-tests-projected-wfs88 deletion completed in 22.135396826s

• [SLOW TEST:26.345 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:14:06.475: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Aug  2 11:14:10.586: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-tkfzz PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  2 11:14:10.586: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
Aug  2 11:14:10.724: INFO: Exec stderr: ""
Aug  2 11:14:10.724: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-tkfzz PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  2 11:14:10.725: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
Aug  2 11:14:10.893: INFO: Exec stderr: ""
Aug  2 11:14:10.893: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-tkfzz PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  2 11:14:10.893: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
Aug  2 11:14:11.048: INFO: Exec stderr: ""
Aug  2 11:14:11.048: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-tkfzz PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  2 11:14:11.048: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
Aug  2 11:14:11.181: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Aug  2 11:14:11.182: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-tkfzz PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  2 11:14:11.182: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
Aug  2 11:14:11.309: INFO: Exec stderr: ""
Aug  2 11:14:11.309: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-tkfzz PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  2 11:14:11.309: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
Aug  2 11:14:11.439: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Aug  2 11:14:11.439: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-tkfzz PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  2 11:14:11.439: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
Aug  2 11:14:11.581: INFO: Exec stderr: ""
Aug  2 11:14:11.581: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-tkfzz PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  2 11:14:11.582: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
Aug  2 11:14:11.721: INFO: Exec stderr: ""
Aug  2 11:14:11.721: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-tkfzz PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  2 11:14:11.721: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
Aug  2 11:14:11.854: INFO: Exec stderr: ""
Aug  2 11:14:11.854: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-tkfzz PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  2 11:14:11.854: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
Aug  2 11:14:11.992: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:14:11.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-tkfzz" for this suite.
Aug  2 11:14:54.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:14:54.095: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-tkfzz, resource: bindings, ignored listing per whitelist
Aug  2 11:14:54.124: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-tkfzz deletion completed in 42.126927122s

• [SLOW TEST:47.649 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:14:54.125: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-c0eb53d5-b516-11e9-b8f5-0a4acaace53e
STEP: Creating a pod to test consume configMaps
Aug  2 11:14:54.219: INFO: Waiting up to 5m0s for pod "pod-configmaps-c0ebf58b-b516-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-configmap-mxmmv" to be "success or failure"
Aug  2 11:14:54.229: INFO: Pod "pod-configmaps-c0ebf58b-b516-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.603911ms
Aug  2 11:14:56.234: INFO: Pod "pod-configmaps-c0ebf58b-b516-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015020973s
Aug  2 11:14:58.238: INFO: Pod "pod-configmaps-c0ebf58b-b516-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019492206s
STEP: Saw pod success
Aug  2 11:14:58.238: INFO: Pod "pod-configmaps-c0ebf58b-b516-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 11:14:58.241: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-configmaps-c0ebf58b-b516-11e9-b8f5-0a4acaace53e container configmap-volume-test: <nil>
STEP: delete the pod
Aug  2 11:14:58.263: INFO: Waiting for pod pod-configmaps-c0ebf58b-b516-11e9-b8f5-0a4acaace53e to disappear
Aug  2 11:14:58.266: INFO: Pod pod-configmaps-c0ebf58b-b516-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:14:58.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-mxmmv" for this suite.
Aug  2 11:15:04.281: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:15:04.449: INFO: namespace: e2e-tests-configmap-mxmmv, resource: bindings, ignored listing per whitelist
Aug  2 11:15:04.478: INFO: namespace e2e-tests-configmap-mxmmv deletion completed in 6.209234447s

• [SLOW TEST:10.353 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:15:04.479: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Aug  2 11:15:04.626: INFO: Waiting up to 5m0s for pod "pod-c71f9c38-b516-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-emptydir-vvv5b" to be "success or failure"
Aug  2 11:15:04.636: INFO: Pod "pod-c71f9c38-b516-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.459151ms
Aug  2 11:15:06.640: INFO: Pod "pod-c71f9c38-b516-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014312986s
STEP: Saw pod success
Aug  2 11:15:06.640: INFO: Pod "pod-c71f9c38-b516-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 11:15:06.644: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-c71f9c38-b516-11e9-b8f5-0a4acaace53e container test-container: <nil>
STEP: delete the pod
Aug  2 11:15:06.672: INFO: Waiting for pod pod-c71f9c38-b516-11e9-b8f5-0a4acaace53e to disappear
Aug  2 11:15:06.679: INFO: Pod pod-c71f9c38-b516-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:15:06.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-vvv5b" for this suite.
Aug  2 11:15:12.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:15:12.779: INFO: namespace: e2e-tests-emptydir-vvv5b, resource: bindings, ignored listing per whitelist
Aug  2 11:15:12.827: INFO: namespace e2e-tests-emptydir-vvv5b deletion completed in 6.122214855s

• [SLOW TEST:8.348 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:15:12.827: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Aug  2 11:15:15.452: INFO: Successfully updated pod "labelsupdatecc1297f7-b516-11e9-b8f5-0a4acaace53e"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:15:17.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mcsjs" for this suite.
Aug  2 11:15:39.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:15:39.592: INFO: namespace: e2e-tests-projected-mcsjs, resource: bindings, ignored listing per whitelist
Aug  2 11:15:39.625: INFO: namespace e2e-tests-projected-mcsjs deletion completed in 22.142474488s

• [SLOW TEST:26.797 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:15:39.625: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Aug  2 11:15:54.749: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:15:55.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-djxx2" for this suite.
Aug  2 11:16:17.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:16:17.833: INFO: namespace: e2e-tests-replicaset-djxx2, resource: bindings, ignored listing per whitelist
Aug  2 11:16:17.909: INFO: namespace e2e-tests-replicaset-djxx2 deletion completed in 22.140408044s

• [SLOW TEST:38.284 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:16:17.909: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Aug  2 11:16:17.985: INFO: Waiting up to 5m0s for pod "pod-f2da20b5-b516-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-emptydir-nnc99" to be "success or failure"
Aug  2 11:16:17.990: INFO: Pod "pod-f2da20b5-b516-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.171672ms
Aug  2 11:16:19.994: INFO: Pod "pod-f2da20b5-b516-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008053771s
STEP: Saw pod success
Aug  2 11:16:19.994: INFO: Pod "pod-f2da20b5-b516-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 11:16:19.996: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-f2da20b5-b516-11e9-b8f5-0a4acaace53e container test-container: <nil>
STEP: delete the pod
Aug  2 11:16:20.014: INFO: Waiting for pod pod-f2da20b5-b516-11e9-b8f5-0a4acaace53e to disappear
Aug  2 11:16:20.017: INFO: Pod pod-f2da20b5-b516-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:16:20.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-nnc99" for this suite.
Aug  2 11:16:26.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:16:26.048: INFO: namespace: e2e-tests-emptydir-nnc99, resource: bindings, ignored listing per whitelist
Aug  2 11:16:26.139: INFO: namespace e2e-tests-emptydir-nnc99 deletion completed in 6.118675842s

• [SLOW TEST:8.229 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:16:26.139: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Aug  2 11:16:26.728: INFO: Waiting up to 5m0s for pod "pod-service-account-f8102ab3-b516-11e9-b8f5-0a4acaace53e-tmbps" in namespace "e2e-tests-svcaccounts-7wrbs" to be "success or failure"
Aug  2 11:16:26.733: INFO: Pod "pod-service-account-f8102ab3-b516-11e9-b8f5-0a4acaace53e-tmbps": Phase="Pending", Reason="", readiness=false. Elapsed: 4.841929ms
Aug  2 11:16:28.737: INFO: Pod "pod-service-account-f8102ab3-b516-11e9-b8f5-0a4acaace53e-tmbps": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00887864s
Aug  2 11:16:30.745: INFO: Pod "pod-service-account-f8102ab3-b516-11e9-b8f5-0a4acaace53e-tmbps": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016163427s
STEP: Saw pod success
Aug  2 11:16:30.745: INFO: Pod "pod-service-account-f8102ab3-b516-11e9-b8f5-0a4acaace53e-tmbps" satisfied condition "success or failure"
Aug  2 11:16:30.748: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-service-account-f8102ab3-b516-11e9-b8f5-0a4acaace53e-tmbps container token-test: <nil>
STEP: delete the pod
Aug  2 11:16:30.775: INFO: Waiting for pod pod-service-account-f8102ab3-b516-11e9-b8f5-0a4acaace53e-tmbps to disappear
Aug  2 11:16:30.779: INFO: Pod pod-service-account-f8102ab3-b516-11e9-b8f5-0a4acaace53e-tmbps no longer exists
STEP: Creating a pod to test consume service account root CA
Aug  2 11:16:30.783: INFO: Waiting up to 5m0s for pod "pod-service-account-f8102ab3-b516-11e9-b8f5-0a4acaace53e-kwgnh" in namespace "e2e-tests-svcaccounts-7wrbs" to be "success or failure"
Aug  2 11:16:30.789: INFO: Pod "pod-service-account-f8102ab3-b516-11e9-b8f5-0a4acaace53e-kwgnh": Phase="Pending", Reason="", readiness=false. Elapsed: 6.7375ms
Aug  2 11:16:32.793: INFO: Pod "pod-service-account-f8102ab3-b516-11e9-b8f5-0a4acaace53e-kwgnh": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00995557s
Aug  2 11:16:34.797: INFO: Pod "pod-service-account-f8102ab3-b516-11e9-b8f5-0a4acaace53e-kwgnh": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014441589s
STEP: Saw pod success
Aug  2 11:16:34.797: INFO: Pod "pod-service-account-f8102ab3-b516-11e9-b8f5-0a4acaace53e-kwgnh" satisfied condition "success or failure"
Aug  2 11:16:34.800: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-service-account-f8102ab3-b516-11e9-b8f5-0a4acaace53e-kwgnh container root-ca-test: <nil>
STEP: delete the pod
Aug  2 11:16:34.824: INFO: Waiting for pod pod-service-account-f8102ab3-b516-11e9-b8f5-0a4acaace53e-kwgnh to disappear
Aug  2 11:16:34.826: INFO: Pod pod-service-account-f8102ab3-b516-11e9-b8f5-0a4acaace53e-kwgnh no longer exists
STEP: Creating a pod to test consume service account namespace
Aug  2 11:16:34.829: INFO: Waiting up to 5m0s for pod "pod-service-account-f8102ab3-b516-11e9-b8f5-0a4acaace53e-xsm7t" in namespace "e2e-tests-svcaccounts-7wrbs" to be "success or failure"
Aug  2 11:16:34.837: INFO: Pod "pod-service-account-f8102ab3-b516-11e9-b8f5-0a4acaace53e-xsm7t": Phase="Pending", Reason="", readiness=false. Elapsed: 7.701556ms
Aug  2 11:16:36.844: INFO: Pod "pod-service-account-f8102ab3-b516-11e9-b8f5-0a4acaace53e-xsm7t": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015048831s
STEP: Saw pod success
Aug  2 11:16:36.844: INFO: Pod "pod-service-account-f8102ab3-b516-11e9-b8f5-0a4acaace53e-xsm7t" satisfied condition "success or failure"
Aug  2 11:16:36.853: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-service-account-f8102ab3-b516-11e9-b8f5-0a4acaace53e-xsm7t container namespace-test: <nil>
STEP: delete the pod
Aug  2 11:16:36.891: INFO: Waiting for pod pod-service-account-f8102ab3-b516-11e9-b8f5-0a4acaace53e-xsm7t to disappear
Aug  2 11:16:36.894: INFO: Pod pod-service-account-f8102ab3-b516-11e9-b8f5-0a4acaace53e-xsm7t no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:16:36.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-7wrbs" for this suite.
Aug  2 11:16:42.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:16:43.000: INFO: namespace: e2e-tests-svcaccounts-7wrbs, resource: bindings, ignored listing per whitelist
Aug  2 11:16:43.012: INFO: namespace e2e-tests-svcaccounts-7wrbs deletion completed in 6.113876048s

• [SLOW TEST:16.873 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:16:43.013: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug  2 11:16:43.091: INFO: Pod name rollover-pod: Found 0 pods out of 1
Aug  2 11:16:48.095: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug  2 11:16:48.096: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Aug  2 11:16:50.100: INFO: Creating deployment "test-rollover-deployment"
Aug  2 11:16:50.110: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Aug  2 11:16:52.118: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Aug  2 11:16:52.124: INFO: Ensure that both replica sets have 1 created replica
Aug  2 11:16:52.129: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Aug  2 11:16:52.137: INFO: Updating deployment test-rollover-deployment
Aug  2 11:16:52.137: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Aug  2 11:16:54.145: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Aug  2 11:16:54.150: INFO: Make sure deployment "test-rollover-deployment" is complete
Aug  2 11:16:54.157: INFO: all replica sets need to contain the pod-template-hash label
Aug  2 11:16:54.157: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700341410, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700341410, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700341414, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700341410, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  2 11:16:56.162: INFO: all replica sets need to contain the pod-template-hash label
Aug  2 11:16:56.162: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700341410, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700341410, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700341414, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700341410, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  2 11:16:58.162: INFO: all replica sets need to contain the pod-template-hash label
Aug  2 11:16:58.162: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700341410, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700341410, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700341414, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700341410, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  2 11:17:00.165: INFO: all replica sets need to contain the pod-template-hash label
Aug  2 11:17:00.165: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700341410, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700341410, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700341414, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700341410, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  2 11:17:02.210: INFO: all replica sets need to contain the pod-template-hash label
Aug  2 11:17:02.210: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700341410, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700341410, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700341414, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700341410, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  2 11:17:04.163: INFO: 
Aug  2 11:17:04.163: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Aug  2 11:17:04.169: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-c7vqz,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-c7vqz/deployments/test-rollover-deployment,UID:0600553a-b517-11e9-9105-fa163e46117c,ResourceVersion:21929,Generation:2,CreationTimestamp:2019-08-02 11:16:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-08-02 11:16:50 +0000 UTC 2019-08-02 11:16:50 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-08-02 11:17:04 +0000 UTC 2019-08-02 11:16:50 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Aug  2 11:17:04.172: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-c7vqz,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-c7vqz/replicasets/test-rollover-deployment-6b7f9d6597,UID:0736ed8d-b517-11e9-9105-fa163e46117c,ResourceVersion:21920,Generation:2,CreationTimestamp:2019-08-02 11:16:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 0600553a-b517-11e9-9105-fa163e46117c 0xc001aaa897 0xc001aaa898}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug  2 11:17:04.172: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Aug  2 11:17:04.173: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-c7vqz,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-c7vqz/replicasets/test-rollover-controller,UID:01d174a4-b517-11e9-9105-fa163e46117c,ResourceVersion:21928,Generation:2,CreationTimestamp:2019-08-02 11:16:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 0600553a-b517-11e9-9105-fa163e46117c 0xc001aaa707 0xc001aaa708}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug  2 11:17:04.173: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-c7vqz,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-c7vqz/replicasets/test-rollover-deployment-6586df867b,UID:06023058-b517-11e9-9105-fa163e46117c,ResourceVersion:21888,Generation:2,CreationTimestamp:2019-08-02 11:16:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 0600553a-b517-11e9-9105-fa163e46117c 0xc001aaa7c7 0xc001aaa7c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug  2 11:17:04.176: INFO: Pod "test-rollover-deployment-6b7f9d6597-r767g" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-r767g,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-c7vqz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-c7vqz/pods/test-rollover-deployment-6b7f9d6597-r767g,UID:073bb23f-b517-11e9-9105-fa163e46117c,ResourceVersion:21898,Generation:0,CreationTimestamp:2019-08-02 11:16:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 0736ed8d-b517-11e9-9105-fa163e46117c 0xc001dfc287 0xc001dfc288}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l59zs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l59zs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-l59zs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test-v1-13-7-gipwxthqfdpj-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001dfc3c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001dfc3e0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 11:16:52 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 11:16:54 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 11:16:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-02 11:16:52 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.11,PodIP:192.168.232.54,StartTime:2019-08-02 11:16:52 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-08-02 11:16:53 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://b751c0a6c093645172a6348709e34976927dedede35bfa51fa338679021ad321}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:17:04.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-c7vqz" for this suite.
Aug  2 11:17:10.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:17:10.314: INFO: namespace: e2e-tests-deployment-c7vqz, resource: bindings, ignored listing per whitelist
Aug  2 11:17:10.346: INFO: namespace e2e-tests-deployment-c7vqz deletion completed in 6.167479999s

• [SLOW TEST:27.333 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:17:10.347: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Aug  2 11:17:12.459: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-121d3680-b517-11e9-b8f5-0a4acaace53e", GenerateName:"", Namespace:"e2e-tests-pods-4jldg", SelfLink:"/api/v1/namespaces/e2e-tests-pods-4jldg/pods/pod-submit-remove-121d3680-b517-11e9-b8f5-0a4acaace53e", UID:"121f6cde-b517-11e9-9105-fa163e46117c", ResourceVersion:"21989", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63700341430, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"429113325"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-h5x7b", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002408c00), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-h5x7b", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002692c68), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"test-v1-13-7-gipwxthqfdpj-minion-0", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc000bdfb60), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002692ca0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002692cc0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc002692cc8)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700341430, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700341432, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700341432, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700341430, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.0.11", PodIP:"192.168.232.55", StartTime:(*v1.Time)(0xc0024ce6c0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc0024ce720), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"docker.io/nginx:1.14-alpine", ImageID:"docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7", ContainerID:"docker://e0500c682eb0300736de4a2e4ac37c0f49c75bb6de5c7d05b52fb530b0271309"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Aug  2 11:17:17.478: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:17:17.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-4jldg" for this suite.
Aug  2 11:17:23.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:17:23.564: INFO: namespace: e2e-tests-pods-4jldg, resource: bindings, ignored listing per whitelist
Aug  2 11:17:23.616: INFO: namespace e2e-tests-pods-4jldg deletion completed in 6.130036119s

• [SLOW TEST:13.269 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:17:23.617: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-vzspb
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Aug  2 11:17:23.834: INFO: Found 0 stateful pods, waiting for 3
Aug  2 11:17:33.839: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug  2 11:17:33.839: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug  2 11:17:33.839: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Aug  2 11:17:33.848: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-vzspb ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug  2 11:17:34.100: INFO: stderr: ""
Aug  2 11:17:34.100: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug  2 11:17:34.100: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Aug  2 11:17:44.128: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Aug  2 11:17:54.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-vzspb ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  2 11:17:54.449: INFO: stderr: ""
Aug  2 11:17:54.449: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug  2 11:17:54.449: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

STEP: Rolling back to a previous revision
Aug  2 11:18:14.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-vzspb ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug  2 11:18:14.704: INFO: stderr: ""
Aug  2 11:18:14.704: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug  2 11:18:14.704: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug  2 11:18:24.758: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Aug  2 11:18:35.168: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 exec --namespace=e2e-tests-statefulset-vzspb ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  2 11:18:35.414: INFO: stderr: ""
Aug  2 11:18:35.414: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug  2 11:18:35.414: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug  2 11:18:45.757: INFO: Waiting for StatefulSet e2e-tests-statefulset-vzspb/ss2 to complete update
Aug  2 11:18:45.757: INFO: Waiting for Pod e2e-tests-statefulset-vzspb/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Aug  2 11:18:55.765: INFO: Deleting all statefulset in ns e2e-tests-statefulset-vzspb
Aug  2 11:18:55.775: INFO: Scaling statefulset ss2 to 0
Aug  2 11:19:05.790: INFO: Waiting for statefulset status.replicas updated to 0
Aug  2 11:19:05.799: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:19:05.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-vzspb" for this suite.
Aug  2 11:19:11.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:19:11.984: INFO: namespace: e2e-tests-statefulset-vzspb, resource: bindings, ignored listing per whitelist
Aug  2 11:19:11.987: INFO: namespace e2e-tests-statefulset-vzspb deletion completed in 6.170870658s

• [SLOW TEST:108.370 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:19:11.988: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Aug  2 11:19:12.076: INFO: Waiting up to 5m0s for pod "client-containers-5a9e75f8-b517-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-containers-mcgpl" to be "success or failure"
Aug  2 11:19:12.085: INFO: Pod "client-containers-5a9e75f8-b517-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.698555ms
Aug  2 11:19:14.089: INFO: Pod "client-containers-5a9e75f8-b517-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012394663s
Aug  2 11:19:16.093: INFO: Pod "client-containers-5a9e75f8-b517-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017074336s
STEP: Saw pod success
Aug  2 11:19:16.094: INFO: Pod "client-containers-5a9e75f8-b517-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 11:19:16.096: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod client-containers-5a9e75f8-b517-11e9-b8f5-0a4acaace53e container test-container: <nil>
STEP: delete the pod
Aug  2 11:19:16.121: INFO: Waiting for pod client-containers-5a9e75f8-b517-11e9-b8f5-0a4acaace53e to disappear
Aug  2 11:19:16.124: INFO: Pod client-containers-5a9e75f8-b517-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:19:16.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-mcgpl" for this suite.
Aug  2 11:19:22.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:19:22.243: INFO: namespace: e2e-tests-containers-mcgpl, resource: bindings, ignored listing per whitelist
Aug  2 11:19:22.247: INFO: namespace e2e-tests-containers-mcgpl deletion completed in 6.119741849s

• [SLOW TEST:10.259 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:19:22.247: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-60c1d0ff-b517-11e9-b8f5-0a4acaace53e
STEP: Creating a pod to test consume secrets
Aug  2 11:19:22.385: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-60c3283f-b517-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-projected-55vng" to be "success or failure"
Aug  2 11:19:22.394: INFO: Pod "pod-projected-secrets-60c3283f-b517-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 9.797208ms
Aug  2 11:19:24.398: INFO: Pod "pod-projected-secrets-60c3283f-b517-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013658888s
Aug  2 11:19:26.402: INFO: Pod "pod-projected-secrets-60c3283f-b517-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017550598s
STEP: Saw pod success
Aug  2 11:19:26.402: INFO: Pod "pod-projected-secrets-60c3283f-b517-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 11:19:26.405: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-projected-secrets-60c3283f-b517-11e9-b8f5-0a4acaace53e container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug  2 11:19:26.431: INFO: Waiting for pod pod-projected-secrets-60c3283f-b517-11e9-b8f5-0a4acaace53e to disappear
Aug  2 11:19:26.435: INFO: Pod pod-projected-secrets-60c3283f-b517-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:19:26.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-55vng" for this suite.
Aug  2 11:19:32.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:19:32.566: INFO: namespace: e2e-tests-projected-55vng, resource: bindings, ignored listing per whitelist
Aug  2 11:19:32.581: INFO: namespace e2e-tests-projected-55vng deletion completed in 6.143580827s

• [SLOW TEST:10.334 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:19:32.581: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0802 11:20:02.728552      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug  2 11:20:02.728: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:20:02.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-s5pdq" for this suite.
Aug  2 11:20:08.740: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:20:08.773: INFO: namespace: e2e-tests-gc-s5pdq, resource: bindings, ignored listing per whitelist
Aug  2 11:20:08.849: INFO: namespace e2e-tests-gc-s5pdq deletion completed in 6.118644402s

• [SLOW TEST:36.268 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:20:08.849: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Aug  2 11:20:12.970: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  2 11:20:12.976: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  2 11:20:14.977: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  2 11:20:14.981: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  2 11:20:16.977: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  2 11:20:16.981: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  2 11:20:18.976: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  2 11:20:18.980: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  2 11:20:20.977: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  2 11:20:20.980: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  2 11:20:22.977: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  2 11:20:22.980: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  2 11:20:24.977: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  2 11:20:24.980: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  2 11:20:26.977: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  2 11:20:26.980: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  2 11:20:28.977: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  2 11:20:28.981: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  2 11:20:30.977: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  2 11:20:30.983: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  2 11:20:32.977: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  2 11:20:32.980: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:20:32.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-nfw7w" for this suite.
Aug  2 11:20:57.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:20:57.090: INFO: namespace: e2e-tests-container-lifecycle-hook-nfw7w, resource: bindings, ignored listing per whitelist
Aug  2 11:20:57.143: INFO: namespace e2e-tests-container-lifecycle-hook-nfw7w deletion completed in 24.145672221s

• [SLOW TEST:48.294 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:20:57.143: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug  2 11:20:57.213: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-ppcb6'
Aug  2 11:20:57.709: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug  2 11:20:57.709: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Aug  2 11:20:57.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-ppcb6'
Aug  2 11:20:57.852: INFO: stderr: ""
Aug  2 11:20:57.852: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:20:57.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ppcb6" for this suite.
Aug  2 11:21:03.870: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:21:03.961: INFO: namespace: e2e-tests-kubectl-ppcb6, resource: bindings, ignored listing per whitelist
Aug  2 11:21:03.988: INFO: namespace e2e-tests-kubectl-ppcb6 deletion completed in 6.131065099s

• [SLOW TEST:6.845 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:21:03.990: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-26kj
STEP: Creating a pod to test atomic-volume-subpath
Aug  2 11:21:04.284: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-26kj" in namespace "e2e-tests-subpath-bwbfz" to be "success or failure"
Aug  2 11:21:04.292: INFO: Pod "pod-subpath-test-downwardapi-26kj": Phase="Pending", Reason="", readiness=false. Elapsed: 7.569301ms
Aug  2 11:21:06.295: INFO: Pod "pod-subpath-test-downwardapi-26kj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011238921s
Aug  2 11:21:08.299: INFO: Pod "pod-subpath-test-downwardapi-26kj": Phase="Running", Reason="", readiness=false. Elapsed: 4.014846318s
Aug  2 11:21:10.303: INFO: Pod "pod-subpath-test-downwardapi-26kj": Phase="Running", Reason="", readiness=false. Elapsed: 6.01926445s
Aug  2 11:21:12.347: INFO: Pod "pod-subpath-test-downwardapi-26kj": Phase="Running", Reason="", readiness=false. Elapsed: 8.062596509s
Aug  2 11:21:14.351: INFO: Pod "pod-subpath-test-downwardapi-26kj": Phase="Running", Reason="", readiness=false. Elapsed: 10.06666885s
Aug  2 11:21:16.355: INFO: Pod "pod-subpath-test-downwardapi-26kj": Phase="Running", Reason="", readiness=false. Elapsed: 12.070633969s
Aug  2 11:21:18.359: INFO: Pod "pod-subpath-test-downwardapi-26kj": Phase="Running", Reason="", readiness=false. Elapsed: 14.075052911s
Aug  2 11:21:20.550: INFO: Pod "pod-subpath-test-downwardapi-26kj": Phase="Running", Reason="", readiness=false. Elapsed: 16.265810299s
Aug  2 11:21:22.553: INFO: Pod "pod-subpath-test-downwardapi-26kj": Phase="Running", Reason="", readiness=false. Elapsed: 18.269175545s
Aug  2 11:21:24.557: INFO: Pod "pod-subpath-test-downwardapi-26kj": Phase="Running", Reason="", readiness=false. Elapsed: 20.27303364s
Aug  2 11:21:26.690: INFO: Pod "pod-subpath-test-downwardapi-26kj": Phase="Running", Reason="", readiness=false. Elapsed: 22.406010762s
Aug  2 11:21:28.693: INFO: Pod "pod-subpath-test-downwardapi-26kj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.409343129s
STEP: Saw pod success
Aug  2 11:21:28.694: INFO: Pod "pod-subpath-test-downwardapi-26kj" satisfied condition "success or failure"
Aug  2 11:21:28.698: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-subpath-test-downwardapi-26kj container test-container-subpath-downwardapi-26kj: <nil>
STEP: delete the pod
Aug  2 11:21:28.723: INFO: Waiting for pod pod-subpath-test-downwardapi-26kj to disappear
Aug  2 11:21:28.726: INFO: Pod pod-subpath-test-downwardapi-26kj no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-26kj
Aug  2 11:21:28.726: INFO: Deleting pod "pod-subpath-test-downwardapi-26kj" in namespace "e2e-tests-subpath-bwbfz"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:21:28.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-bwbfz" for this suite.
Aug  2 11:21:34.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:21:34.893: INFO: namespace: e2e-tests-subpath-bwbfz, resource: bindings, ignored listing per whitelist
Aug  2 11:21:34.893: INFO: namespace e2e-tests-subpath-bwbfz deletion completed in 6.154344632s

• [SLOW TEST:30.903 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:21:34.894: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug  2 11:21:34.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 version --client'
Aug  2 11:21:35.046: INFO: stderr: ""
Aug  2 11:21:35.046: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Aug  2 11:21:35.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 create -f - --namespace=e2e-tests-kubectl-2w8mf'
Aug  2 11:21:36.504: INFO: stderr: ""
Aug  2 11:21:36.504: INFO: stdout: "replicationcontroller/redis-master created\n"
Aug  2 11:21:36.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 create -f - --namespace=e2e-tests-kubectl-2w8mf'
Aug  2 11:21:36.815: INFO: stderr: ""
Aug  2 11:21:36.815: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug  2 11:21:38.986: INFO: Selector matched 1 pods for map[app:redis]
Aug  2 11:21:38.987: INFO: Found 0 / 1
Aug  2 11:21:39.818: INFO: Selector matched 1 pods for map[app:redis]
Aug  2 11:21:39.818: INFO: Found 1 / 1
Aug  2 11:21:39.818: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug  2 11:21:39.820: INFO: Selector matched 1 pods for map[app:redis]
Aug  2 11:21:39.820: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug  2 11:21:39.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 describe pod redis-master-s5zr2 --namespace=e2e-tests-kubectl-2w8mf'
Aug  2 11:21:39.946: INFO: stderr: ""
Aug  2 11:21:39.946: INFO: stdout: "Name:           redis-master-s5zr2\nNamespace:      e2e-tests-kubectl-2w8mf\nNode:           test-v1-13-7-gipwxthqfdpj-minion-0/10.0.0.11\nStart Time:     Fri, 02 Aug 2019 11:21:36 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    <none>\nStatus:         Running\nIP:             192.168.232.17\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://3fd6ecc6420fa57ec6440b4d0d3b0967dc08d7f4659c507585637b2901850402\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Fri, 02 Aug 2019 11:21:39 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-xm4xz (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-xm4xz:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-xm4xz\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                         Message\n  ----    ------     ----  ----                                         -------\n  Normal  Scheduled  3s    default-scheduler                            Successfully assigned e2e-tests-kubectl-2w8mf/redis-master-s5zr2 to test-v1-13-7-gipwxthqfdpj-minion-0\n  Normal  Pulled     0s    kubelet, test-v1-13-7-gipwxthqfdpj-minion-0  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    0s    kubelet, test-v1-13-7-gipwxthqfdpj-minion-0  Created container\n  Normal  Started    0s    kubelet, test-v1-13-7-gipwxthqfdpj-minion-0  Started container\n"
Aug  2 11:21:39.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 describe rc redis-master --namespace=e2e-tests-kubectl-2w8mf'
Aug  2 11:21:40.088: INFO: stderr: ""
Aug  2 11:21:40.088: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-2w8mf\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  4s    replication-controller  Created pod: redis-master-s5zr2\n"
Aug  2 11:21:40.088: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 describe service redis-master --namespace=e2e-tests-kubectl-2w8mf'
Aug  2 11:21:40.245: INFO: stderr: ""
Aug  2 11:21:40.245: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-2w8mf\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.254.202.36\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         192.168.232.17:6379\nSession Affinity:  None\nEvents:            <none>\n"
Aug  2 11:21:40.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 describe node test-v1-13-7-gipwxthqfdpj-master-0'
Aug  2 11:21:40.380: INFO: stderr: ""
Aug  2 11:21:40.380: INFO: stdout: "Name:               test-v1-13-7-gipwxthqfdpj-master-0\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=432a66b6-c886-4cb0-808a-1614a248cac1\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=nz-hlz-1\n                    failure-domain.beta.kubernetes.io/zone=nz-hlz-1a\n                    kubernetes.io/hostname=test-v1-13-7-gipwxthqfdpj-master-0\n                    node-role.kubernetes.io/master=\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Fri, 02 Aug 2019 09:06:51 +0000\nTaints:             CriticalAddonsOnly=True:NoSchedule\n                    dedicated=master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Fri, 02 Aug 2019 11:21:31 +0000   Fri, 02 Aug 2019 09:06:45 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Fri, 02 Aug 2019 11:21:31 +0000   Fri, 02 Aug 2019 09:06:45 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Fri, 02 Aug 2019 11:21:31 +0000   Fri, 02 Aug 2019 09:06:45 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Fri, 02 Aug 2019 11:21:31 +0000   Fri, 02 Aug 2019 09:08:01 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.0.0.10\n  ExternalIP:  103.197.62.56\nCapacity:\n cpu:                2\n ephemeral-storage:  9202Mi\n hugepages-2Mi:      0\n memory:             4039012Ki\n pods:               110\nAllocatable:\n cpu:                2\n ephemeral-storage:  8684096703\n hugepages-2Mi:      0\n memory:             3936612Ki\n pods:               110\nSystem Info:\n Machine ID:                 0c39a451565d4b8581326856e30fb5c4\n System UUID:                0C39A451-565D-4B85-8132-6856E30FB5C4\n Boot ID:                    271dddbb-f775-4ff1-abf0-092fe49fce35\n Kernel Version:             4.14.18-300.fc27.x86_64\n OS Image:                   Debian GNU/Linux 9 (stretch)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://1.13.1\n Kubelet Version:            v1.13.7\n Kube-Proxy Version:         v1.13.7\nPodCIDR:                     192.168.0.0/24\nProviderID:                  openstack:///0c39a451-565d-4b85-8132-6856e30fb5c4\nNon-terminated Pods:         (5 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-a44350f5542845ed-99lq7    0 (0%)        0 (0%)      0 (0%)           0 (0%)         77m\n  kube-system                calico-node-bs6n9                                          250m (12%)    0 (0%)      0 (0%)           0 (0%)         134m\n  kube-system                k8s-keystone-auth-rpdkd                                    200m (10%)    0 (0%)      0 (0%)           0 (0%)         134m\n  kube-system                octavia-ingress-controller-0                               0 (0%)        0 (0%)      0 (0%)           0 (0%)         134m\n  kube-system                openstack-cloud-controller-manager-4vq4r                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         134m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                450m (22%)  0 (0%)\n  memory             0 (0%)      0 (0%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:              <none>\n"
Aug  2 11:21:40.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 describe namespace e2e-tests-kubectl-2w8mf'
Aug  2 11:21:40.509: INFO: stderr: ""
Aug  2 11:21:40.509: INFO: stdout: "Name:         e2e-tests-kubectl-2w8mf\nLabels:       e2e-framework=kubectl\n              e2e-run=0f17542e-b50d-11e9-b8f5-0a4acaace53e\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:21:40.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2w8mf" for this suite.
Aug  2 11:22:02.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:22:02.605: INFO: namespace: e2e-tests-kubectl-2w8mf, resource: bindings, ignored listing per whitelist
Aug  2 11:22:02.623: INFO: namespace e2e-tests-kubectl-2w8mf deletion completed in 22.111453249s

• [SLOW TEST:27.729 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:22:02.624: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Aug  2 11:22:02.749: INFO: Waiting up to 5m0s for pod "client-containers-c058b43a-b517-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-containers-qsrxf" to be "success or failure"
Aug  2 11:22:02.754: INFO: Pod "client-containers-c058b43a-b517-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.783184ms
Aug  2 11:22:04.758: INFO: Pod "client-containers-c058b43a-b517-11e9-b8f5-0a4acaace53e": Phase="Running", Reason="", readiness=true. Elapsed: 2.009103873s
Aug  2 11:22:06.768: INFO: Pod "client-containers-c058b43a-b517-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019147965s
STEP: Saw pod success
Aug  2 11:22:06.768: INFO: Pod "client-containers-c058b43a-b517-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 11:22:06.770: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod client-containers-c058b43a-b517-11e9-b8f5-0a4acaace53e container test-container: <nil>
STEP: delete the pod
Aug  2 11:22:06.790: INFO: Waiting for pod client-containers-c058b43a-b517-11e9-b8f5-0a4acaace53e to disappear
Aug  2 11:22:06.793: INFO: Pod client-containers-c058b43a-b517-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:22:06.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-qsrxf" for this suite.
Aug  2 11:22:12.812: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:22:12.924: INFO: namespace: e2e-tests-containers-qsrxf, resource: bindings, ignored listing per whitelist
Aug  2 11:22:12.937: INFO: namespace e2e-tests-containers-qsrxf deletion completed in 6.137217666s

• [SLOW TEST:10.313 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:22:12.937: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Aug  2 11:22:13.035: INFO: Waiting up to 5m0s for pod "downward-api-c6790770-b517-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-downward-api-h44r9" to be "success or failure"
Aug  2 11:22:13.038: INFO: Pod "downward-api-c6790770-b517-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.169506ms
Aug  2 11:22:15.043: INFO: Pod "downward-api-c6790770-b517-11e9-b8f5-0a4acaace53e": Phase="Running", Reason="", readiness=true. Elapsed: 2.007613728s
Aug  2 11:22:17.046: INFO: Pod "downward-api-c6790770-b517-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011182s
STEP: Saw pod success
Aug  2 11:22:17.047: INFO: Pod "downward-api-c6790770-b517-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 11:22:17.048: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod downward-api-c6790770-b517-11e9-b8f5-0a4acaace53e container dapi-container: <nil>
STEP: delete the pod
Aug  2 11:22:17.072: INFO: Waiting for pod downward-api-c6790770-b517-11e9-b8f5-0a4acaace53e to disappear
Aug  2 11:22:17.074: INFO: Pod downward-api-c6790770-b517-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:22:17.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-h44r9" for this suite.
Aug  2 11:22:23.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:22:23.168: INFO: namespace: e2e-tests-downward-api-h44r9, resource: bindings, ignored listing per whitelist
Aug  2 11:22:23.232: INFO: namespace e2e-tests-downward-api-h44r9 deletion completed in 6.155235032s

• [SLOW TEST:10.295 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:22:23.233: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug  2 11:22:23.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-p49dq'
Aug  2 11:22:23.486: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug  2 11:22:23.486: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Aug  2 11:22:25.515: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-p49dq'
Aug  2 11:22:25.647: INFO: stderr: ""
Aug  2 11:22:25.647: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:22:25.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-p49dq" for this suite.
Aug  2 11:22:31.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:22:31.742: INFO: namespace: e2e-tests-kubectl-p49dq, resource: bindings, ignored listing per whitelist
Aug  2 11:22:31.800: INFO: namespace e2e-tests-kubectl-p49dq deletion completed in 6.147595271s

• [SLOW TEST:8.567 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:22:31.800: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-d1b68c58-b517-11e9-b8f5-0a4acaace53e
STEP: Creating secret with name secret-projected-all-test-volume-d1b68c44-b517-11e9-b8f5-0a4acaace53e
STEP: Creating a pod to test Check all projections for projected volume plugin
Aug  2 11:22:31.891: INFO: Waiting up to 5m0s for pod "projected-volume-d1b68c05-b517-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-projected-sh745" to be "success or failure"
Aug  2 11:22:31.896: INFO: Pod "projected-volume-d1b68c05-b517-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.643006ms
Aug  2 11:22:33.901: INFO: Pod "projected-volume-d1b68c05-b517-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009684598s
STEP: Saw pod success
Aug  2 11:22:33.901: INFO: Pod "projected-volume-d1b68c05-b517-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 11:22:33.904: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod projected-volume-d1b68c05-b517-11e9-b8f5-0a4acaace53e container projected-all-volume-test: <nil>
STEP: delete the pod
Aug  2 11:22:33.931: INFO: Waiting for pod projected-volume-d1b68c05-b517-11e9-b8f5-0a4acaace53e to disappear
Aug  2 11:22:33.935: INFO: Pod projected-volume-d1b68c05-b517-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:22:33.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sh745" for this suite.
Aug  2 11:22:39.968: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:22:40.070: INFO: namespace: e2e-tests-projected-sh745, resource: bindings, ignored listing per whitelist
Aug  2 11:22:40.077: INFO: namespace e2e-tests-projected-sh745 deletion completed in 6.132283212s

• [SLOW TEST:8.277 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:22:40.078: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:23:08.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-xmhbd" for this suite.
Aug  2 11:23:14.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:23:14.476: INFO: namespace: e2e-tests-container-runtime-xmhbd, resource: bindings, ignored listing per whitelist
Aug  2 11:23:14.561: INFO: namespace e2e-tests-container-runtime-xmhbd deletion completed in 6.16988903s

• [SLOW TEST:34.483 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:23:14.562: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-eb3397a4-b517-11e9-b8f5-0a4acaace53e
STEP: Creating a pod to test consume configMaps
Aug  2 11:23:14.654: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-eb346b1c-b517-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-projected-5wqv2" to be "success or failure"
Aug  2 11:23:14.661: INFO: Pod "pod-projected-configmaps-eb346b1c-b517-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.537207ms
Aug  2 11:23:16.665: INFO: Pod "pod-projected-configmaps-eb346b1c-b517-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010158047s
Aug  2 11:23:18.668: INFO: Pod "pod-projected-configmaps-eb346b1c-b517-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013350431s
STEP: Saw pod success
Aug  2 11:23:18.668: INFO: Pod "pod-projected-configmaps-eb346b1c-b517-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 11:23:18.670: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-projected-configmaps-eb346b1c-b517-11e9-b8f5-0a4acaace53e container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug  2 11:23:18.693: INFO: Waiting for pod pod-projected-configmaps-eb346b1c-b517-11e9-b8f5-0a4acaace53e to disappear
Aug  2 11:23:18.699: INFO: Pod pod-projected-configmaps-eb346b1c-b517-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:23:18.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5wqv2" for this suite.
Aug  2 11:23:24.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:23:24.763: INFO: namespace: e2e-tests-projected-5wqv2, resource: bindings, ignored listing per whitelist
Aug  2 11:23:24.848: INFO: namespace e2e-tests-projected-5wqv2 deletion completed in 6.146538986s

• [SLOW TEST:10.286 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:23:24.848: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Aug  2 11:23:24.974: INFO: Waiting up to 5m0s for pod "client-containers-f15a28f2-b517-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-containers-js5pr" to be "success or failure"
Aug  2 11:23:24.988: INFO: Pod "client-containers-f15a28f2-b517-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 13.696402ms
Aug  2 11:23:26.993: INFO: Pod "client-containers-f15a28f2-b517-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018688755s
STEP: Saw pod success
Aug  2 11:23:26.993: INFO: Pod "client-containers-f15a28f2-b517-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 11:23:27.002: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod client-containers-f15a28f2-b517-11e9-b8f5-0a4acaace53e container test-container: <nil>
STEP: delete the pod
Aug  2 11:23:27.033: INFO: Waiting for pod client-containers-f15a28f2-b517-11e9-b8f5-0a4acaace53e to disappear
Aug  2 11:23:27.038: INFO: Pod client-containers-f15a28f2-b517-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:23:27.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-js5pr" for this suite.
Aug  2 11:23:33.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:23:33.139: INFO: namespace: e2e-tests-containers-js5pr, resource: bindings, ignored listing per whitelist
Aug  2 11:23:33.170: INFO: namespace e2e-tests-containers-js5pr deletion completed in 6.129386043s

• [SLOW TEST:8.322 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:23:33.170: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Aug  2 11:23:33.304: INFO: Waiting up to 5m0s for pod "downward-api-f6524e51-b517-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-downward-api-cbmzk" to be "success or failure"
Aug  2 11:23:33.310: INFO: Pod "downward-api-f6524e51-b517-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.760561ms
Aug  2 11:23:35.313: INFO: Pod "downward-api-f6524e51-b517-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00926346s
STEP: Saw pod success
Aug  2 11:23:35.313: INFO: Pod "downward-api-f6524e51-b517-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 11:23:35.315: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod downward-api-f6524e51-b517-11e9-b8f5-0a4acaace53e container dapi-container: <nil>
STEP: delete the pod
Aug  2 11:23:35.375: INFO: Waiting for pod downward-api-f6524e51-b517-11e9-b8f5-0a4acaace53e to disappear
Aug  2 11:23:35.382: INFO: Pod downward-api-f6524e51-b517-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:23:35.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-cbmzk" for this suite.
Aug  2 11:23:41.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:23:41.439: INFO: namespace: e2e-tests-downward-api-cbmzk, resource: bindings, ignored listing per whitelist
Aug  2 11:23:41.521: INFO: namespace e2e-tests-downward-api-cbmzk deletion completed in 6.130274437s

• [SLOW TEST:8.351 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:23:41.521: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-fb4bb3fd-b517-11e9-b8f5-0a4acaace53e
STEP: Creating a pod to test consume configMaps
Aug  2 11:23:41.655: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-fb4c6f79-b517-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-projected-x2xsv" to be "success or failure"
Aug  2 11:23:41.661: INFO: Pod "pod-projected-configmaps-fb4c6f79-b517-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.868172ms
Aug  2 11:23:43.664: INFO: Pod "pod-projected-configmaps-fb4c6f79-b517-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009140454s
STEP: Saw pod success
Aug  2 11:23:43.665: INFO: Pod "pod-projected-configmaps-fb4c6f79-b517-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 11:23:43.667: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-projected-configmaps-fb4c6f79-b517-11e9-b8f5-0a4acaace53e container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug  2 11:23:43.692: INFO: Waiting for pod pod-projected-configmaps-fb4c6f79-b517-11e9-b8f5-0a4acaace53e to disappear
Aug  2 11:23:43.696: INFO: Pod pod-projected-configmaps-fb4c6f79-b517-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:23:43.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-x2xsv" for this suite.
Aug  2 11:23:49.720: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:23:49.752: INFO: namespace: e2e-tests-projected-x2xsv, resource: bindings, ignored listing per whitelist
Aug  2 11:23:49.839: INFO: namespace e2e-tests-projected-x2xsv deletion completed in 6.135918455s

• [SLOW TEST:8.318 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:23:49.840: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Aug  2 11:23:49.915: INFO: Waiting up to 5m0s for pod "var-expansion-00393b5b-b518-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-var-expansion-mktqv" to be "success or failure"
Aug  2 11:23:49.925: INFO: Pod "var-expansion-00393b5b-b518-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 9.635794ms
Aug  2 11:23:51.929: INFO: Pod "var-expansion-00393b5b-b518-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013852125s
STEP: Saw pod success
Aug  2 11:23:51.929: INFO: Pod "var-expansion-00393b5b-b518-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 11:23:51.931: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod var-expansion-00393b5b-b518-11e9-b8f5-0a4acaace53e container dapi-container: <nil>
STEP: delete the pod
Aug  2 11:23:51.951: INFO: Waiting for pod var-expansion-00393b5b-b518-11e9-b8f5-0a4acaace53e to disappear
Aug  2 11:23:51.959: INFO: Pod var-expansion-00393b5b-b518-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:23:51.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-mktqv" for this suite.
Aug  2 11:23:57.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:23:58.037: INFO: namespace: e2e-tests-var-expansion-mktqv, resource: bindings, ignored listing per whitelist
Aug  2 11:23:58.098: INFO: namespace e2e-tests-var-expansion-mktqv deletion completed in 6.136293372s

• [SLOW TEST:8.259 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:23:58.099: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-052716d7-b518-11e9-b8f5-0a4acaace53e
STEP: Creating a pod to test consume secrets
Aug  2 11:23:58.187: INFO: Waiting up to 5m0s for pod "pod-secrets-0527960d-b518-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-secrets-qqptg" to be "success or failure"
Aug  2 11:23:58.195: INFO: Pod "pod-secrets-0527960d-b518-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 7.439788ms
Aug  2 11:24:00.198: INFO: Pod "pod-secrets-0527960d-b518-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010715439s
STEP: Saw pod success
Aug  2 11:24:00.198: INFO: Pod "pod-secrets-0527960d-b518-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 11:24:00.200: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-secrets-0527960d-b518-11e9-b8f5-0a4acaace53e container secret-volume-test: <nil>
STEP: delete the pod
Aug  2 11:24:00.222: INFO: Waiting for pod pod-secrets-0527960d-b518-11e9-b8f5-0a4acaace53e to disappear
Aug  2 11:24:00.228: INFO: Pod pod-secrets-0527960d-b518-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:24:00.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-qqptg" for this suite.
Aug  2 11:24:06.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:24:06.330: INFO: namespace: e2e-tests-secrets-qqptg, resource: bindings, ignored listing per whitelist
Aug  2 11:24:06.367: INFO: namespace e2e-tests-secrets-qqptg deletion completed in 6.13514981s

• [SLOW TEST:8.268 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:24:06.368: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Aug  2 11:24:06.439: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Aug  2 11:24:06.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 create -f - --namespace=e2e-tests-kubectl-wvrpk'
Aug  2 11:24:06.738: INFO: stderr: ""
Aug  2 11:24:06.738: INFO: stdout: "service/redis-slave created\n"
Aug  2 11:24:06.738: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Aug  2 11:24:06.738: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 create -f - --namespace=e2e-tests-kubectl-wvrpk'
Aug  2 11:24:07.030: INFO: stderr: ""
Aug  2 11:24:07.030: INFO: stdout: "service/redis-master created\n"
Aug  2 11:24:07.030: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Aug  2 11:24:07.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 create -f - --namespace=e2e-tests-kubectl-wvrpk'
Aug  2 11:24:07.439: INFO: stderr: ""
Aug  2 11:24:07.439: INFO: stdout: "service/frontend created\n"
Aug  2 11:24:07.439: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Aug  2 11:24:07.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 create -f - --namespace=e2e-tests-kubectl-wvrpk'
Aug  2 11:24:07.843: INFO: stderr: ""
Aug  2 11:24:07.843: INFO: stdout: "deployment.extensions/frontend created\n"
Aug  2 11:24:07.844: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Aug  2 11:24:07.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 create -f - --namespace=e2e-tests-kubectl-wvrpk'
Aug  2 11:24:08.560: INFO: stderr: ""
Aug  2 11:24:08.560: INFO: stdout: "deployment.extensions/redis-master created\n"
Aug  2 11:24:08.560: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Aug  2 11:24:08.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 create -f - --namespace=e2e-tests-kubectl-wvrpk'
Aug  2 11:24:08.901: INFO: stderr: ""
Aug  2 11:24:08.901: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Aug  2 11:24:08.901: INFO: Waiting for all frontend pods to be Running.
Aug  2 11:25:08.955: INFO: Waiting for frontend to serve content.
Aug  2 11:25:13.976: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Aug  2 11:25:23.996: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Aug  2 11:25:29.011: INFO: Trying to add a new entry to the guestbook.
Aug  2 11:25:29.031: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Aug  2 11:25:29.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-wvrpk'
Aug  2 11:25:29.200: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  2 11:25:29.200: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Aug  2 11:25:29.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-wvrpk'
Aug  2 11:25:29.338: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  2 11:25:29.338: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Aug  2 11:25:29.338: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-wvrpk'
Aug  2 11:25:29.461: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  2 11:25:29.461: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Aug  2 11:25:29.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-wvrpk'
Aug  2 11:25:29.581: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  2 11:25:29.581: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Aug  2 11:25:29.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-wvrpk'
Aug  2 11:25:29.733: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  2 11:25:29.733: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Aug  2 11:25:29.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-wvrpk'
Aug  2 11:25:29.961: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  2 11:25:29.961: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:25:29.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wvrpk" for this suite.
Aug  2 11:26:08.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:26:08.139: INFO: namespace: e2e-tests-kubectl-wvrpk, resource: bindings, ignored listing per whitelist
Aug  2 11:26:08.163: INFO: namespace e2e-tests-kubectl-wvrpk deletion completed in 38.177333129s

• [SLOW TEST:121.795 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:26:08.163: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-52b40e5d-b518-11e9-b8f5-0a4acaace53e
STEP: Creating secret with name s-test-opt-upd-52b40ea5-b518-11e9-b8f5-0a4acaace53e
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-52b40e5d-b518-11e9-b8f5-0a4acaace53e
STEP: Updating secret s-test-opt-upd-52b40ea5-b518-11e9-b8f5-0a4acaace53e
STEP: Creating secret with name s-test-opt-create-52b40eba-b518-11e9-b8f5-0a4acaace53e
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:26:12.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gr7z5" for this suite.
Aug  2 11:26:34.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:26:34.468: INFO: namespace: e2e-tests-projected-gr7z5, resource: bindings, ignored listing per whitelist
Aug  2 11:26:34.542: INFO: namespace e2e-tests-projected-gr7z5 deletion completed in 22.137960714s

• [SLOW TEST:26.380 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:26:34.543: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-6266580b-b518-11e9-b8f5-0a4acaace53e
STEP: Creating a pod to test consume configMaps
Aug  2 11:26:34.633: INFO: Waiting up to 5m0s for pod "pod-configmaps-6266fced-b518-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-configmap-fnd7z" to be "success or failure"
Aug  2 11:26:34.645: INFO: Pod "pod-configmaps-6266fced-b518-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 12.042204ms
Aug  2 11:26:36.649: INFO: Pod "pod-configmaps-6266fced-b518-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015255566s
STEP: Saw pod success
Aug  2 11:26:36.649: INFO: Pod "pod-configmaps-6266fced-b518-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 11:26:36.650: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-configmaps-6266fced-b518-11e9-b8f5-0a4acaace53e container configmap-volume-test: <nil>
STEP: delete the pod
Aug  2 11:26:36.703: INFO: Waiting for pod pod-configmaps-6266fced-b518-11e9-b8f5-0a4acaace53e to disappear
Aug  2 11:26:36.707: INFO: Pod pod-configmaps-6266fced-b518-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:26:36.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-fnd7z" for this suite.
Aug  2 11:26:42.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:26:42.813: INFO: namespace: e2e-tests-configmap-fnd7z, resource: bindings, ignored listing per whitelist
Aug  2 11:26:42.838: INFO: namespace e2e-tests-configmap-fnd7z deletion completed in 6.128584788s

• [SLOW TEST:8.295 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:26:42.839: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-67587530-b518-11e9-b8f5-0a4acaace53e
STEP: Creating a pod to test consume secrets
Aug  2 11:26:42.928: INFO: Waiting up to 5m0s for pod "pod-secrets-6759050f-b518-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-secrets-xmjm7" to be "success or failure"
Aug  2 11:26:42.932: INFO: Pod "pod-secrets-6759050f-b518-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.593076ms
Aug  2 11:26:44.936: INFO: Pod "pod-secrets-6759050f-b518-11e9-b8f5-0a4acaace53e": Phase="Running", Reason="", readiness=true. Elapsed: 2.007425308s
Aug  2 11:26:46.940: INFO: Pod "pod-secrets-6759050f-b518-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011371156s
STEP: Saw pod success
Aug  2 11:26:46.940: INFO: Pod "pod-secrets-6759050f-b518-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 11:26:46.942: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-secrets-6759050f-b518-11e9-b8f5-0a4acaace53e container secret-volume-test: <nil>
STEP: delete the pod
Aug  2 11:26:46.964: INFO: Waiting for pod pod-secrets-6759050f-b518-11e9-b8f5-0a4acaace53e to disappear
Aug  2 11:26:46.967: INFO: Pod pod-secrets-6759050f-b518-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:26:46.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-xmjm7" for this suite.
Aug  2 11:26:52.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:26:53.070: INFO: namespace: e2e-tests-secrets-xmjm7, resource: bindings, ignored listing per whitelist
Aug  2 11:26:53.089: INFO: namespace e2e-tests-secrets-xmjm7 deletion completed in 6.116505234s

• [SLOW TEST:10.251 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:26:53.090: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Aug  2 11:26:53.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 create -f - --namespace=e2e-tests-kubectl-xwbrk'
Aug  2 11:26:53.490: INFO: stderr: ""
Aug  2 11:26:53.490: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug  2 11:26:53.490: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-xwbrk'
Aug  2 11:26:53.617: INFO: stderr: ""
Aug  2 11:26:53.617: INFO: stdout: "update-demo-nautilus-4wzzw update-demo-nautilus-wf99l "
Aug  2 11:26:53.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods update-demo-nautilus-4wzzw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xwbrk'
Aug  2 11:26:53.737: INFO: stderr: ""
Aug  2 11:26:53.737: INFO: stdout: ""
Aug  2 11:26:53.737: INFO: update-demo-nautilus-4wzzw is created but not running
Aug  2 11:26:58.738: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-xwbrk'
Aug  2 11:26:58.869: INFO: stderr: ""
Aug  2 11:26:58.869: INFO: stdout: "update-demo-nautilus-4wzzw update-demo-nautilus-wf99l "
Aug  2 11:26:58.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods update-demo-nautilus-4wzzw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xwbrk'
Aug  2 11:26:59.002: INFO: stderr: ""
Aug  2 11:26:59.002: INFO: stdout: "true"
Aug  2 11:26:59.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods update-demo-nautilus-4wzzw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xwbrk'
Aug  2 11:26:59.133: INFO: stderr: ""
Aug  2 11:26:59.133: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug  2 11:26:59.133: INFO: validating pod update-demo-nautilus-4wzzw
Aug  2 11:26:59.140: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  2 11:26:59.140: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  2 11:26:59.140: INFO: update-demo-nautilus-4wzzw is verified up and running
Aug  2 11:26:59.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods update-demo-nautilus-wf99l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xwbrk'
Aug  2 11:26:59.256: INFO: stderr: ""
Aug  2 11:26:59.256: INFO: stdout: "true"
Aug  2 11:26:59.256: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods update-demo-nautilus-wf99l -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xwbrk'
Aug  2 11:26:59.371: INFO: stderr: ""
Aug  2 11:26:59.371: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug  2 11:26:59.371: INFO: validating pod update-demo-nautilus-wf99l
Aug  2 11:26:59.378: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  2 11:26:59.378: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  2 11:26:59.378: INFO: update-demo-nautilus-wf99l is verified up and running
STEP: scaling down the replication controller
Aug  2 11:26:59.383: INFO: scanned /root for discovery docs: <nil>
Aug  2 11:26:59.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-xwbrk'
Aug  2 11:27:00.540: INFO: stderr: ""
Aug  2 11:27:00.541: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug  2 11:27:00.541: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-xwbrk'
Aug  2 11:27:00.651: INFO: stderr: ""
Aug  2 11:27:00.651: INFO: stdout: "update-demo-nautilus-4wzzw update-demo-nautilus-wf99l "
STEP: Replicas for name=update-demo: expected=1 actual=2
Aug  2 11:27:05.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-xwbrk'
Aug  2 11:27:05.773: INFO: stderr: ""
Aug  2 11:27:05.773: INFO: stdout: "update-demo-nautilus-4wzzw "
Aug  2 11:27:05.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods update-demo-nautilus-4wzzw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xwbrk'
Aug  2 11:27:05.887: INFO: stderr: ""
Aug  2 11:27:05.887: INFO: stdout: "true"
Aug  2 11:27:05.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods update-demo-nautilus-4wzzw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xwbrk'
Aug  2 11:27:06.009: INFO: stderr: ""
Aug  2 11:27:06.009: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug  2 11:27:06.009: INFO: validating pod update-demo-nautilus-4wzzw
Aug  2 11:27:06.014: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  2 11:27:06.014: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  2 11:27:06.014: INFO: update-demo-nautilus-4wzzw is verified up and running
STEP: scaling up the replication controller
Aug  2 11:27:06.018: INFO: scanned /root for discovery docs: <nil>
Aug  2 11:27:06.018: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-xwbrk'
Aug  2 11:27:07.176: INFO: stderr: ""
Aug  2 11:27:07.176: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug  2 11:27:07.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-xwbrk'
Aug  2 11:27:07.322: INFO: stderr: ""
Aug  2 11:27:07.322: INFO: stdout: "update-demo-nautilus-4wzzw update-demo-nautilus-h5tjf "
Aug  2 11:27:07.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods update-demo-nautilus-4wzzw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xwbrk'
Aug  2 11:27:07.447: INFO: stderr: ""
Aug  2 11:27:07.447: INFO: stdout: "true"
Aug  2 11:27:07.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods update-demo-nautilus-4wzzw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xwbrk'
Aug  2 11:27:07.568: INFO: stderr: ""
Aug  2 11:27:07.568: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug  2 11:27:07.568: INFO: validating pod update-demo-nautilus-4wzzw
Aug  2 11:27:07.572: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  2 11:27:07.572: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  2 11:27:07.572: INFO: update-demo-nautilus-4wzzw is verified up and running
Aug  2 11:27:07.572: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods update-demo-nautilus-h5tjf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xwbrk'
Aug  2 11:27:07.707: INFO: stderr: ""
Aug  2 11:27:07.707: INFO: stdout: ""
Aug  2 11:27:07.707: INFO: update-demo-nautilus-h5tjf is created but not running
Aug  2 11:27:12.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-xwbrk'
Aug  2 11:27:12.817: INFO: stderr: ""
Aug  2 11:27:12.817: INFO: stdout: "update-demo-nautilus-4wzzw update-demo-nautilus-h5tjf "
Aug  2 11:27:12.817: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods update-demo-nautilus-4wzzw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xwbrk'
Aug  2 11:27:12.924: INFO: stderr: ""
Aug  2 11:27:12.924: INFO: stdout: "true"
Aug  2 11:27:12.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods update-demo-nautilus-4wzzw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xwbrk'
Aug  2 11:27:13.024: INFO: stderr: ""
Aug  2 11:27:13.024: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug  2 11:27:13.024: INFO: validating pod update-demo-nautilus-4wzzw
Aug  2 11:27:13.028: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  2 11:27:13.028: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  2 11:27:13.028: INFO: update-demo-nautilus-4wzzw is verified up and running
Aug  2 11:27:13.028: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods update-demo-nautilus-h5tjf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xwbrk'
Aug  2 11:27:13.137: INFO: stderr: ""
Aug  2 11:27:13.137: INFO: stdout: "true"
Aug  2 11:27:13.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods update-demo-nautilus-h5tjf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xwbrk'
Aug  2 11:27:13.249: INFO: stderr: ""
Aug  2 11:27:13.249: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug  2 11:27:13.249: INFO: validating pod update-demo-nautilus-h5tjf
Aug  2 11:27:13.257: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  2 11:27:13.258: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  2 11:27:13.258: INFO: update-demo-nautilus-h5tjf is verified up and running
STEP: using delete to clean up resources
Aug  2 11:27:13.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-xwbrk'
Aug  2 11:27:13.377: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  2 11:27:13.377: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug  2 11:27:13.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-xwbrk'
Aug  2 11:27:13.524: INFO: stderr: "No resources found.\n"
Aug  2 11:27:13.524: INFO: stdout: ""
Aug  2 11:27:13.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods -l name=update-demo --namespace=e2e-tests-kubectl-xwbrk -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug  2 11:27:13.658: INFO: stderr: ""
Aug  2 11:27:13.658: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:27:13.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xwbrk" for this suite.
Aug  2 11:27:35.680: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:27:35.738: INFO: namespace: e2e-tests-kubectl-xwbrk, resource: bindings, ignored listing per whitelist
Aug  2 11:27:35.803: INFO: namespace e2e-tests-kubectl-xwbrk deletion completed in 22.142703777s

• [SLOW TEST:42.714 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:27:35.808: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Aug  2 11:27:35.889: INFO: Waiting up to 5m0s for pod "pod-86e9e893-b518-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-emptydir-87x7q" to be "success or failure"
Aug  2 11:27:35.894: INFO: Pod "pod-86e9e893-b518-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.497693ms
Aug  2 11:27:37.897: INFO: Pod "pod-86e9e893-b518-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007671446s
STEP: Saw pod success
Aug  2 11:27:37.897: INFO: Pod "pod-86e9e893-b518-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 11:27:37.899: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-86e9e893-b518-11e9-b8f5-0a4acaace53e container test-container: <nil>
STEP: delete the pod
Aug  2 11:27:37.919: INFO: Waiting for pod pod-86e9e893-b518-11e9-b8f5-0a4acaace53e to disappear
Aug  2 11:27:37.926: INFO: Pod pod-86e9e893-b518-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:27:37.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-87x7q" for this suite.
Aug  2 11:27:43.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:27:43.993: INFO: namespace: e2e-tests-emptydir-87x7q, resource: bindings, ignored listing per whitelist
Aug  2 11:27:44.043: INFO: namespace e2e-tests-emptydir-87x7q deletion completed in 6.113232838s

• [SLOW TEST:8.235 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:27:44.043: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-8bd12ae7-b518-11e9-b8f5-0a4acaace53e
STEP: Creating a pod to test consume secrets
Aug  2 11:27:44.119: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8bd1dcba-b518-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-projected-w5q26" to be "success or failure"
Aug  2 11:27:44.127: INFO: Pod "pod-projected-secrets-8bd1dcba-b518-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.759591ms
Aug  2 11:27:46.131: INFO: Pod "pod-projected-secrets-8bd1dcba-b518-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012757308s
STEP: Saw pod success
Aug  2 11:27:46.132: INFO: Pod "pod-projected-secrets-8bd1dcba-b518-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 11:27:46.136: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-projected-secrets-8bd1dcba-b518-11e9-b8f5-0a4acaace53e container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug  2 11:27:46.155: INFO: Waiting for pod pod-projected-secrets-8bd1dcba-b518-11e9-b8f5-0a4acaace53e to disappear
Aug  2 11:27:46.161: INFO: Pod pod-projected-secrets-8bd1dcba-b518-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:27:46.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-w5q26" for this suite.
Aug  2 11:27:52.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:27:52.221: INFO: namespace: e2e-tests-projected-w5q26, resource: bindings, ignored listing per whitelist
Aug  2 11:27:52.285: INFO: namespace e2e-tests-projected-w5q26 deletion completed in 6.121090347s

• [SLOW TEST:8.242 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:27:52.287: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug  2 11:27:52.381: INFO: Waiting up to 5m0s for pod "downwardapi-volume-90be8b8b-b518-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-downward-api-hcv99" to be "success or failure"
Aug  2 11:27:52.389: INFO: Pod "downwardapi-volume-90be8b8b-b518-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 7.37741ms
Aug  2 11:27:54.392: INFO: Pod "downwardapi-volume-90be8b8b-b518-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010671047s
STEP: Saw pod success
Aug  2 11:27:54.392: INFO: Pod "downwardapi-volume-90be8b8b-b518-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 11:27:54.394: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod downwardapi-volume-90be8b8b-b518-11e9-b8f5-0a4acaace53e container client-container: <nil>
STEP: delete the pod
Aug  2 11:27:54.419: INFO: Waiting for pod downwardapi-volume-90be8b8b-b518-11e9-b8f5-0a4acaace53e to disappear
Aug  2 11:27:54.423: INFO: Pod downwardapi-volume-90be8b8b-b518-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:27:54.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-hcv99" for this suite.
Aug  2 11:28:00.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:28:00.492: INFO: namespace: e2e-tests-downward-api-hcv99, resource: bindings, ignored listing per whitelist
Aug  2 11:28:00.545: INFO: namespace e2e-tests-downward-api-hcv99 deletion completed in 6.118438148s

• [SLOW TEST:8.259 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:28:00.547: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Aug  2 11:28:00.672: INFO: PodSpec: initContainers in spec.initContainers
Aug  2 11:28:46.992: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-95b0830a-b518-11e9-b8f5-0a4acaace53e", GenerateName:"", Namespace:"e2e-tests-init-container-5r2p6", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-5r2p6/pods/pod-init-95b0830a-b518-11e9-b8f5-0a4acaace53e", UID:"95b1de70-b518-11e9-9105-fa163e46117c", ResourceVersion:"24681", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63700342080, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"time":"672647071", "name":"foo"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-4mbgd", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc00190d380), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-4mbgd", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-4mbgd", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-4mbgd", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00217e848), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"test-v1-13-7-gipwxthqfdpj-minion-0", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001fa2660), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00217e8c0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00217e8e0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00217e8e8)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700342080, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700342080, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700342080, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700342080, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.0.11", PodIP:"192.168.232.37", StartTime:(*v1.Time)(0xc00242d7c0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001995490)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001995570)}, Ready:false, RestartCount:3, Image:"docker.io/busybox:1.29", ImageID:"docker-pullable://docker.io/busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://ca6345a3a95013111863368cdeca4c6b6acb5e9420ecb770e6ce84378ef8226a"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00242d800), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00242d7e0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:28:46.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-5r2p6" for this suite.
Aug  2 11:29:09.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:29:09.075: INFO: namespace: e2e-tests-init-container-5r2p6, resource: bindings, ignored listing per whitelist
Aug  2 11:29:09.206: INFO: namespace e2e-tests-init-container-5r2p6 deletion completed in 22.209788641s

• [SLOW TEST:68.659 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:29:09.207: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0802 11:29:19.423045      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug  2 11:29:19.423: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:29:19.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-prw2p" for this suite.
Aug  2 11:29:25.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:29:25.492: INFO: namespace: e2e-tests-gc-prw2p, resource: bindings, ignored listing per whitelist
Aug  2 11:29:25.555: INFO: namespace e2e-tests-gc-prw2p deletion completed in 6.129848795s

• [SLOW TEST:16.349 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:29:25.556: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug  2 11:29:25.633: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:29:26.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-f6lvf" for this suite.
Aug  2 11:29:32.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:29:32.762: INFO: namespace: e2e-tests-custom-resource-definition-f6lvf, resource: bindings, ignored listing per whitelist
Aug  2 11:29:32.797: INFO: namespace e2e-tests-custom-resource-definition-f6lvf deletion completed in 6.113858176s

• [SLOW TEST:7.242 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:29:32.798: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-lf4mw
Aug  2 11:29:36.935: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-lf4mw
STEP: checking the pod's current state and verifying that restartCount is present
Aug  2 11:29:36.937: INFO: Initial restart count of pod liveness-exec is 0
Aug  2 11:30:29.044: INFO: Restart count of pod e2e-tests-container-probe-lf4mw/liveness-exec is now 1 (52.106124014s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:30:29.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-lf4mw" for this suite.
Aug  2 11:30:35.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:30:35.194: INFO: namespace: e2e-tests-container-probe-lf4mw, resource: bindings, ignored listing per whitelist
Aug  2 11:30:35.206: INFO: namespace e2e-tests-container-probe-lf4mw deletion completed in 6.146276093s

• [SLOW TEST:62.408 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:30:35.208: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-f1d92c55-b518-11e9-b8f5-0a4acaace53e
STEP: Creating a pod to test consume secrets
Aug  2 11:30:35.322: INFO: Waiting up to 5m0s for pod "pod-secrets-f1dd53b1-b518-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-secrets-htfll" to be "success or failure"
Aug  2 11:30:35.328: INFO: Pod "pod-secrets-f1dd53b1-b518-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.662227ms
Aug  2 11:30:37.333: INFO: Pod "pod-secrets-f1dd53b1-b518-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011258362s
STEP: Saw pod success
Aug  2 11:30:37.333: INFO: Pod "pod-secrets-f1dd53b1-b518-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 11:30:37.335: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-secrets-f1dd53b1-b518-11e9-b8f5-0a4acaace53e container secret-volume-test: <nil>
STEP: delete the pod
Aug  2 11:30:37.353: INFO: Waiting for pod pod-secrets-f1dd53b1-b518-11e9-b8f5-0a4acaace53e to disappear
Aug  2 11:30:37.360: INFO: Pod pod-secrets-f1dd53b1-b518-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:30:37.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-htfll" for this suite.
Aug  2 11:30:43.385: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:30:43.485: INFO: namespace: e2e-tests-secrets-htfll, resource: bindings, ignored listing per whitelist
Aug  2 11:30:43.513: INFO: namespace e2e-tests-secrets-htfll deletion completed in 6.149171521s
STEP: Destroying namespace "e2e-tests-secret-namespace-t5976" for this suite.
Aug  2 11:30:50.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:30:50.489: INFO: namespace: e2e-tests-secret-namespace-t5976, resource: bindings, ignored listing per whitelist
Aug  2 11:30:50.496: INFO: namespace e2e-tests-secret-namespace-t5976 deletion completed in 6.983457877s

• [SLOW TEST:15.289 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:30:50.502: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-fafe92d8-b518-11e9-b8f5-0a4acaace53e
STEP: Creating a pod to test consume secrets
Aug  2 11:30:50.646: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-faff3d0f-b518-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-projected-knvn9" to be "success or failure"
Aug  2 11:30:50.658: INFO: Pod "pod-projected-secrets-faff3d0f-b518-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 12.711588ms
Aug  2 11:30:52.663: INFO: Pod "pod-projected-secrets-faff3d0f-b518-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016868519s
STEP: Saw pod success
Aug  2 11:30:52.663: INFO: Pod "pod-projected-secrets-faff3d0f-b518-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 11:30:52.665: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-projected-secrets-faff3d0f-b518-11e9-b8f5-0a4acaace53e container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug  2 11:30:52.688: INFO: Waiting for pod pod-projected-secrets-faff3d0f-b518-11e9-b8f5-0a4acaace53e to disappear
Aug  2 11:30:52.693: INFO: Pod pod-projected-secrets-faff3d0f-b518-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:30:52.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-knvn9" for this suite.
Aug  2 11:30:58.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:30:58.787: INFO: namespace: e2e-tests-projected-knvn9, resource: bindings, ignored listing per whitelist
Aug  2 11:30:58.822: INFO: namespace e2e-tests-projected-knvn9 deletion completed in 6.12500602s

• [SLOW TEST:8.320 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:30:58.822: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Aug  2 11:30:58.929: INFO: Waiting up to 5m0s for pod "pod-ffef1570-b518-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-emptydir-xlvht" to be "success or failure"
Aug  2 11:30:58.935: INFO: Pod "pod-ffef1570-b518-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.334312ms
Aug  2 11:31:00.938: INFO: Pod "pod-ffef1570-b518-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008645568s
STEP: Saw pod success
Aug  2 11:31:00.938: INFO: Pod "pod-ffef1570-b518-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 11:31:00.940: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-ffef1570-b518-11e9-b8f5-0a4acaace53e container test-container: <nil>
STEP: delete the pod
Aug  2 11:31:00.967: INFO: Waiting for pod pod-ffef1570-b518-11e9-b8f5-0a4acaace53e to disappear
Aug  2 11:31:01.176: INFO: Pod pod-ffef1570-b518-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:31:01.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-xlvht" for this suite.
Aug  2 11:31:07.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:31:07.233: INFO: namespace: e2e-tests-emptydir-xlvht, resource: bindings, ignored listing per whitelist
Aug  2 11:31:07.325: INFO: namespace e2e-tests-emptydir-xlvht deletion completed in 6.139861757s

• [SLOW TEST:8.503 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:31:07.325: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug  2 11:31:07.413: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-kcdr9'
Aug  2 11:31:08.587: INFO: stderr: ""
Aug  2 11:31:08.587: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Aug  2 11:31:08.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-kcdr9'
Aug  2 11:31:09.745: INFO: stderr: ""
Aug  2 11:31:09.745: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:31:09.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kcdr9" for this suite.
Aug  2 11:31:15.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:31:15.822: INFO: namespace: e2e-tests-kubectl-kcdr9, resource: bindings, ignored listing per whitelist
Aug  2 11:31:15.875: INFO: namespace e2e-tests-kubectl-kcdr9 deletion completed in 6.125418553s

• [SLOW TEST:8.550 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:31:15.878: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug  2 11:31:15.963: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0a16b1ba-b519-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-downward-api-487gm" to be "success or failure"
Aug  2 11:31:15.967: INFO: Pod "downwardapi-volume-0a16b1ba-b519-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.338778ms
Aug  2 11:31:18.853: INFO: Pod "downwardapi-volume-0a16b1ba-b519-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.88971017s
STEP: Saw pod success
Aug  2 11:31:18.853: INFO: Pod "downwardapi-volume-0a16b1ba-b519-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 11:31:18.856: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod downwardapi-volume-0a16b1ba-b519-11e9-b8f5-0a4acaace53e container client-container: <nil>
STEP: delete the pod
Aug  2 11:31:18.888: INFO: Waiting for pod downwardapi-volume-0a16b1ba-b519-11e9-b8f5-0a4acaace53e to disappear
Aug  2 11:31:18.893: INFO: Pod downwardapi-volume-0a16b1ba-b519-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:31:18.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-487gm" for this suite.
Aug  2 11:31:24.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:31:24.980: INFO: namespace: e2e-tests-downward-api-487gm, resource: bindings, ignored listing per whitelist
Aug  2 11:31:25.216: INFO: namespace e2e-tests-downward-api-487gm deletion completed in 6.319631894s

• [SLOW TEST:9.339 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:31:25.217: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Aug  2 11:31:25.377: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-scwvc,SelfLink:/api/v1/namespaces/e2e-tests-watch-scwvc/configmaps/e2e-watch-test-label-changed,UID:0fb1bbc3-b519-11e9-9105-fa163e46117c,ResourceVersion:25374,Generation:0,CreationTimestamp:2019-08-02 11:31:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug  2 11:31:25.378: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-scwvc,SelfLink:/api/v1/namespaces/e2e-tests-watch-scwvc/configmaps/e2e-watch-test-label-changed,UID:0fb1bbc3-b519-11e9-9105-fa163e46117c,ResourceVersion:25375,Generation:0,CreationTimestamp:2019-08-02 11:31:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Aug  2 11:31:25.378: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-scwvc,SelfLink:/api/v1/namespaces/e2e-tests-watch-scwvc/configmaps/e2e-watch-test-label-changed,UID:0fb1bbc3-b519-11e9-9105-fa163e46117c,ResourceVersion:25376,Generation:0,CreationTimestamp:2019-08-02 11:31:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Aug  2 11:31:35.850: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-scwvc,SelfLink:/api/v1/namespaces/e2e-tests-watch-scwvc/configmaps/e2e-watch-test-label-changed,UID:0fb1bbc3-b519-11e9-9105-fa163e46117c,ResourceVersion:25396,Generation:0,CreationTimestamp:2019-08-02 11:31:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug  2 11:31:35.850: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-scwvc,SelfLink:/api/v1/namespaces/e2e-tests-watch-scwvc/configmaps/e2e-watch-test-label-changed,UID:0fb1bbc3-b519-11e9-9105-fa163e46117c,ResourceVersion:25397,Generation:0,CreationTimestamp:2019-08-02 11:31:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Aug  2 11:31:35.851: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-scwvc,SelfLink:/api/v1/namespaces/e2e-tests-watch-scwvc/configmaps/e2e-watch-test-label-changed,UID:0fb1bbc3-b519-11e9-9105-fa163e46117c,ResourceVersion:25398,Generation:0,CreationTimestamp:2019-08-02 11:31:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:31:35.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-scwvc" for this suite.
Aug  2 11:31:41.870: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:31:41.933: INFO: namespace: e2e-tests-watch-scwvc, resource: bindings, ignored listing per whitelist
Aug  2 11:31:42.015: INFO: namespace e2e-tests-watch-scwvc deletion completed in 6.158141442s

• [SLOW TEST:16.798 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:31:42.015: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-slpbb A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-slpbb;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-slpbb A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-slpbb;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-slpbb.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-slpbb.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-slpbb.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-slpbb.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-slpbb.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-slpbb.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-slpbb.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-slpbb.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-slpbb.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 231.205.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.205.231_udp@PTR;check="$$(dig +tcp +noall +answer +search 231.205.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.205.231_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-slpbb A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-slpbb;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-slpbb A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-slpbb;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-slpbb.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-slpbb.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-slpbb.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-slpbb.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-slpbb.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-slpbb.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-slpbb.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-slpbb.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-slpbb.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 231.205.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.205.231_udp@PTR;check="$$(dig +tcp +noall +answer +search 231.205.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.205.231_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug  2 11:31:46.212: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:46.217: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:46.221: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-slpbb from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:46.224: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-slpbb from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:46.227: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:46.229: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:46.231: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:46.234: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:46.241: INFO: Unable to read wheezy_udp@PodARecord from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:46.243: INFO: Unable to read wheezy_tcp@PodARecord from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:46.254: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:46.256: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:46.258: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-slpbb from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:46.261: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-slpbb from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:46.263: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:46.266: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:46.268: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:46.271: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:46.278: INFO: Unable to read jessie_udp@PodARecord from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:46.282: INFO: Unable to read jessie_tcp@PodARecord from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:46.299: INFO: Lookups using e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-slpbb wheezy_tcp@dns-test-service.e2e-tests-dns-slpbb wheezy_udp@dns-test-service.e2e-tests-dns-slpbb.svc wheezy_tcp@dns-test-service.e2e-tests-dns-slpbb.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-slpbb jessie_tcp@dns-test-service.e2e-tests-dns-slpbb jessie_udp@dns-test-service.e2e-tests-dns-slpbb.svc jessie_tcp@dns-test-service.e2e-tests-dns-slpbb.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc jessie_udp@PodARecord jessie_tcp@PodARecord]

Aug  2 11:31:51.305: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:51.309: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:51.313: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-slpbb from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:51.316: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-slpbb from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:51.319: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:51.322: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:51.325: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:51.328: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:51.532: INFO: Unable to read wheezy_udp@PodARecord from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:51.536: INFO: Unable to read wheezy_tcp@PodARecord from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:51.546: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:51.548: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:51.551: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-slpbb from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:51.555: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-slpbb from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:51.558: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:51.561: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:51.564: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:51.566: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:51.574: INFO: Unable to read jessie_udp@PodARecord from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:51.577: INFO: Unable to read jessie_tcp@PodARecord from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:51.583: INFO: Lookups using e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-slpbb wheezy_tcp@dns-test-service.e2e-tests-dns-slpbb wheezy_udp@dns-test-service.e2e-tests-dns-slpbb.svc wheezy_tcp@dns-test-service.e2e-tests-dns-slpbb.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-slpbb jessie_tcp@dns-test-service.e2e-tests-dns-slpbb jessie_udp@dns-test-service.e2e-tests-dns-slpbb.svc jessie_tcp@dns-test-service.e2e-tests-dns-slpbb.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc jessie_udp@PodARecord jessie_tcp@PodARecord]

Aug  2 11:31:56.305: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:56.308: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:56.310: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-slpbb from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:56.313: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-slpbb from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:56.316: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:56.318: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:56.320: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:56.323: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:56.332: INFO: Unable to read wheezy_udp@PodARecord from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:56.334: INFO: Unable to read wheezy_tcp@PodARecord from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:56.342: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:56.346: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:56.349: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-slpbb from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:56.351: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-slpbb from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:56.353: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:56.356: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:56.359: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:56.362: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:56.370: INFO: Unable to read jessie_udp@PodARecord from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:56.373: INFO: Unable to read jessie_tcp@PodARecord from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:31:56.379: INFO: Lookups using e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-slpbb wheezy_tcp@dns-test-service.e2e-tests-dns-slpbb wheezy_udp@dns-test-service.e2e-tests-dns-slpbb.svc wheezy_tcp@dns-test-service.e2e-tests-dns-slpbb.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-slpbb jessie_tcp@dns-test-service.e2e-tests-dns-slpbb jessie_udp@dns-test-service.e2e-tests-dns-slpbb.svc jessie_tcp@dns-test-service.e2e-tests-dns-slpbb.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc jessie_udp@PodARecord jessie_tcp@PodARecord]

Aug  2 11:32:01.304: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:01.308: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:01.310: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-slpbb from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:01.313: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-slpbb from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:01.315: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:01.319: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:01.324: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:01.329: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:01.340: INFO: Unable to read wheezy_udp@PodARecord from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:01.344: INFO: Unable to read wheezy_tcp@PodARecord from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:01.353: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:01.362: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:01.365: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-slpbb from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:01.367: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-slpbb from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:01.371: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:01.376: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:01.378: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:01.381: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:01.388: INFO: Unable to read jessie_udp@PodARecord from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:01.391: INFO: Unable to read jessie_tcp@PodARecord from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:01.397: INFO: Lookups using e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-slpbb wheezy_tcp@dns-test-service.e2e-tests-dns-slpbb wheezy_udp@dns-test-service.e2e-tests-dns-slpbb.svc wheezy_tcp@dns-test-service.e2e-tests-dns-slpbb.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-slpbb jessie_tcp@dns-test-service.e2e-tests-dns-slpbb jessie_udp@dns-test-service.e2e-tests-dns-slpbb.svc jessie_tcp@dns-test-service.e2e-tests-dns-slpbb.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc jessie_udp@PodARecord jessie_tcp@PodARecord]

Aug  2 11:32:06.304: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:06.307: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:06.310: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-slpbb from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:06.313: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-slpbb from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:06.318: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:06.321: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:06.325: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:06.328: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:06.335: INFO: Unable to read wheezy_udp@PodARecord from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:06.338: INFO: Unable to read wheezy_tcp@PodARecord from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:06.346: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:06.348: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:06.351: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-slpbb from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:06.354: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-slpbb from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:06.357: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:06.360: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:06.363: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:06.367: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:06.377: INFO: Unable to read jessie_udp@PodARecord from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:06.380: INFO: Unable to read jessie_tcp@PodARecord from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:06.386: INFO: Lookups using e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-slpbb wheezy_tcp@dns-test-service.e2e-tests-dns-slpbb wheezy_udp@dns-test-service.e2e-tests-dns-slpbb.svc wheezy_tcp@dns-test-service.e2e-tests-dns-slpbb.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-slpbb jessie_tcp@dns-test-service.e2e-tests-dns-slpbb jessie_udp@dns-test-service.e2e-tests-dns-slpbb.svc jessie_tcp@dns-test-service.e2e-tests-dns-slpbb.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc jessie_udp@PodARecord jessie_tcp@PodARecord]

Aug  2 11:32:11.311: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:11.314: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:11.318: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-slpbb from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:11.320: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-slpbb from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:11.323: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:11.326: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:11.328: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:11.331: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:11.340: INFO: Unable to read wheezy_udp@PodARecord from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:11.342: INFO: Unable to read wheezy_tcp@PodARecord from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:11.351: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:11.353: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:11.356: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-slpbb from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:11.358: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-slpbb from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:11.361: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:11.363: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:11.367: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:11.370: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:11.379: INFO: Unable to read jessie_udp@PodARecord from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:11.382: INFO: Unable to read jessie_tcp@PodARecord from pod e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e: the server could not find the requested resource (get pods dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e)
Aug  2 11:32:11.394: INFO: Lookups using e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-slpbb wheezy_tcp@dns-test-service.e2e-tests-dns-slpbb wheezy_udp@dns-test-service.e2e-tests-dns-slpbb.svc wheezy_tcp@dns-test-service.e2e-tests-dns-slpbb.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-slpbb jessie_tcp@dns-test-service.e2e-tests-dns-slpbb jessie_udp@dns-test-service.e2e-tests-dns-slpbb.svc jessie_tcp@dns-test-service.e2e-tests-dns-slpbb.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-slpbb.svc jessie_udp@PodARecord jessie_tcp@PodARecord]

Aug  2 11:32:16.373: INFO: DNS probes using e2e-tests-dns-slpbb/dns-test-19b5b354-b519-11e9-b8f5-0a4acaace53e succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:32:16.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-slpbb" for this suite.
Aug  2 11:32:22.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:32:22.522: INFO: namespace: e2e-tests-dns-slpbb, resource: bindings, ignored listing per whitelist
Aug  2 11:32:22.589: INFO: namespace e2e-tests-dns-slpbb deletion completed in 6.153145714s

• [SLOW TEST:40.574 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:32:22.590: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Aug  2 11:32:22.684: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug  2 11:32:22.689: INFO: Waiting for terminating namespaces to be deleted...
Aug  2 11:32:22.692: INFO: 
Logging pods the kubelet thinks is on node test-v1-13-7-gipwxthqfdpj-minion-0 before test
Aug  2 11:32:22.702: INFO: calico-kube-controllers-7fbc9d65bb-nzhzn from kube-system started at 2019-08-02 09:12:12 +0000 UTC (1 container statuses recorded)
Aug  2 11:32:22.702: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Aug  2 11:32:22.702: INFO: heapster-9d5d7fffd-6gk8p from kube-system started at 2019-08-02 09:12:12 +0000 UTC (1 container statuses recorded)
Aug  2 11:32:22.702: INFO: 	Container heapster ready: true, restart count 0
Aug  2 11:32:22.702: INFO: coredns-d9c54b456-2shsm from kube-system started at 2019-08-02 09:12:12 +0000 UTC (1 container statuses recorded)
Aug  2 11:32:22.702: INFO: 	Container coredns ready: true, restart count 0
Aug  2 11:32:22.702: INFO: kubernetes-dashboard-76894767d-7xvg4 from kube-system started at 2019-08-02 09:12:12 +0000 UTC (1 container statuses recorded)
Aug  2 11:32:22.703: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Aug  2 11:32:22.703: INFO: kube-dns-autoscaler-7745486984-65d84 from kube-system started at 2019-08-02 09:12:12 +0000 UTC (1 container statuses recorded)
Aug  2 11:32:22.703: INFO: 	Container autoscaler ready: true, restart count 0
Aug  2 11:32:22.703: INFO: npd-7m9j6 from kube-system started at 2019-08-02 09:12:12 +0000 UTC (1 container statuses recorded)
Aug  2 11:32:22.703: INFO: 	Container node-problem-detector ready: true, restart count 0
Aug  2 11:32:22.703: INFO: calico-node-m4lm9 from kube-system started at 2019-08-02 09:11:32 +0000 UTC (2 container statuses recorded)
Aug  2 11:32:22.703: INFO: 	Container calico-node ready: true, restart count 0
Aug  2 11:32:22.703: INFO: 	Container install-cni ready: true, restart count 0
Aug  2 11:32:22.703: INFO: sonobuoy from heptio-sonobuoy started at 2019-08-02 10:04:09 +0000 UTC (1 container statuses recorded)
Aug  2 11:32:22.703: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug  2 11:32:22.703: INFO: sonobuoy-systemd-logs-daemon-set-a44350f5542845ed-2k4ng from heptio-sonobuoy started at 2019-08-02 10:04:24 +0000 UTC (2 container statuses recorded)
Aug  2 11:32:22.703: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Aug  2 11:32:22.703: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug  2 11:32:22.703: INFO: coredns-d9c54b456-4j4d9 from kube-system started at 2019-08-02 09:13:00 +0000 UTC (1 container statuses recorded)
Aug  2 11:32:22.703: INFO: 	Container coredns ready: true, restart count 0
Aug  2 11:32:22.703: INFO: sonobuoy-e2e-job-3e746bac374b400e from heptio-sonobuoy started at 2019-08-02 10:04:24 +0000 UTC (2 container statuses recorded)
Aug  2 11:32:22.703: INFO: 	Container e2e ready: true, restart count 0
Aug  2 11:32:22.703: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15b717c7dec92dd4], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:32:23.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-54tbl" for this suite.
Aug  2 11:32:29.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:32:29.865: INFO: namespace: e2e-tests-sched-pred-54tbl, resource: bindings, ignored listing per whitelist
Aug  2 11:32:29.871: INFO: namespace e2e-tests-sched-pred-54tbl deletion completed in 6.12647445s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.281 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:32:29.873: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-3632b374-b519-11e9-b8f5-0a4acaace53e
STEP: Creating secret with name s-test-opt-upd-3632b3dd-b519-11e9-b8f5-0a4acaace53e
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-3632b374-b519-11e9-b8f5-0a4acaace53e
STEP: Updating secret s-test-opt-upd-3632b3dd-b519-11e9-b8f5-0a4acaace53e
STEP: Creating secret with name s-test-opt-create-3632b601-b519-11e9-b8f5-0a4acaace53e
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:32:34.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-92kz4" for this suite.
Aug  2 11:32:56.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:32:56.245: INFO: namespace: e2e-tests-secrets-92kz4, resource: bindings, ignored listing per whitelist
Aug  2 11:32:56.267: INFO: namespace e2e-tests-secrets-92kz4 deletion completed in 22.186038272s

• [SLOW TEST:26.395 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:32:56.269: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0802 11:33:36.406137      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug  2 11:33:36.406: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:33:36.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-vdkf4" for this suite.
Aug  2 11:33:42.425: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:33:42.711: INFO: namespace: e2e-tests-gc-vdkf4, resource: bindings, ignored listing per whitelist
Aug  2 11:33:42.735: INFO: namespace e2e-tests-gc-vdkf4 deletion completed in 6.325666336s

• [SLOW TEST:46.466 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:33:42.741: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-61db6853-b519-11e9-b8f5-0a4acaace53e
STEP: Creating a pod to test consume secrets
Aug  2 11:33:43.224: INFO: Waiting up to 5m0s for pod "pod-secrets-61dce830-b519-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-secrets-62w8r" to be "success or failure"
Aug  2 11:33:43.243: INFO: Pod "pod-secrets-61dce830-b519-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 17.243099ms
Aug  2 11:33:45.247: INFO: Pod "pod-secrets-61dce830-b519-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020890338s
Aug  2 11:33:47.250: INFO: Pod "pod-secrets-61dce830-b519-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02456165s
STEP: Saw pod success
Aug  2 11:33:47.250: INFO: Pod "pod-secrets-61dce830-b519-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 11:33:47.253: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-secrets-61dce830-b519-11e9-b8f5-0a4acaace53e container secret-env-test: <nil>
STEP: delete the pod
Aug  2 11:33:47.277: INFO: Waiting for pod pod-secrets-61dce830-b519-11e9-b8f5-0a4acaace53e to disappear
Aug  2 11:33:47.281: INFO: Pod pod-secrets-61dce830-b519-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:33:47.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-62w8r" for this suite.
Aug  2 11:33:53.300: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:33:53.401: INFO: namespace: e2e-tests-secrets-62w8r, resource: bindings, ignored listing per whitelist
Aug  2 11:33:53.429: INFO: namespace e2e-tests-secrets-62w8r deletion completed in 6.143898893s

• [SLOW TEST:10.688 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:33:53.429: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug  2 11:33:53.508: INFO: Waiting up to 5m0s for pod "downwardapi-volume-67fe17fd-b519-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-downward-api-9gn47" to be "success or failure"
Aug  2 11:33:53.516: INFO: Pod "downwardapi-volume-67fe17fd-b519-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 7.912802ms
Aug  2 11:33:55.520: INFO: Pod "downwardapi-volume-67fe17fd-b519-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011539531s
Aug  2 11:33:57.523: INFO: Pod "downwardapi-volume-67fe17fd-b519-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014692624s
STEP: Saw pod success
Aug  2 11:33:57.523: INFO: Pod "downwardapi-volume-67fe17fd-b519-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 11:33:57.525: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod downwardapi-volume-67fe17fd-b519-11e9-b8f5-0a4acaace53e container client-container: <nil>
STEP: delete the pod
Aug  2 11:33:57.546: INFO: Waiting for pod downwardapi-volume-67fe17fd-b519-11e9-b8f5-0a4acaace53e to disappear
Aug  2 11:33:57.549: INFO: Pod downwardapi-volume-67fe17fd-b519-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:33:57.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9gn47" for this suite.
Aug  2 11:34:03.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:34:03.674: INFO: namespace: e2e-tests-downward-api-9gn47, resource: bindings, ignored listing per whitelist
Aug  2 11:34:03.714: INFO: namespace e2e-tests-downward-api-9gn47 deletion completed in 6.163236973s

• [SLOW TEST:10.285 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:34:03.715: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug  2 11:34:03.847: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6e26e908-b519-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-projected-c982w" to be "success or failure"
Aug  2 11:34:03.851: INFO: Pod "downwardapi-volume-6e26e908-b519-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.562148ms
Aug  2 11:34:05.855: INFO: Pod "downwardapi-volume-6e26e908-b519-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008941358s
Aug  2 11:34:07.859: INFO: Pod "downwardapi-volume-6e26e908-b519-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012537704s
STEP: Saw pod success
Aug  2 11:34:07.859: INFO: Pod "downwardapi-volume-6e26e908-b519-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 11:34:07.861: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod downwardapi-volume-6e26e908-b519-11e9-b8f5-0a4acaace53e container client-container: <nil>
STEP: delete the pod
Aug  2 11:34:07.881: INFO: Waiting for pod downwardapi-volume-6e26e908-b519-11e9-b8f5-0a4acaace53e to disappear
Aug  2 11:34:07.884: INFO: Pod downwardapi-volume-6e26e908-b519-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:34:07.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-c982w" for this suite.
Aug  2 11:34:13.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:34:13.952: INFO: namespace: e2e-tests-projected-c982w, resource: bindings, ignored listing per whitelist
Aug  2 11:34:14.020: INFO: namespace e2e-tests-projected-c982w deletion completed in 6.13170734s

• [SLOW TEST:10.306 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:34:14.020: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-ccmj
STEP: Creating a pod to test atomic-volume-subpath
Aug  2 11:34:14.112: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-ccmj" in namespace "e2e-tests-subpath-44ngt" to be "success or failure"
Aug  2 11:34:14.118: INFO: Pod "pod-subpath-test-configmap-ccmj": Phase="Pending", Reason="", readiness=false. Elapsed: 6.392332ms
Aug  2 11:34:16.124: INFO: Pod "pod-subpath-test-configmap-ccmj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011702409s
Aug  2 11:34:18.127: INFO: Pod "pod-subpath-test-configmap-ccmj": Phase="Running", Reason="", readiness=false. Elapsed: 4.01489777s
Aug  2 11:34:20.135: INFO: Pod "pod-subpath-test-configmap-ccmj": Phase="Running", Reason="", readiness=false. Elapsed: 6.022896172s
Aug  2 11:34:22.139: INFO: Pod "pod-subpath-test-configmap-ccmj": Phase="Running", Reason="", readiness=false. Elapsed: 8.026609006s
Aug  2 11:34:24.143: INFO: Pod "pod-subpath-test-configmap-ccmj": Phase="Running", Reason="", readiness=false. Elapsed: 10.030704923s
Aug  2 11:34:26.147: INFO: Pod "pod-subpath-test-configmap-ccmj": Phase="Running", Reason="", readiness=false. Elapsed: 12.035261756s
Aug  2 11:34:28.152: INFO: Pod "pod-subpath-test-configmap-ccmj": Phase="Running", Reason="", readiness=false. Elapsed: 14.039587021s
Aug  2 11:34:30.156: INFO: Pod "pod-subpath-test-configmap-ccmj": Phase="Running", Reason="", readiness=false. Elapsed: 16.043920911s
Aug  2 11:34:32.162: INFO: Pod "pod-subpath-test-configmap-ccmj": Phase="Running", Reason="", readiness=false. Elapsed: 18.050339485s
Aug  2 11:34:34.166: INFO: Pod "pod-subpath-test-configmap-ccmj": Phase="Running", Reason="", readiness=false. Elapsed: 20.053544612s
Aug  2 11:34:36.169: INFO: Pod "pod-subpath-test-configmap-ccmj": Phase="Running", Reason="", readiness=false. Elapsed: 22.057475024s
Aug  2 11:34:38.173: INFO: Pod "pod-subpath-test-configmap-ccmj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.06099289s
STEP: Saw pod success
Aug  2 11:34:38.173: INFO: Pod "pod-subpath-test-configmap-ccmj" satisfied condition "success or failure"
Aug  2 11:34:38.175: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-subpath-test-configmap-ccmj container test-container-subpath-configmap-ccmj: <nil>
STEP: delete the pod
Aug  2 11:34:38.205: INFO: Waiting for pod pod-subpath-test-configmap-ccmj to disappear
Aug  2 11:34:38.213: INFO: Pod pod-subpath-test-configmap-ccmj no longer exists
STEP: Deleting pod pod-subpath-test-configmap-ccmj
Aug  2 11:34:38.213: INFO: Deleting pod "pod-subpath-test-configmap-ccmj" in namespace "e2e-tests-subpath-44ngt"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:34:38.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-44ngt" for this suite.
Aug  2 11:34:44.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:34:44.346: INFO: namespace: e2e-tests-subpath-44ngt, resource: bindings, ignored listing per whitelist
Aug  2 11:34:44.353: INFO: namespace e2e-tests-subpath-44ngt deletion completed in 6.132975653s

• [SLOW TEST:30.333 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:34:44.353: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-865a1f62-b519-11e9-b8f5-0a4acaace53e
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-865a1f62-b519-11e9-b8f5-0a4acaace53e
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:34:48.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pkgbs" for this suite.
Aug  2 11:35:10.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:35:10.616: INFO: namespace: e2e-tests-projected-pkgbs, resource: bindings, ignored listing per whitelist
Aug  2 11:35:10.625: INFO: namespace e2e-tests-projected-pkgbs deletion completed in 22.127523987s

• [SLOW TEST:26.271 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:35:10.625: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug  2 11:35:10.790: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Aug  2 11:35:10.799: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 11:35:10.810: INFO: Number of nodes with available pods: 0
Aug  2 11:35:10.810: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 11:35:11.815: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 11:35:11.820: INFO: Number of nodes with available pods: 0
Aug  2 11:35:11.820: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 11:35:12.815: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 11:35:12.817: INFO: Number of nodes with available pods: 1
Aug  2 11:35:12.817: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Aug  2 11:35:12.839: INFO: Wrong image for pod: daemon-set-6svmm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  2 11:35:12.843: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 11:35:13.846: INFO: Wrong image for pod: daemon-set-6svmm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  2 11:35:13.849: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 11:35:14.847: INFO: Wrong image for pod: daemon-set-6svmm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  2 11:35:14.850: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 11:35:15.846: INFO: Wrong image for pod: daemon-set-6svmm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  2 11:35:15.849: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 11:35:16.846: INFO: Wrong image for pod: daemon-set-6svmm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  2 11:35:16.849: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 11:35:17.846: INFO: Wrong image for pod: daemon-set-6svmm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  2 11:35:17.851: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 11:35:18.846: INFO: Wrong image for pod: daemon-set-6svmm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  2 11:35:18.849: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 11:35:19.846: INFO: Wrong image for pod: daemon-set-6svmm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  2 11:35:19.849: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 11:35:20.847: INFO: Wrong image for pod: daemon-set-6svmm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  2 11:35:20.856: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 11:35:21.847: INFO: Wrong image for pod: daemon-set-6svmm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  2 11:35:21.850: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 11:35:22.846: INFO: Wrong image for pod: daemon-set-6svmm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  2 11:35:22.850: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 11:35:23.847: INFO: Wrong image for pod: daemon-set-6svmm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  2 11:35:23.850: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 11:35:24.847: INFO: Wrong image for pod: daemon-set-6svmm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  2 11:35:24.849: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 11:35:25.846: INFO: Wrong image for pod: daemon-set-6svmm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  2 11:35:25.849: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 11:35:26.846: INFO: Wrong image for pod: daemon-set-6svmm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  2 11:35:26.849: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 11:35:27.847: INFO: Wrong image for pod: daemon-set-6svmm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  2 11:35:27.850: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 11:35:28.846: INFO: Wrong image for pod: daemon-set-6svmm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  2 11:35:28.849: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 11:35:29.846: INFO: Wrong image for pod: daemon-set-6svmm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  2 11:35:29.849: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 11:35:30.846: INFO: Wrong image for pod: daemon-set-6svmm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  2 11:35:30.849: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 11:35:31.846: INFO: Wrong image for pod: daemon-set-6svmm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  2 11:35:31.849: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 11:35:32.846: INFO: Wrong image for pod: daemon-set-6svmm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  2 11:35:32.849: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 11:35:33.846: INFO: Wrong image for pod: daemon-set-6svmm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  2 11:35:33.850: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 11:35:34.846: INFO: Wrong image for pod: daemon-set-6svmm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  2 11:35:34.850: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 11:35:35.847: INFO: Wrong image for pod: daemon-set-6svmm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  2 11:35:35.849: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 11:35:36.847: INFO: Wrong image for pod: daemon-set-6svmm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  2 11:35:36.849: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 11:35:37.846: INFO: Wrong image for pod: daemon-set-6svmm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  2 11:35:37.849: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 11:35:38.846: INFO: Wrong image for pod: daemon-set-6svmm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  2 11:35:38.848: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 11:35:39.846: INFO: Wrong image for pod: daemon-set-6svmm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  2 11:35:39.849: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 11:35:40.848: INFO: Wrong image for pod: daemon-set-6svmm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  2 11:35:40.851: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 11:35:41.846: INFO: Wrong image for pod: daemon-set-6svmm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  2 11:35:41.848: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 11:35:42.847: INFO: Wrong image for pod: daemon-set-6svmm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  2 11:35:42.849: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 11:35:43.847: INFO: Wrong image for pod: daemon-set-6svmm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  2 11:35:43.851: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 11:35:44.846: INFO: Wrong image for pod: daemon-set-6svmm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  2 11:35:44.848: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 11:35:45.847: INFO: Wrong image for pod: daemon-set-6svmm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  2 11:35:45.849: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 11:35:46.847: INFO: Wrong image for pod: daemon-set-6svmm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug  2 11:35:46.847: INFO: Pod daemon-set-6svmm is not available
Aug  2 11:35:46.851: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 11:35:47.935: INFO: Pod daemon-set-lfrsb is not available
Aug  2 11:35:47.938: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Aug  2 11:35:47.942: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 11:35:47.946: INFO: Number of nodes with available pods: 0
Aug  2 11:35:47.946: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 11:35:48.949: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 11:35:48.952: INFO: Number of nodes with available pods: 0
Aug  2 11:35:48.952: INFO: Node test-v1-13-7-gipwxthqfdpj-minion-0 is running more than one daemon pod
Aug  2 11:35:49.950: INFO: DaemonSet pods can't tolerate node test-v1-13-7-gipwxthqfdpj-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug  2 11:35:49.953: INFO: Number of nodes with available pods: 1
Aug  2 11:35:49.953: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-sqxj2, will wait for the garbage collector to delete the pods
Aug  2 11:35:50.033: INFO: Deleting DaemonSet.extensions daemon-set took: 7.223154ms
Aug  2 11:35:50.133: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.342142ms
Aug  2 11:35:53.136: INFO: Number of nodes with available pods: 0
Aug  2 11:35:53.137: INFO: Number of running nodes: 0, number of available pods: 0
Aug  2 11:35:53.139: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-sqxj2/daemonsets","resourceVersion":"26363"},"items":null}

Aug  2 11:35:53.141: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-sqxj2/pods","resourceVersion":"26363"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:35:53.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-sqxj2" for this suite.
Aug  2 11:35:59.165: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:35:59.227: INFO: namespace: e2e-tests-daemonsets-sqxj2, resource: bindings, ignored listing per whitelist
Aug  2 11:35:59.280: INFO: namespace e2e-tests-daemonsets-sqxj2 deletion completed in 6.12923641s

• [SLOW TEST:48.656 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:35:59.283: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Aug  2 11:35:59.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 create -f - --namespace=e2e-tests-kubectl-m8fcg'
Aug  2 11:35:59.631: INFO: stderr: ""
Aug  2 11:35:59.631: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug  2 11:35:59.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-m8fcg'
Aug  2 11:35:59.754: INFO: stderr: ""
Aug  2 11:35:59.754: INFO: stdout: "update-demo-nautilus-66r8m update-demo-nautilus-hchjs "
Aug  2 11:35:59.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods update-demo-nautilus-66r8m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-m8fcg'
Aug  2 11:35:59.880: INFO: stderr: ""
Aug  2 11:35:59.880: INFO: stdout: ""
Aug  2 11:35:59.880: INFO: update-demo-nautilus-66r8m is created but not running
Aug  2 11:36:04.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-m8fcg'
Aug  2 11:36:04.994: INFO: stderr: ""
Aug  2 11:36:04.994: INFO: stdout: "update-demo-nautilus-66r8m update-demo-nautilus-hchjs "
Aug  2 11:36:04.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods update-demo-nautilus-66r8m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-m8fcg'
Aug  2 11:36:05.133: INFO: stderr: ""
Aug  2 11:36:05.133: INFO: stdout: "true"
Aug  2 11:36:05.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods update-demo-nautilus-66r8m -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-m8fcg'
Aug  2 11:36:05.244: INFO: stderr: ""
Aug  2 11:36:05.244: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug  2 11:36:05.244: INFO: validating pod update-demo-nautilus-66r8m
Aug  2 11:36:05.253: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  2 11:36:05.253: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  2 11:36:05.253: INFO: update-demo-nautilus-66r8m is verified up and running
Aug  2 11:36:05.253: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods update-demo-nautilus-hchjs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-m8fcg'
Aug  2 11:36:05.383: INFO: stderr: ""
Aug  2 11:36:05.383: INFO: stdout: "true"
Aug  2 11:36:05.384: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods update-demo-nautilus-hchjs -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-m8fcg'
Aug  2 11:36:05.503: INFO: stderr: ""
Aug  2 11:36:05.503: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug  2 11:36:05.503: INFO: validating pod update-demo-nautilus-hchjs
Aug  2 11:36:05.510: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  2 11:36:05.510: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  2 11:36:05.510: INFO: update-demo-nautilus-hchjs is verified up and running
STEP: rolling-update to new replication controller
Aug  2 11:36:05.512: INFO: scanned /root for discovery docs: <nil>
Aug  2 11:36:05.512: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-m8fcg'
Aug  2 11:36:37.084: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Aug  2 11:36:37.084: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug  2 11:36:37.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-m8fcg'
Aug  2 11:36:37.252: INFO: stderr: ""
Aug  2 11:36:37.253: INFO: stdout: "update-demo-kitten-cf6xd update-demo-kitten-x9qls "
Aug  2 11:36:37.253: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods update-demo-kitten-cf6xd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-m8fcg'
Aug  2 11:36:37.383: INFO: stderr: ""
Aug  2 11:36:37.383: INFO: stdout: "true"
Aug  2 11:36:37.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods update-demo-kitten-cf6xd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-m8fcg'
Aug  2 11:36:37.527: INFO: stderr: ""
Aug  2 11:36:37.527: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Aug  2 11:36:37.527: INFO: validating pod update-demo-kitten-cf6xd
Aug  2 11:36:37.534: INFO: got data: {
  "image": "kitten.jpg"
}

Aug  2 11:36:37.534: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Aug  2 11:36:37.534: INFO: update-demo-kitten-cf6xd is verified up and running
Aug  2 11:36:37.534: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods update-demo-kitten-x9qls -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-m8fcg'
Aug  2 11:36:37.654: INFO: stderr: ""
Aug  2 11:36:37.654: INFO: stdout: "true"
Aug  2 11:36:37.655: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-983173982 get pods update-demo-kitten-x9qls -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-m8fcg'
Aug  2 11:36:37.776: INFO: stderr: ""
Aug  2 11:36:37.776: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Aug  2 11:36:37.776: INFO: validating pod update-demo-kitten-x9qls
Aug  2 11:36:37.782: INFO: got data: {
  "image": "kitten.jpg"
}

Aug  2 11:36:37.782: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Aug  2 11:36:37.782: INFO: update-demo-kitten-x9qls is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:36:37.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-m8fcg" for this suite.
Aug  2 11:36:59.796: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:36:59.859: INFO: namespace: e2e-tests-kubectl-m8fcg, resource: bindings, ignored listing per whitelist
Aug  2 11:36:59.918: INFO: namespace e2e-tests-kubectl-m8fcg deletion completed in 22.132341783s

• [SLOW TEST:60.635 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:36:59.921: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug  2 11:37:00.047: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d72dbab0-b519-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-projected-8r7bz" to be "success or failure"
Aug  2 11:37:00.054: INFO: Pod "downwardapi-volume-d72dbab0-b519-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.786837ms
Aug  2 11:37:02.058: INFO: Pod "downwardapi-volume-d72dbab0-b519-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010834722s
STEP: Saw pod success
Aug  2 11:37:02.058: INFO: Pod "downwardapi-volume-d72dbab0-b519-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 11:37:02.061: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod downwardapi-volume-d72dbab0-b519-11e9-b8f5-0a4acaace53e container client-container: <nil>
STEP: delete the pod
Aug  2 11:37:02.092: INFO: Waiting for pod downwardapi-volume-d72dbab0-b519-11e9-b8f5-0a4acaace53e to disappear
Aug  2 11:37:02.097: INFO: Pod downwardapi-volume-d72dbab0-b519-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:37:02.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8r7bz" for this suite.
Aug  2 11:37:08.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:37:08.163: INFO: namespace: e2e-tests-projected-8r7bz, resource: bindings, ignored listing per whitelist
Aug  2 11:37:08.212: INFO: namespace e2e-tests-projected-8r7bz deletion completed in 6.111555417s

• [SLOW TEST:8.292 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:37:08.215: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Aug  2 11:37:08.569: INFO: Pod name wrapped-volume-race-dc2e7d67-b519-11e9-b8f5-0a4acaace53e: Found 0 pods out of 5
Aug  2 11:37:13.578: INFO: Pod name wrapped-volume-race-dc2e7d67-b519-11e9-b8f5-0a4acaace53e: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-dc2e7d67-b519-11e9-b8f5-0a4acaace53e in namespace e2e-tests-emptydir-wrapper-57vdw, will wait for the garbage collector to delete the pods
Aug  2 11:38:59.687: INFO: Deleting ReplicationController wrapped-volume-race-dc2e7d67-b519-11e9-b8f5-0a4acaace53e took: 6.984716ms
Aug  2 11:38:59.788: INFO: Terminating ReplicationController wrapped-volume-race-dc2e7d67-b519-11e9-b8f5-0a4acaace53e pods took: 100.322678ms
STEP: Creating RC which spawns configmap-volume pods
Aug  2 11:39:34.059: INFO: Pod name wrapped-volume-race-32f03c2e-b51a-11e9-b8f5-0a4acaace53e: Found 3 pods out of 5
Aug  2 11:39:39.065: INFO: Pod name wrapped-volume-race-32f03c2e-b51a-11e9-b8f5-0a4acaace53e: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-32f03c2e-b51a-11e9-b8f5-0a4acaace53e in namespace e2e-tests-emptydir-wrapper-57vdw, will wait for the garbage collector to delete the pods
Aug  2 11:41:59.157: INFO: Deleting ReplicationController wrapped-volume-race-32f03c2e-b51a-11e9-b8f5-0a4acaace53e took: 17.836433ms
Aug  2 11:41:59.258: INFO: Terminating ReplicationController wrapped-volume-race-32f03c2e-b51a-11e9-b8f5-0a4acaace53e pods took: 100.225983ms
STEP: Creating RC which spawns configmap-volume pods
Aug  2 11:42:34.210: INFO: Pod name wrapped-volume-race-9e53e845-b51a-11e9-b8f5-0a4acaace53e: Found 3 pods out of 5
Aug  2 11:42:39.216: INFO: Pod name wrapped-volume-race-9e53e845-b51a-11e9-b8f5-0a4acaace53e: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-9e53e845-b51a-11e9-b8f5-0a4acaace53e in namespace e2e-tests-emptydir-wrapper-57vdw, will wait for the garbage collector to delete the pods
Aug  2 11:45:43.311: INFO: Deleting ReplicationController wrapped-volume-race-9e53e845-b51a-11e9-b8f5-0a4acaace53e took: 9.717661ms
Aug  2 11:45:43.411: INFO: Terminating ReplicationController wrapped-volume-race-9e53e845-b51a-11e9-b8f5-0a4acaace53e pods took: 100.377903ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:46:22.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-57vdw" for this suite.
Aug  2 11:46:28.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:46:28.592: INFO: namespace: e2e-tests-emptydir-wrapper-57vdw, resource: bindings, ignored listing per whitelist
Aug  2 11:46:28.639: INFO: namespace e2e-tests-emptydir-wrapper-57vdw deletion completed in 6.176609424s

• [SLOW TEST:560.424 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:46:28.639: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Aug  2 11:46:31.253: INFO: Successfully updated pod "annotationupdate2a21e50e-b51b-11e9-b8f5-0a4acaace53e"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:46:33.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4v6ql" for this suite.
Aug  2 11:46:55.296: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:46:55.341: INFO: namespace: e2e-tests-downward-api-4v6ql, resource: bindings, ignored listing per whitelist
Aug  2 11:46:55.400: INFO: namespace e2e-tests-downward-api-4v6ql deletion completed in 22.116560533s

• [SLOW TEST:26.761 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:46:55.400: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-68rlk in namespace e2e-tests-proxy-jzm26
I0802 11:46:55.540962      18 runners.go:184] Created replication controller with name: proxy-service-68rlk, namespace: e2e-tests-proxy-jzm26, replica count: 1
I0802 11:46:56.593593      18 runners.go:184] proxy-service-68rlk Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0802 11:46:57.593775      18 runners.go:184] proxy-service-68rlk Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0802 11:46:58.594020      18 runners.go:184] proxy-service-68rlk Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0802 11:46:59.594229      18 runners.go:184] proxy-service-68rlk Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0802 11:47:00.594483      18 runners.go:184] proxy-service-68rlk Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0802 11:47:01.595069      18 runners.go:184] proxy-service-68rlk Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0802 11:47:02.598729      18 runners.go:184] proxy-service-68rlk Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0802 11:47:03.598985      18 runners.go:184] proxy-service-68rlk Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0802 11:47:04.599435      18 runners.go:184] proxy-service-68rlk Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0802 11:47:05.599758      18 runners.go:184] proxy-service-68rlk Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0802 11:47:06.600068      18 runners.go:184] proxy-service-68rlk Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0802 11:47:07.600366      18 runners.go:184] proxy-service-68rlk Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0802 11:47:08.600554      18 runners.go:184] proxy-service-68rlk Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0802 11:47:09.600790      18 runners.go:184] proxy-service-68rlk Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0802 11:47:10.601080      18 runners.go:184] proxy-service-68rlk Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0802 11:47:11.601309      18 runners.go:184] proxy-service-68rlk Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug  2 11:47:11.612: INFO: setup took 16.102220605s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Aug  2 11:47:11.635: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:162/proxy/: bar (200; 23.258086ms)
Aug  2 11:47:11.637: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d/proxy/rewriteme"... (200; 24.683979ms)
Aug  2 11:47:11.638: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/http:proxy-service-68rlk:portname2/proxy/: bar (200; 26.055003ms)
Aug  2 11:47:11.638: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/proxy-service-68rlk:portname2/proxy/: bar (200; 26.063127ms)
Aug  2 11:47:11.652: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:1080/proxy/rewri... (200; 40.200573ms)
Aug  2 11:47:11.653: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:462/proxy/: tls qux (200; 40.960778ms)
Aug  2 11:47:11.658: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:1080/proxy/... (200; 45.989472ms)
Aug  2 11:47:11.658: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:160/proxy/: foo (200; 46.160737ms)
Aug  2 11:47:11.658: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/https:proxy-service-68rlk:tlsportname2/proxy/: tls qux (200; 46.0846ms)
Aug  2 11:47:11.658: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:160/proxy/: foo (200; 46.058021ms)
Aug  2 11:47:11.659: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/proxy-service-68rlk:portname1/proxy/: foo (200; 46.821518ms)
Aug  2 11:47:11.660: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/http:proxy-service-68rlk:portname1/proxy/: foo (200; 47.948829ms)
Aug  2 11:47:11.660: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:162/proxy/: bar (200; 47.921725ms)
Aug  2 11:47:11.664: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:460/proxy/: tls baz (200; 51.518204ms)
Aug  2 11:47:11.664: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/https:proxy-service-68rlk:tlsportname1/proxy/: tls baz (200; 52.025189ms)
Aug  2 11:47:11.668: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:443/proxy/... (200; 56.304081ms)
Aug  2 11:47:11.674: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:160/proxy/: foo (200; 4.965705ms)
Aug  2 11:47:11.675: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:1080/proxy/rewri... (200; 6.527833ms)
Aug  2 11:47:11.675: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:462/proxy/: tls qux (200; 6.288841ms)
Aug  2 11:47:11.676: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d/proxy/rewriteme"... (200; 6.826706ms)
Aug  2 11:47:11.677: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:1080/proxy/... (200; 8.129326ms)
Aug  2 11:47:11.677: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:443/proxy/... (200; 8.410589ms)
Aug  2 11:47:11.677: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/proxy-service-68rlk:portname2/proxy/: bar (200; 8.337087ms)
Aug  2 11:47:11.677: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:162/proxy/: bar (200; 8.531901ms)
Aug  2 11:47:11.677: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:460/proxy/: tls baz (200; 8.466097ms)
Aug  2 11:47:11.678: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/https:proxy-service-68rlk:tlsportname1/proxy/: tls baz (200; 8.464922ms)
Aug  2 11:47:11.678: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:160/proxy/: foo (200; 8.875702ms)
Aug  2 11:47:11.678: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/https:proxy-service-68rlk:tlsportname2/proxy/: tls qux (200; 8.678407ms)
Aug  2 11:47:11.678: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/http:proxy-service-68rlk:portname2/proxy/: bar (200; 9.114832ms)
Aug  2 11:47:11.678: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:162/proxy/: bar (200; 9.474662ms)
Aug  2 11:47:11.679: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/http:proxy-service-68rlk:portname1/proxy/: foo (200; 9.972113ms)
Aug  2 11:47:11.679: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/proxy-service-68rlk:portname1/proxy/: foo (200; 9.99438ms)
Aug  2 11:47:11.683: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/http:proxy-service-68rlk:portname2/proxy/: bar (200; 3.77214ms)
Aug  2 11:47:11.683: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:443/proxy/... (200; 4.117906ms)
Aug  2 11:47:11.685: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:162/proxy/: bar (200; 5.347738ms)
Aug  2 11:47:11.688: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d/proxy/rewriteme"... (200; 8.261392ms)
Aug  2 11:47:11.690: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:1080/proxy/rewri... (200; 10.905638ms)
Aug  2 11:47:11.691: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:1080/proxy/... (200; 11.218789ms)
Aug  2 11:47:11.691: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:162/proxy/: bar (200; 11.36968ms)
Aug  2 11:47:11.691: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/https:proxy-service-68rlk:tlsportname2/proxy/: tls qux (200; 11.516659ms)
Aug  2 11:47:11.692: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:462/proxy/: tls qux (200; 12.020309ms)
Aug  2 11:47:11.692: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:160/proxy/: foo (200; 12.727088ms)
Aug  2 11:47:11.692: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:460/proxy/: tls baz (200; 12.848746ms)
Aug  2 11:47:11.693: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/http:proxy-service-68rlk:portname1/proxy/: foo (200; 13.528424ms)
Aug  2 11:47:11.692: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:160/proxy/: foo (200; 12.65132ms)
Aug  2 11:47:11.693: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/https:proxy-service-68rlk:tlsportname1/proxy/: tls baz (200; 13.449676ms)
Aug  2 11:47:11.693: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/proxy-service-68rlk:portname2/proxy/: bar (200; 13.874729ms)
Aug  2 11:47:11.693: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/proxy-service-68rlk:portname1/proxy/: foo (200; 14.093493ms)
Aug  2 11:47:11.704: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:460/proxy/: tls baz (200; 10.232842ms)
Aug  2 11:47:11.706: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:162/proxy/: bar (200; 11.842462ms)
Aug  2 11:47:11.706: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:462/proxy/: tls qux (200; 12.016524ms)
Aug  2 11:47:11.706: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:1080/proxy/rewri... (200; 12.038888ms)
Aug  2 11:47:11.706: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:160/proxy/: foo (200; 11.855335ms)
Aug  2 11:47:11.706: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:443/proxy/... (200; 12.396942ms)
Aug  2 11:47:11.711: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/http:proxy-service-68rlk:portname2/proxy/: bar (200; 17.572822ms)
Aug  2 11:47:11.711: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:1080/proxy/... (200; 17.768166ms)
Aug  2 11:47:11.712: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d/proxy/rewriteme"... (200; 18.058164ms)
Aug  2 11:47:11.712: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:162/proxy/: bar (200; 18.228501ms)
Aug  2 11:47:11.712: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:160/proxy/: foo (200; 18.220235ms)
Aug  2 11:47:11.713: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/proxy-service-68rlk:portname2/proxy/: bar (200; 18.972781ms)
Aug  2 11:47:11.720: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/https:proxy-service-68rlk:tlsportname2/proxy/: tls qux (200; 26.18565ms)
Aug  2 11:47:11.720: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/proxy-service-68rlk:portname1/proxy/: foo (200; 26.364264ms)
Aug  2 11:47:11.720: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/https:proxy-service-68rlk:tlsportname1/proxy/: tls baz (200; 26.049997ms)
Aug  2 11:47:11.720: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/http:proxy-service-68rlk:portname1/proxy/: foo (200; 26.58818ms)
Aug  2 11:47:11.728: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:162/proxy/: bar (200; 6.57421ms)
Aug  2 11:47:11.728: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:160/proxy/: foo (200; 6.824299ms)
Aug  2 11:47:11.728: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d/proxy/rewriteme"... (200; 6.177653ms)
Aug  2 11:47:11.728: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:443/proxy/... (200; 6.649909ms)
Aug  2 11:47:11.730: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:1080/proxy/... (200; 8.311543ms)
Aug  2 11:47:11.730: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:160/proxy/: foo (200; 7.837766ms)
Aug  2 11:47:11.731: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:162/proxy/: bar (200; 9.39949ms)
Aug  2 11:47:11.731: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/http:proxy-service-68rlk:portname1/proxy/: foo (200; 10.046318ms)
Aug  2 11:47:11.731: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/proxy-service-68rlk:portname1/proxy/: foo (200; 10.091034ms)
Aug  2 11:47:11.731: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/https:proxy-service-68rlk:tlsportname2/proxy/: tls qux (200; 9.551863ms)
Aug  2 11:47:11.731: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/proxy-service-68rlk:portname2/proxy/: bar (200; 9.247438ms)
Aug  2 11:47:11.731: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:462/proxy/: tls qux (200; 9.380729ms)
Aug  2 11:47:11.731: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:460/proxy/: tls baz (200; 9.124654ms)
Aug  2 11:47:11.731: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:1080/proxy/rewri... (200; 10.475881ms)
Aug  2 11:47:11.731: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/http:proxy-service-68rlk:portname2/proxy/: bar (200; 10.058793ms)
Aug  2 11:47:11.731: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/https:proxy-service-68rlk:tlsportname1/proxy/: tls baz (200; 11.067774ms)
Aug  2 11:47:11.737: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:462/proxy/: tls qux (200; 5.009193ms)
Aug  2 11:47:11.737: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:1080/proxy/rewri... (200; 5.701958ms)
Aug  2 11:47:11.738: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:162/proxy/: bar (200; 6.144449ms)
Aug  2 11:47:11.738: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:162/proxy/: bar (200; 6.628241ms)
Aug  2 11:47:11.738: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:460/proxy/: tls baz (200; 5.608997ms)
Aug  2 11:47:11.739: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:160/proxy/: foo (200; 6.660688ms)
Aug  2 11:47:11.739: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/http:proxy-service-68rlk:portname1/proxy/: foo (200; 7.191666ms)
Aug  2 11:47:11.739: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:1080/proxy/... (200; 6.730446ms)
Aug  2 11:47:11.739: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d/proxy/rewriteme"... (200; 6.607893ms)
Aug  2 11:47:11.739: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:443/proxy/... (200; 6.983913ms)
Aug  2 11:47:11.740: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/http:proxy-service-68rlk:portname2/proxy/: bar (200; 8.046314ms)
Aug  2 11:47:11.740: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:160/proxy/: foo (200; 7.186168ms)
Aug  2 11:47:11.740: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/proxy-service-68rlk:portname1/proxy/: foo (200; 7.208095ms)
Aug  2 11:47:11.740: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/https:proxy-service-68rlk:tlsportname2/proxy/: tls qux (200; 7.953217ms)
Aug  2 11:47:11.741: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/proxy-service-68rlk:portname2/proxy/: bar (200; 8.894193ms)
Aug  2 11:47:11.741: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/https:proxy-service-68rlk:tlsportname1/proxy/: tls baz (200; 8.80814ms)
Aug  2 11:47:11.745: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:162/proxy/: bar (200; 3.941485ms)
Aug  2 11:47:11.749: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/proxy-service-68rlk:portname2/proxy/: bar (200; 7.536029ms)
Aug  2 11:47:11.750: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d/proxy/rewriteme"... (200; 7.495219ms)
Aug  2 11:47:11.750: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:462/proxy/: tls qux (200; 7.698564ms)
Aug  2 11:47:11.750: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:160/proxy/: foo (200; 7.490872ms)
Aug  2 11:47:11.750: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:1080/proxy/... (200; 8.101522ms)
Aug  2 11:47:11.751: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/https:proxy-service-68rlk:tlsportname2/proxy/: tls qux (200; 9.167274ms)
Aug  2 11:47:11.751: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:443/proxy/... (200; 8.986737ms)
Aug  2 11:47:11.752: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:460/proxy/: tls baz (200; 9.128109ms)
Aug  2 11:47:11.752: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:162/proxy/: bar (200; 8.825761ms)
Aug  2 11:47:11.752: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:1080/proxy/rewri... (200; 9.066591ms)
Aug  2 11:47:11.752: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/https:proxy-service-68rlk:tlsportname1/proxy/: tls baz (200; 9.843229ms)
Aug  2 11:47:11.752: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:160/proxy/: foo (200; 9.237285ms)
Aug  2 11:47:11.753: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/http:proxy-service-68rlk:portname1/proxy/: foo (200; 9.868534ms)
Aug  2 11:47:11.753: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/http:proxy-service-68rlk:portname2/proxy/: bar (200; 9.775253ms)
Aug  2 11:47:11.753: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/proxy-service-68rlk:portname1/proxy/: foo (200; 10.356328ms)
Aug  2 11:47:11.758: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:160/proxy/: foo (200; 5.203081ms)
Aug  2 11:47:11.759: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:162/proxy/: bar (200; 5.28649ms)
Aug  2 11:47:11.759: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:462/proxy/: tls qux (200; 5.757691ms)
Aug  2 11:47:11.760: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:1080/proxy/rewri... (200; 6.326591ms)
Aug  2 11:47:11.760: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:443/proxy/... (200; 6.36761ms)
Aug  2 11:47:11.760: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:1080/proxy/... (200; 6.677032ms)
Aug  2 11:47:11.761: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:460/proxy/: tls baz (200; 7.343736ms)
Aug  2 11:47:11.761: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:162/proxy/: bar (200; 7.640905ms)
Aug  2 11:47:11.761: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/http:proxy-service-68rlk:portname1/proxy/: foo (200; 7.982661ms)
Aug  2 11:47:11.762: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d/proxy/rewriteme"... (200; 8.380841ms)
Aug  2 11:47:11.763: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:160/proxy/: foo (200; 9.973836ms)
Aug  2 11:47:11.764: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/proxy-service-68rlk:portname1/proxy/: foo (200; 10.472206ms)
Aug  2 11:47:11.764: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/https:proxy-service-68rlk:tlsportname2/proxy/: tls qux (200; 10.194798ms)
Aug  2 11:47:11.765: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/http:proxy-service-68rlk:portname2/proxy/: bar (200; 11.37295ms)
Aug  2 11:47:11.765: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/proxy-service-68rlk:portname2/proxy/: bar (200; 11.006763ms)
Aug  2 11:47:11.765: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/https:proxy-service-68rlk:tlsportname1/proxy/: tls baz (200; 11.892492ms)
Aug  2 11:47:11.769: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/proxy-service-68rlk:portname2/proxy/: bar (200; 4.322148ms)
Aug  2 11:47:11.770: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:1080/proxy/... (200; 4.60572ms)
Aug  2 11:47:11.772: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d/proxy/rewriteme"... (200; 6.36992ms)
Aug  2 11:47:11.772: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:162/proxy/: bar (200; 7.151174ms)
Aug  2 11:47:11.773: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:160/proxy/: foo (200; 7.402647ms)
Aug  2 11:47:11.773: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:460/proxy/: tls baz (200; 7.869857ms)
Aug  2 11:47:11.773: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:160/proxy/: foo (200; 8.058555ms)
Aug  2 11:47:11.774: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/https:proxy-service-68rlk:tlsportname2/proxy/: tls qux (200; 8.953073ms)
Aug  2 11:47:11.774: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/http:proxy-service-68rlk:portname1/proxy/: foo (200; 8.810254ms)
Aug  2 11:47:11.775: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/proxy-service-68rlk:portname1/proxy/: foo (200; 9.455553ms)
Aug  2 11:47:11.775: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/https:proxy-service-68rlk:tlsportname1/proxy/: tls baz (200; 9.672095ms)
Aug  2 11:47:11.776: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:162/proxy/: bar (200; 11.039152ms)
Aug  2 11:47:11.777: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:1080/proxy/rewri... (200; 11.591624ms)
Aug  2 11:47:11.777: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/http:proxy-service-68rlk:portname2/proxy/: bar (200; 11.111986ms)
Aug  2 11:47:11.777: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:443/proxy/... (200; 11.722475ms)
Aug  2 11:47:11.777: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:462/proxy/: tls qux (200; 12.460916ms)
Aug  2 11:47:11.784: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/http:proxy-service-68rlk:portname2/proxy/: bar (200; 6.173037ms)
Aug  2 11:47:11.784: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:1080/proxy/rewri... (200; 6.435209ms)
Aug  2 11:47:11.784: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:443/proxy/... (200; 6.868115ms)
Aug  2 11:47:11.785: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:162/proxy/: bar (200; 7.656777ms)
Aug  2 11:47:11.785: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:160/proxy/: foo (200; 7.335638ms)
Aug  2 11:47:11.786: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:162/proxy/: bar (200; 8.277565ms)
Aug  2 11:47:11.787: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d/proxy/rewriteme"... (200; 8.821097ms)
Aug  2 11:47:11.787: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:1080/proxy/... (200; 9.366131ms)
Aug  2 11:47:11.787: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:462/proxy/: tls qux (200; 9.610995ms)
Aug  2 11:47:11.788: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/proxy-service-68rlk:portname2/proxy/: bar (200; 10.114672ms)
Aug  2 11:47:11.788: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/proxy-service-68rlk:portname1/proxy/: foo (200; 10.06321ms)
Aug  2 11:47:11.788: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:160/proxy/: foo (200; 10.374395ms)
Aug  2 11:47:11.788: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/https:proxy-service-68rlk:tlsportname2/proxy/: tls qux (200; 10.359108ms)
Aug  2 11:47:11.788: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:460/proxy/: tls baz (200; 10.402531ms)
Aug  2 11:47:11.789: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/https:proxy-service-68rlk:tlsportname1/proxy/: tls baz (200; 10.767662ms)
Aug  2 11:47:11.789: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/http:proxy-service-68rlk:portname1/proxy/: foo (200; 10.732766ms)
Aug  2 11:47:11.799: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:162/proxy/: bar (200; 9.921825ms)
Aug  2 11:47:11.799: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:460/proxy/: tls baz (200; 10.339671ms)
Aug  2 11:47:11.800: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d/proxy/rewriteme"... (200; 11.007832ms)
Aug  2 11:47:11.800: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:443/proxy/... (200; 10.884084ms)
Aug  2 11:47:11.801: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/https:proxy-service-68rlk:tlsportname2/proxy/: tls qux (200; 11.962903ms)
Aug  2 11:47:11.801: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:162/proxy/: bar (200; 11.327663ms)
Aug  2 11:47:11.801: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:462/proxy/: tls qux (200; 11.119456ms)
Aug  2 11:47:11.801: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:1080/proxy/... (200; 11.56876ms)
Aug  2 11:47:11.801: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:160/proxy/: foo (200; 12.328039ms)
Aug  2 11:47:11.801: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:160/proxy/: foo (200; 11.92714ms)
Aug  2 11:47:11.802: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:1080/proxy/rewri... (200; 12.969908ms)
Aug  2 11:47:11.803: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/proxy-service-68rlk:portname2/proxy/: bar (200; 13.094015ms)
Aug  2 11:47:11.803: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/http:proxy-service-68rlk:portname2/proxy/: bar (200; 13.497798ms)
Aug  2 11:47:11.803: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/proxy-service-68rlk:portname1/proxy/: foo (200; 14.1038ms)
Aug  2 11:47:11.803: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/https:proxy-service-68rlk:tlsportname1/proxy/: tls baz (200; 14.425409ms)
Aug  2 11:47:11.804: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/http:proxy-service-68rlk:portname1/proxy/: foo (200; 14.378498ms)
Aug  2 11:47:11.812: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:462/proxy/: tls qux (200; 8.282791ms)
Aug  2 11:47:11.814: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:443/proxy/... (200; 9.987718ms)
Aug  2 11:47:11.814: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:160/proxy/: foo (200; 10.508775ms)
Aug  2 11:47:11.814: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:162/proxy/: bar (200; 10.4078ms)
Aug  2 11:47:11.814: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:162/proxy/: bar (200; 10.463804ms)
Aug  2 11:47:11.815: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:1080/proxy/... (200; 11.3126ms)
Aug  2 11:47:11.816: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/proxy-service-68rlk:portname1/proxy/: foo (200; 11.889962ms)
Aug  2 11:47:11.816: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d/proxy/rewriteme"... (200; 12.122798ms)
Aug  2 11:47:11.816: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:160/proxy/: foo (200; 12.152038ms)
Aug  2 11:47:11.816: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:1080/proxy/rewri... (200; 12.566888ms)
Aug  2 11:47:11.816: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:460/proxy/: tls baz (200; 12.578289ms)
Aug  2 11:47:11.818: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/http:proxy-service-68rlk:portname1/proxy/: foo (200; 13.423152ms)
Aug  2 11:47:11.818: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/http:proxy-service-68rlk:portname2/proxy/: bar (200; 13.653079ms)
Aug  2 11:47:11.818: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/https:proxy-service-68rlk:tlsportname1/proxy/: tls baz (200; 14.902753ms)
Aug  2 11:47:11.819: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/proxy-service-68rlk:portname2/proxy/: bar (200; 14.611648ms)
Aug  2 11:47:11.819: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/https:proxy-service-68rlk:tlsportname2/proxy/: tls qux (200; 14.482987ms)
Aug  2 11:47:11.825: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:460/proxy/: tls baz (200; 5.431123ms)
Aug  2 11:47:11.826: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:1080/proxy/... (200; 6.292636ms)
Aug  2 11:47:11.826: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:162/proxy/: bar (200; 6.60577ms)
Aug  2 11:47:11.828: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d/proxy/rewriteme"... (200; 7.570879ms)
Aug  2 11:47:11.828: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:443/proxy/... (200; 8.252412ms)
Aug  2 11:47:11.828: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:462/proxy/: tls qux (200; 8.208026ms)
Aug  2 11:47:11.828: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:160/proxy/: foo (200; 8.757262ms)
Aug  2 11:47:11.828: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:1080/proxy/rewri... (200; 8.543431ms)
Aug  2 11:47:11.828: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/http:proxy-service-68rlk:portname1/proxy/: foo (200; 9.0633ms)
Aug  2 11:47:11.828: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:162/proxy/: bar (200; 8.609337ms)
Aug  2 11:47:11.828: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/http:proxy-service-68rlk:portname2/proxy/: bar (200; 8.985557ms)
Aug  2 11:47:11.828: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/proxy-service-68rlk:portname1/proxy/: foo (200; 8.40562ms)
Aug  2 11:47:11.829: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/https:proxy-service-68rlk:tlsportname2/proxy/: tls qux (200; 8.93899ms)
Aug  2 11:47:11.829: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/https:proxy-service-68rlk:tlsportname1/proxy/: tls baz (200; 8.728649ms)
Aug  2 11:47:11.829: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/proxy-service-68rlk:portname2/proxy/: bar (200; 9.402829ms)
Aug  2 11:47:11.829: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:160/proxy/: foo (200; 9.197866ms)
Aug  2 11:47:11.832: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:1080/proxy/... (200; 2.710572ms)
Aug  2 11:47:11.835: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d/proxy/rewriteme"... (200; 6.019422ms)
Aug  2 11:47:11.836: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:443/proxy/... (200; 6.521086ms)
Aug  2 11:47:11.836: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/proxy-service-68rlk:portname1/proxy/: foo (200; 6.286662ms)
Aug  2 11:47:11.837: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:162/proxy/: bar (200; 7.323876ms)
Aug  2 11:47:11.837: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/http:proxy-service-68rlk:portname2/proxy/: bar (200; 7.819752ms)
Aug  2 11:47:11.837: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/https:proxy-service-68rlk:tlsportname2/proxy/: tls qux (200; 7.828926ms)
Aug  2 11:47:11.838: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:160/proxy/: foo (200; 8.140881ms)
Aug  2 11:47:11.838: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/https:proxy-service-68rlk:tlsportname1/proxy/: tls baz (200; 8.253913ms)
Aug  2 11:47:11.838: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/http:proxy-service-68rlk:portname1/proxy/: foo (200; 8.54671ms)
Aug  2 11:47:11.838: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:462/proxy/: tls qux (200; 8.326333ms)
Aug  2 11:47:11.838: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:1080/proxy/rewri... (200; 8.64875ms)
Aug  2 11:47:11.838: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:162/proxy/: bar (200; 8.615668ms)
Aug  2 11:47:11.838: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:460/proxy/: tls baz (200; 8.506124ms)
Aug  2 11:47:11.838: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/proxy-service-68rlk:portname2/proxy/: bar (200; 8.638058ms)
Aug  2 11:47:11.838: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:160/proxy/: foo (200; 8.634894ms)
Aug  2 11:47:11.842: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/http:proxy-service-68rlk:portname1/proxy/: foo (200; 3.554704ms)
Aug  2 11:47:11.843: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:160/proxy/: foo (200; 4.889233ms)
Aug  2 11:47:11.844: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:162/proxy/: bar (200; 5.174389ms)
Aug  2 11:47:11.844: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/http:proxy-service-68rlk:portname2/proxy/: bar (200; 5.664097ms)
Aug  2 11:47:11.844: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:1080/proxy/rewri... (200; 5.669507ms)
Aug  2 11:47:11.845: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d/proxy/rewriteme"... (200; 6.499124ms)
Aug  2 11:47:11.846: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:162/proxy/: bar (200; 7.740563ms)
Aug  2 11:47:11.847: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/https:proxy-service-68rlk:tlsportname1/proxy/: tls baz (200; 7.943863ms)
Aug  2 11:47:11.847: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:160/proxy/: foo (200; 8.079847ms)
Aug  2 11:47:11.847: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:462/proxy/: tls qux (200; 8.59499ms)
Aug  2 11:47:11.848: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:1080/proxy/... (200; 9.24377ms)
Aug  2 11:47:11.848: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:443/proxy/... (200; 9.208594ms)
Aug  2 11:47:11.848: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:460/proxy/: tls baz (200; 9.654966ms)
Aug  2 11:47:11.848: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/proxy-service-68rlk:portname2/proxy/: bar (200; 9.728505ms)
Aug  2 11:47:11.849: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/proxy-service-68rlk:portname1/proxy/: foo (200; 9.739553ms)
Aug  2 11:47:11.849: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/https:proxy-service-68rlk:tlsportname2/proxy/: tls qux (200; 9.923957ms)
Aug  2 11:47:11.852: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:160/proxy/: foo (200; 3.224679ms)
Aug  2 11:47:11.855: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:162/proxy/: bar (200; 6.212601ms)
Aug  2 11:47:11.856: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:162/proxy/: bar (200; 6.238581ms)
Aug  2 11:47:11.856: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/https:proxy-service-68rlk:tlsportname2/proxy/: tls qux (200; 6.382983ms)
Aug  2 11:47:11.856: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:1080/proxy/rewri... (200; 6.731846ms)
Aug  2 11:47:11.856: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:160/proxy/: foo (200; 6.857673ms)
Aug  2 11:47:11.857: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/proxy-service-68rlk:portname1/proxy/: foo (200; 7.667064ms)
Aug  2 11:47:11.857: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:462/proxy/: tls qux (200; 6.856761ms)
Aug  2 11:47:11.857: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:443/proxy/... (200; 6.910992ms)
Aug  2 11:47:11.857: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:460/proxy/: tls baz (200; 7.091324ms)
Aug  2 11:47:11.857: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:1080/proxy/... (200; 7.1789ms)
Aug  2 11:47:11.857: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/http:proxy-service-68rlk:portname2/proxy/: bar (200; 7.821835ms)
Aug  2 11:47:11.857: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/http:proxy-service-68rlk:portname1/proxy/: foo (200; 8.216335ms)
Aug  2 11:47:11.857: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d/proxy/rewriteme"... (200; 7.316305ms)
Aug  2 11:47:11.858: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/proxy-service-68rlk:portname2/proxy/: bar (200; 8.379107ms)
Aug  2 11:47:11.858: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/https:proxy-service-68rlk:tlsportname1/proxy/: tls baz (200; 8.403857ms)
Aug  2 11:47:11.862: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:162/proxy/: bar (200; 3.331616ms)
Aug  2 11:47:11.863: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:1080/proxy/... (200; 4.317894ms)
Aug  2 11:47:11.864: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:460/proxy/: tls baz (200; 5.449818ms)
Aug  2 11:47:11.865: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:1080/proxy/rewri... (200; 6.068947ms)
Aug  2 11:47:11.865: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:462/proxy/: tls qux (200; 6.069606ms)
Aug  2 11:47:11.865: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:160/proxy/: foo (200; 6.315362ms)
Aug  2 11:47:11.866: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:443/proxy/... (200; 7.403232ms)
Aug  2 11:47:11.866: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/http:proxy-service-68rlk:portname2/proxy/: bar (200; 7.527778ms)
Aug  2 11:47:11.867: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/https:proxy-service-68rlk:tlsportname1/proxy/: tls baz (200; 8.469509ms)
Aug  2 11:47:11.867: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/http:proxy-service-68rlk:portname1/proxy/: foo (200; 8.394984ms)
Aug  2 11:47:11.867: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:160/proxy/: foo (200; 8.785431ms)
Aug  2 11:47:11.868: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/proxy-service-68rlk:portname1/proxy/: foo (200; 8.760887ms)
Aug  2 11:47:11.868: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/https:proxy-service-68rlk:tlsportname2/proxy/: tls qux (200; 8.801843ms)
Aug  2 11:47:11.868: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d/proxy/rewriteme"... (200; 9.059977ms)
Aug  2 11:47:11.868: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/proxy-service-68rlk:portname2/proxy/: bar (200; 8.863388ms)
Aug  2 11:47:11.868: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:162/proxy/: bar (200; 8.84893ms)
Aug  2 11:47:11.876: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:162/proxy/: bar (200; 7.885168ms)
Aug  2 11:47:11.877: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:462/proxy/: tls qux (200; 8.999716ms)
Aug  2 11:47:11.877: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/http:proxy-service-68rlk:portname1/proxy/: foo (200; 9.487496ms)
Aug  2 11:47:11.877: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:160/proxy/: foo (200; 9.397838ms)
Aug  2 11:47:11.877: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:443/proxy/... (200; 9.618235ms)
Aug  2 11:47:11.878: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:460/proxy/: tls baz (200; 9.918541ms)
Aug  2 11:47:11.878: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d/proxy/rewriteme"... (200; 10.223334ms)
Aug  2 11:47:11.878: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:1080/proxy/... (200; 10.275003ms)
Aug  2 11:47:11.878: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:1080/proxy/rewri... (200; 10.39861ms)
Aug  2 11:47:11.878: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/proxy-service-68rlk:portname1/proxy/: foo (200; 10.395688ms)
Aug  2 11:47:11.879: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:160/proxy/: foo (200; 10.970356ms)
Aug  2 11:47:11.879: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/https:proxy-service-68rlk:tlsportname1/proxy/: tls baz (200; 10.980732ms)
Aug  2 11:47:11.879: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/http:proxy-service-68rlk:portname2/proxy/: bar (200; 11.075548ms)
Aug  2 11:47:11.879: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:162/proxy/: bar (200; 11.044584ms)
Aug  2 11:47:11.879: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/https:proxy-service-68rlk:tlsportname2/proxy/: tls qux (200; 11.248395ms)
Aug  2 11:47:11.879: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/proxy-service-68rlk:portname2/proxy/: bar (200; 11.34862ms)
Aug  2 11:47:11.887: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:1080/proxy/... (200; 7.54911ms)
Aug  2 11:47:11.888: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:443/proxy/... (200; 8.178409ms)
Aug  2 11:47:11.888: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:460/proxy/: tls baz (200; 8.191877ms)
Aug  2 11:47:11.888: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d/proxy/rewriteme"... (200; 8.118575ms)
Aug  2 11:47:11.888: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:1080/proxy/rewri... (200; 8.064105ms)
Aug  2 11:47:11.888: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:162/proxy/: bar (200; 8.293331ms)
Aug  2 11:47:11.888: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:160/proxy/: foo (200; 8.589981ms)
Aug  2 11:47:11.888: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:462/proxy/: tls qux (200; 8.722227ms)
Aug  2 11:47:11.889: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:160/proxy/: foo (200; 8.894797ms)
Aug  2 11:47:11.889: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/https:proxy-service-68rlk:tlsportname2/proxy/: tls qux (200; 9.709963ms)
Aug  2 11:47:11.890: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/proxy-service-68rlk:portname2/proxy/: bar (200; 9.978129ms)
Aug  2 11:47:11.890: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:162/proxy/: bar (200; 10.010015ms)
Aug  2 11:47:11.890: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/proxy-service-68rlk:portname1/proxy/: foo (200; 10.104529ms)
Aug  2 11:47:11.890: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/http:proxy-service-68rlk:portname2/proxy/: bar (200; 10.327959ms)
Aug  2 11:47:11.890: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/https:proxy-service-68rlk:tlsportname1/proxy/: tls baz (200; 10.442089ms)
Aug  2 11:47:11.890: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/http:proxy-service-68rlk:portname1/proxy/: foo (200; 10.595786ms)
Aug  2 11:47:11.896: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:1080/proxy/rewri... (200; 5.816338ms)
Aug  2 11:47:11.899: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:462/proxy/: tls qux (200; 8.359513ms)
Aug  2 11:47:11.900: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:1080/proxy/... (200; 9.365969ms)
Aug  2 11:47:11.900: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:162/proxy/: bar (200; 9.594476ms)
Aug  2 11:47:11.900: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/proxy-service-68rlk:portname1/proxy/: foo (200; 9.385832ms)
Aug  2 11:47:11.900: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d/proxy/rewriteme"... (200; 9.353142ms)
Aug  2 11:47:11.900: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:162/proxy/: bar (200; 9.656994ms)
Aug  2 11:47:11.900: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/https:proxy-service-68rlk:tlsportname1/proxy/: tls baz (200; 9.417405ms)
Aug  2 11:47:11.900: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:443/proxy/... (200; 9.74925ms)
Aug  2 11:47:11.900: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/proxy-service-68rlk:portname2/proxy/: bar (200; 9.685279ms)
Aug  2 11:47:11.900: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/http:proxy-service-68rlk-gzm7d:160/proxy/: foo (200; 9.760515ms)
Aug  2 11:47:11.900: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/proxy-service-68rlk-gzm7d:160/proxy/: foo (200; 9.619909ms)
Aug  2 11:47:11.900: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/http:proxy-service-68rlk:portname2/proxy/: bar (200; 9.844284ms)
Aug  2 11:47:11.901: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jzm26/pods/https:proxy-service-68rlk-gzm7d:460/proxy/: tls baz (200; 10.518842ms)
Aug  2 11:47:11.901: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/http:proxy-service-68rlk:portname1/proxy/: foo (200; 10.932948ms)
Aug  2 11:47:11.901: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jzm26/services/https:proxy-service-68rlk:tlsportname2/proxy/: tls qux (200; 10.710642ms)
STEP: deleting ReplicationController proxy-service-68rlk in namespace e2e-tests-proxy-jzm26, will wait for the garbage collector to delete the pods
Aug  2 11:47:11.962: INFO: Deleting ReplicationController proxy-service-68rlk took: 6.937008ms
Aug  2 11:47:12.062: INFO: Terminating ReplicationController proxy-service-68rlk pods took: 100.187678ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:47:14.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-jzm26" for this suite.
Aug  2 11:47:20.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:47:20.632: INFO: namespace: e2e-tests-proxy-jzm26, resource: bindings, ignored listing per whitelist
Aug  2 11:47:20.717: INFO: namespace e2e-tests-proxy-jzm26 deletion completed in 6.150302508s

• [SLOW TEST:25.317 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:47:20.718: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-49391b78-b51b-11e9-b8f5-0a4acaace53e
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:47:22.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-x96wm" for this suite.
Aug  2 11:47:44.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:47:44.993: INFO: namespace: e2e-tests-configmap-x96wm, resource: bindings, ignored listing per whitelist
Aug  2 11:47:45.053: INFO: namespace e2e-tests-configmap-x96wm deletion completed in 22.118730202s

• [SLOW TEST:24.336 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:47:45.054: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Aug  2 11:47:45.127: INFO: Waiting up to 5m0s for pod "pod-57ad1c07-b51b-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-emptydir-mh5hq" to be "success or failure"
Aug  2 11:47:45.135: INFO: Pod "pod-57ad1c07-b51b-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 7.46585ms
Aug  2 11:47:47.139: INFO: Pod "pod-57ad1c07-b51b-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011254291s
STEP: Saw pod success
Aug  2 11:47:47.139: INFO: Pod "pod-57ad1c07-b51b-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 11:47:47.141: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-57ad1c07-b51b-11e9-b8f5-0a4acaace53e container test-container: <nil>
STEP: delete the pod
Aug  2 11:47:47.168: INFO: Waiting for pod pod-57ad1c07-b51b-11e9-b8f5-0a4acaace53e to disappear
Aug  2 11:47:47.176: INFO: Pod pod-57ad1c07-b51b-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:47:47.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-mh5hq" for this suite.
Aug  2 11:47:53.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:47:53.274: INFO: namespace: e2e-tests-emptydir-mh5hq, resource: bindings, ignored listing per whitelist
Aug  2 11:47:53.325: INFO: namespace e2e-tests-emptydir-mh5hq deletion completed in 6.142248061s

• [SLOW TEST:8.271 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:47:53.327: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0802 11:47:54.505613      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug  2 11:47:54.505: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:47:54.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-2z6q9" for this suite.
Aug  2 11:48:00.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:48:00.598: INFO: namespace: e2e-tests-gc-2z6q9, resource: bindings, ignored listing per whitelist
Aug  2 11:48:00.636: INFO: namespace e2e-tests-gc-2z6q9 deletion completed in 6.128542955s

• [SLOW TEST:7.310 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:48:00.637: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Aug  2 11:48:00.716: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-983173982 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:48:00.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-v5sc5" for this suite.
Aug  2 11:48:06.828: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:48:06.865: INFO: namespace: e2e-tests-kubectl-v5sc5, resource: bindings, ignored listing per whitelist
Aug  2 11:48:06.951: INFO: namespace e2e-tests-kubectl-v5sc5 deletion completed in 6.133815645s

• [SLOW TEST:6.314 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:48:06.952: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-64bc49af-b51b-11e9-b8f5-0a4acaace53e
STEP: Creating a pod to test consume secrets
Aug  2 11:48:07.044: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-64bd32a9-b51b-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-projected-k55zs" to be "success or failure"
Aug  2 11:48:07.047: INFO: Pod "pod-projected-secrets-64bd32a9-b51b-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.968945ms
Aug  2 11:48:09.051: INFO: Pod "pod-projected-secrets-64bd32a9-b51b-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006605574s
STEP: Saw pod success
Aug  2 11:48:09.051: INFO: Pod "pod-projected-secrets-64bd32a9-b51b-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 11:48:09.053: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod pod-projected-secrets-64bd32a9-b51b-11e9-b8f5-0a4acaace53e container secret-volume-test: <nil>
STEP: delete the pod
Aug  2 11:48:09.077: INFO: Waiting for pod pod-projected-secrets-64bd32a9-b51b-11e9-b8f5-0a4acaace53e to disappear
Aug  2 11:48:09.094: INFO: Pod pod-projected-secrets-64bd32a9-b51b-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:48:09.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-k55zs" for this suite.
Aug  2 11:48:15.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:48:15.335: INFO: namespace: e2e-tests-projected-k55zs, resource: bindings, ignored listing per whitelist
Aug  2 11:48:15.344: INFO: namespace e2e-tests-projected-k55zs deletion completed in 6.247667927s

• [SLOW TEST:8.393 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug  2 11:48:15.345: INFO: >>> kubeConfig: /tmp/kubeconfig-983173982
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug  2 11:48:15.427: INFO: Waiting up to 5m0s for pod "downwardapi-volume-69bc53db-b51b-11e9-b8f5-0a4acaace53e" in namespace "e2e-tests-projected-crszc" to be "success or failure"
Aug  2 11:48:15.434: INFO: Pod "downwardapi-volume-69bc53db-b51b-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.97955ms
Aug  2 11:48:17.438: INFO: Pod "downwardapi-volume-69bc53db-b51b-11e9-b8f5-0a4acaace53e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010992237s
Aug  2 11:48:19.442: INFO: Pod "downwardapi-volume-69bc53db-b51b-11e9-b8f5-0a4acaace53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015238018s
STEP: Saw pod success
Aug  2 11:48:19.442: INFO: Pod "downwardapi-volume-69bc53db-b51b-11e9-b8f5-0a4acaace53e" satisfied condition "success or failure"
Aug  2 11:48:19.445: INFO: Trying to get logs from node test-v1-13-7-gipwxthqfdpj-minion-0 pod downwardapi-volume-69bc53db-b51b-11e9-b8f5-0a4acaace53e container client-container: <nil>
STEP: delete the pod
Aug  2 11:48:19.466: INFO: Waiting for pod downwardapi-volume-69bc53db-b51b-11e9-b8f5-0a4acaace53e to disappear
Aug  2 11:48:19.470: INFO: Pod downwardapi-volume-69bc53db-b51b-11e9-b8f5-0a4acaace53e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug  2 11:48:19.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-crszc" for this suite.
Aug  2 11:48:25.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  2 11:48:25.569: INFO: namespace: e2e-tests-projected-crszc, resource: bindings, ignored listing per whitelist
Aug  2 11:48:25.612: INFO: namespace e2e-tests-projected-crszc deletion completed in 6.137946041s

• [SLOW TEST:10.266 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
Aug  2 11:48:25.612: INFO: Running AfterSuite actions on all nodes
Aug  2 11:48:25.612: INFO: Running AfterSuite actions on node 1
Aug  2 11:48:25.612: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 6174.499 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h42m55.320334893s
Test Suite Passed
