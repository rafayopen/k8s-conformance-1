I0525 00:56:36.205445      15 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-162046071
I0525 00:56:36.205617      15 e2e.go:224] Starting e2e run "f1aea67a-7e87-11e9-802f-027f94874578" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1558745795 - Will randomize all specs
Will run 201 of 1946 specs

May 25 00:56:36.397: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
May 25 00:56:36.400: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
May 25 00:56:36.411: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
May 25 00:56:36.439: INFO: 16 / 16 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
May 25 00:56:36.439: INFO: expected 6 pod replicas in namespace 'kube-system', 6 are Running and Ready.
May 25 00:56:36.439: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
May 25 00:56:36.455: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
May 25 00:56:36.455: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
May 25 00:56:36.455: INFO: e2e test version: v1.13.0
May 25 00:56:36.457: INFO: kube-apiserver version: v1.13.5
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 00:56:36.457: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename container-lifecycle-hook
May 25 00:56:36.533: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
May 25 00:56:36.567: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-p6psb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
May 25 00:56:44.755: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 25 00:56:44.757: INFO: Pod pod-with-poststart-http-hook still exists
May 25 00:56:46.758: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 25 00:56:46.760: INFO: Pod pod-with-poststart-http-hook still exists
May 25 00:56:48.758: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 25 00:56:48.761: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 00:56:48.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-p6psb" for this suite.
May 25 00:57:10.774: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 00:57:10.819: INFO: namespace: e2e-tests-container-lifecycle-hook-p6psb, resource: bindings, ignored listing per whitelist
May 25 00:57:10.851: INFO: namespace e2e-tests-container-lifecycle-hook-p6psb deletion completed in 22.087255235s

• [SLOW TEST:34.394 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 00:57:10.851: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-stdqz
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
May 25 00:57:11.025: INFO: Waiting up to 5m0s for pod "pod-07083bf6-7e88-11e9-802f-027f94874578" in namespace "e2e-tests-emptydir-stdqz" to be "success or failure"
May 25 00:57:11.031: INFO: Pod "pod-07083bf6-7e88-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 6.121552ms
May 25 00:57:13.033: INFO: Pod "pod-07083bf6-7e88-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008744501s
May 25 00:57:15.037: INFO: Pod "pod-07083bf6-7e88-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011944869s
May 25 00:57:17.040: INFO: Pod "pod-07083bf6-7e88-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 6.014918946s
May 25 00:57:19.042: INFO: Pod "pod-07083bf6-7e88-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 8.016939994s
May 25 00:57:21.044: INFO: Pod "pod-07083bf6-7e88-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.019641098s
STEP: Saw pod success
May 25 00:57:21.044: INFO: Pod "pod-07083bf6-7e88-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 00:57:21.049: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-07083bf6-7e88-11e9-802f-027f94874578 container test-container: <nil>
STEP: delete the pod
May 25 00:57:21.072: INFO: Waiting for pod pod-07083bf6-7e88-11e9-802f-027f94874578 to disappear
May 25 00:57:21.078: INFO: Pod pod-07083bf6-7e88-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 00:57:21.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-stdqz" for this suite.
May 25 00:57:27.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 00:57:27.118: INFO: namespace: e2e-tests-emptydir-stdqz, resource: bindings, ignored listing per whitelist
May 25 00:57:27.169: INFO: namespace e2e-tests-emptydir-stdqz deletion completed in 6.086773285s

• [SLOW TEST:16.318 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 00:57:27.170: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-fgq7j
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 25 00:57:27.343: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
May 25 00:57:27.350: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-fgq7j/daemonsets","resourceVersion":"11510"},"items":null}

May 25 00:57:27.353: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-fgq7j/pods","resourceVersion":"11510"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 00:57:27.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-fgq7j" for this suite.
May 25 00:57:33.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 00:57:33.425: INFO: namespace: e2e-tests-daemonsets-fgq7j, resource: bindings, ignored listing per whitelist
May 25 00:57:33.455: INFO: namespace e2e-tests-daemonsets-fgq7j deletion completed in 6.089646509s

S [SKIPPING] [6.285 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  May 25 00:57:27.343: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 00:57:33.457: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-gmbtt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-gmbtt
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-gmbtt
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-gmbtt
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-gmbtt
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-gmbtt
May 25 00:57:39.664: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-gmbtt, name: ss-0, uid: 181a5f0c-7e88-11e9-ba33-0050569e7ba0, status phase: Pending. Waiting for statefulset controller to delete.
May 25 00:57:41.043: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-gmbtt, name: ss-0, uid: 181a5f0c-7e88-11e9-ba33-0050569e7ba0, status phase: Failed. Waiting for statefulset controller to delete.
May 25 00:57:41.047: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-gmbtt, name: ss-0, uid: 181a5f0c-7e88-11e9-ba33-0050569e7ba0, status phase: Failed. Waiting for statefulset controller to delete.
May 25 00:57:41.052: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-gmbtt
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-gmbtt
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-gmbtt and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 25 00:57:45.079: INFO: Deleting all statefulset in ns e2e-tests-statefulset-gmbtt
May 25 00:57:45.081: INFO: Scaling statefulset ss to 0
May 25 00:58:05.106: INFO: Waiting for statefulset status.replicas updated to 0
May 25 00:58:05.109: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 00:58:05.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-gmbtt" for this suite.
May 25 00:58:11.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 00:58:11.178: INFO: namespace: e2e-tests-statefulset-gmbtt, resource: bindings, ignored listing per whitelist
May 25 00:58:11.219: INFO: namespace e2e-tests-statefulset-gmbtt deletion completed in 6.087565597s

• [SLOW TEST:37.763 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 00:58:11.220: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-cr9xq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
May 25 00:58:11.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 create -f - --namespace=e2e-tests-kubectl-cr9xq'
May 25 00:58:11.980: INFO: stderr: ""
May 25 00:58:11.980: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
May 25 00:58:12.983: INFO: Selector matched 1 pods for map[app:redis]
May 25 00:58:12.983: INFO: Found 0 / 1
May 25 00:58:13.983: INFO: Selector matched 1 pods for map[app:redis]
May 25 00:58:13.983: INFO: Found 0 / 1
May 25 00:58:14.983: INFO: Selector matched 1 pods for map[app:redis]
May 25 00:58:14.983: INFO: Found 1 / 1
May 25 00:58:14.983: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 25 00:58:14.986: INFO: Selector matched 1 pods for map[app:redis]
May 25 00:58:14.986: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
May 25 00:58:14.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 logs redis-master-xrnfh redis-master --namespace=e2e-tests-kubectl-cr9xq'
May 25 00:58:15.083: INFO: stderr: ""
May 25 00:58:15.083: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 25 May 00:58:15.074 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 25 May 00:58:15.074 # Server started, Redis version 3.2.12\n1:M 25 May 00:58:15.074 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 25 May 00:58:15.074 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
May 25 00:58:15.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 log redis-master-xrnfh redis-master --namespace=e2e-tests-kubectl-cr9xq --tail=1'
May 25 00:58:15.193: INFO: stderr: ""
May 25 00:58:15.193: INFO: stdout: "1:M 25 May 00:58:15.074 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
May 25 00:58:15.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 log redis-master-xrnfh redis-master --namespace=e2e-tests-kubectl-cr9xq --limit-bytes=1'
May 25 00:58:15.285: INFO: stderr: ""
May 25 00:58:15.285: INFO: stdout: " "
STEP: exposing timestamps
May 25 00:58:15.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 log redis-master-xrnfh redis-master --namespace=e2e-tests-kubectl-cr9xq --tail=1 --timestamps'
May 25 00:58:15.389: INFO: stderr: ""
May 25 00:58:15.389: INFO: stdout: "2019-05-25T00:58:15.074647856Z 1:M 25 May 00:58:15.074 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
May 25 00:58:17.890: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 log redis-master-xrnfh redis-master --namespace=e2e-tests-kubectl-cr9xq --since=1s'
May 25 00:58:17.987: INFO: stderr: ""
May 25 00:58:17.987: INFO: stdout: ""
May 25 00:58:17.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 log redis-master-xrnfh redis-master --namespace=e2e-tests-kubectl-cr9xq --since=24h'
May 25 00:58:18.093: INFO: stderr: ""
May 25 00:58:18.093: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 25 May 00:58:15.074 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 25 May 00:58:15.074 # Server started, Redis version 3.2.12\n1:M 25 May 00:58:15.074 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 25 May 00:58:15.074 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
May 25 00:58:18.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-cr9xq'
May 25 00:58:18.179: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 25 00:58:18.179: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
May 25 00:58:18.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-cr9xq'
May 25 00:58:18.285: INFO: stderr: "No resources found.\n"
May 25 00:58:18.285: INFO: stdout: ""
May 25 00:58:18.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods -l name=nginx --namespace=e2e-tests-kubectl-cr9xq -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 25 00:58:18.380: INFO: stderr: ""
May 25 00:58:18.380: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 00:58:18.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-cr9xq" for this suite.
May 25 00:58:40.395: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 00:58:40.462: INFO: namespace: e2e-tests-kubectl-cr9xq, resource: bindings, ignored listing per whitelist
May 25 00:58:40.484: INFO: namespace e2e-tests-kubectl-cr9xq deletion completed in 22.098486861s

• [SLOW TEST:29.264 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 00:58:40.485: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-4czxx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 25 00:58:40.647: INFO: (0) /api/v1/nodes/alex-400-cp1718-vsp2-worker00f2b167f8:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 4.040103ms)
May 25 00:58:40.649: INFO: (1) /api/v1/nodes/alex-400-cp1718-vsp2-worker00f2b167f8:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 2.45024ms)
May 25 00:58:40.652: INFO: (2) /api/v1/nodes/alex-400-cp1718-vsp2-worker00f2b167f8:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 2.776465ms)
May 25 00:58:40.655: INFO: (3) /api/v1/nodes/alex-400-cp1718-vsp2-worker00f2b167f8:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 2.433283ms)
May 25 00:58:40.657: INFO: (4) /api/v1/nodes/alex-400-cp1718-vsp2-worker00f2b167f8:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 2.421523ms)
May 25 00:58:40.660: INFO: (5) /api/v1/nodes/alex-400-cp1718-vsp2-worker00f2b167f8:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 2.468511ms)
May 25 00:58:40.662: INFO: (6) /api/v1/nodes/alex-400-cp1718-vsp2-worker00f2b167f8:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 2.73876ms)
May 25 00:58:40.665: INFO: (7) /api/v1/nodes/alex-400-cp1718-vsp2-worker00f2b167f8:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 2.656091ms)
May 25 00:58:40.668: INFO: (8) /api/v1/nodes/alex-400-cp1718-vsp2-worker00f2b167f8:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 2.519508ms)
May 25 00:58:40.674: INFO: (9) /api/v1/nodes/alex-400-cp1718-vsp2-worker00f2b167f8:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 6.905937ms)
May 25 00:58:40.677: INFO: (10) /api/v1/nodes/alex-400-cp1718-vsp2-worker00f2b167f8:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 2.728885ms)
May 25 00:58:40.680: INFO: (11) /api/v1/nodes/alex-400-cp1718-vsp2-worker00f2b167f8:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 2.95812ms)
May 25 00:58:40.683: INFO: (12) /api/v1/nodes/alex-400-cp1718-vsp2-worker00f2b167f8:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 2.83753ms)
May 25 00:58:40.686: INFO: (13) /api/v1/nodes/alex-400-cp1718-vsp2-worker00f2b167f8:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 3.066218ms)
May 25 00:58:40.689: INFO: (14) /api/v1/nodes/alex-400-cp1718-vsp2-worker00f2b167f8:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 2.998117ms)
May 25 00:58:40.692: INFO: (15) /api/v1/nodes/alex-400-cp1718-vsp2-worker00f2b167f8:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 2.734017ms)
May 25 00:58:40.694: INFO: (16) /api/v1/nodes/alex-400-cp1718-vsp2-worker00f2b167f8:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 2.316202ms)
May 25 00:58:40.697: INFO: (17) /api/v1/nodes/alex-400-cp1718-vsp2-worker00f2b167f8:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 2.539655ms)
May 25 00:58:40.700: INFO: (18) /api/v1/nodes/alex-400-cp1718-vsp2-worker00f2b167f8:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 2.584306ms)
May 25 00:58:40.702: INFO: (19) /api/v1/nodes/alex-400-cp1718-vsp2-worker00f2b167f8:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 2.460204ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 00:58:40.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-4czxx" for this suite.
May 25 00:58:46.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 00:58:46.792: INFO: namespace: e2e-tests-proxy-4czxx, resource: bindings, ignored listing per whitelist
May 25 00:58:46.798: INFO: namespace e2e-tests-proxy-4czxx deletion completed in 6.092048137s

• [SLOW TEST:6.313 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 00:58:46.799: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-8cqc5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
May 25 00:58:49.510: INFO: Successfully updated pod "annotationupdate40395d84-7e88-11e9-802f-027f94874578"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 00:58:53.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8cqc5" for this suite.
May 25 00:59:15.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 00:59:15.553: INFO: namespace: e2e-tests-projected-8cqc5, resource: bindings, ignored listing per whitelist
May 25 00:59:15.613: INFO: namespace e2e-tests-projected-8cqc5 deletion completed in 22.079080881s

• [SLOW TEST:28.815 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 00:59:15.615: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-m8xcc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-51645542-7e88-11e9-802f-027f94874578
STEP: Creating a pod to test consume configMaps
May 25 00:59:15.781: INFO: Waiting up to 5m0s for pod "pod-configmaps-516512a7-7e88-11e9-802f-027f94874578" in namespace "e2e-tests-configmap-m8xcc" to be "success or failure"
May 25 00:59:15.787: INFO: Pod "pod-configmaps-516512a7-7e88-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 5.764228ms
May 25 00:59:17.789: INFO: Pod "pod-configmaps-516512a7-7e88-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008659186s
STEP: Saw pod success
May 25 00:59:17.790: INFO: Pod "pod-configmaps-516512a7-7e88-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 00:59:17.792: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-configmaps-516512a7-7e88-11e9-802f-027f94874578 container configmap-volume-test: <nil>
STEP: delete the pod
May 25 00:59:17.808: INFO: Waiting for pod pod-configmaps-516512a7-7e88-11e9-802f-027f94874578 to disappear
May 25 00:59:17.810: INFO: Pod pod-configmaps-516512a7-7e88-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 00:59:17.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-m8xcc" for this suite.
May 25 00:59:23.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 00:59:23.877: INFO: namespace: e2e-tests-configmap-m8xcc, resource: bindings, ignored listing per whitelist
May 25 00:59:23.910: INFO: namespace e2e-tests-configmap-m8xcc deletion completed in 6.097254085s

• [SLOW TEST:8.296 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 00:59:23.913: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-dmzm5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-ctww
STEP: Creating a pod to test atomic-volume-subpath
May 25 00:59:24.085: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-ctww" in namespace "e2e-tests-subpath-dmzm5" to be "success or failure"
May 25 00:59:24.090: INFO: Pod "pod-subpath-test-configmap-ctww": Phase="Pending", Reason="", readiness=false. Elapsed: 4.766418ms
May 25 00:59:26.093: INFO: Pod "pod-subpath-test-configmap-ctww": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007528935s
May 25 00:59:28.095: INFO: Pod "pod-subpath-test-configmap-ctww": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010057856s
May 25 00:59:30.098: INFO: Pod "pod-subpath-test-configmap-ctww": Phase="Running", Reason="", readiness=false. Elapsed: 6.013148934s
May 25 00:59:32.101: INFO: Pod "pod-subpath-test-configmap-ctww": Phase="Running", Reason="", readiness=false. Elapsed: 8.015736029s
May 25 00:59:34.104: INFO: Pod "pod-subpath-test-configmap-ctww": Phase="Running", Reason="", readiness=false. Elapsed: 10.0183314s
May 25 00:59:36.107: INFO: Pod "pod-subpath-test-configmap-ctww": Phase="Running", Reason="", readiness=false. Elapsed: 12.021332288s
May 25 00:59:38.109: INFO: Pod "pod-subpath-test-configmap-ctww": Phase="Running", Reason="", readiness=false. Elapsed: 14.024131934s
May 25 00:59:40.112: INFO: Pod "pod-subpath-test-configmap-ctww": Phase="Running", Reason="", readiness=false. Elapsed: 16.027089684s
May 25 00:59:42.115: INFO: Pod "pod-subpath-test-configmap-ctww": Phase="Running", Reason="", readiness=false. Elapsed: 18.029709042s
May 25 00:59:44.117: INFO: Pod "pod-subpath-test-configmap-ctww": Phase="Running", Reason="", readiness=false. Elapsed: 20.031933572s
May 25 00:59:46.119: INFO: Pod "pod-subpath-test-configmap-ctww": Phase="Running", Reason="", readiness=false. Elapsed: 22.033931092s
May 25 00:59:48.122: INFO: Pod "pod-subpath-test-configmap-ctww": Phase="Running", Reason="", readiness=false. Elapsed: 24.036667325s
May 25 00:59:50.125: INFO: Pod "pod-subpath-test-configmap-ctww": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.039654003s
STEP: Saw pod success
May 25 00:59:50.125: INFO: Pod "pod-subpath-test-configmap-ctww" satisfied condition "success or failure"
May 25 00:59:50.127: INFO: Trying to get logs from node alex-400-cp1718-vsp2-worker00f2b167f8 pod pod-subpath-test-configmap-ctww container test-container-subpath-configmap-ctww: <nil>
STEP: delete the pod
May 25 00:59:50.152: INFO: Waiting for pod pod-subpath-test-configmap-ctww to disappear
May 25 00:59:50.157: INFO: Pod pod-subpath-test-configmap-ctww no longer exists
STEP: Deleting pod pod-subpath-test-configmap-ctww
May 25 00:59:50.157: INFO: Deleting pod "pod-subpath-test-configmap-ctww" in namespace "e2e-tests-subpath-dmzm5"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 00:59:50.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-dmzm5" for this suite.
May 25 00:59:56.174: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 00:59:56.197: INFO: namespace: e2e-tests-subpath-dmzm5, resource: bindings, ignored listing per whitelist
May 25 00:59:56.255: INFO: namespace e2e-tests-subpath-dmzm5 deletion completed in 6.093609278s

• [SLOW TEST:32.342 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 00:59:56.259: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-npsg9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
May 25 00:59:56.440: INFO: Waiting up to 5m0s for pod "var-expansion-69a07cb0-7e88-11e9-802f-027f94874578" in namespace "e2e-tests-var-expansion-npsg9" to be "success or failure"
May 25 00:59:56.443: INFO: Pod "var-expansion-69a07cb0-7e88-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 1.984453ms
May 25 00:59:58.446: INFO: Pod "var-expansion-69a07cb0-7e88-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004368607s
May 25 01:00:00.449: INFO: Pod "var-expansion-69a07cb0-7e88-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007458943s
STEP: Saw pod success
May 25 01:00:00.449: INFO: Pod "var-expansion-69a07cb0-7e88-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:00:00.451: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod var-expansion-69a07cb0-7e88-11e9-802f-027f94874578 container dapi-container: <nil>
STEP: delete the pod
May 25 01:00:00.467: INFO: Waiting for pod var-expansion-69a07cb0-7e88-11e9-802f-027f94874578 to disappear
May 25 01:00:00.469: INFO: Pod var-expansion-69a07cb0-7e88-11e9-802f-027f94874578 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:00:00.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-npsg9" for this suite.
May 25 01:00:06.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:00:06.561: INFO: namespace: e2e-tests-var-expansion-npsg9, resource: bindings, ignored listing per whitelist
May 25 01:00:06.579: INFO: namespace e2e-tests-var-expansion-npsg9 deletion completed in 6.104250033s

• [SLOW TEST:10.321 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:00:06.580: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-vj58q
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-6fc5e22f-7e88-11e9-802f-027f94874578
STEP: Creating a pod to test consume configMaps
May 25 01:00:06.749: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6fc67946-7e88-11e9-802f-027f94874578" in namespace "e2e-tests-projected-vj58q" to be "success or failure"
May 25 01:00:06.760: INFO: Pod "pod-projected-configmaps-6fc67946-7e88-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 11.143394ms
May 25 01:00:08.764: INFO: Pod "pod-projected-configmaps-6fc67946-7e88-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014537865s
STEP: Saw pod success
May 25 01:00:08.764: INFO: Pod "pod-projected-configmaps-6fc67946-7e88-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:00:08.766: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-projected-configmaps-6fc67946-7e88-11e9-802f-027f94874578 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 25 01:00:08.786: INFO: Waiting for pod pod-projected-configmaps-6fc67946-7e88-11e9-802f-027f94874578 to disappear
May 25 01:00:08.788: INFO: Pod pod-projected-configmaps-6fc67946-7e88-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:00:08.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vj58q" for this suite.
May 25 01:00:14.809: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:00:14.863: INFO: namespace: e2e-tests-projected-vj58q, resource: bindings, ignored listing per whitelist
May 25 01:00:14.886: INFO: namespace e2e-tests-projected-vj58q deletion completed in 6.089216625s

• [SLOW TEST:8.307 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:00:14.887: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-hbcnf
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-74c03691-7e88-11e9-802f-027f94874578
STEP: Creating secret with name s-test-opt-upd-74c036d9-7e88-11e9-802f-027f94874578
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-74c03691-7e88-11e9-802f-027f94874578
STEP: Updating secret s-test-opt-upd-74c036d9-7e88-11e9-802f-027f94874578
STEP: Creating secret with name s-test-opt-create-74c03703-7e88-11e9-802f-027f94874578
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:00:19.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hbcnf" for this suite.
May 25 01:00:41.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:00:41.236: INFO: namespace: e2e-tests-projected-hbcnf, resource: bindings, ignored listing per whitelist
May 25 01:00:41.247: INFO: namespace e2e-tests-projected-hbcnf deletion completed in 22.082014236s

• [SLOW TEST:26.360 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:00:41.249: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-ckmvs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 25 01:00:41.519: INFO: Waiting up to 5m0s for pod "downwardapi-volume-846f3140-7e88-11e9-802f-027f94874578" in namespace "e2e-tests-projected-ckmvs" to be "success or failure"
May 25 01:00:41.549: INFO: Pod "downwardapi-volume-846f3140-7e88-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 11.561117ms
May 25 01:00:43.554: INFO: Pod "downwardapi-volume-846f3140-7e88-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016621788s
STEP: Saw pod success
May 25 01:00:43.554: INFO: Pod "downwardapi-volume-846f3140-7e88-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:00:43.557: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod downwardapi-volume-846f3140-7e88-11e9-802f-027f94874578 container client-container: <nil>
STEP: delete the pod
May 25 01:00:43.577: INFO: Waiting for pod downwardapi-volume-846f3140-7e88-11e9-802f-027f94874578 to disappear
May 25 01:00:43.579: INFO: Pod downwardapi-volume-846f3140-7e88-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:00:43.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ckmvs" for this suite.
May 25 01:00:49.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:00:49.647: INFO: namespace: e2e-tests-projected-ckmvs, resource: bindings, ignored listing per whitelist
May 25 01:00:49.675: INFO: namespace e2e-tests-projected-ckmvs deletion completed in 6.092052404s

• [SLOW TEST:8.427 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:00:49.681: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-gxsv2
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-897a7459-7e88-11e9-802f-027f94874578
STEP: Creating configMap with name cm-test-opt-upd-897a74a3-7e88-11e9-802f-027f94874578
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-897a7459-7e88-11e9-802f-027f94874578
STEP: Updating configmap cm-test-opt-upd-897a74a3-7e88-11e9-802f-027f94874578
STEP: Creating configMap with name cm-test-opt-create-897a74c4-7e88-11e9-802f-027f94874578
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:00:53.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-gxsv2" for this suite.
May 25 01:01:15.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:01:16.010: INFO: namespace: e2e-tests-configmap-gxsv2, resource: bindings, ignored listing per whitelist
May 25 01:01:16.037: INFO: namespace e2e-tests-configmap-gxsv2 deletion completed in 22.096534506s

• [SLOW TEST:26.356 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:01:16.038: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-jjjwc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-992beb92-7e88-11e9-802f-027f94874578
STEP: Creating a pod to test consume secrets
May 25 01:01:16.205: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-992c6e4d-7e88-11e9-802f-027f94874578" in namespace "e2e-tests-projected-jjjwc" to be "success or failure"
May 25 01:01:16.207: INFO: Pod "pod-projected-secrets-992c6e4d-7e88-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 1.859304ms
May 25 01:01:18.210: INFO: Pod "pod-projected-secrets-992c6e4d-7e88-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004605628s
STEP: Saw pod success
May 25 01:01:18.210: INFO: Pod "pod-projected-secrets-992c6e4d-7e88-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:01:18.212: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-projected-secrets-992c6e4d-7e88-11e9-802f-027f94874578 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 25 01:01:18.227: INFO: Waiting for pod pod-projected-secrets-992c6e4d-7e88-11e9-802f-027f94874578 to disappear
May 25 01:01:18.230: INFO: Pod pod-projected-secrets-992c6e4d-7e88-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:01:18.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jjjwc" for this suite.
May 25 01:01:24.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:01:24.302: INFO: namespace: e2e-tests-projected-jjjwc, resource: bindings, ignored listing per whitelist
May 25 01:01:24.344: INFO: namespace e2e-tests-projected-jjjwc deletion completed in 6.109269447s

• [SLOW TEST:8.306 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:01:24.345: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-949df
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
May 25 01:01:27.081: INFO: Successfully updated pod "labelsupdate9e26b0dd-7e88-11e9-802f-027f94874578"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:01:29.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-949df" for this suite.
May 25 01:01:51.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:01:51.156: INFO: namespace: e2e-tests-downward-api-949df, resource: bindings, ignored listing per whitelist
May 25 01:01:51.212: INFO: namespace e2e-tests-downward-api-949df deletion completed in 22.113448473s

• [SLOW TEST:26.868 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:01:51.214: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-fzklg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:01:53.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-fzklg" for this suite.
May 25 01:02:31.406: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:02:31.469: INFO: namespace: e2e-tests-kubelet-test-fzklg, resource: bindings, ignored listing per whitelist
May 25 01:02:31.479: INFO: namespace e2e-tests-kubelet-test-fzklg deletion completed in 38.079968592s

• [SLOW TEST:40.265 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:02:31.480: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-8ql6z
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
May 25 01:02:31.654: INFO: Waiting up to 5m0s for pod "downward-api-c624cff1-7e88-11e9-802f-027f94874578" in namespace "e2e-tests-downward-api-8ql6z" to be "success or failure"
May 25 01:02:31.658: INFO: Pod "downward-api-c624cff1-7e88-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 3.973998ms
May 25 01:02:33.661: INFO: Pod "downward-api-c624cff1-7e88-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006889257s
STEP: Saw pod success
May 25 01:02:33.661: INFO: Pod "downward-api-c624cff1-7e88-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:02:33.664: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod downward-api-c624cff1-7e88-11e9-802f-027f94874578 container dapi-container: <nil>
STEP: delete the pod
May 25 01:02:33.677: INFO: Waiting for pod downward-api-c624cff1-7e88-11e9-802f-027f94874578 to disappear
May 25 01:02:33.681: INFO: Pod downward-api-c624cff1-7e88-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:02:33.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-8ql6z" for this suite.
May 25 01:02:39.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:02:39.755: INFO: namespace: e2e-tests-downward-api-8ql6z, resource: bindings, ignored listing per whitelist
May 25 01:02:39.773: INFO: namespace e2e-tests-downward-api-8ql6z deletion completed in 6.088565337s

• [SLOW TEST:8.293 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:02:39.776: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-6489s
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-cb14872e-7e88-11e9-802f-027f94874578
STEP: Creating a pod to test consume secrets
May 25 01:02:39.938: INFO: Waiting up to 5m0s for pod "pod-secrets-cb1507f8-7e88-11e9-802f-027f94874578" in namespace "e2e-tests-secrets-6489s" to be "success or failure"
May 25 01:02:39.946: INFO: Pod "pod-secrets-cb1507f8-7e88-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 4.076053ms
May 25 01:02:41.949: INFO: Pod "pod-secrets-cb1507f8-7e88-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00680911s
STEP: Saw pod success
May 25 01:02:41.949: INFO: Pod "pod-secrets-cb1507f8-7e88-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:02:41.951: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-secrets-cb1507f8-7e88-11e9-802f-027f94874578 container secret-volume-test: <nil>
STEP: delete the pod
May 25 01:02:41.965: INFO: Waiting for pod pod-secrets-cb1507f8-7e88-11e9-802f-027f94874578 to disappear
May 25 01:02:41.968: INFO: Pod pod-secrets-cb1507f8-7e88-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:02:41.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-6489s" for this suite.
May 25 01:02:47.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:02:48.014: INFO: namespace: e2e-tests-secrets-6489s, resource: bindings, ignored listing per whitelist
May 25 01:02:48.065: INFO: namespace e2e-tests-secrets-6489s deletion completed in 6.092847106s

• [SLOW TEST:8.290 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:02:48.067: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-6kptw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 25 01:02:48.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 version --client'
May 25 01:02:48.324: INFO: stderr: ""
May 25 01:02:48.324: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
May 25 01:02:48.326: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 create -f - --namespace=e2e-tests-kubectl-6kptw'
May 25 01:02:48.527: INFO: stderr: ""
May 25 01:02:48.527: INFO: stdout: "replicationcontroller/redis-master created\n"
May 25 01:02:48.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 create -f - --namespace=e2e-tests-kubectl-6kptw'
May 25 01:02:48.757: INFO: stderr: ""
May 25 01:02:48.757: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
May 25 01:02:49.760: INFO: Selector matched 1 pods for map[app:redis]
May 25 01:02:49.760: INFO: Found 0 / 1
May 25 01:02:50.760: INFO: Selector matched 1 pods for map[app:redis]
May 25 01:02:50.760: INFO: Found 1 / 1
May 25 01:02:50.760: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 25 01:02:50.762: INFO: Selector matched 1 pods for map[app:redis]
May 25 01:02:50.762: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 25 01:02:50.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 describe pod redis-master-s9sgz --namespace=e2e-tests-kubectl-6kptw'
May 25 01:02:50.857: INFO: stderr: ""
May 25 01:02:50.857: INFO: stdout: "Name:               redis-master-s9sgz\nNamespace:          e2e-tests-kubectl-6kptw\nPriority:           0\nPriorityClassName:  <none>\nNode:               alex-400-cp1718-vsp2-workere35c6c6a2b/10.10.103.184\nStart Time:         Sat, 25 May 2019 01:02:49 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        cni.projectcalico.org/podIP: 192.168.1.25/32\nStatus:             Running\nIP:                 192.168.1.25\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://38e3ca1af30f5b7e8e56d8e635ce1e1b22f0cb9185cfeb2d656be20cd5882037\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sat, 25 May 2019 01:02:50 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-rbrr6 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-rbrr6:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-rbrr6\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                            Message\n  ----    ------     ----  ----                                            -------\n  Normal  Scheduled  2s    default-scheduler                               Successfully assigned e2e-tests-kubectl-6kptw/redis-master-s9sgz to alex-400-cp1718-vsp2-workere35c6c6a2b\n  Normal  Pulled     1s    kubelet, alex-400-cp1718-vsp2-workere35c6c6a2b  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, alex-400-cp1718-vsp2-workere35c6c6a2b  Created container\n  Normal  Started    0s    kubelet, alex-400-cp1718-vsp2-workere35c6c6a2b  Started container\n"
May 25 01:02:50.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 describe rc redis-master --namespace=e2e-tests-kubectl-6kptw'
May 25 01:02:50.985: INFO: stderr: ""
May 25 01:02:50.985: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-6kptw\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-s9sgz\n"
May 25 01:02:50.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 describe service redis-master --namespace=e2e-tests-kubectl-6kptw'
May 25 01:02:51.086: INFO: stderr: ""
May 25 01:02:51.086: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-6kptw\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.102.206.151\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         192.168.1.25:6379\nSession Affinity:  None\nEvents:            <none>\n"
May 25 01:02:51.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 describe node alex-400-cp1718-vsp2-master942457eba6'
May 25 01:02:51.215: INFO: stderr: ""
May 25 01:02:51.215: INFO: stdout: "Name:               alex-400-cp1718-vsp2-master942457eba6\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/hostname=alex-400-cp1718-vsp2-master942457eba6\n                    node-role.kubernetes.io/master=\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.10.103.182/22\n                    projectcalico.org/IPv4IPIPTunnelAddr: 192.168.185.128\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Fri, 24 May 2019 23:15:55 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Fri, 24 May 2019 23:16:17 +0000   Fri, 24 May 2019 23:16:17 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Sat, 25 May 2019 01:02:46 +0000   Fri, 24 May 2019 23:15:51 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Sat, 25 May 2019 01:02:46 +0000   Fri, 24 May 2019 23:15:51 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Sat, 25 May 2019 01:02:46 +0000   Fri, 24 May 2019 23:15:51 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Sat, 25 May 2019 01:02:46 +0000   Fri, 24 May 2019 23:16:26 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  ExternalIP:  10.10.103.185\n  InternalIP:  10.10.103.182\n  InternalIP:  10.10.103.185\n  Hostname:    alex-400-cp1718-vsp2-master942457eba6\nCapacity:\n cpu:                2\n ephemeral-storage:  40470732Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16426340Ki\n pods:               110\nAllocatable:\n cpu:                2\n ephemeral-storage:  37297826550\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16323940Ki\n pods:               110\nSystem Info:\n Machine ID:                 954100d8464241069c298de7aa7d5161\n System UUID:                421E34D7-2195-B085-1490-A8A11BC6C36B\n Boot ID:                    4c0dd297-af21-4597-84d7-530d20680ae8\n Kernel Version:             4.15.0-48-generic\n OS Image:                   Ubuntu 18.04.2 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://17.3.2\n Kubelet Version:            v1.13.5\n Kube-Proxy Version:         v1.13.5\nPodCIDR:                     192.168.0.0/24\nProviderID:                  vsphere://421e34d7-2195-b085-1490-a8a11bc6c36b\nNon-terminated Pods:         (10 in total)\n  Namespace                  Name                                                             CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                             ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy-e2e-job-4b23e19ca04240f3                                0 (0%)        0 (0%)      0 (0%)           0 (0%)         6m46s\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-759a616327fd41b7-k257b          0 (0%)        0 (0%)      0 (0%)           0 (0%)         6m46s\n  kube-system                calico-kube-controllers-6b99d45456-5wdnk                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         106m\n  kube-system                calico-node-5gqqd                                                250m (12%)    0 (0%)      0 (0%)           0 (0%)         106m\n  kube-system                etcd-alex-400-cp1718-vsp2-master942457eba6                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         105m\n  kube-system                kube-apiserver-alex-400-cp1718-vsp2-master942457eba6             250m (12%)    0 (0%)      0 (0%)           0 (0%)         105m\n  kube-system                kube-controller-manager-alex-400-cp1718-vsp2-master942457eba6    200m (10%)    0 (0%)      0 (0%)           0 (0%)         105m\n  kube-system                kube-proxy-n7c8h                                                 0 (0%)        0 (0%)      0 (0%)           0 (0%)         106m\n  kube-system                kube-scheduler-alex-400-cp1718-vsp2-master942457eba6             100m (5%)     0 (0%)      0 (0%)           0 (0%)         105m\n  kube-system                tiller-deploy-6dff8b9bdb-blc8g                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         106m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                800m (40%)  0 (0%)\n  memory             0 (0%)      0 (0%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:              <none>\n"
May 25 01:02:51.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 describe namespace e2e-tests-kubectl-6kptw'
May 25 01:02:51.331: INFO: stderr: ""
May 25 01:02:51.331: INFO: stdout: "Name:         e2e-tests-kubectl-6kptw\nLabels:       e2e-framework=kubectl\n              e2e-run=f1aea67a-7e87-11e9-802f-027f94874578\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:02:51.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6kptw" for this suite.
May 25 01:03:13.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:03:13.410: INFO: namespace: e2e-tests-kubectl-6kptw, resource: bindings, ignored listing per whitelist
May 25 01:03:13.423: INFO: namespace e2e-tests-kubectl-6kptw deletion completed in 22.087928425s

• [SLOW TEST:25.357 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:03:13.424: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-gvkwk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
May 25 01:03:13.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 create -f - --namespace=e2e-tests-kubectl-gvkwk'
May 25 01:03:13.767: INFO: stderr: ""
May 25 01:03:13.767: INFO: stdout: "pod/pause created\n"
May 25 01:03:13.767: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
May 25 01:03:13.767: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-gvkwk" to be "running and ready"
May 25 01:03:13.770: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.702379ms
May 25 01:03:15.773: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.005720484s
May 25 01:03:15.773: INFO: Pod "pause" satisfied condition "running and ready"
May 25 01:03:15.773: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
May 25 01:03:15.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-gvkwk'
May 25 01:03:15.859: INFO: stderr: ""
May 25 01:03:15.859: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
May 25 01:03:15.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pod pause -L testing-label --namespace=e2e-tests-kubectl-gvkwk'
May 25 01:03:15.939: INFO: stderr: ""
May 25 01:03:15.939: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
May 25 01:03:15.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 label pods pause testing-label- --namespace=e2e-tests-kubectl-gvkwk'
May 25 01:03:16.026: INFO: stderr: ""
May 25 01:03:16.026: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
May 25 01:03:16.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pod pause -L testing-label --namespace=e2e-tests-kubectl-gvkwk'
May 25 01:03:16.122: INFO: stderr: ""
May 25 01:03:16.122: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
May 25 01:03:16.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-gvkwk'
May 25 01:03:16.243: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 25 01:03:16.243: INFO: stdout: "pod \"pause\" force deleted\n"
May 25 01:03:16.244: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-gvkwk'
May 25 01:03:16.353: INFO: stderr: "No resources found.\n"
May 25 01:03:16.353: INFO: stdout: ""
May 25 01:03:16.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods -l name=pause --namespace=e2e-tests-kubectl-gvkwk -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 25 01:03:16.439: INFO: stderr: ""
May 25 01:03:16.439: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:03:16.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gvkwk" for this suite.
May 25 01:03:22.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:03:22.492: INFO: namespace: e2e-tests-kubectl-gvkwk, resource: bindings, ignored listing per whitelist
May 25 01:03:22.534: INFO: namespace e2e-tests-kubectl-gvkwk deletion completed in 6.090489213s

• [SLOW TEST:9.110 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:03:22.536: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-kgmpl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-e4926400-7e88-11e9-802f-027f94874578
STEP: Creating a pod to test consume secrets
May 25 01:03:22.707: INFO: Waiting up to 5m0s for pod "pod-secrets-e492d86d-7e88-11e9-802f-027f94874578" in namespace "e2e-tests-secrets-kgmpl" to be "success or failure"
May 25 01:03:22.712: INFO: Pod "pod-secrets-e492d86d-7e88-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 5.114421ms
May 25 01:03:24.714: INFO: Pod "pod-secrets-e492d86d-7e88-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00789315s
STEP: Saw pod success
May 25 01:03:24.714: INFO: Pod "pod-secrets-e492d86d-7e88-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:03:24.717: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-secrets-e492d86d-7e88-11e9-802f-027f94874578 container secret-volume-test: <nil>
STEP: delete the pod
May 25 01:03:24.733: INFO: Waiting for pod pod-secrets-e492d86d-7e88-11e9-802f-027f94874578 to disappear
May 25 01:03:24.735: INFO: Pod pod-secrets-e492d86d-7e88-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:03:24.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-kgmpl" for this suite.
May 25 01:03:30.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:03:30.780: INFO: namespace: e2e-tests-secrets-kgmpl, resource: bindings, ignored listing per whitelist
May 25 01:03:30.828: INFO: namespace e2e-tests-secrets-kgmpl deletion completed in 6.090014571s

• [SLOW TEST:8.292 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:03:30.829: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-znwv9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-znwv9
May 25 01:03:35.000: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-znwv9
STEP: checking the pod's current state and verifying that restartCount is present
May 25 01:03:35.002: INFO: Initial restart count of pod liveness-http is 0
May 25 01:03:51.024: INFO: Restart count of pod e2e-tests-container-probe-znwv9/liveness-http is now 1 (16.022169915s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:03:51.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-znwv9" for this suite.
May 25 01:03:57.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:03:57.116: INFO: namespace: e2e-tests-container-probe-znwv9, resource: bindings, ignored listing per whitelist
May 25 01:03:57.139: INFO: namespace e2e-tests-container-probe-znwv9 deletion completed in 6.102281844s

• [SLOW TEST:26.310 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:03:57.145: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-tq94c
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
May 25 01:03:57.334: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-tq94c,SelfLink:/api/v1/namespaces/e2e-tests-watch-tq94c/configmaps/e2e-watch-test-resource-version,UID:f935578b-7e88-11e9-ba33-0050569e7ba0,ResourceVersion:12943,Generation:0,CreationTimestamp:2019-05-25 01:03:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 25 01:03:57.335: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-tq94c,SelfLink:/api/v1/namespaces/e2e-tests-watch-tq94c/configmaps/e2e-watch-test-resource-version,UID:f935578b-7e88-11e9-ba33-0050569e7ba0,ResourceVersion:12944,Generation:0,CreationTimestamp:2019-05-25 01:03:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:03:57.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-tq94c" for this suite.
May 25 01:04:03.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:04:03.387: INFO: namespace: e2e-tests-watch-tq94c, resource: bindings, ignored listing per whitelist
May 25 01:04:03.430: INFO: namespace e2e-tests-watch-tq94c deletion completed in 6.09096333s

• [SLOW TEST:6.285 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:04:03.430: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-wqlnr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-fcf1f187-7e88-11e9-802f-027f94874578
STEP: Creating secret with name secret-projected-all-test-volume-fcf1f16a-7e88-11e9-802f-027f94874578
STEP: Creating a pod to test Check all projections for projected volume plugin
May 25 01:04:03.600: INFO: Waiting up to 5m0s for pod "projected-volume-fcf1f125-7e88-11e9-802f-027f94874578" in namespace "e2e-tests-projected-wqlnr" to be "success or failure"
May 25 01:04:03.604: INFO: Pod "projected-volume-fcf1f125-7e88-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 3.397533ms
May 25 01:04:05.607: INFO: Pod "projected-volume-fcf1f125-7e88-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006212627s
STEP: Saw pod success
May 25 01:04:05.607: INFO: Pod "projected-volume-fcf1f125-7e88-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:04:05.609: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod projected-volume-fcf1f125-7e88-11e9-802f-027f94874578 container projected-all-volume-test: <nil>
STEP: delete the pod
May 25 01:04:05.628: INFO: Waiting for pod projected-volume-fcf1f125-7e88-11e9-802f-027f94874578 to disappear
May 25 01:04:05.631: INFO: Pod projected-volume-fcf1f125-7e88-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:04:05.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wqlnr" for this suite.
May 25 01:04:11.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:04:11.659: INFO: namespace: e2e-tests-projected-wqlnr, resource: bindings, ignored listing per whitelist
May 25 01:04:11.711: INFO: namespace e2e-tests-projected-wqlnr deletion completed in 6.076949144s

• [SLOW TEST:8.281 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:04:11.714: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-vn4xd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
May 25 01:04:12.386: INFO: Waiting up to 5m0s for pod "pod-service-account-022f7a8f-7e89-11e9-802f-027f94874578-ph6c4" in namespace "e2e-tests-svcaccounts-vn4xd" to be "success or failure"
May 25 01:04:12.394: INFO: Pod "pod-service-account-022f7a8f-7e89-11e9-802f-027f94874578-ph6c4": Phase="Pending", Reason="", readiness=false. Elapsed: 7.459442ms
May 25 01:04:14.396: INFO: Pod "pod-service-account-022f7a8f-7e89-11e9-802f-027f94874578-ph6c4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0100511s
STEP: Saw pod success
May 25 01:04:14.396: INFO: Pod "pod-service-account-022f7a8f-7e89-11e9-802f-027f94874578-ph6c4" satisfied condition "success or failure"
May 25 01:04:14.400: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-service-account-022f7a8f-7e89-11e9-802f-027f94874578-ph6c4 container token-test: <nil>
STEP: delete the pod
May 25 01:04:14.416: INFO: Waiting for pod pod-service-account-022f7a8f-7e89-11e9-802f-027f94874578-ph6c4 to disappear
May 25 01:04:14.420: INFO: Pod pod-service-account-022f7a8f-7e89-11e9-802f-027f94874578-ph6c4 no longer exists
STEP: Creating a pod to test consume service account root CA
May 25 01:04:14.424: INFO: Waiting up to 5m0s for pod "pod-service-account-022f7a8f-7e89-11e9-802f-027f94874578-dgmq9" in namespace "e2e-tests-svcaccounts-vn4xd" to be "success or failure"
May 25 01:04:14.429: INFO: Pod "pod-service-account-022f7a8f-7e89-11e9-802f-027f94874578-dgmq9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.549997ms
May 25 01:04:16.431: INFO: Pod "pod-service-account-022f7a8f-7e89-11e9-802f-027f94874578-dgmq9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00682179s
STEP: Saw pod success
May 25 01:04:16.431: INFO: Pod "pod-service-account-022f7a8f-7e89-11e9-802f-027f94874578-dgmq9" satisfied condition "success or failure"
May 25 01:04:16.433: INFO: Trying to get logs from node alex-400-cp1718-vsp2-worker00f2b167f8 pod pod-service-account-022f7a8f-7e89-11e9-802f-027f94874578-dgmq9 container root-ca-test: <nil>
STEP: delete the pod
May 25 01:04:16.455: INFO: Waiting for pod pod-service-account-022f7a8f-7e89-11e9-802f-027f94874578-dgmq9 to disappear
May 25 01:04:16.457: INFO: Pod pod-service-account-022f7a8f-7e89-11e9-802f-027f94874578-dgmq9 no longer exists
STEP: Creating a pod to test consume service account namespace
May 25 01:04:16.464: INFO: Waiting up to 5m0s for pod "pod-service-account-022f7a8f-7e89-11e9-802f-027f94874578-84584" in namespace "e2e-tests-svcaccounts-vn4xd" to be "success or failure"
May 25 01:04:16.470: INFO: Pod "pod-service-account-022f7a8f-7e89-11e9-802f-027f94874578-84584": Phase="Pending", Reason="", readiness=false. Elapsed: 5.387502ms
May 25 01:04:18.472: INFO: Pod "pod-service-account-022f7a8f-7e89-11e9-802f-027f94874578-84584": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007790476s
STEP: Saw pod success
May 25 01:04:18.472: INFO: Pod "pod-service-account-022f7a8f-7e89-11e9-802f-027f94874578-84584" satisfied condition "success or failure"
May 25 01:04:18.474: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-service-account-022f7a8f-7e89-11e9-802f-027f94874578-84584 container namespace-test: <nil>
STEP: delete the pod
May 25 01:04:18.490: INFO: Waiting for pod pod-service-account-022f7a8f-7e89-11e9-802f-027f94874578-84584 to disappear
May 25 01:04:18.492: INFO: Pod pod-service-account-022f7a8f-7e89-11e9-802f-027f94874578-84584 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:04:18.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-vn4xd" for this suite.
May 25 01:04:24.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:04:24.673: INFO: namespace: e2e-tests-svcaccounts-vn4xd, resource: bindings, ignored listing per whitelist
May 25 01:04:24.678: INFO: namespace e2e-tests-svcaccounts-vn4xd deletion completed in 6.16861772s

• [SLOW TEST:12.965 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:04:24.681: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-nbxv4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 25 01:04:24.853: INFO: Waiting up to 5m0s for pod "downwardapi-volume-099d88e1-7e89-11e9-802f-027f94874578" in namespace "e2e-tests-projected-nbxv4" to be "success or failure"
May 25 01:04:24.857: INFO: Pod "downwardapi-volume-099d88e1-7e89-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 3.782112ms
May 25 01:04:26.860: INFO: Pod "downwardapi-volume-099d88e1-7e89-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006847554s
STEP: Saw pod success
May 25 01:04:26.860: INFO: Pod "downwardapi-volume-099d88e1-7e89-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:04:26.863: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod downwardapi-volume-099d88e1-7e89-11e9-802f-027f94874578 container client-container: <nil>
STEP: delete the pod
May 25 01:04:26.889: INFO: Waiting for pod downwardapi-volume-099d88e1-7e89-11e9-802f-027f94874578 to disappear
May 25 01:04:26.891: INFO: Pod downwardapi-volume-099d88e1-7e89-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:04:26.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nbxv4" for this suite.
May 25 01:04:32.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:04:32.930: INFO: namespace: e2e-tests-projected-nbxv4, resource: bindings, ignored listing per whitelist
May 25 01:04:32.984: INFO: namespace e2e-tests-projected-nbxv4 deletion completed in 6.088694597s

• [SLOW TEST:8.303 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:04:32.985: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-sc2cr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 25 01:04:33.145: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0e8ed371-7e89-11e9-802f-027f94874578" in namespace "e2e-tests-projected-sc2cr" to be "success or failure"
May 25 01:04:33.151: INFO: Pod "downwardapi-volume-0e8ed371-7e89-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 5.497796ms
May 25 01:04:35.154: INFO: Pod "downwardapi-volume-0e8ed371-7e89-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008496464s
STEP: Saw pod success
May 25 01:04:35.154: INFO: Pod "downwardapi-volume-0e8ed371-7e89-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:04:35.156: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod downwardapi-volume-0e8ed371-7e89-11e9-802f-027f94874578 container client-container: <nil>
STEP: delete the pod
May 25 01:04:35.170: INFO: Waiting for pod downwardapi-volume-0e8ed371-7e89-11e9-802f-027f94874578 to disappear
May 25 01:04:35.172: INFO: Pod downwardapi-volume-0e8ed371-7e89-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:04:35.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sc2cr" for this suite.
May 25 01:04:41.184: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:04:41.210: INFO: namespace: e2e-tests-projected-sc2cr, resource: bindings, ignored listing per whitelist
May 25 01:04:41.268: INFO: namespace e2e-tests-projected-sc2cr deletion completed in 6.092781217s

• [SLOW TEST:8.284 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:04:41.272: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-vwjgv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 25 01:04:45.464: INFO: Waiting up to 5m0s for pod "client-envvars-15e6bff4-7e89-11e9-802f-027f94874578" in namespace "e2e-tests-pods-vwjgv" to be "success or failure"
May 25 01:04:45.472: INFO: Pod "client-envvars-15e6bff4-7e89-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 7.61241ms
May 25 01:04:47.475: INFO: Pod "client-envvars-15e6bff4-7e89-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010394723s
STEP: Saw pod success
May 25 01:04:47.475: INFO: Pod "client-envvars-15e6bff4-7e89-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:04:47.477: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod client-envvars-15e6bff4-7e89-11e9-802f-027f94874578 container env3cont: <nil>
STEP: delete the pod
May 25 01:04:47.498: INFO: Waiting for pod client-envvars-15e6bff4-7e89-11e9-802f-027f94874578 to disappear
May 25 01:04:47.500: INFO: Pod client-envvars-15e6bff4-7e89-11e9-802f-027f94874578 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:04:47.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-vwjgv" for this suite.
May 25 01:05:29.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:05:29.613: INFO: namespace: e2e-tests-pods-vwjgv, resource: bindings, ignored listing per whitelist
May 25 01:05:29.615: INFO: namespace e2e-tests-pods-vwjgv deletion completed in 42.111365556s

• [SLOW TEST:48.344 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:05:29.616: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-gb9gb
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-30532c20-7e89-11e9-802f-027f94874578
STEP: Creating configMap with name cm-test-opt-upd-30532c71-7e89-11e9-802f-027f94874578
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-30532c20-7e89-11e9-802f-027f94874578
STEP: Updating configmap cm-test-opt-upd-30532c71-7e89-11e9-802f-027f94874578
STEP: Creating configMap with name cm-test-opt-create-30532c90-7e89-11e9-802f-027f94874578
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:06:46.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gb9gb" for this suite.
May 25 01:07:08.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:07:08.213: INFO: namespace: e2e-tests-projected-gb9gb, resource: bindings, ignored listing per whitelist
May 25 01:07:08.239: INFO: namespace e2e-tests-projected-gb9gb deletion completed in 22.088718131s

• [SLOW TEST:98.622 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:07:08.241: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-ckbq7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-ckbq7
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 25 01:07:08.397: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 25 01:07:28.473: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.1.37:8080/dial?request=hostName&protocol=http&host=192.168.1.36&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-ckbq7 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 25 01:07:28.473: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
May 25 01:07:28.642: INFO: Waiting for endpoints: map[]
May 25 01:07:28.646: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.1.37:8080/dial?request=hostName&protocol=http&host=192.168.2.21&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-ckbq7 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 25 01:07:28.646: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
May 25 01:07:28.701: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:07:28.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-ckbq7" for this suite.
May 25 01:07:50.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:07:50.785: INFO: namespace: e2e-tests-pod-network-test-ckbq7, resource: bindings, ignored listing per whitelist
May 25 01:07:50.792: INFO: namespace e2e-tests-pod-network-test-ckbq7 deletion completed in 22.086203289s

• [SLOW TEST:42.551 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:07:50.792: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-8598b
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-84767819-7e89-11e9-802f-027f94874578
May 25 01:07:50.956: INFO: Pod name my-hostname-basic-84767819-7e89-11e9-802f-027f94874578: Found 0 pods out of 1
May 25 01:07:55.962: INFO: Pod name my-hostname-basic-84767819-7e89-11e9-802f-027f94874578: Found 1 pods out of 1
May 25 01:07:55.962: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-84767819-7e89-11e9-802f-027f94874578" are running
May 25 01:07:55.966: INFO: Pod "my-hostname-basic-84767819-7e89-11e9-802f-027f94874578-8nvbw" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-25 01:07:51 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-25 01:07:53 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-25 01:07:53 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-25 01:07:50 +0000 UTC Reason: Message:}])
May 25 01:07:55.969: INFO: Trying to dial the pod
May 25 01:08:00.977: INFO: Controller my-hostname-basic-84767819-7e89-11e9-802f-027f94874578: Got expected result from replica 1 [my-hostname-basic-84767819-7e89-11e9-802f-027f94874578-8nvbw]: "my-hostname-basic-84767819-7e89-11e9-802f-027f94874578-8nvbw", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:08:00.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-8598b" for this suite.
May 25 01:08:06.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:08:07.035: INFO: namespace: e2e-tests-replication-controller-8598b, resource: bindings, ignored listing per whitelist
May 25 01:08:07.071: INFO: namespace e2e-tests-replication-controller-8598b deletion completed in 6.090140212s

• [SLOW TEST:16.279 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:08:07.072: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-jrsvz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:08:11.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-jrsvz" for this suite.
May 25 01:08:17.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:08:17.305: INFO: namespace: e2e-tests-kubelet-test-jrsvz, resource: bindings, ignored listing per whitelist
May 25 01:08:17.335: INFO: namespace e2e-tests-kubelet-test-jrsvz deletion completed in 6.085551207s

• [SLOW TEST:10.263 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:08:17.337: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-9646r
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
May 25 01:08:17.505: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 25 01:08:17.520: INFO: Waiting for terminating namespaces to be deleted...
May 25 01:08:17.535: INFO: 
Logging pods the kubelet thinks is on node alex-400-cp1718-vsp2-worker00f2b167f8 before test
May 25 01:08:17.541: INFO: fluentd-es-v2.0.2-qtlkg from ccp started at 2019-05-24 23:16:58 +0000 UTC (1 container statuses recorded)
May 25 01:08:17.542: INFO: 	Container fluentd-es ready: true, restart count 0
May 25 01:08:17.542: INFO: ccp-monitor-grafana-684748f9d4-vk76c from ccp started at 2019-05-24 23:17:00 +0000 UTC (1 container statuses recorded)
May 25 01:08:17.542: INFO: 	Container grafana ready: true, restart count 0
May 25 01:08:17.542: INFO: calico-node-ln8pj from kube-system started at 2019-05-24 23:16:19 +0000 UTC (1 container statuses recorded)
May 25 01:08:17.542: INFO: 	Container calico-node ready: true, restart count 0
May 25 01:08:17.542: INFO: nginx-ingress-default-backend-7b7b5b4985-zth7k from ccp started at 2019-05-24 23:16:48 +0000 UTC (1 container statuses recorded)
May 25 01:08:17.542: INFO: 	Container nginx-ingress-default-backend ready: true, restart count 0
May 25 01:08:17.542: INFO: metallb-controller-78744dd4f-df8gm from ccp started at 2019-05-24 23:16:48 +0000 UTC (1 container statuses recorded)
May 25 01:08:17.542: INFO: 	Container controller ready: true, restart count 0
May 25 01:08:17.542: INFO: ccp-monitor-grafana-set-datasource-27gm4 from ccp started at 2019-05-24 23:16:57 +0000 UTC (1 container statuses recorded)
May 25 01:08:17.542: INFO: 	Container ccp-monitor-grafana-set-datasource ready: false, restart count 2
May 25 01:08:17.542: INFO: ccp-monitor-prometheus-pushgateway-db8b97744-7frml from ccp started at 2019-05-24 23:16:57 +0000 UTC (1 container statuses recorded)
May 25 01:08:17.542: INFO: 	Container prometheus-pushgateway ready: true, restart count 0
May 25 01:08:17.542: INFO: ccp-efk-kibana-7746ff6cdd-vg2vg from ccp started at 2019-05-24 23:16:58 +0000 UTC (1 container statuses recorded)
May 25 01:08:17.543: INFO: 	Container kibana ready: true, restart count 0
May 25 01:08:17.543: INFO: sonobuoy-systemd-logs-daemon-set-759a616327fd41b7-kvqs6 from heptio-sonobuoy started at 2019-05-25 00:56:06 +0000 UTC (2 container statuses recorded)
May 25 01:08:17.543: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 25 01:08:17.543: INFO: 	Container systemd-logs ready: true, restart count 0
May 25 01:08:17.543: INFO: calico-typha-59fdcbc755-6jn4r from kube-system started at 2019-05-24 23:16:29 +0000 UTC (1 container statuses recorded)
May 25 01:08:17.543: INFO: 	Container calico-typha ready: true, restart count 0
May 25 01:08:17.543: INFO: coredns-5d768868f-x48tv from kube-system started at 2019-05-24 23:16:45 +0000 UTC (1 container statuses recorded)
May 25 01:08:17.543: INFO: 	Container coredns ready: true, restart count 0
May 25 01:08:17.543: INFO: ccp-monitor-prometheus-node-exporter-xc6v8 from ccp started at 2019-05-24 23:16:56 +0000 UTC (1 container statuses recorded)
May 25 01:08:17.543: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
May 25 01:08:17.543: INFO: ccp-monitor-prometheus-alertmanager-689d9f95c6-qfbth from ccp started at 2019-05-24 23:16:56 +0000 UTC (2 container statuses recorded)
May 25 01:08:17.543: INFO: 	Container prometheus-alertmanager ready: true, restart count 0
May 25 01:08:17.543: INFO: 	Container prometheus-alertmanager-configmap-reload ready: true, restart count 0
May 25 01:08:17.543: INFO: kube-proxy-gw2wq from kube-system started at 2019-05-24 23:16:19 +0000 UTC (1 container statuses recorded)
May 25 01:08:17.544: INFO: 	Container kube-proxy ready: true, restart count 0
May 25 01:08:17.544: INFO: nginx-ingress-controller-tkn4x from ccp started at 2019-05-24 23:16:48 +0000 UTC (1 container statuses recorded)
May 25 01:08:17.544: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
May 25 01:08:17.544: INFO: metallb-speaker-s252f from ccp started at 2019-05-24 23:16:48 +0000 UTC (1 container statuses recorded)
May 25 01:08:17.544: INFO: 	Container speaker ready: true, restart count 0
May 25 01:08:17.544: INFO: sonobuoy from heptio-sonobuoy started at 2019-05-25 00:56:03 +0000 UTC (1 container statuses recorded)
May 25 01:08:17.544: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 25 01:08:17.544: INFO: 
Logging pods the kubelet thinks is on node alex-400-cp1718-vsp2-workere35c6c6a2b before test
May 25 01:08:17.554: INFO: kube-proxy-xslv4 from kube-system started at 2019-05-24 23:16:19 +0000 UTC (1 container statuses recorded)
May 25 01:08:17.556: INFO: 	Container kube-proxy ready: true, restart count 0
May 25 01:08:17.556: INFO: ccp-monitor-prometheus-server-5cb4549d87-98vp8 from ccp started at 2019-05-24 23:16:57 +0000 UTC (3 container statuses recorded)
May 25 01:08:17.556: INFO: 	Container nginx-proxy ready: true, restart count 0
May 25 01:08:17.556: INFO: 	Container prometheus-server ready: true, restart count 0
May 25 01:08:17.556: INFO: 	Container prometheus-server-configmap-reload ready: true, restart count 0
May 25 01:08:17.556: INFO: calico-typha-59fdcbc755-z6pj6 from kube-system started at 2019-05-24 23:16:29 +0000 UTC (1 container statuses recorded)
May 25 01:08:17.557: INFO: 	Container calico-typha ready: true, restart count 0
May 25 01:08:17.557: INFO: nginx-ingress-controller-772hp from ccp started at 2019-05-24 23:16:48 +0000 UTC (1 container statuses recorded)
May 25 01:08:17.557: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
May 25 01:08:17.557: INFO: kubernetes-dashboard-548b88c5d8-44vhs from ccp started at 2019-05-24 23:16:50 +0000 UTC (1 container statuses recorded)
May 25 01:08:17.557: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 25 01:08:17.557: INFO: ccp-monitor-prometheus-node-exporter-ch87m from ccp started at 2019-05-24 23:16:56 +0000 UTC (1 container statuses recorded)
May 25 01:08:17.557: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
May 25 01:08:17.557: INFO: fluentd-es-v2.0.2-6mb7h from ccp started at 2019-05-24 23:16:58 +0000 UTC (1 container statuses recorded)
May 25 01:08:17.557: INFO: 	Container fluentd-es ready: true, restart count 0
May 25 01:08:17.557: INFO: sonobuoy-systemd-logs-daemon-set-759a616327fd41b7-9bvtk from heptio-sonobuoy started at 2019-05-25 00:56:06 +0000 UTC (2 container statuses recorded)
May 25 01:08:17.557: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 25 01:08:17.557: INFO: 	Container systemd-logs ready: true, restart count 0
May 25 01:08:17.558: INFO: ccp-efk-elasticsearch-curator-1558746000-74q96 from ccp started at 2019-05-25 01:00:10 +0000 UTC (1 container statuses recorded)
May 25 01:08:17.558: INFO: 	Container elasticsearch-curator ready: false, restart count 0
May 25 01:08:17.558: INFO: coredns-5d768868f-ghkvd from kube-system started at 2019-05-24 23:16:45 +0000 UTC (1 container statuses recorded)
May 25 01:08:17.558: INFO: 	Container coredns ready: true, restart count 0
May 25 01:08:17.558: INFO: metallb-speaker-rbdjd from ccp started at 2019-05-24 23:16:48 +0000 UTC (1 container statuses recorded)
May 25 01:08:17.558: INFO: 	Container speaker ready: true, restart count 0
May 25 01:08:17.558: INFO: ccp-monitor-prometheus-kube-state-metrics-7cdd89dbbf-zpwzt from ccp started at 2019-05-24 23:16:57 +0000 UTC (1 container statuses recorded)
May 25 01:08:17.558: INFO: 	Container prometheus-kube-state-metrics ready: true, restart count 0
May 25 01:08:17.558: INFO: elasticsearch-logging-0 from ccp started at 2019-05-24 23:17:01 +0000 UTC (1 container statuses recorded)
May 25 01:08:17.558: INFO: 	Container elasticsearch-logging ready: true, restart count 0
May 25 01:08:17.558: INFO: calico-node-8jh64 from kube-system started at 2019-05-24 23:16:19 +0000 UTC (1 container statuses recorded)
May 25 01:08:17.558: INFO: 	Container calico-node ready: true, restart count 0
May 25 01:08:17.558: INFO: cert-manager-5f9c44cd46-xttzw from ccp started at 2019-05-24 23:16:38 +0000 UTC (1 container statuses recorded)
May 25 01:08:17.559: INFO: 	Container cert-manager ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-958849c7-7e89-11e9-802f-027f94874578 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-958849c7-7e89-11e9-802f-027f94874578 off the node alex-400-cp1718-vsp2-workere35c6c6a2b
STEP: verifying the node doesn't have the label kubernetes.io/e2e-958849c7-7e89-11e9-802f-027f94874578
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:08:21.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-9646r" for this suite.
May 25 01:08:29.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:08:29.774: INFO: namespace: e2e-tests-sched-pred-9646r, resource: bindings, ignored listing per whitelist
May 25 01:08:29.816: INFO: namespace e2e-tests-sched-pred-9646r deletion completed in 8.080947938s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:12.479 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:08:29.817: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-744gj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
May 25 01:08:29.987: INFO: Waiting up to 5m0s for pod "downward-api-9bba31e4-7e89-11e9-802f-027f94874578" in namespace "e2e-tests-downward-api-744gj" to be "success or failure"
May 25 01:08:29.991: INFO: Pod "downward-api-9bba31e4-7e89-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 4.524739ms
May 25 01:08:31.994: INFO: Pod "downward-api-9bba31e4-7e89-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006836758s
STEP: Saw pod success
May 25 01:08:31.994: INFO: Pod "downward-api-9bba31e4-7e89-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:08:31.996: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod downward-api-9bba31e4-7e89-11e9-802f-027f94874578 container dapi-container: <nil>
STEP: delete the pod
May 25 01:08:32.019: INFO: Waiting for pod downward-api-9bba31e4-7e89-11e9-802f-027f94874578 to disappear
May 25 01:08:32.021: INFO: Pod downward-api-9bba31e4-7e89-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:08:32.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-744gj" for this suite.
May 25 01:08:38.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:08:38.082: INFO: namespace: e2e-tests-downward-api-744gj, resource: bindings, ignored listing per whitelist
May 25 01:08:38.113: INFO: namespace e2e-tests-downward-api-744gj deletion completed in 6.088289925s

• [SLOW TEST:8.297 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:08:38.114: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-custom-resource-definition-p8h57
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 25 01:08:38.321: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:08:39.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-p8h57" for this suite.
May 25 01:08:45.375: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:08:45.410: INFO: namespace: e2e-tests-custom-resource-definition-p8h57, resource: bindings, ignored listing per whitelist
May 25 01:08:45.448: INFO: namespace e2e-tests-custom-resource-definition-p8h57 deletion completed in 6.081575754s

• [SLOW TEST:7.335 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:08:45.449: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-2df4j
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-2df4j
May 25 01:08:47.619: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-2df4j
STEP: checking the pod's current state and verifying that restartCount is present
May 25 01:08:47.622: INFO: Initial restart count of pod liveness-http is 0
May 25 01:09:07.655: INFO: Restart count of pod e2e-tests-container-probe-2df4j/liveness-http is now 1 (20.033336768s elapsed)
May 25 01:09:27.682: INFO: Restart count of pod e2e-tests-container-probe-2df4j/liveness-http is now 2 (40.060420801s elapsed)
May 25 01:09:47.710: INFO: Restart count of pod e2e-tests-container-probe-2df4j/liveness-http is now 3 (1m0.08880433s elapsed)
May 25 01:10:07.738: INFO: Restart count of pod e2e-tests-container-probe-2df4j/liveness-http is now 4 (1m20.11640886s elapsed)
May 25 01:11:09.828: INFO: Restart count of pod e2e-tests-container-probe-2df4j/liveness-http is now 5 (2m22.206011646s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:11:09.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-2df4j" for this suite.
May 25 01:11:15.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:11:15.875: INFO: namespace: e2e-tests-container-probe-2df4j, resource: bindings, ignored listing per whitelist
May 25 01:11:15.938: INFO: namespace e2e-tests-container-probe-2df4j deletion completed in 6.093765413s

• [SLOW TEST:150.489 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:11:15.938: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-mcbtz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
May 25 01:11:16.104: INFO: Waiting up to 5m0s for pod "downward-api-febdc1a6-7e89-11e9-802f-027f94874578" in namespace "e2e-tests-downward-api-mcbtz" to be "success or failure"
May 25 01:11:16.108: INFO: Pod "downward-api-febdc1a6-7e89-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 4.42226ms
May 25 01:11:18.111: INFO: Pod "downward-api-febdc1a6-7e89-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007234352s
STEP: Saw pod success
May 25 01:11:18.111: INFO: Pod "downward-api-febdc1a6-7e89-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:11:18.113: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod downward-api-febdc1a6-7e89-11e9-802f-027f94874578 container dapi-container: <nil>
STEP: delete the pod
May 25 01:11:18.135: INFO: Waiting for pod downward-api-febdc1a6-7e89-11e9-802f-027f94874578 to disappear
May 25 01:11:18.137: INFO: Pod downward-api-febdc1a6-7e89-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:11:18.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-mcbtz" for this suite.
May 25 01:11:24.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:11:24.220: INFO: namespace: e2e-tests-downward-api-mcbtz, resource: bindings, ignored listing per whitelist
May 25 01:11:24.232: INFO: namespace e2e-tests-downward-api-mcbtz deletion completed in 6.08901815s

• [SLOW TEST:8.294 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:11:24.233: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-bdq7w
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:11:31.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-bdq7w" for this suite.
May 25 01:11:53.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:11:53.518: INFO: namespace: e2e-tests-replication-controller-bdq7w, resource: bindings, ignored listing per whitelist
May 25 01:11:53.523: INFO: namespace e2e-tests-replication-controller-bdq7w deletion completed in 22.082722701s

• [SLOW TEST:29.290 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:11:53.524: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-t8qlf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
May 25 01:11:53.681: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 25 01:11:53.688: INFO: Waiting for terminating namespaces to be deleted...
May 25 01:11:53.692: INFO: 
Logging pods the kubelet thinks is on node alex-400-cp1718-vsp2-worker00f2b167f8 before test
May 25 01:11:53.701: INFO: fluentd-es-v2.0.2-qtlkg from ccp started at 2019-05-24 23:16:58 +0000 UTC (1 container statuses recorded)
May 25 01:11:53.701: INFO: 	Container fluentd-es ready: true, restart count 0
May 25 01:11:53.701: INFO: ccp-monitor-grafana-684748f9d4-vk76c from ccp started at 2019-05-24 23:17:00 +0000 UTC (1 container statuses recorded)
May 25 01:11:53.701: INFO: 	Container grafana ready: true, restart count 0
May 25 01:11:53.701: INFO: calico-node-ln8pj from kube-system started at 2019-05-24 23:16:19 +0000 UTC (1 container statuses recorded)
May 25 01:11:53.701: INFO: 	Container calico-node ready: true, restart count 0
May 25 01:11:53.701: INFO: nginx-ingress-default-backend-7b7b5b4985-zth7k from ccp started at 2019-05-24 23:16:48 +0000 UTC (1 container statuses recorded)
May 25 01:11:53.701: INFO: 	Container nginx-ingress-default-backend ready: true, restart count 0
May 25 01:11:53.701: INFO: metallb-controller-78744dd4f-df8gm from ccp started at 2019-05-24 23:16:48 +0000 UTC (1 container statuses recorded)
May 25 01:11:53.701: INFO: 	Container controller ready: true, restart count 0
May 25 01:11:53.701: INFO: ccp-monitor-grafana-set-datasource-27gm4 from ccp started at 2019-05-24 23:16:57 +0000 UTC (1 container statuses recorded)
May 25 01:11:53.701: INFO: 	Container ccp-monitor-grafana-set-datasource ready: false, restart count 2
May 25 01:11:53.701: INFO: ccp-monitor-prometheus-pushgateway-db8b97744-7frml from ccp started at 2019-05-24 23:16:57 +0000 UTC (1 container statuses recorded)
May 25 01:11:53.701: INFO: 	Container prometheus-pushgateway ready: true, restart count 0
May 25 01:11:53.701: INFO: ccp-efk-kibana-7746ff6cdd-vg2vg from ccp started at 2019-05-24 23:16:58 +0000 UTC (1 container statuses recorded)
May 25 01:11:53.701: INFO: 	Container kibana ready: true, restart count 0
May 25 01:11:53.701: INFO: sonobuoy-systemd-logs-daemon-set-759a616327fd41b7-kvqs6 from heptio-sonobuoy started at 2019-05-25 00:56:06 +0000 UTC (2 container statuses recorded)
May 25 01:11:53.701: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 25 01:11:53.701: INFO: 	Container systemd-logs ready: true, restart count 0
May 25 01:11:53.701: INFO: calico-typha-59fdcbc755-6jn4r from kube-system started at 2019-05-24 23:16:29 +0000 UTC (1 container statuses recorded)
May 25 01:11:53.701: INFO: 	Container calico-typha ready: true, restart count 0
May 25 01:11:53.701: INFO: coredns-5d768868f-x48tv from kube-system started at 2019-05-24 23:16:45 +0000 UTC (1 container statuses recorded)
May 25 01:11:53.701: INFO: 	Container coredns ready: true, restart count 0
May 25 01:11:53.701: INFO: ccp-monitor-prometheus-node-exporter-xc6v8 from ccp started at 2019-05-24 23:16:56 +0000 UTC (1 container statuses recorded)
May 25 01:11:53.701: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
May 25 01:11:53.701: INFO: ccp-monitor-prometheus-alertmanager-689d9f95c6-qfbth from ccp started at 2019-05-24 23:16:56 +0000 UTC (2 container statuses recorded)
May 25 01:11:53.701: INFO: 	Container prometheus-alertmanager ready: true, restart count 0
May 25 01:11:53.701: INFO: 	Container prometheus-alertmanager-configmap-reload ready: true, restart count 0
May 25 01:11:53.701: INFO: kube-proxy-gw2wq from kube-system started at 2019-05-24 23:16:19 +0000 UTC (1 container statuses recorded)
May 25 01:11:53.701: INFO: 	Container kube-proxy ready: true, restart count 0
May 25 01:11:53.701: INFO: nginx-ingress-controller-tkn4x from ccp started at 2019-05-24 23:16:48 +0000 UTC (1 container statuses recorded)
May 25 01:11:53.701: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
May 25 01:11:53.701: INFO: metallb-speaker-s252f from ccp started at 2019-05-24 23:16:48 +0000 UTC (1 container statuses recorded)
May 25 01:11:53.701: INFO: 	Container speaker ready: true, restart count 0
May 25 01:11:53.701: INFO: sonobuoy from heptio-sonobuoy started at 2019-05-25 00:56:03 +0000 UTC (1 container statuses recorded)
May 25 01:11:53.701: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 25 01:11:53.702: INFO: 
Logging pods the kubelet thinks is on node alex-400-cp1718-vsp2-workere35c6c6a2b before test
May 25 01:11:53.709: INFO: coredns-5d768868f-ghkvd from kube-system started at 2019-05-24 23:16:45 +0000 UTC (1 container statuses recorded)
May 25 01:11:53.709: INFO: 	Container coredns ready: true, restart count 0
May 25 01:11:53.709: INFO: metallb-speaker-rbdjd from ccp started at 2019-05-24 23:16:48 +0000 UTC (1 container statuses recorded)
May 25 01:11:53.709: INFO: 	Container speaker ready: true, restart count 0
May 25 01:11:53.709: INFO: ccp-monitor-prometheus-kube-state-metrics-7cdd89dbbf-zpwzt from ccp started at 2019-05-24 23:16:57 +0000 UTC (1 container statuses recorded)
May 25 01:11:53.709: INFO: 	Container prometheus-kube-state-metrics ready: true, restart count 0
May 25 01:11:53.709: INFO: elasticsearch-logging-0 from ccp started at 2019-05-24 23:17:01 +0000 UTC (1 container statuses recorded)
May 25 01:11:53.710: INFO: 	Container elasticsearch-logging ready: true, restart count 0
May 25 01:11:53.710: INFO: calico-node-8jh64 from kube-system started at 2019-05-24 23:16:19 +0000 UTC (1 container statuses recorded)
May 25 01:11:53.710: INFO: 	Container calico-node ready: true, restart count 0
May 25 01:11:53.710: INFO: cert-manager-5f9c44cd46-xttzw from ccp started at 2019-05-24 23:16:38 +0000 UTC (1 container statuses recorded)
May 25 01:11:53.710: INFO: 	Container cert-manager ready: true, restart count 0
May 25 01:11:53.710: INFO: kube-proxy-xslv4 from kube-system started at 2019-05-24 23:16:19 +0000 UTC (1 container statuses recorded)
May 25 01:11:53.710: INFO: 	Container kube-proxy ready: true, restart count 0
May 25 01:11:53.710: INFO: ccp-monitor-prometheus-server-5cb4549d87-98vp8 from ccp started at 2019-05-24 23:16:57 +0000 UTC (3 container statuses recorded)
May 25 01:11:53.710: INFO: 	Container nginx-proxy ready: true, restart count 0
May 25 01:11:53.710: INFO: 	Container prometheus-server ready: true, restart count 0
May 25 01:11:53.710: INFO: 	Container prometheus-server-configmap-reload ready: true, restart count 0
May 25 01:11:53.710: INFO: calico-typha-59fdcbc755-z6pj6 from kube-system started at 2019-05-24 23:16:29 +0000 UTC (1 container statuses recorded)
May 25 01:11:53.710: INFO: 	Container calico-typha ready: true, restart count 0
May 25 01:11:53.710: INFO: nginx-ingress-controller-772hp from ccp started at 2019-05-24 23:16:48 +0000 UTC (1 container statuses recorded)
May 25 01:11:53.710: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
May 25 01:11:53.710: INFO: kubernetes-dashboard-548b88c5d8-44vhs from ccp started at 2019-05-24 23:16:50 +0000 UTC (1 container statuses recorded)
May 25 01:11:53.710: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 25 01:11:53.710: INFO: ccp-monitor-prometheus-node-exporter-ch87m from ccp started at 2019-05-24 23:16:56 +0000 UTC (1 container statuses recorded)
May 25 01:11:53.710: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
May 25 01:11:53.710: INFO: fluentd-es-v2.0.2-6mb7h from ccp started at 2019-05-24 23:16:58 +0000 UTC (1 container statuses recorded)
May 25 01:11:53.710: INFO: 	Container fluentd-es ready: true, restart count 0
May 25 01:11:53.710: INFO: sonobuoy-systemd-logs-daemon-set-759a616327fd41b7-9bvtk from heptio-sonobuoy started at 2019-05-25 00:56:06 +0000 UTC (2 container statuses recorded)
May 25 01:11:53.710: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 25 01:11:53.710: INFO: 	Container systemd-logs ready: true, restart count 0
May 25 01:11:53.710: INFO: ccp-efk-elasticsearch-curator-1558746000-74q96 from ccp started at 2019-05-25 01:00:10 +0000 UTC (1 container statuses recorded)
May 25 01:11:53.710: INFO: 	Container elasticsearch-curator ready: false, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node alex-400-cp1718-vsp2-worker00f2b167f8
STEP: verifying the node has the label node alex-400-cp1718-vsp2-workere35c6c6a2b
May 25 01:11:53.757: INFO: Pod ccp-efk-kibana-7746ff6cdd-vg2vg requesting resource cpu=0m on Node alex-400-cp1718-vsp2-worker00f2b167f8
May 25 01:11:53.758: INFO: Pod ccp-monitor-grafana-684748f9d4-vk76c requesting resource cpu=0m on Node alex-400-cp1718-vsp2-worker00f2b167f8
May 25 01:11:53.758: INFO: Pod ccp-monitor-prometheus-alertmanager-689d9f95c6-qfbth requesting resource cpu=0m on Node alex-400-cp1718-vsp2-worker00f2b167f8
May 25 01:11:53.758: INFO: Pod ccp-monitor-prometheus-kube-state-metrics-7cdd89dbbf-zpwzt requesting resource cpu=0m on Node alex-400-cp1718-vsp2-workere35c6c6a2b
May 25 01:11:53.758: INFO: Pod ccp-monitor-prometheus-node-exporter-ch87m requesting resource cpu=0m on Node alex-400-cp1718-vsp2-workere35c6c6a2b
May 25 01:11:53.758: INFO: Pod ccp-monitor-prometheus-node-exporter-xc6v8 requesting resource cpu=0m on Node alex-400-cp1718-vsp2-worker00f2b167f8
May 25 01:11:53.758: INFO: Pod ccp-monitor-prometheus-pushgateway-db8b97744-7frml requesting resource cpu=0m on Node alex-400-cp1718-vsp2-worker00f2b167f8
May 25 01:11:53.758: INFO: Pod ccp-monitor-prometheus-server-5cb4549d87-98vp8 requesting resource cpu=0m on Node alex-400-cp1718-vsp2-workere35c6c6a2b
May 25 01:11:53.758: INFO: Pod cert-manager-5f9c44cd46-xttzw requesting resource cpu=0m on Node alex-400-cp1718-vsp2-workere35c6c6a2b
May 25 01:11:53.758: INFO: Pod elasticsearch-logging-0 requesting resource cpu=100m on Node alex-400-cp1718-vsp2-workere35c6c6a2b
May 25 01:11:53.758: INFO: Pod fluentd-es-v2.0.2-6mb7h requesting resource cpu=100m on Node alex-400-cp1718-vsp2-workere35c6c6a2b
May 25 01:11:53.758: INFO: Pod fluentd-es-v2.0.2-qtlkg requesting resource cpu=100m on Node alex-400-cp1718-vsp2-worker00f2b167f8
May 25 01:11:53.758: INFO: Pod kubernetes-dashboard-548b88c5d8-44vhs requesting resource cpu=100m on Node alex-400-cp1718-vsp2-workere35c6c6a2b
May 25 01:11:53.758: INFO: Pod metallb-controller-78744dd4f-df8gm requesting resource cpu=0m on Node alex-400-cp1718-vsp2-worker00f2b167f8
May 25 01:11:53.758: INFO: Pod metallb-speaker-rbdjd requesting resource cpu=0m on Node alex-400-cp1718-vsp2-workere35c6c6a2b
May 25 01:11:53.758: INFO: Pod metallb-speaker-s252f requesting resource cpu=0m on Node alex-400-cp1718-vsp2-worker00f2b167f8
May 25 01:11:53.758: INFO: Pod nginx-ingress-controller-772hp requesting resource cpu=0m on Node alex-400-cp1718-vsp2-workere35c6c6a2b
May 25 01:11:53.758: INFO: Pod nginx-ingress-controller-tkn4x requesting resource cpu=0m on Node alex-400-cp1718-vsp2-worker00f2b167f8
May 25 01:11:53.758: INFO: Pod nginx-ingress-default-backend-7b7b5b4985-zth7k requesting resource cpu=0m on Node alex-400-cp1718-vsp2-worker00f2b167f8
May 25 01:11:53.758: INFO: Pod sonobuoy requesting resource cpu=0m on Node alex-400-cp1718-vsp2-worker00f2b167f8
May 25 01:11:53.758: INFO: Pod sonobuoy-systemd-logs-daemon-set-759a616327fd41b7-9bvtk requesting resource cpu=0m on Node alex-400-cp1718-vsp2-workere35c6c6a2b
May 25 01:11:53.758: INFO: Pod sonobuoy-systemd-logs-daemon-set-759a616327fd41b7-kvqs6 requesting resource cpu=0m on Node alex-400-cp1718-vsp2-worker00f2b167f8
May 25 01:11:53.758: INFO: Pod calico-node-8jh64 requesting resource cpu=250m on Node alex-400-cp1718-vsp2-workere35c6c6a2b
May 25 01:11:53.758: INFO: Pod calico-node-ln8pj requesting resource cpu=250m on Node alex-400-cp1718-vsp2-worker00f2b167f8
May 25 01:11:53.758: INFO: Pod calico-typha-59fdcbc755-6jn4r requesting resource cpu=0m on Node alex-400-cp1718-vsp2-worker00f2b167f8
May 25 01:11:53.758: INFO: Pod calico-typha-59fdcbc755-z6pj6 requesting resource cpu=0m on Node alex-400-cp1718-vsp2-workere35c6c6a2b
May 25 01:11:53.758: INFO: Pod coredns-5d768868f-ghkvd requesting resource cpu=100m on Node alex-400-cp1718-vsp2-workere35c6c6a2b
May 25 01:11:53.758: INFO: Pod coredns-5d768868f-x48tv requesting resource cpu=100m on Node alex-400-cp1718-vsp2-worker00f2b167f8
May 25 01:11:53.758: INFO: Pod kube-proxy-gw2wq requesting resource cpu=0m on Node alex-400-cp1718-vsp2-worker00f2b167f8
May 25 01:11:53.758: INFO: Pod kube-proxy-xslv4 requesting resource cpu=0m on Node alex-400-cp1718-vsp2-workere35c6c6a2b
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-153046d5-7e8a-11e9-802f-027f94874578.15a1c7e0a91f6072], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-t8qlf/filler-pod-153046d5-7e8a-11e9-802f-027f94874578 to alex-400-cp1718-vsp2-worker00f2b167f8]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-153046d5-7e8a-11e9-802f-027f94874578.15a1c7e0feabfa4b], Reason = [Pulling], Message = [pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-153046d5-7e8a-11e9-802f-027f94874578.15a1c7e126add44e], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-153046d5-7e8a-11e9-802f-027f94874578.15a1c7e12a9f1230], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-153046d5-7e8a-11e9-802f-027f94874578.15a1c7e12f8c8203], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1531a0ee-7e8a-11e9-802f-027f94874578.15a1c7e0aa3b948e], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-t8qlf/filler-pod-1531a0ee-7e8a-11e9-802f-027f94874578 to alex-400-cp1718-vsp2-workere35c6c6a2b]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1531a0ee-7e8a-11e9-802f-027f94874578.15a1c7e1049c56e7], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1531a0ee-7e8a-11e9-802f-027f94874578.15a1c7e10907ad7a], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1531a0ee-7e8a-11e9-802f-027f94874578.15a1c7e10d1786f9], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15a1c7e19a5527a6], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 2 Insufficient cpu.]
STEP: removing the label node off the node alex-400-cp1718-vsp2-worker00f2b167f8
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node alex-400-cp1718-vsp2-workere35c6c6a2b
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:11:58.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-t8qlf" for this suite.
May 25 01:12:04.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:12:04.973: INFO: namespace: e2e-tests-sched-pred-t8qlf, resource: bindings, ignored listing per whitelist
May 25 01:12:04.993: INFO: namespace e2e-tests-sched-pred-t8qlf deletion completed in 6.106801101s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:11.469 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:12:04.993: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-wzrnh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 25 01:12:05.166: INFO: (0) /api/v1/nodes/alex-400-cp1718-vsp2-worker00f2b167f8/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 4.139335ms)
May 25 01:12:05.169: INFO: (1) /api/v1/nodes/alex-400-cp1718-vsp2-worker00f2b167f8/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 3.070612ms)
May 25 01:12:05.171: INFO: (2) /api/v1/nodes/alex-400-cp1718-vsp2-worker00f2b167f8/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 2.557603ms)
May 25 01:12:05.174: INFO: (3) /api/v1/nodes/alex-400-cp1718-vsp2-worker00f2b167f8/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 2.320187ms)
May 25 01:12:05.176: INFO: (4) /api/v1/nodes/alex-400-cp1718-vsp2-worker00f2b167f8/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 2.264887ms)
May 25 01:12:05.179: INFO: (5) /api/v1/nodes/alex-400-cp1718-vsp2-worker00f2b167f8/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 3.000734ms)
May 25 01:12:05.182: INFO: (6) /api/v1/nodes/alex-400-cp1718-vsp2-worker00f2b167f8/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 2.940747ms)
May 25 01:12:05.186: INFO: (7) /api/v1/nodes/alex-400-cp1718-vsp2-worker00f2b167f8/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 3.794693ms)
May 25 01:12:05.189: INFO: (8) /api/v1/nodes/alex-400-cp1718-vsp2-worker00f2b167f8/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 2.804592ms)
May 25 01:12:05.192: INFO: (9) /api/v1/nodes/alex-400-cp1718-vsp2-worker00f2b167f8/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 3.189379ms)
May 25 01:12:05.194: INFO: (10) /api/v1/nodes/alex-400-cp1718-vsp2-worker00f2b167f8/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 2.588387ms)
May 25 01:12:05.197: INFO: (11) /api/v1/nodes/alex-400-cp1718-vsp2-worker00f2b167f8/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 2.65755ms)
May 25 01:12:05.199: INFO: (12) /api/v1/nodes/alex-400-cp1718-vsp2-worker00f2b167f8/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 2.425057ms)
May 25 01:12:05.202: INFO: (13) /api/v1/nodes/alex-400-cp1718-vsp2-worker00f2b167f8/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 2.879721ms)
May 25 01:12:05.205: INFO: (14) /api/v1/nodes/alex-400-cp1718-vsp2-worker00f2b167f8/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 2.663263ms)
May 25 01:12:05.207: INFO: (15) /api/v1/nodes/alex-400-cp1718-vsp2-worker00f2b167f8/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 2.304464ms)
May 25 01:12:05.210: INFO: (16) /api/v1/nodes/alex-400-cp1718-vsp2-worker00f2b167f8/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 2.541345ms)
May 25 01:12:05.213: INFO: (17) /api/v1/nodes/alex-400-cp1718-vsp2-worker00f2b167f8/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 2.532943ms)
May 25 01:12:05.216: INFO: (18) /api/v1/nodes/alex-400-cp1718-vsp2-worker00f2b167f8/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 3.160134ms)
May 25 01:12:05.219: INFO: (19) /api/v1/nodes/alex-400-cp1718-vsp2-worker00f2b167f8/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 2.976343ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:12:05.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-wzrnh" for this suite.
May 25 01:12:11.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:12:11.294: INFO: namespace: e2e-tests-proxy-wzrnh, resource: bindings, ignored listing per whitelist
May 25 01:12:11.302: INFO: namespace e2e-tests-proxy-wzrnh deletion completed in 6.080424536s

• [SLOW TEST:6.309 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:12:11.303: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-2l7bs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 25 01:12:11.466: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1fbd1e69-7e8a-11e9-802f-027f94874578" in namespace "e2e-tests-downward-api-2l7bs" to be "success or failure"
May 25 01:12:11.473: INFO: Pod "downwardapi-volume-1fbd1e69-7e8a-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 7.768074ms
May 25 01:12:13.477: INFO: Pod "downwardapi-volume-1fbd1e69-7e8a-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011755589s
STEP: Saw pod success
May 25 01:12:13.477: INFO: Pod "downwardapi-volume-1fbd1e69-7e8a-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:12:13.479: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod downwardapi-volume-1fbd1e69-7e8a-11e9-802f-027f94874578 container client-container: <nil>
STEP: delete the pod
May 25 01:12:13.496: INFO: Waiting for pod downwardapi-volume-1fbd1e69-7e8a-11e9-802f-027f94874578 to disappear
May 25 01:12:13.504: INFO: Pod downwardapi-volume-1fbd1e69-7e8a-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:12:13.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2l7bs" for this suite.
May 25 01:12:19.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:12:19.562: INFO: namespace: e2e-tests-downward-api-2l7bs, resource: bindings, ignored listing per whitelist
May 25 01:12:19.592: INFO: namespace e2e-tests-downward-api-2l7bs deletion completed in 6.085147954s

• [SLOW TEST:8.290 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:12:19.593: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-6fhmt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
May 25 01:12:19.755: INFO: Waiting up to 5m0s for pod "pod-24ae0c65-7e8a-11e9-802f-027f94874578" in namespace "e2e-tests-emptydir-6fhmt" to be "success or failure"
May 25 01:12:19.758: INFO: Pod "pod-24ae0c65-7e8a-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 3.053289ms
May 25 01:12:21.761: INFO: Pod "pod-24ae0c65-7e8a-11e9-802f-027f94874578": Phase="Running", Reason="", readiness=true. Elapsed: 2.00577932s
May 25 01:12:23.763: INFO: Pod "pod-24ae0c65-7e8a-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008345253s
STEP: Saw pod success
May 25 01:12:23.763: INFO: Pod "pod-24ae0c65-7e8a-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:12:23.765: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-24ae0c65-7e8a-11e9-802f-027f94874578 container test-container: <nil>
STEP: delete the pod
May 25 01:12:23.782: INFO: Waiting for pod pod-24ae0c65-7e8a-11e9-802f-027f94874578 to disappear
May 25 01:12:23.783: INFO: Pod pod-24ae0c65-7e8a-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:12:23.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-6fhmt" for this suite.
May 25 01:12:29.796: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:12:29.844: INFO: namespace: e2e-tests-emptydir-6fhmt, resource: bindings, ignored listing per whitelist
May 25 01:12:29.978: INFO: namespace e2e-tests-emptydir-6fhmt deletion completed in 6.190879038s

• [SLOW TEST:10.386 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:12:29.980: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-rvn86
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-rvn86
May 25 01:12:34.157: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-rvn86
STEP: checking the pod's current state and verifying that restartCount is present
May 25 01:12:34.160: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:16:34.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-rvn86" for this suite.
May 25 01:16:40.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:16:40.546: INFO: namespace: e2e-tests-container-probe-rvn86, resource: bindings, ignored listing per whitelist
May 25 01:16:40.612: INFO: namespace e2e-tests-container-probe-rvn86 deletion completed in 6.084629709s

• [SLOW TEST:250.632 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:16:40.614: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-lgk2k
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
May 25 01:16:40.769: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-162046071 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:16:40.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lgk2k" for this suite.
May 25 01:16:46.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:16:46.906: INFO: namespace: e2e-tests-kubectl-lgk2k, resource: bindings, ignored listing per whitelist
May 25 01:16:46.938: INFO: namespace e2e-tests-kubectl-lgk2k deletion completed in 6.090443868s

• [SLOW TEST:6.324 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:16:46.941: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-wr5hn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
May 25 01:16:47.145: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:16:50.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-wr5hn" for this suite.
May 25 01:16:56.300: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:16:56.370: INFO: namespace: e2e-tests-init-container-wr5hn, resource: bindings, ignored listing per whitelist
May 25 01:16:56.383: INFO: namespace e2e-tests-init-container-wr5hn deletion completed in 6.090346187s

• [SLOW TEST:9.442 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:16:56.383: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-lc5rr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:17:56.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-lc5rr" for this suite.
May 25 01:18:18.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:18:18.620: INFO: namespace: e2e-tests-container-probe-lc5rr, resource: bindings, ignored listing per whitelist
May 25 01:18:18.643: INFO: namespace e2e-tests-container-probe-lc5rr deletion completed in 22.088697482s

• [SLOW TEST:82.260 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:18:18.645: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-fbcgj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 25 01:18:18.821: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fab31a56-7e8a-11e9-802f-027f94874578" in namespace "e2e-tests-downward-api-fbcgj" to be "success or failure"
May 25 01:18:18.825: INFO: Pod "downwardapi-volume-fab31a56-7e8a-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 4.004259ms
May 25 01:18:20.829: INFO: Pod "downwardapi-volume-fab31a56-7e8a-11e9-802f-027f94874578": Phase="Running", Reason="", readiness=true. Elapsed: 2.007244429s
May 25 01:18:22.832: INFO: Pod "downwardapi-volume-fab31a56-7e8a-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010098274s
STEP: Saw pod success
May 25 01:18:22.832: INFO: Pod "downwardapi-volume-fab31a56-7e8a-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:18:22.834: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod downwardapi-volume-fab31a56-7e8a-11e9-802f-027f94874578 container client-container: <nil>
STEP: delete the pod
May 25 01:18:22.852: INFO: Waiting for pod downwardapi-volume-fab31a56-7e8a-11e9-802f-027f94874578 to disappear
May 25 01:18:22.854: INFO: Pod downwardapi-volume-fab31a56-7e8a-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:18:22.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-fbcgj" for this suite.
May 25 01:18:28.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:18:28.881: INFO: namespace: e2e-tests-downward-api-fbcgj, resource: bindings, ignored listing per whitelist
May 25 01:18:28.948: INFO: namespace e2e-tests-downward-api-fbcgj deletion completed in 6.091186365s

• [SLOW TEST:10.304 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:18:28.950: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-6ms7n
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
May 25 01:18:33.153: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 25 01:18:33.156: INFO: Pod pod-with-prestop-exec-hook still exists
May 25 01:18:35.156: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 25 01:18:35.159: INFO: Pod pod-with-prestop-exec-hook still exists
May 25 01:18:37.156: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 25 01:18:37.159: INFO: Pod pod-with-prestop-exec-hook still exists
May 25 01:18:39.156: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 25 01:18:39.159: INFO: Pod pod-with-prestop-exec-hook still exists
May 25 01:18:41.156: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 25 01:18:41.160: INFO: Pod pod-with-prestop-exec-hook still exists
May 25 01:18:43.156: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 25 01:18:43.159: INFO: Pod pod-with-prestop-exec-hook still exists
May 25 01:18:45.156: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 25 01:18:45.159: INFO: Pod pod-with-prestop-exec-hook still exists
May 25 01:18:47.156: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 25 01:18:47.159: INFO: Pod pod-with-prestop-exec-hook still exists
May 25 01:18:49.156: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 25 01:18:49.159: INFO: Pod pod-with-prestop-exec-hook still exists
May 25 01:18:51.156: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 25 01:18:51.159: INFO: Pod pod-with-prestop-exec-hook still exists
May 25 01:18:53.156: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 25 01:18:53.159: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:18:53.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-6ms7n" for this suite.
May 25 01:19:15.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:19:15.196: INFO: namespace: e2e-tests-container-lifecycle-hook-6ms7n, resource: bindings, ignored listing per whitelist
May 25 01:19:15.250: INFO: namespace e2e-tests-container-lifecycle-hook-6ms7n deletion completed in 22.081447461s

• [SLOW TEST:46.301 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:19:15.251: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-tfdzp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
May 25 01:19:15.409: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-162046071 proxy --unix-socket=/tmp/kubectl-proxy-unix509079402/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:19:15.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tfdzp" for this suite.
May 25 01:19:21.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:19:21.511: INFO: namespace: e2e-tests-kubectl-tfdzp, resource: bindings, ignored listing per whitelist
May 25 01:19:21.572: INFO: namespace e2e-tests-kubectl-tfdzp deletion completed in 6.089254773s

• [SLOW TEST:6.321 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:19:21.573: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-xql8n
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-xql8n/configmap-test-203476ea-7e8b-11e9-802f-027f94874578
STEP: Creating a pod to test consume configMaps
May 25 01:19:21.747: INFO: Waiting up to 5m0s for pod "pod-configmaps-20350387-7e8b-11e9-802f-027f94874578" in namespace "e2e-tests-configmap-xql8n" to be "success or failure"
May 25 01:19:21.751: INFO: Pod "pod-configmaps-20350387-7e8b-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 4.061333ms
May 25 01:19:23.754: INFO: Pod "pod-configmaps-20350387-7e8b-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006733755s
STEP: Saw pod success
May 25 01:19:23.754: INFO: Pod "pod-configmaps-20350387-7e8b-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:19:23.756: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-configmaps-20350387-7e8b-11e9-802f-027f94874578 container env-test: <nil>
STEP: delete the pod
May 25 01:19:23.775: INFO: Waiting for pod pod-configmaps-20350387-7e8b-11e9-802f-027f94874578 to disappear
May 25 01:19:23.777: INFO: Pod pod-configmaps-20350387-7e8b-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:19:23.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-xql8n" for this suite.
May 25 01:19:29.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:19:29.833: INFO: namespace: e2e-tests-configmap-xql8n, resource: bindings, ignored listing per whitelist
May 25 01:19:29.874: INFO: namespace e2e-tests-configmap-xql8n deletion completed in 6.093079995s

• [SLOW TEST:8.300 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:19:29.874: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-z5rfb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 25 01:19:54.054: INFO: Container started at 2019-05-25 01:19:31 +0000 UTC, pod became ready at 2019-05-25 01:19:53 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:19:54.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-z5rfb" for this suite.
May 25 01:20:16.078: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:20:16.136: INFO: namespace: e2e-tests-container-probe-z5rfb, resource: bindings, ignored listing per whitelist
May 25 01:20:16.151: INFO: namespace e2e-tests-container-probe-z5rfb deletion completed in 22.092105642s

• [SLOW TEST:46.277 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:20:16.152: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-5cncb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
May 25 01:20:16.320: INFO: Waiting up to 5m0s for pod "pod-40bac49a-7e8b-11e9-802f-027f94874578" in namespace "e2e-tests-emptydir-5cncb" to be "success or failure"
May 25 01:20:16.326: INFO: Pod "pod-40bac49a-7e8b-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 6.173907ms
May 25 01:20:18.328: INFO: Pod "pod-40bac49a-7e8b-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008792675s
STEP: Saw pod success
May 25 01:20:18.329: INFO: Pod "pod-40bac49a-7e8b-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:20:18.331: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-40bac49a-7e8b-11e9-802f-027f94874578 container test-container: <nil>
STEP: delete the pod
May 25 01:20:18.359: INFO: Waiting for pod pod-40bac49a-7e8b-11e9-802f-027f94874578 to disappear
May 25 01:20:18.363: INFO: Pod pod-40bac49a-7e8b-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:20:18.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5cncb" for this suite.
May 25 01:20:24.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:20:24.443: INFO: namespace: e2e-tests-emptydir-5cncb, resource: bindings, ignored listing per whitelist
May 25 01:20:24.474: INFO: namespace e2e-tests-emptydir-5cncb deletion completed in 6.103396612s

• [SLOW TEST:8.321 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:20:24.475: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-f78lc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-f78lc.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-f78lc.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-f78lc.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-f78lc.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-f78lc.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-f78lc.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 25 01:20:34.701: INFO: DNS probes using e2e-tests-dns-f78lc/dns-test-45b2861b-7e8b-11e9-802f-027f94874578 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:20:34.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-f78lc" for this suite.
May 25 01:20:40.728: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:20:40.795: INFO: namespace: e2e-tests-dns-f78lc, resource: bindings, ignored listing per whitelist
May 25 01:20:40.805: INFO: namespace e2e-tests-dns-f78lc deletion completed in 6.08337656s

• [SLOW TEST:16.330 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:20:40.806: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-wbn2d
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-wbn2d
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-wbn2d to expose endpoints map[]
May 25 01:20:40.988: INFO: Get endpoints failed (5.496671ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
May 25 01:20:41.990: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-wbn2d exposes endpoints map[] (1.007491638s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-wbn2d
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-wbn2d to expose endpoints map[pod1:[80]]
May 25 01:20:44.016: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-wbn2d exposes endpoints map[pod1:[80]] (2.022009997s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-wbn2d
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-wbn2d to expose endpoints map[pod1:[80] pod2:[80]]
May 25 01:20:46.046: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-wbn2d exposes endpoints map[pod1:[80] pod2:[80]] (2.025003753s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-wbn2d
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-wbn2d to expose endpoints map[pod2:[80]]
May 25 01:20:46.061: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-wbn2d exposes endpoints map[pod2:[80]] (8.041678ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-wbn2d
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-wbn2d to expose endpoints map[]
May 25 01:20:47.073: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-wbn2d exposes endpoints map[] (1.006139846s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:20:47.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-wbn2d" for this suite.
May 25 01:21:09.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:21:09.158: INFO: namespace: e2e-tests-services-wbn2d, resource: bindings, ignored listing per whitelist
May 25 01:21:09.198: INFO: namespace e2e-tests-services-wbn2d deletion completed in 22.097855614s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:28.393 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:21:09.200: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-4hrhh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 25 01:21:09.390: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"605d2034-7e8b-11e9-ba33-0050569e7ba0", Controller:(*bool)(0xc00227099e), BlockOwnerDeletion:(*bool)(0xc00227099f)}}
May 25 01:21:09.399: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"605b3d42-7e8b-11e9-ba33-0050569e7ba0", Controller:(*bool)(0xc001e64c66), BlockOwnerDeletion:(*bool)(0xc001e64c67)}}
May 25 01:21:09.405: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"605bf234-7e8b-11e9-ba33-0050569e7ba0", Controller:(*bool)(0xc002270b86), BlockOwnerDeletion:(*bool)(0xc002270b87)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:21:14.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-4hrhh" for this suite.
May 25 01:21:20.431: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:21:20.457: INFO: namespace: e2e-tests-gc-4hrhh, resource: bindings, ignored listing per whitelist
May 25 01:21:20.518: INFO: namespace e2e-tests-gc-4hrhh deletion completed in 6.096050279s

• [SLOW TEST:11.318 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:21:20.519: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-wt66k
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-671a6aa7-7e8b-11e9-802f-027f94874578
STEP: Creating a pod to test consume secrets
May 25 01:21:20.696: INFO: Waiting up to 5m0s for pod "pod-secrets-671b0181-7e8b-11e9-802f-027f94874578" in namespace "e2e-tests-secrets-wt66k" to be "success or failure"
May 25 01:21:20.705: INFO: Pod "pod-secrets-671b0181-7e8b-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 8.966299ms
May 25 01:21:22.708: INFO: Pod "pod-secrets-671b0181-7e8b-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011563491s
STEP: Saw pod success
May 25 01:21:22.708: INFO: Pod "pod-secrets-671b0181-7e8b-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:21:22.710: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-secrets-671b0181-7e8b-11e9-802f-027f94874578 container secret-env-test: <nil>
STEP: delete the pod
May 25 01:21:22.728: INFO: Waiting for pod pod-secrets-671b0181-7e8b-11e9-802f-027f94874578 to disappear
May 25 01:21:22.732: INFO: Pod pod-secrets-671b0181-7e8b-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:21:22.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-wt66k" for this suite.
May 25 01:21:28.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:21:28.774: INFO: namespace: e2e-tests-secrets-wt66k, resource: bindings, ignored listing per whitelist
May 25 01:21:28.835: INFO: namespace e2e-tests-secrets-wt66k deletion completed in 6.099760276s

• [SLOW TEST:8.316 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:21:28.836: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-zllvw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-zllvw
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
May 25 01:21:29.019: INFO: Found 0 stateful pods, waiting for 3
May 25 01:21:39.023: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 25 01:21:39.023: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 25 01:21:39.023: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
May 25 01:21:39.046: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
May 25 01:21:49.076: INFO: Updating stateful set ss2
May 25 01:21:49.082: INFO: Waiting for Pod e2e-tests-statefulset-zllvw/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
May 25 01:21:59.163: INFO: Found 2 stateful pods, waiting for 3
May 25 01:22:09.167: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 25 01:22:09.167: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 25 01:22:09.167: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
May 25 01:22:09.190: INFO: Updating stateful set ss2
May 25 01:22:09.195: INFO: Waiting for Pod e2e-tests-statefulset-zllvw/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
May 25 01:22:19.218: INFO: Updating stateful set ss2
May 25 01:22:19.224: INFO: Waiting for StatefulSet e2e-tests-statefulset-zllvw/ss2 to complete update
May 25 01:22:19.224: INFO: Waiting for Pod e2e-tests-statefulset-zllvw/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
May 25 01:22:29.230: INFO: Waiting for StatefulSet e2e-tests-statefulset-zllvw/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 25 01:22:39.230: INFO: Deleting all statefulset in ns e2e-tests-statefulset-zllvw
May 25 01:22:39.232: INFO: Scaling statefulset ss2 to 0
May 25 01:22:49.244: INFO: Waiting for statefulset status.replicas updated to 0
May 25 01:22:49.246: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:22:49.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-zllvw" for this suite.
May 25 01:22:55.274: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:22:55.360: INFO: namespace: e2e-tests-statefulset-zllvw, resource: bindings, ignored listing per whitelist
May 25 01:22:55.360: INFO: namespace e2e-tests-statefulset-zllvw deletion completed in 6.096573013s

• [SLOW TEST:86.525 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:22:55.361: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-48pbp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-9fa30188-7e8b-11e9-802f-027f94874578
STEP: Creating a pod to test consume secrets
May 25 01:22:55.541: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9fa39903-7e8b-11e9-802f-027f94874578" in namespace "e2e-tests-projected-48pbp" to be "success or failure"
May 25 01:22:55.544: INFO: Pod "pod-projected-secrets-9fa39903-7e8b-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 2.51945ms
May 25 01:22:57.547: INFO: Pod "pod-projected-secrets-9fa39903-7e8b-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005589073s
STEP: Saw pod success
May 25 01:22:57.547: INFO: Pod "pod-projected-secrets-9fa39903-7e8b-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:22:57.549: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-projected-secrets-9fa39903-7e8b-11e9-802f-027f94874578 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 25 01:22:57.568: INFO: Waiting for pod pod-projected-secrets-9fa39903-7e8b-11e9-802f-027f94874578 to disappear
May 25 01:22:57.573: INFO: Pod pod-projected-secrets-9fa39903-7e8b-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:22:57.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-48pbp" for this suite.
May 25 01:23:03.585: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:23:03.603: INFO: namespace: e2e-tests-projected-48pbp, resource: bindings, ignored listing per whitelist
May 25 01:23:03.678: INFO: namespace e2e-tests-projected-48pbp deletion completed in 6.102543074s

• [SLOW TEST:8.318 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:23:03.681: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-wmtnf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 25 01:23:03.849: INFO: Pod name rollover-pod: Found 0 pods out of 1
May 25 01:23:08.852: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May 25 01:23:08.852: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
May 25 01:23:10.855: INFO: Creating deployment "test-rollover-deployment"
May 25 01:23:10.864: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
May 25 01:23:12.875: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
May 25 01:23:12.881: INFO: Ensure that both replica sets have 1 created replica
May 25 01:23:12.884: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
May 25 01:23:12.890: INFO: Updating deployment test-rollover-deployment
May 25 01:23:12.891: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
May 25 01:23:14.899: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
May 25 01:23:14.903: INFO: Make sure deployment "test-rollover-deployment" is complete
May 25 01:23:14.908: INFO: all replica sets need to contain the pod-template-hash label
May 25 01:23:14.908: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344190, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344190, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344193, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344190, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 25 01:23:16.913: INFO: all replica sets need to contain the pod-template-hash label
May 25 01:23:16.913: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344190, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344190, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344193, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344190, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 25 01:23:18.913: INFO: all replica sets need to contain the pod-template-hash label
May 25 01:23:18.913: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344190, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344190, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344193, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344190, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 25 01:23:20.918: INFO: all replica sets need to contain the pod-template-hash label
May 25 01:23:20.918: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344190, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344190, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344193, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344190, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 25 01:23:22.913: INFO: all replica sets need to contain the pod-template-hash label
May 25 01:23:22.913: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344190, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344190, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344193, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344190, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 25 01:23:24.912: INFO: all replica sets need to contain the pod-template-hash label
May 25 01:23:24.913: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344190, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344190, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344193, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344190, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 25 01:23:26.913: INFO: all replica sets need to contain the pod-template-hash label
May 25 01:23:26.913: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344190, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344190, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344193, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344190, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 25 01:23:28.912: INFO: all replica sets need to contain the pod-template-hash label
May 25 01:23:28.912: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344190, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344190, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344193, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344190, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 25 01:23:30.912: INFO: all replica sets need to contain the pod-template-hash label
May 25 01:23:30.913: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344190, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344190, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344193, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344190, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 25 01:23:32.913: INFO: all replica sets need to contain the pod-template-hash label
May 25 01:23:32.913: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344190, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344190, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344193, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344190, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 25 01:23:34.913: INFO: 
May 25 01:23:34.913: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 25 01:23:34.919: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-wmtnf,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-wmtnf/deployments/test-rollover-deployment,UID:a8c54b71-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:16411,Generation:2,CreationTimestamp:2019-05-25 01:23:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-05-25 01:23:10 +0000 UTC 2019-05-25 01:23:10 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-05-25 01:23:33 +0000 UTC 2019-05-25 01:23:10 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

May 25 01:23:34.921: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-wmtnf,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-wmtnf/replicasets/test-rollover-deployment-6b7f9d6597,UID:a9fbb24d-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:16402,Generation:2,CreationTimestamp:2019-05-25 01:23:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment a8c54b71-7e8b-11e9-ba33-0050569e7ba0 0xc001f61a77 0xc001f61a78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
May 25 01:23:34.921: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
May 25 01:23:34.921: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-wmtnf,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-wmtnf/replicasets/test-rollover-controller,UID:a4966628-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:16410,Generation:2,CreationTimestamp:2019-05-25 01:23:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment a8c54b71-7e8b-11e9-ba33-0050569e7ba0 0xc001f617a7 0xc001f617a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 25 01:23:34.922: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-wmtnf,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-wmtnf/replicasets/test-rollover-deployment-6586df867b,UID:a8c7d703-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:16350,Generation:2,CreationTimestamp:2019-05-25 01:23:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment a8c54b71-7e8b-11e9-ba33-0050569e7ba0 0xc001f61887 0xc001f61888}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 25 01:23:34.924: INFO: Pod "test-rollover-deployment-6b7f9d6597-txjb8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-txjb8,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-wmtnf,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wmtnf/pods/test-rollover-deployment-6b7f9d6597-txjb8,UID:aa007660-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:16368,Generation:0,CreationTimestamp:2019-05-25 01:23:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.65/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 a9fbb24d-7e8b-11e9-ba33-0050569e7ba0 0xc000e49dc7 0xc000e49dc8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cl4vm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cl4vm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-cl4vm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-400-cp1718-vsp2-workere35c6c6a2b,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e49e30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e49e50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:23:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:23:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:23:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:23:12 +0000 UTC  }],Message:,Reason:,HostIP:10.10.103.184,PodIP:192.168.1.65,StartTime:2019-05-25 01:23:13 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-05-25 01:23:14 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://774b0bff56183d6028205c6917f8d16370dee95ca716a3419fc86b499f76a90d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:23:34.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-wmtnf" for this suite.
May 25 01:23:40.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:23:40.947: INFO: namespace: e2e-tests-deployment-wmtnf, resource: bindings, ignored listing per whitelist
May 25 01:23:41.011: INFO: namespace e2e-tests-deployment-wmtnf deletion completed in 6.082027822s

• [SLOW TEST:37.330 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:23:41.012: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-spcpf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0525 01:23:51.237200      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 25 01:23:51.237: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:23:51.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-spcpf" for this suite.
May 25 01:23:57.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:23:57.305: INFO: namespace: e2e-tests-gc-spcpf, resource: bindings, ignored listing per whitelist
May 25 01:23:57.329: INFO: namespace e2e-tests-gc-spcpf deletion completed in 6.088256396s

• [SLOW TEST:16.317 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:23:57.330: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-zrnml
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 25 01:23:57.506: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c49234cc-7e8b-11e9-802f-027f94874578" in namespace "e2e-tests-projected-zrnml" to be "success or failure"
May 25 01:23:57.513: INFO: Pod "downwardapi-volume-c49234cc-7e8b-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 5.699721ms
May 25 01:23:59.516: INFO: Pod "downwardapi-volume-c49234cc-7e8b-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008603615s
STEP: Saw pod success
May 25 01:23:59.516: INFO: Pod "downwardapi-volume-c49234cc-7e8b-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:23:59.518: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod downwardapi-volume-c49234cc-7e8b-11e9-802f-027f94874578 container client-container: <nil>
STEP: delete the pod
May 25 01:23:59.539: INFO: Waiting for pod downwardapi-volume-c49234cc-7e8b-11e9-802f-027f94874578 to disappear
May 25 01:23:59.542: INFO: Pod downwardapi-volume-c49234cc-7e8b-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:23:59.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zrnml" for this suite.
May 25 01:24:05.552: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:24:05.577: INFO: namespace: e2e-tests-projected-zrnml, resource: bindings, ignored listing per whitelist
May 25 01:24:05.634: INFO: namespace e2e-tests-projected-zrnml deletion completed in 6.089196166s

• [SLOW TEST:8.304 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:24:05.635: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-6zd4p
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
May 25 01:24:05.801: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-6zd4p,SelfLink:/api/v1/namespaces/e2e-tests-watch-6zd4p/configmaps/e2e-watch-test-label-changed,UID:c98386a3-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:16767,Generation:0,CreationTimestamp:2019-05-25 01:24:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 25 01:24:05.801: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-6zd4p,SelfLink:/api/v1/namespaces/e2e-tests-watch-6zd4p/configmaps/e2e-watch-test-label-changed,UID:c98386a3-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:16768,Generation:0,CreationTimestamp:2019-05-25 01:24:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
May 25 01:24:05.801: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-6zd4p,SelfLink:/api/v1/namespaces/e2e-tests-watch-6zd4p/configmaps/e2e-watch-test-label-changed,UID:c98386a3-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:16769,Generation:0,CreationTimestamp:2019-05-25 01:24:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
May 25 01:24:15.822: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-6zd4p,SelfLink:/api/v1/namespaces/e2e-tests-watch-6zd4p/configmaps/e2e-watch-test-label-changed,UID:c98386a3-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:16787,Generation:0,CreationTimestamp:2019-05-25 01:24:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 25 01:24:15.822: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-6zd4p,SelfLink:/api/v1/namespaces/e2e-tests-watch-6zd4p/configmaps/e2e-watch-test-label-changed,UID:c98386a3-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:16788,Generation:0,CreationTimestamp:2019-05-25 01:24:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
May 25 01:24:15.822: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-6zd4p,SelfLink:/api/v1/namespaces/e2e-tests-watch-6zd4p/configmaps/e2e-watch-test-label-changed,UID:c98386a3-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:16789,Generation:0,CreationTimestamp:2019-05-25 01:24:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:24:15.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-6zd4p" for this suite.
May 25 01:24:21.833: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:24:21.916: INFO: namespace: e2e-tests-watch-6zd4p, resource: bindings, ignored listing per whitelist
May 25 01:24:21.941: INFO: namespace e2e-tests-watch-6zd4p deletion completed in 6.115340581s

• [SLOW TEST:16.306 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:24:21.941: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-p58cq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 25 01:24:22.097: INFO: Creating deployment "nginx-deployment"
May 25 01:24:22.107: INFO: Waiting for observed generation 1
May 25 01:24:24.123: INFO: Waiting for all required pods to come up
May 25 01:24:24.126: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
May 25 01:24:28.137: INFO: Waiting for deployment "nginx-deployment" to complete
May 25 01:24:28.141: INFO: Updating deployment "nginx-deployment" with a non-existent image
May 25 01:24:28.148: INFO: Updating deployment nginx-deployment
May 25 01:24:28.148: INFO: Waiting for observed generation 2
May 25 01:24:30.160: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
May 25 01:24:30.163: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
May 25 01:24:30.174: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
May 25 01:24:30.179: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
May 25 01:24:30.179: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
May 25 01:24:30.181: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
May 25 01:24:30.184: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
May 25 01:24:30.184: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
May 25 01:24:30.190: INFO: Updating deployment nginx-deployment
May 25 01:24:30.190: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
May 25 01:24:30.223: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
May 25 01:24:32.250: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 25 01:24:32.254: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-p58cq,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-p58cq/deployments/nginx-deployment,UID:d33c0550-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:17092,Generation:3,CreationTimestamp:2019-05-25 01:24:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-05-25 01:24:30 +0000 UTC 2019-05-25 01:24:30 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-05-25 01:24:30 +0000 UTC 2019-05-25 01:24:22 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

May 25 01:24:32.261: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-p58cq,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-p58cq/replicasets/nginx-deployment-65bbdb5f8,UID:d6d6f27e-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:17088,Generation:3,CreationTimestamp:2019-05-25 01:24:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment d33c0550-7e8b-11e9-ba33-0050569e7ba0 0xc00229af37 0xc00229af38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 25 01:24:32.261: INFO: All old ReplicaSets of Deployment "nginx-deployment":
May 25 01:24:32.261: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-p58cq,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-p58cq/replicasets/nginx-deployment-555b55d965,UID:d33e31a7-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:17080,Generation:3,CreationTimestamp:2019-05-25 01:24:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment d33c0550-7e8b-11e9-ba33-0050569e7ba0 0xc00229ae77 0xc00229ae78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
May 25 01:24:32.268: INFO: Pod "nginx-deployment-555b55d965-29j4k" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-29j4k,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-p58cq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p58cq/pods/nginx-deployment-555b55d965-29j4k,UID:d818a541-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:17073,Generation:0,CreationTimestamp:2019-05-25 01:24:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d33e31a7-7e8b-11e9-ba33-0050569e7ba0 0xc00229b887 0xc00229b888}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-msgcg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msgcg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-msgcg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-400-cp1718-vsp2-worker00f2b167f8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00229b8f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00229b910}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 25 01:24:32.271: INFO: Pod "nginx-deployment-555b55d965-2wd5t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-2wd5t,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-p58cq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p58cq/pods/nginx-deployment-555b55d965-2wd5t,UID:d818be5f-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:17074,Generation:0,CreationTimestamp:2019-05-25 01:24:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d33e31a7-7e8b-11e9-ba33-0050569e7ba0 0xc00229b980 0xc00229b981}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-msgcg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msgcg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-msgcg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-400-cp1718-vsp2-worker00f2b167f8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00229b9e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00229ba00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 25 01:24:32.278: INFO: Pod "nginx-deployment-555b55d965-5sbq7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-5sbq7,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-p58cq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p58cq/pods/nginx-deployment-555b55d965-5sbq7,UID:d818bcd1-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:17063,Generation:0,CreationTimestamp:2019-05-25 01:24:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d33e31a7-7e8b-11e9-ba33-0050569e7ba0 0xc00229ba70 0xc00229ba71}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-msgcg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msgcg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-msgcg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-400-cp1718-vsp2-workere35c6c6a2b,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00229bad0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00229baf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 25 01:24:32.278: INFO: Pod "nginx-deployment-555b55d965-6gfgq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-6gfgq,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-p58cq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p58cq/pods/nginx-deployment-555b55d965-6gfgq,UID:d34545ce-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:16939,Generation:0,CreationTimestamp:2019-05-25 01:24:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.2.38/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d33e31a7-7e8b-11e9-ba33-0050569e7ba0 0xc00229bb70 0xc00229bb71}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-msgcg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msgcg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-msgcg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-400-cp1718-vsp2-worker00f2b167f8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00229bbd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00229bbf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:25 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:25 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:22 +0000 UTC  }],Message:,Reason:,HostIP:10.10.103.183,PodIP:192.168.2.38,StartTime:2019-05-25 01:24:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-25 01:24:24 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://30d15214e3dced78f2eb3e7ef8cbd2602902068c9806e0ff1aa997f2b2e830ce}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 25 01:24:32.278: INFO: Pod "nginx-deployment-555b55d965-8prdt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-8prdt,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-p58cq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p58cq/pods/nginx-deployment-555b55d965-8prdt,UID:d818cb72-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:17147,Generation:0,CreationTimestamp:2019-05-25 01:24:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.81/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d33e31a7-7e8b-11e9-ba33-0050569e7ba0 0xc00229bcc7 0xc00229bcc8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-msgcg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msgcg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-msgcg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-400-cp1718-vsp2-workere35c6c6a2b,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00229bd30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00229bd50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 25 01:24:32.280: INFO: Pod "nginx-deployment-555b55d965-bptj2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-bptj2,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-p58cq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p58cq/pods/nginx-deployment-555b55d965-bptj2,UID:d818d885-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:17071,Generation:0,CreationTimestamp:2019-05-25 01:24:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d33e31a7-7e8b-11e9-ba33-0050569e7ba0 0xc00229bdc0 0xc00229bdc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-msgcg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msgcg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-msgcg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-400-cp1718-vsp2-workere35c6c6a2b,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00229be20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00229be40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 25 01:24:32.280: INFO: Pod "nginx-deployment-555b55d965-fqrr2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-fqrr2,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-p58cq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p58cq/pods/nginx-deployment-555b55d965-fqrr2,UID:d814579a-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:17065,Generation:0,CreationTimestamp:2019-05-25 01:24:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d33e31a7-7e8b-11e9-ba33-0050569e7ba0 0xc00229beb0 0xc00229beb1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-msgcg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msgcg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-msgcg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-400-cp1718-vsp2-worker00f2b167f8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00229bf10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00229bf30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 25 01:24:32.281: INFO: Pod "nginx-deployment-555b55d965-hblv5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-hblv5,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-p58cq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p58cq/pods/nginx-deployment-555b55d965-hblv5,UID:d344f4f1-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:16912,Generation:0,CreationTimestamp:2019-05-25 01:24:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.73/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d33e31a7-7e8b-11e9-ba33-0050569e7ba0 0xc00229bfb0 0xc00229bfb1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-msgcg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msgcg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-msgcg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-400-cp1718-vsp2-workere35c6c6a2b,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002938010} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002938030}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:22 +0000 UTC  }],Message:,Reason:,HostIP:10.10.103.184,PodIP:192.168.1.73,StartTime:2019-05-25 01:24:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-25 01:24:23 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://46bb25fbb581247829be03c47a7aff7f244f91aeb1eb692ed7a3cc69d9aeb377}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 25 01:24:32.281: INFO: Pod "nginx-deployment-555b55d965-hlc5n" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-hlc5n,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-p58cq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p58cq/pods/nginx-deployment-555b55d965-hlc5n,UID:d345295e-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:16925,Generation:0,CreationTimestamp:2019-05-25 01:24:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.2.36/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d33e31a7-7e8b-11e9-ba33-0050569e7ba0 0xc002938107 0xc002938108}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-msgcg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msgcg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-msgcg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-400-cp1718-vsp2-worker00f2b167f8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002938170} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002938190}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:22 +0000 UTC  }],Message:,Reason:,HostIP:10.10.103.183,PodIP:192.168.2.36,StartTime:2019-05-25 01:24:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-25 01:24:23 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://1f111c679e39f455f136a9fb47d9d51efde849e27fe77258df5bdc129b5b7f29}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 25 01:24:32.281: INFO: Pod "nginx-deployment-555b55d965-kstjh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-kstjh,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-p58cq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p58cq/pods/nginx-deployment-555b55d965-kstjh,UID:d814467f-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:17140,Generation:0,CreationTimestamp:2019-05-25 01:24:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d33e31a7-7e8b-11e9-ba33-0050569e7ba0 0xc002938257 0xc002938258}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-msgcg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msgcg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-msgcg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-400-cp1718-vsp2-workere35c6c6a2b,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029382c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029382e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC  }],Message:,Reason:,HostIP:10.10.103.184,PodIP:,StartTime:2019-05-25 01:24:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 25 01:24:32.281: INFO: Pod "nginx-deployment-555b55d965-l2wn4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-l2wn4,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-p58cq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p58cq/pods/nginx-deployment-555b55d965-l2wn4,UID:d8107c6c-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:17064,Generation:0,CreationTimestamp:2019-05-25 01:24:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d33e31a7-7e8b-11e9-ba33-0050569e7ba0 0xc002938397 0xc002938398}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-msgcg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msgcg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-msgcg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-400-cp1718-vsp2-workere35c6c6a2b,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002938400} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002938420}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC  }],Message:,Reason:,HostIP:10.10.103.184,PodIP:,StartTime:2019-05-25 01:24:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 25 01:24:32.282: INFO: Pod "nginx-deployment-555b55d965-l44wv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-l44wv,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-p58cq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p58cq/pods/nginx-deployment-555b55d965-l44wv,UID:d3417bac-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:16905,Generation:0,CreationTimestamp:2019-05-25 01:24:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.72/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d33e31a7-7e8b-11e9-ba33-0050569e7ba0 0xc0029384e7 0xc0029384e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-msgcg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msgcg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-msgcg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-400-cp1718-vsp2-workere35c6c6a2b,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002938550} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002938570}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:22 +0000 UTC  }],Message:,Reason:,HostIP:10.10.103.184,PodIP:192.168.1.72,StartTime:2019-05-25 01:24:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-25 01:24:23 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://20428f928782ce6f175d2c2ffae5906e37609c772439212db5710efd56643610}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 25 01:24:32.292: INFO: Pod "nginx-deployment-555b55d965-l66bs" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-l66bs,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-p58cq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p58cq/pods/nginx-deployment-555b55d965-l66bs,UID:d3453d63-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:16929,Generation:0,CreationTimestamp:2019-05-25 01:24:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.75/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d33e31a7-7e8b-11e9-ba33-0050569e7ba0 0xc002938647 0xc002938648}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-msgcg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msgcg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-msgcg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-400-cp1718-vsp2-workere35c6c6a2b,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029386b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029386d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:22 +0000 UTC  }],Message:,Reason:,HostIP:10.10.103.184,PodIP:192.168.1.75,StartTime:2019-05-25 01:24:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-25 01:24:24 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://bc25df528acde007125926f0fe19e94f50fabb955bc16c51c28f7590204e6b4c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 25 01:24:32.292: INFO: Pod "nginx-deployment-555b55d965-lf6fr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-lf6fr,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-p58cq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p58cq/pods/nginx-deployment-555b55d965-lf6fr,UID:d8109406-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:17153,Generation:0,CreationTimestamp:2019-05-25 01:24:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.82/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d33e31a7-7e8b-11e9-ba33-0050569e7ba0 0xc0029387a7 0xc0029387a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-msgcg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msgcg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-msgcg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-400-cp1718-vsp2-workere35c6c6a2b,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002938810} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002938830}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC  }],Message:,Reason:,HostIP:10.10.103.184,PodIP:,StartTime:2019-05-25 01:24:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 25 01:24:32.293: INFO: Pod "nginx-deployment-555b55d965-nf9c6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-nf9c6,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-p58cq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p58cq/pods/nginx-deployment-555b55d965-nf9c6,UID:d80f80b5-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:17126,Generation:0,CreationTimestamp:2019-05-25 01:24:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.2.42/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d33e31a7-7e8b-11e9-ba33-0050569e7ba0 0xc0029388f7 0xc0029388f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-msgcg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msgcg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-msgcg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-400-cp1718-vsp2-worker00f2b167f8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002938960} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002938980}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC  }],Message:,Reason:,HostIP:10.10.103.183,PodIP:,StartTime:2019-05-25 01:24:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 25 01:24:32.293: INFO: Pod "nginx-deployment-555b55d965-pmfvn" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-pmfvn,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-p58cq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p58cq/pods/nginx-deployment-555b55d965-pmfvn,UID:d3493ae0-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:16922,Generation:0,CreationTimestamp:2019-05-25 01:24:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.74/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d33e31a7-7e8b-11e9-ba33-0050569e7ba0 0xc002938a47 0xc002938a48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-msgcg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msgcg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-msgcg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-400-cp1718-vsp2-workere35c6c6a2b,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002938ab0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002938ad0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:22 +0000 UTC  }],Message:,Reason:,HostIP:10.10.103.184,PodIP:192.168.1.74,StartTime:2019-05-25 01:24:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-25 01:24:24 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://2d6147b89ae4ae7835d599a28678d324df5aeba8d6289f2c42ff00f1199b6b82}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 25 01:24:32.294: INFO: Pod "nginx-deployment-555b55d965-q6nk6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-q6nk6,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-p58cq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p58cq/pods/nginx-deployment-555b55d965-q6nk6,UID:d3492815-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:16903,Generation:0,CreationTimestamp:2019-05-25 01:24:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.2.35/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d33e31a7-7e8b-11e9-ba33-0050569e7ba0 0xc002938ba7 0xc002938ba8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-msgcg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msgcg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-msgcg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-400-cp1718-vsp2-worker00f2b167f8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002938c10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002938c30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:22 +0000 UTC  }],Message:,Reason:,HostIP:10.10.103.183,PodIP:192.168.2.35,StartTime:2019-05-25 01:24:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-25 01:24:23 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://36108f229ea10b7435427be86f19fd3ade05aadf4e49c556296b91e1a053f379}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 25 01:24:32.294: INFO: Pod "nginx-deployment-555b55d965-qqt52" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-qqt52,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-p58cq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p58cq/pods/nginx-deployment-555b55d965-qqt52,UID:d34933a9-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:16932,Generation:0,CreationTimestamp:2019-05-25 01:24:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.2.37/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d33e31a7-7e8b-11e9-ba33-0050569e7ba0 0xc002938d07 0xc002938d08}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-msgcg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msgcg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-msgcg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-400-cp1718-vsp2-worker00f2b167f8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002938d70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002938d90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:22 +0000 UTC  }],Message:,Reason:,HostIP:10.10.103.183,PodIP:192.168.2.37,StartTime:2019-05-25 01:24:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-25 01:24:24 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://92f37aaf9aa6443758a6783b0cf4113123ec08a4edb3fa25b4625387406e9916}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 25 01:24:32.295: INFO: Pod "nginx-deployment-555b55d965-w5tql" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-w5tql,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-p58cq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p58cq/pods/nginx-deployment-555b55d965-w5tql,UID:d8144593-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:17151,Generation:0,CreationTimestamp:2019-05-25 01:24:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.2.44/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d33e31a7-7e8b-11e9-ba33-0050569e7ba0 0xc002938e67 0xc002938e68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-msgcg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msgcg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-msgcg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-400-cp1718-vsp2-worker00f2b167f8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002938ed0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002938ef0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC  }],Message:,Reason:,HostIP:10.10.103.183,PodIP:,StartTime:2019-05-25 01:24:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 25 01:24:32.295: INFO: Pod "nginx-deployment-555b55d965-whb2f" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-whb2f,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-p58cq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p58cq/pods/nginx-deployment-555b55d965-whb2f,UID:d81467c1-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:17125,Generation:0,CreationTimestamp:2019-05-25 01:24:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d33e31a7-7e8b-11e9-ba33-0050569e7ba0 0xc002938fa7 0xc002938fa8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-msgcg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msgcg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-msgcg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-400-cp1718-vsp2-worker00f2b167f8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002939010} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002939030}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC  }],Message:,Reason:,HostIP:10.10.103.183,PodIP:,StartTime:2019-05-25 01:24:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 25 01:24:32.297: INFO: Pod "nginx-deployment-65bbdb5f8-bggtw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-bggtw,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-p58cq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p58cq/pods/nginx-deployment-65bbdb5f8-bggtw,UID:d6d92eab-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:17111,Generation:0,CreationTimestamp:2019-05-25 01:24:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.77/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 d6d6f27e-7e8b-11e9-ba33-0050569e7ba0 0xc0029390f7 0xc0029390f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-msgcg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msgcg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-msgcg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-400-cp1718-vsp2-workere35c6c6a2b,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002939160} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002939180}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:28 +0000 UTC  }],Message:,Reason:,HostIP:10.10.103.184,PodIP:192.168.1.77,StartTime:2019-05-25 01:24:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 25 01:24:32.298: INFO: Pod "nginx-deployment-65bbdb5f8-d6n45" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-d6n45,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-p58cq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p58cq/pods/nginx-deployment-65bbdb5f8-d6n45,UID:d818813b-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:17069,Generation:0,CreationTimestamp:2019-05-25 01:24:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 d6d6f27e-7e8b-11e9-ba33-0050569e7ba0 0xc002939260 0xc002939261}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-msgcg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msgcg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-msgcg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-400-cp1718-vsp2-workere35c6c6a2b,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029392d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029392f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 25 01:24:32.301: INFO: Pod "nginx-deployment-65bbdb5f8-gsqmr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-gsqmr,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-p58cq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p58cq/pods/nginx-deployment-65bbdb5f8-gsqmr,UID:d8184cfd-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:17067,Generation:0,CreationTimestamp:2019-05-25 01:24:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 d6d6f27e-7e8b-11e9-ba33-0050569e7ba0 0xc002939360 0xc002939361}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-msgcg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msgcg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-msgcg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-400-cp1718-vsp2-worker00f2b167f8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029393d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029393f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 25 01:24:32.302: INFO: Pod "nginx-deployment-65bbdb5f8-mhh46" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-mhh46,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-p58cq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p58cq/pods/nginx-deployment-65bbdb5f8-mhh46,UID:d81870d8-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:17068,Generation:0,CreationTimestamp:2019-05-25 01:24:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 d6d6f27e-7e8b-11e9-ba33-0050569e7ba0 0xc002939460 0xc002939461}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-msgcg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msgcg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-msgcg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-400-cp1718-vsp2-worker00f2b167f8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029394d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029394f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 25 01:24:32.327: INFO: Pod "nginx-deployment-65bbdb5f8-p4c22" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-p4c22,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-p58cq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p58cq/pods/nginx-deployment-65bbdb5f8-p4c22,UID:d81461bf-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:17066,Generation:0,CreationTimestamp:2019-05-25 01:24:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 d6d6f27e-7e8b-11e9-ba33-0050569e7ba0 0xc002939560 0xc002939561}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-msgcg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msgcg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-msgcg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-400-cp1718-vsp2-worker00f2b167f8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029395d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029395f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 25 01:24:32.330: INFO: Pod "nginx-deployment-65bbdb5f8-pjhbn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-pjhbn,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-p58cq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p58cq/pods/nginx-deployment-65bbdb5f8-pjhbn,UID:d813fd65-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:17137,Generation:0,CreationTimestamp:2019-05-25 01:24:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.80/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 d6d6f27e-7e8b-11e9-ba33-0050569e7ba0 0xc002939670 0xc002939671}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-msgcg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msgcg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-msgcg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-400-cp1718-vsp2-workere35c6c6a2b,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029396e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002939700}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC  }],Message:,Reason:,HostIP:10.10.103.184,PodIP:,StartTime:2019-05-25 01:24:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 25 01:24:32.330: INFO: Pod "nginx-deployment-65bbdb5f8-r82v6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-r82v6,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-p58cq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p58cq/pods/nginx-deployment-65bbdb5f8-r82v6,UID:d81871ed-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:17070,Generation:0,CreationTimestamp:2019-05-25 01:24:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 d6d6f27e-7e8b-11e9-ba33-0050569e7ba0 0xc0029397c0 0xc0029397c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-msgcg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msgcg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-msgcg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-400-cp1718-vsp2-workere35c6c6a2b,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002939830} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002939850}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 25 01:24:32.331: INFO: Pod "nginx-deployment-65bbdb5f8-rwm46" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-rwm46,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-p58cq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p58cq/pods/nginx-deployment-65bbdb5f8-rwm46,UID:d6e2dde4-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:17010,Generation:0,CreationTimestamp:2019-05-25 01:24:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.79/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 d6d6f27e-7e8b-11e9-ba33-0050569e7ba0 0xc0029398d0 0xc0029398d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-msgcg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msgcg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-msgcg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-400-cp1718-vsp2-workere35c6c6a2b,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002939940} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002939960}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:28 +0000 UTC  }],Message:,Reason:,HostIP:10.10.103.184,PodIP:,StartTime:2019-05-25 01:24:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 25 01:24:32.331: INFO: Pod "nginx-deployment-65bbdb5f8-sxd4g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-sxd4g,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-p58cq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p58cq/pods/nginx-deployment-65bbdb5f8-sxd4g,UID:d6e016e2-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:17014,Generation:0,CreationTimestamp:2019-05-25 01:24:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.2.41/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 d6d6f27e-7e8b-11e9-ba33-0050569e7ba0 0xc002939a30 0xc002939a31}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-msgcg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msgcg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-msgcg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-400-cp1718-vsp2-worker00f2b167f8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002939aa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002939ac0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:28 +0000 UTC  }],Message:,Reason:,HostIP:10.10.103.183,PodIP:,StartTime:2019-05-25 01:24:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 25 01:24:32.331: INFO: Pod "nginx-deployment-65bbdb5f8-t58g4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-t58g4,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-p58cq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p58cq/pods/nginx-deployment-65bbdb5f8-t58g4,UID:d810946e-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:17132,Generation:0,CreationTimestamp:2019-05-25 01:24:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.2.43/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 d6d6f27e-7e8b-11e9-ba33-0050569e7ba0 0xc002939b90 0xc002939b91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-msgcg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msgcg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-msgcg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-400-cp1718-vsp2-worker00f2b167f8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002939c00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002939c20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC  }],Message:,Reason:,HostIP:10.10.103.183,PodIP:,StartTime:2019-05-25 01:24:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 25 01:24:32.331: INFO: Pod "nginx-deployment-65bbdb5f8-wt9vv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-wt9vv,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-p58cq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p58cq/pods/nginx-deployment-65bbdb5f8-wt9vv,UID:d81cd969-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:17078,Generation:0,CreationTimestamp:2019-05-25 01:24:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 d6d6f27e-7e8b-11e9-ba33-0050569e7ba0 0xc002939ce0 0xc002939ce1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-msgcg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msgcg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-msgcg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-400-cp1718-vsp2-workere35c6c6a2b,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002939d50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002939d70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:30 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 25 01:24:32.332: INFO: Pod "nginx-deployment-65bbdb5f8-xw7zn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-xw7zn,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-p58cq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p58cq/pods/nginx-deployment-65bbdb5f8-xw7zn,UID:d6d90947-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:17006,Generation:0,CreationTimestamp:2019-05-25 01:24:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.78/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 d6d6f27e-7e8b-11e9-ba33-0050569e7ba0 0xc002939df0 0xc002939df1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-msgcg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msgcg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-msgcg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-400-cp1718-vsp2-workere35c6c6a2b,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002939e60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002939e80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:28 +0000 UTC  }],Message:,Reason:,HostIP:10.10.103.184,PodIP:,StartTime:2019-05-25 01:24:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 25 01:24:32.332: INFO: Pod "nginx-deployment-65bbdb5f8-zft4b" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-zft4b,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-p58cq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p58cq/pods/nginx-deployment-65bbdb5f8-zft4b,UID:d6d77b42-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:17008,Generation:0,CreationTimestamp:2019-05-25 01:24:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.2.40/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 d6d6f27e-7e8b-11e9-ba33-0050569e7ba0 0xc002939f50 0xc002939f51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-msgcg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-msgcg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-msgcg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-400-cp1718-vsp2-worker00f2b167f8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002939fc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002939fe0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:24:28 +0000 UTC  }],Message:,Reason:,HostIP:10.10.103.183,PodIP:,StartTime:2019-05-25 01:24:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:24:32.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-p58cq" for this suite.
May 25 01:24:40.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:24:40.426: INFO: namespace: e2e-tests-deployment-p58cq, resource: bindings, ignored listing per whitelist
May 25 01:24:40.459: INFO: namespace e2e-tests-deployment-p58cq deletion completed in 8.09932339s

• [SLOW TEST:18.518 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:24:40.460: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-fz76t
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
May 25 01:24:40.625: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fz76t,SelfLink:/api/v1/namespaces/e2e-tests-watch-fz76t/configmaps/e2e-watch-test-configmap-a,UID:de468eae-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:17434,Generation:0,CreationTimestamp:2019-05-25 01:24:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 25 01:24:40.625: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fz76t,SelfLink:/api/v1/namespaces/e2e-tests-watch-fz76t/configmaps/e2e-watch-test-configmap-a,UID:de468eae-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:17434,Generation:0,CreationTimestamp:2019-05-25 01:24:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
May 25 01:24:50.631: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fz76t,SelfLink:/api/v1/namespaces/e2e-tests-watch-fz76t/configmaps/e2e-watch-test-configmap-a,UID:de468eae-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:17451,Generation:0,CreationTimestamp:2019-05-25 01:24:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
May 25 01:24:50.631: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fz76t,SelfLink:/api/v1/namespaces/e2e-tests-watch-fz76t/configmaps/e2e-watch-test-configmap-a,UID:de468eae-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:17451,Generation:0,CreationTimestamp:2019-05-25 01:24:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
May 25 01:25:00.638: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fz76t,SelfLink:/api/v1/namespaces/e2e-tests-watch-fz76t/configmaps/e2e-watch-test-configmap-a,UID:de468eae-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:17468,Generation:0,CreationTimestamp:2019-05-25 01:24:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 25 01:25:00.638: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fz76t,SelfLink:/api/v1/namespaces/e2e-tests-watch-fz76t/configmaps/e2e-watch-test-configmap-a,UID:de468eae-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:17468,Generation:0,CreationTimestamp:2019-05-25 01:24:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
May 25 01:25:10.644: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fz76t,SelfLink:/api/v1/namespaces/e2e-tests-watch-fz76t/configmaps/e2e-watch-test-configmap-a,UID:de468eae-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:17484,Generation:0,CreationTimestamp:2019-05-25 01:24:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 25 01:25:10.644: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fz76t,SelfLink:/api/v1/namespaces/e2e-tests-watch-fz76t/configmaps/e2e-watch-test-configmap-a,UID:de468eae-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:17484,Generation:0,CreationTimestamp:2019-05-25 01:24:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
May 25 01:25:20.651: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-fz76t,SelfLink:/api/v1/namespaces/e2e-tests-watch-fz76t/configmaps/e2e-watch-test-configmap-b,UID:f621a31c-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:17502,Generation:0,CreationTimestamp:2019-05-25 01:25:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 25 01:25:20.651: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-fz76t,SelfLink:/api/v1/namespaces/e2e-tests-watch-fz76t/configmaps/e2e-watch-test-configmap-b,UID:f621a31c-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:17502,Generation:0,CreationTimestamp:2019-05-25 01:25:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
May 25 01:25:30.657: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-fz76t,SelfLink:/api/v1/namespaces/e2e-tests-watch-fz76t/configmaps/e2e-watch-test-configmap-b,UID:f621a31c-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:17519,Generation:0,CreationTimestamp:2019-05-25 01:25:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 25 01:25:30.657: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-fz76t,SelfLink:/api/v1/namespaces/e2e-tests-watch-fz76t/configmaps/e2e-watch-test-configmap-b,UID:f621a31c-7e8b-11e9-ba33-0050569e7ba0,ResourceVersion:17519,Generation:0,CreationTimestamp:2019-05-25 01:25:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:25:40.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-fz76t" for this suite.
May 25 01:25:46.672: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:25:46.686: INFO: namespace: e2e-tests-watch-fz76t, resource: bindings, ignored listing per whitelist
May 25 01:25:46.747: INFO: namespace e2e-tests-watch-fz76t deletion completed in 6.08387636s

• [SLOW TEST:66.287 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:25:46.747: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-x5h2p
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 25 01:25:46.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-x5h2p'
May 25 01:25:47.232: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 25 01:25:47.232: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
May 25 01:25:47.241: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
May 25 01:25:47.251: INFO: scanned /root for discovery docs: <nil>
May 25 01:25:47.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-x5h2p'
May 25 01:26:03.097: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
May 25 01:26:03.097: INFO: stdout: "Created e2e-test-nginx-rc-a4de5117119bacb50a1f1f11a14881fd\nScaling up e2e-test-nginx-rc-a4de5117119bacb50a1f1f11a14881fd from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-a4de5117119bacb50a1f1f11a14881fd up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-a4de5117119bacb50a1f1f11a14881fd to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
May 25 01:26:03.097: INFO: stdout: "Created e2e-test-nginx-rc-a4de5117119bacb50a1f1f11a14881fd\nScaling up e2e-test-nginx-rc-a4de5117119bacb50a1f1f11a14881fd from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-a4de5117119bacb50a1f1f11a14881fd up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-a4de5117119bacb50a1f1f11a14881fd to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
May 25 01:26:03.097: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-x5h2p'
May 25 01:26:03.189: INFO: stderr: ""
May 25 01:26:03.189: INFO: stdout: "e2e-test-nginx-rc-a4de5117119bacb50a1f1f11a14881fd-c6gpg "
May 25 01:26:03.189: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods e2e-test-nginx-rc-a4de5117119bacb50a1f1f11a14881fd-c6gpg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x5h2p'
May 25 01:26:03.270: INFO: stderr: ""
May 25 01:26:03.270: INFO: stdout: "true"
May 25 01:26:03.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods e2e-test-nginx-rc-a4de5117119bacb50a1f1f11a14881fd-c6gpg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x5h2p'
May 25 01:26:03.360: INFO: stderr: ""
May 25 01:26:03.360: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
May 25 01:26:03.360: INFO: e2e-test-nginx-rc-a4de5117119bacb50a1f1f11a14881fd-c6gpg is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
May 25 01:26:03.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-x5h2p'
May 25 01:26:03.462: INFO: stderr: ""
May 25 01:26:03.462: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:26:03.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-x5h2p" for this suite.
May 25 01:26:09.478: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:26:09.506: INFO: namespace: e2e-tests-kubectl-x5h2p, resource: bindings, ignored listing per whitelist
May 25 01:26:09.552: INFO: namespace e2e-tests-kubectl-x5h2p deletion completed in 6.080953579s

• [SLOW TEST:22.804 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:26:09.552: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-c75rs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:26:11.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-c75rs" for this suite.
May 25 01:26:49.738: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:26:49.775: INFO: namespace: e2e-tests-kubelet-test-c75rs, resource: bindings, ignored listing per whitelist
May 25 01:26:49.808: INFO: namespace e2e-tests-kubelet-test-c75rs deletion completed in 38.078936149s

• [SLOW TEST:40.257 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:26:49.809: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-6hjrb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-2b5f1f05-7e8c-11e9-802f-027f94874578
STEP: Creating a pod to test consume secrets
May 25 01:26:49.983: INFO: Waiting up to 5m0s for pod "pod-secrets-2b6003e7-7e8c-11e9-802f-027f94874578" in namespace "e2e-tests-secrets-6hjrb" to be "success or failure"
May 25 01:26:49.986: INFO: Pod "pod-secrets-2b6003e7-7e8c-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 3.528127ms
May 25 01:26:51.988: INFO: Pod "pod-secrets-2b6003e7-7e8c-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005714496s
STEP: Saw pod success
May 25 01:26:51.988: INFO: Pod "pod-secrets-2b6003e7-7e8c-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:26:51.991: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-secrets-2b6003e7-7e8c-11e9-802f-027f94874578 container secret-volume-test: <nil>
STEP: delete the pod
May 25 01:26:52.010: INFO: Waiting for pod pod-secrets-2b6003e7-7e8c-11e9-802f-027f94874578 to disappear
May 25 01:26:52.011: INFO: Pod pod-secrets-2b6003e7-7e8c-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:26:52.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-6hjrb" for this suite.
May 25 01:26:58.024: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:26:58.051: INFO: namespace: e2e-tests-secrets-6hjrb, resource: bindings, ignored listing per whitelist
May 25 01:26:58.108: INFO: namespace e2e-tests-secrets-6hjrb deletion completed in 6.091688769s

• [SLOW TEST:8.299 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:26:58.111: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-spfkb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 25 01:26:58.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-spfkb'
May 25 01:26:58.406: INFO: stderr: ""
May 25 01:26:58.406: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
May 25 01:27:03.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-spfkb -o json'
May 25 01:27:03.547: INFO: stderr: ""
May 25 01:27:03.547: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"192.168.1.95/32\"\n        },\n        \"creationTimestamp\": \"2019-05-25T01:26:58Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-spfkb\",\n        \"resourceVersion\": \"17830\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-spfkb/pods/e2e-test-nginx-pod\",\n        \"uid\": \"30622184-7e8c-11e9-ba33-0050569e7ba0\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-zbbjv\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"alex-400-cp1718-vsp2-workere35c6c6a2b\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-zbbjv\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-zbbjv\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-25T01:26:58Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-25T01:27:00Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-25T01:27:00Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-25T01:26:58Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://a3b91264d877181afd6f60ac42b28e64feb560516c63ca625da3151d1b08291a\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-05-25T01:26:59Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.10.103.184\",\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.1.95\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-05-25T01:26:58Z\"\n    }\n}\n"
STEP: replace the image in the pod
May 25 01:27:03.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 replace -f - --namespace=e2e-tests-kubectl-spfkb'
May 25 01:27:03.752: INFO: stderr: ""
May 25 01:27:03.752: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
May 25 01:27:03.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-spfkb'
May 25 01:27:05.190: INFO: stderr: ""
May 25 01:27:05.190: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:27:05.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-spfkb" for this suite.
May 25 01:27:11.207: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:27:11.263: INFO: namespace: e2e-tests-kubectl-spfkb, resource: bindings, ignored listing per whitelist
May 25 01:27:11.294: INFO: namespace e2e-tests-kubectl-spfkb deletion completed in 6.096492307s

• [SLOW TEST:13.183 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:27:11.295: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-v99z5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 25 01:27:11.456: INFO: Creating deployment "test-recreate-deployment"
May 25 01:27:11.466: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
May 25 01:27:11.484: INFO: Waiting deployment "test-recreate-deployment" to complete
May 25 01:27:11.493: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344431, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344431, loc:(*time.Location)(0x7b33b80)}}, Reason:"NewReplicaSetCreated", Message:"Created new replica set \"test-recreate-deployment-5dfdcc846d\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344431, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344431, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
May 25 01:27:13.497: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
May 25 01:27:13.528: INFO: Updating deployment test-recreate-deployment
May 25 01:27:13.529: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 25 01:27:13.593: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-v99z5,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-v99z5/deployments/test-recreate-deployment,UID:382e2069-7e8c-11e9-ba33-0050569e7ba0,ResourceVersion:17917,Generation:2,CreationTimestamp:2019-05-25 01:27:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-05-25 01:27:13 +0000 UTC 2019-05-25 01:27:13 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-05-25 01:27:13 +0000 UTC 2019-05-25 01:27:11 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

May 25 01:27:13.595: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-v99z5,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-v99z5/replicasets/test-recreate-deployment-697fbf54bf,UID:396dad20-7e8c-11e9-ba33-0050569e7ba0,ResourceVersion:17914,Generation:1,CreationTimestamp:2019-05-25 01:27:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 382e2069-7e8c-11e9-ba33-0050569e7ba0 0xc000f5a5d7 0xc000f5a5d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 25 01:27:13.596: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
May 25 01:27:13.596: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-v99z5,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-v99z5/replicasets/test-recreate-deployment-5dfdcc846d,UID:382f27a5-7e8c-11e9-ba33-0050569e7ba0,ResourceVersion:17906,Generation:2,CreationTimestamp:2019-05-25 01:27:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 382e2069-7e8c-11e9-ba33-0050569e7ba0 0xc000f5a2f7 0xc000f5a2f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 25 01:27:13.598: INFO: Pod "test-recreate-deployment-697fbf54bf-ttpzv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-ttpzv,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-v99z5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-v99z5/pods/test-recreate-deployment-697fbf54bf-ttpzv,UID:396e49fc-7e8c-11e9-ba33-0050569e7ba0,ResourceVersion:17918,Generation:0,CreationTimestamp:2019-05-25 01:27:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf 396dad20-7e8c-11e9-ba33-0050569e7ba0 0xc001918507 0xc001918508}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-x779k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-x779k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-x779k true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-400-cp1718-vsp2-workere35c6c6a2b,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001918570} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001918590}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:27:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:27:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:27:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:27:13 +0000 UTC  }],Message:,Reason:,HostIP:10.10.103.184,PodIP:,StartTime:2019-05-25 01:27:14 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:27:13.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-v99z5" for this suite.
May 25 01:27:19.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:27:19.633: INFO: namespace: e2e-tests-deployment-v99z5, resource: bindings, ignored listing per whitelist
May 25 01:27:19.675: INFO: namespace e2e-tests-deployment-v99z5 deletion completed in 6.074590891s

• [SLOW TEST:8.381 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:27:19.676: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-qmb42
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
May 25 01:27:19.902: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:27:19.905: INFO: Number of nodes with available pods: 0
May 25 01:27:19.905: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:27:20.910: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:27:20.912: INFO: Number of nodes with available pods: 0
May 25 01:27:20.912: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:27:21.910: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:27:21.913: INFO: Number of nodes with available pods: 1
May 25 01:27:21.913: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:27:22.909: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:27:22.911: INFO: Number of nodes with available pods: 1
May 25 01:27:22.911: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:27:23.909: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:27:23.912: INFO: Number of nodes with available pods: 2
May 25 01:27:23.912: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
May 25 01:27:23.931: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:27:23.934: INFO: Number of nodes with available pods: 1
May 25 01:27:23.934: INFO: Node alex-400-cp1718-vsp2-workere35c6c6a2b is running more than one daemon pod
May 25 01:27:24.939: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:27:24.941: INFO: Number of nodes with available pods: 1
May 25 01:27:24.941: INFO: Node alex-400-cp1718-vsp2-workere35c6c6a2b is running more than one daemon pod
May 25 01:27:25.939: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:27:25.942: INFO: Number of nodes with available pods: 1
May 25 01:27:25.942: INFO: Node alex-400-cp1718-vsp2-workere35c6c6a2b is running more than one daemon pod
May 25 01:27:26.938: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:27:26.941: INFO: Number of nodes with available pods: 1
May 25 01:27:26.941: INFO: Node alex-400-cp1718-vsp2-workere35c6c6a2b is running more than one daemon pod
May 25 01:27:27.938: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:27:27.941: INFO: Number of nodes with available pods: 1
May 25 01:27:27.941: INFO: Node alex-400-cp1718-vsp2-workere35c6c6a2b is running more than one daemon pod
May 25 01:27:28.937: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:27:28.939: INFO: Number of nodes with available pods: 1
May 25 01:27:28.939: INFO: Node alex-400-cp1718-vsp2-workere35c6c6a2b is running more than one daemon pod
May 25 01:27:29.938: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:27:29.940: INFO: Number of nodes with available pods: 1
May 25 01:27:29.940: INFO: Node alex-400-cp1718-vsp2-workere35c6c6a2b is running more than one daemon pod
May 25 01:27:30.938: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:27:30.942: INFO: Number of nodes with available pods: 1
May 25 01:27:30.942: INFO: Node alex-400-cp1718-vsp2-workere35c6c6a2b is running more than one daemon pod
May 25 01:27:31.938: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:27:31.940: INFO: Number of nodes with available pods: 1
May 25 01:27:31.940: INFO: Node alex-400-cp1718-vsp2-workere35c6c6a2b is running more than one daemon pod
May 25 01:27:32.938: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:27:32.940: INFO: Number of nodes with available pods: 1
May 25 01:27:32.940: INFO: Node alex-400-cp1718-vsp2-workere35c6c6a2b is running more than one daemon pod
May 25 01:27:33.938: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:27:33.941: INFO: Number of nodes with available pods: 1
May 25 01:27:33.941: INFO: Node alex-400-cp1718-vsp2-workere35c6c6a2b is running more than one daemon pod
May 25 01:27:34.938: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:27:34.940: INFO: Number of nodes with available pods: 1
May 25 01:27:34.940: INFO: Node alex-400-cp1718-vsp2-workere35c6c6a2b is running more than one daemon pod
May 25 01:27:35.939: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:27:35.941: INFO: Number of nodes with available pods: 1
May 25 01:27:35.941: INFO: Node alex-400-cp1718-vsp2-workere35c6c6a2b is running more than one daemon pod
May 25 01:27:36.938: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:27:36.940: INFO: Number of nodes with available pods: 1
May 25 01:27:36.941: INFO: Node alex-400-cp1718-vsp2-workere35c6c6a2b is running more than one daemon pod
May 25 01:27:37.938: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:27:37.941: INFO: Number of nodes with available pods: 1
May 25 01:27:37.941: INFO: Node alex-400-cp1718-vsp2-workere35c6c6a2b is running more than one daemon pod
May 25 01:27:38.942: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:27:38.946: INFO: Number of nodes with available pods: 1
May 25 01:27:38.946: INFO: Node alex-400-cp1718-vsp2-workere35c6c6a2b is running more than one daemon pod
May 25 01:27:39.938: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:27:39.942: INFO: Number of nodes with available pods: 1
May 25 01:27:39.942: INFO: Node alex-400-cp1718-vsp2-workere35c6c6a2b is running more than one daemon pod
May 25 01:27:40.938: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:27:40.942: INFO: Number of nodes with available pods: 1
May 25 01:27:40.942: INFO: Node alex-400-cp1718-vsp2-workere35c6c6a2b is running more than one daemon pod
May 25 01:27:41.938: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:27:41.941: INFO: Number of nodes with available pods: 1
May 25 01:27:41.941: INFO: Node alex-400-cp1718-vsp2-workere35c6c6a2b is running more than one daemon pod
May 25 01:27:42.937: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:27:42.940: INFO: Number of nodes with available pods: 1
May 25 01:27:42.940: INFO: Node alex-400-cp1718-vsp2-workere35c6c6a2b is running more than one daemon pod
May 25 01:27:43.938: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:27:43.940: INFO: Number of nodes with available pods: 1
May 25 01:27:43.940: INFO: Node alex-400-cp1718-vsp2-workere35c6c6a2b is running more than one daemon pod
May 25 01:27:44.937: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:27:44.939: INFO: Number of nodes with available pods: 1
May 25 01:27:44.939: INFO: Node alex-400-cp1718-vsp2-workere35c6c6a2b is running more than one daemon pod
May 25 01:27:45.938: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:27:45.941: INFO: Number of nodes with available pods: 1
May 25 01:27:45.941: INFO: Node alex-400-cp1718-vsp2-workere35c6c6a2b is running more than one daemon pod
May 25 01:27:46.937: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:27:46.939: INFO: Number of nodes with available pods: 1
May 25 01:27:46.939: INFO: Node alex-400-cp1718-vsp2-workere35c6c6a2b is running more than one daemon pod
May 25 01:27:47.939: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:27:47.941: INFO: Number of nodes with available pods: 1
May 25 01:27:47.941: INFO: Node alex-400-cp1718-vsp2-workere35c6c6a2b is running more than one daemon pod
May 25 01:27:48.939: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:27:48.941: INFO: Number of nodes with available pods: 1
May 25 01:27:48.941: INFO: Node alex-400-cp1718-vsp2-workere35c6c6a2b is running more than one daemon pod
May 25 01:27:49.938: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:27:49.941: INFO: Number of nodes with available pods: 1
May 25 01:27:49.941: INFO: Node alex-400-cp1718-vsp2-workere35c6c6a2b is running more than one daemon pod
May 25 01:27:50.937: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:27:50.940: INFO: Number of nodes with available pods: 1
May 25 01:27:50.940: INFO: Node alex-400-cp1718-vsp2-workere35c6c6a2b is running more than one daemon pod
May 25 01:27:51.938: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:27:51.940: INFO: Number of nodes with available pods: 1
May 25 01:27:51.940: INFO: Node alex-400-cp1718-vsp2-workere35c6c6a2b is running more than one daemon pod
May 25 01:27:52.938: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:27:52.940: INFO: Number of nodes with available pods: 1
May 25 01:27:52.940: INFO: Node alex-400-cp1718-vsp2-workere35c6c6a2b is running more than one daemon pod
May 25 01:27:53.937: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:27:53.940: INFO: Number of nodes with available pods: 1
May 25 01:27:53.940: INFO: Node alex-400-cp1718-vsp2-workere35c6c6a2b is running more than one daemon pod
May 25 01:27:54.948: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:27:54.952: INFO: Number of nodes with available pods: 1
May 25 01:27:54.952: INFO: Node alex-400-cp1718-vsp2-workere35c6c6a2b is running more than one daemon pod
May 25 01:27:55.938: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:27:55.941: INFO: Number of nodes with available pods: 1
May 25 01:27:55.941: INFO: Node alex-400-cp1718-vsp2-workere35c6c6a2b is running more than one daemon pod
May 25 01:27:56.937: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:27:56.940: INFO: Number of nodes with available pods: 1
May 25 01:27:56.940: INFO: Node alex-400-cp1718-vsp2-workere35c6c6a2b is running more than one daemon pod
May 25 01:27:57.938: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:27:57.940: INFO: Number of nodes with available pods: 1
May 25 01:27:57.940: INFO: Node alex-400-cp1718-vsp2-workere35c6c6a2b is running more than one daemon pod
May 25 01:27:58.938: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:27:58.942: INFO: Number of nodes with available pods: 1
May 25 01:27:58.942: INFO: Node alex-400-cp1718-vsp2-workere35c6c6a2b is running more than one daemon pod
May 25 01:27:59.938: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:27:59.941: INFO: Number of nodes with available pods: 2
May 25 01:27:59.941: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-qmb42, will wait for the garbage collector to delete the pods
May 25 01:28:00.002: INFO: Deleting DaemonSet.extensions daemon-set took: 6.181549ms
May 25 01:28:00.103: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.527953ms
May 25 01:28:38.505: INFO: Number of nodes with available pods: 0
May 25 01:28:38.505: INFO: Number of running nodes: 0, number of available pods: 0
May 25 01:28:38.507: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-qmb42/daemonsets","resourceVersion":"18144"},"items":null}

May 25 01:28:38.509: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-qmb42/pods","resourceVersion":"18144"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:28:38.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-qmb42" for this suite.
May 25 01:28:44.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:28:44.575: INFO: namespace: e2e-tests-daemonsets-qmb42, resource: bindings, ignored listing per whitelist
May 25 01:28:44.611: INFO: namespace e2e-tests-daemonsets-qmb42 deletion completed in 6.091824456s

• [SLOW TEST:84.935 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:28:44.612: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-s72s9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-cd87
STEP: Creating a pod to test atomic-volume-subpath
May 25 01:28:44.784: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-cd87" in namespace "e2e-tests-subpath-s72s9" to be "success or failure"
May 25 01:28:44.792: INFO: Pod "pod-subpath-test-downwardapi-cd87": Phase="Pending", Reason="", readiness=false. Elapsed: 7.710255ms
May 25 01:28:46.795: INFO: Pod "pod-subpath-test-downwardapi-cd87": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010573732s
May 25 01:28:48.798: INFO: Pod "pod-subpath-test-downwardapi-cd87": Phase="Running", Reason="", readiness=false. Elapsed: 4.014085528s
May 25 01:28:50.801: INFO: Pod "pod-subpath-test-downwardapi-cd87": Phase="Running", Reason="", readiness=false. Elapsed: 6.016157948s
May 25 01:28:52.804: INFO: Pod "pod-subpath-test-downwardapi-cd87": Phase="Running", Reason="", readiness=false. Elapsed: 8.019355835s
May 25 01:28:54.807: INFO: Pod "pod-subpath-test-downwardapi-cd87": Phase="Running", Reason="", readiness=false. Elapsed: 10.022141494s
May 25 01:28:56.809: INFO: Pod "pod-subpath-test-downwardapi-cd87": Phase="Running", Reason="", readiness=false. Elapsed: 12.024780475s
May 25 01:28:58.813: INFO: Pod "pod-subpath-test-downwardapi-cd87": Phase="Running", Reason="", readiness=false. Elapsed: 14.028224746s
May 25 01:29:00.815: INFO: Pod "pod-subpath-test-downwardapi-cd87": Phase="Running", Reason="", readiness=false. Elapsed: 16.030991817s
May 25 01:29:02.818: INFO: Pod "pod-subpath-test-downwardapi-cd87": Phase="Running", Reason="", readiness=false. Elapsed: 18.034060182s
May 25 01:29:04.821: INFO: Pod "pod-subpath-test-downwardapi-cd87": Phase="Running", Reason="", readiness=false. Elapsed: 20.036728275s
May 25 01:29:06.824: INFO: Pod "pod-subpath-test-downwardapi-cd87": Phase="Running", Reason="", readiness=false. Elapsed: 22.039671962s
May 25 01:29:08.827: INFO: Pod "pod-subpath-test-downwardapi-cd87": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.042494288s
STEP: Saw pod success
May 25 01:29:08.827: INFO: Pod "pod-subpath-test-downwardapi-cd87" satisfied condition "success or failure"
May 25 01:29:08.829: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-subpath-test-downwardapi-cd87 container test-container-subpath-downwardapi-cd87: <nil>
STEP: delete the pod
May 25 01:29:08.847: INFO: Waiting for pod pod-subpath-test-downwardapi-cd87 to disappear
May 25 01:29:08.849: INFO: Pod pod-subpath-test-downwardapi-cd87 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-cd87
May 25 01:29:08.849: INFO: Deleting pod "pod-subpath-test-downwardapi-cd87" in namespace "e2e-tests-subpath-s72s9"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:29:08.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-s72s9" for this suite.
May 25 01:29:14.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:29:14.883: INFO: namespace: e2e-tests-subpath-s72s9, resource: bindings, ignored listing per whitelist
May 25 01:29:14.938: INFO: namespace e2e-tests-subpath-s72s9 deletion completed in 6.083933202s

• [SLOW TEST:30.326 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:29:14.938: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-rrkf9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
May 25 01:29:15.098: INFO: PodSpec: initContainers in spec.initContainers
May 25 01:29:59.238: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-81e03105-7e8c-11e9-802f-027f94874578", GenerateName:"", Namespace:"e2e-tests-init-container-rrkf9", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-rrkf9/pods/pod-init-81e03105-7e8c-11e9-802f-027f94874578", UID:"81e0a86b-7e8c-11e9-ba33-0050569e7ba0", ResourceVersion:"18377", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63694344555, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"98553563"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"192.168.1.101/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-tvprj", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001aa2100), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-tvprj", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-tvprj", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}, "cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-tvprj", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001eb2468), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"alex-400-cp1718-vsp2-workere35c6c6a2b", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00135c660), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001eb26d0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001eb26f0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001eb26f8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001eb26fc)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344555, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344555, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344555, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344555, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.10.103.184", PodIP:"192.168.1.101", StartTime:(*v1.Time)(0xc000dcc040), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0012820e0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0012821c0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://13312cfbf21064422197d599d6066a5cf24addce0c0dca5ec2dc697661703213"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc000dcc080), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc000dcc060), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:29:59.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-rrkf9" for this suite.
May 25 01:30:21.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:30:21.313: INFO: namespace: e2e-tests-init-container-rrkf9, resource: bindings, ignored listing per whitelist
May 25 01:30:21.327: INFO: namespace e2e-tests-init-container-rrkf9 deletion completed in 22.080534928s

• [SLOW TEST:66.388 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:30:21.328: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-6fckz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 25 01:30:21.486: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
May 25 01:30:21.496: INFO: Pod name sample-pod: Found 0 pods out of 1
May 25 01:30:26.499: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May 25 01:30:26.499: INFO: Creating deployment "test-rolling-update-deployment"
May 25 01:30:26.506: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
May 25 01:30:26.520: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
May 25 01:30:28.525: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
May 25 01:30:28.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344626, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344626, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344626, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694344626, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-68b55d7bc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 25 01:30:30.530: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 25 01:30:30.537: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-6fckz,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-6fckz/deployments/test-rolling-update-deployment,UID:ac6f4e2c-7e8c-11e9-ba33-0050569e7ba0,ResourceVersion:18491,Generation:1,CreationTimestamp:2019-05-25 01:30:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-05-25 01:30:26 +0000 UTC 2019-05-25 01:30:26 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-05-25 01:30:29 +0000 UTC 2019-05-25 01:30:26 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

May 25 01:30:30.539: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-6fckz,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-6fckz/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:ac71620a-7e8c-11e9-ba33-0050569e7ba0,ResourceVersion:18482,Generation:1,CreationTimestamp:2019-05-25 01:30:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment ac6f4e2c-7e8c-11e9-ba33-0050569e7ba0 0xc000b21fe7 0xc000b21fe8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
May 25 01:30:30.540: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
May 25 01:30:30.540: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-6fckz,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-6fckz/replicasets/test-rolling-update-controller,UID:a9724331-7e8c-11e9-ba33-0050569e7ba0,ResourceVersion:18490,Generation:2,CreationTimestamp:2019-05-25 01:30:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment ac6f4e2c-7e8c-11e9-ba33-0050569e7ba0 0xc000b21da7 0xc000b21da8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 25 01:30:30.542: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-lzqlm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-lzqlm,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-6fckz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6fckz/pods/test-rolling-update-deployment-68b55d7bc6-lzqlm,UID:ac724470-7e8c-11e9-ba33-0050569e7ba0,ResourceVersion:18481,Generation:0,CreationTimestamp:2019-05-25 01:30:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.2.54/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 ac71620a-7e8c-11e9-ba33-0050569e7ba0 0xc00226d887 0xc00226d888}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rsjv8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rsjv8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-rsjv8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-400-cp1718-vsp2-worker00f2b167f8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017b2110} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017b2170}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:30:27 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:30:29 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:30:29 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:30:26 +0000 UTC  }],Message:,Reason:,HostIP:10.10.103.183,PodIP:192.168.2.54,StartTime:2019-05-25 01:30:27 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-05-25 01:30:29 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://adc1615830f7e41ef59915119e83a113e15527a23af57204e11a92ebcff2f675}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:30:30.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-6fckz" for this suite.
May 25 01:30:36.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:30:36.624: INFO: namespace: e2e-tests-deployment-6fckz, resource: bindings, ignored listing per whitelist
May 25 01:30:36.624: INFO: namespace e2e-tests-deployment-6fckz deletion completed in 6.078391587s

• [SLOW TEST:15.296 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:30:36.625: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-slm9w
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
May 25 01:30:36.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 cluster-info'
May 25 01:30:36.881: INFO: stderr: ""
May 25 01:30:36.881: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:30:36.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-slm9w" for this suite.
May 25 01:30:42.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:30:42.930: INFO: namespace: e2e-tests-kubectl-slm9w, resource: bindings, ignored listing per whitelist
May 25 01:30:42.981: INFO: namespace e2e-tests-kubectl-slm9w deletion completed in 6.095547078s

• [SLOW TEST:6.357 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:30:42.982: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-ch84n
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 25 01:30:43.146: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:30:45.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-ch84n" for this suite.
May 25 01:31:33.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:31:33.244: INFO: namespace: e2e-tests-pods-ch84n, resource: bindings, ignored listing per whitelist
May 25 01:31:33.289: INFO: namespace e2e-tests-pods-ch84n deletion completed in 48.100828588s

• [SLOW TEST:50.307 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:31:33.291: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-qtb9h
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:31:33.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-qtb9h" for this suite.
May 25 01:31:39.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:31:39.526: INFO: namespace: e2e-tests-services-qtb9h, resource: bindings, ignored listing per whitelist
May 25 01:31:39.540: INFO: namespace e2e-tests-services-qtb9h deletion completed in 6.080248829s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:6.250 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:31:39.543: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-sh6lr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 25 01:31:39.706: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d8109983-7e8c-11e9-802f-027f94874578" in namespace "e2e-tests-downward-api-sh6lr" to be "success or failure"
May 25 01:31:39.713: INFO: Pod "downwardapi-volume-d8109983-7e8c-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 6.139324ms
May 25 01:31:41.715: INFO: Pod "downwardapi-volume-d8109983-7e8c-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008473498s
STEP: Saw pod success
May 25 01:31:41.715: INFO: Pod "downwardapi-volume-d8109983-7e8c-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:31:41.718: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod downwardapi-volume-d8109983-7e8c-11e9-802f-027f94874578 container client-container: <nil>
STEP: delete the pod
May 25 01:31:41.733: INFO: Waiting for pod downwardapi-volume-d8109983-7e8c-11e9-802f-027f94874578 to disappear
May 25 01:31:41.736: INFO: Pod downwardapi-volume-d8109983-7e8c-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:31:41.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-sh6lr" for this suite.
May 25 01:31:47.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:31:47.812: INFO: namespace: e2e-tests-downward-api-sh6lr, resource: bindings, ignored listing per whitelist
May 25 01:31:47.827: INFO: namespace e2e-tests-downward-api-sh6lr deletion completed in 6.086073685s

• [SLOW TEST:8.284 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:31:47.828: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-7xbwh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
May 25 01:31:53.023: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:31:53.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-7xbwh" for this suite.
May 25 01:32:15.072: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:32:15.115: INFO: namespace: e2e-tests-replicaset-7xbwh, resource: bindings, ignored listing per whitelist
May 25 01:32:15.159: INFO: namespace e2e-tests-replicaset-7xbwh deletion completed in 22.104632083s

• [SLOW TEST:27.332 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:32:15.160: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-mrn7c
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-mrn7c
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-mrn7c
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-mrn7c
May 25 01:32:15.341: INFO: Found 0 stateful pods, waiting for 1
May 25 01:32:25.346: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
May 25 01:32:25.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 25 01:32:25.484: INFO: stderr: ""
May 25 01:32:25.484: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 25 01:32:25.484: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 25 01:32:25.487: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May 25 01:32:35.490: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 25 01:32:35.490: INFO: Waiting for statefulset status.replicas updated to 0
May 25 01:32:35.511: INFO: POD   NODE                                   PHASE    GRACE  CONDITIONS
May 25 01:32:35.511: INFO: ss-0  alex-400-cp1718-vsp2-workere35c6c6a2b  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:15 +0000 UTC  }]
May 25 01:32:35.515: INFO: ss-1                                         Pending         []
May 25 01:32:35.515: INFO: 
May 25 01:32:35.515: INFO: StatefulSet ss has not reached scale 3, at 2
May 25 01:32:36.520: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.981548193s
May 25 01:32:37.523: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.977953376s
May 25 01:32:38.526: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.974242805s
May 25 01:32:39.530: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.971652659s
May 25 01:32:40.534: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.967870838s
May 25 01:32:41.542: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.963502799s
May 25 01:32:42.547: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.955018297s
May 25 01:32:43.550: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.950451037s
May 25 01:32:44.553: INFO: Verifying statefulset ss doesn't scale past 3 for another 947.324067ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-mrn7c
May 25 01:32:45.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 25 01:32:45.687: INFO: stderr: ""
May 25 01:32:45.687: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 25 01:32:45.687: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 25 01:32:45.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 25 01:32:45.831: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
May 25 01:32:45.831: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 25 01:32:45.831: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 25 01:32:45.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 25 01:32:45.957: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
May 25 01:32:45.957: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 25 01:32:45.957: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 25 01:32:45.960: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
May 25 01:32:55.969: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May 25 01:32:55.969: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May 25 01:32:55.969: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
May 25 01:32:55.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 25 01:32:56.121: INFO: stderr: ""
May 25 01:32:56.121: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 25 01:32:56.121: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 25 01:32:56.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 25 01:32:56.264: INFO: stderr: ""
May 25 01:32:56.264: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 25 01:32:56.264: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 25 01:32:56.264: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 25 01:32:56.419: INFO: stderr: ""
May 25 01:32:56.419: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 25 01:32:56.419: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 25 01:32:56.419: INFO: Waiting for statefulset status.replicas updated to 0
May 25 01:32:56.422: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
May 25 01:33:06.430: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 25 01:33:06.430: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May 25 01:33:06.430: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May 25 01:33:06.441: INFO: POD   NODE                                   PHASE    GRACE  CONDITIONS
May 25 01:33:06.447: INFO: ss-0  alex-400-cp1718-vsp2-workere35c6c6a2b  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:15 +0000 UTC  }]
May 25 01:33:06.447: INFO: ss-1  alex-400-cp1718-vsp2-worker00f2b167f8  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:35 +0000 UTC  }]
May 25 01:33:06.447: INFO: ss-2  alex-400-cp1718-vsp2-workere35c6c6a2b  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:35 +0000 UTC  }]
May 25 01:33:06.447: INFO: 
May 25 01:33:06.447: INFO: StatefulSet ss has not reached scale 0, at 3
May 25 01:33:07.452: INFO: POD   NODE                                   PHASE    GRACE  CONDITIONS
May 25 01:33:07.452: INFO: ss-0  alex-400-cp1718-vsp2-workere35c6c6a2b  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:15 +0000 UTC  }]
May 25 01:33:07.452: INFO: ss-1  alex-400-cp1718-vsp2-worker00f2b167f8  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:35 +0000 UTC  }]
May 25 01:33:07.452: INFO: ss-2  alex-400-cp1718-vsp2-workere35c6c6a2b  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:35 +0000 UTC  }]
May 25 01:33:07.452: INFO: 
May 25 01:33:07.452: INFO: StatefulSet ss has not reached scale 0, at 3
May 25 01:33:08.455: INFO: POD   NODE                                   PHASE    GRACE  CONDITIONS
May 25 01:33:08.455: INFO: ss-0  alex-400-cp1718-vsp2-workere35c6c6a2b  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:15 +0000 UTC  }]
May 25 01:33:08.455: INFO: ss-1  alex-400-cp1718-vsp2-worker00f2b167f8  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:35 +0000 UTC  }]
May 25 01:33:08.455: INFO: ss-2  alex-400-cp1718-vsp2-workere35c6c6a2b  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:35 +0000 UTC  }]
May 25 01:33:08.455: INFO: 
May 25 01:33:08.455: INFO: StatefulSet ss has not reached scale 0, at 3
May 25 01:33:09.460: INFO: POD   NODE                                   PHASE    GRACE  CONDITIONS
May 25 01:33:09.460: INFO: ss-1  alex-400-cp1718-vsp2-worker00f2b167f8  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:35 +0000 UTC  }]
May 25 01:33:09.460: INFO: ss-2  alex-400-cp1718-vsp2-workere35c6c6a2b  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:35 +0000 UTC  }]
May 25 01:33:09.460: INFO: 
May 25 01:33:09.460: INFO: StatefulSet ss has not reached scale 0, at 2
May 25 01:33:10.463: INFO: POD   NODE                                   PHASE    GRACE  CONDITIONS
May 25 01:33:10.463: INFO: ss-1  alex-400-cp1718-vsp2-worker00f2b167f8  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:35 +0000 UTC  }]
May 25 01:33:10.463: INFO: ss-2  alex-400-cp1718-vsp2-workere35c6c6a2b  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:35 +0000 UTC  }]
May 25 01:33:10.463: INFO: 
May 25 01:33:10.463: INFO: StatefulSet ss has not reached scale 0, at 2
May 25 01:33:11.465: INFO: POD   NODE                                   PHASE    GRACE  CONDITIONS
May 25 01:33:11.465: INFO: ss-1  alex-400-cp1718-vsp2-worker00f2b167f8  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:35 +0000 UTC  }]
May 25 01:33:11.465: INFO: ss-2  alex-400-cp1718-vsp2-workere35c6c6a2b  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:35 +0000 UTC  }]
May 25 01:33:11.465: INFO: 
May 25 01:33:11.465: INFO: StatefulSet ss has not reached scale 0, at 2
May 25 01:33:12.468: INFO: POD   NODE                                   PHASE    GRACE  CONDITIONS
May 25 01:33:12.468: INFO: ss-1  alex-400-cp1718-vsp2-worker00f2b167f8  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:35 +0000 UTC  }]
May 25 01:33:12.468: INFO: ss-2  alex-400-cp1718-vsp2-workere35c6c6a2b  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:35 +0000 UTC  }]
May 25 01:33:12.468: INFO: 
May 25 01:33:12.469: INFO: StatefulSet ss has not reached scale 0, at 2
May 25 01:33:13.471: INFO: POD   NODE                                   PHASE    GRACE  CONDITIONS
May 25 01:33:13.471: INFO: ss-1  alex-400-cp1718-vsp2-worker00f2b167f8  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:35 +0000 UTC  }]
May 25 01:33:13.471: INFO: ss-2  alex-400-cp1718-vsp2-workere35c6c6a2b  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:35 +0000 UTC  }]
May 25 01:33:13.472: INFO: 
May 25 01:33:13.472: INFO: StatefulSet ss has not reached scale 0, at 2
May 25 01:33:14.475: INFO: POD   NODE                                   PHASE    GRACE  CONDITIONS
May 25 01:33:14.475: INFO: ss-1  alex-400-cp1718-vsp2-worker00f2b167f8  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:35 +0000 UTC  }]
May 25 01:33:14.475: INFO: ss-2  alex-400-cp1718-vsp2-workere35c6c6a2b  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:35 +0000 UTC  }]
May 25 01:33:14.475: INFO: 
May 25 01:33:14.475: INFO: StatefulSet ss has not reached scale 0, at 2
May 25 01:33:15.478: INFO: POD   NODE                                   PHASE    GRACE  CONDITIONS
May 25 01:33:15.478: INFO: ss-1  alex-400-cp1718-vsp2-worker00f2b167f8  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:35 +0000 UTC  }]
May 25 01:33:15.478: INFO: ss-2  alex-400-cp1718-vsp2-workere35c6c6a2b  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:32:35 +0000 UTC  }]
May 25 01:33:15.478: INFO: 
May 25 01:33:15.478: INFO: StatefulSet ss has not reached scale 0, at 2
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-mrn7c
May 25 01:33:16.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 25 01:33:16.580: INFO: rc: 1
May 25 01:33:16.580: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc002899290 exit status 1 <nil> <nil> true [0xc000bcee10 0xc000bcee28 0xc000bcee40] [0xc000bcee10 0xc000bcee28 0xc000bcee40] [0xc000bcee20 0xc000bcee38] [0x92f8e0 0x92f8e0] 0xc0029b3320 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

May 25 01:33:26.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 25 01:33:26.664: INFO: rc: 1
May 25 01:33:26.664: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002899680 exit status 1 <nil> <nil> true [0xc000bcee48 0xc000bcee60 0xc000bcee78] [0xc000bcee48 0xc000bcee60 0xc000bcee78] [0xc000bcee58 0xc000bcee70] [0x92f8e0 0x92f8e0] 0xc0029b3620 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

May 25 01:33:36.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 25 01:33:36.742: INFO: rc: 1
May 25 01:33:36.742: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc000e52570 exit status 1 <nil> <nil> true [0xc000952008 0xc000952020 0xc000952038] [0xc000952008 0xc000952020 0xc000952038] [0xc000952018 0xc000952030] [0x92f8e0 0x92f8e0] 0xc002a12240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

May 25 01:33:46.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 25 01:33:46.823: INFO: rc: 1
May 25 01:33:46.823: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001d4c720 exit status 1 <nil> <nil> true [0xc001ea4018 0xc001ea4058 0xc001ea4088] [0xc001ea4018 0xc001ea4058 0xc001ea4088] [0xc001ea4050 0xc001ea4078] [0x92f8e0 0x92f8e0] 0xc001ad4240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

May 25 01:33:56.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 25 01:33:56.996: INFO: rc: 1
May 25 01:33:56.997: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc000e52a20 exit status 1 <nil> <nil> true [0xc000952040 0xc000952078 0xc0009520c0] [0xc000952040 0xc000952078 0xc0009520c0] [0xc000952058 0xc0009520a8] [0x92f8e0 0x92f8e0] 0xc002a12540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

May 25 01:34:06.997: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 25 01:34:07.076: INFO: rc: 1
May 25 01:34:07.076: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc000e530b0 exit status 1 <nil> <nil> true [0xc0009520d8 0xc0009520f8 0xc000952110] [0xc0009520d8 0xc0009520f8 0xc000952110] [0xc0009520f0 0xc000952108] [0x92f8e0 0x92f8e0] 0xc002a12840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

May 25 01:34:17.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 25 01:34:17.169: INFO: rc: 1
May 25 01:34:17.169: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc000e534a0 exit status 1 <nil> <nil> true [0xc000952118 0xc000952148 0xc0009521c8] [0xc000952118 0xc000952148 0xc0009521c8] [0xc000952140 0xc0009521a0] [0x92f8e0 0x92f8e0] 0xc002a12c00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

May 25 01:34:27.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 25 01:34:27.256: INFO: rc: 1
May 25 01:34:27.256: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc000e53980 exit status 1 <nil> <nil> true [0xc0009521d0 0xc0009521e8 0xc000952208] [0xc0009521d0 0xc0009521e8 0xc000952208] [0xc0009521e0 0xc0009521f8] [0x92f8e0 0x92f8e0] 0xc002a12f00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

May 25 01:34:37.256: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 25 01:34:37.342: INFO: rc: 1
May 25 01:34:37.342: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001d4cba0 exit status 1 <nil> <nil> true [0xc001ea4090 0xc001ea40a8 0xc001ea40c0] [0xc001ea4090 0xc001ea40a8 0xc001ea40c0] [0xc001ea40a0 0xc001ea40b8] [0x92f8e0 0x92f8e0] 0xc001ad45a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

May 25 01:34:47.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 25 01:34:47.425: INFO: rc: 1
May 25 01:34:47.425: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001d4cfc0 exit status 1 <nil> <nil> true [0xc001ea40c8 0xc001ea40e8 0xc001ea4108] [0xc001ea40c8 0xc001ea40e8 0xc001ea4108] [0xc001ea40e0 0xc001ea4100] [0x92f8e0 0x92f8e0] 0xc001ad48a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

May 25 01:34:57.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 25 01:34:57.509: INFO: rc: 1
May 25 01:34:57.509: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc000e53da0 exit status 1 <nil> <nil> true [0xc000952210 0xc000952228 0xc000952240] [0xc000952210 0xc000952228 0xc000952240] [0xc000952220 0xc000952238] [0x92f8e0 0x92f8e0] 0xc002a13260 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

May 25 01:35:07.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 25 01:35:07.597: INFO: rc: 1
May 25 01:35:07.597: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001d4d380 exit status 1 <nil> <nil> true [0xc001ea4110 0xc001ea4128 0xc001ea4148] [0xc001ea4110 0xc001ea4128 0xc001ea4148] [0xc001ea4120 0xc001ea4140] [0x92f8e0 0x92f8e0] 0xc001ad4c00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

May 25 01:35:17.597: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 25 01:35:17.689: INFO: rc: 1
May 25 01:35:17.689: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0007ca210 exit status 1 <nil> <nil> true [0xc000952248 0xc000952260 0xc000952278] [0xc000952248 0xc000952260 0xc000952278] [0xc000952258 0xc000952270] [0x92f8e0 0x92f8e0] 0xc002a13560 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

May 25 01:35:27.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 25 01:35:27.773: INFO: rc: 1
May 25 01:35:27.773: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001d4d7a0 exit status 1 <nil> <nil> true [0xc001ea4150 0xc001ea4188 0xc001ea41b0] [0xc001ea4150 0xc001ea4188 0xc001ea41b0] [0xc001ea4180 0xc001ea41a0] [0x92f8e0 0x92f8e0] 0xc001ad51a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

May 25 01:35:37.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 25 01:35:37.864: INFO: rc: 1
May 25 01:35:37.864: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc000e525a0 exit status 1 <nil> <nil> true [0xc000952008 0xc000952020 0xc000952038] [0xc000952008 0xc000952020 0xc000952038] [0xc000952018 0xc000952030] [0x92f8e0 0x92f8e0] 0xc002a12240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

May 25 01:35:47.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 25 01:35:47.953: INFO: rc: 1
May 25 01:35:47.953: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc000e52a80 exit status 1 <nil> <nil> true [0xc000952040 0xc000952078 0xc0009520c0] [0xc000952040 0xc000952078 0xc0009520c0] [0xc000952058 0xc0009520a8] [0x92f8e0 0x92f8e0] 0xc002a12540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

May 25 01:35:57.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 25 01:35:58.057: INFO: rc: 1
May 25 01:35:58.058: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc000e53170 exit status 1 <nil> <nil> true [0xc0009520d8 0xc0009520f8 0xc000952110] [0xc0009520d8 0xc0009520f8 0xc000952110] [0xc0009520f0 0xc000952108] [0x92f8e0 0x92f8e0] 0xc002a12840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

May 25 01:36:08.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 25 01:36:08.146: INFO: rc: 1
May 25 01:36:08.146: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc000e535c0 exit status 1 <nil> <nil> true [0xc000952118 0xc000952148 0xc0009521c8] [0xc000952118 0xc000952148 0xc0009521c8] [0xc000952140 0xc0009521a0] [0x92f8e0 0x92f8e0] 0xc002a12c00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

May 25 01:36:18.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 25 01:36:18.220: INFO: rc: 1
May 25 01:36:18.221: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0007ca3f0 exit status 1 <nil> <nil> true [0xc001ea4018 0xc001ea4058 0xc001ea4088] [0xc001ea4018 0xc001ea4058 0xc001ea4088] [0xc001ea4050 0xc001ea4078] [0x92f8e0 0x92f8e0] 0xc001ad4240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

May 25 01:36:28.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 25 01:36:28.298: INFO: rc: 1
May 25 01:36:28.298: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0007ca7e0 exit status 1 <nil> <nil> true [0xc001ea4090 0xc001ea40a8 0xc001ea40c0] [0xc001ea4090 0xc001ea40a8 0xc001ea40c0] [0xc001ea40a0 0xc001ea40b8] [0x92f8e0 0x92f8e0] 0xc001ad45a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

May 25 01:36:38.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 25 01:36:38.378: INFO: rc: 1
May 25 01:36:38.379: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc000e53aa0 exit status 1 <nil> <nil> true [0xc0009521d0 0xc0009521e8 0xc000952208] [0xc0009521d0 0xc0009521e8 0xc000952208] [0xc0009521e0 0xc0009521f8] [0x92f8e0 0x92f8e0] 0xc002a12f00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

May 25 01:36:48.379: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 25 01:36:48.471: INFO: rc: 1
May 25 01:36:48.472: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0007cabd0 exit status 1 <nil> <nil> true [0xc001ea40c8 0xc001ea40e8 0xc001ea4108] [0xc001ea40c8 0xc001ea40e8 0xc001ea4108] [0xc001ea40e0 0xc001ea4100] [0x92f8e0 0x92f8e0] 0xc001ad48a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

May 25 01:36:58.472: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 25 01:36:58.556: INFO: rc: 1
May 25 01:36:58.556: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc000e53f20 exit status 1 <nil> <nil> true [0xc000952210 0xc000952228 0xc000952240] [0xc000952210 0xc000952228 0xc000952240] [0xc000952220 0xc000952238] [0x92f8e0 0x92f8e0] 0xc002a13260 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

May 25 01:37:08.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 25 01:37:08.641: INFO: rc: 1
May 25 01:37:08.641: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0007cb1a0 exit status 1 <nil> <nil> true [0xc001ea4110 0xc001ea4128 0xc001ea4148] [0xc001ea4110 0xc001ea4128 0xc001ea4148] [0xc001ea4120 0xc001ea4140] [0x92f8e0 0x92f8e0] 0xc001ad4c00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

May 25 01:37:18.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 25 01:37:18.736: INFO: rc: 1
May 25 01:37:18.736: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001d4c630 exit status 1 <nil> <nil> true [0xc000952248 0xc000952260 0xc000952278] [0xc000952248 0xc000952260 0xc000952278] [0xc000952258 0xc000952270] [0x92f8e0 0x92f8e0] 0xc002a13560 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

May 25 01:37:28.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 25 01:37:28.829: INFO: rc: 1
May 25 01:37:28.829: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001d4cb40 exit status 1 <nil> <nil> true [0xc000952280 0xc000952298 0xc0009522b0] [0xc000952280 0xc000952298 0xc0009522b0] [0xc000952290 0xc0009522a8] [0x92f8e0 0x92f8e0] 0xc002a13860 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

May 25 01:37:38.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 25 01:37:38.920: INFO: rc: 1
May 25 01:37:38.921: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001d4cf30 exit status 1 <nil> <nil> true [0xc0009522c0 0xc0009522d8 0xc000952300] [0xc0009522c0 0xc0009522d8 0xc000952300] [0xc0009522d0 0xc0009522f8] [0x92f8e0 0x92f8e0] 0xc002a13b00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

May 25 01:37:48.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 25 01:37:49.002: INFO: rc: 1
May 25 01:37:49.002: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0007ca3c0 exit status 1 <nil> <nil> true [0xc001ea4018 0xc001ea4058 0xc001ea4088] [0xc001ea4018 0xc001ea4058 0xc001ea4088] [0xc001ea4050 0xc001ea4078] [0x92f8e0 0x92f8e0] 0xc001ad4240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

May 25 01:37:59.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 25 01:37:59.074: INFO: rc: 1
May 25 01:37:59.075: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc000e52570 exit status 1 <nil> <nil> true [0xc000952000 0xc000952018 0xc000952030] [0xc000952000 0xc000952018 0xc000952030] [0xc000952010 0xc000952028] [0x92f8e0 0x92f8e0] 0xc002a12240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

May 25 01:38:09.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 25 01:38:09.149: INFO: rc: 1
May 25 01:38:09.149: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc000e52a50 exit status 1 <nil> <nil> true [0xc000952038 0xc000952058 0xc0009520a8] [0xc000952038 0xc000952058 0xc0009520a8] [0xc000952048 0xc000952090] [0x92f8e0 0x92f8e0] 0xc002a12540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

May 25 01:38:19.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-mrn7c ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 25 01:38:19.230: INFO: rc: 1
May 25 01:38:19.230: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: 
May 25 01:38:19.230: INFO: Scaling statefulset ss to 0
May 25 01:38:19.238: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 25 01:38:19.240: INFO: Deleting all statefulset in ns e2e-tests-statefulset-mrn7c
May 25 01:38:19.242: INFO: Scaling statefulset ss to 0
May 25 01:38:19.248: INFO: Waiting for statefulset status.replicas updated to 0
May 25 01:38:19.250: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:38:19.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-mrn7c" for this suite.
May 25 01:38:25.277: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:38:25.312: INFO: namespace: e2e-tests-statefulset-mrn7c, resource: bindings, ignored listing per whitelist
May 25 01:38:25.367: INFO: namespace e2e-tests-statefulset-mrn7c deletion completed in 6.098236803s

• [SLOW TEST:370.207 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:38:25.367: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-cnnn4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-c9f586d3-7e8d-11e9-802f-027f94874578
STEP: Creating a pod to test consume configMaps
May 25 01:38:25.542: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c9f61df8-7e8d-11e9-802f-027f94874578" in namespace "e2e-tests-projected-cnnn4" to be "success or failure"
May 25 01:38:25.545: INFO: Pod "pod-projected-configmaps-c9f61df8-7e8d-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 2.847321ms
May 25 01:38:27.549: INFO: Pod "pod-projected-configmaps-c9f61df8-7e8d-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006734541s
STEP: Saw pod success
May 25 01:38:27.549: INFO: Pod "pod-projected-configmaps-c9f61df8-7e8d-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:38:27.558: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-projected-configmaps-c9f61df8-7e8d-11e9-802f-027f94874578 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 25 01:38:27.588: INFO: Waiting for pod pod-projected-configmaps-c9f61df8-7e8d-11e9-802f-027f94874578 to disappear
May 25 01:38:27.590: INFO: Pod pod-projected-configmaps-c9f61df8-7e8d-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:38:27.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cnnn4" for this suite.
May 25 01:38:33.603: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:38:33.656: INFO: namespace: e2e-tests-projected-cnnn4, resource: bindings, ignored listing per whitelist
May 25 01:38:33.694: INFO: namespace e2e-tests-projected-cnnn4 deletion completed in 6.099497901s

• [SLOW TEST:8.327 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:38:33.694: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-twdzq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 25 01:38:33.866: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ceebf03d-7e8d-11e9-802f-027f94874578" in namespace "e2e-tests-downward-api-twdzq" to be "success or failure"
May 25 01:38:33.879: INFO: Pod "downwardapi-volume-ceebf03d-7e8d-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 12.631365ms
May 25 01:38:35.882: INFO: Pod "downwardapi-volume-ceebf03d-7e8d-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015430481s
STEP: Saw pod success
May 25 01:38:35.882: INFO: Pod "downwardapi-volume-ceebf03d-7e8d-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:38:35.884: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod downwardapi-volume-ceebf03d-7e8d-11e9-802f-027f94874578 container client-container: <nil>
STEP: delete the pod
May 25 01:38:35.902: INFO: Waiting for pod downwardapi-volume-ceebf03d-7e8d-11e9-802f-027f94874578 to disappear
May 25 01:38:35.904: INFO: Pod downwardapi-volume-ceebf03d-7e8d-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:38:35.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-twdzq" for this suite.
May 25 01:38:41.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:38:41.987: INFO: namespace: e2e-tests-downward-api-twdzq, resource: bindings, ignored listing per whitelist
May 25 01:38:41.997: INFO: namespace e2e-tests-downward-api-twdzq deletion completed in 6.089835563s

• [SLOW TEST:8.303 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:38:42.003: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-hostpath-wd62s
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
May 25 01:38:42.181: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-wd62s" to be "success or failure"
May 25 01:38:42.186: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.59285ms
May 25 01:38:44.189: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007193961s
STEP: Saw pod success
May 25 01:38:44.189: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
May 25 01:38:44.191: INFO: Trying to get logs from node alex-400-cp1718-vsp2-worker00f2b167f8 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
May 25 01:38:44.210: INFO: Waiting for pod pod-host-path-test to disappear
May 25 01:38:44.212: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:38:44.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-wd62s" for this suite.
May 25 01:38:50.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:38:50.271: INFO: namespace: e2e-tests-hostpath-wd62s, resource: bindings, ignored listing per whitelist
May 25 01:38:50.317: INFO: namespace e2e-tests-hostpath-wd62s deletion completed in 6.10189989s

• [SLOW TEST:8.314 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:38:50.318: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-pjkh9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 25 01:38:50.483: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d8d3311a-7e8d-11e9-802f-027f94874578" in namespace "e2e-tests-downward-api-pjkh9" to be "success or failure"
May 25 01:38:50.498: INFO: Pod "downwardapi-volume-d8d3311a-7e8d-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 15.405549ms
May 25 01:38:52.502: INFO: Pod "downwardapi-volume-d8d3311a-7e8d-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01957453s
STEP: Saw pod success
May 25 01:38:52.502: INFO: Pod "downwardapi-volume-d8d3311a-7e8d-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:38:52.504: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod downwardapi-volume-d8d3311a-7e8d-11e9-802f-027f94874578 container client-container: <nil>
STEP: delete the pod
May 25 01:38:52.528: INFO: Waiting for pod downwardapi-volume-d8d3311a-7e8d-11e9-802f-027f94874578 to disappear
May 25 01:38:52.533: INFO: Pod downwardapi-volume-d8d3311a-7e8d-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:38:52.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-pjkh9" for this suite.
May 25 01:38:58.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:38:58.599: INFO: namespace: e2e-tests-downward-api-pjkh9, resource: bindings, ignored listing per whitelist
May 25 01:38:58.644: INFO: namespace e2e-tests-downward-api-pjkh9 deletion completed in 6.106066287s

• [SLOW TEST:8.327 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:38:58.645: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-xht9c
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
May 25 01:38:58.814: INFO: Waiting up to 5m0s for pod "client-containers-ddcaf376-7e8d-11e9-802f-027f94874578" in namespace "e2e-tests-containers-xht9c" to be "success or failure"
May 25 01:38:58.819: INFO: Pod "client-containers-ddcaf376-7e8d-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 4.801142ms
May 25 01:39:00.822: INFO: Pod "client-containers-ddcaf376-7e8d-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007293257s
May 25 01:39:02.823: INFO: Pod "client-containers-ddcaf376-7e8d-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009100417s
STEP: Saw pod success
May 25 01:39:02.823: INFO: Pod "client-containers-ddcaf376-7e8d-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:39:02.825: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod client-containers-ddcaf376-7e8d-11e9-802f-027f94874578 container test-container: <nil>
STEP: delete the pod
May 25 01:39:02.841: INFO: Waiting for pod client-containers-ddcaf376-7e8d-11e9-802f-027f94874578 to disappear
May 25 01:39:02.843: INFO: Pod client-containers-ddcaf376-7e8d-11e9-802f-027f94874578 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:39:02.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-xht9c" for this suite.
May 25 01:39:08.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:39:08.878: INFO: namespace: e2e-tests-containers-xht9c, resource: bindings, ignored listing per whitelist
May 25 01:39:08.948: INFO: namespace e2e-tests-containers-xht9c deletion completed in 6.101742145s

• [SLOW TEST:10.303 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:39:08.949: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-8qvrf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-e3ef518c-7e8d-11e9-802f-027f94874578
STEP: Creating a pod to test consume configMaps
May 25 01:39:09.122: INFO: Waiting up to 5m0s for pod "pod-configmaps-e3efe526-7e8d-11e9-802f-027f94874578" in namespace "e2e-tests-configmap-8qvrf" to be "success or failure"
May 25 01:39:09.127: INFO: Pod "pod-configmaps-e3efe526-7e8d-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 5.199682ms
May 25 01:39:11.130: INFO: Pod "pod-configmaps-e3efe526-7e8d-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007826463s
STEP: Saw pod success
May 25 01:39:11.130: INFO: Pod "pod-configmaps-e3efe526-7e8d-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:39:11.132: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-configmaps-e3efe526-7e8d-11e9-802f-027f94874578 container configmap-volume-test: <nil>
STEP: delete the pod
May 25 01:39:11.151: INFO: Waiting for pod pod-configmaps-e3efe526-7e8d-11e9-802f-027f94874578 to disappear
May 25 01:39:11.153: INFO: Pod pod-configmaps-e3efe526-7e8d-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:39:11.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-8qvrf" for this suite.
May 25 01:39:17.163: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:39:17.195: INFO: namespace: e2e-tests-configmap-8qvrf, resource: bindings, ignored listing per whitelist
May 25 01:39:17.237: INFO: namespace e2e-tests-configmap-8qvrf deletion completed in 6.081490113s

• [SLOW TEST:8.289 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:39:17.239: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-9gch8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 25 01:39:17.406: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e8dfc72c-7e8d-11e9-802f-027f94874578" in namespace "e2e-tests-downward-api-9gch8" to be "success or failure"
May 25 01:39:17.420: INFO: Pod "downwardapi-volume-e8dfc72c-7e8d-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 12.226263ms
May 25 01:39:19.423: INFO: Pod "downwardapi-volume-e8dfc72c-7e8d-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01555536s
STEP: Saw pod success
May 25 01:39:19.423: INFO: Pod "downwardapi-volume-e8dfc72c-7e8d-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:39:19.426: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod downwardapi-volume-e8dfc72c-7e8d-11e9-802f-027f94874578 container client-container: <nil>
STEP: delete the pod
May 25 01:39:19.447: INFO: Waiting for pod downwardapi-volume-e8dfc72c-7e8d-11e9-802f-027f94874578 to disappear
May 25 01:39:19.450: INFO: Pod downwardapi-volume-e8dfc72c-7e8d-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:39:19.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9gch8" for this suite.
May 25 01:39:25.462: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:39:25.524: INFO: namespace: e2e-tests-downward-api-9gch8, resource: bindings, ignored listing per whitelist
May 25 01:39:25.535: INFO: namespace e2e-tests-downward-api-9gch8 deletion completed in 6.081488479s

• [SLOW TEST:8.296 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:39:25.537: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-jk2r5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
May 25 01:39:25.698: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 25 01:39:25.706: INFO: Waiting for terminating namespaces to be deleted...
May 25 01:39:25.708: INFO: 
Logging pods the kubelet thinks is on node alex-400-cp1718-vsp2-worker00f2b167f8 before test
May 25 01:39:25.716: INFO: kube-proxy-gw2wq from kube-system started at 2019-05-24 23:16:19 +0000 UTC (1 container statuses recorded)
May 25 01:39:25.716: INFO: 	Container kube-proxy ready: true, restart count 0
May 25 01:39:25.716: INFO: metallb-speaker-s252f from ccp started at 2019-05-24 23:16:48 +0000 UTC (1 container statuses recorded)
May 25 01:39:25.716: INFO: 	Container speaker ready: true, restart count 0
May 25 01:39:25.716: INFO: sonobuoy from heptio-sonobuoy started at 2019-05-25 00:56:03 +0000 UTC (1 container statuses recorded)
May 25 01:39:25.716: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 25 01:39:25.716: INFO: calico-node-ln8pj from kube-system started at 2019-05-24 23:16:19 +0000 UTC (1 container statuses recorded)
May 25 01:39:25.716: INFO: 	Container calico-node ready: true, restart count 0
May 25 01:39:25.716: INFO: nginx-ingress-default-backend-7b7b5b4985-zth7k from ccp started at 2019-05-24 23:16:48 +0000 UTC (1 container statuses recorded)
May 25 01:39:25.716: INFO: 	Container nginx-ingress-default-backend ready: true, restart count 0
May 25 01:39:25.716: INFO: metallb-controller-78744dd4f-df8gm from ccp started at 2019-05-24 23:16:48 +0000 UTC (1 container statuses recorded)
May 25 01:39:25.716: INFO: 	Container controller ready: true, restart count 0
May 25 01:39:25.716: INFO: ccp-monitor-grafana-set-datasource-27gm4 from ccp started at 2019-05-24 23:16:57 +0000 UTC (1 container statuses recorded)
May 25 01:39:25.716: INFO: 	Container ccp-monitor-grafana-set-datasource ready: false, restart count 2
May 25 01:39:25.716: INFO: ccp-monitor-prometheus-pushgateway-db8b97744-7frml from ccp started at 2019-05-24 23:16:57 +0000 UTC (1 container statuses recorded)
May 25 01:39:25.716: INFO: 	Container prometheus-pushgateway ready: true, restart count 0
May 25 01:39:25.716: INFO: ccp-efk-kibana-7746ff6cdd-vg2vg from ccp started at 2019-05-24 23:16:58 +0000 UTC (1 container statuses recorded)
May 25 01:39:25.716: INFO: 	Container kibana ready: true, restart count 0
May 25 01:39:25.716: INFO: coredns-5d768868f-x48tv from kube-system started at 2019-05-24 23:16:45 +0000 UTC (1 container statuses recorded)
May 25 01:39:25.716: INFO: 	Container coredns ready: true, restart count 0
May 25 01:39:25.716: INFO: ccp-monitor-prometheus-node-exporter-xc6v8 from ccp started at 2019-05-24 23:16:56 +0000 UTC (1 container statuses recorded)
May 25 01:39:25.716: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
May 25 01:39:25.716: INFO: ccp-monitor-prometheus-alertmanager-689d9f95c6-qfbth from ccp started at 2019-05-24 23:16:56 +0000 UTC (2 container statuses recorded)
May 25 01:39:25.716: INFO: 	Container prometheus-alertmanager ready: true, restart count 0
May 25 01:39:25.716: INFO: 	Container prometheus-alertmanager-configmap-reload ready: true, restart count 0
May 25 01:39:25.716: INFO: nginx-ingress-controller-tkn4x from ccp started at 2019-05-24 23:16:48 +0000 UTC (1 container statuses recorded)
May 25 01:39:25.716: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
May 25 01:39:25.716: INFO: fluentd-es-v2.0.2-qtlkg from ccp started at 2019-05-24 23:16:58 +0000 UTC (1 container statuses recorded)
May 25 01:39:25.716: INFO: 	Container fluentd-es ready: true, restart count 0
May 25 01:39:25.716: INFO: ccp-monitor-grafana-684748f9d4-vk76c from ccp started at 2019-05-24 23:17:00 +0000 UTC (1 container statuses recorded)
May 25 01:39:25.716: INFO: 	Container grafana ready: true, restart count 0
May 25 01:39:25.716: INFO: calico-typha-59fdcbc755-6jn4r from kube-system started at 2019-05-24 23:16:29 +0000 UTC (1 container statuses recorded)
May 25 01:39:25.716: INFO: 	Container calico-typha ready: true, restart count 0
May 25 01:39:25.716: INFO: sonobuoy-systemd-logs-daemon-set-759a616327fd41b7-kvqs6 from heptio-sonobuoy started at 2019-05-25 00:56:06 +0000 UTC (2 container statuses recorded)
May 25 01:39:25.717: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 25 01:39:25.717: INFO: 	Container systemd-logs ready: true, restart count 0
May 25 01:39:25.717: INFO: 
Logging pods the kubelet thinks is on node alex-400-cp1718-vsp2-workere35c6c6a2b before test
May 25 01:39:25.723: INFO: kube-proxy-xslv4 from kube-system started at 2019-05-24 23:16:19 +0000 UTC (1 container statuses recorded)
May 25 01:39:25.723: INFO: 	Container kube-proxy ready: true, restart count 0
May 25 01:39:25.724: INFO: ccp-monitor-prometheus-node-exporter-ch87m from ccp started at 2019-05-24 23:16:56 +0000 UTC (1 container statuses recorded)
May 25 01:39:25.724: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
May 25 01:39:25.724: INFO: sonobuoy-systemd-logs-daemon-set-759a616327fd41b7-9bvtk from heptio-sonobuoy started at 2019-05-25 00:56:06 +0000 UTC (2 container statuses recorded)
May 25 01:39:25.724: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 25 01:39:25.724: INFO: 	Container systemd-logs ready: true, restart count 0
May 25 01:39:25.724: INFO: ccp-efk-elasticsearch-curator-1558746000-74q96 from ccp started at 2019-05-25 01:00:10 +0000 UTC (1 container statuses recorded)
May 25 01:39:25.725: INFO: 	Container elasticsearch-curator ready: false, restart count 0
May 25 01:39:25.725: INFO: nginx-ingress-controller-772hp from ccp started at 2019-05-24 23:16:48 +0000 UTC (1 container statuses recorded)
May 25 01:39:25.725: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
May 25 01:39:25.725: INFO: ccp-monitor-prometheus-kube-state-metrics-7cdd89dbbf-zpwzt from ccp started at 2019-05-24 23:16:57 +0000 UTC (1 container statuses recorded)
May 25 01:39:25.725: INFO: 	Container prometheus-kube-state-metrics ready: true, restart count 0
May 25 01:39:25.725: INFO: elasticsearch-logging-0 from ccp started at 2019-05-24 23:17:01 +0000 UTC (1 container statuses recorded)
May 25 01:39:25.725: INFO: 	Container elasticsearch-logging ready: true, restart count 0
May 25 01:39:25.725: INFO: coredns-5d768868f-ghkvd from kube-system started at 2019-05-24 23:16:45 +0000 UTC (1 container statuses recorded)
May 25 01:39:25.725: INFO: 	Container coredns ready: true, restart count 0
May 25 01:39:25.725: INFO: cert-manager-5f9c44cd46-xttzw from ccp started at 2019-05-24 23:16:38 +0000 UTC (1 container statuses recorded)
May 25 01:39:25.725: INFO: 	Container cert-manager ready: true, restart count 0
May 25 01:39:25.725: INFO: calico-node-8jh64 from kube-system started at 2019-05-24 23:16:19 +0000 UTC (1 container statuses recorded)
May 25 01:39:25.726: INFO: 	Container calico-node ready: true, restart count 0
May 25 01:39:25.726: INFO: ccp-monitor-prometheus-server-5cb4549d87-98vp8 from ccp started at 2019-05-24 23:16:57 +0000 UTC (3 container statuses recorded)
May 25 01:39:25.726: INFO: 	Container nginx-proxy ready: true, restart count 0
May 25 01:39:25.726: INFO: 	Container prometheus-server ready: true, restart count 0
May 25 01:39:25.726: INFO: 	Container prometheus-server-configmap-reload ready: true, restart count 0
May 25 01:39:25.726: INFO: kubernetes-dashboard-548b88c5d8-44vhs from ccp started at 2019-05-24 23:16:50 +0000 UTC (1 container statuses recorded)
May 25 01:39:25.726: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 25 01:39:25.726: INFO: fluentd-es-v2.0.2-6mb7h from ccp started at 2019-05-24 23:16:58 +0000 UTC (1 container statuses recorded)
May 25 01:39:25.726: INFO: 	Container fluentd-es ready: true, restart count 0
May 25 01:39:25.726: INFO: calico-typha-59fdcbc755-z6pj6 from kube-system started at 2019-05-24 23:16:29 +0000 UTC (1 container statuses recorded)
May 25 01:39:25.726: INFO: 	Container calico-typha ready: true, restart count 0
May 25 01:39:25.727: INFO: metallb-speaker-rbdjd from ccp started at 2019-05-24 23:16:48 +0000 UTC (1 container statuses recorded)
May 25 01:39:25.727: INFO: 	Container speaker ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15a1c9614a6e064a], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:39:26.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-jk2r5" for this suite.
May 25 01:39:32.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:39:32.828: INFO: namespace: e2e-tests-sched-pred-jk2r5, resource: bindings, ignored listing per whitelist
May 25 01:39:32.847: INFO: namespace e2e-tests-sched-pred-jk2r5 deletion completed in 6.089432855s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.311 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:39:32.847: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-9ps9q
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
May 25 01:39:33.019: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

May 25 01:39:33.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 create -f - --namespace=e2e-tests-kubectl-9ps9q'
May 25 01:39:33.448: INFO: stderr: ""
May 25 01:39:33.448: INFO: stdout: "service/redis-slave created\n"
May 25 01:39:33.449: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

May 25 01:39:33.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 create -f - --namespace=e2e-tests-kubectl-9ps9q'
May 25 01:39:33.668: INFO: stderr: ""
May 25 01:39:33.668: INFO: stdout: "service/redis-master created\n"
May 25 01:39:33.668: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

May 25 01:39:33.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 create -f - --namespace=e2e-tests-kubectl-9ps9q'
May 25 01:39:33.897: INFO: stderr: ""
May 25 01:39:33.897: INFO: stdout: "service/frontend created\n"
May 25 01:39:33.897: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

May 25 01:39:33.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 create -f - --namespace=e2e-tests-kubectl-9ps9q'
May 25 01:39:34.122: INFO: stderr: ""
May 25 01:39:34.122: INFO: stdout: "deployment.extensions/frontend created\n"
May 25 01:39:34.122: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

May 25 01:39:34.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 create -f - --namespace=e2e-tests-kubectl-9ps9q'
May 25 01:39:34.366: INFO: stderr: ""
May 25 01:39:34.366: INFO: stdout: "deployment.extensions/redis-master created\n"
May 25 01:39:34.366: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

May 25 01:39:34.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 create -f - --namespace=e2e-tests-kubectl-9ps9q'
May 25 01:39:34.592: INFO: stderr: ""
May 25 01:39:34.592: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
May 25 01:39:34.592: INFO: Waiting for all frontend pods to be Running.
May 25 01:39:49.643: INFO: Waiting for frontend to serve content.
May 25 01:39:49.658: INFO: Trying to add a new entry to the guestbook.
May 25 01:39:49.670: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
May 25 01:39:49.678: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-9ps9q'
May 25 01:39:49.804: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 25 01:39:49.804: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
May 25 01:39:49.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-9ps9q'
May 25 01:39:49.957: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 25 01:39:49.957: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
May 25 01:39:49.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-9ps9q'
May 25 01:39:50.072: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 25 01:39:50.072: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
May 25 01:39:50.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-9ps9q'
May 25 01:39:50.203: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 25 01:39:50.203: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
May 25 01:39:50.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-9ps9q'
May 25 01:39:50.355: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 25 01:39:50.355: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
May 25 01:39:50.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-9ps9q'
May 25 01:39:50.486: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 25 01:39:50.486: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:39:50.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9ps9q" for this suite.
May 25 01:40:30.508: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:40:30.585: INFO: namespace: e2e-tests-kubectl-9ps9q, resource: bindings, ignored listing per whitelist
May 25 01:40:30.591: INFO: namespace e2e-tests-kubectl-9ps9q deletion completed in 40.091844569s

• [SLOW TEST:57.744 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:40:30.595: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-v29rv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
May 25 01:40:33.302: INFO: Successfully updated pod "annotationupdate149ae579-7e8e-11e9-802f-027f94874578"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:40:37.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-v29rv" for this suite.
May 25 01:40:59.337: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:40:59.429: INFO: namespace: e2e-tests-downward-api-v29rv, resource: bindings, ignored listing per whitelist
May 25 01:40:59.429: INFO: namespace e2e-tests-downward-api-v29rv deletion completed in 22.102787402s

• [SLOW TEST:28.835 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:40:59.430: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-4j657
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 25 01:40:59.596: INFO: Waiting up to 5m0s for pod "downwardapi-volume-25c8581f-7e8e-11e9-802f-027f94874578" in namespace "e2e-tests-projected-4j657" to be "success or failure"
May 25 01:40:59.599: INFO: Pod "downwardapi-volume-25c8581f-7e8e-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 2.872616ms
May 25 01:41:01.601: INFO: Pod "downwardapi-volume-25c8581f-7e8e-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00553521s
STEP: Saw pod success
May 25 01:41:01.601: INFO: Pod "downwardapi-volume-25c8581f-7e8e-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:41:01.604: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod downwardapi-volume-25c8581f-7e8e-11e9-802f-027f94874578 container client-container: <nil>
STEP: delete the pod
May 25 01:41:01.619: INFO: Waiting for pod downwardapi-volume-25c8581f-7e8e-11e9-802f-027f94874578 to disappear
May 25 01:41:01.622: INFO: Pod downwardapi-volume-25c8581f-7e8e-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:41:01.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4j657" for this suite.
May 25 01:41:07.632: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:41:07.646: INFO: namespace: e2e-tests-projected-4j657, resource: bindings, ignored listing per whitelist
May 25 01:41:07.702: INFO: namespace e2e-tests-projected-4j657 deletion completed in 6.077864564s

• [SLOW TEST:8.273 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:41:07.705: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-cgcb2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
May 25 01:41:07.916: INFO: Waiting up to 5m0s for pod "pod-2abe1a21-7e8e-11e9-802f-027f94874578" in namespace "e2e-tests-emptydir-cgcb2" to be "success or failure"
May 25 01:41:07.919: INFO: Pod "pod-2abe1a21-7e8e-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 3.176222ms
May 25 01:41:09.922: INFO: Pod "pod-2abe1a21-7e8e-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005738101s
STEP: Saw pod success
May 25 01:41:09.922: INFO: Pod "pod-2abe1a21-7e8e-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:41:09.924: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-2abe1a21-7e8e-11e9-802f-027f94874578 container test-container: <nil>
STEP: delete the pod
May 25 01:41:09.944: INFO: Waiting for pod pod-2abe1a21-7e8e-11e9-802f-027f94874578 to disappear
May 25 01:41:09.946: INFO: Pod pod-2abe1a21-7e8e-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:41:09.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-cgcb2" for this suite.
May 25 01:41:15.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:41:15.981: INFO: namespace: e2e-tests-emptydir-cgcb2, resource: bindings, ignored listing per whitelist
May 25 01:41:16.038: INFO: namespace e2e-tests-emptydir-cgcb2 deletion completed in 6.088526875s

• [SLOW TEST:8.333 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:41:16.040: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-8hvcm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
May 25 01:41:18.727: INFO: Successfully updated pod "pod-update-2faf73b3-7e8e-11e9-802f-027f94874578"
STEP: verifying the updated pod is in kubernetes
May 25 01:41:18.732: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:41:18.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-8hvcm" for this suite.
May 25 01:41:40.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:41:40.781: INFO: namespace: e2e-tests-pods-8hvcm, resource: bindings, ignored listing per whitelist
May 25 01:41:40.833: INFO: namespace e2e-tests-pods-8hvcm deletion completed in 22.096667793s

• [SLOW TEST:24.794 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:41:40.834: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-686df
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
May 25 01:41:41.010: INFO: Waiting up to 5m0s for pod "pod-3e78231a-7e8e-11e9-802f-027f94874578" in namespace "e2e-tests-emptydir-686df" to be "success or failure"
May 25 01:41:41.017: INFO: Pod "pod-3e78231a-7e8e-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 7.004927ms
May 25 01:41:43.019: INFO: Pod "pod-3e78231a-7e8e-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009280769s
STEP: Saw pod success
May 25 01:41:43.019: INFO: Pod "pod-3e78231a-7e8e-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:41:43.021: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-3e78231a-7e8e-11e9-802f-027f94874578 container test-container: <nil>
STEP: delete the pod
May 25 01:41:43.043: INFO: Waiting for pod pod-3e78231a-7e8e-11e9-802f-027f94874578 to disappear
May 25 01:41:43.045: INFO: Pod pod-3e78231a-7e8e-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:41:43.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-686df" for this suite.
May 25 01:41:49.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:41:49.118: INFO: namespace: e2e-tests-emptydir-686df, resource: bindings, ignored listing per whitelist
May 25 01:41:49.127: INFO: namespace e2e-tests-emptydir-686df deletion completed in 6.0789945s

• [SLOW TEST:8.294 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:41:49.127: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-qcw8t
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 25 01:41:49.302: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
May 25 01:41:49.308: INFO: Number of nodes with available pods: 0
May 25 01:41:49.309: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
May 25 01:41:49.336: INFO: Number of nodes with available pods: 0
May 25 01:41:49.336: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:41:50.339: INFO: Number of nodes with available pods: 0
May 25 01:41:50.339: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:41:51.339: INFO: Number of nodes with available pods: 1
May 25 01:41:51.339: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
May 25 01:41:51.359: INFO: Number of nodes with available pods: 1
May 25 01:41:51.359: INFO: Number of running nodes: 0, number of available pods: 1
May 25 01:41:52.364: INFO: Number of nodes with available pods: 0
May 25 01:41:52.364: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
May 25 01:41:52.382: INFO: Number of nodes with available pods: 0
May 25 01:41:52.382: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:41:53.385: INFO: Number of nodes with available pods: 0
May 25 01:41:53.385: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:41:54.385: INFO: Number of nodes with available pods: 0
May 25 01:41:54.385: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:41:55.386: INFO: Number of nodes with available pods: 0
May 25 01:41:55.386: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:41:56.384: INFO: Number of nodes with available pods: 0
May 25 01:41:56.385: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:41:57.385: INFO: Number of nodes with available pods: 0
May 25 01:41:57.385: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:41:58.385: INFO: Number of nodes with available pods: 0
May 25 01:41:58.385: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:41:59.385: INFO: Number of nodes with available pods: 0
May 25 01:41:59.385: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:42:00.389: INFO: Number of nodes with available pods: 0
May 25 01:42:00.389: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:42:01.385: INFO: Number of nodes with available pods: 0
May 25 01:42:01.385: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:42:02.385: INFO: Number of nodes with available pods: 0
May 25 01:42:02.385: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:42:03.385: INFO: Number of nodes with available pods: 0
May 25 01:42:03.385: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:42:04.385: INFO: Number of nodes with available pods: 0
May 25 01:42:04.385: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:42:05.386: INFO: Number of nodes with available pods: 0
May 25 01:42:05.386: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:42:06.385: INFO: Number of nodes with available pods: 0
May 25 01:42:06.385: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:42:07.385: INFO: Number of nodes with available pods: 0
May 25 01:42:07.385: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:42:08.385: INFO: Number of nodes with available pods: 0
May 25 01:42:08.385: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:42:09.385: INFO: Number of nodes with available pods: 0
May 25 01:42:09.385: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:42:10.386: INFO: Number of nodes with available pods: 0
May 25 01:42:10.387: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:42:11.385: INFO: Number of nodes with available pods: 0
May 25 01:42:11.385: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:42:12.385: INFO: Number of nodes with available pods: 0
May 25 01:42:12.385: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:42:13.385: INFO: Number of nodes with available pods: 0
May 25 01:42:13.385: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:42:14.385: INFO: Number of nodes with available pods: 0
May 25 01:42:14.385: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:42:15.386: INFO: Number of nodes with available pods: 0
May 25 01:42:15.386: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:42:16.385: INFO: Number of nodes with available pods: 0
May 25 01:42:16.385: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:42:17.385: INFO: Number of nodes with available pods: 0
May 25 01:42:17.385: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:42:18.385: INFO: Number of nodes with available pods: 0
May 25 01:42:18.385: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:42:19.385: INFO: Number of nodes with available pods: 0
May 25 01:42:19.385: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:42:20.385: INFO: Number of nodes with available pods: 0
May 25 01:42:20.385: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:42:21.385: INFO: Number of nodes with available pods: 0
May 25 01:42:21.385: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:42:22.385: INFO: Number of nodes with available pods: 0
May 25 01:42:22.385: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:42:23.385: INFO: Number of nodes with available pods: 0
May 25 01:42:23.385: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:42:24.385: INFO: Number of nodes with available pods: 0
May 25 01:42:24.385: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:42:25.385: INFO: Number of nodes with available pods: 0
May 25 01:42:25.385: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:42:26.385: INFO: Number of nodes with available pods: 0
May 25 01:42:26.385: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:42:27.385: INFO: Number of nodes with available pods: 0
May 25 01:42:27.385: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:42:28.385: INFO: Number of nodes with available pods: 0
May 25 01:42:28.385: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:42:29.385: INFO: Number of nodes with available pods: 0
May 25 01:42:29.385: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:42:30.385: INFO: Number of nodes with available pods: 0
May 25 01:42:30.385: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:42:31.385: INFO: Number of nodes with available pods: 1
May 25 01:42:31.385: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-qcw8t, will wait for the garbage collector to delete the pods
May 25 01:42:31.453: INFO: Deleting DaemonSet.extensions daemon-set took: 9.866706ms
May 25 01:42:31.553: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.256558ms
May 25 01:43:04.856: INFO: Number of nodes with available pods: 0
May 25 01:43:04.856: INFO: Number of running nodes: 0, number of available pods: 0
May 25 01:43:04.858: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-qcw8t/daemonsets","resourceVersion":"20644"},"items":null}

May 25 01:43:04.865: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-qcw8t/pods","resourceVersion":"20644"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:43:04.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-qcw8t" for this suite.
May 25 01:43:10.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:43:10.909: INFO: namespace: e2e-tests-daemonsets-qcw8t, resource: bindings, ignored listing per whitelist
May 25 01:43:10.976: INFO: namespace e2e-tests-daemonsets-qcw8t deletion completed in 6.086542564s

• [SLOW TEST:81.848 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:43:10.976: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-events-v4ngb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
May 25 01:43:13.154: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-743133fa-7e8e-11e9-802f-027f94874578,GenerateName:,Namespace:e2e-tests-events-v4ngb,SelfLink:/api/v1/namespaces/e2e-tests-events-v4ngb/pods/send-events-743133fa-7e8e-11e9-802f-027f94874578,UID:7431bc99-7e8e-11e9-ba33-0050569e7ba0,ResourceVersion:20692,Generation:0,CreationTimestamp:2019-05-25 01:43:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 134827394,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.122/32,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ztxsq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ztxsq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-ztxsq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-400-cp1718-vsp2-workere35c6c6a2b,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c432d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c432f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:43:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:43:13 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:43:13 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 01:43:11 +0000 UTC  }],Message:,Reason:,HostIP:10.10.103.184,PodIP:192.168.1.122,StartTime:2019-05-25 01:43:11 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-05-25 01:43:12 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://20330645755d8776f7729b823d6cac355e8e36243dc2033e804aa1f446f49027}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
May 25 01:43:15.157: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
May 25 01:43:17.161: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:43:17.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-v4ngb" for this suite.
May 25 01:43:55.180: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:43:55.242: INFO: namespace: e2e-tests-events-v4ngb, resource: bindings, ignored listing per whitelist
May 25 01:43:55.267: INFO: namespace e2e-tests-events-v4ngb deletion completed in 38.094464171s

• [SLOW TEST:44.291 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:43:55.268: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-kkpll
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-8e98d866-7e8e-11e9-802f-027f94874578
STEP: Creating a pod to test consume secrets
May 25 01:43:55.445: INFO: Waiting up to 5m0s for pod "pod-secrets-8e99758d-7e8e-11e9-802f-027f94874578" in namespace "e2e-tests-secrets-kkpll" to be "success or failure"
May 25 01:43:55.451: INFO: Pod "pod-secrets-8e99758d-7e8e-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 6.024591ms
May 25 01:43:57.454: INFO: Pod "pod-secrets-8e99758d-7e8e-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008854589s
STEP: Saw pod success
May 25 01:43:57.454: INFO: Pod "pod-secrets-8e99758d-7e8e-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:43:57.456: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-secrets-8e99758d-7e8e-11e9-802f-027f94874578 container secret-volume-test: <nil>
STEP: delete the pod
May 25 01:43:57.478: INFO: Waiting for pod pod-secrets-8e99758d-7e8e-11e9-802f-027f94874578 to disappear
May 25 01:43:57.481: INFO: Pod pod-secrets-8e99758d-7e8e-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:43:57.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-kkpll" for this suite.
May 25 01:44:03.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:44:03.505: INFO: namespace: e2e-tests-secrets-kkpll, resource: bindings, ignored listing per whitelist
May 25 01:44:03.567: INFO: namespace e2e-tests-secrets-kkpll deletion completed in 6.082286965s

• [SLOW TEST:8.300 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:44:03.574: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-tg7w8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
May 25 01:44:03.743: INFO: Waiting up to 5m0s for pod "pod-938bafef-7e8e-11e9-802f-027f94874578" in namespace "e2e-tests-emptydir-tg7w8" to be "success or failure"
May 25 01:44:03.746: INFO: Pod "pod-938bafef-7e8e-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 2.2928ms
May 25 01:44:05.749: INFO: Pod "pod-938bafef-7e8e-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005688429s
May 25 01:44:07.759: INFO: Pod "pod-938bafef-7e8e-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015078752s
STEP: Saw pod success
May 25 01:44:07.759: INFO: Pod "pod-938bafef-7e8e-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:44:07.761: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-938bafef-7e8e-11e9-802f-027f94874578 container test-container: <nil>
STEP: delete the pod
May 25 01:44:07.778: INFO: Waiting for pod pod-938bafef-7e8e-11e9-802f-027f94874578 to disappear
May 25 01:44:07.779: INFO: Pod pod-938bafef-7e8e-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:44:07.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-tg7w8" for this suite.
May 25 01:44:13.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:44:13.822: INFO: namespace: e2e-tests-emptydir-tg7w8, resource: bindings, ignored listing per whitelist
May 25 01:44:13.888: INFO: namespace e2e-tests-emptydir-tg7w8 deletion completed in 6.10509468s

• [SLOW TEST:10.315 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:44:13.891: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-sbjld
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-99b15c86-7e8e-11e9-802f-027f94874578
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-99b15c86-7e8e-11e9-802f-027f94874578
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:44:18.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sbjld" for this suite.
May 25 01:44:40.113: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:44:40.202: INFO: namespace: e2e-tests-projected-sbjld, resource: bindings, ignored listing per whitelist
May 25 01:44:40.206: INFO: namespace e2e-tests-projected-sbjld deletion completed in 22.101800268s

• [SLOW TEST:26.316 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:44:40.207: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-gttks
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
May 25 01:44:40.392: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:44:43.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-gttks" for this suite.
May 25 01:44:49.163: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:44:49.185: INFO: namespace: e2e-tests-init-container-gttks, resource: bindings, ignored listing per whitelist
May 25 01:44:49.292: INFO: namespace e2e-tests-init-container-gttks deletion completed in 6.138696807s

• [SLOW TEST:9.086 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:44:49.293: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-66sgx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-66sgx A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-66sgx;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-66sgx A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-66sgx;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-66sgx.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-66sgx.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-66sgx.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-66sgx.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-66sgx.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-66sgx.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-66sgx.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-66sgx.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-66sgx.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 190.197.107.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.107.197.190_udp@PTR;check="$$(dig +tcp +noall +answer +search 190.197.107.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.107.197.190_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-66sgx A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-66sgx;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-66sgx A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-66sgx;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-66sgx.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-66sgx.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-66sgx.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-66sgx.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-66sgx.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-66sgx.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-66sgx.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-66sgx.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-66sgx.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 190.197.107.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.107.197.190_udp@PTR;check="$$(dig +tcp +noall +answer +search 190.197.107.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.107.197.190_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 25 01:44:51.510: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:44:51.524: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:44:51.545: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:44:51.548: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:44:51.551: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-66sgx from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:44:51.555: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-66sgx from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:44:51.557: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-66sgx.svc from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:44:51.571: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-66sgx.svc from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:44:51.574: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:44:51.577: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:44:51.591: INFO: Lookups using e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578 failed for: [wheezy_udp@dns-test-service wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-66sgx jessie_tcp@dns-test-service.e2e-tests-dns-66sgx jessie_udp@dns-test-service.e2e-tests-dns-66sgx.svc jessie_tcp@dns-test-service.e2e-tests-dns-66sgx.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc]

May 25 01:44:56.607: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:44:56.627: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:44:56.630: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:44:56.632: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-66sgx from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:44:56.635: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-66sgx from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:44:56.637: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-66sgx.svc from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:44:56.639: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-66sgx.svc from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:44:56.642: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:44:56.644: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:44:56.659: INFO: Lookups using e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578 failed for: [wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-66sgx jessie_tcp@dns-test-service.e2e-tests-dns-66sgx jessie_udp@dns-test-service.e2e-tests-dns-66sgx.svc jessie_tcp@dns-test-service.e2e-tests-dns-66sgx.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc]

May 25 01:45:01.610: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:45:01.628: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:45:01.630: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:45:01.632: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-66sgx from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:45:01.634: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-66sgx from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:45:01.637: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-66sgx.svc from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:45:01.640: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-66sgx.svc from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:45:01.642: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:45:01.645: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:45:01.659: INFO: Lookups using e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578 failed for: [wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-66sgx jessie_tcp@dns-test-service.e2e-tests-dns-66sgx jessie_udp@dns-test-service.e2e-tests-dns-66sgx.svc jessie_tcp@dns-test-service.e2e-tests-dns-66sgx.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc]

May 25 01:45:06.607: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:45:06.628: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:45:06.633: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:45:06.636: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-66sgx from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:45:06.639: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-66sgx from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:45:06.642: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-66sgx.svc from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:45:06.644: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-66sgx.svc from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:45:06.647: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:45:06.650: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:45:06.664: INFO: Lookups using e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578 failed for: [wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-66sgx jessie_tcp@dns-test-service.e2e-tests-dns-66sgx jessie_udp@dns-test-service.e2e-tests-dns-66sgx.svc jessie_tcp@dns-test-service.e2e-tests-dns-66sgx.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc]

May 25 01:45:11.608: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:45:11.626: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:45:11.628: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:45:11.630: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-66sgx from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:45:11.632: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-66sgx from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:45:11.635: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-66sgx.svc from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:45:11.637: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-66sgx.svc from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:45:11.639: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:45:11.641: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:45:11.661: INFO: Lookups using e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578 failed for: [wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-66sgx jessie_tcp@dns-test-service.e2e-tests-dns-66sgx jessie_udp@dns-test-service.e2e-tests-dns-66sgx.svc jessie_tcp@dns-test-service.e2e-tests-dns-66sgx.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc]

May 25 01:45:16.609: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:45:16.629: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:45:16.633: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:45:16.635: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-66sgx from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:45:16.639: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-66sgx from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:45:16.641: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-66sgx.svc from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:45:16.645: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-66sgx.svc from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:45:16.652: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:45:16.656: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc from pod e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578: the server could not find the requested resource (get pods dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578)
May 25 01:45:16.670: INFO: Lookups using e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578 failed for: [wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-66sgx jessie_tcp@dns-test-service.e2e-tests-dns-66sgx jessie_udp@dns-test-service.e2e-tests-dns-66sgx.svc jessie_tcp@dns-test-service.e2e-tests-dns-66sgx.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-66sgx.svc]

May 25 01:45:21.654: INFO: DNS probes using e2e-tests-dns-66sgx/dns-test-aecfb1f0-7e8e-11e9-802f-027f94874578 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:45:21.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-66sgx" for this suite.
May 25 01:45:27.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:45:27.803: INFO: namespace: e2e-tests-dns-66sgx, resource: bindings, ignored listing per whitelist
May 25 01:45:27.827: INFO: namespace e2e-tests-dns-66sgx deletion completed in 6.094808605s

• [SLOW TEST:38.535 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:45:27.833: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-w9q88
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0525 01:45:38.017761      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 25 01:45:38.017: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:45:38.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-w9q88" for this suite.
May 25 01:45:44.029: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:45:44.081: INFO: namespace: e2e-tests-gc-w9q88, resource: bindings, ignored listing per whitelist
May 25 01:45:44.126: INFO: namespace e2e-tests-gc-w9q88 deletion completed in 6.104649611s

• [SLOW TEST:16.293 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:45:44.127: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-tvr5c
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
May 25 01:45:46.885: INFO: Successfully updated pod "labelsupdatecf7f2d2d-7e8e-11e9-802f-027f94874578"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:45:48.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tvr5c" for this suite.
May 25 01:46:10.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:46:10.976: INFO: namespace: e2e-tests-projected-tvr5c, resource: bindings, ignored listing per whitelist
May 25 01:46:10.989: INFO: namespace e2e-tests-projected-tvr5c deletion completed in 22.087322203s

• [SLOW TEST:26.862 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:46:10.991: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-jj8mf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
May 25 01:46:11.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 --namespace=e2e-tests-kubectl-jj8mf run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
May 25 01:46:12.402: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
May 25 01:46:12.402: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:46:14.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jj8mf" for this suite.
May 25 01:46:20.416: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:46:20.475: INFO: namespace: e2e-tests-kubectl-jj8mf, resource: bindings, ignored listing per whitelist
May 25 01:46:20.511: INFO: namespace e2e-tests-kubectl-jj8mf deletion completed in 6.102021297s

• [SLOW TEST:9.520 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:46:20.512: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-rmzgn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-rmzgn
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
May 25 01:46:20.688: INFO: Found 0 stateful pods, waiting for 3
May 25 01:46:30.692: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 25 01:46:30.692: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 25 01:46:30.692: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
May 25 01:46:30.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-rmzgn ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 25 01:46:30.848: INFO: stderr: ""
May 25 01:46:30.848: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 25 01:46:30.848: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
May 25 01:46:40.875: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
May 25 01:46:50.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-rmzgn ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 25 01:46:51.046: INFO: stderr: ""
May 25 01:46:51.046: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 25 01:46:51.046: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 25 01:47:01.062: INFO: Waiting for StatefulSet e2e-tests-statefulset-rmzgn/ss2 to complete update
May 25 01:47:01.062: INFO: Waiting for Pod e2e-tests-statefulset-rmzgn/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
May 25 01:47:11.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-rmzgn ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 25 01:47:11.201: INFO: stderr: ""
May 25 01:47:11.201: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 25 01:47:11.201: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 25 01:47:21.227: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
May 25 01:47:31.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-rmzgn ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 25 01:47:31.385: INFO: stderr: ""
May 25 01:47:31.385: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 25 01:47:31.385: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 25 01:47:51.400: INFO: Waiting for StatefulSet e2e-tests-statefulset-rmzgn/ss2 to complete update
May 25 01:47:51.400: INFO: Waiting for Pod e2e-tests-statefulset-rmzgn/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 25 01:48:01.406: INFO: Deleting all statefulset in ns e2e-tests-statefulset-rmzgn
May 25 01:48:01.408: INFO: Scaling statefulset ss2 to 0
May 25 01:48:11.430: INFO: Waiting for statefulset status.replicas updated to 0
May 25 01:48:11.432: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:48:11.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-rmzgn" for this suite.
May 25 01:48:17.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:48:17.532: INFO: namespace: e2e-tests-statefulset-rmzgn, resource: bindings, ignored listing per whitelist
May 25 01:48:17.540: INFO: namespace e2e-tests-statefulset-rmzgn deletion completed in 6.080581509s

• [SLOW TEST:117.029 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:48:17.542: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-ndffh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
May 25 01:48:19.737: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-2aed564e-7e8f-11e9-802f-027f94874578", GenerateName:"", Namespace:"e2e-tests-pods-ndffh", SelfLink:"/api/v1/namespaces/e2e-tests-pods-ndffh/pods/pod-submit-remove-2aed564e-7e8f-11e9-802f-027f94874578", UID:"2aee3aae-7e8f-11e9-ba33-0050569e7ba0", ResourceVersion:"21858", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63694345697, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"713117071"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"192.168.1.135/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-btchh", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001727340), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-btchh", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001589298), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"alex-400-cp1718-vsp2-workere35c6c6a2b", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001884f60), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0015892d0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0015892f0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0015892f8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0015892fc)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694345698, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694345700, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694345700, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694345697, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.10.103.184", PodIP:"192.168.1.135", StartTime:(*v1.Time)(0xc000ee1340), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc000ee1360), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7", ContainerID:"docker://07533a444d58b436385bc9ad406507542c08f0d9f6bdae56f66369b24839786f"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:48:28.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-ndffh" for this suite.
May 25 01:48:34.457: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:48:34.525: INFO: namespace: e2e-tests-pods-ndffh, resource: bindings, ignored listing per whitelist
May 25 01:48:34.530: INFO: namespace e2e-tests-pods-ndffh deletion completed in 6.080968466s

• [SLOW TEST:16.988 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:48:34.532: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-8lw6v
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 25 01:48:34.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-8lw6v'
May 25 01:48:34.809: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 25 01:48:34.809: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
May 25 01:48:34.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-8lw6v'
May 25 01:48:34.939: INFO: stderr: ""
May 25 01:48:34.939: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:48:34.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8lw6v" for this suite.
May 25 01:48:40.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:48:40.999: INFO: namespace: e2e-tests-kubectl-8lw6v, resource: bindings, ignored listing per whitelist
May 25 01:48:41.030: INFO: namespace e2e-tests-kubectl-8lw6v deletion completed in 6.082850757s

• [SLOW TEST:6.498 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:48:41.033: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-runtime-rxwls
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:49:04.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-rxwls" for this suite.
May 25 01:49:10.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:49:10.440: INFO: namespace: e2e-tests-container-runtime-rxwls, resource: bindings, ignored listing per whitelist
May 25 01:49:10.454: INFO: namespace e2e-tests-container-runtime-rxwls deletion completed in 6.095620806s

• [SLOW TEST:29.422 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:49:10.455: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-vb4xx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:49:10.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-vb4xx" for this suite.
May 25 01:49:32.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:49:32.711: INFO: namespace: e2e-tests-pods-vb4xx, resource: bindings, ignored listing per whitelist
May 25 01:49:32.751: INFO: namespace e2e-tests-pods-vb4xx deletion completed in 22.087813095s

• [SLOW TEST:22.296 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:49:32.752: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-khgm9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-57c133da-7e8f-11e9-802f-027f94874578
STEP: Creating a pod to test consume secrets
May 25 01:49:32.933: INFO: Waiting up to 5m0s for pod "pod-secrets-57c1b782-7e8f-11e9-802f-027f94874578" in namespace "e2e-tests-secrets-khgm9" to be "success or failure"
May 25 01:49:32.938: INFO: Pod "pod-secrets-57c1b782-7e8f-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 2.62452ms
May 25 01:49:34.941: INFO: Pod "pod-secrets-57c1b782-7e8f-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005576693s
STEP: Saw pod success
May 25 01:49:34.941: INFO: Pod "pod-secrets-57c1b782-7e8f-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:49:34.943: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-secrets-57c1b782-7e8f-11e9-802f-027f94874578 container secret-volume-test: <nil>
STEP: delete the pod
May 25 01:49:34.960: INFO: Waiting for pod pod-secrets-57c1b782-7e8f-11e9-802f-027f94874578 to disappear
May 25 01:49:34.963: INFO: Pod pod-secrets-57c1b782-7e8f-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:49:34.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-khgm9" for this suite.
May 25 01:49:40.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:49:41.052: INFO: namespace: e2e-tests-secrets-khgm9, resource: bindings, ignored listing per whitelist
May 25 01:49:41.065: INFO: namespace e2e-tests-secrets-khgm9 deletion completed in 6.088972522s

• [SLOW TEST:8.314 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:49:41.066: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-c7h7f
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 25 01:49:41.232: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
May 25 01:49:41.244: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:49:41.252: INFO: Number of nodes with available pods: 0
May 25 01:49:41.252: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:49:42.257: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:49:42.267: INFO: Number of nodes with available pods: 0
May 25 01:49:42.267: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:49:43.257: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:49:43.259: INFO: Number of nodes with available pods: 2
May 25 01:49:43.259: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
May 25 01:49:43.275: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:49:43.275: INFO: Wrong image for pod: daemon-set-x6v52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:49:43.281: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:49:44.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:49:44.284: INFO: Wrong image for pod: daemon-set-x6v52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:49:44.288: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:49:45.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:49:45.284: INFO: Wrong image for pod: daemon-set-x6v52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:49:45.288: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:49:46.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:49:46.284: INFO: Wrong image for pod: daemon-set-x6v52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:49:46.288: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:49:47.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:49:47.284: INFO: Wrong image for pod: daemon-set-x6v52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:49:47.289: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:49:48.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:49:48.284: INFO: Wrong image for pod: daemon-set-x6v52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:49:48.288: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:49:49.285: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:49:49.285: INFO: Wrong image for pod: daemon-set-x6v52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:49:49.289: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:49:50.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:49:50.284: INFO: Wrong image for pod: daemon-set-x6v52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:49:50.288: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:49:51.285: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:49:51.285: INFO: Wrong image for pod: daemon-set-x6v52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:49:51.289: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:49:52.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:49:52.284: INFO: Wrong image for pod: daemon-set-x6v52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:49:52.287: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:49:53.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:49:53.284: INFO: Wrong image for pod: daemon-set-x6v52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:49:53.288: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:49:54.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:49:54.284: INFO: Wrong image for pod: daemon-set-x6v52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:49:54.288: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:49:55.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:49:55.284: INFO: Wrong image for pod: daemon-set-x6v52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:49:55.288: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:49:56.285: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:49:56.285: INFO: Wrong image for pod: daemon-set-x6v52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:49:56.289: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:49:57.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:49:57.284: INFO: Wrong image for pod: daemon-set-x6v52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:49:57.289: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:49:58.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:49:58.284: INFO: Wrong image for pod: daemon-set-x6v52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:49:58.288: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:49:59.286: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:49:59.286: INFO: Wrong image for pod: daemon-set-x6v52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:49:59.291: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:00.291: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:00.291: INFO: Wrong image for pod: daemon-set-x6v52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:00.295: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:01.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:01.284: INFO: Wrong image for pod: daemon-set-x6v52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:01.288: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:02.285: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:02.285: INFO: Wrong image for pod: daemon-set-x6v52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:02.289: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:03.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:03.284: INFO: Wrong image for pod: daemon-set-x6v52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:03.288: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:04.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:04.284: INFO: Wrong image for pod: daemon-set-x6v52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:04.287: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:05.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:05.284: INFO: Wrong image for pod: daemon-set-x6v52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:05.288: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:06.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:06.284: INFO: Wrong image for pod: daemon-set-x6v52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:06.288: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:07.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:07.284: INFO: Wrong image for pod: daemon-set-x6v52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:07.288: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:08.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:08.284: INFO: Wrong image for pod: daemon-set-x6v52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:08.287: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:09.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:09.284: INFO: Wrong image for pod: daemon-set-x6v52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:09.289: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:10.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:10.284: INFO: Wrong image for pod: daemon-set-x6v52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:10.287: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:11.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:11.284: INFO: Wrong image for pod: daemon-set-x6v52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:11.288: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:12.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:12.284: INFO: Wrong image for pod: daemon-set-x6v52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:12.288: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:13.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:13.284: INFO: Wrong image for pod: daemon-set-x6v52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:13.289: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:14.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:14.284: INFO: Wrong image for pod: daemon-set-x6v52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:14.288: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:15.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:15.284: INFO: Wrong image for pod: daemon-set-x6v52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:15.290: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:16.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:16.284: INFO: Wrong image for pod: daemon-set-x6v52. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:16.284: INFO: Pod daemon-set-x6v52 is not available
May 25 01:50:16.288: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:17.285: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:17.285: INFO: Pod daemon-set-7892b is not available
May 25 01:50:17.288: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:18.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:18.288: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:19.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:19.290: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:20.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:20.288: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:21.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:21.289: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:22.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:22.288: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:23.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:23.288: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:24.285: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:24.295: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:25.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:25.288: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:26.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:26.289: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:27.285: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:27.301: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:28.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:28.288: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:29.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:29.289: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:30.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:30.287: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:31.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:31.288: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:32.285: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:32.289: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:33.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:33.288: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:34.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:34.288: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:35.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:35.288: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:36.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:36.289: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:37.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:37.288: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:38.285: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:38.289: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:39.285: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:39.290: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:40.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:40.288: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:41.285: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:41.289: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:42.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:42.290: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:43.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:43.288: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:44.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:44.287: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:45.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:45.288: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:46.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:46.288: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:47.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:47.287: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:48.287: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:48.291: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:49.286: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:49.286: INFO: Pod daemon-set-6gzms is not available
May 25 01:50:49.290: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:50.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:50.284: INFO: Pod daemon-set-6gzms is not available
May 25 01:50:50.288: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:51.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:51.284: INFO: Pod daemon-set-6gzms is not available
May 25 01:50:51.288: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:52.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:52.285: INFO: Pod daemon-set-6gzms is not available
May 25 01:50:52.289: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:53.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:53.285: INFO: Pod daemon-set-6gzms is not available
May 25 01:50:53.288: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:54.283: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:54.283: INFO: Pod daemon-set-6gzms is not available
May 25 01:50:54.287: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:55.285: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:55.285: INFO: Pod daemon-set-6gzms is not available
May 25 01:50:55.290: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:56.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:56.284: INFO: Pod daemon-set-6gzms is not available
May 25 01:50:56.288: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:57.284: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:57.284: INFO: Pod daemon-set-6gzms is not available
May 25 01:50:57.288: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:58.287: INFO: Wrong image for pod: daemon-set-6gzms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 25 01:50:58.287: INFO: Pod daemon-set-6gzms is not available
May 25 01:50:58.290: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:59.284: INFO: Pod daemon-set-qggwb is not available
May 25 01:50:59.288: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
May 25 01:50:59.291: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:50:59.293: INFO: Number of nodes with available pods: 1
May 25 01:50:59.293: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 01:51:00.297: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 01:51:00.299: INFO: Number of nodes with available pods: 2
May 25 01:51:00.299: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-c7h7f, will wait for the garbage collector to delete the pods
May 25 01:51:00.394: INFO: Deleting DaemonSet.extensions daemon-set took: 17.576376ms
May 25 01:51:00.494: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.185987ms
May 25 01:51:08.797: INFO: Number of nodes with available pods: 0
May 25 01:51:08.797: INFO: Number of running nodes: 0, number of available pods: 0
May 25 01:51:08.799: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-c7h7f/daemonsets","resourceVersion":"22392"},"items":null}

May 25 01:51:08.801: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-c7h7f/pods","resourceVersion":"22392"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:51:08.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-c7h7f" for this suite.
May 25 01:51:14.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:51:14.891: INFO: namespace: e2e-tests-daemonsets-c7h7f, resource: bindings, ignored listing per whitelist
May 25 01:51:14.891: INFO: namespace e2e-tests-daemonsets-c7h7f deletion completed in 6.077664819s

• [SLOW TEST:93.825 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:51:14.892: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-pxjrg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 25 01:51:15.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 version'
May 25 01:51:15.145: INFO: stderr: ""
May 25 01:51:15.145: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.5\", GitCommit:\"2166946f41b36dea2c4626f90a77706f426cdea2\", GitTreeState:\"clean\", BuildDate:\"2019-03-25T15:19:22Z\", GoVersion:\"go1.11.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:51:15.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pxjrg" for this suite.
May 25 01:51:21.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:51:21.199: INFO: namespace: e2e-tests-kubectl-pxjrg, resource: bindings, ignored listing per whitelist
May 25 01:51:21.246: INFO: namespace e2e-tests-kubectl-pxjrg deletion completed in 6.095984445s

• [SLOW TEST:6.354 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:51:21.248: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-6fz2g
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-6fz2g
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 25 01:51:21.404: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 25 01:51:45.516: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.1.143:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-6fz2g PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 25 01:51:45.517: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
May 25 01:51:45.566: INFO: Found all expected endpoints: [netserver-0]
May 25 01:51:45.569: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.2.71:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-6fz2g PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 25 01:51:45.569: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
May 25 01:51:45.614: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:51:45.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-6fz2g" for this suite.
May 25 01:52:07.626: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:52:07.695: INFO: namespace: e2e-tests-pod-network-test-6fz2g, resource: bindings, ignored listing per whitelist
May 25 01:52:07.710: INFO: namespace e2e-tests-pod-network-test-6fz2g deletion completed in 22.09213792s

• [SLOW TEST:46.462 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:52:07.711: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-z9ptn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-b41c6ca5-7e8f-11e9-802f-027f94874578
STEP: Creating a pod to test consume configMaps
May 25 01:52:07.885: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b41cdf5d-7e8f-11e9-802f-027f94874578" in namespace "e2e-tests-projected-z9ptn" to be "success or failure"
May 25 01:52:07.892: INFO: Pod "pod-projected-configmaps-b41cdf5d-7e8f-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 7.265242ms
May 25 01:52:09.895: INFO: Pod "pod-projected-configmaps-b41cdf5d-7e8f-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010344707s
STEP: Saw pod success
May 25 01:52:09.895: INFO: Pod "pod-projected-configmaps-b41cdf5d-7e8f-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:52:09.898: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-projected-configmaps-b41cdf5d-7e8f-11e9-802f-027f94874578 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 25 01:52:09.913: INFO: Waiting for pod pod-projected-configmaps-b41cdf5d-7e8f-11e9-802f-027f94874578 to disappear
May 25 01:52:09.917: INFO: Pod pod-projected-configmaps-b41cdf5d-7e8f-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:52:09.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-z9ptn" for this suite.
May 25 01:52:15.929: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:52:15.999: INFO: namespace: e2e-tests-projected-z9ptn, resource: bindings, ignored listing per whitelist
May 25 01:52:16.007: INFO: namespace e2e-tests-projected-z9ptn deletion completed in 6.086575985s

• [SLOW TEST:8.296 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:52:16.009: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-l2kt2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 25 01:52:16.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-l2kt2'
May 25 01:52:16.489: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 25 01:52:16.489: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
May 25 01:52:16.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-l2kt2'
May 25 01:52:16.614: INFO: stderr: ""
May 25 01:52:16.614: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:52:16.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-l2kt2" for this suite.
May 25 01:52:38.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:52:38.671: INFO: namespace: e2e-tests-kubectl-l2kt2, resource: bindings, ignored listing per whitelist
May 25 01:52:38.727: INFO: namespace e2e-tests-kubectl-l2kt2 deletion completed in 22.105579177s

• [SLOW TEST:22.718 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:52:38.730: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-67gvp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 25 01:52:38.885: INFO: Creating ReplicaSet my-hostname-basic-c69922bf-7e8f-11e9-802f-027f94874578
May 25 01:52:38.894: INFO: Pod name my-hostname-basic-c69922bf-7e8f-11e9-802f-027f94874578: Found 0 pods out of 1
May 25 01:52:43.897: INFO: Pod name my-hostname-basic-c69922bf-7e8f-11e9-802f-027f94874578: Found 1 pods out of 1
May 25 01:52:43.898: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-c69922bf-7e8f-11e9-802f-027f94874578" is running
May 25 01:52:43.900: INFO: Pod "my-hostname-basic-c69922bf-7e8f-11e9-802f-027f94874578-lfj84" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-25 01:52:39 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-25 01:52:40 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-25 01:52:40 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-25 01:52:38 +0000 UTC Reason: Message:}])
May 25 01:52:43.900: INFO: Trying to dial the pod
May 25 01:52:48.908: INFO: Controller my-hostname-basic-c69922bf-7e8f-11e9-802f-027f94874578: Got expected result from replica 1 [my-hostname-basic-c69922bf-7e8f-11e9-802f-027f94874578-lfj84]: "my-hostname-basic-c69922bf-7e8f-11e9-802f-027f94874578-lfj84", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:52:48.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-67gvp" for this suite.
May 25 01:52:54.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:52:54.971: INFO: namespace: e2e-tests-replicaset-67gvp, resource: bindings, ignored listing per whitelist
May 25 01:52:54.990: INFO: namespace e2e-tests-replicaset-67gvp deletion completed in 6.077920646s

• [SLOW TEST:16.260 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:52:54.992: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-gg2pw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 25 01:52:55.156: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d04ab3c0-7e8f-11e9-802f-027f94874578" in namespace "e2e-tests-projected-gg2pw" to be "success or failure"
May 25 01:52:55.165: INFO: Pod "downwardapi-volume-d04ab3c0-7e8f-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 9.263803ms
May 25 01:52:57.168: INFO: Pod "downwardapi-volume-d04ab3c0-7e8f-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012117669s
STEP: Saw pod success
May 25 01:52:57.168: INFO: Pod "downwardapi-volume-d04ab3c0-7e8f-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:52:57.170: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod downwardapi-volume-d04ab3c0-7e8f-11e9-802f-027f94874578 container client-container: <nil>
STEP: delete the pod
May 25 01:52:57.187: INFO: Waiting for pod downwardapi-volume-d04ab3c0-7e8f-11e9-802f-027f94874578 to disappear
May 25 01:52:57.189: INFO: Pod downwardapi-volume-d04ab3c0-7e8f-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:52:57.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gg2pw" for this suite.
May 25 01:53:03.201: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:53:03.230: INFO: namespace: e2e-tests-projected-gg2pw, resource: bindings, ignored listing per whitelist
May 25 01:53:03.281: INFO: namespace e2e-tests-projected-gg2pw deletion completed in 6.088518554s

• [SLOW TEST:8.289 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:53:03.281: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-hkv6j
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-hkv6j
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 25 01:53:03.441: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 25 01:53:23.521: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 192.168.1.147 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-hkv6j PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 25 01:53:23.521: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
May 25 01:53:24.578: INFO: Found all expected endpoints: [netserver-0]
May 25 01:53:24.581: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 192.168.2.73 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-hkv6j PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 25 01:53:24.581: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
May 25 01:53:25.626: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:53:25.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-hkv6j" for this suite.
May 25 01:53:47.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:53:47.658: INFO: namespace: e2e-tests-pod-network-test-hkv6j, resource: bindings, ignored listing per whitelist
May 25 01:53:47.733: INFO: namespace e2e-tests-pod-network-test-hkv6j deletion completed in 22.099692568s

• [SLOW TEST:44.452 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:53:47.733: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-w5dtq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
May 25 01:53:47.906: INFO: Waiting up to 5m0s for pod "pod-efbb5ae4-7e8f-11e9-802f-027f94874578" in namespace "e2e-tests-emptydir-w5dtq" to be "success or failure"
May 25 01:53:47.910: INFO: Pod "pod-efbb5ae4-7e8f-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 4.767789ms
May 25 01:53:49.913: INFO: Pod "pod-efbb5ae4-7e8f-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007613572s
STEP: Saw pod success
May 25 01:53:49.914: INFO: Pod "pod-efbb5ae4-7e8f-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:53:49.917: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-efbb5ae4-7e8f-11e9-802f-027f94874578 container test-container: <nil>
STEP: delete the pod
May 25 01:53:49.936: INFO: Waiting for pod pod-efbb5ae4-7e8f-11e9-802f-027f94874578 to disappear
May 25 01:53:49.939: INFO: Pod pod-efbb5ae4-7e8f-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:53:49.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-w5dtq" for this suite.
May 25 01:53:55.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:53:56.049: INFO: namespace: e2e-tests-emptydir-w5dtq, resource: bindings, ignored listing per whitelist
May 25 01:53:56.075: INFO: namespace e2e-tests-emptydir-w5dtq deletion completed in 6.132504213s

• [SLOW TEST:8.342 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:53:56.076: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-4smh7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-f4ba9362-7e8f-11e9-802f-027f94874578
STEP: Creating a pod to test consume secrets
May 25 01:53:56.291: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f4bb3dc4-7e8f-11e9-802f-027f94874578" in namespace "e2e-tests-projected-4smh7" to be "success or failure"
May 25 01:53:56.297: INFO: Pod "pod-projected-secrets-f4bb3dc4-7e8f-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 5.62605ms
May 25 01:53:58.300: INFO: Pod "pod-projected-secrets-f4bb3dc4-7e8f-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008475534s
STEP: Saw pod success
May 25 01:53:58.300: INFO: Pod "pod-projected-secrets-f4bb3dc4-7e8f-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:53:58.302: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-projected-secrets-f4bb3dc4-7e8f-11e9-802f-027f94874578 container secret-volume-test: <nil>
STEP: delete the pod
May 25 01:53:58.331: INFO: Waiting for pod pod-projected-secrets-f4bb3dc4-7e8f-11e9-802f-027f94874578 to disappear
May 25 01:53:58.333: INFO: Pod pod-projected-secrets-f4bb3dc4-7e8f-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:53:58.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4smh7" for this suite.
May 25 01:54:04.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:54:04.416: INFO: namespace: e2e-tests-projected-4smh7, resource: bindings, ignored listing per whitelist
May 25 01:54:04.424: INFO: namespace e2e-tests-projected-4smh7 deletion completed in 6.086242151s

• [SLOW TEST:8.348 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:54:04.424: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-k26st
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
May 25 01:54:04.592: INFO: Waiting up to 5m0s for pod "downward-api-f9ad8149-7e8f-11e9-802f-027f94874578" in namespace "e2e-tests-downward-api-k26st" to be "success or failure"
May 25 01:54:04.599: INFO: Pod "downward-api-f9ad8149-7e8f-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 7.380065ms
May 25 01:54:06.601: INFO: Pod "downward-api-f9ad8149-7e8f-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009586935s
STEP: Saw pod success
May 25 01:54:06.601: INFO: Pod "downward-api-f9ad8149-7e8f-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:54:06.603: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod downward-api-f9ad8149-7e8f-11e9-802f-027f94874578 container dapi-container: <nil>
STEP: delete the pod
May 25 01:54:06.622: INFO: Waiting for pod downward-api-f9ad8149-7e8f-11e9-802f-027f94874578 to disappear
May 25 01:54:06.624: INFO: Pod downward-api-f9ad8149-7e8f-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:54:06.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-k26st" for this suite.
May 25 01:54:12.636: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:54:12.709: INFO: namespace: e2e-tests-downward-api-k26st, resource: bindings, ignored listing per whitelist
May 25 01:54:12.715: INFO: namespace e2e-tests-downward-api-k26st deletion completed in 6.08790189s

• [SLOW TEST:8.291 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:54:12.715: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-dq5vs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-wf8w
STEP: Creating a pod to test atomic-volume-subpath
May 25 01:54:12.884: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-wf8w" in namespace "e2e-tests-subpath-dq5vs" to be "success or failure"
May 25 01:54:12.889: INFO: Pod "pod-subpath-test-secret-wf8w": Phase="Pending", Reason="", readiness=false. Elapsed: 5.333708ms
May 25 01:54:14.892: INFO: Pod "pod-subpath-test-secret-wf8w": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00855219s
May 25 01:54:16.895: INFO: Pod "pod-subpath-test-secret-wf8w": Phase="Running", Reason="", readiness=false. Elapsed: 4.011046053s
May 25 01:54:18.898: INFO: Pod "pod-subpath-test-secret-wf8w": Phase="Running", Reason="", readiness=false. Elapsed: 6.013750935s
May 25 01:54:20.900: INFO: Pod "pod-subpath-test-secret-wf8w": Phase="Running", Reason="", readiness=false. Elapsed: 8.016478958s
May 25 01:54:22.903: INFO: Pod "pod-subpath-test-secret-wf8w": Phase="Running", Reason="", readiness=false. Elapsed: 10.019429968s
May 25 01:54:24.906: INFO: Pod "pod-subpath-test-secret-wf8w": Phase="Running", Reason="", readiness=false. Elapsed: 12.022410664s
May 25 01:54:26.909: INFO: Pod "pod-subpath-test-secret-wf8w": Phase="Running", Reason="", readiness=false. Elapsed: 14.025172797s
May 25 01:54:28.912: INFO: Pod "pod-subpath-test-secret-wf8w": Phase="Running", Reason="", readiness=false. Elapsed: 16.027709902s
May 25 01:54:30.915: INFO: Pod "pod-subpath-test-secret-wf8w": Phase="Running", Reason="", readiness=false. Elapsed: 18.030784958s
May 25 01:54:32.918: INFO: Pod "pod-subpath-test-secret-wf8w": Phase="Running", Reason="", readiness=false. Elapsed: 20.033972335s
May 25 01:54:34.920: INFO: Pod "pod-subpath-test-secret-wf8w": Phase="Running", Reason="", readiness=false. Elapsed: 22.036465523s
May 25 01:54:36.923: INFO: Pod "pod-subpath-test-secret-wf8w": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.039174663s
STEP: Saw pod success
May 25 01:54:36.923: INFO: Pod "pod-subpath-test-secret-wf8w" satisfied condition "success or failure"
May 25 01:54:36.925: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-subpath-test-secret-wf8w container test-container-subpath-secret-wf8w: <nil>
STEP: delete the pod
May 25 01:54:36.945: INFO: Waiting for pod pod-subpath-test-secret-wf8w to disappear
May 25 01:54:36.951: INFO: Pod pod-subpath-test-secret-wf8w no longer exists
STEP: Deleting pod pod-subpath-test-secret-wf8w
May 25 01:54:36.951: INFO: Deleting pod "pod-subpath-test-secret-wf8w" in namespace "e2e-tests-subpath-dq5vs"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:54:36.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-dq5vs" for this suite.
May 25 01:54:42.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:54:43.009: INFO: namespace: e2e-tests-subpath-dq5vs, resource: bindings, ignored listing per whitelist
May 25 01:54:43.041: INFO: namespace e2e-tests-subpath-dq5vs deletion completed in 6.086072298s

• [SLOW TEST:30.326 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:54:43.042: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-rjww6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0525 01:55:13.266000      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 25 01:55:13.266: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:55:13.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-rjww6" for this suite.
May 25 01:55:19.280: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:55:19.315: INFO: namespace: e2e-tests-gc-rjww6, resource: bindings, ignored listing per whitelist
May 25 01:55:19.357: INFO: namespace e2e-tests-gc-rjww6 deletion completed in 6.087478893s

• [SLOW TEST:36.315 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:55:19.358: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-tvtdm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
May 25 01:55:19.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 create -f - --namespace=e2e-tests-kubectl-tvtdm'
May 25 01:55:19.735: INFO: stderr: ""
May 25 01:55:19.735: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 25 01:55:19.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-tvtdm'
May 25 01:55:19.863: INFO: stderr: ""
May 25 01:55:19.863: INFO: stdout: "update-demo-nautilus-fjlv5 update-demo-nautilus-vqh4f "
May 25 01:55:19.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods update-demo-nautilus-fjlv5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tvtdm'
May 25 01:55:19.950: INFO: stderr: ""
May 25 01:55:19.950: INFO: stdout: ""
May 25 01:55:19.950: INFO: update-demo-nautilus-fjlv5 is created but not running
May 25 01:55:24.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-tvtdm'
May 25 01:55:25.039: INFO: stderr: ""
May 25 01:55:25.039: INFO: stdout: "update-demo-nautilus-fjlv5 update-demo-nautilus-vqh4f "
May 25 01:55:25.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods update-demo-nautilus-fjlv5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tvtdm'
May 25 01:55:25.133: INFO: stderr: ""
May 25 01:55:25.133: INFO: stdout: "true"
May 25 01:55:25.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods update-demo-nautilus-fjlv5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tvtdm'
May 25 01:55:25.215: INFO: stderr: ""
May 25 01:55:25.215: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 25 01:55:25.215: INFO: validating pod update-demo-nautilus-fjlv5
May 25 01:55:25.219: INFO: got data: {
  "image": "nautilus.jpg"
}

May 25 01:55:25.219: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 25 01:55:25.219: INFO: update-demo-nautilus-fjlv5 is verified up and running
May 25 01:55:25.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods update-demo-nautilus-vqh4f -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tvtdm'
May 25 01:55:25.309: INFO: stderr: ""
May 25 01:55:25.309: INFO: stdout: "true"
May 25 01:55:25.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods update-demo-nautilus-vqh4f -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tvtdm'
May 25 01:55:25.400: INFO: stderr: ""
May 25 01:55:25.400: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 25 01:55:25.400: INFO: validating pod update-demo-nautilus-vqh4f
May 25 01:55:25.404: INFO: got data: {
  "image": "nautilus.jpg"
}

May 25 01:55:25.404: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 25 01:55:25.404: INFO: update-demo-nautilus-vqh4f is verified up and running
STEP: using delete to clean up resources
May 25 01:55:25.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-tvtdm'
May 25 01:55:25.525: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 25 01:55:25.525: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May 25 01:55:25.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-tvtdm'
May 25 01:55:25.642: INFO: stderr: "No resources found.\n"
May 25 01:55:25.642: INFO: stdout: ""
May 25 01:55:25.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods -l name=update-demo --namespace=e2e-tests-kubectl-tvtdm -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 25 01:55:25.725: INFO: stderr: ""
May 25 01:55:25.725: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:55:25.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tvtdm" for this suite.
May 25 01:55:47.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:55:47.749: INFO: namespace: e2e-tests-kubectl-tvtdm, resource: bindings, ignored listing per whitelist
May 25 01:55:47.818: INFO: namespace e2e-tests-kubectl-tvtdm deletion completed in 22.089685668s

• [SLOW TEST:28.461 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:55:47.819: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-prestop-7b4xk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-7b4xk
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-7b4xk
STEP: Deleting pre-stop pod
May 25 01:55:59.034: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:55:59.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-7b4xk" for this suite.
May 25 01:56:37.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:56:37.108: INFO: namespace: e2e-tests-prestop-7b4xk, resource: bindings, ignored listing per whitelist
May 25 01:56:37.138: INFO: namespace e2e-tests-prestop-7b4xk deletion completed in 38.095699259s

• [SLOW TEST:49.319 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:56:37.139: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-bd7lb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-54b50fe8-7e90-11e9-802f-027f94874578
STEP: Creating a pod to test consume configMaps
May 25 01:56:37.318: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-54b59828-7e90-11e9-802f-027f94874578" in namespace "e2e-tests-projected-bd7lb" to be "success or failure"
May 25 01:56:37.324: INFO: Pod "pod-projected-configmaps-54b59828-7e90-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 5.897907ms
May 25 01:56:39.327: INFO: Pod "pod-projected-configmaps-54b59828-7e90-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009026459s
STEP: Saw pod success
May 25 01:56:39.327: INFO: Pod "pod-projected-configmaps-54b59828-7e90-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:56:39.330: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-projected-configmaps-54b59828-7e90-11e9-802f-027f94874578 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 25 01:56:39.349: INFO: Waiting for pod pod-projected-configmaps-54b59828-7e90-11e9-802f-027f94874578 to disappear
May 25 01:56:39.351: INFO: Pod pod-projected-configmaps-54b59828-7e90-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:56:39.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bd7lb" for this suite.
May 25 01:56:45.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:56:45.383: INFO: namespace: e2e-tests-projected-bd7lb, resource: bindings, ignored listing per whitelist
May 25 01:56:45.431: INFO: namespace e2e-tests-projected-bd7lb deletion completed in 6.077406568s

• [SLOW TEST:8.293 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:56:45.433: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-dgggn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-9cbh
STEP: Creating a pod to test atomic-volume-subpath
May 25 01:56:45.625: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-9cbh" in namespace "e2e-tests-subpath-dgggn" to be "success or failure"
May 25 01:56:45.629: INFO: Pod "pod-subpath-test-projected-9cbh": Phase="Pending", Reason="", readiness=false. Elapsed: 2.919695ms
May 25 01:56:47.632: INFO: Pod "pod-subpath-test-projected-9cbh": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0059765s
May 25 01:56:49.635: INFO: Pod "pod-subpath-test-projected-9cbh": Phase="Running", Reason="", readiness=false. Elapsed: 4.008894419s
May 25 01:56:51.638: INFO: Pod "pod-subpath-test-projected-9cbh": Phase="Running", Reason="", readiness=false. Elapsed: 6.01186492s
May 25 01:56:53.641: INFO: Pod "pod-subpath-test-projected-9cbh": Phase="Running", Reason="", readiness=false. Elapsed: 8.014964023s
May 25 01:56:55.643: INFO: Pod "pod-subpath-test-projected-9cbh": Phase="Running", Reason="", readiness=false. Elapsed: 10.01754213s
May 25 01:56:57.646: INFO: Pod "pod-subpath-test-projected-9cbh": Phase="Running", Reason="", readiness=false. Elapsed: 12.020385652s
May 25 01:56:59.677: INFO: Pod "pod-subpath-test-projected-9cbh": Phase="Running", Reason="", readiness=false. Elapsed: 14.051359819s
May 25 01:57:01.681: INFO: Pod "pod-subpath-test-projected-9cbh": Phase="Running", Reason="", readiness=false. Elapsed: 16.055223919s
May 25 01:57:03.684: INFO: Pod "pod-subpath-test-projected-9cbh": Phase="Running", Reason="", readiness=false. Elapsed: 18.057945513s
May 25 01:57:05.686: INFO: Pod "pod-subpath-test-projected-9cbh": Phase="Running", Reason="", readiness=false. Elapsed: 20.060115045s
May 25 01:57:07.689: INFO: Pod "pod-subpath-test-projected-9cbh": Phase="Running", Reason="", readiness=false. Elapsed: 22.063159678s
May 25 01:57:09.692: INFO: Pod "pod-subpath-test-projected-9cbh": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.065731304s
STEP: Saw pod success
May 25 01:57:09.692: INFO: Pod "pod-subpath-test-projected-9cbh" satisfied condition "success or failure"
May 25 01:57:09.694: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-subpath-test-projected-9cbh container test-container-subpath-projected-9cbh: <nil>
STEP: delete the pod
May 25 01:57:09.711: INFO: Waiting for pod pod-subpath-test-projected-9cbh to disappear
May 25 01:57:09.713: INFO: Pod pod-subpath-test-projected-9cbh no longer exists
STEP: Deleting pod pod-subpath-test-projected-9cbh
May 25 01:57:09.713: INFO: Deleting pod "pod-subpath-test-projected-9cbh" in namespace "e2e-tests-subpath-dgggn"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:57:09.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-dgggn" for this suite.
May 25 01:57:15.725: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:57:15.746: INFO: namespace: e2e-tests-subpath-dgggn, resource: bindings, ignored listing per whitelist
May 25 01:57:15.815: INFO: namespace e2e-tests-subpath-dgggn deletion completed in 6.097405237s

• [SLOW TEST:30.382 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:57:15.817: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-4jncn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-6bc1c9ce-7e90-11e9-802f-027f94874578
STEP: Creating a pod to test consume secrets
May 25 01:57:15.987: INFO: Waiting up to 5m0s for pod "pod-secrets-6bc27d09-7e90-11e9-802f-027f94874578" in namespace "e2e-tests-secrets-4jncn" to be "success or failure"
May 25 01:57:15.992: INFO: Pod "pod-secrets-6bc27d09-7e90-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 5.350867ms
May 25 01:57:17.995: INFO: Pod "pod-secrets-6bc27d09-7e90-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008139246s
STEP: Saw pod success
May 25 01:57:17.995: INFO: Pod "pod-secrets-6bc27d09-7e90-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:57:17.997: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-secrets-6bc27d09-7e90-11e9-802f-027f94874578 container secret-volume-test: <nil>
STEP: delete the pod
May 25 01:57:18.014: INFO: Waiting for pod pod-secrets-6bc27d09-7e90-11e9-802f-027f94874578 to disappear
May 25 01:57:18.016: INFO: Pod pod-secrets-6bc27d09-7e90-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:57:18.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-4jncn" for this suite.
May 25 01:57:24.029: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:57:24.094: INFO: namespace: e2e-tests-secrets-4jncn, resource: bindings, ignored listing per whitelist
May 25 01:57:24.104: INFO: namespace e2e-tests-secrets-4jncn deletion completed in 6.084682394s

• [SLOW TEST:8.288 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:57:24.105: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-628hc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
May 25 01:57:24.268: INFO: Waiting up to 5m0s for pod "pod-70b1ce17-7e90-11e9-802f-027f94874578" in namespace "e2e-tests-emptydir-628hc" to be "success or failure"
May 25 01:57:24.274: INFO: Pod "pod-70b1ce17-7e90-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 5.855526ms
May 25 01:57:26.277: INFO: Pod "pod-70b1ce17-7e90-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008949415s
STEP: Saw pod success
May 25 01:57:26.277: INFO: Pod "pod-70b1ce17-7e90-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:57:26.279: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-70b1ce17-7e90-11e9-802f-027f94874578 container test-container: <nil>
STEP: delete the pod
May 25 01:57:26.299: INFO: Waiting for pod pod-70b1ce17-7e90-11e9-802f-027f94874578 to disappear
May 25 01:57:26.301: INFO: Pod pod-70b1ce17-7e90-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:57:26.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-628hc" for this suite.
May 25 01:57:32.323: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:57:32.398: INFO: namespace: e2e-tests-emptydir-628hc, resource: bindings, ignored listing per whitelist
May 25 01:57:32.411: INFO: namespace e2e-tests-emptydir-628hc deletion completed in 6.100927372s

• [SLOW TEST:8.306 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:57:32.413: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-6xq2t
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-75a67017-7e90-11e9-802f-027f94874578
STEP: Creating a pod to test consume configMaps
May 25 01:57:32.585: INFO: Waiting up to 5m0s for pod "pod-configmaps-75a70af4-7e90-11e9-802f-027f94874578" in namespace "e2e-tests-configmap-6xq2t" to be "success or failure"
May 25 01:57:32.590: INFO: Pod "pod-configmaps-75a70af4-7e90-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 5.618716ms
May 25 01:57:34.593: INFO: Pod "pod-configmaps-75a70af4-7e90-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00851308s
STEP: Saw pod success
May 25 01:57:34.593: INFO: Pod "pod-configmaps-75a70af4-7e90-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:57:34.596: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-configmaps-75a70af4-7e90-11e9-802f-027f94874578 container configmap-volume-test: <nil>
STEP: delete the pod
May 25 01:57:34.612: INFO: Waiting for pod pod-configmaps-75a70af4-7e90-11e9-802f-027f94874578 to disappear
May 25 01:57:34.615: INFO: Pod pod-configmaps-75a70af4-7e90-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:57:34.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-6xq2t" for this suite.
May 25 01:57:40.626: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:57:40.662: INFO: namespace: e2e-tests-configmap-6xq2t, resource: bindings, ignored listing per whitelist
May 25 01:57:40.695: INFO: namespace e2e-tests-configmap-6xq2t deletion completed in 6.076635997s

• [SLOW TEST:8.283 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:57:40.697: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-v2sdz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-7a94e045-7e90-11e9-802f-027f94874578
STEP: Creating a pod to test consume configMaps
May 25 01:57:40.857: INFO: Waiting up to 5m0s for pod "pod-configmaps-7a956bf0-7e90-11e9-802f-027f94874578" in namespace "e2e-tests-configmap-v2sdz" to be "success or failure"
May 25 01:57:40.864: INFO: Pod "pod-configmaps-7a956bf0-7e90-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 7.091606ms
May 25 01:57:42.867: INFO: Pod "pod-configmaps-7a956bf0-7e90-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01005121s
STEP: Saw pod success
May 25 01:57:42.867: INFO: Pod "pod-configmaps-7a956bf0-7e90-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:57:42.869: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-configmaps-7a956bf0-7e90-11e9-802f-027f94874578 container configmap-volume-test: <nil>
STEP: delete the pod
May 25 01:57:42.886: INFO: Waiting for pod pod-configmaps-7a956bf0-7e90-11e9-802f-027f94874578 to disappear
May 25 01:57:42.891: INFO: Pod pod-configmaps-7a956bf0-7e90-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:57:42.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-v2sdz" for this suite.
May 25 01:57:48.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:57:48.925: INFO: namespace: e2e-tests-configmap-v2sdz, resource: bindings, ignored listing per whitelist
May 25 01:57:48.989: INFO: namespace e2e-tests-configmap-v2sdz deletion completed in 6.093891252s

• [SLOW TEST:8.292 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:57:48.990: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-4q4lr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0525 01:57:55.198969      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 25 01:57:55.199: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:57:55.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-4q4lr" for this suite.
May 25 01:58:01.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:58:01.245: INFO: namespace: e2e-tests-gc-4q4lr, resource: bindings, ignored listing per whitelist
May 25 01:58:01.325: INFO: namespace e2e-tests-gc-4q4lr deletion completed in 6.122855321s

• [SLOW TEST:12.334 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:58:01.325: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-tj8hq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
May 25 01:58:01.564: INFO: Waiting up to 5m0s for pod "var-expansion-86ecf467-7e90-11e9-802f-027f94874578" in namespace "e2e-tests-var-expansion-tj8hq" to be "success or failure"
May 25 01:58:01.574: INFO: Pod "var-expansion-86ecf467-7e90-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 10.036632ms
May 25 01:58:03.576: INFO: Pod "var-expansion-86ecf467-7e90-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012563452s
STEP: Saw pod success
May 25 01:58:03.576: INFO: Pod "var-expansion-86ecf467-7e90-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:58:03.578: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod var-expansion-86ecf467-7e90-11e9-802f-027f94874578 container dapi-container: <nil>
STEP: delete the pod
May 25 01:58:03.596: INFO: Waiting for pod var-expansion-86ecf467-7e90-11e9-802f-027f94874578 to disappear
May 25 01:58:03.598: INFO: Pod var-expansion-86ecf467-7e90-11e9-802f-027f94874578 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:58:03.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-tj8hq" for this suite.
May 25 01:58:09.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:58:09.675: INFO: namespace: e2e-tests-var-expansion-tj8hq, resource: bindings, ignored listing per whitelist
May 25 01:58:09.683: INFO: namespace e2e-tests-var-expansion-tj8hq deletion completed in 6.081277626s

• [SLOW TEST:8.358 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:58:09.685: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-jzwdr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 25 01:58:09.848: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:58:11.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-jzwdr" for this suite.
May 25 01:58:49.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:58:49.960: INFO: namespace: e2e-tests-pods-jzwdr, resource: bindings, ignored listing per whitelist
May 25 01:58:50.022: INFO: namespace e2e-tests-pods-jzwdr deletion completed in 38.092112152s

• [SLOW TEST:40.337 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:58:50.024: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-xlwff
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-xlwff
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 25 01:58:50.182: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 25 01:59:12.255: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.2.83:8080/dial?request=hostName&protocol=udp&host=192.168.2.82&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-xlwff PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 25 01:59:12.255: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
May 25 01:59:12.317: INFO: Waiting for endpoints: map[]
May 25 01:59:12.320: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.2.83:8080/dial?request=hostName&protocol=udp&host=192.168.1.169&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-xlwff PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 25 01:59:12.320: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
May 25 01:59:12.382: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:59:12.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-xlwff" for this suite.
May 25 01:59:34.395: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:59:34.414: INFO: namespace: e2e-tests-pod-network-test-xlwff, resource: bindings, ignored listing per whitelist
May 25 01:59:34.471: INFO: namespace e2e-tests-pod-network-test-xlwff deletion completed in 22.08383185s

• [SLOW TEST:44.447 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:59:34.472: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-vb6qj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
May 25 01:59:34.650: INFO: Waiting up to 5m0s for pod "client-containers-be67f5c7-7e90-11e9-802f-027f94874578" in namespace "e2e-tests-containers-vb6qj" to be "success or failure"
May 25 01:59:34.655: INFO: Pod "client-containers-be67f5c7-7e90-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 4.795433ms
May 25 01:59:36.658: INFO: Pod "client-containers-be67f5c7-7e90-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007482786s
STEP: Saw pod success
May 25 01:59:36.658: INFO: Pod "client-containers-be67f5c7-7e90-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:59:36.660: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod client-containers-be67f5c7-7e90-11e9-802f-027f94874578 container test-container: <nil>
STEP: delete the pod
May 25 01:59:36.677: INFO: Waiting for pod client-containers-be67f5c7-7e90-11e9-802f-027f94874578 to disappear
May 25 01:59:36.680: INFO: Pod client-containers-be67f5c7-7e90-11e9-802f-027f94874578 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:59:36.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-vb6qj" for this suite.
May 25 01:59:42.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:59:42.715: INFO: namespace: e2e-tests-containers-vb6qj, resource: bindings, ignored listing per whitelist
May 25 01:59:42.772: INFO: namespace e2e-tests-containers-vb6qj deletion completed in 6.08915406s

• [SLOW TEST:8.301 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:59:42.772: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-b5tvl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-c35a6684-7e90-11e9-802f-027f94874578
STEP: Creating a pod to test consume secrets
May 25 01:59:42.949: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c35ae320-7e90-11e9-802f-027f94874578" in namespace "e2e-tests-projected-b5tvl" to be "success or failure"
May 25 01:59:42.954: INFO: Pod "pod-projected-secrets-c35ae320-7e90-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 4.266413ms
May 25 01:59:44.957: INFO: Pod "pod-projected-secrets-c35ae320-7e90-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007378428s
STEP: Saw pod success
May 25 01:59:44.957: INFO: Pod "pod-projected-secrets-c35ae320-7e90-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:59:44.959: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-projected-secrets-c35ae320-7e90-11e9-802f-027f94874578 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 25 01:59:44.979: INFO: Waiting for pod pod-projected-secrets-c35ae320-7e90-11e9-802f-027f94874578 to disappear
May 25 01:59:44.981: INFO: Pod pod-projected-secrets-c35ae320-7e90-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:59:44.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-b5tvl" for this suite.
May 25 01:59:50.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:59:51.064: INFO: namespace: e2e-tests-projected-b5tvl, resource: bindings, ignored listing per whitelist
May 25 01:59:51.087: INFO: namespace e2e-tests-projected-b5tvl deletion completed in 6.101855207s

• [SLOW TEST:8.315 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:59:51.088: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-9jlfq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 25 01:59:51.260: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c84ee11e-7e90-11e9-802f-027f94874578" in namespace "e2e-tests-downward-api-9jlfq" to be "success or failure"
May 25 01:59:51.265: INFO: Pod "downwardapi-volume-c84ee11e-7e90-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 5.47777ms
May 25 01:59:53.269: INFO: Pod "downwardapi-volume-c84ee11e-7e90-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009269825s
STEP: Saw pod success
May 25 01:59:53.269: INFO: Pod "downwardapi-volume-c84ee11e-7e90-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 01:59:53.273: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod downwardapi-volume-c84ee11e-7e90-11e9-802f-027f94874578 container client-container: <nil>
STEP: delete the pod
May 25 01:59:53.298: INFO: Waiting for pod downwardapi-volume-c84ee11e-7e90-11e9-802f-027f94874578 to disappear
May 25 01:59:53.300: INFO: Pod downwardapi-volume-c84ee11e-7e90-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 01:59:53.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9jlfq" for this suite.
May 25 01:59:59.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 01:59:59.380: INFO: namespace: e2e-tests-downward-api-9jlfq, resource: bindings, ignored listing per whitelist
May 25 01:59:59.387: INFO: namespace e2e-tests-downward-api-9jlfq deletion completed in 6.08303642s

• [SLOW TEST:8.299 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 01:59:59.390: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-wml9k
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 25 01:59:59.547: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cd3fab88-7e90-11e9-802f-027f94874578" in namespace "e2e-tests-projected-wml9k" to be "success or failure"
May 25 01:59:59.555: INFO: Pod "downwardapi-volume-cd3fab88-7e90-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 7.978343ms
May 25 02:00:01.560: INFO: Pod "downwardapi-volume-cd3fab88-7e90-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012494956s
STEP: Saw pod success
May 25 02:00:01.560: INFO: Pod "downwardapi-volume-cd3fab88-7e90-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 02:00:01.565: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod downwardapi-volume-cd3fab88-7e90-11e9-802f-027f94874578 container client-container: <nil>
STEP: delete the pod
May 25 02:00:01.611: INFO: Waiting for pod downwardapi-volume-cd3fab88-7e90-11e9-802f-027f94874578 to disappear
May 25 02:00:01.615: INFO: Pod downwardapi-volume-cd3fab88-7e90-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:00:01.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wml9k" for this suite.
May 25 02:00:07.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:00:07.692: INFO: namespace: e2e-tests-projected-wml9k, resource: bindings, ignored listing per whitelist
May 25 02:00:07.711: INFO: namespace e2e-tests-projected-wml9k deletion completed in 6.089617842s

• [SLOW TEST:8.321 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:00:07.712: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-qbc8x
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
May 25 02:00:07.880: INFO: Waiting up to 5m0s for pod "var-expansion-d23698c5-7e90-11e9-802f-027f94874578" in namespace "e2e-tests-var-expansion-qbc8x" to be "success or failure"
May 25 02:00:07.882: INFO: Pod "var-expansion-d23698c5-7e90-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 2.262948ms
May 25 02:00:09.885: INFO: Pod "var-expansion-d23698c5-7e90-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005155334s
STEP: Saw pod success
May 25 02:00:09.885: INFO: Pod "var-expansion-d23698c5-7e90-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 02:00:09.888: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod var-expansion-d23698c5-7e90-11e9-802f-027f94874578 container dapi-container: <nil>
STEP: delete the pod
May 25 02:00:09.908: INFO: Waiting for pod var-expansion-d23698c5-7e90-11e9-802f-027f94874578 to disappear
May 25 02:00:09.911: INFO: Pod var-expansion-d23698c5-7e90-11e9-802f-027f94874578 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:00:09.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-qbc8x" for this suite.
May 25 02:00:15.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:00:15.962: INFO: namespace: e2e-tests-var-expansion-qbc8x, resource: bindings, ignored listing per whitelist
May 25 02:00:16.004: INFO: namespace e2e-tests-var-expansion-qbc8x deletion completed in 6.089098203s

• [SLOW TEST:8.292 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:00:16.005: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-dd4n6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
May 25 02:00:16.170: INFO: Waiting up to 5m0s for pod "pod-d72809bc-7e90-11e9-802f-027f94874578" in namespace "e2e-tests-emptydir-dd4n6" to be "success or failure"
May 25 02:00:16.174: INFO: Pod "pod-d72809bc-7e90-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 4.770743ms
May 25 02:00:18.178: INFO: Pod "pod-d72809bc-7e90-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008012592s
STEP: Saw pod success
May 25 02:00:18.178: INFO: Pod "pod-d72809bc-7e90-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 02:00:18.180: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-d72809bc-7e90-11e9-802f-027f94874578 container test-container: <nil>
STEP: delete the pod
May 25 02:00:18.197: INFO: Waiting for pod pod-d72809bc-7e90-11e9-802f-027f94874578 to disappear
May 25 02:00:18.200: INFO: Pod pod-d72809bc-7e90-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:00:18.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-dd4n6" for this suite.
May 25 02:00:24.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:00:24.283: INFO: namespace: e2e-tests-emptydir-dd4n6, resource: bindings, ignored listing per whitelist
May 25 02:00:24.288: INFO: namespace e2e-tests-emptydir-dd4n6 deletion completed in 6.08493597s

• [SLOW TEST:8.284 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:00:24.290: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-ksdw8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:00:24.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-ksdw8" for this suite.
May 25 02:00:30.488: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:00:30.509: INFO: namespace: e2e-tests-kubelet-test-ksdw8, resource: bindings, ignored listing per whitelist
May 25 02:00:30.578: INFO: namespace e2e-tests-kubelet-test-ksdw8 deletion completed in 6.097917417s

• [SLOW TEST:6.288 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:00:30.579: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-4kpks
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-dfda6a34-7e90-11e9-802f-027f94874578
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-dfda6a34-7e90-11e9-802f-027f94874578
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:00:34.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-4kpks" for this suite.
May 25 02:00:56.816: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:00:56.868: INFO: namespace: e2e-tests-configmap-4kpks, resource: bindings, ignored listing per whitelist
May 25 02:00:56.892: INFO: namespace e2e-tests-configmap-4kpks deletion completed in 22.083978541s

• [SLOW TEST:26.313 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:00:56.893: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-vh96z
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:00:59.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-vh96z" for this suite.
May 25 02:01:39.087: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:01:39.106: INFO: namespace: e2e-tests-kubelet-test-vh96z, resource: bindings, ignored listing per whitelist
May 25 02:01:39.172: INFO: namespace e2e-tests-kubelet-test-vh96z deletion completed in 40.093982875s

• [SLOW TEST:42.279 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:01:39.175: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-qgztq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
May 25 02:01:39.341: INFO: Waiting up to 5m0s for pod "client-containers-08bb0f39-7e91-11e9-802f-027f94874578" in namespace "e2e-tests-containers-qgztq" to be "success or failure"
May 25 02:01:39.348: INFO: Pod "client-containers-08bb0f39-7e91-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 6.978515ms
May 25 02:01:41.351: INFO: Pod "client-containers-08bb0f39-7e91-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009913821s
STEP: Saw pod success
May 25 02:01:41.351: INFO: Pod "client-containers-08bb0f39-7e91-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 02:01:41.353: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod client-containers-08bb0f39-7e91-11e9-802f-027f94874578 container test-container: <nil>
STEP: delete the pod
May 25 02:01:41.372: INFO: Waiting for pod client-containers-08bb0f39-7e91-11e9-802f-027f94874578 to disappear
May 25 02:01:41.375: INFO: Pod client-containers-08bb0f39-7e91-11e9-802f-027f94874578 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:01:41.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-qgztq" for this suite.
May 25 02:01:47.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:01:47.431: INFO: namespace: e2e-tests-containers-qgztq, resource: bindings, ignored listing per whitelist
May 25 02:01:47.593: INFO: namespace e2e-tests-containers-qgztq deletion completed in 6.213430009s

• [SLOW TEST:8.419 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:01:47.595: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-bhslp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
May 25 02:01:47.754: INFO: Waiting up to 5m0s for pod "pod-0dbe9d64-7e91-11e9-802f-027f94874578" in namespace "e2e-tests-emptydir-bhslp" to be "success or failure"
May 25 02:01:47.760: INFO: Pod "pod-0dbe9d64-7e91-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 5.829645ms
May 25 02:01:49.763: INFO: Pod "pod-0dbe9d64-7e91-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008636613s
STEP: Saw pod success
May 25 02:01:49.763: INFO: Pod "pod-0dbe9d64-7e91-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 02:01:49.765: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-0dbe9d64-7e91-11e9-802f-027f94874578 container test-container: <nil>
STEP: delete the pod
May 25 02:01:49.781: INFO: Waiting for pod pod-0dbe9d64-7e91-11e9-802f-027f94874578 to disappear
May 25 02:01:49.783: INFO: Pod pod-0dbe9d64-7e91-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:01:49.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-bhslp" for this suite.
May 25 02:01:55.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:01:55.819: INFO: namespace: e2e-tests-emptydir-bhslp, resource: bindings, ignored listing per whitelist
May 25 02:01:55.887: INFO: namespace e2e-tests-emptydir-bhslp deletion completed in 6.100398346s

• [SLOW TEST:8.292 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:01:55.888: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-r9gj4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
May 25 02:01:56.081: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 02:01:56.086: INFO: Number of nodes with available pods: 0
May 25 02:01:56.086: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 02:01:57.093: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 02:01:57.096: INFO: Number of nodes with available pods: 0
May 25 02:01:57.096: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 02:01:58.089: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 02:01:58.092: INFO: Number of nodes with available pods: 2
May 25 02:01:58.092: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
May 25 02:01:58.112: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 02:01:58.120: INFO: Number of nodes with available pods: 1
May 25 02:01:58.120: INFO: Node alex-400-cp1718-vsp2-worker00f2b167f8 is running more than one daemon pod
May 25 02:01:59.124: INFO: DaemonSet pods can't tolerate node alex-400-cp1718-vsp2-master942457eba6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 25 02:01:59.127: INFO: Number of nodes with available pods: 2
May 25 02:01:59.127: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-r9gj4, will wait for the garbage collector to delete the pods
May 25 02:01:59.193: INFO: Deleting DaemonSet.extensions daemon-set took: 10.762076ms
May 25 02:01:59.293: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.203607ms
May 25 02:02:38.796: INFO: Number of nodes with available pods: 0
May 25 02:02:38.796: INFO: Number of running nodes: 0, number of available pods: 0
May 25 02:02:38.799: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-r9gj4/daemonsets","resourceVersion":"25042"},"items":null}

May 25 02:02:38.801: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-r9gj4/pods","resourceVersion":"25042"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:02:38.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-r9gj4" for this suite.
May 25 02:02:44.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:02:44.833: INFO: namespace: e2e-tests-daemonsets-r9gj4, resource: bindings, ignored listing per whitelist
May 25 02:02:44.903: INFO: namespace e2e-tests-daemonsets-r9gj4 deletion completed in 6.092788461s

• [SLOW TEST:49.015 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:02:44.905: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-lkdh6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
May 25 02:02:45.078: INFO: Waiting up to 5m0s for pod "client-containers-2fe99153-7e91-11e9-802f-027f94874578" in namespace "e2e-tests-containers-lkdh6" to be "success or failure"
May 25 02:02:45.082: INFO: Pod "client-containers-2fe99153-7e91-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 3.983176ms
May 25 02:02:47.085: INFO: Pod "client-containers-2fe99153-7e91-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006817151s
STEP: Saw pod success
May 25 02:02:47.085: INFO: Pod "client-containers-2fe99153-7e91-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 02:02:47.088: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod client-containers-2fe99153-7e91-11e9-802f-027f94874578 container test-container: <nil>
STEP: delete the pod
May 25 02:02:47.102: INFO: Waiting for pod client-containers-2fe99153-7e91-11e9-802f-027f94874578 to disappear
May 25 02:02:47.104: INFO: Pod client-containers-2fe99153-7e91-11e9-802f-027f94874578 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:02:47.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-lkdh6" for this suite.
May 25 02:02:53.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:02:53.172: INFO: namespace: e2e-tests-containers-lkdh6, resource: bindings, ignored listing per whitelist
May 25 02:02:53.206: INFO: namespace e2e-tests-containers-lkdh6 deletion completed in 6.099046658s

• [SLOW TEST:8.301 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:02:53.206: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-7ln2v
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
May 25 02:02:53.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 create -f - --namespace=e2e-tests-kubectl-7ln2v'
May 25 02:02:53.802: INFO: stderr: ""
May 25 02:02:53.803: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
May 25 02:02:54.805: INFO: Selector matched 1 pods for map[app:redis]
May 25 02:02:54.805: INFO: Found 0 / 1
May 25 02:02:55.806: INFO: Selector matched 1 pods for map[app:redis]
May 25 02:02:55.806: INFO: Found 1 / 1
May 25 02:02:55.806: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
May 25 02:02:55.808: INFO: Selector matched 1 pods for map[app:redis]
May 25 02:02:55.808: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 25 02:02:55.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 patch pod redis-master-lhzjb --namespace=e2e-tests-kubectl-7ln2v -p {"metadata":{"annotations":{"x":"y"}}}'
May 25 02:02:55.901: INFO: stderr: ""
May 25 02:02:55.901: INFO: stdout: "pod/redis-master-lhzjb patched\n"
STEP: checking annotations
May 25 02:02:55.904: INFO: Selector matched 1 pods for map[app:redis]
May 25 02:02:55.904: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:02:55.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7ln2v" for this suite.
May 25 02:03:17.916: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:03:17.953: INFO: namespace: e2e-tests-kubectl-7ln2v, resource: bindings, ignored listing per whitelist
May 25 02:03:17.993: INFO: namespace e2e-tests-kubectl-7ln2v deletion completed in 22.0864849s

• [SLOW TEST:24.787 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:03:17.995: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-2h8kx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
May 25 02:03:18.181: INFO: Pod name pod-release: Found 0 pods out of 1
May 25 02:03:23.184: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:03:23.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-2h8kx" for this suite.
May 25 02:03:29.238: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:03:29.254: INFO: namespace: e2e-tests-replication-controller-2h8kx, resource: bindings, ignored listing per whitelist
May 25 02:03:29.326: INFO: namespace e2e-tests-replication-controller-2h8kx deletion completed in 6.109107796s

• [SLOW TEST:11.331 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:03:29.329: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-vnbft
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-4a6389be-7e91-11e9-802f-027f94874578
STEP: Creating a pod to test consume configMaps
May 25 02:03:29.505: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4a6425cc-7e91-11e9-802f-027f94874578" in namespace "e2e-tests-projected-vnbft" to be "success or failure"
May 25 02:03:29.510: INFO: Pod "pod-projected-configmaps-4a6425cc-7e91-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 4.753348ms
May 25 02:03:31.512: INFO: Pod "pod-projected-configmaps-4a6425cc-7e91-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007178415s
STEP: Saw pod success
May 25 02:03:31.513: INFO: Pod "pod-projected-configmaps-4a6425cc-7e91-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 02:03:31.515: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-projected-configmaps-4a6425cc-7e91-11e9-802f-027f94874578 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 25 02:03:31.532: INFO: Waiting for pod pod-projected-configmaps-4a6425cc-7e91-11e9-802f-027f94874578 to disappear
May 25 02:03:31.534: INFO: Pod pod-projected-configmaps-4a6425cc-7e91-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:03:31.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vnbft" for this suite.
May 25 02:03:37.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:03:37.577: INFO: namespace: e2e-tests-projected-vnbft, resource: bindings, ignored listing per whitelist
May 25 02:03:37.620: INFO: namespace e2e-tests-projected-vnbft deletion completed in 6.082251898s

• [SLOW TEST:8.292 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:03:37.621: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-6ss9j
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
May 25 02:03:37.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 create -f - --namespace=e2e-tests-kubectl-6ss9j'
May 25 02:03:37.998: INFO: stderr: ""
May 25 02:03:37.998: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 25 02:03:37.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6ss9j'
May 25 02:03:38.119: INFO: stderr: ""
May 25 02:03:38.119: INFO: stdout: "update-demo-nautilus-46tpg update-demo-nautilus-q2sxg "
May 25 02:03:38.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods update-demo-nautilus-46tpg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6ss9j'
May 25 02:03:38.199: INFO: stderr: ""
May 25 02:03:38.199: INFO: stdout: ""
May 25 02:03:38.199: INFO: update-demo-nautilus-46tpg is created but not running
May 25 02:03:43.199: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6ss9j'
May 25 02:03:43.283: INFO: stderr: ""
May 25 02:03:43.283: INFO: stdout: "update-demo-nautilus-46tpg update-demo-nautilus-q2sxg "
May 25 02:03:43.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods update-demo-nautilus-46tpg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6ss9j'
May 25 02:03:43.380: INFO: stderr: ""
May 25 02:03:43.380: INFO: stdout: "true"
May 25 02:03:43.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods update-demo-nautilus-46tpg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6ss9j'
May 25 02:03:43.475: INFO: stderr: ""
May 25 02:03:43.475: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 25 02:03:43.475: INFO: validating pod update-demo-nautilus-46tpg
May 25 02:03:43.478: INFO: got data: {
  "image": "nautilus.jpg"
}

May 25 02:03:43.478: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 25 02:03:43.478: INFO: update-demo-nautilus-46tpg is verified up and running
May 25 02:03:43.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods update-demo-nautilus-q2sxg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6ss9j'
May 25 02:03:43.569: INFO: stderr: ""
May 25 02:03:43.569: INFO: stdout: "true"
May 25 02:03:43.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods update-demo-nautilus-q2sxg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6ss9j'
May 25 02:03:43.670: INFO: stderr: ""
May 25 02:03:43.670: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 25 02:03:43.670: INFO: validating pod update-demo-nautilus-q2sxg
May 25 02:03:43.674: INFO: got data: {
  "image": "nautilus.jpg"
}

May 25 02:03:43.674: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 25 02:03:43.674: INFO: update-demo-nautilus-q2sxg is verified up and running
STEP: rolling-update to new replication controller
May 25 02:03:43.675: INFO: scanned /root for discovery docs: <nil>
May 25 02:03:43.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-6ss9j'
May 25 02:04:06.078: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
May 25 02:04:06.078: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 25 02:04:06.078: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6ss9j'
May 25 02:04:06.176: INFO: stderr: ""
May 25 02:04:06.176: INFO: stdout: "update-demo-kitten-hh99b update-demo-kitten-vpcm5 "
May 25 02:04:06.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods update-demo-kitten-hh99b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6ss9j'
May 25 02:04:06.269: INFO: stderr: ""
May 25 02:04:06.269: INFO: stdout: "true"
May 25 02:04:06.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods update-demo-kitten-hh99b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6ss9j'
May 25 02:04:06.371: INFO: stderr: ""
May 25 02:04:06.371: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
May 25 02:04:06.371: INFO: validating pod update-demo-kitten-hh99b
May 25 02:04:06.375: INFO: got data: {
  "image": "kitten.jpg"
}

May 25 02:04:06.375: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
May 25 02:04:06.375: INFO: update-demo-kitten-hh99b is verified up and running
May 25 02:04:06.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods update-demo-kitten-vpcm5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6ss9j'
May 25 02:04:06.469: INFO: stderr: ""
May 25 02:04:06.469: INFO: stdout: "true"
May 25 02:04:06.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods update-demo-kitten-vpcm5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6ss9j'
May 25 02:04:06.568: INFO: stderr: ""
May 25 02:04:06.568: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
May 25 02:04:06.568: INFO: validating pod update-demo-kitten-vpcm5
May 25 02:04:06.571: INFO: got data: {
  "image": "kitten.jpg"
}

May 25 02:04:06.571: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
May 25 02:04:06.571: INFO: update-demo-kitten-vpcm5 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:04:06.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6ss9j" for this suite.
May 25 02:04:28.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:04:28.607: INFO: namespace: e2e-tests-kubectl-6ss9j, resource: bindings, ignored listing per whitelist
May 25 02:04:28.681: INFO: namespace e2e-tests-kubectl-6ss9j deletion completed in 22.105674913s

• [SLOW TEST:51.059 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:04:28.681: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-hnw5v
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
May 25 02:04:32.877: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 25 02:04:32.879: INFO: Pod pod-with-poststart-exec-hook still exists
May 25 02:04:34.879: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 25 02:04:34.882: INFO: Pod pod-with-poststart-exec-hook still exists
May 25 02:04:36.879: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 25 02:04:36.882: INFO: Pod pod-with-poststart-exec-hook still exists
May 25 02:04:38.879: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 25 02:04:38.882: INFO: Pod pod-with-poststart-exec-hook still exists
May 25 02:04:40.879: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 25 02:04:40.883: INFO: Pod pod-with-poststart-exec-hook still exists
May 25 02:04:42.879: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 25 02:04:42.883: INFO: Pod pod-with-poststart-exec-hook still exists
May 25 02:04:44.879: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 25 02:04:44.882: INFO: Pod pod-with-poststart-exec-hook still exists
May 25 02:04:46.879: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 25 02:04:46.882: INFO: Pod pod-with-poststart-exec-hook still exists
May 25 02:04:48.879: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 25 02:04:48.885: INFO: Pod pod-with-poststart-exec-hook still exists
May 25 02:04:50.879: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 25 02:04:50.882: INFO: Pod pod-with-poststart-exec-hook still exists
May 25 02:04:52.879: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 25 02:04:52.885: INFO: Pod pod-with-poststart-exec-hook still exists
May 25 02:04:54.879: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 25 02:04:54.882: INFO: Pod pod-with-poststart-exec-hook still exists
May 25 02:04:56.879: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 25 02:04:56.882: INFO: Pod pod-with-poststart-exec-hook still exists
May 25 02:04:58.879: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 25 02:04:58.883: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:04:58.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-hnw5v" for this suite.
May 25 02:05:20.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:05:20.948: INFO: namespace: e2e-tests-container-lifecycle-hook-hnw5v, resource: bindings, ignored listing per whitelist
May 25 02:05:20.977: INFO: namespace e2e-tests-container-lifecycle-hook-hnw5v deletion completed in 22.090633527s

• [SLOW TEST:52.297 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:05:20.980: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-x4zhf
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-8cf0138d-7e91-11e9-802f-027f94874578
STEP: Creating secret with name s-test-opt-upd-8cf013d9-7e91-11e9-802f-027f94874578
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-8cf0138d-7e91-11e9-802f-027f94874578
STEP: Updating secret s-test-opt-upd-8cf013d9-7e91-11e9-802f-027f94874578
STEP: Creating secret with name s-test-opt-create-8cf01401-7e91-11e9-802f-027f94874578
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:05:25.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-x4zhf" for this suite.
May 25 02:05:47.229: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:05:47.298: INFO: namespace: e2e-tests-secrets-x4zhf, resource: bindings, ignored listing per whitelist
May 25 02:05:47.319: INFO: namespace e2e-tests-secrets-x4zhf deletion completed in 22.100310421s

• [SLOW TEST:26.340 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:05:47.322: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-7dg94
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-7dg94
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-7dg94
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-7dg94
May 25 02:05:47.515: INFO: Found 0 stateful pods, waiting for 1
May 25 02:05:57.519: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
May 25 02:05:57.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-7dg94 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 25 02:05:57.660: INFO: stderr: ""
May 25 02:05:57.660: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 25 02:05:57.660: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 25 02:05:57.663: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May 25 02:06:07.667: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 25 02:06:07.667: INFO: Waiting for statefulset status.replicas updated to 0
May 25 02:06:07.679: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998745s
May 25 02:06:08.682: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.997478652s
May 25 02:06:09.686: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.994211307s
May 25 02:06:10.689: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.990797951s
May 25 02:06:11.692: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.987964423s
May 25 02:06:12.695: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.985154991s
May 25 02:06:13.698: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.982130498s
May 25 02:06:14.701: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.978336829s
May 25 02:06:15.704: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.97543671s
May 25 02:06:16.708: INFO: Verifying statefulset ss doesn't scale past 1 for another 972.239339ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-7dg94
May 25 02:06:17.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-7dg94 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 25 02:06:17.843: INFO: stderr: ""
May 25 02:06:17.843: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 25 02:06:17.843: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 25 02:06:17.846: INFO: Found 1 stateful pods, waiting for 3
May 25 02:06:27.849: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May 25 02:06:27.849: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May 25 02:06:27.849: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
May 25 02:06:27.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-7dg94 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 25 02:06:27.993: INFO: stderr: ""
May 25 02:06:27.993: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 25 02:06:27.993: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 25 02:06:27.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-7dg94 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 25 02:06:28.137: INFO: stderr: ""
May 25 02:06:28.137: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 25 02:06:28.137: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 25 02:06:28.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-7dg94 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 25 02:06:28.278: INFO: stderr: ""
May 25 02:06:28.278: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 25 02:06:28.278: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 25 02:06:28.278: INFO: Waiting for statefulset status.replicas updated to 0
May 25 02:06:28.281: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
May 25 02:06:38.287: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 25 02:06:38.287: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May 25 02:06:38.287: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May 25 02:06:38.301: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998867s
May 25 02:06:39.305: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.993837708s
May 25 02:06:40.317: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.986718667s
May 25 02:06:41.320: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.978044152s
May 25 02:06:42.324: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.974843928s
May 25 02:06:43.327: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.971388792s
May 25 02:06:44.331: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.967885524s
May 25 02:06:45.334: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.964219769s
May 25 02:06:46.338: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.960889443s
May 25 02:06:47.342: INFO: Verifying statefulset ss doesn't scale past 3 for another 956.840432ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-7dg94
May 25 02:06:48.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-7dg94 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 25 02:06:48.492: INFO: stderr: ""
May 25 02:06:48.492: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 25 02:06:48.492: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 25 02:06:48.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-7dg94 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 25 02:06:48.654: INFO: stderr: ""
May 25 02:06:48.654: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 25 02:06:48.654: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 25 02:06:48.655: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 exec --namespace=e2e-tests-statefulset-7dg94 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 25 02:06:48.788: INFO: stderr: ""
May 25 02:06:48.788: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 25 02:06:48.788: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 25 02:06:48.788: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 25 02:07:08.804: INFO: Deleting all statefulset in ns e2e-tests-statefulset-7dg94
May 25 02:07:08.808: INFO: Scaling statefulset ss to 0
May 25 02:07:08.816: INFO: Waiting for statefulset status.replicas updated to 0
May 25 02:07:08.818: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:07:08.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-7dg94" for this suite.
May 25 02:07:14.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:07:14.909: INFO: namespace: e2e-tests-statefulset-7dg94, resource: bindings, ignored listing per whitelist
May 25 02:07:14.927: INFO: namespace e2e-tests-statefulset-7dg94 deletion completed in 6.084993575s

• [SLOW TEST:87.605 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:07:14.931: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-p4jhz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
May 25 02:07:19.137: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 25 02:07:19.140: INFO: Pod pod-with-prestop-http-hook still exists
May 25 02:07:21.140: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 25 02:07:21.143: INFO: Pod pod-with-prestop-http-hook still exists
May 25 02:07:23.140: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 25 02:07:23.143: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:07:23.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-p4jhz" for this suite.
May 25 02:07:45.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:07:45.201: INFO: namespace: e2e-tests-container-lifecycle-hook-p4jhz, resource: bindings, ignored listing per whitelist
May 25 02:07:45.241: INFO: namespace e2e-tests-container-lifecycle-hook-p4jhz deletion completed in 22.086804272s

• [SLOW TEST:30.310 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:07:45.241: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-ps6kl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
May 25 02:07:45.414: INFO: Waiting up to 5m0s for pod "pod-e2ed1a8e-7e91-11e9-802f-027f94874578" in namespace "e2e-tests-emptydir-ps6kl" to be "success or failure"
May 25 02:07:45.419: INFO: Pod "pod-e2ed1a8e-7e91-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 4.632265ms
May 25 02:07:47.421: INFO: Pod "pod-e2ed1a8e-7e91-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007081154s
STEP: Saw pod success
May 25 02:07:47.421: INFO: Pod "pod-e2ed1a8e-7e91-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 02:07:47.424: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-e2ed1a8e-7e91-11e9-802f-027f94874578 container test-container: <nil>
STEP: delete the pod
May 25 02:07:47.440: INFO: Waiting for pod pod-e2ed1a8e-7e91-11e9-802f-027f94874578 to disappear
May 25 02:07:47.442: INFO: Pod pod-e2ed1a8e-7e91-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:07:47.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-ps6kl" for this suite.
May 25 02:07:53.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:07:53.526: INFO: namespace: e2e-tests-emptydir-ps6kl, resource: bindings, ignored listing per whitelist
May 25 02:07:53.532: INFO: namespace e2e-tests-emptydir-ps6kl deletion completed in 6.085929602s

• [SLOW TEST:8.290 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:07:53.532: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-mnlws
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 25 02:07:53.695: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e7dc787b-7e91-11e9-802f-027f94874578" in namespace "e2e-tests-projected-mnlws" to be "success or failure"
May 25 02:07:53.700: INFO: Pod "downwardapi-volume-e7dc787b-7e91-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 4.548179ms
May 25 02:07:55.702: INFO: Pod "downwardapi-volume-e7dc787b-7e91-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007403575s
STEP: Saw pod success
May 25 02:07:55.703: INFO: Pod "downwardapi-volume-e7dc787b-7e91-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 02:07:55.705: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod downwardapi-volume-e7dc787b-7e91-11e9-802f-027f94874578 container client-container: <nil>
STEP: delete the pod
May 25 02:07:55.725: INFO: Waiting for pod downwardapi-volume-e7dc787b-7e91-11e9-802f-027f94874578 to disappear
May 25 02:07:55.727: INFO: Pod downwardapi-volume-e7dc787b-7e91-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:07:55.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mnlws" for this suite.
May 25 02:08:01.739: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:08:01.770: INFO: namespace: e2e-tests-projected-mnlws, resource: bindings, ignored listing per whitelist
May 25 02:08:01.851: INFO: namespace e2e-tests-projected-mnlws deletion completed in 6.119885025s

• [SLOW TEST:8.319 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:08:01.851: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-rw2s2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
May 25 02:08:02.064: INFO: Waiting up to 5m0s for pod "pod-ecd9cdc6-7e91-11e9-802f-027f94874578" in namespace "e2e-tests-emptydir-rw2s2" to be "success or failure"
May 25 02:08:02.069: INFO: Pod "pod-ecd9cdc6-7e91-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 5.405713ms
May 25 02:08:04.072: INFO: Pod "pod-ecd9cdc6-7e91-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007950094s
STEP: Saw pod success
May 25 02:08:04.072: INFO: Pod "pod-ecd9cdc6-7e91-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 02:08:04.078: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-ecd9cdc6-7e91-11e9-802f-027f94874578 container test-container: <nil>
STEP: delete the pod
May 25 02:08:04.104: INFO: Waiting for pod pod-ecd9cdc6-7e91-11e9-802f-027f94874578 to disappear
May 25 02:08:04.105: INFO: Pod pod-ecd9cdc6-7e91-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:08:04.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-rw2s2" for this suite.
May 25 02:08:10.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:08:10.128: INFO: namespace: e2e-tests-emptydir-rw2s2, resource: bindings, ignored listing per whitelist
May 25 02:08:10.213: INFO: namespace e2e-tests-emptydir-rw2s2 deletion completed in 6.104754997s

• [SLOW TEST:8.362 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:08:10.215: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-t64fp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-d2xw
STEP: Creating a pod to test atomic-volume-subpath
May 25 02:08:10.386: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-d2xw" in namespace "e2e-tests-subpath-t64fp" to be "success or failure"
May 25 02:08:10.393: INFO: Pod "pod-subpath-test-configmap-d2xw": Phase="Pending", Reason="", readiness=false. Elapsed: 6.791971ms
May 25 02:08:12.396: INFO: Pod "pod-subpath-test-configmap-d2xw": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009561908s
May 25 02:08:14.399: INFO: Pod "pod-subpath-test-configmap-d2xw": Phase="Running", Reason="", readiness=false. Elapsed: 4.012334905s
May 25 02:08:16.402: INFO: Pod "pod-subpath-test-configmap-d2xw": Phase="Running", Reason="", readiness=false. Elapsed: 6.015176485s
May 25 02:08:18.404: INFO: Pod "pod-subpath-test-configmap-d2xw": Phase="Running", Reason="", readiness=false. Elapsed: 8.017955207s
May 25 02:08:20.407: INFO: Pod "pod-subpath-test-configmap-d2xw": Phase="Running", Reason="", readiness=false. Elapsed: 10.020299937s
May 25 02:08:22.409: INFO: Pod "pod-subpath-test-configmap-d2xw": Phase="Running", Reason="", readiness=false. Elapsed: 12.02256879s
May 25 02:08:24.412: INFO: Pod "pod-subpath-test-configmap-d2xw": Phase="Running", Reason="", readiness=false. Elapsed: 14.025208347s
May 25 02:08:26.414: INFO: Pod "pod-subpath-test-configmap-d2xw": Phase="Running", Reason="", readiness=false. Elapsed: 16.027808792s
May 25 02:08:28.417: INFO: Pod "pod-subpath-test-configmap-d2xw": Phase="Running", Reason="", readiness=false. Elapsed: 18.030788122s
May 25 02:08:30.423: INFO: Pod "pod-subpath-test-configmap-d2xw": Phase="Running", Reason="", readiness=false. Elapsed: 20.03681168s
May 25 02:08:32.427: INFO: Pod "pod-subpath-test-configmap-d2xw": Phase="Running", Reason="", readiness=false. Elapsed: 22.040863283s
May 25 02:08:34.430: INFO: Pod "pod-subpath-test-configmap-d2xw": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.043728187s
STEP: Saw pod success
May 25 02:08:34.430: INFO: Pod "pod-subpath-test-configmap-d2xw" satisfied condition "success or failure"
May 25 02:08:34.433: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-subpath-test-configmap-d2xw container test-container-subpath-configmap-d2xw: <nil>
STEP: delete the pod
May 25 02:08:34.452: INFO: Waiting for pod pod-subpath-test-configmap-d2xw to disappear
May 25 02:08:34.454: INFO: Pod pod-subpath-test-configmap-d2xw no longer exists
STEP: Deleting pod pod-subpath-test-configmap-d2xw
May 25 02:08:34.454: INFO: Deleting pod "pod-subpath-test-configmap-d2xw" in namespace "e2e-tests-subpath-t64fp"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:08:34.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-t64fp" for this suite.
May 25 02:08:40.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:08:40.479: INFO: namespace: e2e-tests-subpath-t64fp, resource: bindings, ignored listing per whitelist
May 25 02:08:40.543: INFO: namespace e2e-tests-subpath-t64fp deletion completed in 6.083695556s

• [SLOW TEST:30.328 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:08:40.545: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-hzk7k
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-03e2fad5-7e92-11e9-802f-027f94874578
STEP: Creating a pod to test consume configMaps
May 25 02:08:40.714: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-03e37b31-7e92-11e9-802f-027f94874578" in namespace "e2e-tests-projected-hzk7k" to be "success or failure"
May 25 02:08:40.721: INFO: Pod "pod-projected-configmaps-03e37b31-7e92-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 6.147046ms
May 25 02:08:42.723: INFO: Pod "pod-projected-configmaps-03e37b31-7e92-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008869822s
STEP: Saw pod success
May 25 02:08:42.723: INFO: Pod "pod-projected-configmaps-03e37b31-7e92-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 02:08:42.725: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-projected-configmaps-03e37b31-7e92-11e9-802f-027f94874578 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 25 02:08:42.743: INFO: Waiting for pod pod-projected-configmaps-03e37b31-7e92-11e9-802f-027f94874578 to disappear
May 25 02:08:42.745: INFO: Pod pod-projected-configmaps-03e37b31-7e92-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:08:42.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hzk7k" for this suite.
May 25 02:08:48.758: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:08:48.798: INFO: namespace: e2e-tests-projected-hzk7k, resource: bindings, ignored listing per whitelist
May 25 02:08:48.843: INFO: namespace e2e-tests-projected-hzk7k deletion completed in 6.094386406s

• [SLOW TEST:8.298 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:08:48.844: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-x9fcm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-08d53542-7e92-11e9-802f-027f94874578
STEP: Creating a pod to test consume configMaps
May 25 02:08:49.012: INFO: Waiting up to 5m0s for pod "pod-configmaps-08d5bac3-7e92-11e9-802f-027f94874578" in namespace "e2e-tests-configmap-x9fcm" to be "success or failure"
May 25 02:08:49.014: INFO: Pod "pod-configmaps-08d5bac3-7e92-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 2.558432ms
May 25 02:08:51.017: INFO: Pod "pod-configmaps-08d5bac3-7e92-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0051697s
STEP: Saw pod success
May 25 02:08:51.017: INFO: Pod "pod-configmaps-08d5bac3-7e92-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 02:08:51.019: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-configmaps-08d5bac3-7e92-11e9-802f-027f94874578 container configmap-volume-test: <nil>
STEP: delete the pod
May 25 02:08:51.058: INFO: Waiting for pod pod-configmaps-08d5bac3-7e92-11e9-802f-027f94874578 to disappear
May 25 02:08:51.061: INFO: Pod pod-configmaps-08d5bac3-7e92-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:08:51.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-x9fcm" for this suite.
May 25 02:08:57.076: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:08:57.103: INFO: namespace: e2e-tests-configmap-x9fcm, resource: bindings, ignored listing per whitelist
May 25 02:08:57.150: INFO: namespace e2e-tests-configmap-x9fcm deletion completed in 6.081878702s

• [SLOW TEST:8.306 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:08:57.150: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-8sl86
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
May 25 02:08:57.306: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 create -f - --namespace=e2e-tests-kubectl-8sl86'
May 25 02:08:57.498: INFO: stderr: ""
May 25 02:08:57.498: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 25 02:08:57.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-8sl86'
May 25 02:08:57.621: INFO: stderr: ""
May 25 02:08:57.621: INFO: stdout: "update-demo-nautilus-fl8bx update-demo-nautilus-r6ww2 "
May 25 02:08:57.621: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods update-demo-nautilus-fl8bx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8sl86'
May 25 02:08:57.707: INFO: stderr: ""
May 25 02:08:57.707: INFO: stdout: ""
May 25 02:08:57.707: INFO: update-demo-nautilus-fl8bx is created but not running
May 25 02:09:02.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-8sl86'
May 25 02:09:02.793: INFO: stderr: ""
May 25 02:09:02.793: INFO: stdout: "update-demo-nautilus-fl8bx update-demo-nautilus-r6ww2 "
May 25 02:09:02.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods update-demo-nautilus-fl8bx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8sl86'
May 25 02:09:02.883: INFO: stderr: ""
May 25 02:09:02.883: INFO: stdout: "true"
May 25 02:09:02.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods update-demo-nautilus-fl8bx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8sl86'
May 25 02:09:02.976: INFO: stderr: ""
May 25 02:09:02.976: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 25 02:09:02.976: INFO: validating pod update-demo-nautilus-fl8bx
May 25 02:09:02.979: INFO: got data: {
  "image": "nautilus.jpg"
}

May 25 02:09:02.980: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 25 02:09:02.980: INFO: update-demo-nautilus-fl8bx is verified up and running
May 25 02:09:02.980: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods update-demo-nautilus-r6ww2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8sl86'
May 25 02:09:03.075: INFO: stderr: ""
May 25 02:09:03.075: INFO: stdout: "true"
May 25 02:09:03.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods update-demo-nautilus-r6ww2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8sl86'
May 25 02:09:03.165: INFO: stderr: ""
May 25 02:09:03.165: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 25 02:09:03.165: INFO: validating pod update-demo-nautilus-r6ww2
May 25 02:09:03.169: INFO: got data: {
  "image": "nautilus.jpg"
}

May 25 02:09:03.169: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 25 02:09:03.169: INFO: update-demo-nautilus-r6ww2 is verified up and running
STEP: scaling down the replication controller
May 25 02:09:03.171: INFO: scanned /root for discovery docs: <nil>
May 25 02:09:03.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-8sl86'
May 25 02:09:04.305: INFO: stderr: ""
May 25 02:09:04.305: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 25 02:09:04.305: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-8sl86'
May 25 02:09:04.404: INFO: stderr: ""
May 25 02:09:04.404: INFO: stdout: "update-demo-nautilus-fl8bx update-demo-nautilus-r6ww2 "
STEP: Replicas for name=update-demo: expected=1 actual=2
May 25 02:09:09.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-8sl86'
May 25 02:09:09.495: INFO: stderr: ""
May 25 02:09:09.495: INFO: stdout: "update-demo-nautilus-r6ww2 "
May 25 02:09:09.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods update-demo-nautilus-r6ww2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8sl86'
May 25 02:09:09.584: INFO: stderr: ""
May 25 02:09:09.584: INFO: stdout: "true"
May 25 02:09:09.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods update-demo-nautilus-r6ww2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8sl86'
May 25 02:09:09.673: INFO: stderr: ""
May 25 02:09:09.673: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 25 02:09:09.673: INFO: validating pod update-demo-nautilus-r6ww2
May 25 02:09:09.676: INFO: got data: {
  "image": "nautilus.jpg"
}

May 25 02:09:09.676: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 25 02:09:09.676: INFO: update-demo-nautilus-r6ww2 is verified up and running
STEP: scaling up the replication controller
May 25 02:09:09.677: INFO: scanned /root for discovery docs: <nil>
May 25 02:09:09.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-8sl86'
May 25 02:09:10.787: INFO: stderr: ""
May 25 02:09:10.787: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 25 02:09:10.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-8sl86'
May 25 02:09:10.879: INFO: stderr: ""
May 25 02:09:10.879: INFO: stdout: "update-demo-nautilus-nddz4 update-demo-nautilus-r6ww2 "
May 25 02:09:10.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods update-demo-nautilus-nddz4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8sl86'
May 25 02:09:10.961: INFO: stderr: ""
May 25 02:09:10.961: INFO: stdout: ""
May 25 02:09:10.961: INFO: update-demo-nautilus-nddz4 is created but not running
May 25 02:09:15.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-8sl86'
May 25 02:09:16.056: INFO: stderr: ""
May 25 02:09:16.056: INFO: stdout: "update-demo-nautilus-nddz4 update-demo-nautilus-r6ww2 "
May 25 02:09:16.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods update-demo-nautilus-nddz4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8sl86'
May 25 02:09:16.157: INFO: stderr: ""
May 25 02:09:16.157: INFO: stdout: "true"
May 25 02:09:16.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods update-demo-nautilus-nddz4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8sl86'
May 25 02:09:16.248: INFO: stderr: ""
May 25 02:09:16.248: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 25 02:09:16.248: INFO: validating pod update-demo-nautilus-nddz4
May 25 02:09:16.253: INFO: got data: {
  "image": "nautilus.jpg"
}

May 25 02:09:16.253: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 25 02:09:16.253: INFO: update-demo-nautilus-nddz4 is verified up and running
May 25 02:09:16.253: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods update-demo-nautilus-r6ww2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8sl86'
May 25 02:09:16.344: INFO: stderr: ""
May 25 02:09:16.344: INFO: stdout: "true"
May 25 02:09:16.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods update-demo-nautilus-r6ww2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8sl86'
May 25 02:09:16.430: INFO: stderr: ""
May 25 02:09:16.430: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 25 02:09:16.430: INFO: validating pod update-demo-nautilus-r6ww2
May 25 02:09:16.433: INFO: got data: {
  "image": "nautilus.jpg"
}

May 25 02:09:16.434: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 25 02:09:16.434: INFO: update-demo-nautilus-r6ww2 is verified up and running
STEP: using delete to clean up resources
May 25 02:09:16.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-8sl86'
May 25 02:09:16.526: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 25 02:09:16.526: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May 25 02:09:16.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-8sl86'
May 25 02:09:16.646: INFO: stderr: "No resources found.\n"
May 25 02:09:16.646: INFO: stdout: ""
May 25 02:09:16.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 get pods -l name=update-demo --namespace=e2e-tests-kubectl-8sl86 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 25 02:09:16.728: INFO: stderr: ""
May 25 02:09:16.728: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:09:16.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8sl86" for this suite.
May 25 02:09:38.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:09:38.793: INFO: namespace: e2e-tests-kubectl-8sl86, resource: bindings, ignored listing per whitelist
May 25 02:09:38.820: INFO: namespace e2e-tests-kubectl-8sl86 deletion completed in 22.087071242s

• [SLOW TEST:41.670 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:09:38.824: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-blkk7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-blkk7/configmap-test-269f89a7-7e92-11e9-802f-027f94874578
STEP: Creating a pod to test consume configMaps
May 25 02:09:38.990: INFO: Waiting up to 5m0s for pod "pod-configmaps-26a00737-7e92-11e9-802f-027f94874578" in namespace "e2e-tests-configmap-blkk7" to be "success or failure"
May 25 02:09:38.998: INFO: Pod "pod-configmaps-26a00737-7e92-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 7.598684ms
May 25 02:09:41.001: INFO: Pod "pod-configmaps-26a00737-7e92-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010895722s
STEP: Saw pod success
May 25 02:09:41.001: INFO: Pod "pod-configmaps-26a00737-7e92-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 02:09:41.004: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-configmaps-26a00737-7e92-11e9-802f-027f94874578 container env-test: <nil>
STEP: delete the pod
May 25 02:09:41.023: INFO: Waiting for pod pod-configmaps-26a00737-7e92-11e9-802f-027f94874578 to disappear
May 25 02:09:41.024: INFO: Pod pod-configmaps-26a00737-7e92-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:09:41.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-blkk7" for this suite.
May 25 02:09:47.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:09:47.100: INFO: namespace: e2e-tests-configmap-blkk7, resource: bindings, ignored listing per whitelist
May 25 02:09:47.118: INFO: namespace e2e-tests-configmap-blkk7 deletion completed in 6.089465185s

• [SLOW TEST:8.293 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:09:47.118: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-hvpvx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
May 25 02:09:47.279: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:09:51.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-hvpvx" for this suite.
May 25 02:10:13.377: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:10:13.439: INFO: namespace: e2e-tests-init-container-hvpvx, resource: bindings, ignored listing per whitelist
May 25 02:10:13.473: INFO: namespace e2e-tests-init-container-hvpvx deletion completed in 22.103298873s

• [SLOW TEST:26.355 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:10:13.475: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-7c2q9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
May 25 02:10:13.630: INFO: namespace e2e-tests-kubectl-7c2q9
May 25 02:10:13.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 create -f - --namespace=e2e-tests-kubectl-7c2q9'
May 25 02:10:13.833: INFO: stderr: ""
May 25 02:10:13.833: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
May 25 02:10:14.836: INFO: Selector matched 1 pods for map[app:redis]
May 25 02:10:14.836: INFO: Found 0 / 1
May 25 02:10:15.836: INFO: Selector matched 1 pods for map[app:redis]
May 25 02:10:15.836: INFO: Found 1 / 1
May 25 02:10:15.836: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 25 02:10:15.838: INFO: Selector matched 1 pods for map[app:redis]
May 25 02:10:15.838: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 25 02:10:15.838: INFO: wait on redis-master startup in e2e-tests-kubectl-7c2q9 
May 25 02:10:15.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 logs redis-master-4dqbp redis-master --namespace=e2e-tests-kubectl-7c2q9'
May 25 02:10:15.956: INFO: stderr: ""
May 25 02:10:15.956: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 25 May 02:10:15.452 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 25 May 02:10:15.452 # Server started, Redis version 3.2.12\n1:M 25 May 02:10:15.452 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 25 May 02:10:15.452 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
May 25 02:10:15.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-7c2q9'
May 25 02:10:16.062: INFO: stderr: ""
May 25 02:10:16.062: INFO: stdout: "service/rm2 exposed\n"
May 25 02:10:16.070: INFO: Service rm2 in namespace e2e-tests-kubectl-7c2q9 found.
STEP: exposing service
May 25 02:10:18.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-7c2q9'
May 25 02:10:18.198: INFO: stderr: ""
May 25 02:10:18.198: INFO: stdout: "service/rm3 exposed\n"
May 25 02:10:18.201: INFO: Service rm3 in namespace e2e-tests-kubectl-7c2q9 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:10:20.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7c2q9" for this suite.
May 25 02:10:42.216: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:10:42.273: INFO: namespace: e2e-tests-kubectl-7c2q9, resource: bindings, ignored listing per whitelist
May 25 02:10:42.294: INFO: namespace e2e-tests-kubectl-7c2q9 deletion completed in 22.084839128s

• [SLOW TEST:28.819 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:10:42.294: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-nrl9k
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
May 25 02:10:42.481: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-nrl9k,SelfLink:/api/v1/namespaces/e2e-tests-watch-nrl9k/configmaps/e2e-watch-test-watch-closed,UID:4c7656d9-7e92-11e9-ba33-0050569e7ba0,ResourceVersion:26863,Generation:0,CreationTimestamp:2019-05-25 02:10:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 25 02:10:42.481: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-nrl9k,SelfLink:/api/v1/namespaces/e2e-tests-watch-nrl9k/configmaps/e2e-watch-test-watch-closed,UID:4c7656d9-7e92-11e9-ba33-0050569e7ba0,ResourceVersion:26864,Generation:0,CreationTimestamp:2019-05-25 02:10:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
May 25 02:10:42.491: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-nrl9k,SelfLink:/api/v1/namespaces/e2e-tests-watch-nrl9k/configmaps/e2e-watch-test-watch-closed,UID:4c7656d9-7e92-11e9-ba33-0050569e7ba0,ResourceVersion:26865,Generation:0,CreationTimestamp:2019-05-25 02:10:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 25 02:10:42.491: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-nrl9k,SelfLink:/api/v1/namespaces/e2e-tests-watch-nrl9k/configmaps/e2e-watch-test-watch-closed,UID:4c7656d9-7e92-11e9-ba33-0050569e7ba0,ResourceVersion:26866,Generation:0,CreationTimestamp:2019-05-25 02:10:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:10:42.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-nrl9k" for this suite.
May 25 02:10:48.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:10:48.532: INFO: namespace: e2e-tests-watch-nrl9k, resource: bindings, ignored listing per whitelist
May 25 02:10:48.579: INFO: namespace e2e-tests-watch-nrl9k deletion completed in 6.085031589s

• [SLOW TEST:6.285 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:10:48.579: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-rvdnc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-rvdnc
May 25 02:10:50.753: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-rvdnc
STEP: checking the pod's current state and verifying that restartCount is present
May 25 02:10:50.760: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:14:51.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-rvdnc" for this suite.
May 25 02:14:57.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:14:57.213: INFO: namespace: e2e-tests-container-probe-rvdnc, resource: bindings, ignored listing per whitelist
May 25 02:14:57.233: INFO: namespace e2e-tests-container-probe-rvdnc deletion completed in 6.087475111s

• [SLOW TEST:248.654 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:14:57.234: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-z8lfz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 25 02:14:57.408: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e46a335b-7e92-11e9-802f-027f94874578" in namespace "e2e-tests-projected-z8lfz" to be "success or failure"
May 25 02:14:57.416: INFO: Pod "downwardapi-volume-e46a335b-7e92-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 8.232969ms
May 25 02:14:59.419: INFO: Pod "downwardapi-volume-e46a335b-7e92-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011134549s
STEP: Saw pod success
May 25 02:14:59.419: INFO: Pod "downwardapi-volume-e46a335b-7e92-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 02:14:59.421: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod downwardapi-volume-e46a335b-7e92-11e9-802f-027f94874578 container client-container: <nil>
STEP: delete the pod
May 25 02:14:59.440: INFO: Waiting for pod downwardapi-volume-e46a335b-7e92-11e9-802f-027f94874578 to disappear
May 25 02:14:59.442: INFO: Pod downwardapi-volume-e46a335b-7e92-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:14:59.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-z8lfz" for this suite.
May 25 02:15:05.455: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:15:05.529: INFO: namespace: e2e-tests-projected-z8lfz, resource: bindings, ignored listing per whitelist
May 25 02:15:05.549: INFO: namespace e2e-tests-projected-z8lfz deletion completed in 6.101634023s

• [SLOW TEST:8.315 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:15:05.549: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-9r2sd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-56lmh in namespace e2e-tests-proxy-9r2sd
I0525 02:15:05.727717      15 runners.go:184] Created replication controller with name: proxy-service-56lmh, namespace: e2e-tests-proxy-9r2sd, replica count: 1
I0525 02:15:06.778070      15 runners.go:184] proxy-service-56lmh Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0525 02:15:07.778331      15 runners.go:184] proxy-service-56lmh Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0525 02:15:08.778511      15 runners.go:184] proxy-service-56lmh Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0525 02:15:09.778695      15 runners.go:184] proxy-service-56lmh Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0525 02:15:10.778915      15 runners.go:184] proxy-service-56lmh Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0525 02:15:11.779136      15 runners.go:184] proxy-service-56lmh Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 25 02:15:11.781: INFO: setup took 6.07487389s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
May 25 02:15:11.791: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw/proxy/rewriteme"... (200; 9.490315ms)
May 25 02:15:11.796: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:162/proxy/: bar (200; 13.288998ms)
May 25 02:15:11.796: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:1080/proxy/rewri... (200; 14.704553ms)
May 25 02:15:11.800: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:162/proxy/: bar (200; 17.19611ms)
May 25 02:15:11.800: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:160/proxy/: foo (200; 17.502056ms)
May 25 02:15:11.801: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:1080/proxy/... (200; 17.536534ms)
May 25 02:15:11.801: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:160/proxy/: foo (200; 17.748326ms)
May 25 02:15:11.803: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/proxy-service-56lmh:portname1/proxy/: foo (200; 19.676569ms)
May 25 02:15:11.804: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:460/proxy/: tls baz (200; 20.758226ms)
May 25 02:15:11.805: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/https:proxy-service-56lmh:tlsportname1/proxy/: tls baz (200; 22.408125ms)
May 25 02:15:11.805: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/http:proxy-service-56lmh:portname2/proxy/: bar (200; 22.129406ms)
May 25 02:15:11.806: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/proxy-service-56lmh:portname2/proxy/: bar (200; 22.387369ms)
May 25 02:15:11.806: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/https:proxy-service-56lmh:tlsportname2/proxy/: tls qux (200; 22.692564ms)
May 25 02:15:11.806: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/http:proxy-service-56lmh:portname1/proxy/: foo (200; 22.607951ms)
May 25 02:15:11.806: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:462/proxy/: tls qux (200; 22.3894ms)
May 25 02:15:11.807: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:443/proxy/... (200; 24.084233ms)
May 25 02:15:11.825: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw/proxy/rewriteme"... (200; 16.372199ms)
May 25 02:15:11.825: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:162/proxy/: bar (200; 8.991958ms)
May 25 02:15:11.825: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:1080/proxy/... (200; 12.772606ms)
May 25 02:15:11.825: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:160/proxy/: foo (200; 16.385723ms)
May 25 02:15:11.825: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:460/proxy/: tls baz (200; 18.089194ms)
May 25 02:15:11.825: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:443/proxy/... (200; 12.427558ms)
May 25 02:15:11.826: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:462/proxy/: tls qux (200; 15.229655ms)
May 25 02:15:11.834: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:162/proxy/: bar (200; 23.88203ms)
May 25 02:15:11.834: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/proxy-service-56lmh:portname2/proxy/: bar (200; 23.402559ms)
May 25 02:15:11.834: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:1080/proxy/rewri... (200; 22.303981ms)
May 25 02:15:11.834: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/http:proxy-service-56lmh:portname2/proxy/: bar (200; 22.950969ms)
May 25 02:15:11.834: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:160/proxy/: foo (200; 18.121077ms)
May 25 02:15:11.834: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/https:proxy-service-56lmh:tlsportname1/proxy/: tls baz (200; 20.538745ms)
May 25 02:15:11.834: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/proxy-service-56lmh:portname1/proxy/: foo (200; 26.649202ms)
May 25 02:15:11.834: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/https:proxy-service-56lmh:tlsportname2/proxy/: tls qux (200; 20.242303ms)
May 25 02:15:11.834: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/http:proxy-service-56lmh:portname1/proxy/: foo (200; 26.26019ms)
May 25 02:15:11.847: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:443/proxy/... (200; 12.578343ms)
May 25 02:15:11.847: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:160/proxy/: foo (200; 10.217971ms)
May 25 02:15:11.849: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:162/proxy/: bar (200; 10.46205ms)
May 25 02:15:11.858: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/http:proxy-service-56lmh:portname2/proxy/: bar (200; 18.052738ms)
May 25 02:15:11.864: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:1080/proxy/rewri... (200; 23.344803ms)
May 25 02:15:11.864: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/http:proxy-service-56lmh:portname1/proxy/: foo (200; 23.945464ms)
May 25 02:15:11.864: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:162/proxy/: bar (200; 23.949096ms)
May 25 02:15:11.864: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/proxy-service-56lmh:portname1/proxy/: foo (200; 24.816043ms)
May 25 02:15:11.864: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:1080/proxy/... (200; 24.02898ms)
May 25 02:15:11.865: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:160/proxy/: foo (200; 24.596823ms)
May 25 02:15:11.865: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/https:proxy-service-56lmh:tlsportname2/proxy/: tls qux (200; 28.675466ms)
May 25 02:15:11.865: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/https:proxy-service-56lmh:tlsportname1/proxy/: tls baz (200; 29.408731ms)
May 25 02:15:11.865: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/proxy-service-56lmh:portname2/proxy/: bar (200; 24.607375ms)
May 25 02:15:11.865: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw/proxy/rewriteme"... (200; 24.823879ms)
May 25 02:15:11.866: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:462/proxy/: tls qux (200; 26.438545ms)
May 25 02:15:11.870: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:460/proxy/: tls baz (200; 30.812277ms)
May 25 02:15:11.887: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:462/proxy/: tls qux (200; 17.022903ms)
May 25 02:15:11.893: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:1080/proxy/... (200; 21.947743ms)
May 25 02:15:11.898: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw/proxy/rewriteme"... (200; 26.894841ms)
May 25 02:15:11.899: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:1080/proxy/rewri... (200; 27.776553ms)
May 25 02:15:11.901: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/http:proxy-service-56lmh:portname1/proxy/: foo (200; 29.330648ms)
May 25 02:15:11.901: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:443/proxy/... (200; 30.098096ms)
May 25 02:15:11.901: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/https:proxy-service-56lmh:tlsportname1/proxy/: tls baz (200; 30.037303ms)
May 25 02:15:11.901: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/https:proxy-service-56lmh:tlsportname2/proxy/: tls qux (200; 30.001896ms)
May 25 02:15:11.901: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:162/proxy/: bar (200; 29.588359ms)
May 25 02:15:11.901: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:162/proxy/: bar (200; 29.947279ms)
May 25 02:15:11.901: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:460/proxy/: tls baz (200; 30.217434ms)
May 25 02:15:11.901: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/proxy-service-56lmh:portname1/proxy/: foo (200; 29.958365ms)
May 25 02:15:11.901: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/proxy-service-56lmh:portname2/proxy/: bar (200; 30.523571ms)
May 25 02:15:11.901: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:160/proxy/: foo (200; 30.206931ms)
May 25 02:15:11.901: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:160/proxy/: foo (200; 29.912856ms)
May 25 02:15:11.901: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/http:proxy-service-56lmh:portname2/proxy/: bar (200; 30.628433ms)
May 25 02:15:11.917: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:462/proxy/: tls qux (200; 15.936196ms)
May 25 02:15:11.924: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:1080/proxy/rewri... (200; 19.626668ms)
May 25 02:15:11.924: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/http:proxy-service-56lmh:portname2/proxy/: bar (200; 19.884523ms)
May 25 02:15:11.924: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/https:proxy-service-56lmh:tlsportname1/proxy/: tls baz (200; 18.171274ms)
May 25 02:15:11.925: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw/proxy/rewriteme"... (200; 13.861883ms)
May 25 02:15:11.925: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:160/proxy/: foo (200; 16.282264ms)
May 25 02:15:11.925: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/https:proxy-service-56lmh:tlsportname2/proxy/: tls qux (200; 17.757634ms)
May 25 02:15:11.925: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:162/proxy/: bar (200; 13.227895ms)
May 25 02:15:11.925: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:1080/proxy/... (200; 19.749639ms)
May 25 02:15:11.925: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/proxy-service-56lmh:portname2/proxy/: bar (200; 21.819132ms)
May 25 02:15:11.925: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/proxy-service-56lmh:portname1/proxy/: foo (200; 15.168571ms)
May 25 02:15:11.925: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:162/proxy/: bar (200; 16.128235ms)
May 25 02:15:11.925: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/http:proxy-service-56lmh:portname1/proxy/: foo (200; 14.867689ms)
May 25 02:15:11.925: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:460/proxy/: tls baz (200; 15.864114ms)
May 25 02:15:11.925: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:160/proxy/: foo (200; 14.089009ms)
May 25 02:15:11.925: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:443/proxy/... (200; 20.120996ms)
May 25 02:15:11.937: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:443/proxy/... (200; 11.122192ms)
May 25 02:15:11.938: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:160/proxy/: foo (200; 7.373197ms)
May 25 02:15:11.938: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:1080/proxy/... (200; 9.072411ms)
May 25 02:15:11.938: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw/proxy/rewriteme"... (200; 12.557725ms)
May 25 02:15:11.939: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:460/proxy/: tls baz (200; 8.475622ms)
May 25 02:15:11.939: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:160/proxy/: foo (200; 12.829593ms)
May 25 02:15:11.939: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/proxy-service-56lmh:portname1/proxy/: foo (200; 8.834354ms)
May 25 02:15:11.939: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:1080/proxy/rewri... (200; 11.128157ms)
May 25 02:15:11.940: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:162/proxy/: bar (200; 10.413315ms)
May 25 02:15:11.940: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:462/proxy/: tls qux (200; 13.082183ms)
May 25 02:15:11.940: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:162/proxy/: bar (200; 13.996998ms)
May 25 02:15:11.945: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/https:proxy-service-56lmh:tlsportname1/proxy/: tls baz (200; 15.336657ms)
May 25 02:15:11.945: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/http:proxy-service-56lmh:portname1/proxy/: foo (200; 14.857927ms)
May 25 02:15:11.945: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/http:proxy-service-56lmh:portname2/proxy/: bar (200; 17.499592ms)
May 25 02:15:11.945: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/proxy-service-56lmh:portname2/proxy/: bar (200; 18.066673ms)
May 25 02:15:11.945: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/https:proxy-service-56lmh:tlsportname2/proxy/: tls qux (200; 15.137257ms)
May 25 02:15:11.954: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:162/proxy/: bar (200; 7.568561ms)
May 25 02:15:11.954: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:162/proxy/: bar (200; 8.309773ms)
May 25 02:15:11.955: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:160/proxy/: foo (200; 8.540107ms)
May 25 02:15:11.955: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:462/proxy/: tls qux (200; 7.82943ms)
May 25 02:15:11.955: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw/proxy/rewriteme"... (200; 8.245541ms)
May 25 02:15:11.955: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:460/proxy/: tls baz (200; 8.656682ms)
May 25 02:15:11.958: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:160/proxy/: foo (200; 11.869483ms)
May 25 02:15:11.958: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/https:proxy-service-56lmh:tlsportname1/proxy/: tls baz (200; 12.001296ms)
May 25 02:15:11.958: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:1080/proxy/... (200; 10.782765ms)
May 25 02:15:11.958: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:1080/proxy/rewri... (200; 11.214016ms)
May 25 02:15:11.958: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/https:proxy-service-56lmh:tlsportname2/proxy/: tls qux (200; 12.649632ms)
May 25 02:15:11.960: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/http:proxy-service-56lmh:portname2/proxy/: bar (200; 12.755921ms)
May 25 02:15:11.960: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:443/proxy/... (200; 14.492174ms)
May 25 02:15:11.960: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/proxy-service-56lmh:portname1/proxy/: foo (200; 14.143277ms)
May 25 02:15:11.961: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/http:proxy-service-56lmh:portname1/proxy/: foo (200; 14.261352ms)
May 25 02:15:11.961: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/proxy-service-56lmh:portname2/proxy/: bar (200; 14.340605ms)
May 25 02:15:11.972: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:462/proxy/: tls qux (200; 10.720386ms)
May 25 02:15:11.972: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:1080/proxy/rewri... (200; 10.948306ms)
May 25 02:15:11.972: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:443/proxy/... (200; 10.680771ms)
May 25 02:15:11.972: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:162/proxy/: bar (200; 10.280791ms)
May 25 02:15:11.972: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw/proxy/rewriteme"... (200; 9.772404ms)
May 25 02:15:11.972: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:460/proxy/: tls baz (200; 10.698108ms)
May 25 02:15:11.972: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:1080/proxy/... (200; 10.910402ms)
May 25 02:15:11.973: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:160/proxy/: foo (200; 11.418876ms)
May 25 02:15:11.973: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:160/proxy/: foo (200; 10.853604ms)
May 25 02:15:11.973: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/proxy-service-56lmh:portname2/proxy/: bar (200; 11.167114ms)
May 25 02:15:11.973: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/https:proxy-service-56lmh:tlsportname2/proxy/: tls qux (200; 10.509053ms)
May 25 02:15:11.973: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/http:proxy-service-56lmh:portname1/proxy/: foo (200; 11.101495ms)
May 25 02:15:11.973: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/proxy-service-56lmh:portname1/proxy/: foo (200; 10.165442ms)
May 25 02:15:11.973: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/http:proxy-service-56lmh:portname2/proxy/: bar (200; 11.012559ms)
May 25 02:15:11.973: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/https:proxy-service-56lmh:tlsportname1/proxy/: tls baz (200; 10.473378ms)
May 25 02:15:11.973: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:162/proxy/: bar (200; 11.532934ms)
May 25 02:15:11.988: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:162/proxy/: bar (200; 11.553407ms)
May 25 02:15:11.988: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:162/proxy/: bar (200; 14.166889ms)
May 25 02:15:11.988: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:1080/proxy/... (200; 12.237391ms)
May 25 02:15:11.988: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:1080/proxy/rewri... (200; 12.395285ms)
May 25 02:15:11.988: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/http:proxy-service-56lmh:portname1/proxy/: foo (200; 12.010748ms)
May 25 02:15:11.988: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/http:proxy-service-56lmh:portname2/proxy/: bar (200; 12.556446ms)
May 25 02:15:11.988: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/https:proxy-service-56lmh:tlsportname2/proxy/: tls qux (200; 12.306169ms)
May 25 02:15:11.989: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:160/proxy/: foo (200; 12.890916ms)
May 25 02:15:11.989: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/proxy-service-56lmh:portname2/proxy/: bar (200; 14.818888ms)
May 25 02:15:11.989: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw/proxy/rewriteme"... (200; 12.275368ms)
May 25 02:15:11.989: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:460/proxy/: tls baz (200; 12.734014ms)
May 25 02:15:11.989: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/https:proxy-service-56lmh:tlsportname1/proxy/: tls baz (200; 12.457174ms)
May 25 02:15:11.989: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:443/proxy/... (200; 12.925427ms)
May 25 02:15:11.989: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:160/proxy/: foo (200; 12.800005ms)
May 25 02:15:11.989: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:462/proxy/: tls qux (200; 15.121222ms)
May 25 02:15:11.989: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/proxy-service-56lmh:portname1/proxy/: foo (200; 11.016076ms)
May 25 02:15:12.001: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:462/proxy/: tls qux (200; 11.980699ms)
May 25 02:15:12.001: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:160/proxy/: foo (200; 12.261785ms)
May 25 02:15:12.002: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:443/proxy/... (200; 12.421189ms)
May 25 02:15:12.002: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:160/proxy/: foo (200; 11.904577ms)
May 25 02:15:12.002: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:460/proxy/: tls baz (200; 11.87216ms)
May 25 02:15:12.002: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw/proxy/rewriteme"... (200; 11.86383ms)
May 25 02:15:12.002: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:1080/proxy/rewri... (200; 12.416731ms)
May 25 02:15:12.002: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:1080/proxy/... (200; 12.500404ms)
May 25 02:15:12.002: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:162/proxy/: bar (200; 12.771096ms)
May 25 02:15:12.003: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/http:proxy-service-56lmh:portname1/proxy/: foo (200; 12.54046ms)
May 25 02:15:12.003: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/proxy-service-56lmh:portname1/proxy/: foo (200; 12.701768ms)
May 25 02:15:12.003: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:162/proxy/: bar (200; 13.370798ms)
May 25 02:15:12.003: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/proxy-service-56lmh:portname2/proxy/: bar (200; 13.239198ms)
May 25 02:15:12.003: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/http:proxy-service-56lmh:portname2/proxy/: bar (200; 13.279228ms)
May 25 02:15:12.003: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/https:proxy-service-56lmh:tlsportname1/proxy/: tls baz (200; 13.166916ms)
May 25 02:15:12.003: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/https:proxy-service-56lmh:tlsportname2/proxy/: tls qux (200; 13.114118ms)
May 25 02:15:12.026: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:460/proxy/: tls baz (200; 22.727718ms)
May 25 02:15:12.026: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:160/proxy/: foo (200; 23.074066ms)
May 25 02:15:12.026: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw/proxy/rewriteme"... (200; 23.201723ms)
May 25 02:15:12.026: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/https:proxy-service-56lmh:tlsportname1/proxy/: tls baz (200; 22.945186ms)
May 25 02:15:12.026: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:160/proxy/: foo (200; 22.980351ms)
May 25 02:15:12.028: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:1080/proxy/... (200; 24.360422ms)
May 25 02:15:12.028: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/http:proxy-service-56lmh:portname1/proxy/: foo (200; 24.782859ms)
May 25 02:15:12.028: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:1080/proxy/rewri... (200; 25.004908ms)
May 25 02:15:12.029: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/https:proxy-service-56lmh:tlsportname2/proxy/: tls qux (200; 25.12963ms)
May 25 02:15:12.029: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:462/proxy/: tls qux (200; 25.463987ms)
May 25 02:15:12.029: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/http:proxy-service-56lmh:portname2/proxy/: bar (200; 25.461042ms)
May 25 02:15:12.029: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/proxy-service-56lmh:portname1/proxy/: foo (200; 25.7535ms)
May 25 02:15:12.029: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:162/proxy/: bar (200; 25.987351ms)
May 25 02:15:12.029: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:443/proxy/... (200; 25.967944ms)
May 25 02:15:12.029: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:162/proxy/: bar (200; 26.258953ms)
May 25 02:15:12.029: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/proxy-service-56lmh:portname2/proxy/: bar (200; 25.993407ms)
May 25 02:15:12.034: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:1080/proxy/... (200; 4.326713ms)
May 25 02:15:12.042: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw/proxy/rewriteme"... (200; 12.279097ms)
May 25 02:15:12.050: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:160/proxy/: foo (200; 19.776286ms)
May 25 02:15:12.050: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:160/proxy/: foo (200; 20.115877ms)
May 25 02:15:12.051: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:162/proxy/: bar (200; 20.140806ms)
May 25 02:15:12.051: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:1080/proxy/rewri... (200; 20.473493ms)
May 25 02:15:12.051: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:162/proxy/: bar (200; 20.380059ms)
May 25 02:15:12.051: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:462/proxy/: tls qux (200; 20.746742ms)
May 25 02:15:12.051: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/https:proxy-service-56lmh:tlsportname2/proxy/: tls qux (200; 21.252695ms)
May 25 02:15:12.051: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:460/proxy/: tls baz (200; 20.406303ms)
May 25 02:15:12.053: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:443/proxy/... (200; 22.3598ms)
May 25 02:15:12.057: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/proxy-service-56lmh:portname2/proxy/: bar (200; 26.306692ms)
May 25 02:15:12.057: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/http:proxy-service-56lmh:portname2/proxy/: bar (200; 26.232953ms)
May 25 02:15:12.057: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/proxy-service-56lmh:portname1/proxy/: foo (200; 26.970851ms)
May 25 02:15:12.057: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/https:proxy-service-56lmh:tlsportname1/proxy/: tls baz (200; 26.360972ms)
May 25 02:15:12.057: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/http:proxy-service-56lmh:portname1/proxy/: foo (200; 26.968922ms)
May 25 02:15:12.076: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:1080/proxy/... (200; 17.709915ms)
May 25 02:15:12.077: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:162/proxy/: bar (200; 18.241026ms)
May 25 02:15:12.077: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:460/proxy/: tls baz (200; 20.013866ms)
May 25 02:15:12.078: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:1080/proxy/rewri... (200; 19.229821ms)
May 25 02:15:12.078: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw/proxy/rewriteme"... (200; 20.657875ms)
May 25 02:15:12.078: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:160/proxy/: foo (200; 19.745233ms)
May 25 02:15:12.078: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:462/proxy/: tls qux (200; 20.519589ms)
May 25 02:15:12.081: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:443/proxy/... (200; 22.231458ms)
May 25 02:15:12.081: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:160/proxy/: foo (200; 23.52139ms)
May 25 02:15:12.081: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/proxy-service-56lmh:portname2/proxy/: bar (200; 23.315157ms)
May 25 02:15:12.081: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/http:proxy-service-56lmh:portname2/proxy/: bar (200; 23.286305ms)
May 25 02:15:12.081: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:162/proxy/: bar (200; 23.547329ms)
May 25 02:15:12.081: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/https:proxy-service-56lmh:tlsportname2/proxy/: tls qux (200; 22.9483ms)
May 25 02:15:12.081: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/http:proxy-service-56lmh:portname1/proxy/: foo (200; 23.88374ms)
May 25 02:15:12.081: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/https:proxy-service-56lmh:tlsportname1/proxy/: tls baz (200; 23.131587ms)
May 25 02:15:12.081: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/proxy-service-56lmh:portname1/proxy/: foo (200; 24.076964ms)
May 25 02:15:12.102: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/proxy-service-56lmh:portname1/proxy/: foo (200; 19.831746ms)
May 25 02:15:12.102: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:162/proxy/: bar (200; 20.006007ms)
May 25 02:15:12.102: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:462/proxy/: tls qux (200; 20.204692ms)
May 25 02:15:12.102: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:160/proxy/: foo (200; 20.270489ms)
May 25 02:15:12.102: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw/proxy/rewriteme"... (200; 19.988105ms)
May 25 02:15:12.103: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/https:proxy-service-56lmh:tlsportname1/proxy/: tls baz (200; 20.852742ms)
May 25 02:15:12.103: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:1080/proxy/rewri... (200; 20.680066ms)
May 25 02:15:12.103: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:443/proxy/... (200; 20.72759ms)
May 25 02:15:12.103: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/https:proxy-service-56lmh:tlsportname2/proxy/: tls qux (200; 20.780977ms)
May 25 02:15:12.103: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:1080/proxy/... (200; 20.978164ms)
May 25 02:15:12.103: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/http:proxy-service-56lmh:portname2/proxy/: bar (200; 21.321468ms)
May 25 02:15:12.103: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/proxy-service-56lmh:portname2/proxy/: bar (200; 21.246792ms)
May 25 02:15:12.110: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/http:proxy-service-56lmh:portname1/proxy/: foo (200; 27.324792ms)
May 25 02:15:12.110: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:162/proxy/: bar (200; 27.441619ms)
May 25 02:15:12.110: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:160/proxy/: foo (200; 27.528586ms)
May 25 02:15:12.110: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:460/proxy/: tls baz (200; 28.110315ms)
May 25 02:15:12.132: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:162/proxy/: bar (200; 18.186943ms)
May 25 02:15:12.132: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw/proxy/rewriteme"... (200; 21.214529ms)
May 25 02:15:12.135: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:1080/proxy/rewri... (200; 22.964595ms)
May 25 02:15:12.135: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:462/proxy/: tls qux (200; 23.176932ms)
May 25 02:15:12.136: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:1080/proxy/... (200; 23.45244ms)
May 25 02:15:12.136: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:162/proxy/: bar (200; 23.756257ms)
May 25 02:15:12.136: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:160/proxy/: foo (200; 24.847314ms)
May 25 02:15:12.136: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:160/proxy/: foo (200; 23.948706ms)
May 25 02:15:12.137: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:460/proxy/: tls baz (200; 22.813072ms)
May 25 02:15:12.140: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:443/proxy/... (200; 27.43314ms)
May 25 02:15:12.146: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/https:proxy-service-56lmh:tlsportname1/proxy/: tls baz (200; 33.320495ms)
May 25 02:15:12.146: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/http:proxy-service-56lmh:portname1/proxy/: foo (200; 32.064536ms)
May 25 02:15:12.146: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/http:proxy-service-56lmh:portname2/proxy/: bar (200; 34.119116ms)
May 25 02:15:12.146: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/https:proxy-service-56lmh:tlsportname2/proxy/: tls qux (200; 34.033361ms)
May 25 02:15:12.147: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/proxy-service-56lmh:portname1/proxy/: foo (200; 33.354566ms)
May 25 02:15:12.147: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/proxy-service-56lmh:portname2/proxy/: bar (200; 35.066389ms)
May 25 02:15:12.157: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:443/proxy/... (200; 10.130491ms)
May 25 02:15:12.167: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:162/proxy/: bar (200; 18.202799ms)
May 25 02:15:12.167: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:162/proxy/: bar (200; 18.909501ms)
May 25 02:15:12.167: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:160/proxy/: foo (200; 18.499043ms)
May 25 02:15:12.170: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:460/proxy/: tls baz (200; 22.346939ms)
May 25 02:15:12.170: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw/proxy/rewriteme"... (200; 22.116536ms)
May 25 02:15:12.170: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:160/proxy/: foo (200; 22.716299ms)
May 25 02:15:12.170: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:462/proxy/: tls qux (200; 22.022621ms)
May 25 02:15:12.171: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:1080/proxy/rewri... (200; 21.805101ms)
May 25 02:15:12.173: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:1080/proxy/... (200; 23.957276ms)
May 25 02:15:12.173: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/proxy-service-56lmh:portname2/proxy/: bar (200; 24.32217ms)
May 25 02:15:12.173: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/proxy-service-56lmh:portname1/proxy/: foo (200; 25.096168ms)
May 25 02:15:12.177: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/http:proxy-service-56lmh:portname1/proxy/: foo (200; 28.803105ms)
May 25 02:15:12.178: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/http:proxy-service-56lmh:portname2/proxy/: bar (200; 29.052072ms)
May 25 02:15:12.178: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/https:proxy-service-56lmh:tlsportname2/proxy/: tls qux (200; 30.286109ms)
May 25 02:15:12.180: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/https:proxy-service-56lmh:tlsportname1/proxy/: tls baz (200; 32.79926ms)
May 25 02:15:12.190: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:160/proxy/: foo (200; 9.718254ms)
May 25 02:15:12.191: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw/proxy/rewriteme"... (200; 10.930347ms)
May 25 02:15:12.198: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/http:proxy-service-56lmh:portname2/proxy/: bar (200; 14.405668ms)
May 25 02:15:12.198: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:1080/proxy/... (200; 14.200993ms)
May 25 02:15:12.198: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:462/proxy/: tls qux (200; 14.784307ms)
May 25 02:15:12.198: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:162/proxy/: bar (200; 17.811492ms)
May 25 02:15:12.198: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/proxy-service-56lmh:portname2/proxy/: bar (200; 14.674124ms)
May 25 02:15:12.199: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:1080/proxy/rewri... (200; 14.454111ms)
May 25 02:15:12.199: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:443/proxy/... (200; 14.191436ms)
May 25 02:15:12.201: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:460/proxy/: tls baz (200; 10.385555ms)
May 25 02:15:12.208: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/http:proxy-service-56lmh:portname1/proxy/: foo (200; 16.56181ms)
May 25 02:15:12.208: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/proxy-service-56lmh:portname1/proxy/: foo (200; 16.714977ms)
May 25 02:15:12.208: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/https:proxy-service-56lmh:tlsportname1/proxy/: tls baz (200; 17.196802ms)
May 25 02:15:12.208: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:160/proxy/: foo (200; 16.800797ms)
May 25 02:15:12.208: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:162/proxy/: bar (200; 17.066052ms)
May 25 02:15:12.208: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/https:proxy-service-56lmh:tlsportname2/proxy/: tls qux (200; 16.913254ms)
May 25 02:15:12.230: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:462/proxy/: tls qux (200; 21.958592ms)
May 25 02:15:12.230: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:162/proxy/: bar (200; 21.956208ms)
May 25 02:15:12.230: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:1080/proxy/... (200; 22.060338ms)
May 25 02:15:12.231: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:460/proxy/: tls baz (200; 22.642406ms)
May 25 02:15:12.231: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:1080/proxy/rewri... (200; 22.648283ms)
May 25 02:15:12.231: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw/proxy/rewriteme"... (200; 22.837469ms)
May 25 02:15:12.231: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:160/proxy/: foo (200; 23.14485ms)
May 25 02:15:12.232: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:443/proxy/... (200; 23.41345ms)
May 25 02:15:12.232: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:160/proxy/: foo (200; 23.741667ms)
May 25 02:15:12.232: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:162/proxy/: bar (200; 24.058361ms)
May 25 02:15:12.238: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/proxy-service-56lmh:portname2/proxy/: bar (200; 29.764386ms)
May 25 02:15:12.238: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/http:proxy-service-56lmh:portname1/proxy/: foo (200; 29.832966ms)
May 25 02:15:12.243: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/https:proxy-service-56lmh:tlsportname2/proxy/: tls qux (200; 35.346734ms)
May 25 02:15:12.243: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/http:proxy-service-56lmh:portname2/proxy/: bar (200; 35.206431ms)
May 25 02:15:12.244: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/proxy-service-56lmh:portname1/proxy/: foo (200; 35.523455ms)
May 25 02:15:12.244: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/https:proxy-service-56lmh:tlsportname1/proxy/: tls baz (200; 35.450119ms)
May 25 02:15:12.261: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:160/proxy/: foo (200; 14.633516ms)
May 25 02:15:12.263: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:443/proxy/... (200; 16.210564ms)
May 25 02:15:12.263: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/proxy-service-56lmh:portname1/proxy/: foo (200; 16.447097ms)
May 25 02:15:12.263: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw/proxy/rewriteme"... (200; 16.384566ms)
May 25 02:15:12.263: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:1080/proxy/rewri... (200; 16.368403ms)
May 25 02:15:12.263: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:162/proxy/: bar (200; 16.213036ms)
May 25 02:15:12.263: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/http:proxy-service-56lmh:portname2/proxy/: bar (200; 17.155125ms)
May 25 02:15:12.263: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:462/proxy/: tls qux (200; 18.990109ms)
May 25 02:15:12.262: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/https:proxy-service-56lmh:tlsportname2/proxy/: tls qux (200; 15.006765ms)
May 25 02:15:12.262: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:460/proxy/: tls baz (200; 15.330946ms)
May 25 02:15:12.262: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:1080/proxy/... (200; 15.138102ms)
May 25 02:15:12.262: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:160/proxy/: foo (200; 15.058899ms)
May 25 02:15:12.262: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:162/proxy/: bar (200; 15.427074ms)
May 25 02:15:12.262: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/http:proxy-service-56lmh:portname1/proxy/: foo (200; 15.312384ms)
May 25 02:15:12.262: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/https:proxy-service-56lmh:tlsportname1/proxy/: tls baz (200; 15.181828ms)
May 25 02:15:12.265: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/proxy-service-56lmh:portname2/proxy/: bar (200; 19.882228ms)
May 25 02:15:12.270: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:460/proxy/: tls baz (200; 4.069393ms)
May 25 02:15:12.295: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:443/proxy/... (200; 28.481176ms)
May 25 02:15:12.296: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:1080/proxy/... (200; 29.268384ms)
May 25 02:15:12.313: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:160/proxy/: foo (200; 46.175767ms)
May 25 02:15:12.313: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/proxy-service-56lmh:portname1/proxy/: foo (200; 45.366175ms)
May 25 02:15:12.313: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/proxy-service-56lmh:portname2/proxy/: bar (200; 45.96853ms)
May 25 02:15:12.313: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/http:proxy-service-56lmh:portname1/proxy/: foo (200; 47.593052ms)
May 25 02:15:12.313: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw/proxy/rewriteme"... (200; 46.703443ms)
May 25 02:15:12.313: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/https:proxy-service-56lmh-984cw:462/proxy/: tls qux (200; 46.456276ms)
May 25 02:15:12.313: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/http:proxy-service-56lmh:portname2/proxy/: bar (200; 46.291445ms)
May 25 02:15:12.313: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/https:proxy-service-56lmh:tlsportname2/proxy/: tls qux (200; 46.004638ms)
May 25 02:15:12.313: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:162/proxy/: bar (200; 46.022664ms)
May 25 02:15:12.313: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/http:proxy-service-56lmh-984cw:162/proxy/: bar (200; 46.686254ms)
May 25 02:15:12.313: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:160/proxy/: foo (200; 46.239079ms)
May 25 02:15:12.313: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9r2sd/services/https:proxy-service-56lmh:tlsportname1/proxy/: tls baz (200; 46.151187ms)
May 25 02:15:12.313: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9r2sd/pods/proxy-service-56lmh-984cw:1080/proxy/rewri... (200; 46.31584ms)
STEP: deleting ReplicationController proxy-service-56lmh in namespace e2e-tests-proxy-9r2sd, will wait for the garbage collector to delete the pods
May 25 02:15:12.379: INFO: Deleting ReplicationController proxy-service-56lmh took: 12.261766ms
May 25 02:15:12.479: INFO: Terminating ReplicationController proxy-service-56lmh pods took: 100.188232ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:15:14.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-9r2sd" for this suite.
May 25 02:15:20.593: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:15:20.620: INFO: namespace: e2e-tests-proxy-9r2sd, resource: bindings, ignored listing per whitelist
May 25 02:15:20.668: INFO: namespace e2e-tests-proxy-9r2sd deletion completed in 6.08290367s

• [SLOW TEST:15.118 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:15:20.668: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-vxngm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0525 02:16:00.870459      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 25 02:16:00.870: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:16:00.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-vxngm" for this suite.
May 25 02:16:06.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:16:06.923: INFO: namespace: e2e-tests-gc-vxngm, resource: bindings, ignored listing per whitelist
May 25 02:16:06.957: INFO: namespace e2e-tests-gc-vxngm deletion completed in 6.081525733s

• [SLOW TEST:46.289 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:16:06.959: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-zp79q
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 25 02:16:07.123: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0df7e87e-7e93-11e9-802f-027f94874578" in namespace "e2e-tests-downward-api-zp79q" to be "success or failure"
May 25 02:16:07.130: INFO: Pod "downwardapi-volume-0df7e87e-7e93-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 6.555421ms
May 25 02:16:09.133: INFO: Pod "downwardapi-volume-0df7e87e-7e93-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009434683s
May 25 02:16:11.136: INFO: Pod "downwardapi-volume-0df7e87e-7e93-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012261336s
STEP: Saw pod success
May 25 02:16:11.136: INFO: Pod "downwardapi-volume-0df7e87e-7e93-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 02:16:11.138: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod downwardapi-volume-0df7e87e-7e93-11e9-802f-027f94874578 container client-container: <nil>
STEP: delete the pod
May 25 02:16:11.157: INFO: Waiting for pod downwardapi-volume-0df7e87e-7e93-11e9-802f-027f94874578 to disappear
May 25 02:16:11.160: INFO: Pod downwardapi-volume-0df7e87e-7e93-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:16:11.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-zp79q" for this suite.
May 25 02:16:17.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:16:17.199: INFO: namespace: e2e-tests-downward-api-zp79q, resource: bindings, ignored listing per whitelist
May 25 02:16:17.245: INFO: namespace e2e-tests-downward-api-zp79q deletion completed in 6.081084716s

• [SLOW TEST:10.286 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:16:17.248: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-2ckrv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
May 25 02:16:17.412: INFO: Waiting up to 5m0s for pod "pod-141a14ae-7e93-11e9-802f-027f94874578" in namespace "e2e-tests-emptydir-2ckrv" to be "success or failure"
May 25 02:16:17.418: INFO: Pod "pod-141a14ae-7e93-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 6.147063ms
May 25 02:16:19.421: INFO: Pod "pod-141a14ae-7e93-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009079619s
STEP: Saw pod success
May 25 02:16:19.421: INFO: Pod "pod-141a14ae-7e93-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 02:16:19.423: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-141a14ae-7e93-11e9-802f-027f94874578 container test-container: <nil>
STEP: delete the pod
May 25 02:16:19.446: INFO: Waiting for pod pod-141a14ae-7e93-11e9-802f-027f94874578 to disappear
May 25 02:16:19.448: INFO: Pod pod-141a14ae-7e93-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:16:19.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-2ckrv" for this suite.
May 25 02:16:25.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:16:25.480: INFO: namespace: e2e-tests-emptydir-2ckrv, resource: bindings, ignored listing per whitelist
May 25 02:16:25.546: INFO: namespace e2e-tests-emptydir-2ckrv deletion completed in 6.094536853s

• [SLOW TEST:8.298 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:16:25.548: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-z2m42
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-190ceb8a-7e93-11e9-802f-027f94874578
STEP: Creating a pod to test consume secrets
May 25 02:16:25.720: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-190d9aae-7e93-11e9-802f-027f94874578" in namespace "e2e-tests-projected-z2m42" to be "success or failure"
May 25 02:16:25.725: INFO: Pod "pod-projected-secrets-190d9aae-7e93-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 5.247115ms
May 25 02:16:27.728: INFO: Pod "pod-projected-secrets-190d9aae-7e93-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00824881s
STEP: Saw pod success
May 25 02:16:27.728: INFO: Pod "pod-projected-secrets-190d9aae-7e93-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 02:16:27.731: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-projected-secrets-190d9aae-7e93-11e9-802f-027f94874578 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 25 02:16:27.749: INFO: Waiting for pod pod-projected-secrets-190d9aae-7e93-11e9-802f-027f94874578 to disappear
May 25 02:16:27.751: INFO: Pod pod-projected-secrets-190d9aae-7e93-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:16:27.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-z2m42" for this suite.
May 25 02:16:33.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:16:33.789: INFO: namespace: e2e-tests-projected-z2m42, resource: bindings, ignored listing per whitelist
May 25 02:16:33.860: INFO: namespace e2e-tests-projected-z2m42 deletion completed in 6.102614355s

• [SLOW TEST:8.312 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:16:33.860: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-wrapper-9ktzk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:16:36.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-9ktzk" for this suite.
May 25 02:16:42.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:16:42.185: INFO: namespace: e2e-tests-emptydir-wrapper-9ktzk, resource: bindings, ignored listing per whitelist
May 25 02:16:42.190: INFO: namespace e2e-tests-emptydir-wrapper-9ktzk deletion completed in 6.12104889s

• [SLOW TEST:8.331 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:16:42.191: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-e2e-kubelet-etc-hosts-694vl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
May 25 02:16:46.384: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-694vl PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 25 02:16:46.384: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
May 25 02:16:46.455: INFO: Exec stderr: ""
May 25 02:16:46.455: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-694vl PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 25 02:16:46.455: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
May 25 02:16:46.517: INFO: Exec stderr: ""
May 25 02:16:46.517: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-694vl PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 25 02:16:46.517: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
May 25 02:16:46.568: INFO: Exec stderr: ""
May 25 02:16:46.568: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-694vl PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 25 02:16:46.568: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
May 25 02:16:46.619: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
May 25 02:16:46.619: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-694vl PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 25 02:16:46.620: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
May 25 02:16:46.665: INFO: Exec stderr: ""
May 25 02:16:46.665: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-694vl PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 25 02:16:46.665: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
May 25 02:16:46.709: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
May 25 02:16:46.709: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-694vl PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 25 02:16:46.709: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
May 25 02:16:46.759: INFO: Exec stderr: ""
May 25 02:16:46.759: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-694vl PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 25 02:16:46.760: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
May 25 02:16:46.825: INFO: Exec stderr: ""
May 25 02:16:46.825: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-694vl PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 25 02:16:46.826: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
May 25 02:16:46.872: INFO: Exec stderr: ""
May 25 02:16:46.872: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-694vl PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 25 02:16:46.872: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
May 25 02:16:46.936: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:16:46.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-694vl" for this suite.
May 25 02:17:32.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:17:32.960: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-694vl, resource: bindings, ignored listing per whitelist
May 25 02:17:33.035: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-694vl deletion completed in 46.0942944s

• [SLOW TEST:50.844 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:17:33.035: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-486jb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-4147a1e2-7e93-11e9-802f-027f94874578
STEP: Creating a pod to test consume configMaps
May 25 02:17:33.216: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4148469b-7e93-11e9-802f-027f94874578" in namespace "e2e-tests-projected-486jb" to be "success or failure"
May 25 02:17:33.224: INFO: Pod "pod-projected-configmaps-4148469b-7e93-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 8.573311ms
May 25 02:17:35.228: INFO: Pod "pod-projected-configmaps-4148469b-7e93-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012172748s
STEP: Saw pod success
May 25 02:17:35.228: INFO: Pod "pod-projected-configmaps-4148469b-7e93-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 02:17:35.231: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-projected-configmaps-4148469b-7e93-11e9-802f-027f94874578 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 25 02:17:35.246: INFO: Waiting for pod pod-projected-configmaps-4148469b-7e93-11e9-802f-027f94874578 to disappear
May 25 02:17:35.248: INFO: Pod pod-projected-configmaps-4148469b-7e93-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:17:35.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-486jb" for this suite.
May 25 02:17:41.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:17:41.413: INFO: namespace: e2e-tests-projected-486jb, resource: bindings, ignored listing per whitelist
May 25 02:17:41.491: INFO: namespace e2e-tests-projected-486jb deletion completed in 6.240237943s

• [SLOW TEST:8.456 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:17:41.494: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-4q4rw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-4q4rw
May 25 02:17:43.677: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-4q4rw
STEP: checking the pod's current state and verifying that restartCount is present
May 25 02:17:43.680: INFO: Initial restart count of pod liveness-exec is 0
May 25 02:18:33.751: INFO: Restart count of pod e2e-tests-container-probe-4q4rw/liveness-exec is now 1 (50.070649768s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:18:33.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-4q4rw" for this suite.
May 25 02:18:39.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:18:39.827: INFO: namespace: e2e-tests-container-probe-4q4rw, resource: bindings, ignored listing per whitelist
May 25 02:18:39.853: INFO: namespace e2e-tests-container-probe-4q4rw deletion completed in 6.083371781s

• [SLOW TEST:58.359 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:18:39.853: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-wcfsc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 25 02:18:40.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-wcfsc'
May 25 02:18:40.348: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 25 02:18:40.348: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
May 25 02:18:44.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-wcfsc'
May 25 02:18:44.462: INFO: stderr: ""
May 25 02:18:44.462: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:18:44.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wcfsc" for this suite.
May 25 02:18:50.478: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:18:50.497: INFO: namespace: e2e-tests-kubectl-wcfsc, resource: bindings, ignored listing per whitelist
May 25 02:18:50.553: INFO: namespace e2e-tests-kubectl-wcfsc deletion completed in 6.085849104s

• [SLOW TEST:10.700 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:18:50.555: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-wnl5z
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-6f7b72cb-7e93-11e9-802f-027f94874578
STEP: Creating a pod to test consume configMaps
May 25 02:18:50.726: INFO: Waiting up to 5m0s for pod "pod-configmaps-6f7c07a9-7e93-11e9-802f-027f94874578" in namespace "e2e-tests-configmap-wnl5z" to be "success or failure"
May 25 02:18:50.730: INFO: Pod "pod-configmaps-6f7c07a9-7e93-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 4.518714ms
May 25 02:18:52.734: INFO: Pod "pod-configmaps-6f7c07a9-7e93-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007633946s
STEP: Saw pod success
May 25 02:18:52.734: INFO: Pod "pod-configmaps-6f7c07a9-7e93-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 02:18:52.736: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-configmaps-6f7c07a9-7e93-11e9-802f-027f94874578 container configmap-volume-test: <nil>
STEP: delete the pod
May 25 02:18:52.753: INFO: Waiting for pod pod-configmaps-6f7c07a9-7e93-11e9-802f-027f94874578 to disappear
May 25 02:18:52.755: INFO: Pod pod-configmaps-6f7c07a9-7e93-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:18:52.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-wnl5z" for this suite.
May 25 02:18:58.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:18:58.828: INFO: namespace: e2e-tests-configmap-wnl5z, resource: bindings, ignored listing per whitelist
May 25 02:18:58.843: INFO: namespace e2e-tests-configmap-wnl5z deletion completed in 6.084689582s

• [SLOW TEST:8.289 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:18:58.844: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svc-latency-2n9cj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-2n9cj
I0525 02:18:59.036399      15 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-2n9cj, replica count: 1
I0525 02:19:00.086896      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0525 02:19:01.087070      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 25 02:19:01.200: INFO: Created: latency-svc-hfjn2
May 25 02:19:01.208: INFO: Got endpoints: latency-svc-hfjn2 [21.514871ms]
May 25 02:19:01.328: INFO: Created: latency-svc-zgz7d
May 25 02:19:01.328: INFO: Got endpoints: latency-svc-zgz7d [119.916733ms]
May 25 02:19:01.354: INFO: Created: latency-svc-jpszz
May 25 02:19:01.367: INFO: Got endpoints: latency-svc-jpszz [158.297139ms]
May 25 02:19:01.389: INFO: Created: latency-svc-jfnhx
May 25 02:19:01.394: INFO: Got endpoints: latency-svc-jfnhx [184.86522ms]
May 25 02:19:01.409: INFO: Created: latency-svc-2tlz8
May 25 02:19:01.413: INFO: Got endpoints: latency-svc-2tlz8 [203.161227ms]
May 25 02:19:01.422: INFO: Created: latency-svc-zsq78
May 25 02:19:01.427: INFO: Got endpoints: latency-svc-zsq78 [216.823241ms]
May 25 02:19:01.434: INFO: Created: latency-svc-scs2n
May 25 02:19:01.437: INFO: Got endpoints: latency-svc-scs2n [226.742763ms]
May 25 02:19:01.450: INFO: Created: latency-svc-6kt8f
May 25 02:19:01.454: INFO: Got endpoints: latency-svc-6kt8f [243.43381ms]
May 25 02:19:01.473: INFO: Created: latency-svc-s9rmz
May 25 02:19:01.473: INFO: Got endpoints: latency-svc-s9rmz [262.690887ms]
May 25 02:19:01.487: INFO: Created: latency-svc-td9xd
May 25 02:19:01.487: INFO: Got endpoints: latency-svc-td9xd [276.866752ms]
May 25 02:19:01.527: INFO: Created: latency-svc-msbph
May 25 02:19:01.534: INFO: Got endpoints: latency-svc-msbph [323.16257ms]
May 25 02:19:01.542: INFO: Created: latency-svc-cd9gb
May 25 02:19:01.547: INFO: Got endpoints: latency-svc-cd9gb [338.487826ms]
May 25 02:19:01.562: INFO: Created: latency-svc-b7s8n
May 25 02:19:01.578: INFO: Got endpoints: latency-svc-b7s8n [367.466848ms]
May 25 02:19:01.591: INFO: Created: latency-svc-8xsq6
May 25 02:19:01.592: INFO: Got endpoints: latency-svc-8xsq6 [380.512593ms]
May 25 02:19:01.613: INFO: Created: latency-svc-tv6f2
May 25 02:19:01.613: INFO: Got endpoints: latency-svc-tv6f2 [401.566633ms]
May 25 02:19:01.626: INFO: Created: latency-svc-rlk9h
May 25 02:19:01.629: INFO: Got endpoints: latency-svc-rlk9h [417.474409ms]
May 25 02:19:01.643: INFO: Created: latency-svc-fv4hz
May 25 02:19:01.647: INFO: Got endpoints: latency-svc-fv4hz [317.768063ms]
May 25 02:19:01.658: INFO: Created: latency-svc-n6rdx
May 25 02:19:01.666: INFO: Got endpoints: latency-svc-n6rdx [299.328516ms]
May 25 02:19:01.690: INFO: Created: latency-svc-qnckl
May 25 02:19:01.696: INFO: Got endpoints: latency-svc-qnckl [302.553446ms]
May 25 02:19:01.703: INFO: Created: latency-svc-rggc6
May 25 02:19:01.714: INFO: Got endpoints: latency-svc-rggc6 [300.802046ms]
May 25 02:19:01.719: INFO: Created: latency-svc-jfqcv
May 25 02:19:01.723: INFO: Got endpoints: latency-svc-jfqcv [296.06536ms]
May 25 02:19:01.737: INFO: Created: latency-svc-rdrsv
May 25 02:19:01.739: INFO: Got endpoints: latency-svc-rdrsv [302.03287ms]
May 25 02:19:01.759: INFO: Created: latency-svc-gg4jg
May 25 02:19:01.759: INFO: Got endpoints: latency-svc-gg4jg [305.733099ms]
May 25 02:19:01.768: INFO: Created: latency-svc-nn5pc
May 25 02:19:01.778: INFO: Created: latency-svc-cdsjk
May 25 02:19:01.778: INFO: Got endpoints: latency-svc-nn5pc [304.588609ms]
May 25 02:19:01.797: INFO: Got endpoints: latency-svc-cdsjk [309.08935ms]
May 25 02:19:01.803: INFO: Created: latency-svc-rwrjn
May 25 02:19:01.809: INFO: Got endpoints: latency-svc-rwrjn [274.722555ms]
May 25 02:19:01.825: INFO: Created: latency-svc-l656n
May 25 02:19:01.851: INFO: Created: latency-svc-k88qr
May 25 02:19:01.852: INFO: Got endpoints: latency-svc-l656n [304.110122ms]
May 25 02:19:01.856: INFO: Got endpoints: latency-svc-k88qr [276.761066ms]
May 25 02:19:01.892: INFO: Created: latency-svc-pxwng
May 25 02:19:01.904: INFO: Got endpoints: latency-svc-pxwng [312.335857ms]
May 25 02:19:01.938: INFO: Created: latency-svc-mr9sc
May 25 02:19:01.943: INFO: Got endpoints: latency-svc-mr9sc [330.711377ms]
May 25 02:19:01.965: INFO: Created: latency-svc-qxw6j
May 25 02:19:01.970: INFO: Got endpoints: latency-svc-qxw6j [341.322743ms]
May 25 02:19:01.978: INFO: Created: latency-svc-7lf5d
May 25 02:19:01.981: INFO: Got endpoints: latency-svc-7lf5d [334.742166ms]
May 25 02:19:01.999: INFO: Created: latency-svc-lwqn5
May 25 02:19:02.003: INFO: Got endpoints: latency-svc-lwqn5 [336.409801ms]
May 25 02:19:02.026: INFO: Created: latency-svc-tj742
May 25 02:19:02.028: INFO: Got endpoints: latency-svc-tj742 [331.787021ms]
May 25 02:19:02.050: INFO: Created: latency-svc-kctc6
May 25 02:19:02.110: INFO: Got endpoints: latency-svc-kctc6 [396.474586ms]
May 25 02:19:02.128: INFO: Created: latency-svc-dvzhr
May 25 02:19:02.128: INFO: Got endpoints: latency-svc-dvzhr [404.605248ms]
May 25 02:19:02.142: INFO: Created: latency-svc-ts896
May 25 02:19:02.162: INFO: Got endpoints: latency-svc-ts896 [422.098985ms]
May 25 02:19:02.171: INFO: Created: latency-svc-kb6wj
May 25 02:19:02.178: INFO: Got endpoints: latency-svc-kb6wj [418.382093ms]
May 25 02:19:02.198: INFO: Created: latency-svc-b5wm4
May 25 02:19:02.216: INFO: Got endpoints: latency-svc-b5wm4 [438.261976ms]
May 25 02:19:02.229: INFO: Created: latency-svc-8znfk
May 25 02:19:02.236: INFO: Got endpoints: latency-svc-8znfk [439.330922ms]
May 25 02:19:02.248: INFO: Created: latency-svc-vk8mj
May 25 02:19:02.252: INFO: Got endpoints: latency-svc-vk8mj [442.806627ms]
May 25 02:19:02.268: INFO: Created: latency-svc-w44g4
May 25 02:19:02.268: INFO: Got endpoints: latency-svc-w44g4 [416.188711ms]
May 25 02:19:02.280: INFO: Created: latency-svc-4wv8b
May 25 02:19:02.283: INFO: Got endpoints: latency-svc-4wv8b [427.562234ms]
May 25 02:19:02.304: INFO: Created: latency-svc-4t7gx
May 25 02:19:02.325: INFO: Got endpoints: latency-svc-4t7gx [420.465386ms]
May 25 02:19:02.337: INFO: Created: latency-svc-szm4d
May 25 02:19:02.337: INFO: Got endpoints: latency-svc-szm4d [393.050794ms]
May 25 02:19:02.350: INFO: Created: latency-svc-nndkr
May 25 02:19:02.354: INFO: Got endpoints: latency-svc-nndkr [383.218958ms]
May 25 02:19:02.363: INFO: Created: latency-svc-45djv
May 25 02:19:02.369: INFO: Got endpoints: latency-svc-45djv [386.676842ms]
May 25 02:19:02.381: INFO: Created: latency-svc-vs69p
May 25 02:19:02.381: INFO: Got endpoints: latency-svc-vs69p [377.762016ms]
May 25 02:19:02.398: INFO: Created: latency-svc-xvqw2
May 25 02:19:02.410: INFO: Got endpoints: latency-svc-xvqw2 [381.591456ms]
May 25 02:19:02.425: INFO: Created: latency-svc-c55fk
May 25 02:19:02.446: INFO: Got endpoints: latency-svc-c55fk [317.98297ms]
May 25 02:19:02.455: INFO: Created: latency-svc-l9t7n
May 25 02:19:02.461: INFO: Got endpoints: latency-svc-l9t7n [350.600572ms]
May 25 02:19:02.473: INFO: Created: latency-svc-tprpw
May 25 02:19:02.476: INFO: Got endpoints: latency-svc-tprpw [314.169044ms]
May 25 02:19:02.486: INFO: Created: latency-svc-zxdxp
May 25 02:19:02.493: INFO: Got endpoints: latency-svc-zxdxp [315.287749ms]
May 25 02:19:02.508: INFO: Created: latency-svc-p86q8
May 25 02:19:02.511: INFO: Got endpoints: latency-svc-p86q8 [294.173657ms]
May 25 02:19:02.521: INFO: Created: latency-svc-csdmj
May 25 02:19:02.529: INFO: Got endpoints: latency-svc-csdmj [292.753848ms]
May 25 02:19:02.544: INFO: Created: latency-svc-gwx4p
May 25 02:19:02.545: INFO: Got endpoints: latency-svc-gwx4p [293.079938ms]
May 25 02:19:02.567: INFO: Created: latency-svc-s49rr
May 25 02:19:02.579: INFO: Created: latency-svc-tnhvp
May 25 02:19:02.596: INFO: Created: latency-svc-2ppb6
May 25 02:19:02.601: INFO: Got endpoints: latency-svc-s49rr [331.658406ms]
May 25 02:19:02.620: INFO: Created: latency-svc-s9vbf
May 25 02:19:02.627: INFO: Created: latency-svc-8qq4w
May 25 02:19:02.644: INFO: Created: latency-svc-jlsdj
May 25 02:19:02.650: INFO: Got endpoints: latency-svc-tnhvp [366.380766ms]
May 25 02:19:02.667: INFO: Created: latency-svc-xwvrd
May 25 02:19:02.678: INFO: Created: latency-svc-p8rlb
May 25 02:19:02.685: INFO: Created: latency-svc-7vfrp
May 25 02:19:02.695: INFO: Got endpoints: latency-svc-2ppb6 [369.712084ms]
May 25 02:19:02.702: INFO: Created: latency-svc-tqtsb
May 25 02:19:02.716: INFO: Created: latency-svc-zrzwb
May 25 02:19:02.736: INFO: Created: latency-svc-pl8f6
May 25 02:19:02.755: INFO: Got endpoints: latency-svc-s9vbf [417.841099ms]
May 25 02:19:02.764: INFO: Created: latency-svc-wk6ws
May 25 02:19:02.790: INFO: Created: latency-svc-8k4x6
May 25 02:19:02.796: INFO: Got endpoints: latency-svc-8qq4w [442.700044ms]
May 25 02:19:02.802: INFO: Created: latency-svc-shkp6
May 25 02:19:02.851: INFO: Got endpoints: latency-svc-jlsdj [481.983906ms]
May 25 02:19:02.858: INFO: Created: latency-svc-wk5jj
May 25 02:19:02.866: INFO: Created: latency-svc-tphs4
May 25 02:19:02.886: INFO: Created: latency-svc-gdrrj
May 25 02:19:02.892: INFO: Got endpoints: latency-svc-xwvrd [510.801621ms]
May 25 02:19:02.898: INFO: Created: latency-svc-nc2jx
May 25 02:19:02.912: INFO: Created: latency-svc-65lns
May 25 02:19:02.931: INFO: Created: latency-svc-vchx9
May 25 02:19:02.945: INFO: Got endpoints: latency-svc-p8rlb [535.624441ms]
May 25 02:19:02.945: INFO: Created: latency-svc-hr8b8
May 25 02:19:02.973: INFO: Created: latency-svc-2tr8b
May 25 02:19:03.001: INFO: Got endpoints: latency-svc-7vfrp [555.239989ms]
May 25 02:19:03.018: INFO: Created: latency-svc-xkt84
May 25 02:19:03.041: INFO: Got endpoints: latency-svc-tqtsb [580.129197ms]
May 25 02:19:03.059: INFO: Created: latency-svc-wpt27
May 25 02:19:03.093: INFO: Got endpoints: latency-svc-zrzwb [617.133905ms]
May 25 02:19:03.136: INFO: Created: latency-svc-4vknv
May 25 02:19:03.142: INFO: Got endpoints: latency-svc-pl8f6 [648.948132ms]
May 25 02:19:03.163: INFO: Created: latency-svc-gsjvf
May 25 02:19:03.191: INFO: Got endpoints: latency-svc-wk6ws [680.293697ms]
May 25 02:19:03.220: INFO: Created: latency-svc-gpb4v
May 25 02:19:03.244: INFO: Got endpoints: latency-svc-8k4x6 [715.000895ms]
May 25 02:19:03.271: INFO: Created: latency-svc-s6rmt
May 25 02:19:03.302: INFO: Got endpoints: latency-svc-shkp6 [756.743345ms]
May 25 02:19:03.398: INFO: Got endpoints: latency-svc-wk5jj [797.718635ms]
May 25 02:19:03.402: INFO: Got endpoints: latency-svc-tphs4 [752.210325ms]
May 25 02:19:03.429: INFO: Created: latency-svc-d5bt5
May 25 02:19:03.445: INFO: Created: latency-svc-59svw
May 25 02:19:03.445: INFO: Got endpoints: latency-svc-gdrrj [749.981014ms]
May 25 02:19:03.467: INFO: Created: latency-svc-qvvvl
May 25 02:19:03.470: INFO: Created: latency-svc-w648m
May 25 02:19:03.492: INFO: Got endpoints: latency-svc-nc2jx [736.979892ms]
May 25 02:19:03.522: INFO: Created: latency-svc-wml9n
May 25 02:19:03.542: INFO: Got endpoints: latency-svc-65lns [745.273667ms]
May 25 02:19:03.561: INFO: Created: latency-svc-zhbgc
May 25 02:19:03.594: INFO: Got endpoints: latency-svc-vchx9 [743.233638ms]
May 25 02:19:03.621: INFO: Created: latency-svc-gk2kv
May 25 02:19:03.644: INFO: Got endpoints: latency-svc-hr8b8 [752.165693ms]
May 25 02:19:03.680: INFO: Created: latency-svc-n5lhd
May 25 02:19:03.693: INFO: Got endpoints: latency-svc-2tr8b [747.842147ms]
May 25 02:19:03.710: INFO: Created: latency-svc-hv5wp
May 25 02:19:03.748: INFO: Got endpoints: latency-svc-xkt84 [746.564156ms]
May 25 02:19:03.803: INFO: Got endpoints: latency-svc-wpt27 [761.695389ms]
May 25 02:19:03.809: INFO: Created: latency-svc-r96vn
May 25 02:19:03.849: INFO: Got endpoints: latency-svc-4vknv [755.648061ms]
May 25 02:19:03.866: INFO: Created: latency-svc-qhm4p
May 25 02:19:03.889: INFO: Created: latency-svc-f4sg7
May 25 02:19:03.889: INFO: Got endpoints: latency-svc-gsjvf [746.608081ms]
May 25 02:19:03.916: INFO: Created: latency-svc-4sn5t
May 25 02:19:03.942: INFO: Got endpoints: latency-svc-gpb4v [751.038295ms]
May 25 02:19:03.975: INFO: Created: latency-svc-7n6xz
May 25 02:19:03.991: INFO: Got endpoints: latency-svc-s6rmt [746.392839ms]
May 25 02:19:04.012: INFO: Created: latency-svc-76t69
May 25 02:19:04.041: INFO: Got endpoints: latency-svc-d5bt5 [739.589687ms]
May 25 02:19:04.061: INFO: Created: latency-svc-2cbh9
May 25 02:19:04.092: INFO: Got endpoints: latency-svc-59svw [689.761741ms]
May 25 02:19:04.114: INFO: Created: latency-svc-9vcvh
May 25 02:19:04.142: INFO: Got endpoints: latency-svc-qvvvl [743.157097ms]
May 25 02:19:04.164: INFO: Created: latency-svc-875bf
May 25 02:19:04.195: INFO: Got endpoints: latency-svc-w648m [749.93434ms]
May 25 02:19:04.214: INFO: Created: latency-svc-jmhbq
May 25 02:19:04.244: INFO: Got endpoints: latency-svc-wml9n [751.755766ms]
May 25 02:19:04.268: INFO: Created: latency-svc-58cj2
May 25 02:19:04.292: INFO: Got endpoints: latency-svc-zhbgc [750.506128ms]
May 25 02:19:04.322: INFO: Created: latency-svc-2m69x
May 25 02:19:04.342: INFO: Got endpoints: latency-svc-gk2kv [747.47235ms]
May 25 02:19:04.360: INFO: Created: latency-svc-2ncqt
May 25 02:19:04.391: INFO: Got endpoints: latency-svc-n5lhd [746.377441ms]
May 25 02:19:04.417: INFO: Created: latency-svc-9khs5
May 25 02:19:04.441: INFO: Got endpoints: latency-svc-hv5wp [747.061286ms]
May 25 02:19:04.459: INFO: Created: latency-svc-zbcfj
May 25 02:19:04.491: INFO: Got endpoints: latency-svc-r96vn [743.392055ms]
May 25 02:19:04.513: INFO: Created: latency-svc-4pczb
May 25 02:19:04.541: INFO: Got endpoints: latency-svc-qhm4p [734.437128ms]
May 25 02:19:04.564: INFO: Created: latency-svc-kgcxb
May 25 02:19:04.592: INFO: Got endpoints: latency-svc-f4sg7 [742.915431ms]
May 25 02:19:04.618: INFO: Created: latency-svc-ht6gt
May 25 02:19:04.642: INFO: Got endpoints: latency-svc-4sn5t [752.545775ms]
May 25 02:19:04.661: INFO: Created: latency-svc-wkt52
May 25 02:19:04.693: INFO: Got endpoints: latency-svc-7n6xz [750.583816ms]
May 25 02:19:04.711: INFO: Created: latency-svc-d68g9
May 25 02:19:04.742: INFO: Got endpoints: latency-svc-76t69 [750.649916ms]
May 25 02:19:04.760: INFO: Created: latency-svc-t65v4
May 25 02:19:04.793: INFO: Got endpoints: latency-svc-2cbh9 [751.508259ms]
May 25 02:19:04.812: INFO: Created: latency-svc-vrph4
May 25 02:19:04.842: INFO: Got endpoints: latency-svc-9vcvh [749.306018ms]
May 25 02:19:04.861: INFO: Created: latency-svc-lmzv4
May 25 02:19:04.891: INFO: Got endpoints: latency-svc-875bf [749.644557ms]
May 25 02:19:04.911: INFO: Created: latency-svc-tmd46
May 25 02:19:04.943: INFO: Got endpoints: latency-svc-jmhbq [747.498259ms]
May 25 02:19:04.975: INFO: Created: latency-svc-dwpgp
May 25 02:19:04.991: INFO: Got endpoints: latency-svc-58cj2 [747.079765ms]
May 25 02:19:05.010: INFO: Created: latency-svc-fs2vf
May 25 02:19:05.046: INFO: Got endpoints: latency-svc-2m69x [752.404187ms]
May 25 02:19:05.066: INFO: Created: latency-svc-lwdbr
May 25 02:19:05.095: INFO: Got endpoints: latency-svc-2ncqt [753.41425ms]
May 25 02:19:05.117: INFO: Created: latency-svc-jtl8k
May 25 02:19:05.142: INFO: Got endpoints: latency-svc-9khs5 [750.017551ms]
May 25 02:19:05.166: INFO: Created: latency-svc-m7nx9
May 25 02:19:05.192: INFO: Got endpoints: latency-svc-zbcfj [750.004061ms]
May 25 02:19:05.208: INFO: Created: latency-svc-sgjlz
May 25 02:19:05.243: INFO: Got endpoints: latency-svc-4pczb [751.920856ms]
May 25 02:19:05.263: INFO: Created: latency-svc-hkh6x
May 25 02:19:05.294: INFO: Got endpoints: latency-svc-kgcxb [752.376168ms]
May 25 02:19:05.310: INFO: Created: latency-svc-kwtll
May 25 02:19:05.343: INFO: Got endpoints: latency-svc-ht6gt [750.316993ms]
May 25 02:19:05.363: INFO: Created: latency-svc-9sz7d
May 25 02:19:05.393: INFO: Got endpoints: latency-svc-wkt52 [751.209629ms]
May 25 02:19:05.410: INFO: Created: latency-svc-ztrzj
May 25 02:19:05.442: INFO: Got endpoints: latency-svc-d68g9 [748.861671ms]
May 25 02:19:05.463: INFO: Created: latency-svc-vlrtf
May 25 02:19:05.492: INFO: Got endpoints: latency-svc-t65v4 [750.004023ms]
May 25 02:19:05.508: INFO: Created: latency-svc-vz4nq
May 25 02:19:05.543: INFO: Got endpoints: latency-svc-vrph4 [749.537999ms]
May 25 02:19:05.561: INFO: Created: latency-svc-q2jq8
May 25 02:19:05.593: INFO: Got endpoints: latency-svc-lmzv4 [750.910037ms]
May 25 02:19:05.611: INFO: Created: latency-svc-mz56d
May 25 02:19:05.643: INFO: Got endpoints: latency-svc-tmd46 [751.035237ms]
May 25 02:19:05.662: INFO: Created: latency-svc-srpkz
May 25 02:19:05.697: INFO: Got endpoints: latency-svc-dwpgp [754.081039ms]
May 25 02:19:05.714: INFO: Created: latency-svc-tcfm6
May 25 02:19:05.743: INFO: Got endpoints: latency-svc-fs2vf [751.075973ms]
May 25 02:19:05.762: INFO: Created: latency-svc-shs77
May 25 02:19:05.792: INFO: Got endpoints: latency-svc-lwdbr [746.376233ms]
May 25 02:19:05.814: INFO: Created: latency-svc-shrsl
May 25 02:19:05.842: INFO: Got endpoints: latency-svc-jtl8k [745.966457ms]
May 25 02:19:05.858: INFO: Created: latency-svc-7zjwq
May 25 02:19:05.893: INFO: Got endpoints: latency-svc-m7nx9 [749.948299ms]
May 25 02:19:05.914: INFO: Created: latency-svc-j6nns
May 25 02:19:05.944: INFO: Got endpoints: latency-svc-sgjlz [752.531601ms]
May 25 02:19:05.960: INFO: Created: latency-svc-hz7l9
May 25 02:19:05.992: INFO: Got endpoints: latency-svc-hkh6x [748.309403ms]
May 25 02:19:06.008: INFO: Created: latency-svc-qzsrw
May 25 02:19:06.043: INFO: Got endpoints: latency-svc-kwtll [748.807769ms]
May 25 02:19:06.060: INFO: Created: latency-svc-nb7tp
May 25 02:19:06.091: INFO: Got endpoints: latency-svc-9sz7d [748.058905ms]
May 25 02:19:06.109: INFO: Created: latency-svc-wsst2
May 25 02:19:06.142: INFO: Got endpoints: latency-svc-ztrzj [749.180809ms]
May 25 02:19:06.173: INFO: Created: latency-svc-wnm96
May 25 02:19:06.191: INFO: Got endpoints: latency-svc-vlrtf [748.94159ms]
May 25 02:19:06.210: INFO: Created: latency-svc-cq454
May 25 02:19:06.244: INFO: Got endpoints: latency-svc-vz4nq [751.777083ms]
May 25 02:19:06.262: INFO: Created: latency-svc-vjrbj
May 25 02:19:06.291: INFO: Got endpoints: latency-svc-q2jq8 [748.391149ms]
May 25 02:19:06.316: INFO: Created: latency-svc-4b42w
May 25 02:19:06.342: INFO: Got endpoints: latency-svc-mz56d [748.891491ms]
May 25 02:19:06.360: INFO: Created: latency-svc-vjmjd
May 25 02:19:06.394: INFO: Got endpoints: latency-svc-srpkz [750.851655ms]
May 25 02:19:06.415: INFO: Created: latency-svc-kv6wc
May 25 02:19:06.448: INFO: Got endpoints: latency-svc-tcfm6 [750.936689ms]
May 25 02:19:06.465: INFO: Created: latency-svc-dmhg4
May 25 02:19:06.490: INFO: Got endpoints: latency-svc-shs77 [745.640993ms]
May 25 02:19:06.509: INFO: Created: latency-svc-wmltf
May 25 02:19:06.542: INFO: Got endpoints: latency-svc-shrsl [749.529222ms]
May 25 02:19:06.562: INFO: Created: latency-svc-jstwz
May 25 02:19:06.591: INFO: Got endpoints: latency-svc-7zjwq [749.313801ms]
May 25 02:19:06.609: INFO: Created: latency-svc-s6xvl
May 25 02:19:06.641: INFO: Got endpoints: latency-svc-j6nns [748.47457ms]
May 25 02:19:06.660: INFO: Created: latency-svc-z78n6
May 25 02:19:06.693: INFO: Got endpoints: latency-svc-hz7l9 [748.212978ms]
May 25 02:19:06.715: INFO: Created: latency-svc-hp56f
May 25 02:19:06.758: INFO: Got endpoints: latency-svc-qzsrw [765.572436ms]
May 25 02:19:06.781: INFO: Created: latency-svc-pd58j
May 25 02:19:06.792: INFO: Got endpoints: latency-svc-nb7tp [749.012166ms]
May 25 02:19:06.809: INFO: Created: latency-svc-vm85r
May 25 02:19:06.842: INFO: Got endpoints: latency-svc-wsst2 [750.55522ms]
May 25 02:19:06.860: INFO: Created: latency-svc-bq7k4
May 25 02:19:06.894: INFO: Got endpoints: latency-svc-wnm96 [750.871465ms]
May 25 02:19:06.913: INFO: Created: latency-svc-xzqrl
May 25 02:19:06.946: INFO: Got endpoints: latency-svc-cq454 [755.127063ms]
May 25 02:19:06.968: INFO: Created: latency-svc-655bw
May 25 02:19:06.991: INFO: Got endpoints: latency-svc-vjrbj [747.001886ms]
May 25 02:19:07.007: INFO: Created: latency-svc-gx7dv
May 25 02:19:07.041: INFO: Got endpoints: latency-svc-4b42w [749.900778ms]
May 25 02:19:07.055: INFO: Created: latency-svc-prndc
May 25 02:19:07.092: INFO: Got endpoints: latency-svc-vjmjd [749.940075ms]
May 25 02:19:07.111: INFO: Created: latency-svc-t6fcw
May 25 02:19:07.141: INFO: Got endpoints: latency-svc-kv6wc [747.125335ms]
May 25 02:19:07.154: INFO: Created: latency-svc-hx4c4
May 25 02:19:07.193: INFO: Got endpoints: latency-svc-dmhg4 [744.782727ms]
May 25 02:19:07.357: INFO: Got endpoints: latency-svc-wmltf [866.496086ms]
May 25 02:19:07.357: INFO: Got endpoints: latency-svc-jstwz [813.893277ms]
May 25 02:19:07.370: INFO: Got endpoints: latency-svc-s6xvl [779.136587ms]
May 25 02:19:07.371: INFO: Created: latency-svc-9zrqs
May 25 02:19:07.392: INFO: Created: latency-svc-cj2gn
May 25 02:19:07.416: INFO: Got endpoints: latency-svc-z78n6 [774.507267ms]
May 25 02:19:07.425: INFO: Created: latency-svc-6s9x5
May 25 02:19:07.441: INFO: Created: latency-svc-4sccf
May 25 02:19:07.449: INFO: Got endpoints: latency-svc-hp56f [756.61609ms]
May 25 02:19:07.469: INFO: Created: latency-svc-5r56x
May 25 02:19:07.480: INFO: Created: latency-svc-lng9k
May 25 02:19:07.494: INFO: Got endpoints: latency-svc-pd58j [736.638966ms]
May 25 02:19:07.536: INFO: Created: latency-svc-djdpv
May 25 02:19:07.542: INFO: Got endpoints: latency-svc-vm85r [750.420489ms]
May 25 02:19:07.558: INFO: Created: latency-svc-jpr24
May 25 02:19:07.595: INFO: Got endpoints: latency-svc-bq7k4 [752.846561ms]
May 25 02:19:07.613: INFO: Created: latency-svc-hqbf6
May 25 02:19:07.644: INFO: Got endpoints: latency-svc-xzqrl [750.091926ms]
May 25 02:19:07.662: INFO: Created: latency-svc-96ctm
May 25 02:19:07.694: INFO: Got endpoints: latency-svc-655bw [747.265956ms]
May 25 02:19:07.715: INFO: Created: latency-svc-ld8wz
May 25 02:19:07.742: INFO: Got endpoints: latency-svc-gx7dv [750.83795ms]
May 25 02:19:07.765: INFO: Created: latency-svc-82zzf
May 25 02:19:07.793: INFO: Got endpoints: latency-svc-prndc [751.312177ms]
May 25 02:19:07.813: INFO: Created: latency-svc-z8lzn
May 25 02:19:07.842: INFO: Got endpoints: latency-svc-t6fcw [750.016226ms]
May 25 02:19:07.864: INFO: Created: latency-svc-s66rs
May 25 02:19:07.893: INFO: Got endpoints: latency-svc-hx4c4 [751.997107ms]
May 25 02:19:07.912: INFO: Created: latency-svc-bqn2r
May 25 02:19:07.945: INFO: Got endpoints: latency-svc-9zrqs [751.703159ms]
May 25 02:19:07.968: INFO: Created: latency-svc-mnjjx
May 25 02:19:07.993: INFO: Got endpoints: latency-svc-cj2gn [635.892234ms]
May 25 02:19:08.013: INFO: Created: latency-svc-z9gwr
May 25 02:19:08.043: INFO: Got endpoints: latency-svc-6s9x5 [684.259988ms]
May 25 02:19:08.062: INFO: Created: latency-svc-wcdrq
May 25 02:19:08.094: INFO: Got endpoints: latency-svc-4sccf [724.092968ms]
May 25 02:19:08.123: INFO: Created: latency-svc-g8hhq
May 25 02:19:08.141: INFO: Got endpoints: latency-svc-5r56x [725.054711ms]
May 25 02:19:08.157: INFO: Created: latency-svc-57wf9
May 25 02:19:08.192: INFO: Got endpoints: latency-svc-lng9k [742.398869ms]
May 25 02:19:08.211: INFO: Created: latency-svc-4tctz
May 25 02:19:08.244: INFO: Got endpoints: latency-svc-djdpv [749.262999ms]
May 25 02:19:08.268: INFO: Created: latency-svc-qkpll
May 25 02:19:08.293: INFO: Got endpoints: latency-svc-jpr24 [750.266199ms]
May 25 02:19:08.324: INFO: Created: latency-svc-dvv7d
May 25 02:19:08.341: INFO: Got endpoints: latency-svc-hqbf6 [746.232018ms]
May 25 02:19:08.360: INFO: Created: latency-svc-ng8pm
May 25 02:19:08.395: INFO: Got endpoints: latency-svc-96ctm [750.913614ms]
May 25 02:19:08.414: INFO: Created: latency-svc-8hjhr
May 25 02:19:08.441: INFO: Got endpoints: latency-svc-ld8wz [747.135848ms]
May 25 02:19:08.459: INFO: Created: latency-svc-vqmwf
May 25 02:19:08.490: INFO: Got endpoints: latency-svc-82zzf [747.759926ms]
May 25 02:19:08.510: INFO: Created: latency-svc-npdk5
May 25 02:19:08.541: INFO: Got endpoints: latency-svc-z8lzn [747.404762ms]
May 25 02:19:08.559: INFO: Created: latency-svc-5ndtz
May 25 02:19:08.591: INFO: Got endpoints: latency-svc-s66rs [748.493271ms]
May 25 02:19:08.611: INFO: Created: latency-svc-trxgg
May 25 02:19:08.640: INFO: Got endpoints: latency-svc-bqn2r [747.194672ms]
May 25 02:19:08.655: INFO: Created: latency-svc-t9pjz
May 25 02:19:08.692: INFO: Got endpoints: latency-svc-mnjjx [746.084681ms]
May 25 02:19:08.716: INFO: Created: latency-svc-qgnr6
May 25 02:19:08.742: INFO: Got endpoints: latency-svc-z9gwr [748.845616ms]
May 25 02:19:08.758: INFO: Created: latency-svc-q4fqs
May 25 02:19:08.791: INFO: Got endpoints: latency-svc-wcdrq [748.532772ms]
May 25 02:19:08.809: INFO: Created: latency-svc-fhzdj
May 25 02:19:08.842: INFO: Got endpoints: latency-svc-g8hhq [747.574132ms]
May 25 02:19:08.864: INFO: Created: latency-svc-m2l6q
May 25 02:19:08.893: INFO: Got endpoints: latency-svc-57wf9 [751.611012ms]
May 25 02:19:08.910: INFO: Created: latency-svc-jvv7x
May 25 02:19:08.941: INFO: Got endpoints: latency-svc-4tctz [748.982613ms]
May 25 02:19:08.980: INFO: Created: latency-svc-lp4dv
May 25 02:19:08.991: INFO: Got endpoints: latency-svc-qkpll [747.096302ms]
May 25 02:19:09.010: INFO: Created: latency-svc-gh5j9
May 25 02:19:09.041: INFO: Got endpoints: latency-svc-dvv7d [747.831744ms]
May 25 02:19:09.059: INFO: Created: latency-svc-c74fb
May 25 02:19:09.092: INFO: Got endpoints: latency-svc-ng8pm [750.556892ms]
May 25 02:19:09.143: INFO: Got endpoints: latency-svc-8hjhr [748.157724ms]
May 25 02:19:09.195: INFO: Got endpoints: latency-svc-vqmwf [754.357176ms]
May 25 02:19:09.242: INFO: Got endpoints: latency-svc-npdk5 [752.116754ms]
May 25 02:19:09.292: INFO: Got endpoints: latency-svc-5ndtz [751.234001ms]
May 25 02:19:09.341: INFO: Got endpoints: latency-svc-trxgg [750.347459ms]
May 25 02:19:09.391: INFO: Got endpoints: latency-svc-t9pjz [750.710722ms]
May 25 02:19:09.442: INFO: Got endpoints: latency-svc-qgnr6 [750.109987ms]
May 25 02:19:09.491: INFO: Got endpoints: latency-svc-q4fqs [749.378927ms]
May 25 02:19:09.542: INFO: Got endpoints: latency-svc-fhzdj [750.415075ms]
May 25 02:19:09.592: INFO: Got endpoints: latency-svc-m2l6q [749.598913ms]
May 25 02:19:09.642: INFO: Got endpoints: latency-svc-jvv7x [748.689079ms]
May 25 02:19:09.691: INFO: Got endpoints: latency-svc-lp4dv [750.200227ms]
May 25 02:19:09.741: INFO: Got endpoints: latency-svc-gh5j9 [749.48334ms]
May 25 02:19:09.792: INFO: Got endpoints: latency-svc-c74fb [751.145003ms]
May 25 02:19:09.793: INFO: Latencies: [119.916733ms 158.297139ms 184.86522ms 203.161227ms 216.823241ms 226.742763ms 243.43381ms 262.690887ms 274.722555ms 276.761066ms 276.866752ms 292.753848ms 293.079938ms 294.173657ms 296.06536ms 299.328516ms 300.802046ms 302.03287ms 302.553446ms 304.110122ms 304.588609ms 305.733099ms 309.08935ms 312.335857ms 314.169044ms 315.287749ms 317.768063ms 317.98297ms 323.16257ms 330.711377ms 331.658406ms 331.787021ms 334.742166ms 336.409801ms 338.487826ms 341.322743ms 350.600572ms 366.380766ms 367.466848ms 369.712084ms 377.762016ms 380.512593ms 381.591456ms 383.218958ms 386.676842ms 393.050794ms 396.474586ms 401.566633ms 404.605248ms 416.188711ms 417.474409ms 417.841099ms 418.382093ms 420.465386ms 422.098985ms 427.562234ms 438.261976ms 439.330922ms 442.700044ms 442.806627ms 481.983906ms 510.801621ms 535.624441ms 555.239989ms 580.129197ms 617.133905ms 635.892234ms 648.948132ms 680.293697ms 684.259988ms 689.761741ms 715.000895ms 724.092968ms 725.054711ms 734.437128ms 736.638966ms 736.979892ms 739.589687ms 742.398869ms 742.915431ms 743.157097ms 743.233638ms 743.392055ms 744.782727ms 745.273667ms 745.640993ms 745.966457ms 746.084681ms 746.232018ms 746.376233ms 746.377441ms 746.392839ms 746.564156ms 746.608081ms 747.001886ms 747.061286ms 747.079765ms 747.096302ms 747.125335ms 747.135848ms 747.194672ms 747.265956ms 747.404762ms 747.47235ms 747.498259ms 747.574132ms 747.759926ms 747.831744ms 747.842147ms 748.058905ms 748.157724ms 748.212978ms 748.309403ms 748.391149ms 748.47457ms 748.493271ms 748.532772ms 748.689079ms 748.807769ms 748.845616ms 748.861671ms 748.891491ms 748.94159ms 748.982613ms 749.012166ms 749.180809ms 749.262999ms 749.306018ms 749.313801ms 749.378927ms 749.48334ms 749.529222ms 749.537999ms 749.598913ms 749.644557ms 749.900778ms 749.93434ms 749.940075ms 749.948299ms 749.981014ms 750.004023ms 750.004061ms 750.016226ms 750.017551ms 750.091926ms 750.109987ms 750.200227ms 750.266199ms 750.316993ms 750.347459ms 750.415075ms 750.420489ms 750.506128ms 750.55522ms 750.556892ms 750.583816ms 750.649916ms 750.710722ms 750.83795ms 750.851655ms 750.871465ms 750.910037ms 750.913614ms 750.936689ms 751.035237ms 751.038295ms 751.075973ms 751.145003ms 751.209629ms 751.234001ms 751.312177ms 751.508259ms 751.611012ms 751.703159ms 751.755766ms 751.777083ms 751.920856ms 751.997107ms 752.116754ms 752.165693ms 752.210325ms 752.376168ms 752.404187ms 752.531601ms 752.545775ms 752.846561ms 753.41425ms 754.081039ms 754.357176ms 755.127063ms 755.648061ms 756.61609ms 756.743345ms 761.695389ms 765.572436ms 774.507267ms 779.136587ms 797.718635ms 813.893277ms 866.496086ms]
May 25 02:19:09.793: INFO: 50 %ile: 747.194672ms
May 25 02:19:09.793: INFO: 90 %ile: 752.210325ms
May 25 02:19:09.793: INFO: 99 %ile: 813.893277ms
May 25 02:19:09.793: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:19:09.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-2n9cj" for this suite.
May 25 02:19:33.807: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:19:33.891: INFO: namespace: e2e-tests-svc-latency-2n9cj, resource: bindings, ignored listing per whitelist
May 25 02:19:33.926: INFO: namespace e2e-tests-svc-latency-2n9cj deletion completed in 24.128049683s

• [SLOW TEST:35.082 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:19:33.929: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-pxljd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
May 25 02:19:34.093: INFO: Waiting up to 5m0s for pod "downward-api-8954b87a-7e93-11e9-802f-027f94874578" in namespace "e2e-tests-downward-api-pxljd" to be "success or failure"
May 25 02:19:34.098: INFO: Pod "downward-api-8954b87a-7e93-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 5.273754ms
May 25 02:19:36.101: INFO: Pod "downward-api-8954b87a-7e93-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007495558s
STEP: Saw pod success
May 25 02:19:36.101: INFO: Pod "downward-api-8954b87a-7e93-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 02:19:36.107: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod downward-api-8954b87a-7e93-11e9-802f-027f94874578 container dapi-container: <nil>
STEP: delete the pod
May 25 02:19:36.125: INFO: Waiting for pod downward-api-8954b87a-7e93-11e9-802f-027f94874578 to disappear
May 25 02:19:36.128: INFO: Pod downward-api-8954b87a-7e93-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:19:36.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-pxljd" for this suite.
May 25 02:19:42.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:19:42.160: INFO: namespace: e2e-tests-downward-api-pxljd, resource: bindings, ignored listing per whitelist
May 25 02:19:42.218: INFO: namespace e2e-tests-downward-api-pxljd deletion completed in 6.08469841s

• [SLOW TEST:8.289 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:19:42.218: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-kk4sm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-kk4sm/secret-test-8e45a466-7e93-11e9-802f-027f94874578
STEP: Creating a pod to test consume secrets
May 25 02:19:42.386: INFO: Waiting up to 5m0s for pod "pod-configmaps-8e4639a2-7e93-11e9-802f-027f94874578" in namespace "e2e-tests-secrets-kk4sm" to be "success or failure"
May 25 02:19:42.399: INFO: Pod "pod-configmaps-8e4639a2-7e93-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 13.144494ms
May 25 02:19:44.401: INFO: Pod "pod-configmaps-8e4639a2-7e93-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015749879s
STEP: Saw pod success
May 25 02:19:44.401: INFO: Pod "pod-configmaps-8e4639a2-7e93-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 02:19:44.404: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-configmaps-8e4639a2-7e93-11e9-802f-027f94874578 container env-test: <nil>
STEP: delete the pod
May 25 02:19:44.425: INFO: Waiting for pod pod-configmaps-8e4639a2-7e93-11e9-802f-027f94874578 to disappear
May 25 02:19:44.432: INFO: Pod pod-configmaps-8e4639a2-7e93-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:19:44.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-kk4sm" for this suite.
May 25 02:19:50.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:19:50.503: INFO: namespace: e2e-tests-secrets-kk4sm, resource: bindings, ignored listing per whitelist
May 25 02:19:50.522: INFO: namespace e2e-tests-secrets-kk4sm deletion completed in 6.085863115s

• [SLOW TEST:8.305 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:19:50.523: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-qcchq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
May 25 02:19:53.222: INFO: Successfully updated pod "pod-update-activedeadlineseconds-9339d9d8-7e93-11e9-802f-027f94874578"
May 25 02:19:53.222: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-9339d9d8-7e93-11e9-802f-027f94874578" in namespace "e2e-tests-pods-qcchq" to be "terminated due to deadline exceeded"
May 25 02:19:53.232: INFO: Pod "pod-update-activedeadlineseconds-9339d9d8-7e93-11e9-802f-027f94874578": Phase="Running", Reason="", readiness=true. Elapsed: 9.219668ms
May 25 02:19:55.236: INFO: Pod "pod-update-activedeadlineseconds-9339d9d8-7e93-11e9-802f-027f94874578": Phase="Running", Reason="", readiness=true. Elapsed: 2.013309461s
May 25 02:19:57.238: INFO: Pod "pod-update-activedeadlineseconds-9339d9d8-7e93-11e9-802f-027f94874578": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.01580173s
May 25 02:19:57.238: INFO: Pod "pod-update-activedeadlineseconds-9339d9d8-7e93-11e9-802f-027f94874578" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:19:57.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-qcchq" for this suite.
May 25 02:20:03.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:20:03.303: INFO: namespace: e2e-tests-pods-qcchq, resource: bindings, ignored listing per whitelist
May 25 02:20:03.348: INFO: namespace e2e-tests-pods-qcchq deletion completed in 6.105437742s

• [SLOW TEST:12.825 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:20:03.349: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-jl2q9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-m7rqz
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
May 25 02:20:05.674: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-r8rff
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:20:29.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-jl2q9" for this suite.
May 25 02:20:35.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:20:35.883: INFO: namespace: e2e-tests-namespaces-jl2q9, resource: bindings, ignored listing per whitelist
May 25 02:20:35.919: INFO: namespace e2e-tests-namespaces-jl2q9 deletion completed in 6.085208532s
STEP: Destroying namespace "e2e-tests-nsdeletetest-m7rqz" for this suite.
May 25 02:20:35.921: INFO: Namespace e2e-tests-nsdeletetest-m7rqz was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-r8rff" for this suite.
May 25 02:20:41.929: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:20:41.986: INFO: namespace: e2e-tests-nsdeletetest-r8rff, resource: bindings, ignored listing per whitelist
May 25 02:20:41.998: INFO: namespace e2e-tests-nsdeletetest-r8rff deletion completed in 6.07679995s

• [SLOW TEST:38.649 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:20:41.998: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-wrapper-pq879
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
May 25 02:20:42.403: INFO: Pod name wrapped-volume-race-b20621e9-7e93-11e9-802f-027f94874578: Found 1 pods out of 5
May 25 02:20:47.410: INFO: Pod name wrapped-volume-race-b20621e9-7e93-11e9-802f-027f94874578: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-b20621e9-7e93-11e9-802f-027f94874578 in namespace e2e-tests-emptydir-wrapper-pq879, will wait for the garbage collector to delete the pods
May 25 02:22:57.497: INFO: Deleting ReplicationController wrapped-volume-race-b20621e9-7e93-11e9-802f-027f94874578 took: 6.463368ms
May 25 02:22:57.597: INFO: Terminating ReplicationController wrapped-volume-race-b20621e9-7e93-11e9-802f-027f94874578 pods took: 100.452235ms
STEP: Creating RC which spawns configmap-volume pods
May 25 02:23:39.117: INFO: Pod name wrapped-volume-race-1b5efbdb-7e94-11e9-802f-027f94874578: Found 0 pods out of 5
May 25 02:23:44.122: INFO: Pod name wrapped-volume-race-1b5efbdb-7e94-11e9-802f-027f94874578: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-1b5efbdb-7e94-11e9-802f-027f94874578 in namespace e2e-tests-emptydir-wrapper-pq879, will wait for the garbage collector to delete the pods
May 25 02:25:36.201: INFO: Deleting ReplicationController wrapped-volume-race-1b5efbdb-7e94-11e9-802f-027f94874578 took: 10.659045ms
May 25 02:25:36.302: INFO: Terminating ReplicationController wrapped-volume-race-1b5efbdb-7e94-11e9-802f-027f94874578 pods took: 100.759979ms
STEP: Creating RC which spawns configmap-volume pods
May 25 02:26:18.838: INFO: Pod name wrapped-volume-race-7a8ffc93-7e94-11e9-802f-027f94874578: Found 0 pods out of 5
May 25 02:26:23.843: INFO: Pod name wrapped-volume-race-7a8ffc93-7e94-11e9-802f-027f94874578: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-7a8ffc93-7e94-11e9-802f-027f94874578 in namespace e2e-tests-emptydir-wrapper-pq879, will wait for the garbage collector to delete the pods
May 25 02:28:47.940: INFO: Deleting ReplicationController wrapped-volume-race-7a8ffc93-7e94-11e9-802f-027f94874578 took: 11.588935ms
May 25 02:28:48.040: INFO: Terminating ReplicationController wrapped-volume-race-7a8ffc93-7e94-11e9-802f-027f94874578 pods took: 100.174874ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:29:23.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-pq879" for this suite.
May 25 02:29:29.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:29:29.527: INFO: namespace: e2e-tests-emptydir-wrapper-pq879, resource: bindings, ignored listing per whitelist
May 25 02:29:29.548: INFO: namespace e2e-tests-emptydir-wrapper-pq879 deletion completed in 6.086971217s

• [SLOW TEST:527.549 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:29:29.548: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-dnkrr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 25 02:29:29.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-dnkrr'
May 25 02:29:30.037: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 25 02:29:30.037: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
May 25 02:29:30.045: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-2c4db]
May 25 02:29:30.045: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-2c4db" in namespace "e2e-tests-kubectl-dnkrr" to be "running and ready"
May 25 02:29:30.047: INFO: Pod "e2e-test-nginx-rc-2c4db": Phase="Pending", Reason="", readiness=false. Elapsed: 1.916014ms
May 25 02:29:32.050: INFO: Pod "e2e-test-nginx-rc-2c4db": Phase="Running", Reason="", readiness=true. Elapsed: 2.004917971s
May 25 02:29:32.050: INFO: Pod "e2e-test-nginx-rc-2c4db" satisfied condition "running and ready"
May 25 02:29:32.050: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-2c4db]
May 25 02:29:32.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-dnkrr'
May 25 02:29:32.171: INFO: stderr: ""
May 25 02:29:32.171: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
May 25 02:29:32.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-dnkrr'
May 25 02:29:32.270: INFO: stderr: ""
May 25 02:29:32.270: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:29:32.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dnkrr" for this suite.
May 25 02:29:54.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:29:54.340: INFO: namespace: e2e-tests-kubectl-dnkrr, resource: bindings, ignored listing per whitelist
May 25 02:29:54.379: INFO: namespace e2e-tests-kubectl-dnkrr deletion completed in 22.102149703s

• [SLOW TEST:24.832 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:29:54.382: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-92n4s
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-cj9j4
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-mhsrs
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:30:00.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-92n4s" for this suite.
May 25 02:30:06.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:30:06.988: INFO: namespace: e2e-tests-namespaces-92n4s, resource: bindings, ignored listing per whitelist
May 25 02:30:07.008: INFO: namespace e2e-tests-namespaces-92n4s deletion completed in 6.094191768s
STEP: Destroying namespace "e2e-tests-nsdeletetest-cj9j4" for this suite.
May 25 02:30:07.009: INFO: Namespace e2e-tests-nsdeletetest-cj9j4 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-mhsrs" for this suite.
May 25 02:30:13.019: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:30:13.080: INFO: namespace: e2e-tests-nsdeletetest-mhsrs, resource: bindings, ignored listing per whitelist
May 25 02:30:13.092: INFO: namespace e2e-tests-nsdeletetest-mhsrs deletion completed in 6.08219777s

• [SLOW TEST:18.711 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:30:13.093: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-gn4fj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
May 25 02:30:13.261: INFO: Waiting up to 5m0s for pod "pod-064e610b-7e95-11e9-802f-027f94874578" in namespace "e2e-tests-emptydir-gn4fj" to be "success or failure"
May 25 02:30:13.267: INFO: Pod "pod-064e610b-7e95-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 6.538912ms
May 25 02:30:15.271: INFO: Pod "pod-064e610b-7e95-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009959904s
STEP: Saw pod success
May 25 02:30:15.271: INFO: Pod "pod-064e610b-7e95-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 02:30:15.274: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-064e610b-7e95-11e9-802f-027f94874578 container test-container: <nil>
STEP: delete the pod
May 25 02:30:15.295: INFO: Waiting for pod pod-064e610b-7e95-11e9-802f-027f94874578 to disappear
May 25 02:30:15.297: INFO: Pod pod-064e610b-7e95-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:30:15.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-gn4fj" for this suite.
May 25 02:30:21.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:30:21.369: INFO: namespace: e2e-tests-emptydir-gn4fj, resource: bindings, ignored listing per whitelist
May 25 02:30:21.397: INFO: namespace e2e-tests-emptydir-gn4fj deletion completed in 6.096979114s

• [SLOW TEST:8.305 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:30:21.400: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-6drvm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secret-namespace-bnwlf
STEP: Creating secret with name secret-test-0b41601a-7e95-11e9-802f-027f94874578
STEP: Creating a pod to test consume secrets
May 25 02:30:21.696: INFO: Waiting up to 5m0s for pod "pod-secrets-0b55b4c0-7e95-11e9-802f-027f94874578" in namespace "e2e-tests-secrets-6drvm" to be "success or failure"
May 25 02:30:21.702: INFO: Pod "pod-secrets-0b55b4c0-7e95-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 5.865438ms
May 25 02:30:23.704: INFO: Pod "pod-secrets-0b55b4c0-7e95-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008200443s
STEP: Saw pod success
May 25 02:30:23.704: INFO: Pod "pod-secrets-0b55b4c0-7e95-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 02:30:23.706: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-secrets-0b55b4c0-7e95-11e9-802f-027f94874578 container secret-volume-test: <nil>
STEP: delete the pod
May 25 02:30:23.723: INFO: Waiting for pod pod-secrets-0b55b4c0-7e95-11e9-802f-027f94874578 to disappear
May 25 02:30:23.725: INFO: Pod pod-secrets-0b55b4c0-7e95-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:30:23.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-6drvm" for this suite.
May 25 02:30:29.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:30:29.804: INFO: namespace: e2e-tests-secrets-6drvm, resource: bindings, ignored listing per whitelist
May 25 02:30:29.806: INFO: namespace e2e-tests-secrets-6drvm deletion completed in 6.076625859s
STEP: Destroying namespace "e2e-tests-secret-namespace-bnwlf" for this suite.
May 25 02:30:35.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:30:35.841: INFO: namespace: e2e-tests-secret-namespace-bnwlf, resource: bindings, ignored listing per whitelist
May 25 02:30:35.883: INFO: namespace e2e-tests-secret-namespace-bnwlf deletion completed in 6.077089872s

• [SLOW TEST:14.484 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:30:35.884: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-kq2xd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 25 02:30:36.051: INFO: Waiting up to 5m0s for pod "downwardapi-volume-13e3f722-7e95-11e9-802f-027f94874578" in namespace "e2e-tests-downward-api-kq2xd" to be "success or failure"
May 25 02:30:36.054: INFO: Pod "downwardapi-volume-13e3f722-7e95-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 3.557622ms
May 25 02:30:38.057: INFO: Pod "downwardapi-volume-13e3f722-7e95-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006240728s
STEP: Saw pod success
May 25 02:30:38.057: INFO: Pod "downwardapi-volume-13e3f722-7e95-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 02:30:38.059: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod downwardapi-volume-13e3f722-7e95-11e9-802f-027f94874578 container client-container: <nil>
STEP: delete the pod
May 25 02:30:38.079: INFO: Waiting for pod downwardapi-volume-13e3f722-7e95-11e9-802f-027f94874578 to disappear
May 25 02:30:38.080: INFO: Pod downwardapi-volume-13e3f722-7e95-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:30:38.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-kq2xd" for this suite.
May 25 02:30:44.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:30:44.103: INFO: namespace: e2e-tests-downward-api-kq2xd, resource: bindings, ignored listing per whitelist
May 25 02:30:44.170: INFO: namespace e2e-tests-downward-api-kq2xd deletion completed in 6.085932565s

• [SLOW TEST:8.286 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:30:44.171: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-b6fdd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-18d61526-7e95-11e9-802f-027f94874578
STEP: Creating a pod to test consume configMaps
May 25 02:30:44.354: INFO: Waiting up to 5m0s for pod "pod-configmaps-18d69708-7e95-11e9-802f-027f94874578" in namespace "e2e-tests-configmap-b6fdd" to be "success or failure"
May 25 02:30:44.360: INFO: Pod "pod-configmaps-18d69708-7e95-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 5.613413ms
May 25 02:30:46.362: INFO: Pod "pod-configmaps-18d69708-7e95-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008126114s
STEP: Saw pod success
May 25 02:30:46.362: INFO: Pod "pod-configmaps-18d69708-7e95-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 02:30:46.365: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-configmaps-18d69708-7e95-11e9-802f-027f94874578 container configmap-volume-test: <nil>
STEP: delete the pod
May 25 02:30:46.380: INFO: Waiting for pod pod-configmaps-18d69708-7e95-11e9-802f-027f94874578 to disappear
May 25 02:30:46.383: INFO: Pod pod-configmaps-18d69708-7e95-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:30:46.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-b6fdd" for this suite.
May 25 02:30:52.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:30:52.450: INFO: namespace: e2e-tests-configmap-b6fdd, resource: bindings, ignored listing per whitelist
May 25 02:30:52.476: INFO: namespace e2e-tests-configmap-b6fdd deletion completed in 6.088054874s

• [SLOW TEST:8.305 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:30:52.477: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-j6rd7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
May 25 02:30:53.155: INFO: created pod pod-service-account-defaultsa
May 25 02:30:53.155: INFO: pod pod-service-account-defaultsa service account token volume mount: true
May 25 02:30:53.164: INFO: created pod pod-service-account-mountsa
May 25 02:30:53.164: INFO: pod pod-service-account-mountsa service account token volume mount: true
May 25 02:30:53.169: INFO: created pod pod-service-account-nomountsa
May 25 02:30:53.170: INFO: pod pod-service-account-nomountsa service account token volume mount: false
May 25 02:30:53.185: INFO: created pod pod-service-account-defaultsa-mountspec
May 25 02:30:53.185: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
May 25 02:30:53.196: INFO: created pod pod-service-account-mountsa-mountspec
May 25 02:30:53.196: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
May 25 02:30:53.211: INFO: created pod pod-service-account-nomountsa-mountspec
May 25 02:30:53.212: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
May 25 02:30:53.224: INFO: created pod pod-service-account-defaultsa-nomountspec
May 25 02:30:53.224: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
May 25 02:30:53.232: INFO: created pod pod-service-account-mountsa-nomountspec
May 25 02:30:53.232: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
May 25 02:30:53.243: INFO: created pod pod-service-account-nomountsa-nomountspec
May 25 02:30:53.243: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:30:53.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-j6rd7" for this suite.
May 25 02:30:59.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:30:59.360: INFO: namespace: e2e-tests-svcaccounts-j6rd7, resource: bindings, ignored listing per whitelist
May 25 02:30:59.370: INFO: namespace e2e-tests-svcaccounts-j6rd7 deletion completed in 6.112614286s

• [SLOW TEST:6.893 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:30:59.370: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-zd52s
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 25 02:30:59.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-zd52s'
May 25 02:30:59.639: INFO: stderr: ""
May 25 02:30:59.639: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
May 25 02:30:59.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-zd52s'
May 25 02:31:08.420: INFO: stderr: ""
May 25 02:31:08.420: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:31:08.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zd52s" for this suite.
May 25 02:31:14.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:31:14.508: INFO: namespace: e2e-tests-kubectl-zd52s, resource: bindings, ignored listing per whitelist
May 25 02:31:14.530: INFO: namespace e2e-tests-kubectl-zd52s deletion completed in 6.105459891s

• [SLOW TEST:15.160 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:31:14.530: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-8nv7j
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 25 02:31:14.702: INFO: Pod name cleanup-pod: Found 0 pods out of 1
May 25 02:31:19.705: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May 25 02:31:19.705: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 25 02:31:19.731: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-8nv7j,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8nv7j/deployments/test-cleanup-deployment,UID:2deacf6c-7e95-11e9-ba33-0050569e7ba0,ResourceVersion:31679,Generation:1,CreationTimestamp:2019-05-25 02:31:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

May 25 02:31:19.735: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
May 25 02:31:19.736: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
May 25 02:31:19.736: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-8nv7j,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8nv7j/replicasets/test-cleanup-controller,UID:2aedaf23-7e95-11e9-ba33-0050569e7ba0,ResourceVersion:31680,Generation:1,CreationTimestamp:2019-05-25 02:31:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 2deacf6c-7e95-11e9-ba33-0050569e7ba0 0xc000e49717 0xc000e49718}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
May 25 02:31:19.742: INFO: Pod "test-cleanup-controller-nvwjp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-nvwjp,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-8nv7j,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8nv7j/pods/test-cleanup-controller-nvwjp,UID:2aef1e86-7e95-11e9-ba33-0050569e7ba0,ResourceVersion:31671,Generation:0,CreationTimestamp:2019-05-25 02:31:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.235/32,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 2aedaf23-7e95-11e9-ba33-0050569e7ba0 0xc001d2fae7 0xc001d2fae8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nj2sc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nj2sc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nj2sc true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-400-cp1718-vsp2-workere35c6c6a2b,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d2fb50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d2fb70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 02:31:15 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 02:31:17 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 02:31:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-25 02:31:14 +0000 UTC  }],Message:,Reason:,HostIP:10.10.103.184,PodIP:192.168.1.235,StartTime:2019-05-25 02:31:15 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-25 02:31:16 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://443bf2cea36fec24459a5a64fb7f7046b2dc03354e0fa53a57e164c529e75553}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:31:19.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-8nv7j" for this suite.
May 25 02:31:25.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:31:25.799: INFO: namespace: e2e-tests-deployment-8nv7j, resource: bindings, ignored listing per whitelist
May 25 02:31:25.853: INFO: namespace e2e-tests-deployment-8nv7j deletion completed in 6.087758096s

• [SLOW TEST:11.323 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:31:25.853: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-hf7p9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
May 25 02:31:26.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-162046071 api-versions'
May 25 02:31:26.184: INFO: stderr: ""
May 25 02:31:26.184: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncertmanager.k8s.io/v1alpha1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:31:26.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hf7p9" for this suite.
May 25 02:31:32.202: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:31:32.252: INFO: namespace: e2e-tests-kubectl-hf7p9, resource: bindings, ignored listing per whitelist
May 25 02:31:32.277: INFO: namespace e2e-tests-kubectl-hf7p9 deletion completed in 6.087788207s

• [SLOW TEST:6.424 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:31:32.280: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-2ngvp
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-3582260e-7e95-11e9-802f-027f94874578
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:31:34.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-2ngvp" for this suite.
May 25 02:31:56.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:31:56.537: INFO: namespace: e2e-tests-configmap-2ngvp, resource: bindings, ignored listing per whitelist
May 25 02:31:56.571: INFO: namespace e2e-tests-configmap-2ngvp deletion completed in 22.089526262s

• [SLOW TEST:24.291 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:31:56.572: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-4jpq8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
May 25 02:31:58.748: INFO: Pod pod-hostip-43fb7eeb-7e95-11e9-802f-027f94874578 has hostIP: 10.10.103.184
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:31:58.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-4jpq8" for this suite.
May 25 02:32:20.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:32:20.814: INFO: namespace: e2e-tests-pods-4jpq8, resource: bindings, ignored listing per whitelist
May 25 02:32:20.840: INFO: namespace e2e-tests-pods-4jpq8 deletion completed in 22.087727738s

• [SLOW TEST:24.268 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:32:20.841: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-48ll2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-48ll2
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-48ll2 to expose endpoints map[]
May 25 02:32:21.017: INFO: Get endpoints failed (4.668845ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
May 25 02:32:22.019: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-48ll2 exposes endpoints map[] (1.006805019s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-48ll2
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-48ll2 to expose endpoints map[pod1:[100]]
May 25 02:32:24.044: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-48ll2 exposes endpoints map[pod1:[100]] (2.018169474s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-48ll2
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-48ll2 to expose endpoints map[pod1:[100] pod2:[101]]
May 25 02:32:25.068: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-48ll2 exposes endpoints map[pod1:[100] pod2:[101]] (1.016095953s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-48ll2
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-48ll2 to expose endpoints map[pod2:[101]]
May 25 02:32:25.085: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-48ll2 exposes endpoints map[pod2:[101]] (8.181124ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-48ll2
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-48ll2 to expose endpoints map[]
May 25 02:32:25.106: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-48ll2 exposes endpoints map[] (12.345781ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:32:25.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-48ll2" for this suite.
May 25 02:32:31.149: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:32:31.192: INFO: namespace: e2e-tests-services-48ll2, resource: bindings, ignored listing per whitelist
May 25 02:32:31.227: INFO: namespace e2e-tests-services-48ll2 deletion completed in 6.08875577s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:10.387 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:32:31.233: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-fstd9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-58a906da-7e95-11e9-802f-027f94874578
STEP: Creating a pod to test consume secrets
May 25 02:32:31.435: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-58a9b4a7-7e95-11e9-802f-027f94874578" in namespace "e2e-tests-projected-fstd9" to be "success or failure"
May 25 02:32:31.439: INFO: Pod "pod-projected-secrets-58a9b4a7-7e95-11e9-802f-027f94874578": Phase="Pending", Reason="", readiness=false. Elapsed: 3.282364ms
May 25 02:32:33.442: INFO: Pod "pod-projected-secrets-58a9b4a7-7e95-11e9-802f-027f94874578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0064433s
STEP: Saw pod success
May 25 02:32:33.442: INFO: Pod "pod-projected-secrets-58a9b4a7-7e95-11e9-802f-027f94874578" satisfied condition "success or failure"
May 25 02:32:33.444: INFO: Trying to get logs from node alex-400-cp1718-vsp2-workere35c6c6a2b pod pod-projected-secrets-58a9b4a7-7e95-11e9-802f-027f94874578 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 25 02:32:33.465: INFO: Waiting for pod pod-projected-secrets-58a9b4a7-7e95-11e9-802f-027f94874578 to disappear
May 25 02:32:33.470: INFO: Pod pod-projected-secrets-58a9b4a7-7e95-11e9-802f-027f94874578 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:32:33.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fstd9" for this suite.
May 25 02:32:39.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:32:39.573: INFO: namespace: e2e-tests-projected-fstd9, resource: bindings, ignored listing per whitelist
May 25 02:32:39.579: INFO: namespace e2e-tests-projected-fstd9 deletion completed in 6.105823959s

• [SLOW TEST:8.347 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 25 02:32:39.582: INFO: >>> kubeConfig: /tmp/kubeconfig-162046071
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-tfckn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0525 02:32:40.795234      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 25 02:32:40.795: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 25 02:32:40.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-tfckn" for this suite.
May 25 02:32:46.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 25 02:32:46.831: INFO: namespace: e2e-tests-gc-tfckn, resource: bindings, ignored listing per whitelist
May 25 02:32:46.876: INFO: namespace e2e-tests-gc-tfckn deletion completed in 6.077000734s

• [SLOW TEST:7.295 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
May 25 02:32:46.877: INFO: Running AfterSuite actions on all nodes
May 25 02:32:46.877: INFO: Running AfterSuite actions on node 1
May 25 02:32:46.877: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 5770.481 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h36m11.808378567s
Test Suite Passed
