I1205 19:29:06.308815      15 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-100404934
I1205 19:29:06.308960      15 e2e.go:224] Starting e2e run "07703534-f8c4-11e8-b559-c27407a18179" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1544038145 - Will randomize all specs
Will run 201 of 1946 specs

Dec  5 19:29:06.470: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
Dec  5 19:29:06.472: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Dec  5 19:29:06.480: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Dec  5 19:29:06.519: INFO: 5 / 5 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Dec  5 19:29:06.519: INFO: expected 5 pod replicas in namespace 'kube-system', 5 are Running and Ready.
Dec  5 19:29:06.519: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Dec  5 19:29:06.527: INFO: e2e test version: v1.13.0
Dec  5 19:29:06.537: INFO: kube-apiserver version: v1.13.0
SSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:29:06.537: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename svcaccounts
Dec  5 19:29:06.602: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Dec  5 19:29:07.127: INFO: created pod pod-service-account-defaultsa
Dec  5 19:29:07.127: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Dec  5 19:29:07.133: INFO: created pod pod-service-account-mountsa
Dec  5 19:29:07.133: INFO: pod pod-service-account-mountsa service account token volume mount: true
Dec  5 19:29:07.142: INFO: created pod pod-service-account-nomountsa
Dec  5 19:29:07.142: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Dec  5 19:29:07.149: INFO: created pod pod-service-account-defaultsa-mountspec
Dec  5 19:29:07.149: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Dec  5 19:29:07.158: INFO: created pod pod-service-account-mountsa-mountspec
Dec  5 19:29:07.158: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Dec  5 19:29:07.165: INFO: created pod pod-service-account-nomountsa-mountspec
Dec  5 19:29:07.165: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Dec  5 19:29:07.174: INFO: created pod pod-service-account-defaultsa-nomountspec
Dec  5 19:29:07.174: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Dec  5 19:29:07.186: INFO: created pod pod-service-account-mountsa-nomountspec
Dec  5 19:29:07.186: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Dec  5 19:29:07.193: INFO: created pod pod-service-account-nomountsa-nomountspec
Dec  5 19:29:07.193: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:29:07.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-grk47" for this suite.
Dec  5 19:29:13.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:29:13.311: INFO: namespace: e2e-tests-svcaccounts-grk47, resource: bindings, ignored listing per whitelist
Dec  5 19:29:13.387: INFO: namespace e2e-tests-svcaccounts-grk47 deletion completed in 6.19039623s

• [SLOW TEST:6.850 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:29:13.388: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  5 19:29:13.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-nwnh6'
Dec  5 19:29:13.849: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  5 19:29:13.850: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Dec  5 19:29:13.853: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-nwnh6'
Dec  5 19:29:13.939: INFO: stderr: ""
Dec  5 19:29:13.939: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:29:13.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nwnh6" for this suite.
Dec  5 19:29:35.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:29:36.059: INFO: namespace: e2e-tests-kubectl-nwnh6, resource: bindings, ignored listing per whitelist
Dec  5 19:29:36.065: INFO: namespace e2e-tests-kubectl-nwnh6 deletion completed in 22.120299665s

• [SLOW TEST:22.678 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:29:36.065: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Dec  5 19:29:36.127: INFO: namespace e2e-tests-kubectl-qczmn
Dec  5 19:29:36.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 create -f - --namespace=e2e-tests-kubectl-qczmn'
Dec  5 19:29:36.391: INFO: stderr: ""
Dec  5 19:29:36.391: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  5 19:29:37.395: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 19:29:37.395: INFO: Found 0 / 1
Dec  5 19:29:38.395: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 19:29:38.395: INFO: Found 0 / 1
Dec  5 19:29:39.395: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 19:29:39.395: INFO: Found 0 / 1
Dec  5 19:29:40.396: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 19:29:40.396: INFO: Found 1 / 1
Dec  5 19:29:40.396: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  5 19:29:40.399: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 19:29:40.399: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  5 19:29:40.399: INFO: wait on redis-master startup in e2e-tests-kubectl-qczmn 
Dec  5 19:29:40.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 logs redis-master-lfvbl redis-master --namespace=e2e-tests-kubectl-qczmn'
Dec  5 19:29:40.505: INFO: stderr: ""
Dec  5 19:29:40.505: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 05 Dec 19:29:38.501 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 05 Dec 19:29:38.501 # Server started, Redis version 3.2.12\n1:M 05 Dec 19:29:38.501 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 05 Dec 19:29:38.501 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Dec  5 19:29:40.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-qczmn'
Dec  5 19:29:40.592: INFO: stderr: ""
Dec  5 19:29:40.592: INFO: stdout: "service/rm2 exposed\n"
Dec  5 19:29:40.598: INFO: Service rm2 in namespace e2e-tests-kubectl-qczmn found.
STEP: exposing service
Dec  5 19:29:42.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-qczmn'
Dec  5 19:29:42.700: INFO: stderr: ""
Dec  5 19:29:42.700: INFO: stdout: "service/rm3 exposed\n"
Dec  5 19:29:42.705: INFO: Service rm3 in namespace e2e-tests-kubectl-qczmn found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:29:44.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qczmn" for this suite.
Dec  5 19:30:08.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:30:08.819: INFO: namespace: e2e-tests-kubectl-qczmn, resource: bindings, ignored listing per whitelist
Dec  5 19:30:08.847: INFO: namespace e2e-tests-kubectl-qczmn deletion completed in 24.125043727s

• [SLOW TEST:32.782 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:30:08.848: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec  5 19:30:08.925: INFO: Waiting up to 5m0s for pod "pod-2d2021eb-f8c4-11e8-b559-c27407a18179" in namespace "e2e-tests-emptydir-cxmpz" to be "success or failure"
Dec  5 19:30:08.930: INFO: Pod "pod-2d2021eb-f8c4-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 5.839011ms
Dec  5 19:30:10.934: INFO: Pod "pod-2d2021eb-f8c4-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009375146s
Dec  5 19:30:12.938: INFO: Pod "pod-2d2021eb-f8c4-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013369909s
STEP: Saw pod success
Dec  5 19:30:12.938: INFO: Pod "pod-2d2021eb-f8c4-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 19:30:12.941: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-2d2021eb-f8c4-11e8-b559-c27407a18179 container test-container: <nil>
STEP: delete the pod
Dec  5 19:30:17.977: INFO: Waiting for pod pod-2d2021eb-f8c4-11e8-b559-c27407a18179 to disappear
Dec  5 19:30:17.980: INFO: Pod pod-2d2021eb-f8c4-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:30:17.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-cxmpz" for this suite.
Dec  5 19:30:23.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:30:24.099: INFO: namespace: e2e-tests-emptydir-cxmpz, resource: bindings, ignored listing per whitelist
Dec  5 19:30:24.154: INFO: namespace e2e-tests-emptydir-cxmpz deletion completed in 6.169851393s

• [SLOW TEST:15.306 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:30:24.154: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Dec  5 19:30:24.215: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Dec  5 19:30:24.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 create -f - --namespace=e2e-tests-kubectl-b76qd'
Dec  5 19:30:24.454: INFO: stderr: ""
Dec  5 19:30:24.454: INFO: stdout: "service/redis-slave created\n"
Dec  5 19:30:24.454: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Dec  5 19:30:24.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 create -f - --namespace=e2e-tests-kubectl-b76qd'
Dec  5 19:30:24.701: INFO: stderr: ""
Dec  5 19:30:24.701: INFO: stdout: "service/redis-master created\n"
Dec  5 19:30:24.701: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Dec  5 19:30:24.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 create -f - --namespace=e2e-tests-kubectl-b76qd'
Dec  5 19:30:24.918: INFO: stderr: ""
Dec  5 19:30:24.918: INFO: stdout: "service/frontend created\n"
Dec  5 19:30:24.919: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Dec  5 19:30:24.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 create -f - --namespace=e2e-tests-kubectl-b76qd'
Dec  5 19:30:25.095: INFO: stderr: ""
Dec  5 19:30:25.095: INFO: stdout: "deployment.extensions/frontend created\n"
Dec  5 19:30:25.095: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec  5 19:30:25.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 create -f - --namespace=e2e-tests-kubectl-b76qd'
Dec  5 19:30:25.361: INFO: stderr: ""
Dec  5 19:30:25.361: INFO: stdout: "deployment.extensions/redis-master created\n"
Dec  5 19:30:25.361: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Dec  5 19:30:25.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 create -f - --namespace=e2e-tests-kubectl-b76qd'
Dec  5 19:30:25.560: INFO: stderr: ""
Dec  5 19:30:25.560: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Dec  5 19:30:25.560: INFO: Waiting for all frontend pods to be Running.
Dec  5 19:30:50.611: INFO: Waiting for frontend to serve content.
Dec  5 19:30:50.629: INFO: Trying to add a new entry to the guestbook.
Dec  5 19:30:50.643: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Dec  5 19:30:50.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-b76qd'
Dec  5 19:30:50.759: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  5 19:30:50.759: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Dec  5 19:30:50.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-b76qd'
Dec  5 19:30:50.867: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  5 19:30:50.867: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec  5 19:30:50.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-b76qd'
Dec  5 19:30:50.957: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  5 19:30:50.957: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec  5 19:30:50.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-b76qd'
Dec  5 19:30:51.036: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  5 19:30:51.036: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec  5 19:30:51.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-b76qd'
Dec  5 19:30:51.115: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  5 19:30:51.115: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec  5 19:30:51.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-b76qd'
Dec  5 19:30:51.209: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  5 19:30:51.209: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:30:51.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-b76qd" for this suite.
Dec  5 19:31:35.229: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:31:35.243: INFO: namespace: e2e-tests-kubectl-b76qd, resource: bindings, ignored listing per whitelist
Dec  5 19:31:35.366: INFO: namespace e2e-tests-kubectl-b76qd deletion completed in 44.153470344s

• [SLOW TEST:71.212 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:31:35.366: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:31:39.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-hq6b6" for this suite.
Dec  5 19:32:19.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:32:19.573: INFO: namespace: e2e-tests-kubelet-test-hq6b6, resource: bindings, ignored listing per whitelist
Dec  5 19:32:19.587: INFO: namespace e2e-tests-kubelet-test-hq6b6 deletion completed in 40.130219284s

• [SLOW TEST:44.221 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:32:19.587: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-7b0d42dd-f8c4-11e8-b559-c27407a18179
STEP: Creating a pod to test consume secrets
Dec  5 19:32:19.667: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7b0df056-f8c4-11e8-b559-c27407a18179" in namespace "e2e-tests-projected-ztqvf" to be "success or failure"
Dec  5 19:32:19.671: INFO: Pod "pod-projected-secrets-7b0df056-f8c4-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 4.187438ms
Dec  5 19:32:21.676: INFO: Pod "pod-projected-secrets-7b0df056-f8c4-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008547194s
Dec  5 19:32:23.680: INFO: Pod "pod-projected-secrets-7b0df056-f8c4-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013047738s
STEP: Saw pod success
Dec  5 19:32:23.680: INFO: Pod "pod-projected-secrets-7b0df056-f8c4-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 19:32:23.684: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-projected-secrets-7b0df056-f8c4-11e8-b559-c27407a18179 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  5 19:32:23.714: INFO: Waiting for pod pod-projected-secrets-7b0df056-f8c4-11e8-b559-c27407a18179 to disappear
Dec  5 19:32:23.717: INFO: Pod pod-projected-secrets-7b0df056-f8c4-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:32:23.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ztqvf" for this suite.
Dec  5 19:32:29.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:32:29.744: INFO: namespace: e2e-tests-projected-ztqvf, resource: bindings, ignored listing per whitelist
Dec  5 19:32:29.835: INFO: namespace e2e-tests-projected-ztqvf deletion completed in 6.113297405s

• [SLOW TEST:10.248 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:32:29.835: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-812bab8b-f8c4-11e8-b559-c27407a18179
STEP: Creating a pod to test consume configMaps
Dec  5 19:32:29.938: INFO: Waiting up to 5m0s for pod "pod-configmaps-812d4676-f8c4-11e8-b559-c27407a18179" in namespace "e2e-tests-configmap-k8fwn" to be "success or failure"
Dec  5 19:32:29.943: INFO: Pod "pod-configmaps-812d4676-f8c4-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 4.639473ms
Dec  5 19:32:31.947: INFO: Pod "pod-configmaps-812d4676-f8c4-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008744636s
Dec  5 19:32:33.951: INFO: Pod "pod-configmaps-812d4676-f8c4-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012976127s
STEP: Saw pod success
Dec  5 19:32:33.951: INFO: Pod "pod-configmaps-812d4676-f8c4-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 19:32:33.955: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-configmaps-812d4676-f8c4-11e8-b559-c27407a18179 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 19:32:33.974: INFO: Waiting for pod pod-configmaps-812d4676-f8c4-11e8-b559-c27407a18179 to disappear
Dec  5 19:32:33.978: INFO: Pod pod-configmaps-812d4676-f8c4-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:32:33.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-k8fwn" for this suite.
Dec  5 19:32:39.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:32:40.023: INFO: namespace: e2e-tests-configmap-k8fwn, resource: bindings, ignored listing per whitelist
Dec  5 19:32:40.107: INFO: namespace e2e-tests-configmap-k8fwn deletion completed in 6.125886033s

• [SLOW TEST:10.272 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:32:40.107: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-ggm54
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  5 19:32:40.166: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  5 19:33:06.255: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.41.19:8080/dial?request=hostName&protocol=udp&host=10.1.41.18&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-ggm54 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 19:33:06.255: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
Dec  5 19:33:06.392: INFO: Waiting for endpoints: map[]
Dec  5 19:33:06.396: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.41.19:8080/dial?request=hostName&protocol=udp&host=10.1.43.9&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-ggm54 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 19:33:06.396: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
Dec  5 19:33:06.510: INFO: Waiting for endpoints: map[]
Dec  5 19:33:06.513: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.41.19:8080/dial?request=hostName&protocol=udp&host=10.1.94.12&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-ggm54 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 19:33:06.513: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
Dec  5 19:33:06.598: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:33:06.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-ggm54" for this suite.
Dec  5 19:33:28.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:33:28.717: INFO: namespace: e2e-tests-pod-network-test-ggm54, resource: bindings, ignored listing per whitelist
Dec  5 19:33:28.729: INFO: namespace e2e-tests-pod-network-test-ggm54 deletion completed in 22.124983487s

• [SLOW TEST:48.622 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:33:28.729: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-a442cfd8-f8c4-11e8-b559-c27407a18179
STEP: Creating a pod to test consume secrets
Dec  5 19:33:28.805: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a44374b2-f8c4-11e8-b559-c27407a18179" in namespace "e2e-tests-projected-zdl9p" to be "success or failure"
Dec  5 19:33:28.809: INFO: Pod "pod-projected-secrets-a44374b2-f8c4-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 3.819081ms
Dec  5 19:33:30.813: INFO: Pod "pod-projected-secrets-a44374b2-f8c4-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008077614s
Dec  5 19:33:32.817: INFO: Pod "pod-projected-secrets-a44374b2-f8c4-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012018195s
Dec  5 19:33:35.251: INFO: Pod "pod-projected-secrets-a44374b2-f8c4-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.445795279s
STEP: Saw pod success
Dec  5 19:33:35.251: INFO: Pod "pod-projected-secrets-a44374b2-f8c4-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 19:33:35.256: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-projected-secrets-a44374b2-f8c4-11e8-b559-c27407a18179 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  5 19:33:35.285: INFO: Waiting for pod pod-projected-secrets-a44374b2-f8c4-11e8-b559-c27407a18179 to disappear
Dec  5 19:33:35.288: INFO: Pod pod-projected-secrets-a44374b2-f8c4-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:33:35.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zdl9p" for this suite.
Dec  5 19:33:41.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:33:41.345: INFO: namespace: e2e-tests-projected-zdl9p, resource: bindings, ignored listing per whitelist
Dec  5 19:33:41.408: INFO: namespace e2e-tests-projected-zdl9p deletion completed in 6.117117186s

• [SLOW TEST:12.680 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:33:41.409: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  5 19:33:41.473: INFO: Waiting up to 5m0s for pod "downward-api-abd08af9-f8c4-11e8-b559-c27407a18179" in namespace "e2e-tests-downward-api-sd9kq" to be "success or failure"
Dec  5 19:33:41.478: INFO: Pod "downward-api-abd08af9-f8c4-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 5.032476ms
Dec  5 19:33:43.482: INFO: Pod "downward-api-abd08af9-f8c4-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009112175s
Dec  5 19:33:45.486: INFO: Pod "downward-api-abd08af9-f8c4-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013190207s
STEP: Saw pod success
Dec  5 19:33:45.486: INFO: Pod "downward-api-abd08af9-f8c4-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 19:33:45.490: INFO: Trying to get logs from node ip-172-31-2-231 pod downward-api-abd08af9-f8c4-11e8-b559-c27407a18179 container dapi-container: <nil>
STEP: delete the pod
Dec  5 19:33:45.537: INFO: Waiting for pod downward-api-abd08af9-f8c4-11e8-b559-c27407a18179 to disappear
Dec  5 19:33:45.540: INFO: Pod downward-api-abd08af9-f8c4-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:33:45.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-sd9kq" for this suite.
Dec  5 19:33:51.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:33:51.643: INFO: namespace: e2e-tests-downward-api-sd9kq, resource: bindings, ignored listing per whitelist
Dec  5 19:33:51.683: INFO: namespace e2e-tests-downward-api-sd9kq deletion completed in 6.139072143s

• [SLOW TEST:10.274 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:33:51.683: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-8mfbt
Dec  5 19:33:55.760: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-8mfbt
STEP: checking the pod's current state and verifying that restartCount is present
Dec  5 19:33:55.763: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:37:56.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-8mfbt" for this suite.
Dec  5 19:38:02.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:38:02.520: INFO: namespace: e2e-tests-container-probe-8mfbt, resource: bindings, ignored listing per whitelist
Dec  5 19:38:02.602: INFO: namespace e2e-tests-container-probe-8mfbt deletion completed in 6.141203355s

• [SLOW TEST:250.919 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:38:02.602: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-47824d14-f8c5-11e8-b559-c27407a18179
STEP: Creating a pod to test consume configMaps
Dec  5 19:38:02.689: INFO: Waiting up to 5m0s for pod "pod-configmaps-4782fc3d-f8c5-11e8-b559-c27407a18179" in namespace "e2e-tests-configmap-h5rgk" to be "success or failure"
Dec  5 19:38:02.692: INFO: Pod "pod-configmaps-4782fc3d-f8c5-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 3.651622ms
Dec  5 19:38:04.697: INFO: Pod "pod-configmaps-4782fc3d-f8c5-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008072842s
STEP: Saw pod success
Dec  5 19:38:04.697: INFO: Pod "pod-configmaps-4782fc3d-f8c5-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 19:38:04.700: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-configmaps-4782fc3d-f8c5-11e8-b559-c27407a18179 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 19:38:04.988: INFO: Waiting for pod pod-configmaps-4782fc3d-f8c5-11e8-b559-c27407a18179 to disappear
Dec  5 19:38:05.295: INFO: Pod pod-configmaps-4782fc3d-f8c5-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:38:05.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-h5rgk" for this suite.
Dec  5 19:38:11.312: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:38:11.355: INFO: namespace: e2e-tests-configmap-h5rgk, resource: bindings, ignored listing per whitelist
Dec  5 19:38:11.416: INFO: namespace e2e-tests-configmap-h5rgk deletion completed in 6.116751606s

• [SLOW TEST:8.814 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:38:11.416: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Dec  5 19:38:11.654: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-100404934 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:38:11.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zbjfk" for this suite.
Dec  5 19:38:17.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:38:17.834: INFO: namespace: e2e-tests-kubectl-zbjfk, resource: bindings, ignored listing per whitelist
Dec  5 19:38:17.837: INFO: namespace e2e-tests-kubectl-zbjfk deletion completed in 6.119630401s

• [SLOW TEST:6.421 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:38:17.837: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-5094e72b-f8c5-11e8-b559-c27407a18179
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-5094e72b-f8c5-11e8-b559-c27407a18179
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:38:21.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-rnqrn" for this suite.
Dec  5 19:38:43.969: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:38:44.043: INFO: namespace: e2e-tests-configmap-rnqrn, resource: bindings, ignored listing per whitelist
Dec  5 19:38:44.098: INFO: namespace e2e-tests-configmap-rnqrn deletion completed in 22.143642464s

• [SLOW TEST:26.262 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:38:44.099: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-605fe7cf-f8c5-11e8-b559-c27407a18179
STEP: Creating a pod to test consume configMaps
Dec  5 19:38:44.406: INFO: Waiting up to 5m0s for pod "pod-configmaps-6060a978-f8c5-11e8-b559-c27407a18179" in namespace "e2e-tests-configmap-xvfsj" to be "success or failure"
Dec  5 19:38:44.410: INFO: Pod "pod-configmaps-6060a978-f8c5-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 4.269495ms
Dec  5 19:38:46.485: INFO: Pod "pod-configmaps-6060a978-f8c5-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.079069009s
Dec  5 19:38:48.489: INFO: Pod "pod-configmaps-6060a978-f8c5-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.083197889s
STEP: Saw pod success
Dec  5 19:38:48.489: INFO: Pod "pod-configmaps-6060a978-f8c5-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 19:38:48.492: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-configmaps-6060a978-f8c5-11e8-b559-c27407a18179 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 19:38:48.512: INFO: Waiting for pod pod-configmaps-6060a978-f8c5-11e8-b559-c27407a18179 to disappear
Dec  5 19:38:48.515: INFO: Pod pod-configmaps-6060a978-f8c5-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:38:48.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-xvfsj" for this suite.
Dec  5 19:38:54.532: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:38:54.673: INFO: namespace: e2e-tests-configmap-xvfsj, resource: bindings, ignored listing per whitelist
Dec  5 19:38:54.692: INFO: namespace e2e-tests-configmap-xvfsj deletion completed in 6.173801111s

• [SLOW TEST:10.594 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:38:54.693: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 19:38:54.758: INFO: Waiting up to 5m0s for pod "downwardapi-volume-668bfc42-f8c5-11e8-b559-c27407a18179" in namespace "e2e-tests-downward-api-g4wpb" to be "success or failure"
Dec  5 19:38:54.763: INFO: Pod "downwardapi-volume-668bfc42-f8c5-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 5.568641ms
Dec  5 19:38:56.768: INFO: Pod "downwardapi-volume-668bfc42-f8c5-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009650813s
STEP: Saw pod success
Dec  5 19:38:56.768: INFO: Pod "downwardapi-volume-668bfc42-f8c5-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 19:38:56.772: INFO: Trying to get logs from node ip-172-31-24-193 pod downwardapi-volume-668bfc42-f8c5-11e8-b559-c27407a18179 container client-container: <nil>
STEP: delete the pod
Dec  5 19:38:56.795: INFO: Waiting for pod downwardapi-volume-668bfc42-f8c5-11e8-b559-c27407a18179 to disappear
Dec  5 19:38:56.800: INFO: Pod downwardapi-volume-668bfc42-f8c5-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:38:56.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-g4wpb" for this suite.
Dec  5 19:39:03.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:39:03.602: INFO: namespace: e2e-tests-downward-api-g4wpb, resource: bindings, ignored listing per whitelist
Dec  5 19:39:03.614: INFO: namespace e2e-tests-downward-api-g4wpb deletion completed in 6.810072299s

• [SLOW TEST:8.921 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:39:03.615: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec  5 19:39:03.724: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:39:08.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-bjfw9" for this suite.
Dec  5 19:39:30.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:39:30.199: INFO: namespace: e2e-tests-init-container-bjfw9, resource: bindings, ignored listing per whitelist
Dec  5 19:39:30.271: INFO: namespace e2e-tests-init-container-bjfw9 deletion completed in 22.121528889s

• [SLOW TEST:26.656 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:39:30.271: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-7bf0650b-f8c5-11e8-b559-c27407a18179
STEP: Creating a pod to test consume secrets
Dec  5 19:39:30.652: INFO: Waiting up to 5m0s for pod "pod-secrets-7bf11f6b-f8c5-11e8-b559-c27407a18179" in namespace "e2e-tests-secrets-cnzlg" to be "success or failure"
Dec  5 19:39:30.657: INFO: Pod "pod-secrets-7bf11f6b-f8c5-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 4.88481ms
Dec  5 19:39:32.661: INFO: Pod "pod-secrets-7bf11f6b-f8c5-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008609235s
Dec  5 19:39:34.665: INFO: Pod "pod-secrets-7bf11f6b-f8c5-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012351429s
STEP: Saw pod success
Dec  5 19:39:34.665: INFO: Pod "pod-secrets-7bf11f6b-f8c5-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 19:39:34.667: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-secrets-7bf11f6b-f8c5-11e8-b559-c27407a18179 container secret-volume-test: <nil>
STEP: delete the pod
Dec  5 19:39:34.827: INFO: Waiting for pod pod-secrets-7bf11f6b-f8c5-11e8-b559-c27407a18179 to disappear
Dec  5 19:39:34.831: INFO: Pod pod-secrets-7bf11f6b-f8c5-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:39:34.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-cnzlg" for this suite.
Dec  5 19:39:41.183: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:39:41.214: INFO: namespace: e2e-tests-secrets-cnzlg, resource: bindings, ignored listing per whitelist
Dec  5 19:39:41.311: INFO: namespace e2e-tests-secrets-cnzlg deletion completed in 6.470852237s

• [SLOW TEST:11.039 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:39:41.311: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Dec  5 19:39:41.368: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 create -f - --namespace=e2e-tests-kubectl-52mf2'
Dec  5 19:39:42.010: INFO: stderr: ""
Dec  5 19:39:42.010: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  5 19:39:43.014: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 19:39:43.014: INFO: Found 0 / 1
Dec  5 19:39:44.014: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 19:39:44.014: INFO: Found 1 / 1
Dec  5 19:39:44.015: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Dec  5 19:39:44.018: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 19:39:44.018: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  5 19:39:44.018: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 patch pod redis-master-2rstj --namespace=e2e-tests-kubectl-52mf2 -p {"metadata":{"annotations":{"x":"y"}}}'
Dec  5 19:39:44.126: INFO: stderr: ""
Dec  5 19:39:44.126: INFO: stdout: "pod/redis-master-2rstj patched\n"
STEP: checking annotations
Dec  5 19:39:44.130: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 19:39:44.130: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:39:44.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-52mf2" for this suite.
Dec  5 19:40:06.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:40:06.182: INFO: namespace: e2e-tests-kubectl-52mf2, resource: bindings, ignored listing per whitelist
Dec  5 19:40:06.344: INFO: namespace e2e-tests-kubectl-52mf2 deletion completed in 22.207549082s

• [SLOW TEST:25.034 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:40:06.344: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 19:40:06.409: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Dec  5 19:40:06.417: INFO: Pod name sample-pod: Found 0 pods out of 1
Dec  5 19:40:11.424: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  5 19:40:11.424: INFO: Creating deployment "test-rolling-update-deployment"
Dec  5 19:40:11.429: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Dec  5 19:40:11.438: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Dec  5 19:40:13.446: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Dec  5 19:40:13.448: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679635611, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679635611, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679635611, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679635611, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-68b55d7bc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  5 19:40:15.453: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  5 19:40:15.462: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-djtqt,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-djtqt/deployments/test-rolling-update-deployment,UID:94373616-f8c5-11e8-b622-12e7eb78a7a2,ResourceVersion:3898,Generation:1,CreationTimestamp:2018-12-05 19:40:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-12-05 19:40:11 +0000 UTC 2018-12-05 19:40:11 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-12-05 19:40:13 +0000 UTC 2018-12-05 19:40:11 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec  5 19:40:15.466: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-djtqt,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-djtqt/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:94394ef7-f8c5-11e8-b622-12e7eb78a7a2,ResourceVersion:3889,Generation:1,CreationTimestamp:2018-12-05 19:40:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 94373616-f8c5-11e8-b622-12e7eb78a7a2 0xc001f6f497 0xc001f6f498}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec  5 19:40:15.466: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Dec  5 19:40:15.466: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-djtqt,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-djtqt/replicasets/test-rolling-update-controller,UID:913a01a9-f8c5-11e8-b622-12e7eb78a7a2,ResourceVersion:3897,Generation:2,CreationTimestamp:2018-12-05 19:40:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 94373616-f8c5-11e8-b622-12e7eb78a7a2 0xc001f6f35f 0xc001f6f370}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  5 19:40:15.469: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-x6zmz" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-x6zmz,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-djtqt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-djtqt/pods/test-rolling-update-deployment-68b55d7bc6-x6zmz,UID:9439fabf-f8c5-11e8-b622-12e7eb78a7a2,ResourceVersion:3888,Generation:0,CreationTimestamp:2018-12-05 19:40:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 94394ef7-f8c5-11e8-b622-12e7eb78a7a2 0xc001f6fdc7 0xc001f6fdc8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-knnpc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-knnpc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-knnpc true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-24-193,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f6fe40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f6fe60}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 19:40:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 19:40:13 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 19:40:13 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 19:40:11 +0000 UTC  }],Message:,Reason:,HostIP:172.31.24.193,PodIP:10.1.41.30,StartTime:2018-12-05 19:40:11 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-12-05 19:40:12 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://f8141563be9b584fe66b06b40e09fc0be92258954824b9da49ed2ac072c768cd}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:40:15.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-djtqt" for this suite.
Dec  5 19:40:21.484: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:40:21.546: INFO: namespace: e2e-tests-deployment-djtqt, resource: bindings, ignored listing per whitelist
Dec  5 19:40:21.588: INFO: namespace e2e-tests-deployment-djtqt deletion completed in 6.115807131s

• [SLOW TEST:15.244 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:40:21.588: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-9a571be7-f8c5-11e8-b559-c27407a18179
STEP: Creating a pod to test consume secrets
Dec  5 19:40:21.691: INFO: Waiting up to 5m0s for pod "pod-secrets-9a5d0fe4-f8c5-11e8-b559-c27407a18179" in namespace "e2e-tests-secrets-xbfq9" to be "success or failure"
Dec  5 19:40:21.695: INFO: Pod "pod-secrets-9a5d0fe4-f8c5-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 4.444849ms
Dec  5 19:40:23.701: INFO: Pod "pod-secrets-9a5d0fe4-f8c5-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01000359s
Dec  5 19:40:25.705: INFO: Pod "pod-secrets-9a5d0fe4-f8c5-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014135451s
STEP: Saw pod success
Dec  5 19:40:25.705: INFO: Pod "pod-secrets-9a5d0fe4-f8c5-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 19:40:25.709: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-secrets-9a5d0fe4-f8c5-11e8-b559-c27407a18179 container secret-volume-test: <nil>
STEP: delete the pod
Dec  5 19:40:25.729: INFO: Waiting for pod pod-secrets-9a5d0fe4-f8c5-11e8-b559-c27407a18179 to disappear
Dec  5 19:40:25.732: INFO: Pod pod-secrets-9a5d0fe4-f8c5-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:40:25.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-xbfq9" for this suite.
Dec  5 19:40:31.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:40:31.796: INFO: namespace: e2e-tests-secrets-xbfq9, resource: bindings, ignored listing per whitelist
Dec  5 19:40:31.860: INFO: namespace e2e-tests-secrets-xbfq9 deletion completed in 6.125027201s
STEP: Destroying namespace "e2e-tests-secret-namespace-4dbqd" for this suite.
Dec  5 19:40:37.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:40:37.975: INFO: namespace: e2e-tests-secret-namespace-4dbqd, resource: bindings, ignored listing per whitelist
Dec  5 19:40:37.988: INFO: namespace e2e-tests-secret-namespace-4dbqd deletion completed in 6.127734159s

• [SLOW TEST:16.400 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:40:37.988: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Dec  5 19:40:42.592: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-a46c67fb-f8c5-11e8-b559-c27407a18179", GenerateName:"", Namespace:"e2e-tests-pods-pgsm7", SelfLink:"/api/v1/namespaces/e2e-tests-pods-pgsm7/pods/pod-submit-remove-a46c67fb-f8c5-11e8-b559-c27407a18179", UID:"a4650314-f8c5-11e8-b622-12e7eb78a7a2", ResourceVersion:"4021", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63679635638, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"561388177"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-cjghj", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0014ff780), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-cjghj", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001b5e948), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-31-24-193", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc000a410e0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001b5e990)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001b5e9b0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001b5e9b8)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679635638, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679635640, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679635640, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679635638, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.31.24.193", PodIP:"10.1.41.32", StartTime:(*v1.Time)(0xc00179e4c0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc00179e4e0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd", ContainerID:"docker://6f05762228789783189b7331cc55abce44493d796fe9dc764a9e1f9123fac8b1"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Dec  5 19:40:47.606: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:40:47.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-pgsm7" for this suite.
Dec  5 19:40:53.626: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:40:53.723: INFO: namespace: e2e-tests-pods-pgsm7, resource: bindings, ignored listing per whitelist
Dec  5 19:40:53.731: INFO: namespace e2e-tests-pods-pgsm7 deletion completed in 6.117419628s

• [SLOW TEST:15.743 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:40:53.731: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:41:53.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-cswsc" for this suite.
Dec  5 19:42:15.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:42:16.273: INFO: namespace: e2e-tests-container-probe-cswsc, resource: bindings, ignored listing per whitelist
Dec  5 19:42:16.297: INFO: namespace e2e-tests-container-probe-cswsc deletion completed in 22.467386186s

• [SLOW TEST:82.565 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:42:16.297: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-42gg9/secret-test-deb67b4b-f8c5-11e8-b559-c27407a18179
STEP: Creating a pod to test consume secrets
Dec  5 19:42:16.365: INFO: Waiting up to 5m0s for pod "pod-configmaps-deb70efd-f8c5-11e8-b559-c27407a18179" in namespace "e2e-tests-secrets-42gg9" to be "success or failure"
Dec  5 19:42:16.370: INFO: Pod "pod-configmaps-deb70efd-f8c5-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 5.102742ms
Dec  5 19:42:18.374: INFO: Pod "pod-configmaps-deb70efd-f8c5-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009169077s
STEP: Saw pod success
Dec  5 19:42:18.374: INFO: Pod "pod-configmaps-deb70efd-f8c5-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 19:42:18.378: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-configmaps-deb70efd-f8c5-11e8-b559-c27407a18179 container env-test: <nil>
STEP: delete the pod
Dec  5 19:42:18.398: INFO: Waiting for pod pod-configmaps-deb70efd-f8c5-11e8-b559-c27407a18179 to disappear
Dec  5 19:42:18.401: INFO: Pod pod-configmaps-deb70efd-f8c5-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:42:18.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-42gg9" for this suite.
Dec  5 19:42:24.420: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:42:24.519: INFO: namespace: e2e-tests-secrets-42gg9, resource: bindings, ignored listing per whitelist
Dec  5 19:42:24.525: INFO: namespace e2e-tests-secrets-42gg9 deletion completed in 6.121036202s

• [SLOW TEST:8.229 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:42:24.526: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec  5 19:42:29.164: INFO: Successfully updated pod "pod-update-activedeadlineseconds-e3a5e3be-f8c5-11e8-b559-c27407a18179"
Dec  5 19:42:29.164: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-e3a5e3be-f8c5-11e8-b559-c27407a18179" in namespace "e2e-tests-pods-bzwbs" to be "terminated due to deadline exceeded"
Dec  5 19:42:29.168: INFO: Pod "pod-update-activedeadlineseconds-e3a5e3be-f8c5-11e8-b559-c27407a18179": Phase="Running", Reason="", readiness=true. Elapsed: 3.140262ms
Dec  5 19:42:31.171: INFO: Pod "pod-update-activedeadlineseconds-e3a5e3be-f8c5-11e8-b559-c27407a18179": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.006921873s
Dec  5 19:42:31.171: INFO: Pod "pod-update-activedeadlineseconds-e3a5e3be-f8c5-11e8-b559-c27407a18179" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:42:31.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-bzwbs" for this suite.
Dec  5 19:42:37.594: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:42:37.700: INFO: namespace: e2e-tests-pods-bzwbs, resource: bindings, ignored listing per whitelist
Dec  5 19:42:37.773: INFO: namespace e2e-tests-pods-bzwbs deletion completed in 6.597924822s

• [SLOW TEST:13.247 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:42:37.773: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:42:37.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-sr2gs" for this suite.
Dec  5 19:42:59.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:42:59.930: INFO: namespace: e2e-tests-pods-sr2gs, resource: bindings, ignored listing per whitelist
Dec  5 19:42:59.993: INFO: namespace e2e-tests-pods-sr2gs deletion completed in 22.14817667s

• [SLOW TEST:22.220 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:42:59.993: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 19:43:00.087: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f8c5d6c7-f8c5-11e8-b559-c27407a18179" in namespace "e2e-tests-projected-d2f24" to be "success or failure"
Dec  5 19:43:00.093: INFO: Pod "downwardapi-volume-f8c5d6c7-f8c5-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 5.608363ms
Dec  5 19:43:02.262: INFO: Pod "downwardapi-volume-f8c5d6c7-f8c5-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.175249799s
Dec  5 19:43:04.267: INFO: Pod "downwardapi-volume-f8c5d6c7-f8c5-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.179401265s
STEP: Saw pod success
Dec  5 19:43:04.267: INFO: Pod "downwardapi-volume-f8c5d6c7-f8c5-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 19:43:04.270: INFO: Trying to get logs from node ip-172-31-24-193 pod downwardapi-volume-f8c5d6c7-f8c5-11e8-b559-c27407a18179 container client-container: <nil>
STEP: delete the pod
Dec  5 19:43:04.544: INFO: Waiting for pod downwardapi-volume-f8c5d6c7-f8c5-11e8-b559-c27407a18179 to disappear
Dec  5 19:43:04.547: INFO: Pod downwardapi-volume-f8c5d6c7-f8c5-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:43:04.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-d2f24" for this suite.
Dec  5 19:43:10.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:43:10.598: INFO: namespace: e2e-tests-projected-d2f24, resource: bindings, ignored listing per whitelist
Dec  5 19:43:10.668: INFO: namespace e2e-tests-projected-d2f24 deletion completed in 6.118135811s

• [SLOW TEST:10.676 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:43:10.669: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Dec  5 19:43:10.733: INFO: Waiting up to 5m0s for pod "client-containers-ff1ebd90-f8c5-11e8-b559-c27407a18179" in namespace "e2e-tests-containers-mc7tm" to be "success or failure"
Dec  5 19:43:10.737: INFO: Pod "client-containers-ff1ebd90-f8c5-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 4.141634ms
Dec  5 19:43:12.742: INFO: Pod "client-containers-ff1ebd90-f8c5-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00829106s
Dec  5 19:43:14.746: INFO: Pod "client-containers-ff1ebd90-f8c5-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012617697s
STEP: Saw pod success
Dec  5 19:43:14.746: INFO: Pod "client-containers-ff1ebd90-f8c5-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 19:43:14.749: INFO: Trying to get logs from node ip-172-31-24-193 pod client-containers-ff1ebd90-f8c5-11e8-b559-c27407a18179 container test-container: <nil>
STEP: delete the pod
Dec  5 19:43:14.776: INFO: Waiting for pod client-containers-ff1ebd90-f8c5-11e8-b559-c27407a18179 to disappear
Dec  5 19:43:14.780: INFO: Pod client-containers-ff1ebd90-f8c5-11e8-b559-c27407a18179 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:43:14.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-mc7tm" for this suite.
Dec  5 19:43:20.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:43:20.852: INFO: namespace: e2e-tests-containers-mc7tm, resource: bindings, ignored listing per whitelist
Dec  5 19:43:20.902: INFO: namespace e2e-tests-containers-mc7tm deletion completed in 6.118057464s

• [SLOW TEST:10.233 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:43:20.902: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-0539e065-f8c6-11e8-b559-c27407a18179
STEP: Creating a pod to test consume configMaps
Dec  5 19:43:20.981: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-053aa170-f8c6-11e8-b559-c27407a18179" in namespace "e2e-tests-projected-8qh6f" to be "success or failure"
Dec  5 19:43:20.986: INFO: Pod "pod-projected-configmaps-053aa170-f8c6-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 4.954059ms
Dec  5 19:43:22.994: INFO: Pod "pod-projected-configmaps-053aa170-f8c6-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012594138s
STEP: Saw pod success
Dec  5 19:43:22.994: INFO: Pod "pod-projected-configmaps-053aa170-f8c6-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 19:43:22.998: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-projected-configmaps-053aa170-f8c6-11e8-b559-c27407a18179 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 19:43:23.018: INFO: Waiting for pod pod-projected-configmaps-053aa170-f8c6-11e8-b559-c27407a18179 to disappear
Dec  5 19:43:23.021: INFO: Pod pod-projected-configmaps-053aa170-f8c6-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:43:23.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8qh6f" for this suite.
Dec  5 19:43:29.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:43:29.105: INFO: namespace: e2e-tests-projected-8qh6f, resource: bindings, ignored listing per whitelist
Dec  5 19:43:29.141: INFO: namespace e2e-tests-projected-8qh6f deletion completed in 6.116349008s

• [SLOW TEST:8.239 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:43:29.141: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-ht5g6
Dec  5 19:43:33.217: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-ht5g6
STEP: checking the pod's current state and verifying that restartCount is present
Dec  5 19:43:33.221: INFO: Initial restart count of pod liveness-http is 0
Dec  5 19:43:45.375: INFO: Restart count of pod e2e-tests-container-probe-ht5g6/liveness-http is now 1 (12.153792237s elapsed)
Dec  5 19:44:05.416: INFO: Restart count of pod e2e-tests-container-probe-ht5g6/liveness-http is now 2 (32.194777144s elapsed)
Dec  5 19:44:25.665: INFO: Restart count of pod e2e-tests-container-probe-ht5g6/liveness-http is now 3 (52.443911496s elapsed)
Dec  5 19:44:45.715: INFO: Restart count of pod e2e-tests-container-probe-ht5g6/liveness-http is now 4 (1m12.494615455s elapsed)
Dec  5 19:45:54.433: INFO: Restart count of pod e2e-tests-container-probe-ht5g6/liveness-http is now 5 (2m21.211697449s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:45:54.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-ht5g6" for this suite.
Dec  5 19:46:00.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:46:00.523: INFO: namespace: e2e-tests-container-probe-ht5g6, resource: bindings, ignored listing per whitelist
Dec  5 19:46:00.584: INFO: namespace e2e-tests-container-probe-ht5g6 deletion completed in 6.132916581s

• [SLOW TEST:151.443 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:46:00.584: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 19:46:00.656: INFO: (0) /api/v1/nodes/ip-172-31-2-231/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 7.57197ms)
Dec  5 19:46:00.660: INFO: (1) /api/v1/nodes/ip-172-31-2-231/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.006892ms)
Dec  5 19:46:00.664: INFO: (2) /api/v1/nodes/ip-172-31-2-231/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.860356ms)
Dec  5 19:46:00.668: INFO: (3) /api/v1/nodes/ip-172-31-2-231/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.81852ms)
Dec  5 19:46:00.672: INFO: (4) /api/v1/nodes/ip-172-31-2-231/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.065452ms)
Dec  5 19:46:00.676: INFO: (5) /api/v1/nodes/ip-172-31-2-231/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.978484ms)
Dec  5 19:46:00.679: INFO: (6) /api/v1/nodes/ip-172-31-2-231/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.805741ms)
Dec  5 19:46:00.684: INFO: (7) /api/v1/nodes/ip-172-31-2-231/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.937475ms)
Dec  5 19:46:00.689: INFO: (8) /api/v1/nodes/ip-172-31-2-231/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.251044ms)
Dec  5 19:46:00.693: INFO: (9) /api/v1/nodes/ip-172-31-2-231/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.909261ms)
Dec  5 19:46:00.697: INFO: (10) /api/v1/nodes/ip-172-31-2-231/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.922884ms)
Dec  5 19:46:00.700: INFO: (11) /api/v1/nodes/ip-172-31-2-231/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.729942ms)
Dec  5 19:46:00.704: INFO: (12) /api/v1/nodes/ip-172-31-2-231/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.012476ms)
Dec  5 19:46:00.709: INFO: (13) /api/v1/nodes/ip-172-31-2-231/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.476407ms)
Dec  5 19:46:00.713: INFO: (14) /api/v1/nodes/ip-172-31-2-231/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.75429ms)
Dec  5 19:46:00.717: INFO: (15) /api/v1/nodes/ip-172-31-2-231/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.889607ms)
Dec  5 19:46:00.720: INFO: (16) /api/v1/nodes/ip-172-31-2-231/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.729235ms)
Dec  5 19:46:00.724: INFO: (17) /api/v1/nodes/ip-172-31-2-231/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.799886ms)
Dec  5 19:46:00.728: INFO: (18) /api/v1/nodes/ip-172-31-2-231/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.824861ms)
Dec  5 19:46:00.732: INFO: (19) /api/v1/nodes/ip-172-31-2-231/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.643844ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:46:00.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-2w5g7" for this suite.
Dec  5 19:46:06.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:46:06.766: INFO: namespace: e2e-tests-proxy-2w5g7, resource: bindings, ignored listing per whitelist
Dec  5 19:46:06.855: INFO: namespace e2e-tests-proxy-2w5g7 deletion completed in 6.118771903s

• [SLOW TEST:6.270 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:46:06.855: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 19:46:26.991: INFO: Container started at 2018-12-05 19:46:08 +0000 UTC, pod became ready at 2018-12-05 19:46:26 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:46:26.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-cgrv8" for this suite.
Dec  5 19:46:51.007: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:46:51.183: INFO: namespace: e2e-tests-container-probe-cgrv8, resource: bindings, ignored listing per whitelist
Dec  5 19:46:51.195: INFO: namespace e2e-tests-container-probe-cgrv8 deletion completed in 24.200897504s

• [SLOW TEST:44.341 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:46:51.195: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-829169a6-f8c6-11e8-b559-c27407a18179
STEP: Creating a pod to test consume secrets
Dec  5 19:46:51.269: INFO: Waiting up to 5m0s for pod "pod-secrets-82920882-f8c6-11e8-b559-c27407a18179" in namespace "e2e-tests-secrets-2lsgk" to be "success or failure"
Dec  5 19:46:51.273: INFO: Pod "pod-secrets-82920882-f8c6-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 4.439481ms
Dec  5 19:46:53.277: INFO: Pod "pod-secrets-82920882-f8c6-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008386201s
Dec  5 19:46:55.281: INFO: Pod "pod-secrets-82920882-f8c6-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01243991s
STEP: Saw pod success
Dec  5 19:46:55.281: INFO: Pod "pod-secrets-82920882-f8c6-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 19:46:55.285: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-secrets-82920882-f8c6-11e8-b559-c27407a18179 container secret-volume-test: <nil>
STEP: delete the pod
Dec  5 19:46:55.305: INFO: Waiting for pod pod-secrets-82920882-f8c6-11e8-b559-c27407a18179 to disappear
Dec  5 19:46:55.308: INFO: Pod pod-secrets-82920882-f8c6-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:46:55.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-2lsgk" for this suite.
Dec  5 19:47:01.325: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:47:01.382: INFO: namespace: e2e-tests-secrets-2lsgk, resource: bindings, ignored listing per whitelist
Dec  5 19:47:01.438: INFO: namespace e2e-tests-secrets-2lsgk deletion completed in 6.126060299s

• [SLOW TEST:10.242 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:47:01.438: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 19:47:02.062: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8900d465-f8c6-11e8-b559-c27407a18179" in namespace "e2e-tests-downward-api-fkskm" to be "success or failure"
Dec  5 19:47:02.068: INFO: Pod "downwardapi-volume-8900d465-f8c6-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 5.346607ms
Dec  5 19:47:04.072: INFO: Pod "downwardapi-volume-8900d465-f8c6-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009620721s
STEP: Saw pod success
Dec  5 19:47:04.072: INFO: Pod "downwardapi-volume-8900d465-f8c6-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 19:47:04.075: INFO: Trying to get logs from node ip-172-31-24-193 pod downwardapi-volume-8900d465-f8c6-11e8-b559-c27407a18179 container client-container: <nil>
STEP: delete the pod
Dec  5 19:47:04.095: INFO: Waiting for pod downwardapi-volume-8900d465-f8c6-11e8-b559-c27407a18179 to disappear
Dec  5 19:47:04.098: INFO: Pod downwardapi-volume-8900d465-f8c6-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:47:04.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-fkskm" for this suite.
Dec  5 19:47:10.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:47:10.206: INFO: namespace: e2e-tests-downward-api-fkskm, resource: bindings, ignored listing per whitelist
Dec  5 19:47:10.220: INFO: namespace e2e-tests-downward-api-fkskm deletion completed in 6.118847156s

• [SLOW TEST:8.783 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:47:10.221: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1205 19:47:16.492501      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  5 19:47:16.492: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:47:16.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-d58vt" for this suite.
Dec  5 19:47:22.508: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:47:22.599: INFO: namespace: e2e-tests-gc-d58vt, resource: bindings, ignored listing per whitelist
Dec  5 19:47:22.619: INFO: namespace e2e-tests-gc-d58vt deletion completed in 6.124008141s

• [SLOW TEST:12.399 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:47:22.619: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 19:47:22.749: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Dec  5 19:47:22.757: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-dx8mr/daemonsets","resourceVersion":"5186"},"items":null}

Dec  5 19:47:22.760: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-dx8mr/pods","resourceVersion":"5186"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:47:22.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-dx8mr" for this suite.
Dec  5 19:47:52.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:47:52.961: INFO: namespace: e2e-tests-daemonsets-dx8mr, resource: bindings, ignored listing per whitelist
Dec  5 19:47:52.967: INFO: namespace e2e-tests-daemonsets-dx8mr deletion completed in 30.191374142s

S [SKIPPING] [30.347 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Dec  5 19:47:22.749: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:47:52.967: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  5 19:47:53.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-mr7gw'
Dec  5 19:47:53.121: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  5 19:47:53.121: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Dec  5 19:47:55.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-mr7gw'
Dec  5 19:47:55.226: INFO: stderr: ""
Dec  5 19:47:55.226: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:47:55.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mr7gw" for this suite.
Dec  5 19:48:01.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:48:01.415: INFO: namespace: e2e-tests-kubectl-mr7gw, resource: bindings, ignored listing per whitelist
Dec  5 19:48:01.491: INFO: namespace e2e-tests-kubectl-mr7gw deletion completed in 6.261796645s

• [SLOW TEST:8.525 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:48:01.492: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec  5 19:48:06.115: INFO: Successfully updated pod "annotationupdateac7add09-f8c6-11e8-b559-c27407a18179"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:48:08.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bkrvw" for this suite.
Dec  5 19:48:30.148: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:48:30.226: INFO: namespace: e2e-tests-projected-bkrvw, resource: bindings, ignored listing per whitelist
Dec  5 19:48:30.275: INFO: namespace e2e-tests-projected-bkrvw deletion completed in 22.138501981s

• [SLOW TEST:28.784 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:48:30.276: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-qt79b.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-qt79b.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-qt79b.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-qt79b.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-qt79b.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-qt79b.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  5 19:48:46.425: INFO: DNS probes using e2e-tests-dns-qt79b/dns-test-bd9e9170-f8c6-11e8-b559-c27407a18179 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:48:46.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-qt79b" for this suite.
Dec  5 19:48:52.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:48:52.489: INFO: namespace: e2e-tests-dns-qt79b, resource: bindings, ignored listing per whitelist
Dec  5 19:48:52.561: INFO: namespace e2e-tests-dns-qt79b deletion completed in 6.116960008s

• [SLOW TEST:22.286 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:48:52.562: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 19:48:52.643: INFO: Waiting up to 5m0s for pod "downwardapi-volume-caea098c-f8c6-11e8-b559-c27407a18179" in namespace "e2e-tests-downward-api-zjm62" to be "success or failure"
Dec  5 19:48:52.650: INFO: Pod "downwardapi-volume-caea098c-f8c6-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 6.883022ms
Dec  5 19:48:54.654: INFO: Pod "downwardapi-volume-caea098c-f8c6-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010411018s
STEP: Saw pod success
Dec  5 19:48:54.654: INFO: Pod "downwardapi-volume-caea098c-f8c6-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 19:48:54.657: INFO: Trying to get logs from node ip-172-31-24-193 pod downwardapi-volume-caea098c-f8c6-11e8-b559-c27407a18179 container client-container: <nil>
STEP: delete the pod
Dec  5 19:48:54.679: INFO: Waiting for pod downwardapi-volume-caea098c-f8c6-11e8-b559-c27407a18179 to disappear
Dec  5 19:48:54.681: INFO: Pod downwardapi-volume-caea098c-f8c6-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:48:54.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-zjm62" for this suite.
Dec  5 19:49:00.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:49:00.735: INFO: namespace: e2e-tests-downward-api-zjm62, resource: bindings, ignored listing per whitelist
Dec  5 19:49:00.786: INFO: namespace e2e-tests-downward-api-zjm62 deletion completed in 6.100920819s

• [SLOW TEST:8.224 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:49:00.786: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Dec  5 19:49:00.847: INFO: Waiting up to 5m0s for pod "var-expansion-cfce0d22-f8c6-11e8-b559-c27407a18179" in namespace "e2e-tests-var-expansion-qxb2b" to be "success or failure"
Dec  5 19:49:00.849: INFO: Pod "var-expansion-cfce0d22-f8c6-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.645067ms
Dec  5 19:49:02.858: INFO: Pod "var-expansion-cfce0d22-f8c6-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011208663s
Dec  5 19:49:04.862: INFO: Pod "var-expansion-cfce0d22-f8c6-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014829051s
STEP: Saw pod success
Dec  5 19:49:04.862: INFO: Pod "var-expansion-cfce0d22-f8c6-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 19:49:04.864: INFO: Trying to get logs from node ip-172-31-24-193 pod var-expansion-cfce0d22-f8c6-11e8-b559-c27407a18179 container dapi-container: <nil>
STEP: delete the pod
Dec  5 19:49:04.881: INFO: Waiting for pod var-expansion-cfce0d22-f8c6-11e8-b559-c27407a18179 to disappear
Dec  5 19:49:04.883: INFO: Pod var-expansion-cfce0d22-f8c6-11e8-b559-c27407a18179 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:49:04.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-qxb2b" for this suite.
Dec  5 19:49:10.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:49:11.008: INFO: namespace: e2e-tests-var-expansion-qxb2b, resource: bindings, ignored listing per whitelist
Dec  5 19:49:11.048: INFO: namespace e2e-tests-var-expansion-qxb2b deletion completed in 6.161877165s

• [SLOW TEST:10.262 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:49:11.048: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-ss2r
STEP: Creating a pod to test atomic-volume-subpath
Dec  5 19:49:11.116: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-ss2r" in namespace "e2e-tests-subpath-nvtx6" to be "success or failure"
Dec  5 19:49:11.120: INFO: Pod "pod-subpath-test-downwardapi-ss2r": Phase="Pending", Reason="", readiness=false. Elapsed: 3.165149ms
Dec  5 19:49:13.123: INFO: Pod "pod-subpath-test-downwardapi-ss2r": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006933693s
Dec  5 19:49:15.127: INFO: Pod "pod-subpath-test-downwardapi-ss2r": Phase="Running", Reason="", readiness=false. Elapsed: 4.010827551s
Dec  5 19:49:17.131: INFO: Pod "pod-subpath-test-downwardapi-ss2r": Phase="Running", Reason="", readiness=false. Elapsed: 6.014594326s
Dec  5 19:49:19.134: INFO: Pod "pod-subpath-test-downwardapi-ss2r": Phase="Running", Reason="", readiness=false. Elapsed: 8.01804264s
Dec  5 19:49:21.138: INFO: Pod "pod-subpath-test-downwardapi-ss2r": Phase="Running", Reason="", readiness=false. Elapsed: 10.021401546s
Dec  5 19:49:23.142: INFO: Pod "pod-subpath-test-downwardapi-ss2r": Phase="Running", Reason="", readiness=false. Elapsed: 12.025927613s
Dec  5 19:49:25.146: INFO: Pod "pod-subpath-test-downwardapi-ss2r": Phase="Running", Reason="", readiness=false. Elapsed: 14.029543113s
Dec  5 19:49:27.150: INFO: Pod "pod-subpath-test-downwardapi-ss2r": Phase="Running", Reason="", readiness=false. Elapsed: 16.033303604s
Dec  5 19:49:29.153: INFO: Pod "pod-subpath-test-downwardapi-ss2r": Phase="Running", Reason="", readiness=false. Elapsed: 18.036935258s
Dec  5 19:49:31.157: INFO: Pod "pod-subpath-test-downwardapi-ss2r": Phase="Running", Reason="", readiness=false. Elapsed: 20.040718518s
Dec  5 19:49:33.161: INFO: Pod "pod-subpath-test-downwardapi-ss2r": Phase="Running", Reason="", readiness=false. Elapsed: 22.04464789s
Dec  5 19:49:35.165: INFO: Pod "pod-subpath-test-downwardapi-ss2r": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.048514942s
STEP: Saw pod success
Dec  5 19:49:35.165: INFO: Pod "pod-subpath-test-downwardapi-ss2r" satisfied condition "success or failure"
Dec  5 19:49:35.168: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-subpath-test-downwardapi-ss2r container test-container-subpath-downwardapi-ss2r: <nil>
STEP: delete the pod
Dec  5 19:49:35.187: INFO: Waiting for pod pod-subpath-test-downwardapi-ss2r to disappear
Dec  5 19:49:35.190: INFO: Pod pod-subpath-test-downwardapi-ss2r no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-ss2r
Dec  5 19:49:35.190: INFO: Deleting pod "pod-subpath-test-downwardapi-ss2r" in namespace "e2e-tests-subpath-nvtx6"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:49:35.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-nvtx6" for this suite.
Dec  5 19:49:41.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:49:41.245: INFO: namespace: e2e-tests-subpath-nvtx6, resource: bindings, ignored listing per whitelist
Dec  5 19:49:41.357: INFO: namespace e2e-tests-subpath-nvtx6 deletion completed in 6.16041887s

• [SLOW TEST:30.308 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:49:41.357: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:49:43.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-h5w7w" for this suite.
Dec  5 19:49:49.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:49:49.579: INFO: namespace: e2e-tests-emptydir-wrapper-h5w7w, resource: bindings, ignored listing per whitelist
Dec  5 19:49:49.588: INFO: namespace e2e-tests-emptydir-wrapper-h5w7w deletion completed in 6.100776412s

• [SLOW TEST:8.231 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:49:49.588: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-ece43988-f8c6-11e8-b559-c27407a18179
STEP: Creating a pod to test consume secrets
Dec  5 19:49:49.650: INFO: Waiting up to 5m0s for pod "pod-secrets-ece4cf79-f8c6-11e8-b559-c27407a18179" in namespace "e2e-tests-secrets-fs2cm" to be "success or failure"
Dec  5 19:49:49.652: INFO: Pod "pod-secrets-ece4cf79-f8c6-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.72587ms
Dec  5 19:49:51.656: INFO: Pod "pod-secrets-ece4cf79-f8c6-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00614573s
STEP: Saw pod success
Dec  5 19:49:51.656: INFO: Pod "pod-secrets-ece4cf79-f8c6-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 19:49:51.659: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-secrets-ece4cf79-f8c6-11e8-b559-c27407a18179 container secret-volume-test: <nil>
STEP: delete the pod
Dec  5 19:49:51.675: INFO: Waiting for pod pod-secrets-ece4cf79-f8c6-11e8-b559-c27407a18179 to disappear
Dec  5 19:49:51.678: INFO: Pod pod-secrets-ece4cf79-f8c6-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:49:51.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-fs2cm" for this suite.
Dec  5 19:49:57.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:49:57.918: INFO: namespace: e2e-tests-secrets-fs2cm, resource: bindings, ignored listing per whitelist
Dec  5 19:49:57.980: INFO: namespace e2e-tests-secrets-fs2cm deletion completed in 6.299694974s

• [SLOW TEST:8.392 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:49:57.980: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-gqjmn
Dec  5 19:50:02.092: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-gqjmn
STEP: checking the pod's current state and verifying that restartCount is present
Dec  5 19:50:02.095: INFO: Initial restart count of pod liveness-exec is 0
Dec  5 19:50:56.215: INFO: Restart count of pod e2e-tests-container-probe-gqjmn/liveness-exec is now 1 (54.119602833s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:50:56.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-gqjmn" for this suite.
Dec  5 19:51:02.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:51:02.308: INFO: namespace: e2e-tests-container-probe-gqjmn, resource: bindings, ignored listing per whitelist
Dec  5 19:51:02.339: INFO: namespace e2e-tests-container-probe-gqjmn deletion completed in 6.111020391s

• [SLOW TEST:64.358 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:51:02.339: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-v5v6l/configmap-test-184670ff-f8c7-11e8-b559-c27407a18179
STEP: Creating a pod to test consume configMaps
Dec  5 19:51:02.445: INFO: Waiting up to 5m0s for pod "pod-configmaps-1847fb64-f8c7-11e8-b559-c27407a18179" in namespace "e2e-tests-configmap-v5v6l" to be "success or failure"
Dec  5 19:51:02.449: INFO: Pod "pod-configmaps-1847fb64-f8c7-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 3.562226ms
Dec  5 19:51:04.452: INFO: Pod "pod-configmaps-1847fb64-f8c7-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00718417s
STEP: Saw pod success
Dec  5 19:51:04.452: INFO: Pod "pod-configmaps-1847fb64-f8c7-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 19:51:04.455: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-configmaps-1847fb64-f8c7-11e8-b559-c27407a18179 container env-test: <nil>
STEP: delete the pod
Dec  5 19:51:04.472: INFO: Waiting for pod pod-configmaps-1847fb64-f8c7-11e8-b559-c27407a18179 to disappear
Dec  5 19:51:04.475: INFO: Pod pod-configmaps-1847fb64-f8c7-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:51:04.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-v5v6l" for this suite.
Dec  5 19:51:10.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:51:10.524: INFO: namespace: e2e-tests-configmap-v5v6l, resource: bindings, ignored listing per whitelist
Dec  5 19:51:10.628: INFO: namespace e2e-tests-configmap-v5v6l deletion completed in 6.145443483s

• [SLOW TEST:8.288 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:51:10.628: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Dec  5 19:51:10.690: INFO: Waiting up to 5m0s for pod "var-expansion-1d329e24-f8c7-11e8-b559-c27407a18179" in namespace "e2e-tests-var-expansion-j8sjj" to be "success or failure"
Dec  5 19:51:10.693: INFO: Pod "var-expansion-1d329e24-f8c7-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 3.620915ms
Dec  5 19:51:12.697: INFO: Pod "var-expansion-1d329e24-f8c7-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00709532s
Dec  5 19:51:14.700: INFO: Pod "var-expansion-1d329e24-f8c7-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010764242s
STEP: Saw pod success
Dec  5 19:51:14.700: INFO: Pod "var-expansion-1d329e24-f8c7-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 19:51:14.704: INFO: Trying to get logs from node ip-172-31-24-193 pod var-expansion-1d329e24-f8c7-11e8-b559-c27407a18179 container dapi-container: <nil>
STEP: delete the pod
Dec  5 19:51:14.721: INFO: Waiting for pod var-expansion-1d329e24-f8c7-11e8-b559-c27407a18179 to disappear
Dec  5 19:51:14.724: INFO: Pod var-expansion-1d329e24-f8c7-11e8-b559-c27407a18179 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:51:14.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-j8sjj" for this suite.
Dec  5 19:51:20.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:51:20.839: INFO: namespace: e2e-tests-var-expansion-j8sjj, resource: bindings, ignored listing per whitelist
Dec  5 19:51:20.857: INFO: namespace e2e-tests-var-expansion-j8sjj deletion completed in 6.130203414s

• [SLOW TEST:10.229 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:51:20.857: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-234d633d-f8c7-11e8-b559-c27407a18179
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:51:24.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-xq4v6" for this suite.
Dec  5 19:51:46.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:51:47.041: INFO: namespace: e2e-tests-configmap-xq4v6, resource: bindings, ignored listing per whitelist
Dec  5 19:51:47.074: INFO: namespace e2e-tests-configmap-xq4v6 deletion completed in 22.109918921s

• [SLOW TEST:26.217 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:51:47.075: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 19:51:47.185: INFO: Creating deployment "test-recreate-deployment"
Dec  5 19:51:47.189: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Dec  5 19:51:47.199: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Dec  5 19:51:49.206: INFO: Waiting deployment "test-recreate-deployment" to complete
Dec  5 19:51:49.209: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Dec  5 19:51:49.217: INFO: Updating deployment test-recreate-deployment
Dec  5 19:51:49.217: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  5 19:51:49.291: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-bwd7q,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bwd7q/deployments/test-recreate-deployment,UID:32e9d085-f8c7-11e8-b622-12e7eb78a7a2,ResourceVersion:6028,Generation:2,CreationTimestamp:2018-12-05 19:51:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2018-12-05 19:51:49 +0000 UTC 2018-12-05 19:51:49 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2018-12-05 19:51:49 +0000 UTC 2018-12-05 19:51:47 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Dec  5 19:51:49.295: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-bwd7q,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bwd7q/replicasets/test-recreate-deployment-697fbf54bf,UID:3423b910-f8c7-11e8-b622-12e7eb78a7a2,ResourceVersion:6027,Generation:1,CreationTimestamp:2018-12-05 19:51:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 32e9d085-f8c7-11e8-b622-12e7eb78a7a2 0xc00218d277 0xc00218d278}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  5 19:51:49.295: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Dec  5 19:51:49.295: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-bwd7q,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bwd7q/replicasets/test-recreate-deployment-5dfdcc846d,UID:32ea5cfc-f8c7-11e8-b622-12e7eb78a7a2,ResourceVersion:6016,Generation:2,CreationTimestamp:2018-12-05 19:51:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 32e9d085-f8c7-11e8-b622-12e7eb78a7a2 0xc00218d1c7 0xc00218d1c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  5 19:51:49.298: INFO: Pod "test-recreate-deployment-697fbf54bf-8h58l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-8h58l,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-bwd7q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bwd7q/pods/test-recreate-deployment-697fbf54bf-8h58l,UID:34246093-f8c7-11e8-b622-12e7eb78a7a2,ResourceVersion:6025,Generation:0,CreationTimestamp:2018-12-05 19:51:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf 3423b910-f8c7-11e8-b622-12e7eb78a7a2 0xc00218dae7 0xc00218dae8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4jtg5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4jtg5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4jtg5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-24-193,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00218db60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00218db80}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 19:51:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 19:51:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 19:51:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 19:51:49 +0000 UTC  }],Message:,Reason:,HostIP:172.31.24.193,PodIP:,StartTime:2018-12-05 19:51:49 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:51:49.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-bwd7q" for this suite.
Dec  5 19:51:55.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:51:55.347: INFO: namespace: e2e-tests-deployment-bwd7q, resource: bindings, ignored listing per whitelist
Dec  5 19:51:55.400: INFO: namespace e2e-tests-deployment-bwd7q deletion completed in 6.099039327s

• [SLOW TEST:8.326 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:51:55.400: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-2ngw7
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Dec  5 19:51:55.534: INFO: Found 0 stateful pods, waiting for 3
Dec  5 19:52:05.538: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 19:52:05.538: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 19:52:05.538: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 19:52:05.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-2ngw7 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  5 19:52:10.734: INFO: stderr: ""
Dec  5 19:52:10.734: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  5 19:52:10.734: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Dec  5 19:52:20.769: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Dec  5 19:52:30.784: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-2ngw7 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 19:52:35.975: INFO: stderr: ""
Dec  5 19:52:35.975: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  5 19:52:35.975: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  5 19:52:55.997: INFO: Waiting for StatefulSet e2e-tests-statefulset-2ngw7/ss2 to complete update
Dec  5 19:52:55.997: INFO: Waiting for Pod e2e-tests-statefulset-2ngw7/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec  5 19:53:06.005: INFO: Waiting for StatefulSet e2e-tests-statefulset-2ngw7/ss2 to complete update
STEP: Rolling back to a previous revision
Dec  5 19:53:16.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-2ngw7 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  5 19:53:16.189: INFO: stderr: ""
Dec  5 19:53:16.189: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  5 19:53:16.189: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  5 19:53:26.221: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Dec  5 19:53:36.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-2ngw7 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 19:53:36.426: INFO: stderr: ""
Dec  5 19:53:36.426: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  5 19:53:36.426: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  5 19:53:56.446: INFO: Deleting all statefulset in ns e2e-tests-statefulset-2ngw7
Dec  5 19:53:56.449: INFO: Scaling statefulset ss2 to 0
Dec  5 19:54:26.466: INFO: Waiting for statefulset status.replicas updated to 0
Dec  5 19:54:26.470: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:54:26.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-2ngw7" for this suite.
Dec  5 19:54:32.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:54:32.616: INFO: namespace: e2e-tests-statefulset-2ngw7, resource: bindings, ignored listing per whitelist
Dec  5 19:54:32.656: INFO: namespace e2e-tests-statefulset-2ngw7 deletion completed in 6.164251512s

• [SLOW TEST:157.255 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:54:32.656: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Dec  5 19:54:32.709: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-100404934 proxy --unix-socket=/tmp/kubectl-proxy-unix143282541/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:54:32.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-84zhx" for this suite.
Dec  5 19:54:38.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:54:38.797: INFO: namespace: e2e-tests-kubectl-84zhx, resource: bindings, ignored listing per whitelist
Dec  5 19:54:39.039: INFO: namespace e2e-tests-kubectl-84zhx deletion completed in 6.272298061s

• [SLOW TEST:6.383 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:54:39.039: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-ltpvc
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  5 19:54:39.124: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  5 19:55:05.532: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.41.68:8080/dial?request=hostName&protocol=http&host=10.1.94.20&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-ltpvc PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 19:55:05.532: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
Dec  5 19:55:05.646: INFO: Waiting for endpoints: map[]
Dec  5 19:55:05.649: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.41.68:8080/dial?request=hostName&protocol=http&host=10.1.43.16&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-ltpvc PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 19:55:05.649: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
Dec  5 19:55:05.734: INFO: Waiting for endpoints: map[]
Dec  5 19:55:05.738: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.41.68:8080/dial?request=hostName&protocol=http&host=10.1.41.67&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-ltpvc PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 19:55:05.738: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
Dec  5 19:55:05.820: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:55:05.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-ltpvc" for this suite.
Dec  5 19:55:27.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:55:27.916: INFO: namespace: e2e-tests-pod-network-test-ltpvc, resource: bindings, ignored listing per whitelist
Dec  5 19:55:27.975: INFO: namespace e2e-tests-pod-network-test-ltpvc deletion completed in 22.149432813s

• [SLOW TEST:48.936 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:55:27.975: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 19:55:28.039: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b696f7b6-f8c7-11e8-b559-c27407a18179" in namespace "e2e-tests-downward-api-6jqv6" to be "success or failure"
Dec  5 19:55:28.045: INFO: Pod "downwardapi-volume-b696f7b6-f8c7-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 5.193361ms
Dec  5 19:55:30.048: INFO: Pod "downwardapi-volume-b696f7b6-f8c7-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008691048s
Dec  5 19:55:32.052: INFO: Pod "downwardapi-volume-b696f7b6-f8c7-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012529209s
STEP: Saw pod success
Dec  5 19:55:32.052: INFO: Pod "downwardapi-volume-b696f7b6-f8c7-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 19:55:32.055: INFO: Trying to get logs from node ip-172-31-24-193 pod downwardapi-volume-b696f7b6-f8c7-11e8-b559-c27407a18179 container client-container: <nil>
STEP: delete the pod
Dec  5 19:55:32.075: INFO: Waiting for pod downwardapi-volume-b696f7b6-f8c7-11e8-b559-c27407a18179 to disappear
Dec  5 19:55:32.078: INFO: Pod downwardapi-volume-b696f7b6-f8c7-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:55:32.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-6jqv6" for this suite.
Dec  5 19:55:38.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:55:38.122: INFO: namespace: e2e-tests-downward-api-6jqv6, resource: bindings, ignored listing per whitelist
Dec  5 19:55:38.193: INFO: namespace e2e-tests-downward-api-6jqv6 deletion completed in 6.112193682s

• [SLOW TEST:10.218 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:55:38.193: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-bcadba4b-f8c7-11e8-b559-c27407a18179
STEP: Creating a pod to test consume secrets
Dec  5 19:55:38.259: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-bcae5111-f8c7-11e8-b559-c27407a18179" in namespace "e2e-tests-projected-x5x7g" to be "success or failure"
Dec  5 19:55:38.264: INFO: Pod "pod-projected-secrets-bcae5111-f8c7-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 4.699536ms
Dec  5 19:55:40.267: INFO: Pod "pod-projected-secrets-bcae5111-f8c7-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008414578s
Dec  5 19:55:42.271: INFO: Pod "pod-projected-secrets-bcae5111-f8c7-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012417868s
STEP: Saw pod success
Dec  5 19:55:42.271: INFO: Pod "pod-projected-secrets-bcae5111-f8c7-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 19:55:42.274: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-projected-secrets-bcae5111-f8c7-11e8-b559-c27407a18179 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  5 19:55:42.296: INFO: Waiting for pod pod-projected-secrets-bcae5111-f8c7-11e8-b559-c27407a18179 to disappear
Dec  5 19:55:42.301: INFO: Pod pod-projected-secrets-bcae5111-f8c7-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:55:42.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-x5x7g" for this suite.
Dec  5 19:55:48.318: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:55:48.375: INFO: namespace: e2e-tests-projected-x5x7g, resource: bindings, ignored listing per whitelist
Dec  5 19:55:48.526: INFO: namespace e2e-tests-projected-x5x7g deletion completed in 6.221212618s

• [SLOW TEST:10.332 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:55:48.526: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:55:48.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-4hlx2" for this suite.
Dec  5 19:55:54.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:55:54.690: INFO: namespace: e2e-tests-kubelet-test-4hlx2, resource: bindings, ignored listing per whitelist
Dec  5 19:55:54.746: INFO: namespace e2e-tests-kubelet-test-4hlx2 deletion completed in 6.105717015s

• [SLOW TEST:6.220 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:55:54.746: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  5 19:55:54.810: INFO: Waiting up to 5m0s for pod "downward-api-c68bb5ed-f8c7-11e8-b559-c27407a18179" in namespace "e2e-tests-downward-api-zbs7x" to be "success or failure"
Dec  5 19:55:54.814: INFO: Pod "downward-api-c68bb5ed-f8c7-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 3.706983ms
Dec  5 19:55:56.817: INFO: Pod "downward-api-c68bb5ed-f8c7-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007271783s
Dec  5 19:55:58.822: INFO: Pod "downward-api-c68bb5ed-f8c7-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012232041s
STEP: Saw pod success
Dec  5 19:55:58.822: INFO: Pod "downward-api-c68bb5ed-f8c7-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 19:55:58.827: INFO: Trying to get logs from node ip-172-31-2-231 pod downward-api-c68bb5ed-f8c7-11e8-b559-c27407a18179 container dapi-container: <nil>
STEP: delete the pod
Dec  5 19:55:58.851: INFO: Waiting for pod downward-api-c68bb5ed-f8c7-11e8-b559-c27407a18179 to disappear
Dec  5 19:55:58.854: INFO: Pod downward-api-c68bb5ed-f8c7-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:55:58.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-zbs7x" for this suite.
Dec  5 19:56:04.867: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:56:04.986: INFO: namespace: e2e-tests-downward-api-zbs7x, resource: bindings, ignored listing per whitelist
Dec  5 19:56:04.991: INFO: namespace e2e-tests-downward-api-zbs7x deletion completed in 6.134468103s

• [SLOW TEST:10.245 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:56:04.991: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  5 19:56:05.080: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-b4c9k'
Dec  5 19:56:05.375: INFO: stderr: ""
Dec  5 19:56:05.375: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Dec  5 19:56:05.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-b4c9k'
Dec  5 19:56:12.647: INFO: stderr: ""
Dec  5 19:56:12.647: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:56:12.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-b4c9k" for this suite.
Dec  5 19:56:18.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:56:18.699: INFO: namespace: e2e-tests-kubectl-b4c9k, resource: bindings, ignored listing per whitelist
Dec  5 19:56:18.771: INFO: namespace e2e-tests-kubectl-b4c9k deletion completed in 6.121210945s

• [SLOW TEST:13.780 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:56:18.772: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:56:22.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-tfk9n" for this suite.
Dec  5 19:56:28.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:56:29.004: INFO: namespace: e2e-tests-kubelet-test-tfk9n, resource: bindings, ignored listing per whitelist
Dec  5 19:56:29.094: INFO: namespace e2e-tests-kubelet-test-tfk9n deletion completed in 6.191295889s

• [SLOW TEST:10.323 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:56:29.094: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-cb78t
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  5 19:56:29.182: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  5 19:56:49.268: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.1.41.72:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-cb78t PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 19:56:49.268: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
Dec  5 19:56:49.381: INFO: Found all expected endpoints: [netserver-0]
Dec  5 19:56:49.384: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.1.94.22:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-cb78t PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 19:56:49.384: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
Dec  5 19:56:49.477: INFO: Found all expected endpoints: [netserver-1]
Dec  5 19:56:49.480: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.1.43.17:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-cb78t PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 19:56:49.480: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
Dec  5 19:56:49.571: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:56:49.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-cb78t" for this suite.
Dec  5 19:57:11.586: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:57:11.618: INFO: namespace: e2e-tests-pod-network-test-cb78t, resource: bindings, ignored listing per whitelist
Dec  5 19:57:11.689: INFO: namespace e2e-tests-pod-network-test-cb78t deletion completed in 22.11465231s

• [SLOW TEST:42.595 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:57:11.690: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Dec  5 19:57:11.758: INFO: Waiting up to 5m0s for pod "client-containers-f46918a0-f8c7-11e8-b559-c27407a18179" in namespace "e2e-tests-containers-d6p28" to be "success or failure"
Dec  5 19:57:11.761: INFO: Pod "client-containers-f46918a0-f8c7-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.763012ms
Dec  5 19:57:13.765: INFO: Pod "client-containers-f46918a0-f8c7-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006247493s
Dec  5 19:57:15.768: INFO: Pod "client-containers-f46918a0-f8c7-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009654338s
STEP: Saw pod success
Dec  5 19:57:15.768: INFO: Pod "client-containers-f46918a0-f8c7-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 19:57:15.771: INFO: Trying to get logs from node ip-172-31-24-193 pod client-containers-f46918a0-f8c7-11e8-b559-c27407a18179 container test-container: <nil>
STEP: delete the pod
Dec  5 19:57:15.788: INFO: Waiting for pod client-containers-f46918a0-f8c7-11e8-b559-c27407a18179 to disappear
Dec  5 19:57:15.791: INFO: Pod client-containers-f46918a0-f8c7-11e8-b559-c27407a18179 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:57:15.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-d6p28" for this suite.
Dec  5 19:57:21.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:57:21.908: INFO: namespace: e2e-tests-containers-d6p28, resource: bindings, ignored listing per whitelist
Dec  5 19:57:21.915: INFO: namespace e2e-tests-containers-d6p28 deletion completed in 6.121207824s

• [SLOW TEST:10.225 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:57:21.915: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Dec  5 19:57:21.994: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-thlpx,SelfLink:/api/v1/namespaces/e2e-tests-watch-thlpx/configmaps/e2e-watch-test-resource-version,UID:fa753525-f8c7-11e8-b622-12e7eb78a7a2,ResourceVersion:7282,Generation:0,CreationTimestamp:2018-12-05 19:57:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  5 19:57:21.994: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-thlpx,SelfLink:/api/v1/namespaces/e2e-tests-watch-thlpx/configmaps/e2e-watch-test-resource-version,UID:fa753525-f8c7-11e8-b622-12e7eb78a7a2,ResourceVersion:7283,Generation:0,CreationTimestamp:2018-12-05 19:57:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:57:21.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-thlpx" for this suite.
Dec  5 19:57:28.010: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:57:28.031: INFO: namespace: e2e-tests-watch-thlpx, resource: bindings, ignored listing per whitelist
Dec  5 19:57:28.096: INFO: namespace e2e-tests-watch-thlpx deletion completed in 6.098166757s

• [SLOW TEST:6.181 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:57:28.096: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-bg7cb A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-bg7cb;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-bg7cb A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-bg7cb;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-bg7cb.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-bg7cb.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-bg7cb.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-bg7cb.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-bg7cb.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-bg7cb.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-bg7cb.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-bg7cb.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-bg7cb.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-bg7cb.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-bg7cb.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-bg7cb.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-bg7cb.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 198.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.198_udp@PTR;check="$$(dig +tcp +noall +answer +search 198.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.198_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-bg7cb A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-bg7cb;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-bg7cb A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-bg7cb;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-bg7cb.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-bg7cb.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-bg7cb.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-bg7cb.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-bg7cb.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-bg7cb.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-bg7cb.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-bg7cb.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-bg7cb.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-bg7cb.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-bg7cb.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-bg7cb.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-bg7cb.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 198.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.198_udp@PTR;check="$$(dig +tcp +noall +answer +search 198.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.198_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  5 19:57:32.275: INFO: DNS probes using e2e-tests-dns-bg7cb/dns-test-fe314401-f8c7-11e8-b559-c27407a18179 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:57:32.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-bg7cb" for this suite.
Dec  5 19:57:38.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:57:38.426: INFO: namespace: e2e-tests-dns-bg7cb, resource: bindings, ignored listing per whitelist
Dec  5 19:57:38.432: INFO: namespace e2e-tests-dns-bg7cb deletion completed in 6.100526703s

• [SLOW TEST:10.336 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:57:38.432: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Dec  5 19:57:38.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 create -f - --namespace=e2e-tests-kubectl-5sg7w'
Dec  5 19:57:38.668: INFO: stderr: ""
Dec  5 19:57:38.668: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Dec  5 19:57:39.672: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 19:57:39.672: INFO: Found 0 / 1
Dec  5 19:57:40.672: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 19:57:40.672: INFO: Found 0 / 1
Dec  5 19:57:41.672: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 19:57:41.672: INFO: Found 1 / 1
Dec  5 19:57:41.672: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  5 19:57:41.674: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 19:57:41.674: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Dec  5 19:57:41.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 logs redis-master-bqhhz redis-master --namespace=e2e-tests-kubectl-5sg7w'
Dec  5 19:57:41.767: INFO: stderr: ""
Dec  5 19:57:41.767: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 05 Dec 19:57:40.476 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 05 Dec 19:57:40.476 # Server started, Redis version 3.2.12\n1:M 05 Dec 19:57:40.476 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 05 Dec 19:57:40.476 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Dec  5 19:57:41.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 log redis-master-bqhhz redis-master --namespace=e2e-tests-kubectl-5sg7w --tail=1'
Dec  5 19:57:41.850: INFO: stderr: ""
Dec  5 19:57:41.850: INFO: stdout: "1:M 05 Dec 19:57:40.476 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Dec  5 19:57:41.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 log redis-master-bqhhz redis-master --namespace=e2e-tests-kubectl-5sg7w --limit-bytes=1'
Dec  5 19:57:41.948: INFO: stderr: ""
Dec  5 19:57:41.948: INFO: stdout: " "
STEP: exposing timestamps
Dec  5 19:57:41.948: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 log redis-master-bqhhz redis-master --namespace=e2e-tests-kubectl-5sg7w --tail=1 --timestamps'
Dec  5 19:57:42.029: INFO: stderr: ""
Dec  5 19:57:42.029: INFO: stdout: "2018-12-05T19:57:40.476232988Z 1:M 05 Dec 19:57:40.476 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Dec  5 19:57:44.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 log redis-master-bqhhz redis-master --namespace=e2e-tests-kubectl-5sg7w --since=1s'
Dec  5 19:57:44.604: INFO: stderr: ""
Dec  5 19:57:44.604: INFO: stdout: ""
Dec  5 19:57:44.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 log redis-master-bqhhz redis-master --namespace=e2e-tests-kubectl-5sg7w --since=24h'
Dec  5 19:57:44.694: INFO: stderr: ""
Dec  5 19:57:44.694: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 05 Dec 19:57:40.476 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 05 Dec 19:57:40.476 # Server started, Redis version 3.2.12\n1:M 05 Dec 19:57:40.476 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 05 Dec 19:57:40.476 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Dec  5 19:57:44.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-5sg7w'
Dec  5 19:57:44.787: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  5 19:57:44.787: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Dec  5 19:57:44.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-5sg7w'
Dec  5 19:57:44.879: INFO: stderr: "No resources found.\n"
Dec  5 19:57:44.879: INFO: stdout: ""
Dec  5 19:57:44.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods -l name=nginx --namespace=e2e-tests-kubectl-5sg7w -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  5 19:57:44.943: INFO: stderr: ""
Dec  5 19:57:44.943: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:57:44.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5sg7w" for this suite.
Dec  5 19:57:50.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:57:51.040: INFO: namespace: e2e-tests-kubectl-5sg7w, resource: bindings, ignored listing per whitelist
Dec  5 19:57:51.043: INFO: namespace e2e-tests-kubectl-5sg7w deletion completed in 6.096425185s

• [SLOW TEST:12.610 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:57:51.043: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Dec  5 19:57:51.099: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 cluster-info'
Dec  5 19:57:51.165: INFO: stderr: ""
Dec  5 19:57:51.165: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.152.183.1:443\x1b[0m\n\x1b[0;32mHeapster\x1b[0m is running at \x1b[0;33mhttps://10.152.183.1:443/api/v1/namespaces/kube-system/services/heapster/proxy\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.152.183.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://10.152.183.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\x1b[0;32mGrafana\x1b[0m is running at \x1b[0;33mhttps://10.152.183.1:443/api/v1/namespaces/kube-system/services/monitoring-grafana/proxy\x1b[0m\n\x1b[0;32mInfluxDB\x1b[0m is running at \x1b[0;33mhttps://10.152.183.1:443/api/v1/namespaces/kube-system/services/monitoring-influxdb:http/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:57:51.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lj5gg" for this suite.
Dec  5 19:57:57.179: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:57:57.233: INFO: namespace: e2e-tests-kubectl-lj5gg, resource: bindings, ignored listing per whitelist
Dec  5 19:57:57.313: INFO: namespace e2e-tests-kubectl-lj5gg deletion completed in 6.144163668s

• [SLOW TEST:6.270 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:57:57.313: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec  5 19:57:57.371: INFO: Waiting up to 5m0s for pod "pod-0f994a42-f8c8-11e8-b559-c27407a18179" in namespace "e2e-tests-emptydir-25z8v" to be "success or failure"
Dec  5 19:57:57.374: INFO: Pod "pod-0f994a42-f8c8-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.516983ms
Dec  5 19:57:59.377: INFO: Pod "pod-0f994a42-f8c8-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00624084s
Dec  5 19:58:01.380: INFO: Pod "pod-0f994a42-f8c8-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009326721s
STEP: Saw pod success
Dec  5 19:58:01.381: INFO: Pod "pod-0f994a42-f8c8-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 19:58:01.383: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-0f994a42-f8c8-11e8-b559-c27407a18179 container test-container: <nil>
STEP: delete the pod
Dec  5 19:58:01.400: INFO: Waiting for pod pod-0f994a42-f8c8-11e8-b559-c27407a18179 to disappear
Dec  5 19:58:01.403: INFO: Pod pod-0f994a42-f8c8-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:58:01.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-25z8v" for this suite.
Dec  5 19:58:07.420: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:58:07.565: INFO: namespace: e2e-tests-emptydir-25z8v, resource: bindings, ignored listing per whitelist
Dec  5 19:58:07.614: INFO: namespace e2e-tests-emptydir-25z8v deletion completed in 6.207724139s

• [SLOW TEST:10.301 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:58:07.614: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 19:58:07.672: INFO: Waiting up to 5m0s for pod "downwardapi-volume-15bd0ff7-f8c8-11e8-b559-c27407a18179" in namespace "e2e-tests-projected-757dk" to be "success or failure"
Dec  5 19:58:07.676: INFO: Pod "downwardapi-volume-15bd0ff7-f8c8-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029727ms
Dec  5 19:58:09.680: INFO: Pod "downwardapi-volume-15bd0ff7-f8c8-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007582361s
Dec  5 19:58:11.684: INFO: Pod "downwardapi-volume-15bd0ff7-f8c8-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011458045s
STEP: Saw pod success
Dec  5 19:58:11.684: INFO: Pod "downwardapi-volume-15bd0ff7-f8c8-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 19:58:11.686: INFO: Trying to get logs from node ip-172-31-24-193 pod downwardapi-volume-15bd0ff7-f8c8-11e8-b559-c27407a18179 container client-container: <nil>
STEP: delete the pod
Dec  5 19:58:11.707: INFO: Waiting for pod downwardapi-volume-15bd0ff7-f8c8-11e8-b559-c27407a18179 to disappear
Dec  5 19:58:11.709: INFO: Pod downwardapi-volume-15bd0ff7-f8c8-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:58:11.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-757dk" for this suite.
Dec  5 19:58:17.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:58:17.812: INFO: namespace: e2e-tests-projected-757dk, resource: bindings, ignored listing per whitelist
Dec  5 19:58:17.827: INFO: namespace e2e-tests-projected-757dk deletion completed in 6.115099309s

• [SLOW TEST:10.213 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:58:17.827: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 19:58:17.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 version --client'
Dec  5 19:58:17.969: INFO: stderr: ""
Dec  5 19:58:17.969: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Dec  5 19:58:17.971: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 create -f - --namespace=e2e-tests-kubectl-k85lv'
Dec  5 19:58:18.400: INFO: stderr: ""
Dec  5 19:58:18.400: INFO: stdout: "replicationcontroller/redis-master created\n"
Dec  5 19:58:18.400: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 create -f - --namespace=e2e-tests-kubectl-k85lv'
Dec  5 19:58:18.598: INFO: stderr: ""
Dec  5 19:58:18.598: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  5 19:58:19.602: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 19:58:19.602: INFO: Found 0 / 1
Dec  5 19:58:20.601: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 19:58:20.601: INFO: Found 1 / 1
Dec  5 19:58:20.601: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  5 19:58:20.604: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 19:58:20.604: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  5 19:58:20.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 describe pod redis-master-2qvn9 --namespace=e2e-tests-kubectl-k85lv'
Dec  5 19:58:20.683: INFO: stderr: ""
Dec  5 19:58:20.683: INFO: stdout: "Name:           redis-master-2qvn9\nNamespace:      e2e-tests-kubectl-k85lv\nNode:           ip-172-31-24-193/172.31.24.193\nStart Time:     Wed, 05 Dec 2018 19:58:18 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    <none>\nStatus:         Running\nIP:             10.1.41.79\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://0dc161a639f7c254889791ef79aae1c4e86589381516413eef862658e0c797b1\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 05 Dec 2018 19:58:19 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-m4nl6 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-m4nl6:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-m4nl6\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                       Message\n  ----    ------     ----  ----                       -------\n  Normal  Scheduled  2s    default-scheduler          Successfully assigned e2e-tests-kubectl-k85lv/redis-master-2qvn9 to ip-172-31-24-193\n  Normal  Pulled     1s    kubelet, ip-172-31-24-193  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, ip-172-31-24-193  Created container\n  Normal  Started    1s    kubelet, ip-172-31-24-193  Started container\n"
Dec  5 19:58:20.683: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 describe rc redis-master --namespace=e2e-tests-kubectl-k85lv'
Dec  5 19:58:20.777: INFO: stderr: ""
Dec  5 19:58:20.778: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-k85lv\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-2qvn9\n"
Dec  5 19:58:20.778: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 describe service redis-master --namespace=e2e-tests-kubectl-k85lv'
Dec  5 19:58:20.849: INFO: stderr: ""
Dec  5 19:58:20.849: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-k85lv\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.152.183.87\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.1.41.79:6379\nSession Affinity:  None\nEvents:            <none>\n"
Dec  5 19:58:20.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 describe node ip-172-31-2-231'
Dec  5 19:58:20.952: INFO: stderr: ""
Dec  5 19:58:20.952: INFO: stdout: "Name:               ip-172-31-2-231\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    juju-application=kubernetes-worker\n                    kubernetes.io/hostname=ip-172-31-2-231\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 05 Dec 2018 19:17:07 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Wed, 05 Dec 2018 19:58:18 +0000   Wed, 05 Dec 2018 19:17:07 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Wed, 05 Dec 2018 19:58:18 +0000   Wed, 05 Dec 2018 19:17:07 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Wed, 05 Dec 2018 19:58:18 +0000   Wed, 05 Dec 2018 19:17:07 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Wed, 05 Dec 2018 19:58:18 +0000   Wed, 05 Dec 2018 19:24:30 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  172.31.2.231\n  Hostname:    ip-172-31-2-231\nCapacity:\n cpu:                4\n ephemeral-storage:  16197480Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16235512Ki\n pods:               110\nAllocatable:\n cpu:                4\n ephemeral-storage:  14927597544\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16133112Ki\n pods:               110\nSystem Info:\n Machine ID:                       ec2828264caf11f2d6c187a71612897b\n System UUID:                      EC282826-4CAF-11F2-D6C1-87A71612897B\n Boot ID:                          f7eaeb65-0d54-43f7-94f2-3074bd16e712\n Kernel Version:                   4.15.0-1027-aws\n OS Image:                         Ubuntu 18.04.1 LTS\n Operating System:                 linux\n Architecture:                     amd64\n Container Runtime Version:        docker://18.6.1\n Kubelet Version:                  v1.13.0\n Kube-Proxy Version:               v1.13.0\nNon-terminated Pods:               (5 in total)\n  Namespace                        Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                        ----                                                       ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy                  sonobuoy-systemd-logs-daemon-set-5821f0bd06934aee-wxzkp    0 (0%)        0 (0%)      0 (0%)           0 (0%)         29m\n  ingress-nginx-kubernetes-worker  nginx-ingress-controller-kubernetes-worker-tqt8p           0 (0%)        0 (0%)      0 (0%)           0 (0%)         41m\n  kube-system                      kube-dns-8f7866879-f6tkp                                   260m (6%)     0 (0%)      110Mi (0%)       170Mi (1%)     41m\n  kube-system                      kubernetes-dashboard-654cfb4879-bwd9z                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         41m\n  kube-system                      monitoring-influxdb-grafana-v4-5866497777-xh229            200m (5%)     200m (5%)   600Mi (3%)       600Mi (3%)     41m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                460m (11%)  200m (5%)\n  memory             710Mi (4%)  770Mi (4%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:\n  Type    Reason                   Age                From                         Message\n  ----    ------                   ----               ----                         -------\n  Normal  Starting                 41m                kubelet, ip-172-31-2-231     Starting kubelet.\n  Normal  NodeHasSufficientMemory  41m (x2 over 41m)  kubelet, ip-172-31-2-231     Node ip-172-31-2-231 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    41m (x2 over 41m)  kubelet, ip-172-31-2-231     Node ip-172-31-2-231 status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     41m (x2 over 41m)  kubelet, ip-172-31-2-231     Node ip-172-31-2-231 status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced  41m                kubelet, ip-172-31-2-231     Updated Node Allocatable limit across pods\n  Normal  Starting                 41m                kube-proxy, ip-172-31-2-231  Starting kube-proxy.\n  Normal  NodeReady                41m                kubelet, ip-172-31-2-231     Node ip-172-31-2-231 status is now: NodeReady\n  Normal  NodeAllocatableEnforced  39m                kubelet, ip-172-31-2-231     Updated Node Allocatable limit across pods\n  Normal  Starting                 39m                kube-proxy, ip-172-31-2-231  Starting kube-proxy.\n  Normal  Starting                 39m                kubelet, ip-172-31-2-231     Starting kubelet.\n  Normal  NodeHasSufficientMemory  39m                kubelet, ip-172-31-2-231     Node ip-172-31-2-231 status is now: NodeHasSufficientMemory\n  Normal  NodeHasSufficientPID     39m                kubelet, ip-172-31-2-231     Node ip-172-31-2-231 status is now: NodeHasSufficientPID\n  Normal  NodeHasNoDiskPressure    39m                kubelet, ip-172-31-2-231     Node ip-172-31-2-231 status is now: NodeHasNoDiskPressure\n  Normal  Starting                 34m                kube-proxy, ip-172-31-2-231  Starting kube-proxy.\n  Normal  Starting                 34m                kubelet, ip-172-31-2-231     Starting kubelet.\n  Normal  NodeHasSufficientMemory  34m                kubelet, ip-172-31-2-231     Node ip-172-31-2-231 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    34m                kubelet, ip-172-31-2-231     Node ip-172-31-2-231 status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     34m                kubelet, ip-172-31-2-231     Node ip-172-31-2-231 status is now: NodeHasSufficientPID\n  Normal  NodeNotReady             34m                kubelet, ip-172-31-2-231     Node ip-172-31-2-231 status is now: NodeNotReady\n  Normal  NodeAllocatableEnforced  34m                kubelet, ip-172-31-2-231     Updated Node Allocatable limit across pods\n  Normal  NodeReady                33m                kubelet, ip-172-31-2-231     Node ip-172-31-2-231 status is now: NodeReady\n"
Dec  5 19:58:20.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 describe namespace e2e-tests-kubectl-k85lv'
Dec  5 19:58:21.023: INFO: stderr: ""
Dec  5 19:58:21.023: INFO: stdout: "Name:         e2e-tests-kubectl-k85lv\nLabels:       e2e-framework=kubectl\n              e2e-run=07703534-f8c4-11e8-b559-c27407a18179\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:58:21.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-k85lv" for this suite.
Dec  5 19:58:43.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:58:43.122: INFO: namespace: e2e-tests-kubectl-k85lv, resource: bindings, ignored listing per whitelist
Dec  5 19:58:43.171: INFO: namespace e2e-tests-kubectl-k85lv deletion completed in 22.144537073s

• [SLOW TEST:25.343 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:58:43.171: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 19:58:43.225: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:58:44.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-tjd6b" for this suite.
Dec  5 19:58:50.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:58:50.320: INFO: namespace: e2e-tests-custom-resource-definition-tjd6b, resource: bindings, ignored listing per whitelist
Dec  5 19:58:50.377: INFO: namespace e2e-tests-custom-resource-definition-tjd6b deletion completed in 6.100176974s

• [SLOW TEST:7.207 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:58:50.378: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Dec  5 19:58:54.459: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-2f3a8534-f8c8-11e8-b559-c27407a18179,GenerateName:,Namespace:e2e-tests-events-sv6ql,SelfLink:/api/v1/namespaces/e2e-tests-events-sv6ql/pods/send-events-2f3a8534-f8c8-11e8-b559-c27407a18179,UID:2f2f6928-f8c8-11e8-b622-12e7eb78a7a2,ResourceVersion:7653,Generation:0,CreationTimestamp:2018-12-05 19:58:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 431225051,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7bdnc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7bdnc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-7bdnc true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-24-193,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002345020} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002345040}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 19:58:50 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 19:58:54 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 19:58:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 19:58:50 +0000 UTC  }],Message:,Reason:,HostIP:172.31.24.193,PodIP:10.1.41.80,StartTime:2018-12-05 19:58:50 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2018-12-05 19:58:53 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://d185700152c71bb5e864dc5364d234b721f1ae9d4a160d73afd2c75a2d805910}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Dec  5 19:58:56.463: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Dec  5 19:58:58.466: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:58:58.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-sv6ql" for this suite.
Dec  5 19:59:36.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:59:36.563: INFO: namespace: e2e-tests-events-sv6ql, resource: bindings, ignored listing per whitelist
Dec  5 19:59:36.574: INFO: namespace e2e-tests-events-sv6ql deletion completed in 38.09839553s

• [SLOW TEST:46.196 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:59:36.574: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-4ac35e97-f8c8-11e8-b559-c27407a18179
STEP: Creating a pod to test consume configMaps
Dec  5 19:59:36.636: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4ac3e94e-f8c8-11e8-b559-c27407a18179" in namespace "e2e-tests-projected-k6zvl" to be "success or failure"
Dec  5 19:59:36.639: INFO: Pod "pod-projected-configmaps-4ac3e94e-f8c8-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.847135ms
Dec  5 19:59:38.643: INFO: Pod "pod-projected-configmaps-4ac3e94e-f8c8-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006473611s
STEP: Saw pod success
Dec  5 19:59:38.643: INFO: Pod "pod-projected-configmaps-4ac3e94e-f8c8-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 19:59:38.645: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-projected-configmaps-4ac3e94e-f8c8-11e8-b559-c27407a18179 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 19:59:38.667: INFO: Waiting for pod pod-projected-configmaps-4ac3e94e-f8c8-11e8-b559-c27407a18179 to disappear
Dec  5 19:59:38.670: INFO: Pod pod-projected-configmaps-4ac3e94e-f8c8-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:59:38.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-k6zvl" for this suite.
Dec  5 19:59:44.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:59:44.719: INFO: namespace: e2e-tests-projected-k6zvl, resource: bindings, ignored listing per whitelist
Dec  5 19:59:44.770: INFO: namespace e2e-tests-projected-k6zvl deletion completed in 6.097498222s

• [SLOW TEST:8.196 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:59:44.770: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Dec  5 19:59:44.836: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-fzgmr" to be "success or failure"
Dec  5 19:59:44.840: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.059258ms
Dec  5 19:59:46.844: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007658357s
STEP: Saw pod success
Dec  5 19:59:46.844: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Dec  5 19:59:46.846: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Dec  5 19:59:46.863: INFO: Waiting for pod pod-host-path-test to disappear
Dec  5 19:59:46.867: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 19:59:46.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-fzgmr" for this suite.
Dec  5 19:59:52.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 19:59:52.960: INFO: namespace: e2e-tests-hostpath-fzgmr, resource: bindings, ignored listing per whitelist
Dec  5 19:59:52.971: INFO: namespace e2e-tests-hostpath-fzgmr deletion completed in 6.101114467s

• [SLOW TEST:8.201 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 19:59:52.971: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:00:00.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-mmz4s" for this suite.
Dec  5 20:00:22.068: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:00:22.137: INFO: namespace: e2e-tests-replication-controller-mmz4s, resource: bindings, ignored listing per whitelist
Dec  5 20:00:22.154: INFO: namespace e2e-tests-replication-controller-mmz4s deletion completed in 22.095692608s

• [SLOW TEST:29.182 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:00:22.154: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Dec  5 20:00:22.219: INFO: Waiting up to 5m0s for pod "var-expansion-65ef398e-f8c8-11e8-b559-c27407a18179" in namespace "e2e-tests-var-expansion-tclb6" to be "success or failure"
Dec  5 20:00:22.222: INFO: Pod "var-expansion-65ef398e-f8c8-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 3.078355ms
Dec  5 20:00:24.225: INFO: Pod "var-expansion-65ef398e-f8c8-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00651284s
STEP: Saw pod success
Dec  5 20:00:24.225: INFO: Pod "var-expansion-65ef398e-f8c8-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 20:00:24.228: INFO: Trying to get logs from node ip-172-31-24-193 pod var-expansion-65ef398e-f8c8-11e8-b559-c27407a18179 container dapi-container: <nil>
STEP: delete the pod
Dec  5 20:00:24.245: INFO: Waiting for pod var-expansion-65ef398e-f8c8-11e8-b559-c27407a18179 to disappear
Dec  5 20:00:24.248: INFO: Pod var-expansion-65ef398e-f8c8-11e8-b559-c27407a18179 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:00:24.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-tclb6" for this suite.
Dec  5 20:00:30.261: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:00:30.289: INFO: namespace: e2e-tests-var-expansion-tclb6, resource: bindings, ignored listing per whitelist
Dec  5 20:00:30.352: INFO: namespace e2e-tests-var-expansion-tclb6 deletion completed in 6.101434626s

• [SLOW TEST:8.198 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:00:30.352: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:00:32.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-8jtbq" for this suite.
Dec  5 20:01:10.455: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:01:10.550: INFO: namespace: e2e-tests-kubelet-test-8jtbq, resource: bindings, ignored listing per whitelist
Dec  5 20:01:10.561: INFO: namespace e2e-tests-kubelet-test-8jtbq deletion completed in 38.119821964s

• [SLOW TEST:40.208 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:01:10.561: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Dec  5 20:01:10.620: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  5 20:01:10.627: INFO: Waiting for terminating namespaces to be deleted...
Dec  5 20:01:10.630: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-2-231 before test
Dec  5 20:01:10.639: INFO: monitoring-influxdb-grafana-v4-5866497777-xh229 from kube-system started at 2018-12-05 19:17:08 +0000 UTC (2 container statuses recorded)
Dec  5 20:01:10.639: INFO: 	Container grafana ready: true, restart count 0
Dec  5 20:01:10.639: INFO: 	Container influxdb ready: true, restart count 0
Dec  5 20:01:10.639: INFO: kube-dns-8f7866879-f6tkp from kube-system started at 2018-12-05 19:17:08 +0000 UTC (3 container statuses recorded)
Dec  5 20:01:10.639: INFO: 	Container dnsmasq ready: true, restart count 0
Dec  5 20:01:10.639: INFO: 	Container kubedns ready: true, restart count 0
Dec  5 20:01:10.639: INFO: 	Container sidecar ready: true, restart count 0
Dec  5 20:01:10.639: INFO: nginx-ingress-controller-kubernetes-worker-tqt8p from ingress-nginx-kubernetes-worker started at 2018-12-05 19:17:11 +0000 UTC (1 container statuses recorded)
Dec  5 20:01:10.639: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Dec  5 20:01:10.639: INFO: sonobuoy-systemd-logs-daemon-set-5821f0bd06934aee-wxzkp from heptio-sonobuoy started at 2018-12-05 19:28:41 +0000 UTC (2 container statuses recorded)
Dec  5 20:01:10.639: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Dec  5 20:01:10.639: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  5 20:01:10.639: INFO: kubernetes-dashboard-654cfb4879-bwd9z from kube-system started at 2018-12-05 19:17:08 +0000 UTC (1 container statuses recorded)
Dec  5 20:01:10.639: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec  5 20:01:10.639: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-24-193 before test
Dec  5 20:01:10.644: INFO: nginx-ingress-controller-kubernetes-worker-r2dmv from ingress-nginx-kubernetes-worker started at 2018-12-05 19:17:11 +0000 UTC (1 container statuses recorded)
Dec  5 20:01:10.644: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Dec  5 20:01:10.644: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-05 19:28:31 +0000 UTC (1 container statuses recorded)
Dec  5 20:01:10.644: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec  5 20:01:10.644: INFO: metrics-server-v0.3.1-54b884db75-fv2g7 from kube-system started at 2018-12-05 19:18:29 +0000 UTC (2 container statuses recorded)
Dec  5 20:01:10.644: INFO: 	Container metrics-server ready: true, restart count 0
Dec  5 20:01:10.644: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Dec  5 20:01:10.644: INFO: sonobuoy-systemd-logs-daemon-set-5821f0bd06934aee-2dj6p from heptio-sonobuoy started at 2018-12-05 19:28:41 +0000 UTC (2 container statuses recorded)
Dec  5 20:01:10.644: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Dec  5 20:01:10.644: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  5 20:01:10.644: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-66-194 before test
Dec  5 20:01:10.679: INFO: default-http-backend-kubernetes-worker-7f7f76df64-fq4nj from ingress-nginx-kubernetes-worker started at 2018-12-05 19:17:10 +0000 UTC (1 container statuses recorded)
Dec  5 20:01:10.679: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
Dec  5 20:01:10.679: INFO: nginx-ingress-controller-kubernetes-worker-dxhb9 from ingress-nginx-kubernetes-worker started at 2018-12-05 19:17:11 +0000 UTC (1 container statuses recorded)
Dec  5 20:01:10.679: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 1
Dec  5 20:01:10.679: INFO: heapster-v1.6.0-beta.1-6d5d4878cb-cwfd2 from kube-system started at 2018-12-05 19:21:46 +0000 UTC (4 container statuses recorded)
Dec  5 20:01:10.679: INFO: 	Container eventer ready: true, restart count 0
Dec  5 20:01:10.679: INFO: 	Container eventer-nanny ready: true, restart count 0
Dec  5 20:01:10.679: INFO: 	Container heapster ready: true, restart count 0
Dec  5 20:01:10.679: INFO: 	Container heapster-nanny ready: true, restart count 0
Dec  5 20:01:10.679: INFO: sonobuoy-e2e-job-70e3eb1949d94e90 from heptio-sonobuoy started at 2018-12-05 19:28:41 +0000 UTC (2 container statuses recorded)
Dec  5 20:01:10.679: INFO: 	Container e2e ready: true, restart count 0
Dec  5 20:01:10.679: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  5 20:01:10.679: INFO: sonobuoy-systemd-logs-daemon-set-5821f0bd06934aee-qzgmw from heptio-sonobuoy started at 2018-12-05 19:28:41 +0000 UTC (2 container statuses recorded)
Dec  5 20:01:10.679: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Dec  5 20:01:10.679: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-840801b2-f8c8-11e8-b559-c27407a18179 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-840801b2-f8c8-11e8-b559-c27407a18179 off the node ip-172-31-24-193
STEP: verifying the node doesn't have the label kubernetes.io/e2e-840801b2-f8c8-11e8-b559-c27407a18179
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:01:16.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-h97qx" for this suite.
Dec  5 20:01:34.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:01:34.855: INFO: namespace: e2e-tests-sched-pred-h97qx, resource: bindings, ignored listing per whitelist
Dec  5 20:01:34.864: INFO: namespace e2e-tests-sched-pred-h97qx deletion completed in 18.122186279s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:24.304 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:01:34.864: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec  5 20:01:34.927: INFO: Waiting up to 5m0s for pod "pod-9145c6e9-f8c8-11e8-b559-c27407a18179" in namespace "e2e-tests-emptydir-s4vr8" to be "success or failure"
Dec  5 20:01:34.931: INFO: Pod "pod-9145c6e9-f8c8-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 3.940498ms
Dec  5 20:01:36.935: INFO: Pod "pod-9145c6e9-f8c8-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007780384s
Dec  5 20:01:38.938: INFO: Pod "pod-9145c6e9-f8c8-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011343941s
STEP: Saw pod success
Dec  5 20:01:38.938: INFO: Pod "pod-9145c6e9-f8c8-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 20:01:38.941: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-9145c6e9-f8c8-11e8-b559-c27407a18179 container test-container: <nil>
STEP: delete the pod
Dec  5 20:01:38.958: INFO: Waiting for pod pod-9145c6e9-f8c8-11e8-b559-c27407a18179 to disappear
Dec  5 20:01:38.960: INFO: Pod pod-9145c6e9-f8c8-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:01:38.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-s4vr8" for this suite.
Dec  5 20:01:44.973: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:01:44.987: INFO: namespace: e2e-tests-emptydir-s4vr8, resource: bindings, ignored listing per whitelist
Dec  5 20:01:45.061: INFO: namespace e2e-tests-emptydir-s4vr8 deletion completed in 6.097308228s

• [SLOW TEST:10.196 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:01:45.061: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-8kpl
STEP: Creating a pod to test atomic-volume-subpath
Dec  5 20:01:45.129: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-8kpl" in namespace "e2e-tests-subpath-jdwj7" to be "success or failure"
Dec  5 20:01:45.134: INFO: Pod "pod-subpath-test-configmap-8kpl": Phase="Pending", Reason="", readiness=false. Elapsed: 4.554817ms
Dec  5 20:01:47.137: INFO: Pod "pod-subpath-test-configmap-8kpl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007829122s
Dec  5 20:01:49.141: INFO: Pod "pod-subpath-test-configmap-8kpl": Phase="Running", Reason="", readiness=false. Elapsed: 4.011914193s
Dec  5 20:01:51.144: INFO: Pod "pod-subpath-test-configmap-8kpl": Phase="Running", Reason="", readiness=false. Elapsed: 6.01508477s
Dec  5 20:01:53.148: INFO: Pod "pod-subpath-test-configmap-8kpl": Phase="Running", Reason="", readiness=false. Elapsed: 8.018905403s
Dec  5 20:01:55.152: INFO: Pod "pod-subpath-test-configmap-8kpl": Phase="Running", Reason="", readiness=false. Elapsed: 10.022995873s
Dec  5 20:01:57.156: INFO: Pod "pod-subpath-test-configmap-8kpl": Phase="Running", Reason="", readiness=false. Elapsed: 12.026794654s
Dec  5 20:01:59.160: INFO: Pod "pod-subpath-test-configmap-8kpl": Phase="Running", Reason="", readiness=false. Elapsed: 14.03080294s
Dec  5 20:02:01.163: INFO: Pod "pod-subpath-test-configmap-8kpl": Phase="Running", Reason="", readiness=false. Elapsed: 16.034246633s
Dec  5 20:02:03.167: INFO: Pod "pod-subpath-test-configmap-8kpl": Phase="Running", Reason="", readiness=false. Elapsed: 18.038109138s
Dec  5 20:02:05.171: INFO: Pod "pod-subpath-test-configmap-8kpl": Phase="Running", Reason="", readiness=false. Elapsed: 20.041650752s
Dec  5 20:02:07.175: INFO: Pod "pod-subpath-test-configmap-8kpl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.046288069s
STEP: Saw pod success
Dec  5 20:02:07.176: INFO: Pod "pod-subpath-test-configmap-8kpl" satisfied condition "success or failure"
Dec  5 20:02:07.178: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-subpath-test-configmap-8kpl container test-container-subpath-configmap-8kpl: <nil>
STEP: delete the pod
Dec  5 20:02:07.195: INFO: Waiting for pod pod-subpath-test-configmap-8kpl to disappear
Dec  5 20:02:07.197: INFO: Pod pod-subpath-test-configmap-8kpl no longer exists
STEP: Deleting pod pod-subpath-test-configmap-8kpl
Dec  5 20:02:07.197: INFO: Deleting pod "pod-subpath-test-configmap-8kpl" in namespace "e2e-tests-subpath-jdwj7"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:02:07.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-jdwj7" for this suite.
Dec  5 20:02:13.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:02:13.859: INFO: namespace: e2e-tests-subpath-jdwj7, resource: bindings, ignored listing per whitelist
Dec  5 20:02:13.863: INFO: namespace e2e-tests-subpath-jdwj7 deletion completed in 6.66009005s

• [SLOW TEST:28.802 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:02:13.863: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  5 20:02:13.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-cb48p'
Dec  5 20:02:14.055: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  5 20:02:14.055: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Dec  5 20:02:14.075: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-n822z]
Dec  5 20:02:14.075: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-n822z" in namespace "e2e-tests-kubectl-cb48p" to be "running and ready"
Dec  5 20:02:14.079: INFO: Pod "e2e-test-nginx-rc-n822z": Phase="Pending", Reason="", readiness=false. Elapsed: 3.336489ms
Dec  5 20:02:16.082: INFO: Pod "e2e-test-nginx-rc-n822z": Phase="Running", Reason="", readiness=true. Elapsed: 2.006579937s
Dec  5 20:02:16.082: INFO: Pod "e2e-test-nginx-rc-n822z" satisfied condition "running and ready"
Dec  5 20:02:16.082: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-n822z]
Dec  5 20:02:16.082: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-cb48p'
Dec  5 20:02:16.170: INFO: stderr: ""
Dec  5 20:02:16.170: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Dec  5 20:02:16.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-cb48p'
Dec  5 20:02:16.241: INFO: stderr: ""
Dec  5 20:02:16.241: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:02:16.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-cb48p" for this suite.
Dec  5 20:02:38.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:02:38.350: INFO: namespace: e2e-tests-kubectl-cb48p, resource: bindings, ignored listing per whitelist
Dec  5 20:02:38.353: INFO: namespace e2e-tests-kubectl-cb48p deletion completed in 22.1080592s

• [SLOW TEST:24.490 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:02:38.353: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec  5 20:02:42.944: INFO: Successfully updated pod "annotationupdateb71cfb0e-f8c8-11e8-b559-c27407a18179"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:02:44.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xnhlz" for this suite.
Dec  5 20:03:06.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:03:07.067: INFO: namespace: e2e-tests-downward-api-xnhlz, resource: bindings, ignored listing per whitelist
Dec  5 20:03:07.097: INFO: namespace e2e-tests-downward-api-xnhlz deletion completed in 22.133949605s

• [SLOW TEST:28.744 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:03:07.097: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-c8400611-f8c8-11e8-b559-c27407a18179
STEP: Creating secret with name s-test-opt-upd-c8400665-f8c8-11e8-b559-c27407a18179
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-c8400611-f8c8-11e8-b559-c27407a18179
STEP: Updating secret s-test-opt-upd-c8400665-f8c8-11e8-b559-c27407a18179
STEP: Creating secret with name s-test-opt-create-c8400685-f8c8-11e8-b559-c27407a18179
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:03:13.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-bkhcl" for this suite.
Dec  5 20:03:39.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:03:39.350: INFO: namespace: e2e-tests-secrets-bkhcl, resource: bindings, ignored listing per whitelist
Dec  5 20:03:39.361: INFO: namespace e2e-tests-secrets-bkhcl deletion completed in 26.108954469s

• [SLOW TEST:32.264 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:03:39.361: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Dec  5 20:03:39.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 --namespace=e2e-tests-kubectl-z42ht run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Dec  5 20:03:42.522: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Dec  5 20:03:42.522: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:03:44.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-z42ht" for this suite.
Dec  5 20:03:54.542: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:03:54.562: INFO: namespace: e2e-tests-kubectl-z42ht, resource: bindings, ignored listing per whitelist
Dec  5 20:03:54.629: INFO: namespace e2e-tests-kubectl-z42ht deletion completed in 10.097808379s

• [SLOW TEST:15.268 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:03:54.629: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec  5 20:03:59.214: INFO: Successfully updated pod "labelsupdatee4933d03-f8c8-11e8-b559-c27407a18179"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:04:01.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-lrqhj" for this suite.
Dec  5 20:04:23.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:04:23.330: INFO: namespace: e2e-tests-projected-lrqhj, resource: bindings, ignored listing per whitelist
Dec  5 20:04:23.355: INFO: namespace e2e-tests-projected-lrqhj deletion completed in 22.122109269s

• [SLOW TEST:28.726 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:04:23.355: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 20:04:23.427: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f5b4e184-f8c8-11e8-b559-c27407a18179" in namespace "e2e-tests-downward-api-zgf9w" to be "success or failure"
Dec  5 20:04:23.430: INFO: Pod "downwardapi-volume-f5b4e184-f8c8-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.691552ms
Dec  5 20:04:25.438: INFO: Pod "downwardapi-volume-f5b4e184-f8c8-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010537785s
STEP: Saw pod success
Dec  5 20:04:25.438: INFO: Pod "downwardapi-volume-f5b4e184-f8c8-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 20:04:25.441: INFO: Trying to get logs from node ip-172-31-24-193 pod downwardapi-volume-f5b4e184-f8c8-11e8-b559-c27407a18179 container client-container: <nil>
STEP: delete the pod
Dec  5 20:04:25.459: INFO: Waiting for pod downwardapi-volume-f5b4e184-f8c8-11e8-b559-c27407a18179 to disappear
Dec  5 20:04:25.461: INFO: Pod downwardapi-volume-f5b4e184-f8c8-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:04:25.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-zgf9w" for this suite.
Dec  5 20:04:31.474: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:04:31.569: INFO: namespace: e2e-tests-downward-api-zgf9w, resource: bindings, ignored listing per whitelist
Dec  5 20:04:31.577: INFO: namespace e2e-tests-downward-api-zgf9w deletion completed in 6.112719652s

• [SLOW TEST:8.221 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:04:31.577: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 20:04:31.709: INFO: Waiting up to 5m0s for pod "downwardapi-volume-faa47b56-f8c8-11e8-b559-c27407a18179" in namespace "e2e-tests-projected-qwfjb" to be "success or failure"
Dec  5 20:04:31.711: INFO: Pod "downwardapi-volume-faa47b56-f8c8-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.658935ms
Dec  5 20:04:33.715: INFO: Pod "downwardapi-volume-faa47b56-f8c8-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006582899s
STEP: Saw pod success
Dec  5 20:04:33.715: INFO: Pod "downwardapi-volume-faa47b56-f8c8-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 20:04:33.718: INFO: Trying to get logs from node ip-172-31-2-231 pod downwardapi-volume-faa47b56-f8c8-11e8-b559-c27407a18179 container client-container: <nil>
STEP: delete the pod
Dec  5 20:04:33.734: INFO: Waiting for pod downwardapi-volume-faa47b56-f8c8-11e8-b559-c27407a18179 to disappear
Dec  5 20:04:33.737: INFO: Pod downwardapi-volume-faa47b56-f8c8-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:04:33.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qwfjb" for this suite.
Dec  5 20:04:39.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:04:39.842: INFO: namespace: e2e-tests-projected-qwfjb, resource: bindings, ignored listing per whitelist
Dec  5 20:04:39.847: INFO: namespace e2e-tests-projected-qwfjb deletion completed in 6.107658174s

• [SLOW TEST:8.270 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:04:39.847: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec  5 20:04:40.631: INFO: Waiting up to 5m0s for pod "pod-fff5f449-f8c8-11e8-b559-c27407a18179" in namespace "e2e-tests-emptydir-dsnw6" to be "success or failure"
Dec  5 20:04:40.634: INFO: Pod "pod-fff5f449-f8c8-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.878174ms
Dec  5 20:04:42.637: INFO: Pod "pod-fff5f449-f8c8-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00600418s
Dec  5 20:04:44.640: INFO: Pod "pod-fff5f449-f8c8-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008966917s
STEP: Saw pod success
Dec  5 20:04:44.640: INFO: Pod "pod-fff5f449-f8c8-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 20:04:44.643: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-fff5f449-f8c8-11e8-b559-c27407a18179 container test-container: <nil>
STEP: delete the pod
Dec  5 20:04:44.661: INFO: Waiting for pod pod-fff5f449-f8c8-11e8-b559-c27407a18179 to disappear
Dec  5 20:04:44.663: INFO: Pod pod-fff5f449-f8c8-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:04:44.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-dsnw6" for this suite.
Dec  5 20:04:50.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:04:50.711: INFO: namespace: e2e-tests-emptydir-dsnw6, resource: bindings, ignored listing per whitelist
Dec  5 20:04:50.775: INFO: namespace e2e-tests-emptydir-dsnw6 deletion completed in 6.108694836s

• [SLOW TEST:10.928 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:04:50.775: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Dec  5 20:04:51.014: INFO: Pod name wrapped-volume-race-062522d2-f8c9-11e8-b559-c27407a18179: Found 0 pods out of 5
Dec  5 20:04:56.020: INFO: Pod name wrapped-volume-race-062522d2-f8c9-11e8-b559-c27407a18179: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-062522d2-f8c9-11e8-b559-c27407a18179 in namespace e2e-tests-emptydir-wrapper-h29kb, will wait for the garbage collector to delete the pods
Dec  5 20:05:08.416: INFO: Deleting ReplicationController wrapped-volume-race-062522d2-f8c9-11e8-b559-c27407a18179 took: 10.638117ms
Dec  5 20:05:08.517: INFO: Terminating ReplicationController wrapped-volume-race-062522d2-f8c9-11e8-b559-c27407a18179 pods took: 100.255738ms
STEP: Creating RC which spawns configmap-volume pods
Dec  5 20:05:51.633: INFO: Pod name wrapped-volume-race-2a467038-f8c9-11e8-b559-c27407a18179: Found 0 pods out of 5
Dec  5 20:05:56.638: INFO: Pod name wrapped-volume-race-2a467038-f8c9-11e8-b559-c27407a18179: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-2a467038-f8c9-11e8-b559-c27407a18179 in namespace e2e-tests-emptydir-wrapper-h29kb, will wait for the garbage collector to delete the pods
Dec  5 20:06:08.719: INFO: Deleting ReplicationController wrapped-volume-race-2a467038-f8c9-11e8-b559-c27407a18179 took: 12.419163ms
Dec  5 20:06:08.819: INFO: Terminating ReplicationController wrapped-volume-race-2a467038-f8c9-11e8-b559-c27407a18179 pods took: 100.222495ms
STEP: Creating RC which spawns configmap-volume pods
Dec  5 20:06:51.035: INFO: Pod name wrapped-volume-race-4dae907c-f8c9-11e8-b559-c27407a18179: Found 0 pods out of 5
Dec  5 20:06:56.041: INFO: Pod name wrapped-volume-race-4dae907c-f8c9-11e8-b559-c27407a18179: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-4dae907c-f8c9-11e8-b559-c27407a18179 in namespace e2e-tests-emptydir-wrapper-h29kb, will wait for the garbage collector to delete the pods
Dec  5 20:07:10.126: INFO: Deleting ReplicationController wrapped-volume-race-4dae907c-f8c9-11e8-b559-c27407a18179 took: 7.818054ms
Dec  5 20:07:10.226: INFO: Terminating ReplicationController wrapped-volume-race-4dae907c-f8c9-11e8-b559-c27407a18179 pods took: 100.212428ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:07:51.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-h29kb" for this suite.
Dec  5 20:07:59.938: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:08:00.023: INFO: namespace: e2e-tests-emptydir-wrapper-h29kb, resource: bindings, ignored listing per whitelist
Dec  5 20:08:00.084: INFO: namespace e2e-tests-emptydir-wrapper-h29kb deletion completed in 8.160200025s

• [SLOW TEST:189.309 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:08:00.084: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-76e0eaaf-f8c9-11e8-b559-c27407a18179
STEP: Creating a pod to test consume secrets
Dec  5 20:08:00.146: INFO: Waiting up to 5m0s for pod "pod-secrets-76e17a8d-f8c9-11e8-b559-c27407a18179" in namespace "e2e-tests-secrets-zkkd6" to be "success or failure"
Dec  5 20:08:00.149: INFO: Pod "pod-secrets-76e17a8d-f8c9-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.880395ms
Dec  5 20:08:02.153: INFO: Pod "pod-secrets-76e17a8d-f8c9-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0069516s
STEP: Saw pod success
Dec  5 20:08:02.153: INFO: Pod "pod-secrets-76e17a8d-f8c9-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 20:08:02.157: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-secrets-76e17a8d-f8c9-11e8-b559-c27407a18179 container secret-env-test: <nil>
STEP: delete the pod
Dec  5 20:08:02.178: INFO: Waiting for pod pod-secrets-76e17a8d-f8c9-11e8-b559-c27407a18179 to disappear
Dec  5 20:08:02.180: INFO: Pod pod-secrets-76e17a8d-f8c9-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:08:02.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-zkkd6" for this suite.
Dec  5 20:08:08.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:08:08.274: INFO: namespace: e2e-tests-secrets-zkkd6, resource: bindings, ignored listing per whitelist
Dec  5 20:08:08.306: INFO: namespace e2e-tests-secrets-zkkd6 deletion completed in 6.12235192s

• [SLOW TEST:8.222 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:08:08.306: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-8jdwr/configmap-test-7bc9418f-f8c9-11e8-b559-c27407a18179
STEP: Creating a pod to test consume configMaps
Dec  5 20:08:08.381: INFO: Waiting up to 5m0s for pod "pod-configmaps-7bca0340-f8c9-11e8-b559-c27407a18179" in namespace "e2e-tests-configmap-8jdwr" to be "success or failure"
Dec  5 20:08:08.384: INFO: Pod "pod-configmaps-7bca0340-f8c9-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.723098ms
Dec  5 20:08:10.387: INFO: Pod "pod-configmaps-7bca0340-f8c9-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00624428s
STEP: Saw pod success
Dec  5 20:08:10.387: INFO: Pod "pod-configmaps-7bca0340-f8c9-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 20:08:10.390: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-configmaps-7bca0340-f8c9-11e8-b559-c27407a18179 container env-test: <nil>
STEP: delete the pod
Dec  5 20:08:10.407: INFO: Waiting for pod pod-configmaps-7bca0340-f8c9-11e8-b559-c27407a18179 to disappear
Dec  5 20:08:10.410: INFO: Pod pod-configmaps-7bca0340-f8c9-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:08:10.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-8jdwr" for this suite.
Dec  5 20:08:16.423: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:08:16.471: INFO: namespace: e2e-tests-configmap-8jdwr, resource: bindings, ignored listing per whitelist
Dec  5 20:08:16.544: INFO: namespace e2e-tests-configmap-8jdwr deletion completed in 6.131135109s

• [SLOW TEST:8.238 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:08:16.544: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec  5 20:08:16.622: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:08:19.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-wjn2s" for this suite.
Dec  5 20:08:25.769: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:08:25.823: INFO: namespace: e2e-tests-init-container-wjn2s, resource: bindings, ignored listing per whitelist
Dec  5 20:08:25.859: INFO: namespace e2e-tests-init-container-wjn2s deletion completed in 6.1016229s

• [SLOW TEST:9.315 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:08:25.859: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 20:08:25.930: INFO: Waiting up to 5m0s for pod "downwardapi-volume-863fad3f-f8c9-11e8-b559-c27407a18179" in namespace "e2e-tests-downward-api-rbspv" to be "success or failure"
Dec  5 20:08:25.933: INFO: Pod "downwardapi-volume-863fad3f-f8c9-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 3.110887ms
Dec  5 20:08:27.937: INFO: Pod "downwardapi-volume-863fad3f-f8c9-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006868413s
STEP: Saw pod success
Dec  5 20:08:27.937: INFO: Pod "downwardapi-volume-863fad3f-f8c9-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 20:08:27.939: INFO: Trying to get logs from node ip-172-31-24-193 pod downwardapi-volume-863fad3f-f8c9-11e8-b559-c27407a18179 container client-container: <nil>
STEP: delete the pod
Dec  5 20:08:27.971: INFO: Waiting for pod downwardapi-volume-863fad3f-f8c9-11e8-b559-c27407a18179 to disappear
Dec  5 20:08:27.973: INFO: Pod downwardapi-volume-863fad3f-f8c9-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:08:27.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rbspv" for this suite.
Dec  5 20:08:33.987: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:08:34.012: INFO: namespace: e2e-tests-downward-api-rbspv, resource: bindings, ignored listing per whitelist
Dec  5 20:08:34.135: INFO: namespace e2e-tests-downward-api-rbspv deletion completed in 6.158827415s

• [SLOW TEST:8.276 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:08:34.135: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec  5 20:08:34.220: INFO: Number of nodes with available pods: 0
Dec  5 20:08:34.220: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 20:08:35.227: INFO: Number of nodes with available pods: 0
Dec  5 20:08:35.227: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 20:08:36.334: INFO: Number of nodes with available pods: 1
Dec  5 20:08:36.334: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 20:08:37.227: INFO: Number of nodes with available pods: 2
Dec  5 20:08:37.227: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 20:08:38.227: INFO: Number of nodes with available pods: 3
Dec  5 20:08:38.227: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Dec  5 20:08:38.244: INFO: Number of nodes with available pods: 2
Dec  5 20:08:38.244: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:08:39.251: INFO: Number of nodes with available pods: 2
Dec  5 20:08:39.251: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:08:40.251: INFO: Number of nodes with available pods: 2
Dec  5 20:08:40.251: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:08:41.252: INFO: Number of nodes with available pods: 2
Dec  5 20:08:41.252: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:08:42.251: INFO: Number of nodes with available pods: 2
Dec  5 20:08:42.252: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:08:43.252: INFO: Number of nodes with available pods: 2
Dec  5 20:08:43.252: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:08:44.251: INFO: Number of nodes with available pods: 2
Dec  5 20:08:44.251: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:08:45.251: INFO: Number of nodes with available pods: 2
Dec  5 20:08:45.251: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:08:46.251: INFO: Number of nodes with available pods: 2
Dec  5 20:08:46.251: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:08:47.251: INFO: Number of nodes with available pods: 2
Dec  5 20:08:47.251: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:08:48.251: INFO: Number of nodes with available pods: 2
Dec  5 20:08:48.251: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:08:49.252: INFO: Number of nodes with available pods: 2
Dec  5 20:08:49.252: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:08:50.252: INFO: Number of nodes with available pods: 2
Dec  5 20:08:50.252: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:08:51.423: INFO: Number of nodes with available pods: 2
Dec  5 20:08:51.423: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:08:52.251: INFO: Number of nodes with available pods: 2
Dec  5 20:08:52.251: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:08:53.251: INFO: Number of nodes with available pods: 2
Dec  5 20:08:53.251: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:08:54.251: INFO: Number of nodes with available pods: 2
Dec  5 20:08:54.251: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:08:55.251: INFO: Number of nodes with available pods: 2
Dec  5 20:08:55.251: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:08:56.255: INFO: Number of nodes with available pods: 2
Dec  5 20:08:56.255: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:08:57.254: INFO: Number of nodes with available pods: 2
Dec  5 20:08:57.254: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:08:58.251: INFO: Number of nodes with available pods: 2
Dec  5 20:08:58.251: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:08:59.255: INFO: Number of nodes with available pods: 2
Dec  5 20:08:59.255: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:09:00.251: INFO: Number of nodes with available pods: 2
Dec  5 20:09:00.251: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:09:01.251: INFO: Number of nodes with available pods: 2
Dec  5 20:09:01.251: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:09:02.253: INFO: Number of nodes with available pods: 2
Dec  5 20:09:02.253: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:09:03.251: INFO: Number of nodes with available pods: 2
Dec  5 20:09:03.251: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:09:04.253: INFO: Number of nodes with available pods: 2
Dec  5 20:09:04.253: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:09:05.251: INFO: Number of nodes with available pods: 2
Dec  5 20:09:05.251: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:09:06.251: INFO: Number of nodes with available pods: 2
Dec  5 20:09:06.251: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:09:07.252: INFO: Number of nodes with available pods: 2
Dec  5 20:09:07.252: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:09:08.252: INFO: Number of nodes with available pods: 2
Dec  5 20:09:08.252: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:09:09.252: INFO: Number of nodes with available pods: 2
Dec  5 20:09:09.252: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:09:10.251: INFO: Number of nodes with available pods: 2
Dec  5 20:09:10.251: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:09:11.251: INFO: Number of nodes with available pods: 2
Dec  5 20:09:11.251: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:09:12.251: INFO: Number of nodes with available pods: 2
Dec  5 20:09:12.251: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:09:13.251: INFO: Number of nodes with available pods: 2
Dec  5 20:09:13.251: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:09:14.251: INFO: Number of nodes with available pods: 2
Dec  5 20:09:14.251: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:09:15.252: INFO: Number of nodes with available pods: 2
Dec  5 20:09:15.252: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:09:16.251: INFO: Number of nodes with available pods: 2
Dec  5 20:09:16.251: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:09:17.251: INFO: Number of nodes with available pods: 2
Dec  5 20:09:17.251: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:09:18.251: INFO: Number of nodes with available pods: 2
Dec  5 20:09:18.251: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:09:19.251: INFO: Number of nodes with available pods: 2
Dec  5 20:09:19.251: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:09:20.251: INFO: Number of nodes with available pods: 2
Dec  5 20:09:20.251: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:09:21.252: INFO: Number of nodes with available pods: 2
Dec  5 20:09:21.252: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:09:22.251: INFO: Number of nodes with available pods: 3
Dec  5 20:09:22.251: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-r47lg, will wait for the garbage collector to delete the pods
Dec  5 20:09:22.314: INFO: Deleting DaemonSet.extensions daemon-set took: 7.200955ms
Dec  5 20:09:22.414: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.185481ms
Dec  5 20:09:56.217: INFO: Number of nodes with available pods: 0
Dec  5 20:09:56.217: INFO: Number of running nodes: 0, number of available pods: 0
Dec  5 20:09:56.222: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-r47lg/daemonsets","resourceVersion":"10255"},"items":null}

Dec  5 20:09:56.225: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-r47lg/pods","resourceVersion":"10255"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:09:56.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-r47lg" for this suite.
Dec  5 20:10:02.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:10:02.491: INFO: namespace: e2e-tests-daemonsets-r47lg, resource: bindings, ignored listing per whitelist
Dec  5 20:10:02.528: INFO: namespace e2e-tests-daemonsets-r47lg deletion completed in 6.283112265s

• [SLOW TEST:88.393 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:10:02.528: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Dec  5 20:10:02.733: INFO: Waiting up to 5m0s for pod "client-containers-bff0676f-f8c9-11e8-b559-c27407a18179" in namespace "e2e-tests-containers-qlkxg" to be "success or failure"
Dec  5 20:10:02.749: INFO: Pod "client-containers-bff0676f-f8c9-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 16.214393ms
Dec  5 20:10:04.753: INFO: Pod "client-containers-bff0676f-f8c9-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020095218s
Dec  5 20:10:06.757: INFO: Pod "client-containers-bff0676f-f8c9-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024332338s
STEP: Saw pod success
Dec  5 20:10:06.757: INFO: Pod "client-containers-bff0676f-f8c9-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 20:10:06.761: INFO: Trying to get logs from node ip-172-31-24-193 pod client-containers-bff0676f-f8c9-11e8-b559-c27407a18179 container test-container: <nil>
STEP: delete the pod
Dec  5 20:10:06.789: INFO: Waiting for pod client-containers-bff0676f-f8c9-11e8-b559-c27407a18179 to disappear
Dec  5 20:10:06.791: INFO: Pod client-containers-bff0676f-f8c9-11e8-b559-c27407a18179 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:10:06.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-qlkxg" for this suite.
Dec  5 20:10:12.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:10:12.947: INFO: namespace: e2e-tests-containers-qlkxg, resource: bindings, ignored listing per whitelist
Dec  5 20:10:13.006: INFO: namespace e2e-tests-containers-qlkxg deletion completed in 6.209701451s

• [SLOW TEST:10.477 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:10:13.006: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec  5 20:10:13.126: INFO: Waiting up to 5m0s for pod "pod-c624aca0-f8c9-11e8-b559-c27407a18179" in namespace "e2e-tests-emptydir-wtsxd" to be "success or failure"
Dec  5 20:10:13.130: INFO: Pod "pod-c624aca0-f8c9-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 3.769672ms
Dec  5 20:10:15.133: INFO: Pod "pod-c624aca0-f8c9-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007020705s
Dec  5 20:10:17.137: INFO: Pod "pod-c624aca0-f8c9-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01073573s
STEP: Saw pod success
Dec  5 20:10:17.137: INFO: Pod "pod-c624aca0-f8c9-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 20:10:17.140: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-c624aca0-f8c9-11e8-b559-c27407a18179 container test-container: <nil>
STEP: delete the pod
Dec  5 20:10:17.156: INFO: Waiting for pod pod-c624aca0-f8c9-11e8-b559-c27407a18179 to disappear
Dec  5 20:10:17.159: INFO: Pod pod-c624aca0-f8c9-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:10:17.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wtsxd" for this suite.
Dec  5 20:10:23.172: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:10:23.225: INFO: namespace: e2e-tests-emptydir-wtsxd, resource: bindings, ignored listing per whitelist
Dec  5 20:10:23.283: INFO: namespace e2e-tests-emptydir-wtsxd deletion completed in 6.121700588s

• [SLOW TEST:10.277 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:10:23.283: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W1205 20:10:33.361703      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  5 20:10:33.361: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:10:33.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-bj78p" for this suite.
Dec  5 20:10:39.533: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:10:39.571: INFO: namespace: e2e-tests-gc-bj78p, resource: bindings, ignored listing per whitelist
Dec  5 20:10:39.640: INFO: namespace e2e-tests-gc-bj78p deletion completed in 6.275452914s

• [SLOW TEST:16.356 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:10:39.640: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 20:10:39.713: INFO: Creating ReplicaSet my-hostname-basic-d5fe6a5f-f8c9-11e8-b559-c27407a18179
Dec  5 20:10:39.721: INFO: Pod name my-hostname-basic-d5fe6a5f-f8c9-11e8-b559-c27407a18179: Found 0 pods out of 1
Dec  5 20:10:44.725: INFO: Pod name my-hostname-basic-d5fe6a5f-f8c9-11e8-b559-c27407a18179: Found 1 pods out of 1
Dec  5 20:10:44.725: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-d5fe6a5f-f8c9-11e8-b559-c27407a18179" is running
Dec  5 20:10:44.728: INFO: Pod "my-hostname-basic-d5fe6a5f-f8c9-11e8-b559-c27407a18179-f8dnh" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-05 20:10:39 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-05 20:10:41 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-05 20:10:41 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-05 20:10:39 +0000 UTC Reason: Message:}])
Dec  5 20:10:44.728: INFO: Trying to dial the pod
Dec  5 20:10:49.739: INFO: Controller my-hostname-basic-d5fe6a5f-f8c9-11e8-b559-c27407a18179: Got expected result from replica 1 [my-hostname-basic-d5fe6a5f-f8c9-11e8-b559-c27407a18179-f8dnh]: "my-hostname-basic-d5fe6a5f-f8c9-11e8-b559-c27407a18179-f8dnh", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:10:49.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-7hz2d" for this suite.
Dec  5 20:10:55.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:10:55.851: INFO: namespace: e2e-tests-replicaset-7hz2d, resource: bindings, ignored listing per whitelist
Dec  5 20:10:55.851: INFO: namespace e2e-tests-replicaset-7hz2d deletion completed in 6.107814974s

• [SLOW TEST:16.211 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:10:55.851: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 20:10:55.911: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dfa4ad68-f8c9-11e8-b559-c27407a18179" in namespace "e2e-tests-projected-xhc6q" to be "success or failure"
Dec  5 20:10:55.915: INFO: Pod "downwardapi-volume-dfa4ad68-f8c9-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 4.055111ms
Dec  5 20:10:57.919: INFO: Pod "downwardapi-volume-dfa4ad68-f8c9-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008366299s
Dec  5 20:10:59.923: INFO: Pod "downwardapi-volume-dfa4ad68-f8c9-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011855783s
STEP: Saw pod success
Dec  5 20:10:59.923: INFO: Pod "downwardapi-volume-dfa4ad68-f8c9-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 20:10:59.927: INFO: Trying to get logs from node ip-172-31-24-193 pod downwardapi-volume-dfa4ad68-f8c9-11e8-b559-c27407a18179 container client-container: <nil>
STEP: delete the pod
Dec  5 20:10:59.945: INFO: Waiting for pod downwardapi-volume-dfa4ad68-f8c9-11e8-b559-c27407a18179 to disappear
Dec  5 20:10:59.948: INFO: Pod downwardapi-volume-dfa4ad68-f8c9-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:10:59.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xhc6q" for this suite.
Dec  5 20:11:05.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:11:06.010: INFO: namespace: e2e-tests-projected-xhc6q, resource: bindings, ignored listing per whitelist
Dec  5 20:11:06.069: INFO: namespace e2e-tests-projected-xhc6q deletion completed in 6.117925587s

• [SLOW TEST:10.218 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:11:06.069: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec  5 20:11:10.690: INFO: Successfully updated pod "pod-update-e5c20a26-f8c9-11e8-b559-c27407a18179"
STEP: verifying the updated pod is in kubernetes
Dec  5 20:11:10.697: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:11:10.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-h7qbd" for this suite.
Dec  5 20:11:32.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:11:32.748: INFO: namespace: e2e-tests-pods-h7qbd, resource: bindings, ignored listing per whitelist
Dec  5 20:11:32.799: INFO: namespace e2e-tests-pods-h7qbd deletion completed in 22.099275133s

• [SLOW TEST:26.730 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:11:32.800: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Dec  5 20:11:36.890: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:12:00.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-s5bq9" for this suite.
Dec  5 20:12:06.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:12:06.997: INFO: namespace: e2e-tests-namespaces-s5bq9, resource: bindings, ignored listing per whitelist
Dec  5 20:12:07.037: INFO: namespace e2e-tests-namespaces-s5bq9 deletion completed in 6.107281178s
STEP: Destroying namespace "e2e-tests-nsdeletetest-vgvwz" for this suite.
Dec  5 20:12:07.039: INFO: Namespace e2e-tests-nsdeletetest-vgvwz was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-pzkj5" for this suite.
Dec  5 20:12:13.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:12:13.070: INFO: namespace: e2e-tests-nsdeletetest-pzkj5, resource: bindings, ignored listing per whitelist
Dec  5 20:12:13.245: INFO: namespace e2e-tests-nsdeletetest-pzkj5 deletion completed in 6.205828931s

• [SLOW TEST:40.445 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:12:13.245: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 20:12:13.353: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0dcd649d-f8ca-11e8-b559-c27407a18179" in namespace "e2e-tests-downward-api-2mk9g" to be "success or failure"
Dec  5 20:12:13.357: INFO: Pod "downwardapi-volume-0dcd649d-f8ca-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 3.41532ms
Dec  5 20:12:15.360: INFO: Pod "downwardapi-volume-0dcd649d-f8ca-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00676011s
Dec  5 20:12:17.364: INFO: Pod "downwardapi-volume-0dcd649d-f8ca-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010244337s
STEP: Saw pod success
Dec  5 20:12:17.364: INFO: Pod "downwardapi-volume-0dcd649d-f8ca-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 20:12:17.367: INFO: Trying to get logs from node ip-172-31-24-193 pod downwardapi-volume-0dcd649d-f8ca-11e8-b559-c27407a18179 container client-container: <nil>
STEP: delete the pod
Dec  5 20:12:17.383: INFO: Waiting for pod downwardapi-volume-0dcd649d-f8ca-11e8-b559-c27407a18179 to disappear
Dec  5 20:12:17.386: INFO: Pod downwardapi-volume-0dcd649d-f8ca-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:12:17.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2mk9g" for this suite.
Dec  5 20:12:23.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:12:23.424: INFO: namespace: e2e-tests-downward-api-2mk9g, resource: bindings, ignored listing per whitelist
Dec  5 20:12:23.493: INFO: namespace e2e-tests-downward-api-2mk9g deletion completed in 6.104953653s

• [SLOW TEST:10.248 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:12:23.494: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Dec  5 20:12:23.614: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-bpwhd,SelfLink:/api/v1/namespaces/e2e-tests-watch-bpwhd/configmaps/e2e-watch-test-watch-closed,UID:13dde96e-f8ca-11e8-b622-12e7eb78a7a2,ResourceVersion:10793,Generation:0,CreationTimestamp:2018-12-05 20:12:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  5 20:12:23.614: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-bpwhd,SelfLink:/api/v1/namespaces/e2e-tests-watch-bpwhd/configmaps/e2e-watch-test-watch-closed,UID:13dde96e-f8ca-11e8-b622-12e7eb78a7a2,ResourceVersion:10794,Generation:0,CreationTimestamp:2018-12-05 20:12:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Dec  5 20:12:23.646: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-bpwhd,SelfLink:/api/v1/namespaces/e2e-tests-watch-bpwhd/configmaps/e2e-watch-test-watch-closed,UID:13dde96e-f8ca-11e8-b622-12e7eb78a7a2,ResourceVersion:10795,Generation:0,CreationTimestamp:2018-12-05 20:12:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  5 20:12:23.646: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-bpwhd,SelfLink:/api/v1/namespaces/e2e-tests-watch-bpwhd/configmaps/e2e-watch-test-watch-closed,UID:13dde96e-f8ca-11e8-b622-12e7eb78a7a2,ResourceVersion:10796,Generation:0,CreationTimestamp:2018-12-05 20:12:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:12:23.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-bpwhd" for this suite.
Dec  5 20:12:29.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:12:29.766: INFO: namespace: e2e-tests-watch-bpwhd, resource: bindings, ignored listing per whitelist
Dec  5 20:12:29.780: INFO: namespace e2e-tests-watch-bpwhd deletion completed in 6.131302974s

• [SLOW TEST:6.287 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:12:29.781: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec  5 20:12:29.906: INFO: Waiting up to 5m0s for pod "pod-17ab4b09-f8ca-11e8-b559-c27407a18179" in namespace "e2e-tests-emptydir-rqzj4" to be "success or failure"
Dec  5 20:12:29.914: INFO: Pod "pod-17ab4b09-f8ca-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 7.099668ms
Dec  5 20:12:31.917: INFO: Pod "pod-17ab4b09-f8ca-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010672459s
Dec  5 20:12:33.921: INFO: Pod "pod-17ab4b09-f8ca-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014124442s
STEP: Saw pod success
Dec  5 20:12:33.921: INFO: Pod "pod-17ab4b09-f8ca-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 20:12:33.923: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-17ab4b09-f8ca-11e8-b559-c27407a18179 container test-container: <nil>
STEP: delete the pod
Dec  5 20:12:33.941: INFO: Waiting for pod pod-17ab4b09-f8ca-11e8-b559-c27407a18179 to disappear
Dec  5 20:12:33.943: INFO: Pod pod-17ab4b09-f8ca-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:12:33.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-rqzj4" for this suite.
Dec  5 20:12:39.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:12:40.071: INFO: namespace: e2e-tests-emptydir-rqzj4, resource: bindings, ignored listing per whitelist
Dec  5 20:12:40.084: INFO: namespace e2e-tests-emptydir-rqzj4 deletion completed in 6.138040646s

• [SLOW TEST:10.303 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:12:40.084: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W1205 20:13:20.261853      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  5 20:13:20.261: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:13:20.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-6p8dg" for this suite.
Dec  5 20:13:26.278: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:13:26.406: INFO: namespace: e2e-tests-gc-6p8dg, resource: bindings, ignored listing per whitelist
Dec  5 20:13:26.437: INFO: namespace e2e-tests-gc-6p8dg deletion completed in 6.17182994s

• [SLOW TEST:46.353 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:13:26.437: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 20:13:26.496: INFO: Waiting up to 5m0s for pod "downwardapi-volume-396656e4-f8ca-11e8-b559-c27407a18179" in namespace "e2e-tests-projected-cbpqd" to be "success or failure"
Dec  5 20:13:26.500: INFO: Pod "downwardapi-volume-396656e4-f8ca-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 4.2807ms
Dec  5 20:13:28.504: INFO: Pod "downwardapi-volume-396656e4-f8ca-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008361752s
Dec  5 20:13:30.508: INFO: Pod "downwardapi-volume-396656e4-f8ca-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01196744s
Dec  5 20:13:32.513: INFO: Pod "downwardapi-volume-396656e4-f8ca-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.017474204s
STEP: Saw pod success
Dec  5 20:13:32.513: INFO: Pod "downwardapi-volume-396656e4-f8ca-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 20:13:32.518: INFO: Trying to get logs from node ip-172-31-24-193 pod downwardapi-volume-396656e4-f8ca-11e8-b559-c27407a18179 container client-container: <nil>
STEP: delete the pod
Dec  5 20:13:32.540: INFO: Waiting for pod downwardapi-volume-396656e4-f8ca-11e8-b559-c27407a18179 to disappear
Dec  5 20:13:32.542: INFO: Pod downwardapi-volume-396656e4-f8ca-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:13:32.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cbpqd" for this suite.
Dec  5 20:13:38.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:13:38.570: INFO: namespace: e2e-tests-projected-cbpqd, resource: bindings, ignored listing per whitelist
Dec  5 20:13:38.654: INFO: namespace e2e-tests-projected-cbpqd deletion completed in 6.109153796s

• [SLOW TEST:12.217 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:13:38.654: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-40ba67b4-f8ca-11e8-b559-c27407a18179
STEP: Creating a pod to test consume secrets
Dec  5 20:13:38.795: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-40bb02b2-f8ca-11e8-b559-c27407a18179" in namespace "e2e-tests-projected-jq5bk" to be "success or failure"
Dec  5 20:13:38.799: INFO: Pod "pod-projected-secrets-40bb02b2-f8ca-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 3.280519ms
Dec  5 20:13:40.802: INFO: Pod "pod-projected-secrets-40bb02b2-f8ca-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007004314s
STEP: Saw pod success
Dec  5 20:13:40.803: INFO: Pod "pod-projected-secrets-40bb02b2-f8ca-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 20:13:40.805: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-projected-secrets-40bb02b2-f8ca-11e8-b559-c27407a18179 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  5 20:13:40.822: INFO: Waiting for pod pod-projected-secrets-40bb02b2-f8ca-11e8-b559-c27407a18179 to disappear
Dec  5 20:13:40.824: INFO: Pod pod-projected-secrets-40bb02b2-f8ca-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:13:40.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jq5bk" for this suite.
Dec  5 20:13:46.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:13:46.922: INFO: namespace: e2e-tests-projected-jq5bk, resource: bindings, ignored listing per whitelist
Dec  5 20:13:46.964: INFO: namespace e2e-tests-projected-jq5bk deletion completed in 6.135593572s

• [SLOW TEST:8.310 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:13:46.964: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Dec  5 20:13:47.037: INFO: Waiting up to 5m0s for pod "pod-45a4b4b3-f8ca-11e8-b559-c27407a18179" in namespace "e2e-tests-emptydir-glljq" to be "success or failure"
Dec  5 20:13:47.039: INFO: Pod "pod-45a4b4b3-f8ca-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.832634ms
Dec  5 20:13:49.044: INFO: Pod "pod-45a4b4b3-f8ca-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007049477s
Dec  5 20:13:51.047: INFO: Pod "pod-45a4b4b3-f8ca-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010706971s
STEP: Saw pod success
Dec  5 20:13:51.047: INFO: Pod "pod-45a4b4b3-f8ca-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 20:13:51.050: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-45a4b4b3-f8ca-11e8-b559-c27407a18179 container test-container: <nil>
STEP: delete the pod
Dec  5 20:13:51.068: INFO: Waiting for pod pod-45a4b4b3-f8ca-11e8-b559-c27407a18179 to disappear
Dec  5 20:13:51.070: INFO: Pod pod-45a4b4b3-f8ca-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:13:51.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-glljq" for this suite.
Dec  5 20:13:57.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:13:57.160: INFO: namespace: e2e-tests-emptydir-glljq, resource: bindings, ignored listing per whitelist
Dec  5 20:13:57.180: INFO: namespace e2e-tests-emptydir-glljq deletion completed in 6.106830862s

• [SLOW TEST:10.216 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:13:57.180: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Dec  5 20:13:57.263: INFO: Waiting up to 5m0s for pod "client-containers-4bbd18cf-f8ca-11e8-b559-c27407a18179" in namespace "e2e-tests-containers-gv7gs" to be "success or failure"
Dec  5 20:13:57.267: INFO: Pod "client-containers-4bbd18cf-f8ca-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 4.032527ms
Dec  5 20:13:59.271: INFO: Pod "client-containers-4bbd18cf-f8ca-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008224967s
Dec  5 20:14:01.275: INFO: Pod "client-containers-4bbd18cf-f8ca-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011930455s
STEP: Saw pod success
Dec  5 20:14:01.275: INFO: Pod "client-containers-4bbd18cf-f8ca-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 20:14:01.279: INFO: Trying to get logs from node ip-172-31-24-193 pod client-containers-4bbd18cf-f8ca-11e8-b559-c27407a18179 container test-container: <nil>
STEP: delete the pod
Dec  5 20:14:01.300: INFO: Waiting for pod client-containers-4bbd18cf-f8ca-11e8-b559-c27407a18179 to disappear
Dec  5 20:14:01.303: INFO: Pod client-containers-4bbd18cf-f8ca-11e8-b559-c27407a18179 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:14:01.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-gv7gs" for this suite.
Dec  5 20:14:07.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:14:07.343: INFO: namespace: e2e-tests-containers-gv7gs, resource: bindings, ignored listing per whitelist
Dec  5 20:14:07.428: INFO: namespace e2e-tests-containers-gv7gs deletion completed in 6.1215959s

• [SLOW TEST:10.248 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:14:07.428: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec  5 20:14:07.562: INFO: Waiting up to 5m0s for pod "pod-51df1538-f8ca-11e8-b559-c27407a18179" in namespace "e2e-tests-emptydir-dxwcv" to be "success or failure"
Dec  5 20:14:07.566: INFO: Pod "pod-51df1538-f8ca-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 3.784744ms
Dec  5 20:14:09.570: INFO: Pod "pod-51df1538-f8ca-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008364s
Dec  5 20:14:11.574: INFO: Pod "pod-51df1538-f8ca-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011709754s
STEP: Saw pod success
Dec  5 20:14:11.574: INFO: Pod "pod-51df1538-f8ca-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 20:14:11.576: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-51df1538-f8ca-11e8-b559-c27407a18179 container test-container: <nil>
STEP: delete the pod
Dec  5 20:14:11.595: INFO: Waiting for pod pod-51df1538-f8ca-11e8-b559-c27407a18179 to disappear
Dec  5 20:14:11.598: INFO: Pod pod-51df1538-f8ca-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:14:11.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-dxwcv" for this suite.
Dec  5 20:14:17.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:14:17.655: INFO: namespace: e2e-tests-emptydir-dxwcv, resource: bindings, ignored listing per whitelist
Dec  5 20:14:17.830: INFO: namespace e2e-tests-emptydir-dxwcv deletion completed in 6.228588558s

• [SLOW TEST:10.402 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:14:17.830: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Dec  5 20:14:17.889: INFO: Waiting up to 5m0s for pod "pod-58086f7c-f8ca-11e8-b559-c27407a18179" in namespace "e2e-tests-emptydir-c8td6" to be "success or failure"
Dec  5 20:14:17.892: INFO: Pod "pod-58086f7c-f8ca-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.658677ms
Dec  5 20:14:19.896: INFO: Pod "pod-58086f7c-f8ca-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006809152s
Dec  5 20:14:21.899: INFO: Pod "pod-58086f7c-f8ca-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010216714s
STEP: Saw pod success
Dec  5 20:14:21.899: INFO: Pod "pod-58086f7c-f8ca-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 20:14:21.902: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-58086f7c-f8ca-11e8-b559-c27407a18179 container test-container: <nil>
STEP: delete the pod
Dec  5 20:14:21.918: INFO: Waiting for pod pod-58086f7c-f8ca-11e8-b559-c27407a18179 to disappear
Dec  5 20:14:21.921: INFO: Pod pod-58086f7c-f8ca-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:14:21.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-c8td6" for this suite.
Dec  5 20:14:27.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:14:27.949: INFO: namespace: e2e-tests-emptydir-c8td6, resource: bindings, ignored listing per whitelist
Dec  5 20:14:28.044: INFO: namespace e2e-tests-emptydir-c8td6 deletion completed in 6.120418807s

• [SLOW TEST:10.213 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:14:28.044: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec  5 20:14:34.138: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 20:14:34.141: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 20:14:36.141: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 20:14:36.145: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 20:14:38.141: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 20:14:38.145: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 20:14:40.141: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 20:14:40.145: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 20:14:42.141: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 20:14:42.145: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 20:14:44.141: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 20:14:44.145: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 20:14:46.141: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 20:14:46.145: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 20:14:48.141: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 20:14:48.147: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 20:14:50.141: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 20:14:50.145: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 20:14:52.141: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 20:14:52.145: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 20:14:54.141: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 20:14:54.148: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 20:14:56.141: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 20:14:56.145: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 20:14:58.141: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 20:14:58.145: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 20:15:00.141: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 20:15:00.145: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 20:15:02.141: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 20:15:02.145: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 20:15:04.141: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 20:15:04.145: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:15:04.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-mfpbh" for this suite.
Dec  5 20:15:26.170: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:15:26.223: INFO: namespace: e2e-tests-container-lifecycle-hook-mfpbh, resource: bindings, ignored listing per whitelist
Dec  5 20:15:26.270: INFO: namespace e2e-tests-container-lifecycle-hook-mfpbh deletion completed in 22.112488461s

• [SLOW TEST:58.226 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:15:26.270: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-80d42ee4-f8ca-11e8-b559-c27407a18179
STEP: Creating a pod to test consume configMaps
Dec  5 20:15:26.337: INFO: Waiting up to 5m0s for pod "pod-configmaps-80d4ba2a-f8ca-11e8-b559-c27407a18179" in namespace "e2e-tests-configmap-hwxvf" to be "success or failure"
Dec  5 20:15:26.340: INFO: Pod "pod-configmaps-80d4ba2a-f8ca-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 3.368355ms
Dec  5 20:15:28.345: INFO: Pod "pod-configmaps-80d4ba2a-f8ca-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007412098s
Dec  5 20:15:30.348: INFO: Pod "pod-configmaps-80d4ba2a-f8ca-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010879244s
STEP: Saw pod success
Dec  5 20:15:30.348: INFO: Pod "pod-configmaps-80d4ba2a-f8ca-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 20:15:30.351: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-configmaps-80d4ba2a-f8ca-11e8-b559-c27407a18179 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 20:15:30.372: INFO: Waiting for pod pod-configmaps-80d4ba2a-f8ca-11e8-b559-c27407a18179 to disappear
Dec  5 20:15:30.380: INFO: Pod pod-configmaps-80d4ba2a-f8ca-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:15:30.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-hwxvf" for this suite.
Dec  5 20:15:36.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:15:36.417: INFO: namespace: e2e-tests-configmap-hwxvf, resource: bindings, ignored listing per whitelist
Dec  5 20:15:36.482: INFO: namespace e2e-tests-configmap-hwxvf deletion completed in 6.098353843s

• [SLOW TEST:10.212 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:15:36.482: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-79tw
STEP: Creating a pod to test atomic-volume-subpath
Dec  5 20:15:36.549: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-79tw" in namespace "e2e-tests-subpath-s6ctc" to be "success or failure"
Dec  5 20:15:36.552: INFO: Pod "pod-subpath-test-secret-79tw": Phase="Pending", Reason="", readiness=false. Elapsed: 2.638471ms
Dec  5 20:15:38.555: INFO: Pod "pod-subpath-test-secret-79tw": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005838836s
Dec  5 20:15:40.558: INFO: Pod "pod-subpath-test-secret-79tw": Phase="Running", Reason="", readiness=false. Elapsed: 4.009238446s
Dec  5 20:15:42.562: INFO: Pod "pod-subpath-test-secret-79tw": Phase="Running", Reason="", readiness=false. Elapsed: 6.01283026s
Dec  5 20:15:44.565: INFO: Pod "pod-subpath-test-secret-79tw": Phase="Running", Reason="", readiness=false. Elapsed: 8.016485028s
Dec  5 20:15:46.569: INFO: Pod "pod-subpath-test-secret-79tw": Phase="Running", Reason="", readiness=false. Elapsed: 10.020115797s
Dec  5 20:15:48.572: INFO: Pod "pod-subpath-test-secret-79tw": Phase="Running", Reason="", readiness=false. Elapsed: 12.023561948s
Dec  5 20:15:50.576: INFO: Pod "pod-subpath-test-secret-79tw": Phase="Running", Reason="", readiness=false. Elapsed: 14.027188233s
Dec  5 20:15:52.580: INFO: Pod "pod-subpath-test-secret-79tw": Phase="Running", Reason="", readiness=false. Elapsed: 16.030792892s
Dec  5 20:15:54.583: INFO: Pod "pod-subpath-test-secret-79tw": Phase="Running", Reason="", readiness=false. Elapsed: 18.034619598s
Dec  5 20:15:56.587: INFO: Pod "pod-subpath-test-secret-79tw": Phase="Running", Reason="", readiness=false. Elapsed: 20.03836159s
Dec  5 20:15:58.591: INFO: Pod "pod-subpath-test-secret-79tw": Phase="Running", Reason="", readiness=false. Elapsed: 22.042537686s
Dec  5 20:16:00.596: INFO: Pod "pod-subpath-test-secret-79tw": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.046791355s
STEP: Saw pod success
Dec  5 20:16:00.596: INFO: Pod "pod-subpath-test-secret-79tw" satisfied condition "success or failure"
Dec  5 20:16:00.599: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-subpath-test-secret-79tw container test-container-subpath-secret-79tw: <nil>
STEP: delete the pod
Dec  5 20:16:00.619: INFO: Waiting for pod pod-subpath-test-secret-79tw to disappear
Dec  5 20:16:00.622: INFO: Pod pod-subpath-test-secret-79tw no longer exists
STEP: Deleting pod pod-subpath-test-secret-79tw
Dec  5 20:16:00.622: INFO: Deleting pod "pod-subpath-test-secret-79tw" in namespace "e2e-tests-subpath-s6ctc"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:16:00.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-s6ctc" for this suite.
Dec  5 20:16:06.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:16:06.745: INFO: namespace: e2e-tests-subpath-s6ctc, resource: bindings, ignored listing per whitelist
Dec  5 20:16:06.784: INFO: namespace e2e-tests-subpath-s6ctc deletion completed in 6.15635665s

• [SLOW TEST:30.302 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:16:06.784: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec  5 20:16:06.839: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:16:12.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-pvfkj" for this suite.
Dec  5 20:16:18.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:16:18.740: INFO: namespace: e2e-tests-init-container-pvfkj, resource: bindings, ignored listing per whitelist
Dec  5 20:16:18.769: INFO: namespace e2e-tests-init-container-pvfkj deletion completed in 6.170021591s

• [SLOW TEST:11.985 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:16:18.769: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-75p7k
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  5 20:16:18.828: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  5 20:16:38.910: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.1.94.43 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-75p7k PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 20:16:38.910: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
Dec  5 20:16:40.016: INFO: Found all expected endpoints: [netserver-0]
Dec  5 20:16:40.020: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.1.41.128 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-75p7k PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 20:16:40.020: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
Dec  5 20:16:41.101: INFO: Found all expected endpoints: [netserver-1]
Dec  5 20:16:41.105: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.1.43.24 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-75p7k PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 20:16:41.105: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
Dec  5 20:16:42.190: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:16:42.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-75p7k" for this suite.
Dec  5 20:17:04.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:17:04.229: INFO: namespace: e2e-tests-pod-network-test-75p7k, resource: bindings, ignored listing per whitelist
Dec  5 20:17:04.326: INFO: namespace e2e-tests-pod-network-test-75p7k deletion completed in 22.131608921s

• [SLOW TEST:45.557 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:17:04.326: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:17:10.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-zmmwf" for this suite.
Dec  5 20:17:16.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:17:16.514: INFO: namespace: e2e-tests-namespaces-zmmwf, resource: bindings, ignored listing per whitelist
Dec  5 20:17:16.584: INFO: namespace e2e-tests-namespaces-zmmwf deletion completed in 6.105873598s
STEP: Destroying namespace "e2e-tests-nsdeletetest-d5ttt" for this suite.
Dec  5 20:17:16.586: INFO: Namespace e2e-tests-nsdeletetest-d5ttt was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-5sg8c" for this suite.
Dec  5 20:17:22.697: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:17:22.719: INFO: namespace: e2e-tests-nsdeletetest-5sg8c, resource: bindings, ignored listing per whitelist
Dec  5 20:17:22.792: INFO: namespace e2e-tests-nsdeletetest-5sg8c deletion completed in 6.205630588s

• [SLOW TEST:18.466 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:17:22.792: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:17:53.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-5zd6v" for this suite.
Dec  5 20:17:59.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:17:59.168: INFO: namespace: e2e-tests-container-runtime-5zd6v, resource: bindings, ignored listing per whitelist
Dec  5 20:17:59.243: INFO: namespace e2e-tests-container-runtime-5zd6v deletion completed in 6.103506559s

• [SLOW TEST:36.451 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:17:59.244: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Dec  5 20:17:59.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 api-versions'
Dec  5 20:17:59.377: INFO: stderr: ""
Dec  5 20:17:59.377: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:17:59.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-l78qw" for this suite.
Dec  5 20:18:05.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:18:05.415: INFO: namespace: e2e-tests-kubectl-l78qw, resource: bindings, ignored listing per whitelist
Dec  5 20:18:05.646: INFO: namespace e2e-tests-kubectl-l78qw deletion completed in 6.264909816s

• [SLOW TEST:6.402 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:18:05.646: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Dec  5 20:18:05.882: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 create -f - --namespace=e2e-tests-kubectl-v4k26'
Dec  5 20:18:06.782: INFO: stderr: ""
Dec  5 20:18:06.782: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  5 20:18:06.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-v4k26'
Dec  5 20:18:06.866: INFO: stderr: ""
Dec  5 20:18:06.866: INFO: stdout: "update-demo-nautilus-sr6wr update-demo-nautilus-sxbdj "
Dec  5 20:18:06.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods update-demo-nautilus-sr6wr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-v4k26'
Dec  5 20:18:06.949: INFO: stderr: ""
Dec  5 20:18:06.949: INFO: stdout: ""
Dec  5 20:18:06.949: INFO: update-demo-nautilus-sr6wr is created but not running
Dec  5 20:18:11.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-v4k26'
Dec  5 20:18:12.218: INFO: stderr: ""
Dec  5 20:18:12.218: INFO: stdout: "update-demo-nautilus-sr6wr update-demo-nautilus-sxbdj "
Dec  5 20:18:12.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods update-demo-nautilus-sr6wr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-v4k26'
Dec  5 20:18:12.294: INFO: stderr: ""
Dec  5 20:18:12.294: INFO: stdout: ""
Dec  5 20:18:12.294: INFO: update-demo-nautilus-sr6wr is created but not running
Dec  5 20:18:17.294: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-v4k26'
Dec  5 20:18:17.362: INFO: stderr: ""
Dec  5 20:18:17.362: INFO: stdout: "update-demo-nautilus-sr6wr update-demo-nautilus-sxbdj "
Dec  5 20:18:17.362: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods update-demo-nautilus-sr6wr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-v4k26'
Dec  5 20:18:17.442: INFO: stderr: ""
Dec  5 20:18:17.442: INFO: stdout: "true"
Dec  5 20:18:17.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods update-demo-nautilus-sr6wr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-v4k26'
Dec  5 20:18:17.514: INFO: stderr: ""
Dec  5 20:18:17.514: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  5 20:18:17.514: INFO: validating pod update-demo-nautilus-sr6wr
Dec  5 20:18:17.519: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  5 20:18:17.519: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  5 20:18:17.519: INFO: update-demo-nautilus-sr6wr is verified up and running
Dec  5 20:18:17.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods update-demo-nautilus-sxbdj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-v4k26'
Dec  5 20:18:17.596: INFO: stderr: ""
Dec  5 20:18:17.596: INFO: stdout: "true"
Dec  5 20:18:17.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods update-demo-nautilus-sxbdj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-v4k26'
Dec  5 20:18:17.667: INFO: stderr: ""
Dec  5 20:18:17.667: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  5 20:18:17.667: INFO: validating pod update-demo-nautilus-sxbdj
Dec  5 20:18:17.672: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  5 20:18:17.672: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  5 20:18:17.672: INFO: update-demo-nautilus-sxbdj is verified up and running
STEP: using delete to clean up resources
Dec  5 20:18:17.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-v4k26'
Dec  5 20:18:17.746: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  5 20:18:17.746: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec  5 20:18:17.746: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-v4k26'
Dec  5 20:18:17.852: INFO: stderr: "No resources found.\n"
Dec  5 20:18:17.852: INFO: stdout: ""
Dec  5 20:18:17.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods -l name=update-demo --namespace=e2e-tests-kubectl-v4k26 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  5 20:18:17.941: INFO: stderr: ""
Dec  5 20:18:17.941: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:18:17.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-v4k26" for this suite.
Dec  5 20:18:39.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:18:40.131: INFO: namespace: e2e-tests-kubectl-v4k26, resource: bindings, ignored listing per whitelist
Dec  5 20:18:40.196: INFO: namespace e2e-tests-kubectl-v4k26 deletion completed in 22.251305061s

• [SLOW TEST:34.550 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:18:40.196: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W1205 20:18:41.298501      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  5 20:18:41.298: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:18:41.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-xt7qx" for this suite.
Dec  5 20:18:47.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:18:47.336: INFO: namespace: e2e-tests-gc-xt7qx, resource: bindings, ignored listing per whitelist
Dec  5 20:18:47.397: INFO: namespace e2e-tests-gc-xt7qx deletion completed in 6.095853358s

• [SLOW TEST:7.201 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:18:47.397: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  5 20:18:47.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-hmbqm'
Dec  5 20:18:47.599: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  5 20:18:47.599: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Dec  5 20:18:47.605: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-hmbqm'
Dec  5 20:18:47.699: INFO: stderr: ""
Dec  5 20:18:47.699: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:18:47.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hmbqm" for this suite.
Dec  5 20:18:53.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:18:53.813: INFO: namespace: e2e-tests-kubectl-hmbqm, resource: bindings, ignored listing per whitelist
Dec  5 20:18:53.883: INFO: namespace e2e-tests-kubectl-hmbqm deletion completed in 6.179951247s

• [SLOW TEST:6.486 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:18:53.883: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec  5 20:18:58.474: INFO: Successfully updated pod "labelsupdatefc9349e6-f8ca-11e8-b559-c27407a18179"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:19:00.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-qbhbc" for this suite.
Dec  5 20:19:22.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:19:22.584: INFO: namespace: e2e-tests-downward-api-qbhbc, resource: bindings, ignored listing per whitelist
Dec  5 20:19:22.602: INFO: namespace e2e-tests-downward-api-qbhbc deletion completed in 22.104958617s

• [SLOW TEST:28.719 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:19:22.602: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Dec  5 20:19:22.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 create -f - --namespace=e2e-tests-kubectl-wh22f'
Dec  5 20:19:23.013: INFO: stderr: ""
Dec  5 20:19:23.013: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  5 20:19:23.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-wh22f'
Dec  5 20:19:23.096: INFO: stderr: ""
Dec  5 20:19:23.096: INFO: stdout: "update-demo-nautilus-bh6v2 update-demo-nautilus-xk7hq "
Dec  5 20:19:23.096: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods update-demo-nautilus-bh6v2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wh22f'
Dec  5 20:19:23.169: INFO: stderr: ""
Dec  5 20:19:23.169: INFO: stdout: ""
Dec  5 20:19:23.169: INFO: update-demo-nautilus-bh6v2 is created but not running
Dec  5 20:19:28.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-wh22f'
Dec  5 20:19:28.243: INFO: stderr: ""
Dec  5 20:19:28.243: INFO: stdout: "update-demo-nautilus-bh6v2 update-demo-nautilus-xk7hq "
Dec  5 20:19:28.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods update-demo-nautilus-bh6v2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wh22f'
Dec  5 20:19:28.311: INFO: stderr: ""
Dec  5 20:19:28.311: INFO: stdout: "true"
Dec  5 20:19:28.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods update-demo-nautilus-bh6v2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wh22f'
Dec  5 20:19:28.386: INFO: stderr: ""
Dec  5 20:19:28.386: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  5 20:19:28.386: INFO: validating pod update-demo-nautilus-bh6v2
Dec  5 20:19:28.391: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  5 20:19:28.391: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  5 20:19:28.391: INFO: update-demo-nautilus-bh6v2 is verified up and running
Dec  5 20:19:28.391: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods update-demo-nautilus-xk7hq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wh22f'
Dec  5 20:19:28.472: INFO: stderr: ""
Dec  5 20:19:28.472: INFO: stdout: "true"
Dec  5 20:19:28.472: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods update-demo-nautilus-xk7hq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wh22f'
Dec  5 20:19:28.538: INFO: stderr: ""
Dec  5 20:19:28.538: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  5 20:19:28.538: INFO: validating pod update-demo-nautilus-xk7hq
Dec  5 20:19:28.543: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  5 20:19:28.544: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  5 20:19:28.544: INFO: update-demo-nautilus-xk7hq is verified up and running
STEP: rolling-update to new replication controller
Dec  5 20:19:28.545: INFO: scanned /root for discovery docs: <nil>
Dec  5 20:19:28.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-wh22f'
Dec  5 20:19:51.912: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec  5 20:19:51.912: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  5 20:19:51.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-wh22f'
Dec  5 20:19:51.995: INFO: stderr: ""
Dec  5 20:19:51.995: INFO: stdout: "update-demo-kitten-n9t8s update-demo-kitten-xv248 update-demo-nautilus-xk7hq "
STEP: Replicas for name=update-demo: expected=2 actual=3
Dec  5 20:19:56.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-wh22f'
Dec  5 20:19:57.080: INFO: stderr: ""
Dec  5 20:19:57.080: INFO: stdout: "update-demo-kitten-n9t8s update-demo-kitten-xv248 "
Dec  5 20:19:57.080: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods update-demo-kitten-n9t8s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wh22f'
Dec  5 20:19:57.170: INFO: stderr: ""
Dec  5 20:19:57.170: INFO: stdout: "true"
Dec  5 20:19:57.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods update-demo-kitten-n9t8s -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wh22f'
Dec  5 20:19:57.241: INFO: stderr: ""
Dec  5 20:19:57.241: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec  5 20:19:57.241: INFO: validating pod update-demo-kitten-n9t8s
Dec  5 20:19:57.246: INFO: got data: {
  "image": "kitten.jpg"
}

Dec  5 20:19:57.246: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec  5 20:19:57.246: INFO: update-demo-kitten-n9t8s is verified up and running
Dec  5 20:19:57.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods update-demo-kitten-xv248 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wh22f'
Dec  5 20:19:57.324: INFO: stderr: ""
Dec  5 20:19:57.324: INFO: stdout: "true"
Dec  5 20:19:57.324: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods update-demo-kitten-xv248 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wh22f'
Dec  5 20:19:57.395: INFO: stderr: ""
Dec  5 20:19:57.395: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec  5 20:19:57.395: INFO: validating pod update-demo-kitten-xv248
Dec  5 20:19:57.399: INFO: got data: {
  "image": "kitten.jpg"
}

Dec  5 20:19:57.399: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec  5 20:19:57.399: INFO: update-demo-kitten-xv248 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:19:57.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wh22f" for this suite.
Dec  5 20:20:19.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:20:19.547: INFO: namespace: e2e-tests-kubectl-wh22f, resource: bindings, ignored listing per whitelist
Dec  5 20:20:19.585: INFO: namespace e2e-tests-kubectl-wh22f deletion completed in 22.182276548s

• [SLOW TEST:56.983 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:20:19.585: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-xnfvg
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-xnfvg to expose endpoints map[]
Dec  5 20:20:19.704: INFO: Get endpoints failed (5.513918ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Dec  5 20:20:20.708: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-xnfvg exposes endpoints map[] (1.009502933s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-xnfvg
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-xnfvg to expose endpoints map[pod1:[100]]
Dec  5 20:20:22.734: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-xnfvg exposes endpoints map[pod1:[100]] (2.018952286s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-xnfvg
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-xnfvg to expose endpoints map[pod1:[100] pod2:[101]]
Dec  5 20:20:24.767: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-xnfvg exposes endpoints map[pod1:[100] pod2:[101]] (2.027555315s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-xnfvg
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-xnfvg to expose endpoints map[pod2:[101]]
Dec  5 20:20:25.796: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-xnfvg exposes endpoints map[pod2:[101]] (1.022356549s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-xnfvg
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-xnfvg to expose endpoints map[]
Dec  5 20:20:26.810: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-xnfvg exposes endpoints map[] (1.006844755s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:20:26.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-xnfvg" for this suite.
Dec  5 20:20:32.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:20:32.866: INFO: namespace: e2e-tests-services-xnfvg, resource: bindings, ignored listing per whitelist
Dec  5 20:20:32.935: INFO: namespace e2e-tests-services-xnfvg deletion completed in 6.104162519s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:13.350 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:20:32.935: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-6r9jw
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-6r9jw
STEP: Deleting pre-stop pod
Dec  5 20:20:46.171: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:20:46.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-6r9jw" for this suite.
Dec  5 20:21:24.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:21:24.462: INFO: namespace: e2e-tests-prestop-6r9jw, resource: bindings, ignored listing per whitelist
Dec  5 20:21:24.465: INFO: namespace e2e-tests-prestop-6r9jw deletion completed in 38.282854474s

• [SLOW TEST:51.530 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:21:24.465: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-6zfjl
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Dec  5 20:21:24.699: INFO: Found 0 stateful pods, waiting for 3
Dec  5 20:21:34.703: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 20:21:34.703: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 20:21:34.703: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Dec  5 20:21:34.736: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Dec  5 20:21:44.778: INFO: Updating stateful set ss2
Dec  5 20:21:44.791: INFO: Waiting for Pod e2e-tests-statefulset-6zfjl/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Dec  5 20:21:54.871: INFO: Found 2 stateful pods, waiting for 3
Dec  5 20:22:04.875: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 20:22:04.875: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 20:22:04.875: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Dec  5 20:22:04.900: INFO: Updating stateful set ss2
Dec  5 20:22:04.908: INFO: Waiting for Pod e2e-tests-statefulset-6zfjl/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec  5 20:22:14.934: INFO: Updating stateful set ss2
Dec  5 20:22:14.942: INFO: Waiting for StatefulSet e2e-tests-statefulset-6zfjl/ss2 to complete update
Dec  5 20:22:14.942: INFO: Waiting for Pod e2e-tests-statefulset-6zfjl/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  5 20:22:24.949: INFO: Deleting all statefulset in ns e2e-tests-statefulset-6zfjl
Dec  5 20:22:24.953: INFO: Scaling statefulset ss2 to 0
Dec  5 20:22:34.968: INFO: Waiting for statefulset status.replicas updated to 0
Dec  5 20:22:34.971: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:22:34.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-6zfjl" for this suite.
Dec  5 20:22:41.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:22:41.064: INFO: namespace: e2e-tests-statefulset-6zfjl, resource: bindings, ignored listing per whitelist
Dec  5 20:22:41.086: INFO: namespace e2e-tests-statefulset-6zfjl deletion completed in 6.095837755s

• [SLOW TEST:76.621 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:22:41.086: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 20:22:41.695: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"840a2b4e-f8cb-11e8-b622-12e7eb78a7a2", Controller:(*bool)(0xc000b3eb16), BlockOwnerDeletion:(*bool)(0xc000b3eb17)}}
Dec  5 20:22:41.701: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"83fc2ce0-f8cb-11e8-b622-12e7eb78a7a2", Controller:(*bool)(0xc001b806f6), BlockOwnerDeletion:(*bool)(0xc001b806f7)}}
Dec  5 20:22:41.707: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"83fccdc5-f8cb-11e8-b622-12e7eb78a7a2", Controller:(*bool)(0xc001ba6e7e), BlockOwnerDeletion:(*bool)(0xc001ba6e7f)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:22:46.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-9bcwk" for this suite.
Dec  5 20:22:52.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:22:52.953: INFO: namespace: e2e-tests-gc-9bcwk, resource: bindings, ignored listing per whitelist
Dec  5 20:22:52.980: INFO: namespace e2e-tests-gc-9bcwk deletion completed in 6.260562813s

• [SLOW TEST:11.893 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:22:52.980: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 20:22:53.042: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8b167d6e-f8cb-11e8-b559-c27407a18179" in namespace "e2e-tests-projected-k7v56" to be "success or failure"
Dec  5 20:22:53.046: INFO: Pod "downwardapi-volume-8b167d6e-f8cb-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 4.288405ms
Dec  5 20:22:55.050: INFO: Pod "downwardapi-volume-8b167d6e-f8cb-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00838536s
Dec  5 20:22:57.054: INFO: Pod "downwardapi-volume-8b167d6e-f8cb-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011840696s
STEP: Saw pod success
Dec  5 20:22:57.054: INFO: Pod "downwardapi-volume-8b167d6e-f8cb-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 20:22:57.056: INFO: Trying to get logs from node ip-172-31-2-231 pod downwardapi-volume-8b167d6e-f8cb-11e8-b559-c27407a18179 container client-container: <nil>
STEP: delete the pod
Dec  5 20:22:57.077: INFO: Waiting for pod downwardapi-volume-8b167d6e-f8cb-11e8-b559-c27407a18179 to disappear
Dec  5 20:22:57.080: INFO: Pod downwardapi-volume-8b167d6e-f8cb-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:22:57.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-k7v56" for this suite.
Dec  5 20:23:03.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:23:03.236: INFO: namespace: e2e-tests-projected-k7v56, resource: bindings, ignored listing per whitelist
Dec  5 20:23:03.343: INFO: namespace e2e-tests-projected-k7v56 deletion completed in 6.260153729s

• [SLOW TEST:10.363 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:23:03.343: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec  5 20:23:07.487: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  5 20:23:07.490: INFO: Pod pod-with-prestop-http-hook still exists
Dec  5 20:23:09.490: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  5 20:23:09.494: INFO: Pod pod-with-prestop-http-hook still exists
Dec  5 20:23:11.490: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  5 20:23:11.494: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:23:11.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-f2tvl" for this suite.
Dec  5 20:23:33.517: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:23:33.578: INFO: namespace: e2e-tests-container-lifecycle-hook-f2tvl, resource: bindings, ignored listing per whitelist
Dec  5 20:23:33.625: INFO: namespace e2e-tests-container-lifecycle-hook-f2tvl deletion completed in 22.120225542s

• [SLOW TEST:30.282 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:23:33.625: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  5 20:23:33.684: INFO: Waiting up to 5m0s for pod "downward-api-a3500285-f8cb-11e8-b559-c27407a18179" in namespace "e2e-tests-downward-api-lbdn4" to be "success or failure"
Dec  5 20:23:33.688: INFO: Pod "downward-api-a3500285-f8cb-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 3.735016ms
Dec  5 20:23:35.692: INFO: Pod "downward-api-a3500285-f8cb-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00761774s
STEP: Saw pod success
Dec  5 20:23:35.692: INFO: Pod "downward-api-a3500285-f8cb-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 20:23:35.695: INFO: Trying to get logs from node ip-172-31-24-193 pod downward-api-a3500285-f8cb-11e8-b559-c27407a18179 container dapi-container: <nil>
STEP: delete the pod
Dec  5 20:23:35.711: INFO: Waiting for pod downward-api-a3500285-f8cb-11e8-b559-c27407a18179 to disappear
Dec  5 20:23:35.714: INFO: Pod downward-api-a3500285-f8cb-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:23:35.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-lbdn4" for this suite.
Dec  5 20:23:41.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:23:41.781: INFO: namespace: e2e-tests-downward-api-lbdn4, resource: bindings, ignored listing per whitelist
Dec  5 20:23:41.816: INFO: namespace e2e-tests-downward-api-lbdn4 deletion completed in 6.09893856s

• [SLOW TEST:8.191 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:23:41.816: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1205 20:23:51.994460      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  5 20:23:51.994: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:23:51.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-fc6gl" for this suite.
Dec  5 20:23:58.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:23:58.524: INFO: namespace: e2e-tests-gc-fc6gl, resource: bindings, ignored listing per whitelist
Dec  5 20:23:58.605: INFO: namespace e2e-tests-gc-fc6gl deletion completed in 6.607167334s

• [SLOW TEST:16.789 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:23:58.605: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  5 20:23:58.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-7v8xg'
Dec  5 20:23:58.892: INFO: stderr: ""
Dec  5 20:23:58.892: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Dec  5 20:24:03.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-7v8xg -o json'
Dec  5 20:24:04.012: INFO: stderr: ""
Dec  5 20:24:04.012: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2018-12-05T20:23:58Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-7v8xg\",\n        \"resourceVersion\": \"13657\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-7v8xg/pods/e2e-test-nginx-pod\",\n        \"uid\": \"b251cfce-f8cb-11e8-83dd-0223e7df6b22\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-sh4n7\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-172-31-24-193\",\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-sh4n7\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-sh4n7\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-05T20:23:58Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-05T20:24:01Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-05T20:24:01Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-05T20:23:58Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://f0099536ceb15793584081cd525699d9f6cfe4a6ef95bb51a845c35bcc9589e7\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2018-12-05T20:24:00Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.31.24.193\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.1.41.152\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2018-12-05T20:23:58Z\"\n    }\n}\n"
STEP: replace the image in the pod
Dec  5 20:24:04.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 replace -f - --namespace=e2e-tests-kubectl-7v8xg'
Dec  5 20:24:04.203: INFO: stderr: ""
Dec  5 20:24:04.203: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Dec  5 20:24:04.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-7v8xg'
Dec  5 20:24:12.667: INFO: stderr: ""
Dec  5 20:24:12.667: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:24:12.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7v8xg" for this suite.
Dec  5 20:24:18.682: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:24:18.733: INFO: namespace: e2e-tests-kubectl-7v8xg, resource: bindings, ignored listing per whitelist
Dec  5 20:24:18.778: INFO: namespace e2e-tests-kubectl-7v8xg deletion completed in 6.107138949s

• [SLOW TEST:20.173 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:24:18.778: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 20:24:18.859: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Dec  5 20:24:18.869: INFO: Number of nodes with available pods: 0
Dec  5 20:24:18.869: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 20:24:19.884: INFO: Number of nodes with available pods: 0
Dec  5 20:24:19.884: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 20:24:20.878: INFO: Number of nodes with available pods: 1
Dec  5 20:24:20.878: INFO: Node ip-172-31-24-193 is running more than one daemon pod
Dec  5 20:24:21.876: INFO: Number of nodes with available pods: 2
Dec  5 20:24:21.876: INFO: Node ip-172-31-66-194 is running more than one daemon pod
Dec  5 20:24:22.876: INFO: Number of nodes with available pods: 3
Dec  5 20:24:22.876: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Dec  5 20:24:22.896: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:22.896: INFO: Wrong image for pod: daemon-set-f2t6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:22.896: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:23.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:23.904: INFO: Wrong image for pod: daemon-set-f2t6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:23.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:24.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:24.904: INFO: Wrong image for pod: daemon-set-f2t6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:24.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:25.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:25.904: INFO: Wrong image for pod: daemon-set-f2t6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:25.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:26.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:26.904: INFO: Wrong image for pod: daemon-set-f2t6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:26.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:27.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:27.904: INFO: Wrong image for pod: daemon-set-f2t6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:27.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:28.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:28.904: INFO: Wrong image for pod: daemon-set-f2t6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:28.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:29.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:29.904: INFO: Wrong image for pod: daemon-set-f2t6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:29.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:30.906: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:30.906: INFO: Wrong image for pod: daemon-set-f2t6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:30.906: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:31.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:31.904: INFO: Wrong image for pod: daemon-set-f2t6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:31.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:32.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:32.904: INFO: Wrong image for pod: daemon-set-f2t6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:32.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:33.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:33.904: INFO: Wrong image for pod: daemon-set-f2t6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:33.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:34.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:34.904: INFO: Wrong image for pod: daemon-set-f2t6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:34.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:35.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:35.904: INFO: Wrong image for pod: daemon-set-f2t6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:35.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:36.905: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:36.905: INFO: Wrong image for pod: daemon-set-f2t6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:36.905: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:37.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:37.904: INFO: Wrong image for pod: daemon-set-f2t6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:37.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:38.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:38.904: INFO: Wrong image for pod: daemon-set-f2t6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:38.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:39.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:39.904: INFO: Wrong image for pod: daemon-set-f2t6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:39.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:40.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:40.904: INFO: Wrong image for pod: daemon-set-f2t6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:40.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:41.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:41.904: INFO: Wrong image for pod: daemon-set-f2t6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:41.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:42.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:42.904: INFO: Wrong image for pod: daemon-set-f2t6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:42.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:43.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:43.904: INFO: Wrong image for pod: daemon-set-f2t6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:43.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:44.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:44.905: INFO: Wrong image for pod: daemon-set-f2t6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:44.905: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:45.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:45.904: INFO: Wrong image for pod: daemon-set-f2t6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:45.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:46.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:46.904: INFO: Wrong image for pod: daemon-set-f2t6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:46.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:47.905: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:47.905: INFO: Wrong image for pod: daemon-set-f2t6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:47.905: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:48.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:48.904: INFO: Wrong image for pod: daemon-set-f2t6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:48.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:49.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:49.904: INFO: Wrong image for pod: daemon-set-f2t6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:49.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:50.906: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:50.906: INFO: Wrong image for pod: daemon-set-f2t6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:50.906: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:51.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:51.904: INFO: Wrong image for pod: daemon-set-f2t6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:51.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:52.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:52.904: INFO: Wrong image for pod: daemon-set-f2t6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:52.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:53.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:53.904: INFO: Wrong image for pod: daemon-set-f2t6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:53.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:54.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:54.904: INFO: Wrong image for pod: daemon-set-f2t6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:54.904: INFO: Pod daemon-set-f2t6q is not available
Dec  5 20:24:54.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:55.905: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:55.905: INFO: Pod daemon-set-hrq42 is not available
Dec  5 20:24:55.905: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:56.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:56.904: INFO: Pod daemon-set-hrq42 is not available
Dec  5 20:24:56.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:57.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:57.904: INFO: Pod daemon-set-hrq42 is not available
Dec  5 20:24:57.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:58.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:58.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:59.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:24:59.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:01.077: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:01.077: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:01.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:01.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:02.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:02.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:03.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:03.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:04.905: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:04.905: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:05.905: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:05.905: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:06.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:06.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:07.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:07.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:08.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:08.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:09.905: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:09.905: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:10.905: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:10.905: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:11.905: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:11.905: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:12.905: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:12.905: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:13.905: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:13.905: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:14.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:14.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:15.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:15.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:16.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:16.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:17.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:17.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:18.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:18.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:19.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:19.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:20.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:20.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:21.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:21.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:22.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:22.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:23.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:23.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:24.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:24.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:25.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:25.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:26.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:26.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:27.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:27.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:28.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:28.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:29.904: INFO: Wrong image for pod: daemon-set-4td4f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:29.904: INFO: Pod daemon-set-4td4f is not available
Dec  5 20:25:29.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:30.904: INFO: Pod daemon-set-7vzzh is not available
Dec  5 20:25:30.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:31.904: INFO: Pod daemon-set-7vzzh is not available
Dec  5 20:25:31.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:32.904: INFO: Pod daemon-set-7vzzh is not available
Dec  5 20:25:32.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:33.904: INFO: Pod daemon-set-7vzzh is not available
Dec  5 20:25:33.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:34.906: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:35.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:36.905: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:37.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:38.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:39.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:40.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:41.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:42.906: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:43.905: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:44.905: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:45.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:46.906: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:47.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:48.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:49.906: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:50.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:51.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:52.905: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:53.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:54.905: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:55.907: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:56.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:57.905: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:58.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:25:59.905: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:26:00.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:26:01.905: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:26:02.905: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:26:03.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:26:04.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:26:05.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:26:06.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:26:07.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:26:07.904: INFO: Pod daemon-set-z4ckq is not available
Dec  5 20:26:08.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:26:08.904: INFO: Pod daemon-set-z4ckq is not available
Dec  5 20:26:09.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:26:09.904: INFO: Pod daemon-set-z4ckq is not available
Dec  5 20:26:10.905: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:26:10.905: INFO: Pod daemon-set-z4ckq is not available
Dec  5 20:26:11.904: INFO: Wrong image for pod: daemon-set-z4ckq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  5 20:26:11.904: INFO: Pod daemon-set-z4ckq is not available
Dec  5 20:26:12.904: INFO: Pod daemon-set-hl74s is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Dec  5 20:26:12.913: INFO: Number of nodes with available pods: 2
Dec  5 20:26:12.913: INFO: Node ip-172-31-24-193 is running more than one daemon pod
Dec  5 20:26:13.919: INFO: Number of nodes with available pods: 2
Dec  5 20:26:13.919: INFO: Node ip-172-31-24-193 is running more than one daemon pod
Dec  5 20:26:14.920: INFO: Number of nodes with available pods: 3
Dec  5 20:26:14.920: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-sq8hp, will wait for the garbage collector to delete the pods
Dec  5 20:26:14.995: INFO: Deleting DaemonSet.extensions daemon-set took: 9.382342ms
Dec  5 20:26:15.096: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.341051ms
Dec  5 20:26:22.700: INFO: Number of nodes with available pods: 0
Dec  5 20:26:22.700: INFO: Number of running nodes: 0, number of available pods: 0
Dec  5 20:26:22.703: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-sq8hp/daemonsets","resourceVersion":"14027"},"items":null}

Dec  5 20:26:22.706: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-sq8hp/pods","resourceVersion":"14027"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:26:22.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-sq8hp" for this suite.
Dec  5 20:26:28.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:26:28.747: INFO: namespace: e2e-tests-daemonsets-sq8hp, resource: bindings, ignored listing per whitelist
Dec  5 20:26:28.824: INFO: namespace e2e-tests-daemonsets-sq8hp deletion completed in 6.103108234s

• [SLOW TEST:130.046 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:26:28.824: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-hvw9b
Dec  5 20:26:32.948: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-hvw9b
STEP: checking the pod's current state and verifying that restartCount is present
Dec  5 20:26:32.950: INFO: Initial restart count of pod liveness-http is 0
Dec  5 20:26:54.994: INFO: Restart count of pod e2e-tests-container-probe-hvw9b/liveness-http is now 1 (22.043745608s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:26:55.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-hvw9b" for this suite.
Dec  5 20:27:01.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:27:01.171: INFO: namespace: e2e-tests-container-probe-hvw9b, resource: bindings, ignored listing per whitelist
Dec  5 20:27:01.201: INFO: namespace e2e-tests-container-probe-hvw9b deletion completed in 6.194390934s

• [SLOW TEST:32.376 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:27:01.201: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-t2gn9
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-t2gn9 to expose endpoints map[]
Dec  5 20:27:01.268: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-t2gn9 exposes endpoints map[] (3.823409ms elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-t2gn9
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-t2gn9 to expose endpoints map[pod1:[80]]
Dec  5 20:27:04.313: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-t2gn9 exposes endpoints map[pod1:[80]] (3.036897444s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-t2gn9
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-t2gn9 to expose endpoints map[pod2:[80] pod1:[80]]
Dec  5 20:27:06.364: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-t2gn9 exposes endpoints map[pod1:[80] pod2:[80]] (2.039782358s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-t2gn9
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-t2gn9 to expose endpoints map[pod2:[80]]
Dec  5 20:27:07.386: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-t2gn9 exposes endpoints map[pod2:[80]] (1.016521076s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-t2gn9
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-t2gn9 to expose endpoints map[]
Dec  5 20:27:08.400: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-t2gn9 exposes endpoints map[] (1.006857359s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:27:08.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-t2gn9" for this suite.
Dec  5 20:27:30.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:27:30.538: INFO: namespace: e2e-tests-services-t2gn9, resource: bindings, ignored listing per whitelist
Dec  5 20:27:30.613: INFO: namespace e2e-tests-services-t2gn9 deletion completed in 22.182610436s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:29.413 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:27:30.613: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 20:27:30.679: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3092724c-f8cc-11e8-b559-c27407a18179" in namespace "e2e-tests-projected-zk79d" to be "success or failure"
Dec  5 20:27:30.684: INFO: Pod "downwardapi-volume-3092724c-f8cc-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 4.27865ms
Dec  5 20:27:32.687: INFO: Pod "downwardapi-volume-3092724c-f8cc-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007934087s
STEP: Saw pod success
Dec  5 20:27:32.687: INFO: Pod "downwardapi-volume-3092724c-f8cc-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 20:27:32.690: INFO: Trying to get logs from node ip-172-31-2-231 pod downwardapi-volume-3092724c-f8cc-11e8-b559-c27407a18179 container client-container: <nil>
STEP: delete the pod
Dec  5 20:27:32.707: INFO: Waiting for pod downwardapi-volume-3092724c-f8cc-11e8-b559-c27407a18179 to disappear
Dec  5 20:27:32.709: INFO: Pod downwardapi-volume-3092724c-f8cc-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:27:32.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zk79d" for this suite.
Dec  5 20:27:38.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:27:38.782: INFO: namespace: e2e-tests-projected-zk79d, resource: bindings, ignored listing per whitelist
Dec  5 20:27:38.809: INFO: namespace e2e-tests-projected-zk79d deletion completed in 6.096785539s

• [SLOW TEST:8.196 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:27:38.809: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-3574e3bb-f8cc-11e8-b559-c27407a18179
STEP: Creating a pod to test consume configMaps
Dec  5 20:27:38.877: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-35757c69-f8cc-11e8-b559-c27407a18179" in namespace "e2e-tests-projected-kvdwh" to be "success or failure"
Dec  5 20:27:38.882: INFO: Pod "pod-projected-configmaps-35757c69-f8cc-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 4.343333ms
Dec  5 20:27:40.886: INFO: Pod "pod-projected-configmaps-35757c69-f8cc-11e8-b559-c27407a18179": Phase="Running", Reason="", readiness=true. Elapsed: 2.008638128s
Dec  5 20:27:42.890: INFO: Pod "pod-projected-configmaps-35757c69-f8cc-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012144377s
STEP: Saw pod success
Dec  5 20:27:42.890: INFO: Pod "pod-projected-configmaps-35757c69-f8cc-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 20:27:42.894: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-projected-configmaps-35757c69-f8cc-11e8-b559-c27407a18179 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 20:27:42.918: INFO: Waiting for pod pod-projected-configmaps-35757c69-f8cc-11e8-b559-c27407a18179 to disappear
Dec  5 20:27:42.920: INFO: Pod pod-projected-configmaps-35757c69-f8cc-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:27:42.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kvdwh" for this suite.
Dec  5 20:27:48.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:27:48.999: INFO: namespace: e2e-tests-projected-kvdwh, resource: bindings, ignored listing per whitelist
Dec  5 20:27:49.024: INFO: namespace e2e-tests-projected-kvdwh deletion completed in 6.100318243s

• [SLOW TEST:10.215 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:27:49.025: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 20:27:49.088: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3b8b642b-f8cc-11e8-b559-c27407a18179" in namespace "e2e-tests-projected-hqsxj" to be "success or failure"
Dec  5 20:27:49.092: INFO: Pod "downwardapi-volume-3b8b642b-f8cc-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 3.313164ms
Dec  5 20:27:51.099: INFO: Pod "downwardapi-volume-3b8b642b-f8cc-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010457926s
STEP: Saw pod success
Dec  5 20:27:51.099: INFO: Pod "downwardapi-volume-3b8b642b-f8cc-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 20:27:51.102: INFO: Trying to get logs from node ip-172-31-2-231 pod downwardapi-volume-3b8b642b-f8cc-11e8-b559-c27407a18179 container client-container: <nil>
STEP: delete the pod
Dec  5 20:27:51.123: INFO: Waiting for pod downwardapi-volume-3b8b642b-f8cc-11e8-b559-c27407a18179 to disappear
Dec  5 20:27:51.125: INFO: Pod downwardapi-volume-3b8b642b-f8cc-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:27:51.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hqsxj" for this suite.
Dec  5 20:27:57.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:27:57.215: INFO: namespace: e2e-tests-projected-hqsxj, resource: bindings, ignored listing per whitelist
Dec  5 20:27:57.231: INFO: namespace e2e-tests-projected-hqsxj deletion completed in 6.101626324s

• [SLOW TEST:8.206 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:27:57.231: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Dec  5 20:27:57.801: INFO: Waiting up to 5m0s for pod "pod-service-account-40bcf53e-f8cc-11e8-b559-c27407a18179-rkfnn" in namespace "e2e-tests-svcaccounts-m826w" to be "success or failure"
Dec  5 20:27:57.806: INFO: Pod "pod-service-account-40bcf53e-f8cc-11e8-b559-c27407a18179-rkfnn": Phase="Pending", Reason="", readiness=false. Elapsed: 4.125809ms
Dec  5 20:27:59.810: INFO: Pod "pod-service-account-40bcf53e-f8cc-11e8-b559-c27407a18179-rkfnn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008129593s
Dec  5 20:28:01.815: INFO: Pod "pod-service-account-40bcf53e-f8cc-11e8-b559-c27407a18179-rkfnn": Phase="Running", Reason="", readiness=false. Elapsed: 4.014020628s
Dec  5 20:28:03.819: INFO: Pod "pod-service-account-40bcf53e-f8cc-11e8-b559-c27407a18179-rkfnn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.017686359s
STEP: Saw pod success
Dec  5 20:28:03.819: INFO: Pod "pod-service-account-40bcf53e-f8cc-11e8-b559-c27407a18179-rkfnn" satisfied condition "success or failure"
Dec  5 20:28:03.822: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-service-account-40bcf53e-f8cc-11e8-b559-c27407a18179-rkfnn container token-test: <nil>
STEP: delete the pod
Dec  5 20:28:03.839: INFO: Waiting for pod pod-service-account-40bcf53e-f8cc-11e8-b559-c27407a18179-rkfnn to disappear
Dec  5 20:28:03.842: INFO: Pod pod-service-account-40bcf53e-f8cc-11e8-b559-c27407a18179-rkfnn no longer exists
STEP: Creating a pod to test consume service account root CA
Dec  5 20:28:03.846: INFO: Waiting up to 5m0s for pod "pod-service-account-40bcf53e-f8cc-11e8-b559-c27407a18179-p8m6x" in namespace "e2e-tests-svcaccounts-m826w" to be "success or failure"
Dec  5 20:28:03.850: INFO: Pod "pod-service-account-40bcf53e-f8cc-11e8-b559-c27407a18179-p8m6x": Phase="Pending", Reason="", readiness=false. Elapsed: 3.875193ms
Dec  5 20:28:06.046: INFO: Pod "pod-service-account-40bcf53e-f8cc-11e8-b559-c27407a18179-p8m6x": Phase="Pending", Reason="", readiness=false. Elapsed: 2.199439656s
Dec  5 20:28:08.049: INFO: Pod "pod-service-account-40bcf53e-f8cc-11e8-b559-c27407a18179-p8m6x": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.202731426s
STEP: Saw pod success
Dec  5 20:28:08.049: INFO: Pod "pod-service-account-40bcf53e-f8cc-11e8-b559-c27407a18179-p8m6x" satisfied condition "success or failure"
Dec  5 20:28:08.052: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-service-account-40bcf53e-f8cc-11e8-b559-c27407a18179-p8m6x container root-ca-test: <nil>
STEP: delete the pod
Dec  5 20:28:08.069: INFO: Waiting for pod pod-service-account-40bcf53e-f8cc-11e8-b559-c27407a18179-p8m6x to disappear
Dec  5 20:28:08.072: INFO: Pod pod-service-account-40bcf53e-f8cc-11e8-b559-c27407a18179-p8m6x no longer exists
STEP: Creating a pod to test consume service account namespace
Dec  5 20:28:08.078: INFO: Waiting up to 5m0s for pod "pod-service-account-40bcf53e-f8cc-11e8-b559-c27407a18179-dwtkp" in namespace "e2e-tests-svcaccounts-m826w" to be "success or failure"
Dec  5 20:28:08.081: INFO: Pod "pod-service-account-40bcf53e-f8cc-11e8-b559-c27407a18179-dwtkp": Phase="Pending", Reason="", readiness=false. Elapsed: 3.290469ms
Dec  5 20:28:10.084: INFO: Pod "pod-service-account-40bcf53e-f8cc-11e8-b559-c27407a18179-dwtkp": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006593313s
Dec  5 20:28:12.088: INFO: Pod "pod-service-account-40bcf53e-f8cc-11e8-b559-c27407a18179-dwtkp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010111501s
STEP: Saw pod success
Dec  5 20:28:12.088: INFO: Pod "pod-service-account-40bcf53e-f8cc-11e8-b559-c27407a18179-dwtkp" satisfied condition "success or failure"
Dec  5 20:28:12.091: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-service-account-40bcf53e-f8cc-11e8-b559-c27407a18179-dwtkp container namespace-test: <nil>
STEP: delete the pod
Dec  5 20:28:12.109: INFO: Waiting for pod pod-service-account-40bcf53e-f8cc-11e8-b559-c27407a18179-dwtkp to disappear
Dec  5 20:28:12.112: INFO: Pod pod-service-account-40bcf53e-f8cc-11e8-b559-c27407a18179-dwtkp no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:28:12.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-m826w" for this suite.
Dec  5 20:28:18.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:28:18.157: INFO: namespace: e2e-tests-svcaccounts-m826w, resource: bindings, ignored listing per whitelist
Dec  5 20:28:18.226: INFO: namespace e2e-tests-svcaccounts-m826w deletion completed in 6.111156253s

• [SLOW TEST:20.995 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:28:18.226: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-4cf30885-f8cc-11e8-b559-c27407a18179
STEP: Creating a pod to test consume secrets
Dec  5 20:28:18.293: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4cf3a45c-f8cc-11e8-b559-c27407a18179" in namespace "e2e-tests-projected-gqdnq" to be "success or failure"
Dec  5 20:28:18.296: INFO: Pod "pod-projected-secrets-4cf3a45c-f8cc-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 3.210969ms
Dec  5 20:28:20.300: INFO: Pod "pod-projected-secrets-4cf3a45c-f8cc-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007348571s
STEP: Saw pod success
Dec  5 20:28:20.300: INFO: Pod "pod-projected-secrets-4cf3a45c-f8cc-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 20:28:20.304: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-projected-secrets-4cf3a45c-f8cc-11e8-b559-c27407a18179 container secret-volume-test: <nil>
STEP: delete the pod
Dec  5 20:28:20.322: INFO: Waiting for pod pod-projected-secrets-4cf3a45c-f8cc-11e8-b559-c27407a18179 to disappear
Dec  5 20:28:20.326: INFO: Pod pod-projected-secrets-4cf3a45c-f8cc-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:28:20.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gqdnq" for this suite.
Dec  5 20:28:26.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:28:26.399: INFO: namespace: e2e-tests-projected-gqdnq, resource: bindings, ignored listing per whitelist
Dec  5 20:28:26.439: INFO: namespace e2e-tests-projected-gqdnq deletion completed in 6.10983384s

• [SLOW TEST:8.212 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:28:26.439: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 20:28:26.531: INFO: Waiting up to 5m0s for pod "downwardapi-volume-51dc9865-f8cc-11e8-b559-c27407a18179" in namespace "e2e-tests-downward-api-5jc7d" to be "success or failure"
Dec  5 20:28:26.535: INFO: Pod "downwardapi-volume-51dc9865-f8cc-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 4.311829ms
Dec  5 20:28:28.539: INFO: Pod "downwardapi-volume-51dc9865-f8cc-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008274594s
STEP: Saw pod success
Dec  5 20:28:28.539: INFO: Pod "downwardapi-volume-51dc9865-f8cc-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 20:28:28.542: INFO: Trying to get logs from node ip-172-31-24-193 pod downwardapi-volume-51dc9865-f8cc-11e8-b559-c27407a18179 container client-container: <nil>
STEP: delete the pod
Dec  5 20:28:28.562: INFO: Waiting for pod downwardapi-volume-51dc9865-f8cc-11e8-b559-c27407a18179 to disappear
Dec  5 20:28:28.565: INFO: Pod downwardapi-volume-51dc9865-f8cc-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:28:28.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5jc7d" for this suite.
Dec  5 20:28:34.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:28:34.626: INFO: namespace: e2e-tests-downward-api-5jc7d, resource: bindings, ignored listing per whitelist
Dec  5 20:28:34.676: INFO: namespace e2e-tests-downward-api-5jc7d deletion completed in 6.107463551s

• [SLOW TEST:8.237 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:28:34.676: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-mp84x
Dec  5 20:28:38.739: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-mp84x
STEP: checking the pod's current state and verifying that restartCount is present
Dec  5 20:28:38.743: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:32:39.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-mp84x" for this suite.
Dec  5 20:32:45.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:32:45.849: INFO: namespace: e2e-tests-container-probe-mp84x, resource: bindings, ignored listing per whitelist
Dec  5 20:32:45.877: INFO: namespace e2e-tests-container-probe-mp84x deletion completed in 6.09752455s

• [SLOW TEST:251.201 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:32:45.877: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec  5 20:32:45.938: INFO: Waiting up to 5m0s for pod "pod-ec7b612d-f8cc-11e8-b559-c27407a18179" in namespace "e2e-tests-emptydir-ps5qd" to be "success or failure"
Dec  5 20:32:45.944: INFO: Pod "pod-ec7b612d-f8cc-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 5.56572ms
Dec  5 20:32:47.948: INFO: Pod "pod-ec7b612d-f8cc-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009262437s
Dec  5 20:32:49.951: INFO: Pod "pod-ec7b612d-f8cc-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012759226s
STEP: Saw pod success
Dec  5 20:32:49.951: INFO: Pod "pod-ec7b612d-f8cc-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 20:32:49.954: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-ec7b612d-f8cc-11e8-b559-c27407a18179 container test-container: <nil>
STEP: delete the pod
Dec  5 20:32:49.976: INFO: Waiting for pod pod-ec7b612d-f8cc-11e8-b559-c27407a18179 to disappear
Dec  5 20:32:49.979: INFO: Pod pod-ec7b612d-f8cc-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:32:49.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-ps5qd" for this suite.
Dec  5 20:32:55.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:32:56.133: INFO: namespace: e2e-tests-emptydir-ps5qd, resource: bindings, ignored listing per whitelist
Dec  5 20:32:56.142: INFO: namespace e2e-tests-emptydir-ps5qd deletion completed in 6.159947154s

• [SLOW TEST:10.265 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:32:56.142: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-c49nm
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-c49nm
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-c49nm
Dec  5 20:32:56.222: INFO: Found 0 stateful pods, waiting for 1
Dec  5 20:33:06.226: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Dec  5 20:33:06.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-c49nm ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  5 20:33:06.408: INFO: stderr: ""
Dec  5 20:33:06.408: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  5 20:33:06.408: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  5 20:33:06.412: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec  5 20:33:16.419: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  5 20:33:16.419: INFO: Waiting for statefulset status.replicas updated to 0
Dec  5 20:33:16.442: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999576s
Dec  5 20:33:17.446: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.994934031s
Dec  5 20:33:18.449: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.990927118s
Dec  5 20:33:19.453: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.987184202s
Dec  5 20:33:20.456: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.983735684s
Dec  5 20:33:21.461: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.980081497s
Dec  5 20:33:22.465: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.975573679s
Dec  5 20:33:23.468: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.971769035s
Dec  5 20:33:24.473: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.96836532s
Dec  5 20:33:25.477: INFO: Verifying statefulset ss doesn't scale past 1 for another 963.76026ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-c49nm
Dec  5 20:33:26.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-c49nm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 20:33:31.663: INFO: stderr: ""
Dec  5 20:33:31.663: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  5 20:33:31.663: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  5 20:33:31.666: INFO: Found 1 stateful pods, waiting for 3
Dec  5 20:33:41.675: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 20:33:41.675: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 20:33:41.675: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Dec  5 20:33:41.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-c49nm ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  5 20:33:41.832: INFO: stderr: ""
Dec  5 20:33:41.832: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  5 20:33:41.832: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  5 20:33:41.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-c49nm ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  5 20:33:42.017: INFO: stderr: ""
Dec  5 20:33:42.017: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  5 20:33:42.017: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  5 20:33:42.017: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-c49nm ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  5 20:33:42.181: INFO: stderr: ""
Dec  5 20:33:42.181: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  5 20:33:42.181: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  5 20:33:42.181: INFO: Waiting for statefulset status.replicas updated to 0
Dec  5 20:33:42.188: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Dec  5 20:33:52.196: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  5 20:33:52.196: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec  5 20:33:52.196: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec  5 20:33:52.209: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999769s
Dec  5 20:33:53.213: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995697194s
Dec  5 20:33:54.217: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.991531072s
Dec  5 20:33:55.221: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.98776971s
Dec  5 20:33:56.225: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.983688982s
Dec  5 20:33:57.229: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.979499395s
Dec  5 20:33:58.233: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.975617701s
Dec  5 20:33:59.237: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.971333905s
Dec  5 20:34:00.242: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.967048157s
Dec  5 20:34:01.246: INFO: Verifying statefulset ss doesn't scale past 3 for another 962.818392ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-c49nm
Dec  5 20:34:02.254: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-c49nm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 20:34:02.472: INFO: stderr: ""
Dec  5 20:34:02.472: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  5 20:34:02.472: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  5 20:34:02.472: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-c49nm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 20:34:02.647: INFO: stderr: ""
Dec  5 20:34:02.647: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  5 20:34:02.647: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  5 20:34:02.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-c49nm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 20:34:02.809: INFO: stderr: ""
Dec  5 20:34:02.809: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  5 20:34:02.809: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  5 20:34:02.809: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  5 20:34:22.823: INFO: Deleting all statefulset in ns e2e-tests-statefulset-c49nm
Dec  5 20:34:22.828: INFO: Scaling statefulset ss to 0
Dec  5 20:34:22.837: INFO: Waiting for statefulset status.replicas updated to 0
Dec  5 20:34:22.839: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:34:22.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-c49nm" for this suite.
Dec  5 20:34:28.877: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:34:28.947: INFO: namespace: e2e-tests-statefulset-c49nm, resource: bindings, ignored listing per whitelist
Dec  5 20:34:28.973: INFO: namespace e2e-tests-statefulset-c49nm deletion completed in 6.109072897s

• [SLOW TEST:92.831 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:34:28.973: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-29f6ef3b-f8cd-11e8-b559-c27407a18179
STEP: Creating configMap with name cm-test-opt-upd-29f6ef6c-f8cd-11e8-b559-c27407a18179
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-29f6ef3b-f8cd-11e8-b559-c27407a18179
STEP: Updating configmap cm-test-opt-upd-29f6ef6c-f8cd-11e8-b559-c27407a18179
STEP: Creating configMap with name cm-test-opt-create-29f6ef80-f8cd-11e8-b559-c27407a18179
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:34:35.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-ztf5f" for this suite.
Dec  5 20:34:57.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:34:57.221: INFO: namespace: e2e-tests-configmap-ztf5f, resource: bindings, ignored listing per whitelist
Dec  5 20:34:57.341: INFO: namespace e2e-tests-configmap-ztf5f deletion completed in 22.165761303s

• [SLOW TEST:28.368 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:34:57.342: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-3ade38aa-f8cd-11e8-b559-c27407a18179
STEP: Creating a pod to test consume configMaps
Dec  5 20:34:57.462: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3adf959e-f8cd-11e8-b559-c27407a18179" in namespace "e2e-tests-projected-p4l6l" to be "success or failure"
Dec  5 20:34:57.466: INFO: Pod "pod-projected-configmaps-3adf959e-f8cd-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 3.849769ms
Dec  5 20:34:59.470: INFO: Pod "pod-projected-configmaps-3adf959e-f8cd-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007844657s
Dec  5 20:35:01.473: INFO: Pod "pod-projected-configmaps-3adf959e-f8cd-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011511241s
STEP: Saw pod success
Dec  5 20:35:01.474: INFO: Pod "pod-projected-configmaps-3adf959e-f8cd-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 20:35:01.478: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-projected-configmaps-3adf959e-f8cd-11e8-b559-c27407a18179 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 20:35:01.504: INFO: Waiting for pod pod-projected-configmaps-3adf959e-f8cd-11e8-b559-c27407a18179 to disappear
Dec  5 20:35:01.507: INFO: Pod pod-projected-configmaps-3adf959e-f8cd-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:35:01.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-p4l6l" for this suite.
Dec  5 20:35:07.534: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:35:07.672: INFO: namespace: e2e-tests-projected-p4l6l, resource: bindings, ignored listing per whitelist
Dec  5 20:35:07.719: INFO: namespace e2e-tests-projected-p4l6l deletion completed in 6.205357768s

• [SLOW TEST:10.377 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:35:07.719: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec  5 20:35:07.830: INFO: Waiting up to 5m0s for pod "pod-410d9495-f8cd-11e8-b559-c27407a18179" in namespace "e2e-tests-emptydir-gxf4w" to be "success or failure"
Dec  5 20:35:07.835: INFO: Pod "pod-410d9495-f8cd-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 5.115451ms
Dec  5 20:35:09.839: INFO: Pod "pod-410d9495-f8cd-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008602044s
Dec  5 20:35:11.843: INFO: Pod "pod-410d9495-f8cd-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012468353s
STEP: Saw pod success
Dec  5 20:35:11.843: INFO: Pod "pod-410d9495-f8cd-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 20:35:11.846: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-410d9495-f8cd-11e8-b559-c27407a18179 container test-container: <nil>
STEP: delete the pod
Dec  5 20:35:11.863: INFO: Waiting for pod pod-410d9495-f8cd-11e8-b559-c27407a18179 to disappear
Dec  5 20:35:11.865: INFO: Pod pod-410d9495-f8cd-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:35:11.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-gxf4w" for this suite.
Dec  5 20:35:17.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:35:18.014: INFO: namespace: e2e-tests-emptydir-gxf4w, resource: bindings, ignored listing per whitelist
Dec  5 20:35:18.064: INFO: namespace e2e-tests-emptydir-gxf4w deletion completed in 6.195636744s

• [SLOW TEST:10.345 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:35:18.064: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Dec  5 20:35:23.167: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:35:24.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-hngsg" for this suite.
Dec  5 20:35:46.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:35:46.401: INFO: namespace: e2e-tests-replicaset-hngsg, resource: bindings, ignored listing per whitelist
Dec  5 20:35:46.469: INFO: namespace e2e-tests-replicaset-hngsg deletion completed in 22.283803881s

• [SLOW TEST:28.405 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:35:46.469: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 20:35:46.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 version'
Dec  5 20:35:46.609: INFO: stderr: ""
Dec  5 20:35:46.610: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T20:56:12Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:35:46.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qr6vm" for this suite.
Dec  5 20:35:52.624: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:35:52.658: INFO: namespace: e2e-tests-kubectl-qr6vm, resource: bindings, ignored listing per whitelist
Dec  5 20:35:52.912: INFO: namespace e2e-tests-kubectl-qr6vm deletion completed in 6.299610806s

• [SLOW TEST:6.443 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:35:52.912: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:35:52.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-q2tw6" for this suite.
Dec  5 20:35:58.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:35:59.066: INFO: namespace: e2e-tests-services-q2tw6, resource: bindings, ignored listing per whitelist
Dec  5 20:35:59.085: INFO: namespace e2e-tests-services-q2tw6 deletion completed in 6.109437821s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:6.173 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:35:59.085: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-z25fx
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-z25fx
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-z25fx
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-z25fx
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-z25fx
Dec  5 20:36:03.224: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-z25fx, name: ss-0, uid: 61b61fe0-f8cd-11e8-b622-12e7eb78a7a2, status phase: Failed. Waiting for statefulset controller to delete.
Dec  5 20:36:03.228: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-z25fx, name: ss-0, uid: 61b61fe0-f8cd-11e8-b622-12e7eb78a7a2, status phase: Failed. Waiting for statefulset controller to delete.
Dec  5 20:36:03.233: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-z25fx
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-z25fx
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-z25fx and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  5 20:36:07.260: INFO: Deleting all statefulset in ns e2e-tests-statefulset-z25fx
Dec  5 20:36:07.263: INFO: Scaling statefulset ss to 0
Dec  5 20:36:17.277: INFO: Waiting for statefulset status.replicas updated to 0
Dec  5 20:36:17.280: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:36:17.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-z25fx" for this suite.
Dec  5 20:36:23.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:36:23.413: INFO: namespace: e2e-tests-statefulset-z25fx, resource: bindings, ignored listing per whitelist
Dec  5 20:36:23.469: INFO: namespace e2e-tests-statefulset-z25fx deletion completed in 6.170970141s

• [SLOW TEST:24.384 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:36:23.469: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec  5 20:36:23.526: INFO: PodSpec: initContainers in spec.initContainers
Dec  5 20:37:13.579: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-6e2d82fd-f8cd-11e8-b559-c27407a18179", GenerateName:"", Namespace:"e2e-tests-init-container-mlql2", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-mlql2/pods/pod-init-6e2d82fd-f8cd-11e8-b559-c27407a18179", UID:"6e2c0bcf-f8cd-11e8-b622-12e7eb78a7a2", ResourceVersion:"16051", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63679638983, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"526071850"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-v8zgj", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0022a3940), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-v8zgj", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-v8zgj", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-v8zgj", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0022a5d68), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-31-24-193", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0023fd440), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001e7c050)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001e7c070)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001e7c078)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679638983, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679638983, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679638983, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679638983, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.31.24.193", PodIP:"10.1.41.171", StartTime:(*v1.Time)(0xc00242fb20), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002212770)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002212850)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:2a03a6059f21e150ae84b0973863609494aad70f0a80eaeb64bddd8d92465812", ContainerID:"docker://1b84a4b6da4967045b837d43d4f911af1acfcca927f8f695a9ea0fe5275b3c01"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00242fb60), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00242fb40), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:37:13.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-mlql2" for this suite.
Dec  5 20:37:35.595: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:37:35.723: INFO: namespace: e2e-tests-init-container-mlql2, resource: bindings, ignored listing per whitelist
Dec  5 20:37:35.753: INFO: namespace e2e-tests-init-container-mlql2 deletion completed in 22.169417706s

• [SLOW TEST:72.284 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:37:35.753: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Dec  5 20:37:35.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 create -f - --namespace=e2e-tests-kubectl-f8dmp'
Dec  5 20:37:36.246: INFO: stderr: ""
Dec  5 20:37:36.246: INFO: stdout: "pod/pause created\n"
Dec  5 20:37:36.246: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Dec  5 20:37:36.246: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-f8dmp" to be "running and ready"
Dec  5 20:37:36.249: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 3.154398ms
Dec  5 20:37:38.256: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010266903s
Dec  5 20:37:40.262: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.016159044s
Dec  5 20:37:40.262: INFO: Pod "pause" satisfied condition "running and ready"
Dec  5 20:37:40.262: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Dec  5 20:37:40.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-f8dmp'
Dec  5 20:37:40.354: INFO: stderr: ""
Dec  5 20:37:40.354: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Dec  5 20:37:40.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pod pause -L testing-label --namespace=e2e-tests-kubectl-f8dmp'
Dec  5 20:37:40.460: INFO: stderr: ""
Dec  5 20:37:40.460: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Dec  5 20:37:40.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 label pods pause testing-label- --namespace=e2e-tests-kubectl-f8dmp'
Dec  5 20:37:40.539: INFO: stderr: ""
Dec  5 20:37:40.539: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Dec  5 20:37:40.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pod pause -L testing-label --namespace=e2e-tests-kubectl-f8dmp'
Dec  5 20:37:40.626: INFO: stderr: ""
Dec  5 20:37:40.626: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Dec  5 20:37:40.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-f8dmp'
Dec  5 20:37:40.718: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  5 20:37:40.718: INFO: stdout: "pod \"pause\" force deleted\n"
Dec  5 20:37:40.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-f8dmp'
Dec  5 20:37:40.808: INFO: stderr: "No resources found.\n"
Dec  5 20:37:40.808: INFO: stdout: ""
Dec  5 20:37:40.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods -l name=pause --namespace=e2e-tests-kubectl-f8dmp -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  5 20:37:40.886: INFO: stderr: ""
Dec  5 20:37:40.886: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:37:40.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-f8dmp" for this suite.
Dec  5 20:37:46.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:37:46.949: INFO: namespace: e2e-tests-kubectl-f8dmp, resource: bindings, ignored listing per whitelist
Dec  5 20:37:47.015: INFO: namespace e2e-tests-kubectl-f8dmp deletion completed in 6.125484681s

• [SLOW TEST:11.262 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:37:47.015: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 20:37:47.086: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:37:51.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-95m5b" for this suite.
Dec  5 20:38:31.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:38:31.318: INFO: namespace: e2e-tests-pods-95m5b, resource: bindings, ignored listing per whitelist
Dec  5 20:38:31.385: INFO: namespace e2e-tests-pods-95m5b deletion completed in 40.125667969s

• [SLOW TEST:44.370 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:38:31.385: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  5 20:38:31.456: INFO: Waiting up to 5m0s for pod "downward-api-ba6d2b84-f8cd-11e8-b559-c27407a18179" in namespace "e2e-tests-downward-api-zjz8f" to be "success or failure"
Dec  5 20:38:31.461: INFO: Pod "downward-api-ba6d2b84-f8cd-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 4.896832ms
Dec  5 20:38:33.464: INFO: Pod "downward-api-ba6d2b84-f8cd-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008231975s
Dec  5 20:38:35.468: INFO: Pod "downward-api-ba6d2b84-f8cd-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012033599s
STEP: Saw pod success
Dec  5 20:38:35.468: INFO: Pod "downward-api-ba6d2b84-f8cd-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 20:38:35.471: INFO: Trying to get logs from node ip-172-31-24-193 pod downward-api-ba6d2b84-f8cd-11e8-b559-c27407a18179 container dapi-container: <nil>
STEP: delete the pod
Dec  5 20:38:35.489: INFO: Waiting for pod downward-api-ba6d2b84-f8cd-11e8-b559-c27407a18179 to disappear
Dec  5 20:38:35.492: INFO: Pod downward-api-ba6d2b84-f8cd-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:38:35.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-zjz8f" for this suite.
Dec  5 20:38:41.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:38:41.747: INFO: namespace: e2e-tests-downward-api-zjz8f, resource: bindings, ignored listing per whitelist
Dec  5 20:38:41.752: INFO: namespace e2e-tests-downward-api-zjz8f deletion completed in 6.256634988s

• [SLOW TEST:10.367 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:38:41.752: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec  5 20:38:41.811: INFO: Waiting up to 5m0s for pod "pod-c0995497-f8cd-11e8-b559-c27407a18179" in namespace "e2e-tests-emptydir-pwfxp" to be "success or failure"
Dec  5 20:38:41.815: INFO: Pod "pod-c0995497-f8cd-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 3.859165ms
Dec  5 20:38:43.820: INFO: Pod "pod-c0995497-f8cd-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008660049s
Dec  5 20:38:45.823: INFO: Pod "pod-c0995497-f8cd-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011767606s
STEP: Saw pod success
Dec  5 20:38:45.823: INFO: Pod "pod-c0995497-f8cd-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 20:38:45.826: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-c0995497-f8cd-11e8-b559-c27407a18179 container test-container: <nil>
STEP: delete the pod
Dec  5 20:38:45.844: INFO: Waiting for pod pod-c0995497-f8cd-11e8-b559-c27407a18179 to disappear
Dec  5 20:38:45.847: INFO: Pod pod-c0995497-f8cd-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:38:45.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-pwfxp" for this suite.
Dec  5 20:38:51.860: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:38:51.901: INFO: namespace: e2e-tests-emptydir-pwfxp, resource: bindings, ignored listing per whitelist
Dec  5 20:38:51.956: INFO: namespace e2e-tests-emptydir-pwfxp deletion completed in 6.105659756s

• [SLOW TEST:10.203 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:38:51.956: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-c6aed93e-f8cd-11e8-b559-c27407a18179
STEP: Creating a pod to test consume configMaps
Dec  5 20:38:52.024: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c6af6b74-f8cd-11e8-b559-c27407a18179" in namespace "e2e-tests-projected-rjm4v" to be "success or failure"
Dec  5 20:38:52.030: INFO: Pod "pod-projected-configmaps-c6af6b74-f8cd-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 5.22813ms
Dec  5 20:38:54.034: INFO: Pod "pod-projected-configmaps-c6af6b74-f8cd-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009312284s
Dec  5 20:38:56.038: INFO: Pod "pod-projected-configmaps-c6af6b74-f8cd-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013515797s
STEP: Saw pod success
Dec  5 20:38:56.038: INFO: Pod "pod-projected-configmaps-c6af6b74-f8cd-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 20:38:56.041: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-projected-configmaps-c6af6b74-f8cd-11e8-b559-c27407a18179 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 20:38:56.060: INFO: Waiting for pod pod-projected-configmaps-c6af6b74-f8cd-11e8-b559-c27407a18179 to disappear
Dec  5 20:38:56.063: INFO: Pod pod-projected-configmaps-c6af6b74-f8cd-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:38:56.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rjm4v" for this suite.
Dec  5 20:39:02.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:39:02.199: INFO: namespace: e2e-tests-projected-rjm4v, resource: bindings, ignored listing per whitelist
Dec  5 20:39:02.212: INFO: namespace e2e-tests-projected-rjm4v deletion completed in 6.144840821s

• [SLOW TEST:10.256 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:39:02.212: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec  5 20:39:10.322: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  5 20:39:10.325: INFO: Pod pod-with-poststart-http-hook still exists
Dec  5 20:39:12.325: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  5 20:39:12.329: INFO: Pod pod-with-poststart-http-hook still exists
Dec  5 20:39:14.325: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  5 20:39:14.329: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:39:14.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-bbbph" for this suite.
Dec  5 20:39:36.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:39:36.428: INFO: namespace: e2e-tests-container-lifecycle-hook-bbbph, resource: bindings, ignored listing per whitelist
Dec  5 20:39:36.481: INFO: namespace e2e-tests-container-lifecycle-hook-bbbph deletion completed in 22.148107172s

• [SLOW TEST:34.269 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:39:36.481: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Dec  5 20:39:42.583: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-r7d4c PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 20:39:42.583: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
Dec  5 20:39:42.680: INFO: Exec stderr: ""
Dec  5 20:39:42.680: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-r7d4c PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 20:39:42.680: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
Dec  5 20:39:42.779: INFO: Exec stderr: ""
Dec  5 20:39:42.779: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-r7d4c PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 20:39:42.779: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
Dec  5 20:39:42.853: INFO: Exec stderr: ""
Dec  5 20:39:42.853: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-r7d4c PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 20:39:42.853: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
Dec  5 20:39:42.931: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Dec  5 20:39:42.931: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-r7d4c PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 20:39:42.931: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
Dec  5 20:39:43.008: INFO: Exec stderr: ""
Dec  5 20:39:43.008: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-r7d4c PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 20:39:43.008: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
Dec  5 20:39:43.083: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Dec  5 20:39:43.083: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-r7d4c PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 20:39:43.083: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
Dec  5 20:39:43.167: INFO: Exec stderr: ""
Dec  5 20:39:43.167: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-r7d4c PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 20:39:43.167: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
Dec  5 20:39:43.256: INFO: Exec stderr: ""
Dec  5 20:39:43.256: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-r7d4c PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 20:39:43.256: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
Dec  5 20:39:43.342: INFO: Exec stderr: ""
Dec  5 20:39:43.342: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-r7d4c PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 20:39:43.342: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
Dec  5 20:39:43.431: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:39:43.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-r7d4c" for this suite.
Dec  5 20:40:21.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:40:21.527: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-r7d4c, resource: bindings, ignored listing per whitelist
Dec  5 20:40:21.541: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-r7d4c deletion completed in 38.106261692s

• [SLOW TEST:45.060 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:40:21.542: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-84cp
STEP: Creating a pod to test atomic-volume-subpath
Dec  5 20:40:21.672: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-84cp" in namespace "e2e-tests-subpath-q7mx5" to be "success or failure"
Dec  5 20:40:21.676: INFO: Pod "pod-subpath-test-projected-84cp": Phase="Pending", Reason="", readiness=false. Elapsed: 4.179463ms
Dec  5 20:40:23.681: INFO: Pod "pod-subpath-test-projected-84cp": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008974015s
Dec  5 20:40:25.685: INFO: Pod "pod-subpath-test-projected-84cp": Phase="Running", Reason="", readiness=false. Elapsed: 4.012815268s
Dec  5 20:40:27.688: INFO: Pod "pod-subpath-test-projected-84cp": Phase="Running", Reason="", readiness=false. Elapsed: 6.016260369s
Dec  5 20:40:29.692: INFO: Pod "pod-subpath-test-projected-84cp": Phase="Running", Reason="", readiness=false. Elapsed: 8.020233699s
Dec  5 20:40:31.696: INFO: Pod "pod-subpath-test-projected-84cp": Phase="Running", Reason="", readiness=false. Elapsed: 10.023815955s
Dec  5 20:40:33.699: INFO: Pod "pod-subpath-test-projected-84cp": Phase="Running", Reason="", readiness=false. Elapsed: 12.027013134s
Dec  5 20:40:35.703: INFO: Pod "pod-subpath-test-projected-84cp": Phase="Running", Reason="", readiness=false. Elapsed: 14.030555653s
Dec  5 20:40:37.706: INFO: Pod "pod-subpath-test-projected-84cp": Phase="Running", Reason="", readiness=false. Elapsed: 16.034335089s
Dec  5 20:40:39.710: INFO: Pod "pod-subpath-test-projected-84cp": Phase="Running", Reason="", readiness=false. Elapsed: 18.037952613s
Dec  5 20:40:41.713: INFO: Pod "pod-subpath-test-projected-84cp": Phase="Running", Reason="", readiness=false. Elapsed: 20.041493091s
Dec  5 20:40:43.717: INFO: Pod "pod-subpath-test-projected-84cp": Phase="Running", Reason="", readiness=false. Elapsed: 22.045440093s
Dec  5 20:40:45.721: INFO: Pod "pod-subpath-test-projected-84cp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.049111245s
STEP: Saw pod success
Dec  5 20:40:45.721: INFO: Pod "pod-subpath-test-projected-84cp" satisfied condition "success or failure"
Dec  5 20:40:45.724: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-subpath-test-projected-84cp container test-container-subpath-projected-84cp: <nil>
STEP: delete the pod
Dec  5 20:40:45.743: INFO: Waiting for pod pod-subpath-test-projected-84cp to disappear
Dec  5 20:40:45.746: INFO: Pod pod-subpath-test-projected-84cp no longer exists
STEP: Deleting pod pod-subpath-test-projected-84cp
Dec  5 20:40:45.746: INFO: Deleting pod "pod-subpath-test-projected-84cp" in namespace "e2e-tests-subpath-q7mx5"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:40:45.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-q7mx5" for this suite.
Dec  5 20:40:51.769: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:40:51.983: INFO: namespace: e2e-tests-subpath-q7mx5, resource: bindings, ignored listing per whitelist
Dec  5 20:40:52.020: INFO: namespace e2e-tests-subpath-q7mx5 deletion completed in 6.268462045s

• [SLOW TEST:30.478 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:40:52.020: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Dec  5 20:40:56.103: INFO: Pod pod-hostip-0e3efe43-f8ce-11e8-b559-c27407a18179 has hostIP: 172.31.24.193
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:40:56.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-c8lft" for this suite.
Dec  5 20:41:18.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:41:18.165: INFO: namespace: e2e-tests-pods-c8lft, resource: bindings, ignored listing per whitelist
Dec  5 20:41:18.284: INFO: namespace e2e-tests-pods-c8lft deletion completed in 22.177837134s

• [SLOW TEST:26.264 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:41:18.284: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-1de74346-f8ce-11e8-b559-c27407a18179
STEP: Creating a pod to test consume configMaps
Dec  5 20:41:18.357: INFO: Waiting up to 5m0s for pod "pod-configmaps-1de7f787-f8ce-11e8-b559-c27407a18179" in namespace "e2e-tests-configmap-xfwj7" to be "success or failure"
Dec  5 20:41:18.360: INFO: Pod "pod-configmaps-1de7f787-f8ce-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 3.346904ms
Dec  5 20:41:20.364: INFO: Pod "pod-configmaps-1de7f787-f8ce-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006874565s
Dec  5 20:41:22.367: INFO: Pod "pod-configmaps-1de7f787-f8ce-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010784851s
STEP: Saw pod success
Dec  5 20:41:22.367: INFO: Pod "pod-configmaps-1de7f787-f8ce-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 20:41:22.370: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-configmaps-1de7f787-f8ce-11e8-b559-c27407a18179 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 20:41:22.391: INFO: Waiting for pod pod-configmaps-1de7f787-f8ce-11e8-b559-c27407a18179 to disappear
Dec  5 20:41:22.393: INFO: Pod pod-configmaps-1de7f787-f8ce-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:41:22.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-xfwj7" for this suite.
Dec  5 20:41:28.407: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:41:28.490: INFO: namespace: e2e-tests-configmap-xfwj7, resource: bindings, ignored listing per whitelist
Dec  5 20:41:28.514: INFO: namespace e2e-tests-configmap-xfwj7 deletion completed in 6.116845749s

• [SLOW TEST:10.230 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:41:28.514: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-23ffeb27-f8ce-11e8-b559-c27407a18179
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-23ffeb27-f8ce-11e8-b559-c27407a18179
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:42:35.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rwln6" for this suite.
Dec  5 20:42:57.237: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:42:57.257: INFO: namespace: e2e-tests-projected-rwln6, resource: bindings, ignored listing per whitelist
Dec  5 20:42:57.337: INFO: namespace e2e-tests-projected-rwln6 deletion completed in 22.111811467s

• [SLOW TEST:88.824 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:42:57.338: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:43:01.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-xgfbm" for this suite.
Dec  5 20:43:39.505: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:43:39.529: INFO: namespace: e2e-tests-kubelet-test-xgfbm, resource: bindings, ignored listing per whitelist
Dec  5 20:43:39.591: INFO: namespace e2e-tests-kubelet-test-xgfbm deletion completed in 38.100522538s

• [SLOW TEST:42.254 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:43:39.592: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Dec  5 20:43:39.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 create -f - --namespace=e2e-tests-kubectl-tmgm5'
Dec  5 20:43:40.135: INFO: stderr: ""
Dec  5 20:43:40.135: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  5 20:43:40.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-tmgm5'
Dec  5 20:43:40.259: INFO: stderr: ""
Dec  5 20:43:40.259: INFO: stdout: "update-demo-nautilus-5dms8 update-demo-nautilus-kq4p2 "
Dec  5 20:43:40.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods update-demo-nautilus-5dms8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tmgm5'
Dec  5 20:43:40.362: INFO: stderr: ""
Dec  5 20:43:40.362: INFO: stdout: ""
Dec  5 20:43:40.362: INFO: update-demo-nautilus-5dms8 is created but not running
Dec  5 20:43:45.362: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-tmgm5'
Dec  5 20:43:45.472: INFO: stderr: ""
Dec  5 20:43:45.472: INFO: stdout: "update-demo-nautilus-5dms8 update-demo-nautilus-kq4p2 "
Dec  5 20:43:45.472: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods update-demo-nautilus-5dms8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tmgm5'
Dec  5 20:43:45.575: INFO: stderr: ""
Dec  5 20:43:45.575: INFO: stdout: "true"
Dec  5 20:43:45.575: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods update-demo-nautilus-5dms8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tmgm5'
Dec  5 20:43:45.692: INFO: stderr: ""
Dec  5 20:43:45.692: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  5 20:43:45.692: INFO: validating pod update-demo-nautilus-5dms8
Dec  5 20:43:45.705: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  5 20:43:45.705: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  5 20:43:45.705: INFO: update-demo-nautilus-5dms8 is verified up and running
Dec  5 20:43:45.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods update-demo-nautilus-kq4p2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tmgm5'
Dec  5 20:43:45.797: INFO: stderr: ""
Dec  5 20:43:45.797: INFO: stdout: "true"
Dec  5 20:43:45.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods update-demo-nautilus-kq4p2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tmgm5'
Dec  5 20:43:45.916: INFO: stderr: ""
Dec  5 20:43:45.916: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  5 20:43:45.916: INFO: validating pod update-demo-nautilus-kq4p2
Dec  5 20:43:45.924: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  5 20:43:45.924: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  5 20:43:45.924: INFO: update-demo-nautilus-kq4p2 is verified up and running
STEP: scaling down the replication controller
Dec  5 20:43:45.925: INFO: scanned /root for discovery docs: <nil>
Dec  5 20:43:45.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-tmgm5'
Dec  5 20:43:47.070: INFO: stderr: ""
Dec  5 20:43:47.070: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  5 20:43:47.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-tmgm5'
Dec  5 20:43:47.169: INFO: stderr: ""
Dec  5 20:43:47.169: INFO: stdout: "update-demo-nautilus-5dms8 update-demo-nautilus-kq4p2 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec  5 20:43:52.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-tmgm5'
Dec  5 20:43:52.281: INFO: stderr: ""
Dec  5 20:43:52.281: INFO: stdout: "update-demo-nautilus-kq4p2 "
Dec  5 20:43:52.281: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods update-demo-nautilus-kq4p2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tmgm5'
Dec  5 20:43:52.398: INFO: stderr: ""
Dec  5 20:43:52.398: INFO: stdout: "true"
Dec  5 20:43:52.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods update-demo-nautilus-kq4p2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tmgm5'
Dec  5 20:43:52.497: INFO: stderr: ""
Dec  5 20:43:52.497: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  5 20:43:52.497: INFO: validating pod update-demo-nautilus-kq4p2
Dec  5 20:43:52.502: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  5 20:43:52.502: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  5 20:43:52.502: INFO: update-demo-nautilus-kq4p2 is verified up and running
STEP: scaling up the replication controller
Dec  5 20:43:52.503: INFO: scanned /root for discovery docs: <nil>
Dec  5 20:43:52.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-tmgm5'
Dec  5 20:43:53.643: INFO: stderr: ""
Dec  5 20:43:53.644: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  5 20:43:53.644: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-tmgm5'
Dec  5 20:43:53.771: INFO: stderr: ""
Dec  5 20:43:53.771: INFO: stdout: "update-demo-nautilus-4bv2v update-demo-nautilus-kq4p2 "
Dec  5 20:43:53.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods update-demo-nautilus-4bv2v -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tmgm5'
Dec  5 20:43:53.882: INFO: stderr: ""
Dec  5 20:43:53.882: INFO: stdout: ""
Dec  5 20:43:53.882: INFO: update-demo-nautilus-4bv2v is created but not running
Dec  5 20:43:58.882: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-tmgm5'
Dec  5 20:43:58.984: INFO: stderr: ""
Dec  5 20:43:58.984: INFO: stdout: "update-demo-nautilus-4bv2v update-demo-nautilus-kq4p2 "
Dec  5 20:43:58.984: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods update-demo-nautilus-4bv2v -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tmgm5'
Dec  5 20:43:59.086: INFO: stderr: ""
Dec  5 20:43:59.086: INFO: stdout: "true"
Dec  5 20:43:59.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods update-demo-nautilus-4bv2v -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tmgm5'
Dec  5 20:43:59.193: INFO: stderr: ""
Dec  5 20:43:59.193: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  5 20:43:59.193: INFO: validating pod update-demo-nautilus-4bv2v
Dec  5 20:43:59.202: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  5 20:43:59.202: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  5 20:43:59.202: INFO: update-demo-nautilus-4bv2v is verified up and running
Dec  5 20:43:59.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods update-demo-nautilus-kq4p2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tmgm5'
Dec  5 20:43:59.311: INFO: stderr: ""
Dec  5 20:43:59.311: INFO: stdout: "true"
Dec  5 20:43:59.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods update-demo-nautilus-kq4p2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tmgm5'
Dec  5 20:43:59.416: INFO: stderr: ""
Dec  5 20:43:59.417: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  5 20:43:59.417: INFO: validating pod update-demo-nautilus-kq4p2
Dec  5 20:43:59.422: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  5 20:43:59.422: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  5 20:43:59.422: INFO: update-demo-nautilus-kq4p2 is verified up and running
STEP: using delete to clean up resources
Dec  5 20:43:59.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-tmgm5'
Dec  5 20:43:59.537: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  5 20:43:59.537: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec  5 20:43:59.537: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-tmgm5'
Dec  5 20:43:59.651: INFO: stderr: "No resources found.\n"
Dec  5 20:43:59.651: INFO: stdout: ""
Dec  5 20:43:59.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods -l name=update-demo --namespace=e2e-tests-kubectl-tmgm5 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  5 20:43:59.765: INFO: stderr: ""
Dec  5 20:43:59.765: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:43:59.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tmgm5" for this suite.
Dec  5 20:44:21.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:44:21.890: INFO: namespace: e2e-tests-kubectl-tmgm5, resource: bindings, ignored listing per whitelist
Dec  5 20:44:21.923: INFO: namespace e2e-tests-kubectl-tmgm5 deletion completed in 22.154341452s

• [SLOW TEST:42.331 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:44:21.923: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W1205 20:44:52.156988      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  5 20:44:52.157: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:44:52.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-jj8t8" for this suite.
Dec  5 20:44:58.170: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:44:58.244: INFO: namespace: e2e-tests-gc-jj8t8, resource: bindings, ignored listing per whitelist
Dec  5 20:44:58.263: INFO: namespace e2e-tests-gc-jj8t8 deletion completed in 6.103109668s

• [SLOW TEST:36.340 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:44:58.263: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-a10451ce-f8ce-11e8-b559-c27407a18179
STEP: Creating a pod to test consume configMaps
Dec  5 20:44:58.328: INFO: Waiting up to 5m0s for pod "pod-configmaps-a104dd60-f8ce-11e8-b559-c27407a18179" in namespace "e2e-tests-configmap-cqcz6" to be "success or failure"
Dec  5 20:44:58.332: INFO: Pod "pod-configmaps-a104dd60-f8ce-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 4.116132ms
Dec  5 20:45:00.336: INFO: Pod "pod-configmaps-a104dd60-f8ce-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007672703s
STEP: Saw pod success
Dec  5 20:45:00.336: INFO: Pod "pod-configmaps-a104dd60-f8ce-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 20:45:00.339: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-configmaps-a104dd60-f8ce-11e8-b559-c27407a18179 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 20:45:00.356: INFO: Waiting for pod pod-configmaps-a104dd60-f8ce-11e8-b559-c27407a18179 to disappear
Dec  5 20:45:00.359: INFO: Pod pod-configmaps-a104dd60-f8ce-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:45:00.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-cqcz6" for this suite.
Dec  5 20:45:06.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:45:06.404: INFO: namespace: e2e-tests-configmap-cqcz6, resource: bindings, ignored listing per whitelist
Dec  5 20:45:06.466: INFO: namespace e2e-tests-configmap-cqcz6 deletion completed in 6.104262365s

• [SLOW TEST:8.203 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:45:06.466: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 20:45:06.531: INFO: Pod name rollover-pod: Found 0 pods out of 1
Dec  5 20:45:11.535: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  5 20:45:11.535: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Dec  5 20:45:13.538: INFO: Creating deployment "test-rollover-deployment"
Dec  5 20:45:13.547: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Dec  5 20:45:15.561: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Dec  5 20:45:15.572: INFO: Ensure that both replica sets have 1 created replica
Dec  5 20:45:15.582: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Dec  5 20:45:15.595: INFO: Updating deployment test-rollover-deployment
Dec  5 20:45:15.595: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Dec  5 20:45:17.607: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Dec  5 20:45:17.622: INFO: Make sure deployment "test-rollover-deployment" is complete
Dec  5 20:45:17.641: INFO: all replica sets need to contain the pod-template-hash label
Dec  5 20:45:17.641: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679639513, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679639513, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679639515, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679639513, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  5 20:45:19.650: INFO: all replica sets need to contain the pod-template-hash label
Dec  5 20:45:19.650: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679639513, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679639513, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679639518, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679639513, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  5 20:45:21.654: INFO: all replica sets need to contain the pod-template-hash label
Dec  5 20:45:21.654: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679639513, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679639513, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679639518, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679639513, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  5 20:45:23.650: INFO: all replica sets need to contain the pod-template-hash label
Dec  5 20:45:23.650: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679639513, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679639513, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679639518, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679639513, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  5 20:45:25.650: INFO: all replica sets need to contain the pod-template-hash label
Dec  5 20:45:25.650: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679639513, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679639513, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679639518, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679639513, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  5 20:45:27.650: INFO: all replica sets need to contain the pod-template-hash label
Dec  5 20:45:27.650: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679639513, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679639513, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679639518, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679639513, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  5 20:45:29.650: INFO: 
Dec  5 20:45:29.650: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  5 20:45:29.663: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-h8msd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-h8msd/deployments/test-rollover-deployment,UID:aa14f49d-f8ce-11e8-b622-12e7eb78a7a2,ResourceVersion:17494,Generation:2,CreationTimestamp:2018-12-05 20:45:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-12-05 20:45:13 +0000 UTC 2018-12-05 20:45:13 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-12-05 20:45:28 +0000 UTC 2018-12-05 20:45:13 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec  5 20:45:29.668: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-h8msd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-h8msd/replicasets/test-rollover-deployment-6b7f9d6597,UID:ab4eab9c-f8ce-11e8-b622-12e7eb78a7a2,ResourceVersion:17485,Generation:2,CreationTimestamp:2018-12-05 20:45:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment aa14f49d-f8ce-11e8-b622-12e7eb78a7a2 0xc001c7c827 0xc001c7c828}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec  5 20:45:29.668: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Dec  5 20:45:29.668: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-h8msd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-h8msd/replicasets/test-rollover-controller,UID:a5e64e4c-f8ce-11e8-b622-12e7eb78a7a2,ResourceVersion:17493,Generation:2,CreationTimestamp:2018-12-05 20:45:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment aa14f49d-f8ce-11e8-b622-12e7eb78a7a2 0xc001c7c697 0xc001c7c698}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  5 20:45:29.668: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-h8msd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-h8msd/replicasets/test-rollover-deployment-6586df867b,UID:aa16cdd3-f8ce-11e8-b622-12e7eb78a7a2,ResourceVersion:17456,Generation:2,CreationTimestamp:2018-12-05 20:45:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment aa14f49d-f8ce-11e8-b622-12e7eb78a7a2 0xc001c7c757 0xc001c7c758}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  5 20:45:29.673: INFO: Pod "test-rollover-deployment-6b7f9d6597-8dcfz" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-8dcfz,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-h8msd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-h8msd/pods/test-rollover-deployment-6b7f9d6597-8dcfz,UID:ab5553d4-f8ce-11e8-b622-12e7eb78a7a2,ResourceVersion:17466,Generation:0,CreationTimestamp:2018-12-05 20:45:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 ab4eab9c-f8ce-11e8-b622-12e7eb78a7a2 0xc001c7d467 0xc001c7d468}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-c6vkn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-c6vkn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-c6vkn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-24-193,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c7d4f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c7d510}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:45:15 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:45:18 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:45:18 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:45:15 +0000 UTC  }],Message:,Reason:,HostIP:172.31.24.193,PodIP:10.1.41.190,StartTime:2018-12-05 20:45:15 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-12-05 20:45:17 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://116386ffa52117d7e78812d78f4d64f9e331d32d5f42431c3216ab305a501f0f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:45:29.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-h8msd" for this suite.
Dec  5 20:45:35.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:45:35.719: INFO: namespace: e2e-tests-deployment-h8msd, resource: bindings, ignored listing per whitelist
Dec  5 20:45:35.911: INFO: namespace e2e-tests-deployment-h8msd deletion completed in 6.234052804s

• [SLOW TEST:29.445 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:45:35.911: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec  5 20:45:44.089: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 20:45:44.092: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  5 20:45:46.092: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 20:45:46.096: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  5 20:45:48.092: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 20:45:48.096: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  5 20:45:50.092: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 20:45:50.113: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  5 20:45:52.092: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 20:45:52.095: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  5 20:45:54.092: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 20:45:54.096: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  5 20:45:56.092: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 20:45:56.096: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  5 20:45:58.092: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 20:45:58.096: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  5 20:46:00.092: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 20:46:00.096: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  5 20:46:02.092: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 20:46:02.096: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:46:02.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-bb56g" for this suite.
Dec  5 20:46:24.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:46:24.228: INFO: namespace: e2e-tests-container-lifecycle-hook-bb56g, resource: bindings, ignored listing per whitelist
Dec  5 20:46:24.506: INFO: namespace e2e-tests-container-lifecycle-hook-bb56g deletion completed in 22.406431832s

• [SLOW TEST:48.595 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:46:24.506: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Dec  5 20:46:24.636: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-sjll7,SelfLink:/api/v1/namespaces/e2e-tests-watch-sjll7/configmaps/e2e-watch-test-configmap-a,UID:d4753f71-f8ce-11e8-b622-12e7eb78a7a2,ResourceVersion:17673,Generation:0,CreationTimestamp:2018-12-05 20:46:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  5 20:46:24.636: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-sjll7,SelfLink:/api/v1/namespaces/e2e-tests-watch-sjll7/configmaps/e2e-watch-test-configmap-a,UID:d4753f71-f8ce-11e8-b622-12e7eb78a7a2,ResourceVersion:17673,Generation:0,CreationTimestamp:2018-12-05 20:46:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Dec  5 20:46:34.644: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-sjll7,SelfLink:/api/v1/namespaces/e2e-tests-watch-sjll7/configmaps/e2e-watch-test-configmap-a,UID:d4753f71-f8ce-11e8-b622-12e7eb78a7a2,ResourceVersion:17690,Generation:0,CreationTimestamp:2018-12-05 20:46:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec  5 20:46:34.644: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-sjll7,SelfLink:/api/v1/namespaces/e2e-tests-watch-sjll7/configmaps/e2e-watch-test-configmap-a,UID:d4753f71-f8ce-11e8-b622-12e7eb78a7a2,ResourceVersion:17690,Generation:0,CreationTimestamp:2018-12-05 20:46:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Dec  5 20:46:44.654: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-sjll7,SelfLink:/api/v1/namespaces/e2e-tests-watch-sjll7/configmaps/e2e-watch-test-configmap-a,UID:d4753f71-f8ce-11e8-b622-12e7eb78a7a2,ResourceVersion:17707,Generation:0,CreationTimestamp:2018-12-05 20:46:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  5 20:46:44.654: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-sjll7,SelfLink:/api/v1/namespaces/e2e-tests-watch-sjll7/configmaps/e2e-watch-test-configmap-a,UID:d4753f71-f8ce-11e8-b622-12e7eb78a7a2,ResourceVersion:17707,Generation:0,CreationTimestamp:2018-12-05 20:46:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Dec  5 20:46:54.662: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-sjll7,SelfLink:/api/v1/namespaces/e2e-tests-watch-sjll7/configmaps/e2e-watch-test-configmap-a,UID:d4753f71-f8ce-11e8-b622-12e7eb78a7a2,ResourceVersion:17726,Generation:0,CreationTimestamp:2018-12-05 20:46:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  5 20:46:54.662: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-sjll7,SelfLink:/api/v1/namespaces/e2e-tests-watch-sjll7/configmaps/e2e-watch-test-configmap-a,UID:d4753f71-f8ce-11e8-b622-12e7eb78a7a2,ResourceVersion:17726,Generation:0,CreationTimestamp:2018-12-05 20:46:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Dec  5 20:47:04.672: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-sjll7,SelfLink:/api/v1/namespaces/e2e-tests-watch-sjll7/configmaps/e2e-watch-test-configmap-b,UID:ec515f52-f8ce-11e8-b622-12e7eb78a7a2,ResourceVersion:17743,Generation:0,CreationTimestamp:2018-12-05 20:47:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  5 20:47:04.672: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-sjll7,SelfLink:/api/v1/namespaces/e2e-tests-watch-sjll7/configmaps/e2e-watch-test-configmap-b,UID:ec515f52-f8ce-11e8-b622-12e7eb78a7a2,ResourceVersion:17743,Generation:0,CreationTimestamp:2018-12-05 20:47:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Dec  5 20:47:14.680: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-sjll7,SelfLink:/api/v1/namespaces/e2e-tests-watch-sjll7/configmaps/e2e-watch-test-configmap-b,UID:ec515f52-f8ce-11e8-b622-12e7eb78a7a2,ResourceVersion:17760,Generation:0,CreationTimestamp:2018-12-05 20:47:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  5 20:47:14.680: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-sjll7,SelfLink:/api/v1/namespaces/e2e-tests-watch-sjll7/configmaps/e2e-watch-test-configmap-b,UID:ec515f52-f8ce-11e8-b622-12e7eb78a7a2,ResourceVersion:17760,Generation:0,CreationTimestamp:2018-12-05 20:47:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:47:24.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-sjll7" for this suite.
Dec  5 20:47:31.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:47:31.211: INFO: namespace: e2e-tests-watch-sjll7, resource: bindings, ignored listing per whitelist
Dec  5 20:47:31.234: INFO: namespace e2e-tests-watch-sjll7 deletion completed in 6.129549962s

• [SLOW TEST:66.727 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:47:31.234: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Dec  5 20:47:31.302: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  5 20:47:31.308: INFO: Waiting for terminating namespaces to be deleted...
Dec  5 20:47:31.310: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-2-231 before test
Dec  5 20:47:31.332: INFO: kube-dns-8f7866879-f6tkp from kube-system started at 2018-12-05 19:17:08 +0000 UTC (3 container statuses recorded)
Dec  5 20:47:31.332: INFO: 	Container dnsmasq ready: true, restart count 0
Dec  5 20:47:31.332: INFO: 	Container kubedns ready: true, restart count 0
Dec  5 20:47:31.332: INFO: 	Container sidecar ready: true, restart count 0
Dec  5 20:47:31.332: INFO: sonobuoy-systemd-logs-daemon-set-5821f0bd06934aee-wxzkp from heptio-sonobuoy started at 2018-12-05 19:28:41 +0000 UTC (2 container statuses recorded)
Dec  5 20:47:31.332: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec  5 20:47:31.332: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec  5 20:47:31.332: INFO: kubernetes-dashboard-654cfb4879-bwd9z from kube-system started at 2018-12-05 19:17:08 +0000 UTC (1 container statuses recorded)
Dec  5 20:47:31.332: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec  5 20:47:31.332: INFO: monitoring-influxdb-grafana-v4-5866497777-xh229 from kube-system started at 2018-12-05 19:17:08 +0000 UTC (2 container statuses recorded)
Dec  5 20:47:31.332: INFO: 	Container grafana ready: true, restart count 0
Dec  5 20:47:31.332: INFO: 	Container influxdb ready: true, restart count 0
Dec  5 20:47:31.332: INFO: nginx-ingress-controller-kubernetes-worker-tqt8p from ingress-nginx-kubernetes-worker started at 2018-12-05 19:17:11 +0000 UTC (1 container statuses recorded)
Dec  5 20:47:31.332: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Dec  5 20:47:31.332: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-24-193 before test
Dec  5 20:47:31.341: INFO: metrics-server-v0.3.1-54b884db75-fv2g7 from kube-system started at 2018-12-05 19:18:29 +0000 UTC (2 container statuses recorded)
Dec  5 20:47:31.341: INFO: 	Container metrics-server ready: true, restart count 0
Dec  5 20:47:31.341: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Dec  5 20:47:31.341: INFO: sonobuoy-systemd-logs-daemon-set-5821f0bd06934aee-2dj6p from heptio-sonobuoy started at 2018-12-05 19:28:41 +0000 UTC (2 container statuses recorded)
Dec  5 20:47:31.341: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec  5 20:47:31.341: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec  5 20:47:31.341: INFO: nginx-ingress-controller-kubernetes-worker-r2dmv from ingress-nginx-kubernetes-worker started at 2018-12-05 19:17:11 +0000 UTC (1 container statuses recorded)
Dec  5 20:47:31.341: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Dec  5 20:47:31.341: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-05 19:28:31 +0000 UTC (1 container statuses recorded)
Dec  5 20:47:31.341: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec  5 20:47:31.341: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-66-194 before test
Dec  5 20:47:31.353: INFO: sonobuoy-systemd-logs-daemon-set-5821f0bd06934aee-qzgmw from heptio-sonobuoy started at 2018-12-05 19:28:41 +0000 UTC (2 container statuses recorded)
Dec  5 20:47:31.353: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec  5 20:47:31.353: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec  5 20:47:31.353: INFO: default-http-backend-kubernetes-worker-7f7f76df64-fq4nj from ingress-nginx-kubernetes-worker started at 2018-12-05 19:17:10 +0000 UTC (1 container statuses recorded)
Dec  5 20:47:31.353: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
Dec  5 20:47:31.353: INFO: nginx-ingress-controller-kubernetes-worker-dxhb9 from ingress-nginx-kubernetes-worker started at 2018-12-05 19:17:11 +0000 UTC (1 container statuses recorded)
Dec  5 20:47:31.353: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 1
Dec  5 20:47:31.353: INFO: heapster-v1.6.0-beta.1-6d5d4878cb-cwfd2 from kube-system started at 2018-12-05 19:21:46 +0000 UTC (4 container statuses recorded)
Dec  5 20:47:31.353: INFO: 	Container eventer ready: true, restart count 0
Dec  5 20:47:31.353: INFO: 	Container eventer-nanny ready: true, restart count 0
Dec  5 20:47:31.353: INFO: 	Container heapster ready: true, restart count 0
Dec  5 20:47:31.353: INFO: 	Container heapster-nanny ready: true, restart count 0
Dec  5 20:47:31.353: INFO: sonobuoy-e2e-job-70e3eb1949d94e90 from heptio-sonobuoy started at 2018-12-05 19:28:41 +0000 UTC (2 container statuses recorded)
Dec  5 20:47:31.353: INFO: 	Container e2e ready: true, restart count 0
Dec  5 20:47:31.353: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node ip-172-31-2-231
STEP: verifying the node has the label node ip-172-31-24-193
STEP: verifying the node has the label node ip-172-31-66-194
Dec  5 20:47:31.406: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-172-31-24-193
Dec  5 20:47:31.406: INFO: Pod sonobuoy-e2e-job-70e3eb1949d94e90 requesting resource cpu=0m on Node ip-172-31-66-194
Dec  5 20:47:31.406: INFO: Pod sonobuoy-systemd-logs-daemon-set-5821f0bd06934aee-2dj6p requesting resource cpu=0m on Node ip-172-31-24-193
Dec  5 20:47:31.406: INFO: Pod sonobuoy-systemd-logs-daemon-set-5821f0bd06934aee-qzgmw requesting resource cpu=0m on Node ip-172-31-66-194
Dec  5 20:47:31.406: INFO: Pod sonobuoy-systemd-logs-daemon-set-5821f0bd06934aee-wxzkp requesting resource cpu=0m on Node ip-172-31-2-231
Dec  5 20:47:31.406: INFO: Pod default-http-backend-kubernetes-worker-7f7f76df64-fq4nj requesting resource cpu=10m on Node ip-172-31-66-194
Dec  5 20:47:31.406: INFO: Pod nginx-ingress-controller-kubernetes-worker-dxhb9 requesting resource cpu=0m on Node ip-172-31-66-194
Dec  5 20:47:31.406: INFO: Pod nginx-ingress-controller-kubernetes-worker-r2dmv requesting resource cpu=0m on Node ip-172-31-24-193
Dec  5 20:47:31.406: INFO: Pod nginx-ingress-controller-kubernetes-worker-tqt8p requesting resource cpu=0m on Node ip-172-31-2-231
Dec  5 20:47:31.406: INFO: Pod heapster-v1.6.0-beta.1-6d5d4878cb-cwfd2 requesting resource cpu=288m on Node ip-172-31-66-194
Dec  5 20:47:31.406: INFO: Pod kube-dns-8f7866879-f6tkp requesting resource cpu=260m on Node ip-172-31-2-231
Dec  5 20:47:31.406: INFO: Pod kubernetes-dashboard-654cfb4879-bwd9z requesting resource cpu=0m on Node ip-172-31-2-231
Dec  5 20:47:31.407: INFO: Pod metrics-server-v0.3.1-54b884db75-fv2g7 requesting resource cpu=53m on Node ip-172-31-24-193
Dec  5 20:47:31.407: INFO: Pod monitoring-influxdb-grafana-v4-5866497777-xh229 requesting resource cpu=200m on Node ip-172-31-2-231
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fc4411dd-f8ce-11e8-b559-c27407a18179.156d8acaec944fd7], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-d4czs/filler-pod-fc4411dd-f8ce-11e8-b559-c27407a18179 to ip-172-31-66-194]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fc4411dd-f8ce-11e8-b559-c27407a18179.156d8acb28f5ef3f], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fc4411dd-f8ce-11e8-b559-c27407a18179.156d8acb2eaf235a], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fc4411dd-f8ce-11e8-b559-c27407a18179.156d8acb3b358ed2], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fc465974-f8ce-11e8-b559-c27407a18179.156d8acaed48785e], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-d4czs/filler-pod-fc465974-f8ce-11e8-b559-c27407a18179 to ip-172-31-2-231]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fc465974-f8ce-11e8-b559-c27407a18179.156d8acb4bce5257], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fc465974-f8ce-11e8-b559-c27407a18179.156d8acb5f1dab04], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fc465974-f8ce-11e8-b559-c27407a18179.156d8acb7998cb5d], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fc48328f-f8ce-11e8-b559-c27407a18179.156d8acaee2602c3], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-d4czs/filler-pod-fc48328f-f8ce-11e8-b559-c27407a18179 to ip-172-31-24-193]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fc48328f-f8ce-11e8-b559-c27407a18179.156d8acb35cd039a], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fc48328f-f8ce-11e8-b559-c27407a18179.156d8acb3b12e467], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fc48328f-f8ce-11e8-b559-c27407a18179.156d8acb435df2fd], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.156d8acbde6558bc], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node ip-172-31-2-231
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-172-31-24-193
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-172-31-66-194
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:47:36.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-d4czs" for this suite.
Dec  5 20:47:42.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:47:42.616: INFO: namespace: e2e-tests-sched-pred-d4czs, resource: bindings, ignored listing per whitelist
Dec  5 20:47:42.662: INFO: namespace e2e-tests-sched-pred-d4czs deletion completed in 6.132956835s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:11.429 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:47:42.663: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  5 20:47:42.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-znd5r'
Dec  5 20:47:43.014: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  5 20:47:43.014: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Dec  5 20:47:43.020: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Dec  5 20:47:43.025: INFO: scanned /root for discovery docs: <nil>
Dec  5 20:47:43.025: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-znd5r'
Dec  5 20:47:58.801: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec  5 20:47:58.801: INFO: stdout: "Created e2e-test-nginx-rc-4ee61a50b2e92fcda1b3bfbdfbb0b888\nScaling up e2e-test-nginx-rc-4ee61a50b2e92fcda1b3bfbdfbb0b888 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-4ee61a50b2e92fcda1b3bfbdfbb0b888 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-4ee61a50b2e92fcda1b3bfbdfbb0b888 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Dec  5 20:47:58.801: INFO: stdout: "Created e2e-test-nginx-rc-4ee61a50b2e92fcda1b3bfbdfbb0b888\nScaling up e2e-test-nginx-rc-4ee61a50b2e92fcda1b3bfbdfbb0b888 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-4ee61a50b2e92fcda1b3bfbdfbb0b888 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-4ee61a50b2e92fcda1b3bfbdfbb0b888 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Dec  5 20:47:58.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-znd5r'
Dec  5 20:47:58.877: INFO: stderr: ""
Dec  5 20:47:58.877: INFO: stdout: "e2e-test-nginx-rc-4ee61a50b2e92fcda1b3bfbdfbb0b888-h6pb7 "
Dec  5 20:47:58.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods e2e-test-nginx-rc-4ee61a50b2e92fcda1b3bfbdfbb0b888-h6pb7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-znd5r'
Dec  5 20:47:58.954: INFO: stderr: ""
Dec  5 20:47:58.954: INFO: stdout: "true"
Dec  5 20:47:58.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 get pods e2e-test-nginx-rc-4ee61a50b2e92fcda1b3bfbdfbb0b888-h6pb7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-znd5r'
Dec  5 20:47:59.024: INFO: stderr: ""
Dec  5 20:47:59.024: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Dec  5 20:47:59.024: INFO: e2e-test-nginx-rc-4ee61a50b2e92fcda1b3bfbdfbb0b888-h6pb7 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Dec  5 20:47:59.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-znd5r'
Dec  5 20:47:59.100: INFO: stderr: ""
Dec  5 20:47:59.100: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:47:59.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-znd5r" for this suite.
Dec  5 20:48:21.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:48:21.193: INFO: namespace: e2e-tests-kubectl-znd5r, resource: bindings, ignored listing per whitelist
Dec  5 20:48:21.205: INFO: namespace e2e-tests-kubectl-znd5r deletion completed in 22.101346989s

• [SLOW TEST:38.542 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:48:21.205: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Dec  5 20:48:21.257: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  5 20:48:21.262: INFO: Waiting for terminating namespaces to be deleted...
Dec  5 20:48:21.265: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-2-231 before test
Dec  5 20:48:21.270: INFO: kube-dns-8f7866879-f6tkp from kube-system started at 2018-12-05 19:17:08 +0000 UTC (3 container statuses recorded)
Dec  5 20:48:21.270: INFO: 	Container dnsmasq ready: true, restart count 0
Dec  5 20:48:21.270: INFO: 	Container kubedns ready: true, restart count 0
Dec  5 20:48:21.270: INFO: 	Container sidecar ready: true, restart count 0
Dec  5 20:48:21.270: INFO: sonobuoy-systemd-logs-daemon-set-5821f0bd06934aee-wxzkp from heptio-sonobuoy started at 2018-12-05 19:28:41 +0000 UTC (2 container statuses recorded)
Dec  5 20:48:21.270: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec  5 20:48:21.270: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec  5 20:48:21.270: INFO: kubernetes-dashboard-654cfb4879-bwd9z from kube-system started at 2018-12-05 19:17:08 +0000 UTC (1 container statuses recorded)
Dec  5 20:48:21.270: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec  5 20:48:21.270: INFO: monitoring-influxdb-grafana-v4-5866497777-xh229 from kube-system started at 2018-12-05 19:17:08 +0000 UTC (2 container statuses recorded)
Dec  5 20:48:21.270: INFO: 	Container grafana ready: true, restart count 0
Dec  5 20:48:21.270: INFO: 	Container influxdb ready: true, restart count 0
Dec  5 20:48:21.270: INFO: nginx-ingress-controller-kubernetes-worker-tqt8p from ingress-nginx-kubernetes-worker started at 2018-12-05 19:17:11 +0000 UTC (1 container statuses recorded)
Dec  5 20:48:21.270: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Dec  5 20:48:21.270: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-24-193 before test
Dec  5 20:48:21.279: INFO: nginx-ingress-controller-kubernetes-worker-r2dmv from ingress-nginx-kubernetes-worker started at 2018-12-05 19:17:11 +0000 UTC (1 container statuses recorded)
Dec  5 20:48:21.279: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Dec  5 20:48:21.279: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-05 19:28:31 +0000 UTC (1 container statuses recorded)
Dec  5 20:48:21.279: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec  5 20:48:21.279: INFO: metrics-server-v0.3.1-54b884db75-fv2g7 from kube-system started at 2018-12-05 19:18:29 +0000 UTC (2 container statuses recorded)
Dec  5 20:48:21.279: INFO: 	Container metrics-server ready: true, restart count 0
Dec  5 20:48:21.279: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Dec  5 20:48:21.279: INFO: sonobuoy-systemd-logs-daemon-set-5821f0bd06934aee-2dj6p from heptio-sonobuoy started at 2018-12-05 19:28:41 +0000 UTC (2 container statuses recorded)
Dec  5 20:48:21.279: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec  5 20:48:21.279: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec  5 20:48:21.279: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-66-194 before test
Dec  5 20:48:21.284: INFO: nginx-ingress-controller-kubernetes-worker-dxhb9 from ingress-nginx-kubernetes-worker started at 2018-12-05 19:17:11 +0000 UTC (1 container statuses recorded)
Dec  5 20:48:21.284: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 1
Dec  5 20:48:21.284: INFO: heapster-v1.6.0-beta.1-6d5d4878cb-cwfd2 from kube-system started at 2018-12-05 19:21:46 +0000 UTC (4 container statuses recorded)
Dec  5 20:48:21.284: INFO: 	Container eventer ready: true, restart count 0
Dec  5 20:48:21.284: INFO: 	Container eventer-nanny ready: true, restart count 0
Dec  5 20:48:21.284: INFO: 	Container heapster ready: true, restart count 0
Dec  5 20:48:21.284: INFO: 	Container heapster-nanny ready: true, restart count 0
Dec  5 20:48:21.284: INFO: sonobuoy-e2e-job-70e3eb1949d94e90 from heptio-sonobuoy started at 2018-12-05 19:28:41 +0000 UTC (2 container statuses recorded)
Dec  5 20:48:21.284: INFO: 	Container e2e ready: true, restart count 0
Dec  5 20:48:21.284: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  5 20:48:21.284: INFO: sonobuoy-systemd-logs-daemon-set-5821f0bd06934aee-qzgmw from heptio-sonobuoy started at 2018-12-05 19:28:41 +0000 UTC (2 container statuses recorded)
Dec  5 20:48:21.284: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec  5 20:48:21.284: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec  5 20:48:21.284: INFO: default-http-backend-kubernetes-worker-7f7f76df64-fq4nj from ingress-nginx-kubernetes-worker started at 2018-12-05 19:17:10 +0000 UTC (1 container statuses recorded)
Dec  5 20:48:21.284: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.156d8ad6894b4266], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:48:22.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-wtfsv" for this suite.
Dec  5 20:48:28.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:48:28.394: INFO: namespace: e2e-tests-sched-pred-wtfsv, resource: bindings, ignored listing per whitelist
Dec  5 20:48:28.409: INFO: namespace e2e-tests-sched-pred-wtfsv deletion completed in 6.100310749s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.205 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:48:28.409: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-8dwh
STEP: Creating a pod to test atomic-volume-subpath
Dec  5 20:48:28.475: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-8dwh" in namespace "e2e-tests-subpath-rkvqh" to be "success or failure"
Dec  5 20:48:28.478: INFO: Pod "pod-subpath-test-configmap-8dwh": Phase="Pending", Reason="", readiness=false. Elapsed: 2.627413ms
Dec  5 20:48:30.482: INFO: Pod "pod-subpath-test-configmap-8dwh": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006490434s
Dec  5 20:48:32.485: INFO: Pod "pod-subpath-test-configmap-8dwh": Phase="Running", Reason="", readiness=false. Elapsed: 4.009779413s
Dec  5 20:48:34.489: INFO: Pod "pod-subpath-test-configmap-8dwh": Phase="Running", Reason="", readiness=false. Elapsed: 6.013721524s
Dec  5 20:48:36.493: INFO: Pod "pod-subpath-test-configmap-8dwh": Phase="Running", Reason="", readiness=false. Elapsed: 8.017778385s
Dec  5 20:48:38.498: INFO: Pod "pod-subpath-test-configmap-8dwh": Phase="Running", Reason="", readiness=false. Elapsed: 10.02205613s
Dec  5 20:48:40.502: INFO: Pod "pod-subpath-test-configmap-8dwh": Phase="Running", Reason="", readiness=false. Elapsed: 12.026406854s
Dec  5 20:48:42.505: INFO: Pod "pod-subpath-test-configmap-8dwh": Phase="Running", Reason="", readiness=false. Elapsed: 14.029988506s
Dec  5 20:48:44.509: INFO: Pod "pod-subpath-test-configmap-8dwh": Phase="Running", Reason="", readiness=false. Elapsed: 16.033838721s
Dec  5 20:48:46.513: INFO: Pod "pod-subpath-test-configmap-8dwh": Phase="Running", Reason="", readiness=false. Elapsed: 18.037944486s
Dec  5 20:48:48.518: INFO: Pod "pod-subpath-test-configmap-8dwh": Phase="Running", Reason="", readiness=false. Elapsed: 20.042529476s
Dec  5 20:48:50.522: INFO: Pod "pod-subpath-test-configmap-8dwh": Phase="Running", Reason="", readiness=false. Elapsed: 22.046396525s
Dec  5 20:48:52.525: INFO: Pod "pod-subpath-test-configmap-8dwh": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.049827694s
STEP: Saw pod success
Dec  5 20:48:52.525: INFO: Pod "pod-subpath-test-configmap-8dwh" satisfied condition "success or failure"
Dec  5 20:48:52.528: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-subpath-test-configmap-8dwh container test-container-subpath-configmap-8dwh: <nil>
STEP: delete the pod
Dec  5 20:48:52.548: INFO: Waiting for pod pod-subpath-test-configmap-8dwh to disappear
Dec  5 20:48:52.551: INFO: Pod pod-subpath-test-configmap-8dwh no longer exists
STEP: Deleting pod pod-subpath-test-configmap-8dwh
Dec  5 20:48:52.551: INFO: Deleting pod "pod-subpath-test-configmap-8dwh" in namespace "e2e-tests-subpath-rkvqh"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:48:52.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-rkvqh" for this suite.
Dec  5 20:48:58.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:48:58.692: INFO: namespace: e2e-tests-subpath-rkvqh, resource: bindings, ignored listing per whitelist
Dec  5 20:48:58.701: INFO: namespace e2e-tests-subpath-rkvqh deletion completed in 6.142570189s

• [SLOW TEST:30.292 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:48:58.701: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-57xs4
I1205 20:48:58.765086      15 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-57xs4, replica count: 1
I1205 20:48:59.815581      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1205 20:49:00.815808      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1205 20:49:01.816016      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  5 20:49:01.927: INFO: Created: latency-svc-6tn7w
Dec  5 20:49:01.937: INFO: Got endpoints: latency-svc-6tn7w [21.317986ms]
Dec  5 20:49:01.961: INFO: Created: latency-svc-md48z
Dec  5 20:49:01.962: INFO: Got endpoints: latency-svc-md48z [25.211583ms]
Dec  5 20:49:01.969: INFO: Created: latency-svc-jdlt5
Dec  5 20:49:01.976: INFO: Got endpoints: latency-svc-jdlt5 [38.546765ms]
Dec  5 20:49:01.983: INFO: Created: latency-svc-plb67
Dec  5 20:49:01.995: INFO: Got endpoints: latency-svc-plb67 [57.38882ms]
Dec  5 20:49:02.002: INFO: Created: latency-svc-q9fc6
Dec  5 20:49:02.006: INFO: Got endpoints: latency-svc-q9fc6 [68.115878ms]
Dec  5 20:49:02.014: INFO: Created: latency-svc-q8rwt
Dec  5 20:49:02.022: INFO: Got endpoints: latency-svc-q8rwt [84.505615ms]
Dec  5 20:49:02.025: INFO: Created: latency-svc-5tlmj
Dec  5 20:49:02.030: INFO: Got endpoints: latency-svc-5tlmj [24.258099ms]
Dec  5 20:49:02.040: INFO: Created: latency-svc-6sp5l
Dec  5 20:49:02.052: INFO: Got endpoints: latency-svc-6sp5l [114.517058ms]
Dec  5 20:49:02.057: INFO: Created: latency-svc-bpk9x
Dec  5 20:49:02.064: INFO: Got endpoints: latency-svc-bpk9x [126.848339ms]
Dec  5 20:49:02.078: INFO: Created: latency-svc-5dr8f
Dec  5 20:49:02.086: INFO: Created: latency-svc-r5wmk
Dec  5 20:49:02.097: INFO: Got endpoints: latency-svc-5dr8f [159.792541ms]
Dec  5 20:49:02.107: INFO: Created: latency-svc-x4fjt
Dec  5 20:49:02.119: INFO: Got endpoints: latency-svc-r5wmk [181.256663ms]
Dec  5 20:49:02.120: INFO: Created: latency-svc-qpmds
Dec  5 20:49:02.123: INFO: Got endpoints: latency-svc-x4fjt [185.668991ms]
Dec  5 20:49:02.139: INFO: Got endpoints: latency-svc-qpmds [201.853718ms]
Dec  5 20:49:02.141: INFO: Created: latency-svc-5gnj6
Dec  5 20:49:02.158: INFO: Created: latency-svc-fjnsl
Dec  5 20:49:02.164: INFO: Got endpoints: latency-svc-5gnj6 [225.989134ms]
Dec  5 20:49:02.172: INFO: Got endpoints: latency-svc-fjnsl [234.161192ms]
Dec  5 20:49:02.178: INFO: Created: latency-svc-vvhzh
Dec  5 20:49:02.192: INFO: Created: latency-svc-5gjs8
Dec  5 20:49:02.200: INFO: Got endpoints: latency-svc-5gjs8 [262.844825ms]
Dec  5 20:49:02.204: INFO: Got endpoints: latency-svc-vvhzh [266.148562ms]
Dec  5 20:49:02.206: INFO: Created: latency-svc-ghtc7
Dec  5 20:49:02.227: INFO: Created: latency-svc-4vvtc
Dec  5 20:49:02.229: INFO: Got endpoints: latency-svc-ghtc7 [266.856541ms]
Dec  5 20:49:02.240: INFO: Got endpoints: latency-svc-4vvtc [263.732134ms]
Dec  5 20:49:02.242: INFO: Created: latency-svc-vr2nt
Dec  5 20:49:02.253: INFO: Got endpoints: latency-svc-vr2nt [258.572257ms]
Dec  5 20:49:02.265: INFO: Created: latency-svc-qg8z7
Dec  5 20:49:02.279: INFO: Got endpoints: latency-svc-qg8z7 [256.969683ms]
Dec  5 20:49:02.282: INFO: Created: latency-svc-rmtxd
Dec  5 20:49:02.300: INFO: Created: latency-svc-nrpph
Dec  5 20:49:02.303: INFO: Got endpoints: latency-svc-nrpph [250.956692ms]
Dec  5 20:49:02.303: INFO: Got endpoints: latency-svc-rmtxd [273.403801ms]
Dec  5 20:49:02.311: INFO: Created: latency-svc-6zhg9
Dec  5 20:49:02.320: INFO: Got endpoints: latency-svc-6zhg9 [255.955665ms]
Dec  5 20:49:02.330: INFO: Created: latency-svc-7rn8m
Dec  5 20:49:02.336: INFO: Got endpoints: latency-svc-7rn8m [238.636785ms]
Dec  5 20:49:02.343: INFO: Created: latency-svc-nv6lv
Dec  5 20:49:02.359: INFO: Got endpoints: latency-svc-nv6lv [240.271489ms]
Dec  5 20:49:02.363: INFO: Created: latency-svc-x699b
Dec  5 20:49:02.373: INFO: Created: latency-svc-vl77k
Dec  5 20:49:02.381: INFO: Got endpoints: latency-svc-x699b [257.6848ms]
Dec  5 20:49:02.390: INFO: Got endpoints: latency-svc-vl77k [250.242ms]
Dec  5 20:49:02.399: INFO: Created: latency-svc-kpfh9
Dec  5 20:49:02.405: INFO: Got endpoints: latency-svc-kpfh9 [241.555863ms]
Dec  5 20:49:02.412: INFO: Created: latency-svc-4crq5
Dec  5 20:49:02.424: INFO: Created: latency-svc-vftk9
Dec  5 20:49:02.437: INFO: Got endpoints: latency-svc-vftk9 [236.635062ms]
Dec  5 20:49:02.437: INFO: Got endpoints: latency-svc-4crq5 [265.308253ms]
Dec  5 20:49:02.450: INFO: Created: latency-svc-nc554
Dec  5 20:49:02.457: INFO: Got endpoints: latency-svc-nc554 [253.233045ms]
Dec  5 20:49:02.457: INFO: Created: latency-svc-lpvj2
Dec  5 20:49:02.465: INFO: Got endpoints: latency-svc-lpvj2 [236.049571ms]
Dec  5 20:49:02.479: INFO: Created: latency-svc-j9ss6
Dec  5 20:49:02.484: INFO: Got endpoints: latency-svc-j9ss6 [243.71415ms]
Dec  5 20:49:02.495: INFO: Created: latency-svc-5thph
Dec  5 20:49:02.512: INFO: Got endpoints: latency-svc-5thph [258.229507ms]
Dec  5 20:49:02.533: INFO: Created: latency-svc-22vqc
Dec  5 20:49:02.539: INFO: Got endpoints: latency-svc-22vqc [260.265732ms]
Dec  5 20:49:02.548: INFO: Created: latency-svc-gptvt
Dec  5 20:49:02.563: INFO: Created: latency-svc-6xmpb
Dec  5 20:49:02.575: INFO: Created: latency-svc-r7mm6
Dec  5 20:49:02.577: INFO: Got endpoints: latency-svc-6xmpb [273.484225ms]
Dec  5 20:49:02.584: INFO: Got endpoints: latency-svc-r7mm6 [263.479066ms]
Dec  5 20:49:02.616: INFO: Got endpoints: latency-svc-gptvt [312.901013ms]
Dec  5 20:49:02.616: INFO: Created: latency-svc-4q6hd
Dec  5 20:49:02.621: INFO: Got endpoints: latency-svc-4q6hd [285.320765ms]
Dec  5 20:49:02.632: INFO: Created: latency-svc-kcx9g
Dec  5 20:49:02.642: INFO: Got endpoints: latency-svc-kcx9g [282.801651ms]
Dec  5 20:49:02.683: INFO: Created: latency-svc-7gfpn
Dec  5 20:49:02.683: INFO: Created: latency-svc-5dkv2
Dec  5 20:49:02.690: INFO: Got endpoints: latency-svc-7gfpn [300.335851ms]
Dec  5 20:49:02.690: INFO: Got endpoints: latency-svc-5dkv2 [309.340882ms]
Dec  5 20:49:02.695: INFO: Created: latency-svc-gwhjd
Dec  5 20:49:02.704: INFO: Got endpoints: latency-svc-gwhjd [298.678465ms]
Dec  5 20:49:02.718: INFO: Created: latency-svc-n8cq4
Dec  5 20:49:02.725: INFO: Got endpoints: latency-svc-n8cq4 [287.673768ms]
Dec  5 20:49:02.734: INFO: Created: latency-svc-8d54h
Dec  5 20:49:02.736: INFO: Got endpoints: latency-svc-8d54h [298.388248ms]
Dec  5 20:49:02.749: INFO: Created: latency-svc-ptv6w
Dec  5 20:49:02.753: INFO: Created: latency-svc-tg7b6
Dec  5 20:49:02.761: INFO: Created: latency-svc-dv86n
Dec  5 20:49:02.773: INFO: Created: latency-svc-v6slq
Dec  5 20:49:02.788: INFO: Got endpoints: latency-svc-ptv6w [331.078267ms]
Dec  5 20:49:02.789: INFO: Created: latency-svc-pg8ks
Dec  5 20:49:02.799: INFO: Created: latency-svc-xplgx
Dec  5 20:49:02.813: INFO: Created: latency-svc-f8nl7
Dec  5 20:49:02.818: INFO: Created: latency-svc-tmddh
Dec  5 20:49:02.830: INFO: Created: latency-svc-ttg4s
Dec  5 20:49:02.841: INFO: Got endpoints: latency-svc-tg7b6 [376.011326ms]
Dec  5 20:49:02.844: INFO: Created: latency-svc-tc6pv
Dec  5 20:49:02.852: INFO: Created: latency-svc-zl5xb
Dec  5 20:49:02.862: INFO: Created: latency-svc-rqdvt
Dec  5 20:49:02.870: INFO: Created: latency-svc-rjqhm
Dec  5 20:49:02.880: INFO: Created: latency-svc-qmdq8
Dec  5 20:49:02.891: INFO: Got endpoints: latency-svc-dv86n [406.952444ms]
Dec  5 20:49:02.898: INFO: Created: latency-svc-dvr48
Dec  5 20:49:02.919: INFO: Created: latency-svc-z4j27
Dec  5 20:49:02.919: INFO: Created: latency-svc-t86xk
Dec  5 20:49:02.933: INFO: Created: latency-svc-pn8hl
Dec  5 20:49:02.941: INFO: Got endpoints: latency-svc-v6slq [428.972563ms]
Dec  5 20:49:02.957: INFO: Created: latency-svc-rwzh6
Dec  5 20:49:02.985: INFO: Got endpoints: latency-svc-pg8ks [446.191898ms]
Dec  5 20:49:03.000: INFO: Created: latency-svc-x7957
Dec  5 20:49:03.037: INFO: Got endpoints: latency-svc-xplgx [459.757209ms]
Dec  5 20:49:03.056: INFO: Created: latency-svc-mbghw
Dec  5 20:49:03.086: INFO: Got endpoints: latency-svc-f8nl7 [501.763013ms]
Dec  5 20:49:03.108: INFO: Created: latency-svc-sswc8
Dec  5 20:49:03.140: INFO: Got endpoints: latency-svc-tmddh [523.768779ms]
Dec  5 20:49:03.158: INFO: Created: latency-svc-64x9c
Dec  5 20:49:03.529: INFO: Got endpoints: latency-svc-ttg4s [907.589754ms]
Dec  5 20:49:03.529: INFO: Got endpoints: latency-svc-tc6pv [886.962274ms]
Dec  5 20:49:03.529: INFO: Got endpoints: latency-svc-rjqhm [824.51115ms]
Dec  5 20:49:03.529: INFO: Got endpoints: latency-svc-rqdvt [838.69519ms]
Dec  5 20:49:03.529: INFO: Got endpoints: latency-svc-zl5xb [838.829055ms]
Dec  5 20:49:03.545: INFO: Got endpoints: latency-svc-t86xk [756.95929ms]
Dec  5 20:49:03.548: INFO: Got endpoints: latency-svc-dvr48 [812.777365ms]
Dec  5 20:49:03.549: INFO: Got endpoints: latency-svc-qmdq8 [823.531883ms]
Dec  5 20:49:03.575: INFO: Created: latency-svc-98p2b
Dec  5 20:49:03.588: INFO: Created: latency-svc-nzkf5
Dec  5 20:49:03.589: INFO: Got endpoints: latency-svc-z4j27 [747.850722ms]
Dec  5 20:49:03.607: INFO: Created: latency-svc-fsvzb
Dec  5 20:49:03.618: INFO: Created: latency-svc-g4zs8
Dec  5 20:49:03.632: INFO: Created: latency-svc-zmbzw
Dec  5 20:49:03.640: INFO: Got endpoints: latency-svc-pn8hl [748.756422ms]
Dec  5 20:49:03.656: INFO: Created: latency-svc-j7tzd
Dec  5 20:49:03.660: INFO: Created: latency-svc-lttf4
Dec  5 20:49:03.669: INFO: Created: latency-svc-nz4bc
Dec  5 20:49:03.687: INFO: Got endpoints: latency-svc-rwzh6 [746.195848ms]
Dec  5 20:49:03.700: INFO: Created: latency-svc-thgmd
Dec  5 20:49:03.711: INFO: Created: latency-svc-t2nqn
Dec  5 20:49:03.711: INFO: Created: latency-svc-f5wp4
Dec  5 20:49:03.734: INFO: Got endpoints: latency-svc-x7957 [749.127143ms]
Dec  5 20:49:03.757: INFO: Created: latency-svc-s6w2x
Dec  5 20:49:03.787: INFO: Got endpoints: latency-svc-mbghw [750.426212ms]
Dec  5 20:49:03.817: INFO: Created: latency-svc-2pdjh
Dec  5 20:49:03.835: INFO: Got endpoints: latency-svc-sswc8 [749.452203ms]
Dec  5 20:49:03.856: INFO: Created: latency-svc-ghfd7
Dec  5 20:49:03.889: INFO: Got endpoints: latency-svc-64x9c [749.068746ms]
Dec  5 20:49:03.903: INFO: Created: latency-svc-swnfj
Dec  5 20:49:03.936: INFO: Got endpoints: latency-svc-98p2b [406.603846ms]
Dec  5 20:49:03.956: INFO: Created: latency-svc-znd8b
Dec  5 20:49:03.988: INFO: Got endpoints: latency-svc-nzkf5 [458.738877ms]
Dec  5 20:49:04.006: INFO: Created: latency-svc-4qpf9
Dec  5 20:49:04.039: INFO: Got endpoints: latency-svc-fsvzb [493.620846ms]
Dec  5 20:49:04.060: INFO: Created: latency-svc-4fddl
Dec  5 20:49:04.087: INFO: Got endpoints: latency-svc-g4zs8 [538.385765ms]
Dec  5 20:49:04.108: INFO: Created: latency-svc-pdctr
Dec  5 20:49:04.140: INFO: Got endpoints: latency-svc-zmbzw [591.301121ms]
Dec  5 20:49:04.160: INFO: Created: latency-svc-9sdc5
Dec  5 20:49:04.190: INFO: Got endpoints: latency-svc-j7tzd [660.679241ms]
Dec  5 20:49:04.206: INFO: Created: latency-svc-vksd2
Dec  5 20:49:04.234: INFO: Got endpoints: latency-svc-lttf4 [704.690261ms]
Dec  5 20:49:04.254: INFO: Created: latency-svc-864hx
Dec  5 20:49:04.287: INFO: Got endpoints: latency-svc-nz4bc [757.753002ms]
Dec  5 20:49:04.312: INFO: Created: latency-svc-f6bfb
Dec  5 20:49:04.335: INFO: Got endpoints: latency-svc-t2nqn [745.783295ms]
Dec  5 20:49:04.347: INFO: Created: latency-svc-4sqk9
Dec  5 20:49:04.394: INFO: Got endpoints: latency-svc-thgmd [754.531962ms]
Dec  5 20:49:04.411: INFO: Created: latency-svc-sdqzd
Dec  5 20:49:04.436: INFO: Got endpoints: latency-svc-f5wp4 [748.734808ms]
Dec  5 20:49:04.448: INFO: Created: latency-svc-4k8tr
Dec  5 20:49:04.483: INFO: Got endpoints: latency-svc-s6w2x [748.766809ms]
Dec  5 20:49:04.503: INFO: Created: latency-svc-p2nnp
Dec  5 20:49:04.534: INFO: Got endpoints: latency-svc-2pdjh [747.044676ms]
Dec  5 20:49:04.549: INFO: Created: latency-svc-9njkj
Dec  5 20:49:04.583: INFO: Got endpoints: latency-svc-ghfd7 [748.082236ms]
Dec  5 20:49:04.600: INFO: Created: latency-svc-trr9w
Dec  5 20:49:04.633: INFO: Got endpoints: latency-svc-swnfj [744.454322ms]
Dec  5 20:49:04.654: INFO: Created: latency-svc-7pqk4
Dec  5 20:49:04.685: INFO: Got endpoints: latency-svc-znd8b [749.655252ms]
Dec  5 20:49:04.701: INFO: Created: latency-svc-wm2rk
Dec  5 20:49:04.737: INFO: Got endpoints: latency-svc-4qpf9 [749.143169ms]
Dec  5 20:49:04.754: INFO: Created: latency-svc-zt49h
Dec  5 20:49:04.788: INFO: Got endpoints: latency-svc-4fddl [749.546662ms]
Dec  5 20:49:04.803: INFO: Created: latency-svc-n4qrn
Dec  5 20:49:04.838: INFO: Got endpoints: latency-svc-pdctr [751.163457ms]
Dec  5 20:49:04.860: INFO: Created: latency-svc-x84wn
Dec  5 20:49:04.887: INFO: Got endpoints: latency-svc-9sdc5 [747.257668ms]
Dec  5 20:49:05.097: INFO: Got endpoints: latency-svc-864hx [863.200265ms]
Dec  5 20:49:05.097: INFO: Got endpoints: latency-svc-vksd2 [907.315514ms]
Dec  5 20:49:05.098: INFO: Got endpoints: latency-svc-f6bfb [810.740277ms]
Dec  5 20:49:05.100: INFO: Got endpoints: latency-svc-4sqk9 [764.568601ms]
Dec  5 20:49:05.104: INFO: Created: latency-svc-77ct2
Dec  5 20:49:05.109: INFO: Created: latency-svc-rg9vk
Dec  5 20:49:05.128: INFO: Created: latency-svc-zlxw2
Dec  5 20:49:05.136: INFO: Got endpoints: latency-svc-sdqzd [741.419682ms]
Dec  5 20:49:05.149: INFO: Created: latency-svc-kwzsw
Dec  5 20:49:05.166: INFO: Created: latency-svc-gnwr6
Dec  5 20:49:05.167: INFO: Created: latency-svc-j9b5w
Dec  5 20:49:05.182: INFO: Got endpoints: latency-svc-4k8tr [746.529026ms]
Dec  5 20:49:05.198: INFO: Created: latency-svc-fqj49
Dec  5 20:49:05.236: INFO: Got endpoints: latency-svc-p2nnp [752.988767ms]
Dec  5 20:49:05.257: INFO: Created: latency-svc-ckqfb
Dec  5 20:49:05.284: INFO: Got endpoints: latency-svc-9njkj [749.790738ms]
Dec  5 20:49:05.299: INFO: Created: latency-svc-k7hq6
Dec  5 20:49:05.338: INFO: Got endpoints: latency-svc-trr9w [754.211455ms]
Dec  5 20:49:05.349: INFO: Created: latency-svc-wjkqm
Dec  5 20:49:05.383: INFO: Got endpoints: latency-svc-7pqk4 [749.290997ms]
Dec  5 20:49:05.392: INFO: Created: latency-svc-lkwz7
Dec  5 20:49:05.434: INFO: Got endpoints: latency-svc-wm2rk [748.261091ms]
Dec  5 20:49:05.443: INFO: Created: latency-svc-s7pqw
Dec  5 20:49:05.483: INFO: Got endpoints: latency-svc-zt49h [746.288223ms]
Dec  5 20:49:05.498: INFO: Created: latency-svc-hh8tr
Dec  5 20:49:05.532: INFO: Got endpoints: latency-svc-n4qrn [743.677167ms]
Dec  5 20:49:05.547: INFO: Created: latency-svc-886q6
Dec  5 20:49:05.589: INFO: Got endpoints: latency-svc-x84wn [750.614829ms]
Dec  5 20:49:05.598: INFO: Created: latency-svc-7q9zg
Dec  5 20:49:05.633: INFO: Got endpoints: latency-svc-77ct2 [746.039479ms]
Dec  5 20:49:05.644: INFO: Created: latency-svc-g785s
Dec  5 20:49:05.684: INFO: Got endpoints: latency-svc-rg9vk [586.577695ms]
Dec  5 20:49:05.695: INFO: Created: latency-svc-n2tvv
Dec  5 20:49:05.738: INFO: Got endpoints: latency-svc-zlxw2 [640.843645ms]
Dec  5 20:49:05.753: INFO: Created: latency-svc-dh584
Dec  5 20:49:05.782: INFO: Got endpoints: latency-svc-kwzsw [682.609491ms]
Dec  5 20:49:05.798: INFO: Created: latency-svc-7x2v8
Dec  5 20:49:05.832: INFO: Got endpoints: latency-svc-j9b5w [734.477459ms]
Dec  5 20:49:05.844: INFO: Created: latency-svc-7jq66
Dec  5 20:49:05.887: INFO: Got endpoints: latency-svc-gnwr6 [751.32682ms]
Dec  5 20:49:05.897: INFO: Created: latency-svc-ms6b4
Dec  5 20:49:05.932: INFO: Got endpoints: latency-svc-fqj49 [749.849815ms]
Dec  5 20:49:05.943: INFO: Created: latency-svc-wg8k7
Dec  5 20:49:05.982: INFO: Got endpoints: latency-svc-ckqfb [746.139442ms]
Dec  5 20:49:05.993: INFO: Created: latency-svc-7dmvs
Dec  5 20:49:06.032: INFO: Got endpoints: latency-svc-k7hq6 [748.485769ms]
Dec  5 20:49:06.045: INFO: Created: latency-svc-tvm29
Dec  5 20:49:06.086: INFO: Got endpoints: latency-svc-wjkqm [748.341904ms]
Dec  5 20:49:06.096: INFO: Created: latency-svc-s6rq2
Dec  5 20:49:06.132: INFO: Got endpoints: latency-svc-lkwz7 [749.430806ms]
Dec  5 20:49:06.143: INFO: Created: latency-svc-lk9dd
Dec  5 20:49:06.185: INFO: Got endpoints: latency-svc-s7pqw [750.960347ms]
Dec  5 20:49:06.197: INFO: Created: latency-svc-6vdjk
Dec  5 20:49:06.237: INFO: Got endpoints: latency-svc-hh8tr [753.269994ms]
Dec  5 20:49:06.249: INFO: Created: latency-svc-499ln
Dec  5 20:49:06.285: INFO: Got endpoints: latency-svc-886q6 [752.463581ms]
Dec  5 20:49:06.296: INFO: Created: latency-svc-bkf8b
Dec  5 20:49:06.333: INFO: Got endpoints: latency-svc-7q9zg [744.51032ms]
Dec  5 20:49:06.349: INFO: Created: latency-svc-cjbnp
Dec  5 20:49:06.385: INFO: Got endpoints: latency-svc-g785s [751.713188ms]
Dec  5 20:49:06.398: INFO: Created: latency-svc-rf9m9
Dec  5 20:49:06.434: INFO: Got endpoints: latency-svc-n2tvv [750.359259ms]
Dec  5 20:49:06.444: INFO: Created: latency-svc-xpw2n
Dec  5 20:49:06.484: INFO: Got endpoints: latency-svc-dh584 [746.006014ms]
Dec  5 20:49:06.497: INFO: Created: latency-svc-sknhl
Dec  5 20:49:06.533: INFO: Got endpoints: latency-svc-7x2v8 [750.44293ms]
Dec  5 20:49:06.544: INFO: Created: latency-svc-zr9n7
Dec  5 20:49:06.582: INFO: Got endpoints: latency-svc-7jq66 [749.526189ms]
Dec  5 20:49:06.592: INFO: Created: latency-svc-tdb44
Dec  5 20:49:06.652: INFO: Got endpoints: latency-svc-ms6b4 [765.314795ms]
Dec  5 20:49:06.664: INFO: Created: latency-svc-m2rpq
Dec  5 20:49:06.683: INFO: Got endpoints: latency-svc-wg8k7 [750.512946ms]
Dec  5 20:49:06.693: INFO: Created: latency-svc-h2q45
Dec  5 20:49:06.733: INFO: Got endpoints: latency-svc-7dmvs [750.217588ms]
Dec  5 20:49:06.745: INFO: Created: latency-svc-6pk55
Dec  5 20:49:06.784: INFO: Got endpoints: latency-svc-tvm29 [751.735975ms]
Dec  5 20:49:06.794: INFO: Created: latency-svc-s529c
Dec  5 20:49:06.835: INFO: Got endpoints: latency-svc-s6rq2 [749.101785ms]
Dec  5 20:49:06.846: INFO: Created: latency-svc-l2l9x
Dec  5 20:49:06.883: INFO: Got endpoints: latency-svc-lk9dd [751.134848ms]
Dec  5 20:49:06.895: INFO: Created: latency-svc-j26jr
Dec  5 20:49:06.935: INFO: Got endpoints: latency-svc-6vdjk [750.713481ms]
Dec  5 20:49:06.945: INFO: Created: latency-svc-8c2bc
Dec  5 20:49:06.988: INFO: Got endpoints: latency-svc-499ln [751.072579ms]
Dec  5 20:49:06.997: INFO: Created: latency-svc-sktbn
Dec  5 20:49:07.034: INFO: Got endpoints: latency-svc-bkf8b [748.825574ms]
Dec  5 20:49:07.044: INFO: Created: latency-svc-v4lc9
Dec  5 20:49:07.084: INFO: Got endpoints: latency-svc-cjbnp [750.764439ms]
Dec  5 20:49:07.095: INFO: Created: latency-svc-kcmfc
Dec  5 20:49:07.133: INFO: Got endpoints: latency-svc-rf9m9 [747.526904ms]
Dec  5 20:49:07.298: INFO: Got endpoints: latency-svc-sknhl [814.270265ms]
Dec  5 20:49:07.298: INFO: Got endpoints: latency-svc-xpw2n [864.283127ms]
Dec  5 20:49:07.305: INFO: Created: latency-svc-rz9rv
Dec  5 20:49:07.305: INFO: Got endpoints: latency-svc-zr9n7 [771.728899ms]
Dec  5 20:49:07.312: INFO: Created: latency-svc-tz8mk
Dec  5 20:49:07.318: INFO: Created: latency-svc-xh8px
Dec  5 20:49:07.324: INFO: Created: latency-svc-fws5w
Dec  5 20:49:07.335: INFO: Got endpoints: latency-svc-tdb44 [752.767736ms]
Dec  5 20:49:07.342: INFO: Created: latency-svc-rh8tw
Dec  5 20:49:07.383: INFO: Got endpoints: latency-svc-m2rpq [730.173299ms]
Dec  5 20:49:07.395: INFO: Created: latency-svc-mmp2n
Dec  5 20:49:07.434: INFO: Got endpoints: latency-svc-h2q45 [751.794785ms]
Dec  5 20:49:07.445: INFO: Created: latency-svc-j54hm
Dec  5 20:49:07.482: INFO: Got endpoints: latency-svc-6pk55 [749.265722ms]
Dec  5 20:49:07.494: INFO: Created: latency-svc-v9mbb
Dec  5 20:49:07.533: INFO: Got endpoints: latency-svc-s529c [749.183857ms]
Dec  5 20:49:07.543: INFO: Created: latency-svc-rq557
Dec  5 20:49:07.583: INFO: Got endpoints: latency-svc-l2l9x [747.381791ms]
Dec  5 20:49:07.595: INFO: Created: latency-svc-z8296
Dec  5 20:49:07.632: INFO: Got endpoints: latency-svc-j26jr [748.866542ms]
Dec  5 20:49:07.643: INFO: Created: latency-svc-5b86j
Dec  5 20:49:07.683: INFO: Got endpoints: latency-svc-8c2bc [747.684558ms]
Dec  5 20:49:07.692: INFO: Created: latency-svc-ql9zf
Dec  5 20:49:07.732: INFO: Got endpoints: latency-svc-sktbn [744.174792ms]
Dec  5 20:49:07.742: INFO: Created: latency-svc-sk44q
Dec  5 20:49:07.783: INFO: Got endpoints: latency-svc-v4lc9 [749.642076ms]
Dec  5 20:49:07.793: INFO: Created: latency-svc-kjbhw
Dec  5 20:49:07.836: INFO: Got endpoints: latency-svc-kcmfc [751.388918ms]
Dec  5 20:49:07.845: INFO: Created: latency-svc-6mnhp
Dec  5 20:49:07.884: INFO: Got endpoints: latency-svc-rz9rv [751.401483ms]
Dec  5 20:49:07.893: INFO: Created: latency-svc-kb2hd
Dec  5 20:49:07.933: INFO: Got endpoints: latency-svc-tz8mk [634.641086ms]
Dec  5 20:49:07.943: INFO: Created: latency-svc-bxv9v
Dec  5 20:49:07.983: INFO: Got endpoints: latency-svc-xh8px [684.389481ms]
Dec  5 20:49:07.992: INFO: Created: latency-svc-fmps4
Dec  5 20:49:08.032: INFO: Got endpoints: latency-svc-fws5w [727.508872ms]
Dec  5 20:49:08.041: INFO: Created: latency-svc-65qlh
Dec  5 20:49:08.086: INFO: Got endpoints: latency-svc-rh8tw [751.360346ms]
Dec  5 20:49:08.095: INFO: Created: latency-svc-wbd6p
Dec  5 20:49:08.133: INFO: Got endpoints: latency-svc-mmp2n [750.577099ms]
Dec  5 20:49:08.141: INFO: Created: latency-svc-f7zb6
Dec  5 20:49:08.184: INFO: Got endpoints: latency-svc-j54hm [749.188808ms]
Dec  5 20:49:08.193: INFO: Created: latency-svc-n7ggl
Dec  5 20:49:08.240: INFO: Got endpoints: latency-svc-v9mbb [758.296578ms]
Dec  5 20:49:08.253: INFO: Created: latency-svc-lb2qs
Dec  5 20:49:08.282: INFO: Got endpoints: latency-svc-rq557 [748.173779ms]
Dec  5 20:49:08.294: INFO: Created: latency-svc-brg4t
Dec  5 20:49:08.332: INFO: Got endpoints: latency-svc-z8296 [749.419013ms]
Dec  5 20:49:08.344: INFO: Created: latency-svc-md4pl
Dec  5 20:49:08.383: INFO: Got endpoints: latency-svc-5b86j [750.087242ms]
Dec  5 20:49:08.397: INFO: Created: latency-svc-cgmpq
Dec  5 20:49:08.436: INFO: Got endpoints: latency-svc-ql9zf [753.239511ms]
Dec  5 20:49:08.446: INFO: Created: latency-svc-wpwqn
Dec  5 20:49:08.483: INFO: Got endpoints: latency-svc-sk44q [750.947517ms]
Dec  5 20:49:08.495: INFO: Created: latency-svc-zrvh2
Dec  5 20:49:08.542: INFO: Got endpoints: latency-svc-kjbhw [758.440322ms]
Dec  5 20:49:08.560: INFO: Created: latency-svc-4nxl7
Dec  5 20:49:08.582: INFO: Got endpoints: latency-svc-6mnhp [746.539956ms]
Dec  5 20:49:08.591: INFO: Created: latency-svc-7qxbh
Dec  5 20:49:08.635: INFO: Got endpoints: latency-svc-kb2hd [750.985937ms]
Dec  5 20:49:08.645: INFO: Created: latency-svc-mcvzl
Dec  5 20:49:08.683: INFO: Got endpoints: latency-svc-bxv9v [750.192511ms]
Dec  5 20:49:08.695: INFO: Created: latency-svc-h9cgf
Dec  5 20:49:08.742: INFO: Got endpoints: latency-svc-fmps4 [758.838895ms]
Dec  5 20:49:08.753: INFO: Created: latency-svc-l8lgd
Dec  5 20:49:08.782: INFO: Got endpoints: latency-svc-65qlh [750.076019ms]
Dec  5 20:49:08.791: INFO: Created: latency-svc-r9d6r
Dec  5 20:49:08.834: INFO: Got endpoints: latency-svc-wbd6p [747.875594ms]
Dec  5 20:49:08.844: INFO: Created: latency-svc-mqdrk
Dec  5 20:49:08.882: INFO: Got endpoints: latency-svc-f7zb6 [748.959033ms]
Dec  5 20:49:08.892: INFO: Created: latency-svc-m4x2q
Dec  5 20:49:08.934: INFO: Got endpoints: latency-svc-n7ggl [749.971015ms]
Dec  5 20:49:08.948: INFO: Created: latency-svc-9vtxm
Dec  5 20:49:08.983: INFO: Got endpoints: latency-svc-lb2qs [742.919286ms]
Dec  5 20:49:08.993: INFO: Created: latency-svc-xxzvm
Dec  5 20:49:09.034: INFO: Got endpoints: latency-svc-brg4t [751.989864ms]
Dec  5 20:49:09.045: INFO: Created: latency-svc-99xkb
Dec  5 20:49:09.084: INFO: Got endpoints: latency-svc-md4pl [752.129701ms]
Dec  5 20:49:09.098: INFO: Created: latency-svc-8vgnq
Dec  5 20:49:09.133: INFO: Got endpoints: latency-svc-cgmpq [750.251835ms]
Dec  5 20:49:09.147: INFO: Created: latency-svc-rmvmj
Dec  5 20:49:09.182: INFO: Got endpoints: latency-svc-wpwqn [745.131038ms]
Dec  5 20:49:09.193: INFO: Created: latency-svc-zsl6d
Dec  5 20:49:09.232: INFO: Got endpoints: latency-svc-zrvh2 [749.318161ms]
Dec  5 20:49:09.242: INFO: Created: latency-svc-l524f
Dec  5 20:49:09.282: INFO: Got endpoints: latency-svc-4nxl7 [740.044004ms]
Dec  5 20:49:09.293: INFO: Created: latency-svc-8qkj7
Dec  5 20:49:09.351: INFO: Got endpoints: latency-svc-7qxbh [768.69898ms]
Dec  5 20:49:09.363: INFO: Created: latency-svc-h4nqt
Dec  5 20:49:09.384: INFO: Got endpoints: latency-svc-mcvzl [748.46961ms]
Dec  5 20:49:09.397: INFO: Created: latency-svc-485zq
Dec  5 20:49:09.432: INFO: Got endpoints: latency-svc-h9cgf [748.850542ms]
Dec  5 20:49:09.442: INFO: Created: latency-svc-nxdbf
Dec  5 20:49:09.482: INFO: Got endpoints: latency-svc-l8lgd [740.593613ms]
Dec  5 20:49:09.493: INFO: Created: latency-svc-522vd
Dec  5 20:49:09.533: INFO: Got endpoints: latency-svc-r9d6r [751.018037ms]
Dec  5 20:49:09.545: INFO: Created: latency-svc-jgv5s
Dec  5 20:49:09.583: INFO: Got endpoints: latency-svc-mqdrk [749.425657ms]
Dec  5 20:49:09.592: INFO: Created: latency-svc-sbxpc
Dec  5 20:49:09.634: INFO: Got endpoints: latency-svc-m4x2q [751.496075ms]
Dec  5 20:49:09.645: INFO: Created: latency-svc-lsr42
Dec  5 20:49:09.683: INFO: Got endpoints: latency-svc-9vtxm [749.614808ms]
Dec  5 20:49:09.693: INFO: Created: latency-svc-rrv6c
Dec  5 20:49:09.733: INFO: Got endpoints: latency-svc-xxzvm [749.840398ms]
Dec  5 20:49:09.744: INFO: Created: latency-svc-dhj67
Dec  5 20:49:09.787: INFO: Got endpoints: latency-svc-99xkb [752.989995ms]
Dec  5 20:49:09.832: INFO: Got endpoints: latency-svc-8vgnq [747.805975ms]
Dec  5 20:49:09.883: INFO: Got endpoints: latency-svc-rmvmj [749.388001ms]
Dec  5 20:49:09.937: INFO: Got endpoints: latency-svc-zsl6d [755.277ms]
Dec  5 20:49:09.983: INFO: Got endpoints: latency-svc-l524f [750.499371ms]
Dec  5 20:49:10.033: INFO: Got endpoints: latency-svc-8qkj7 [750.656534ms]
Dec  5 20:49:10.092: INFO: Got endpoints: latency-svc-h4nqt [740.767998ms]
Dec  5 20:49:10.132: INFO: Got endpoints: latency-svc-485zq [748.560888ms]
Dec  5 20:49:10.183: INFO: Got endpoints: latency-svc-nxdbf [750.364447ms]
Dec  5 20:49:10.234: INFO: Got endpoints: latency-svc-522vd [751.771031ms]
Dec  5 20:49:10.284: INFO: Got endpoints: latency-svc-jgv5s [750.487901ms]
Dec  5 20:49:10.333: INFO: Got endpoints: latency-svc-sbxpc [750.038913ms]
Dec  5 20:49:10.384: INFO: Got endpoints: latency-svc-lsr42 [750.191745ms]
Dec  5 20:49:10.437: INFO: Got endpoints: latency-svc-rrv6c [752.842945ms]
Dec  5 20:49:10.484: INFO: Got endpoints: latency-svc-dhj67 [750.829515ms]
Dec  5 20:49:10.484: INFO: Latencies: [24.258099ms 25.211583ms 38.546765ms 57.38882ms 68.115878ms 84.505615ms 114.517058ms 126.848339ms 159.792541ms 181.256663ms 185.668991ms 201.853718ms 225.989134ms 234.161192ms 236.049571ms 236.635062ms 238.636785ms 240.271489ms 241.555863ms 243.71415ms 250.242ms 250.956692ms 253.233045ms 255.955665ms 256.969683ms 257.6848ms 258.229507ms 258.572257ms 260.265732ms 262.844825ms 263.479066ms 263.732134ms 265.308253ms 266.148562ms 266.856541ms 273.403801ms 273.484225ms 282.801651ms 285.320765ms 287.673768ms 298.388248ms 298.678465ms 300.335851ms 309.340882ms 312.901013ms 331.078267ms 376.011326ms 406.603846ms 406.952444ms 428.972563ms 446.191898ms 458.738877ms 459.757209ms 493.620846ms 501.763013ms 523.768779ms 538.385765ms 586.577695ms 591.301121ms 634.641086ms 640.843645ms 660.679241ms 682.609491ms 684.389481ms 704.690261ms 727.508872ms 730.173299ms 734.477459ms 740.044004ms 740.593613ms 740.767998ms 741.419682ms 742.919286ms 743.677167ms 744.174792ms 744.454322ms 744.51032ms 745.131038ms 745.783295ms 746.006014ms 746.039479ms 746.139442ms 746.195848ms 746.288223ms 746.529026ms 746.539956ms 747.044676ms 747.257668ms 747.381791ms 747.526904ms 747.684558ms 747.805975ms 747.850722ms 747.875594ms 748.082236ms 748.173779ms 748.261091ms 748.341904ms 748.46961ms 748.485769ms 748.560888ms 748.734808ms 748.756422ms 748.766809ms 748.825574ms 748.850542ms 748.866542ms 748.959033ms 749.068746ms 749.101785ms 749.127143ms 749.143169ms 749.183857ms 749.188808ms 749.265722ms 749.290997ms 749.318161ms 749.388001ms 749.419013ms 749.425657ms 749.430806ms 749.452203ms 749.526189ms 749.546662ms 749.614808ms 749.642076ms 749.655252ms 749.790738ms 749.840398ms 749.849815ms 749.971015ms 750.038913ms 750.076019ms 750.087242ms 750.191745ms 750.192511ms 750.217588ms 750.251835ms 750.359259ms 750.364447ms 750.426212ms 750.44293ms 750.487901ms 750.499371ms 750.512946ms 750.577099ms 750.614829ms 750.656534ms 750.713481ms 750.764439ms 750.829515ms 750.947517ms 750.960347ms 750.985937ms 751.018037ms 751.072579ms 751.134848ms 751.163457ms 751.32682ms 751.360346ms 751.388918ms 751.401483ms 751.496075ms 751.713188ms 751.735975ms 751.771031ms 751.794785ms 751.989864ms 752.129701ms 752.463581ms 752.767736ms 752.842945ms 752.988767ms 752.989995ms 753.239511ms 753.269994ms 754.211455ms 754.531962ms 755.277ms 756.95929ms 757.753002ms 758.296578ms 758.440322ms 758.838895ms 764.568601ms 765.314795ms 768.69898ms 771.728899ms 810.740277ms 812.777365ms 814.270265ms 823.531883ms 824.51115ms 838.69519ms 838.829055ms 863.200265ms 864.283127ms 886.962274ms 907.315514ms 907.589754ms]
Dec  5 20:49:10.484: INFO: 50 %ile: 748.560888ms
Dec  5 20:49:10.484: INFO: 90 %ile: 757.753002ms
Dec  5 20:49:10.484: INFO: 99 %ile: 907.315514ms
Dec  5 20:49:10.484: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:49:10.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-57xs4" for this suite.
Dec  5 20:49:24.501: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:49:24.534: INFO: namespace: e2e-tests-svc-latency-57xs4, resource: bindings, ignored listing per whitelist
Dec  5 20:49:24.603: INFO: namespace e2e-tests-svc-latency-57xs4 deletion completed in 14.113668261s

• [SLOW TEST:25.902 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:49:24.603: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-3fc509a9-f8cf-11e8-b559-c27407a18179
STEP: Creating secret with name secret-projected-all-test-volume-3fc50995-f8cf-11e8-b559-c27407a18179
STEP: Creating a pod to test Check all projections for projected volume plugin
Dec  5 20:49:24.673: INFO: Waiting up to 5m0s for pod "projected-volume-3fc5095e-f8cf-11e8-b559-c27407a18179" in namespace "e2e-tests-projected-zb75g" to be "success or failure"
Dec  5 20:49:24.676: INFO: Pod "projected-volume-3fc5095e-f8cf-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.844417ms
Dec  5 20:49:26.864: INFO: Pod "projected-volume-3fc5095e-f8cf-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.190738484s
Dec  5 20:49:28.868: INFO: Pod "projected-volume-3fc5095e-f8cf-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.194330198s
STEP: Saw pod success
Dec  5 20:49:28.868: INFO: Pod "projected-volume-3fc5095e-f8cf-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 20:49:28.870: INFO: Trying to get logs from node ip-172-31-24-193 pod projected-volume-3fc5095e-f8cf-11e8-b559-c27407a18179 container projected-all-volume-test: <nil>
STEP: delete the pod
Dec  5 20:49:28.888: INFO: Waiting for pod projected-volume-3fc5095e-f8cf-11e8-b559-c27407a18179 to disappear
Dec  5 20:49:28.891: INFO: Pod projected-volume-3fc5095e-f8cf-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:49:28.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zb75g" for this suite.
Dec  5 20:49:34.906: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:49:34.993: INFO: namespace: e2e-tests-projected-zb75g, resource: bindings, ignored listing per whitelist
Dec  5 20:49:35.010: INFO: namespace e2e-tests-projected-zb75g deletion completed in 6.114976933s

• [SLOW TEST:10.407 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:49:35.011: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-46011980-f8cf-11e8-b559-c27407a18179
STEP: Creating a pod to test consume secrets
Dec  5 20:49:35.131: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4601c0a3-f8cf-11e8-b559-c27407a18179" in namespace "e2e-tests-projected-57snd" to be "success or failure"
Dec  5 20:49:35.136: INFO: Pod "pod-projected-secrets-4601c0a3-f8cf-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 4.928824ms
Dec  5 20:49:37.140: INFO: Pod "pod-projected-secrets-4601c0a3-f8cf-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008552467s
Dec  5 20:49:39.144: INFO: Pod "pod-projected-secrets-4601c0a3-f8cf-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012508681s
STEP: Saw pod success
Dec  5 20:49:39.144: INFO: Pod "pod-projected-secrets-4601c0a3-f8cf-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 20:49:39.147: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-projected-secrets-4601c0a3-f8cf-11e8-b559-c27407a18179 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  5 20:49:39.166: INFO: Waiting for pod pod-projected-secrets-4601c0a3-f8cf-11e8-b559-c27407a18179 to disappear
Dec  5 20:49:39.169: INFO: Pod pod-projected-secrets-4601c0a3-f8cf-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:49:39.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-57snd" for this suite.
Dec  5 20:49:45.183: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:49:45.247: INFO: namespace: e2e-tests-projected-57snd, resource: bindings, ignored listing per whitelist
Dec  5 20:49:45.273: INFO: namespace e2e-tests-projected-57snd deletion completed in 6.100459198s

• [SLOW TEST:10.262 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:49:45.273: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec  5 20:49:45.335: INFO: Waiting up to 5m0s for pod "pod-4c169f94-f8cf-11e8-b559-c27407a18179" in namespace "e2e-tests-emptydir-plxjf" to be "success or failure"
Dec  5 20:49:45.339: INFO: Pod "pod-4c169f94-f8cf-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022741ms
Dec  5 20:49:47.342: INFO: Pod "pod-4c169f94-f8cf-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007267668s
Dec  5 20:49:49.345: INFO: Pod "pod-4c169f94-f8cf-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010817138s
STEP: Saw pod success
Dec  5 20:49:49.345: INFO: Pod "pod-4c169f94-f8cf-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 20:49:49.348: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-4c169f94-f8cf-11e8-b559-c27407a18179 container test-container: <nil>
STEP: delete the pod
Dec  5 20:49:49.366: INFO: Waiting for pod pod-4c169f94-f8cf-11e8-b559-c27407a18179 to disappear
Dec  5 20:49:49.369: INFO: Pod pod-4c169f94-f8cf-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:49:49.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-plxjf" for this suite.
Dec  5 20:49:55.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:49:55.439: INFO: namespace: e2e-tests-emptydir-plxjf, resource: bindings, ignored listing per whitelist
Dec  5 20:49:55.481: INFO: namespace e2e-tests-emptydir-plxjf deletion completed in 6.109986191s

• [SLOW TEST:10.209 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:49:55.482: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec  5 20:49:55.540: INFO: Waiting up to 5m0s for pod "pod-522c11f2-f8cf-11e8-b559-c27407a18179" in namespace "e2e-tests-emptydir-x56h4" to be "success or failure"
Dec  5 20:49:55.543: INFO: Pod "pod-522c11f2-f8cf-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.581094ms
Dec  5 20:49:57.546: INFO: Pod "pod-522c11f2-f8cf-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006076739s
STEP: Saw pod success
Dec  5 20:49:57.546: INFO: Pod "pod-522c11f2-f8cf-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 20:49:57.549: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-522c11f2-f8cf-11e8-b559-c27407a18179 container test-container: <nil>
STEP: delete the pod
Dec  5 20:49:57.567: INFO: Waiting for pod pod-522c11f2-f8cf-11e8-b559-c27407a18179 to disappear
Dec  5 20:49:57.570: INFO: Pod pod-522c11f2-f8cf-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:49:57.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-x56h4" for this suite.
Dec  5 20:50:03.585: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:50:03.830: INFO: namespace: e2e-tests-emptydir-x56h4, resource: bindings, ignored listing per whitelist
Dec  5 20:50:03.830: INFO: namespace e2e-tests-emptydir-x56h4 deletion completed in 6.256669151s

• [SLOW TEST:8.348 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:50:03.830: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-5725c6c6-f8cf-11e8-b559-c27407a18179
STEP: Creating a pod to test consume secrets
Dec  5 20:50:03.891: INFO: Waiting up to 5m0s for pod "pod-secrets-57265d42-f8cf-11e8-b559-c27407a18179" in namespace "e2e-tests-secrets-vkz56" to be "success or failure"
Dec  5 20:50:03.896: INFO: Pod "pod-secrets-57265d42-f8cf-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 5.570624ms
Dec  5 20:50:05.900: INFO: Pod "pod-secrets-57265d42-f8cf-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0093571s
STEP: Saw pod success
Dec  5 20:50:05.900: INFO: Pod "pod-secrets-57265d42-f8cf-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 20:50:05.903: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-secrets-57265d42-f8cf-11e8-b559-c27407a18179 container secret-volume-test: <nil>
STEP: delete the pod
Dec  5 20:50:05.922: INFO: Waiting for pod pod-secrets-57265d42-f8cf-11e8-b559-c27407a18179 to disappear
Dec  5 20:50:05.925: INFO: Pod pod-secrets-57265d42-f8cf-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:50:05.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-vkz56" for this suite.
Dec  5 20:50:11.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:50:11.998: INFO: namespace: e2e-tests-secrets-vkz56, resource: bindings, ignored listing per whitelist
Dec  5 20:50:12.047: INFO: namespace e2e-tests-secrets-vkz56 deletion completed in 6.119179822s

• [SLOW TEST:8.217 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:50:12.047: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-4lr2b in namespace e2e-tests-proxy-bp4p2
I1205 20:50:12.115820      15 runners.go:184] Created replication controller with name: proxy-service-4lr2b, namespace: e2e-tests-proxy-bp4p2, replica count: 1
I1205 20:50:13.166208      15 runners.go:184] proxy-service-4lr2b Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1205 20:50:14.166379      15 runners.go:184] proxy-service-4lr2b Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1205 20:50:15.166578      15 runners.go:184] proxy-service-4lr2b Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1205 20:50:16.166742      15 runners.go:184] proxy-service-4lr2b Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  5 20:50:16.170: INFO: setup took 4.071231478s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Dec  5 20:50:16.178: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v/proxy/rewriteme"... (200; 8.186743ms)
Dec  5 20:50:16.178: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:1080/proxy/... (200; 8.174124ms)
Dec  5 20:50:16.179: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:160/proxy/: foo (200; 8.866561ms)
Dec  5 20:50:16.179: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:162/proxy/: bar (200; 9.281345ms)
Dec  5 20:50:16.180: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/http:proxy-service-4lr2b:portname1/proxy/: foo (200; 9.828033ms)
Dec  5 20:50:16.180: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:162/proxy/: bar (200; 9.783623ms)
Dec  5 20:50:16.180: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/proxy-service-4lr2b:portname2/proxy/: bar (200; 10.100266ms)
Dec  5 20:50:16.180: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/proxy-service-4lr2b:portname1/proxy/: foo (200; 10.229806ms)
Dec  5 20:50:16.184: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:443/proxy/... (200; 13.965658ms)
Dec  5 20:50:16.185: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:1080/proxy/rewri... (200; 15.037249ms)
Dec  5 20:50:16.185: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/http:proxy-service-4lr2b:portname2/proxy/: bar (200; 15.220602ms)
Dec  5 20:50:16.185: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:160/proxy/: foo (200; 15.159503ms)
Dec  5 20:50:16.186: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:462/proxy/: tls qux (200; 15.683924ms)
Dec  5 20:50:16.186: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/https:proxy-service-4lr2b:tlsportname1/proxy/: tls baz (200; 16.010478ms)
Dec  5 20:50:16.186: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:460/proxy/: tls baz (200; 16.232223ms)
Dec  5 20:50:16.189: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/https:proxy-service-4lr2b:tlsportname2/proxy/: tls qux (200; 18.481967ms)
Dec  5 20:50:16.194: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:1080/proxy/... (200; 5.432163ms)
Dec  5 20:50:16.194: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:162/proxy/: bar (200; 5.292203ms)
Dec  5 20:50:16.195: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:160/proxy/: foo (200; 6.411154ms)
Dec  5 20:50:16.196: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:160/proxy/: foo (200; 7.685933ms)
Dec  5 20:50:16.197: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:1080/proxy/rewri... (200; 8.045512ms)
Dec  5 20:50:16.198: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/http:proxy-service-4lr2b:portname2/proxy/: bar (200; 9.071632ms)
Dec  5 20:50:16.198: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v/proxy/rewriteme"... (200; 9.240979ms)
Dec  5 20:50:16.199: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:162/proxy/: bar (200; 9.908712ms)
Dec  5 20:50:16.199: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:443/proxy/... (200; 9.865131ms)
Dec  5 20:50:16.199: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:462/proxy/: tls qux (200; 9.805743ms)
Dec  5 20:50:16.199: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:460/proxy/: tls baz (200; 9.838432ms)
Dec  5 20:50:16.200: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/proxy-service-4lr2b:portname1/proxy/: foo (200; 11.259461ms)
Dec  5 20:50:16.200: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/proxy-service-4lr2b:portname2/proxy/: bar (200; 11.400235ms)
Dec  5 20:50:16.200: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/https:proxy-service-4lr2b:tlsportname1/proxy/: tls baz (200; 11.413541ms)
Dec  5 20:50:16.200: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/http:proxy-service-4lr2b:portname1/proxy/: foo (200; 11.448501ms)
Dec  5 20:50:16.200: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/https:proxy-service-4lr2b:tlsportname2/proxy/: tls qux (200; 11.391706ms)
Dec  5 20:50:16.206: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:162/proxy/: bar (200; 5.190467ms)
Dec  5 20:50:16.206: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:160/proxy/: foo (200; 5.799965ms)
Dec  5 20:50:16.206: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:160/proxy/: foo (200; 6.000349ms)
Dec  5 20:50:16.206: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:443/proxy/... (200; 6.1053ms)
Dec  5 20:50:16.207: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:1080/proxy/... (200; 6.420256ms)
Dec  5 20:50:16.208: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/https:proxy-service-4lr2b:tlsportname1/proxy/: tls baz (200; 7.779384ms)
Dec  5 20:50:16.208: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v/proxy/rewriteme"... (200; 7.9318ms)
Dec  5 20:50:16.208: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:460/proxy/: tls baz (200; 8.074065ms)
Dec  5 20:50:16.209: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:1080/proxy/rewri... (200; 8.841062ms)
Dec  5 20:50:16.209: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:462/proxy/: tls qux (200; 8.594774ms)
Dec  5 20:50:16.210: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/http:proxy-service-4lr2b:portname1/proxy/: foo (200; 9.584943ms)
Dec  5 20:50:16.210: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/proxy-service-4lr2b:portname2/proxy/: bar (200; 9.940333ms)
Dec  5 20:50:16.211: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/proxy-service-4lr2b:portname1/proxy/: foo (200; 10.512202ms)
Dec  5 20:50:16.211: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/https:proxy-service-4lr2b:tlsportname2/proxy/: tls qux (200; 10.533804ms)
Dec  5 20:50:16.211: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/http:proxy-service-4lr2b:portname2/proxy/: bar (200; 10.64916ms)
Dec  5 20:50:16.211: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:162/proxy/: bar (200; 11.130459ms)
Dec  5 20:50:16.216: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:160/proxy/: foo (200; 4.387923ms)
Dec  5 20:50:16.217: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:160/proxy/: foo (200; 5.828494ms)
Dec  5 20:50:16.219: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:162/proxy/: bar (200; 7.444855ms)
Dec  5 20:50:16.220: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:443/proxy/... (200; 7.847943ms)
Dec  5 20:50:16.221: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:1080/proxy/... (200; 8.908958ms)
Dec  5 20:50:16.221: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v/proxy/rewriteme"... (200; 9.424542ms)
Dec  5 20:50:16.222: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:460/proxy/: tls baz (200; 9.685087ms)
Dec  5 20:50:16.223: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/http:proxy-service-4lr2b:portname2/proxy/: bar (200; 11.074737ms)
Dec  5 20:50:16.223: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/http:proxy-service-4lr2b:portname1/proxy/: foo (200; 11.573313ms)
Dec  5 20:50:16.223: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:1080/proxy/rewri... (200; 11.506192ms)
Dec  5 20:50:16.223: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/proxy-service-4lr2b:portname1/proxy/: foo (200; 11.386424ms)
Dec  5 20:50:16.223: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:162/proxy/: bar (200; 11.499018ms)
Dec  5 20:50:16.224: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/https:proxy-service-4lr2b:tlsportname2/proxy/: tls qux (200; 12.304119ms)
Dec  5 20:50:16.224: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/proxy-service-4lr2b:portname2/proxy/: bar (200; 12.108571ms)
Dec  5 20:50:16.224: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:462/proxy/: tls qux (200; 12.251841ms)
Dec  5 20:50:16.224: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/https:proxy-service-4lr2b:tlsportname1/proxy/: tls baz (200; 12.388143ms)
Dec  5 20:50:16.228: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:1080/proxy/... (200; 4.070274ms)
Dec  5 20:50:16.229: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:162/proxy/: bar (200; 4.34615ms)
Dec  5 20:50:16.232: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/proxy-service-4lr2b:portname2/proxy/: bar (200; 7.472643ms)
Dec  5 20:50:16.233: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:1080/proxy/rewri... (200; 8.41244ms)
Dec  5 20:50:16.233: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:462/proxy/: tls qux (200; 8.555078ms)
Dec  5 20:50:16.233: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:160/proxy/: foo (200; 8.808717ms)
Dec  5 20:50:16.233: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:162/proxy/: bar (200; 9.05514ms)
Dec  5 20:50:16.235: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:460/proxy/: tls baz (200; 10.657617ms)
Dec  5 20:50:16.235: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/https:proxy-service-4lr2b:tlsportname1/proxy/: tls baz (200; 10.806357ms)
Dec  5 20:50:16.235: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/proxy-service-4lr2b:portname1/proxy/: foo (200; 11.020048ms)
Dec  5 20:50:16.235: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:443/proxy/... (200; 10.98836ms)
Dec  5 20:50:16.235: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:160/proxy/: foo (200; 10.873981ms)
Dec  5 20:50:16.235: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v/proxy/rewriteme"... (200; 10.994949ms)
Dec  5 20:50:16.236: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/http:proxy-service-4lr2b:portname2/proxy/: bar (200; 11.614857ms)
Dec  5 20:50:16.236: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/http:proxy-service-4lr2b:portname1/proxy/: foo (200; 11.552263ms)
Dec  5 20:50:16.236: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/https:proxy-service-4lr2b:tlsportname2/proxy/: tls qux (200; 11.915004ms)
Dec  5 20:50:16.240: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:1080/proxy/rewri... (200; 3.986723ms)
Dec  5 20:50:16.241: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:162/proxy/: bar (200; 4.651955ms)
Dec  5 20:50:16.241: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:443/proxy/... (200; 4.865174ms)
Dec  5 20:50:16.243: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/https:proxy-service-4lr2b:tlsportname2/proxy/: tls qux (200; 6.290584ms)
Dec  5 20:50:16.243: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:1080/proxy/... (200; 6.585821ms)
Dec  5 20:50:16.244: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/http:proxy-service-4lr2b:portname2/proxy/: bar (200; 7.182557ms)
Dec  5 20:50:16.245: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v/proxy/rewriteme"... (200; 8.840037ms)
Dec  5 20:50:16.245: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/https:proxy-service-4lr2b:tlsportname1/proxy/: tls baz (200; 9.095071ms)
Dec  5 20:50:16.245: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:462/proxy/: tls qux (200; 8.707833ms)
Dec  5 20:50:16.245: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:160/proxy/: foo (200; 8.715255ms)
Dec  5 20:50:16.246: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:162/proxy/: bar (200; 9.198564ms)
Dec  5 20:50:16.246: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:460/proxy/: tls baz (200; 9.195941ms)
Dec  5 20:50:16.246: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/proxy-service-4lr2b:portname2/proxy/: bar (200; 9.498864ms)
Dec  5 20:50:16.246: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:160/proxy/: foo (200; 9.150647ms)
Dec  5 20:50:16.246: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/http:proxy-service-4lr2b:portname1/proxy/: foo (200; 9.369173ms)
Dec  5 20:50:16.246: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/proxy-service-4lr2b:portname1/proxy/: foo (200; 9.529511ms)
Dec  5 20:50:16.251: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:462/proxy/: tls qux (200; 5.123216ms)
Dec  5 20:50:16.251: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:1080/proxy/rewri... (200; 5.275518ms)
Dec  5 20:50:16.253: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:160/proxy/: foo (200; 6.758607ms)
Dec  5 20:50:16.253: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:162/proxy/: bar (200; 6.810702ms)
Dec  5 20:50:16.254: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v/proxy/rewriteme"... (200; 7.580005ms)
Dec  5 20:50:16.254: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:460/proxy/: tls baz (200; 7.676273ms)
Dec  5 20:50:16.254: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:1080/proxy/... (200; 7.749031ms)
Dec  5 20:50:16.255: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:443/proxy/... (200; 8.480147ms)
Dec  5 20:50:16.255: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:160/proxy/: foo (200; 8.738669ms)
Dec  5 20:50:16.255: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:162/proxy/: bar (200; 9.032903ms)
Dec  5 20:50:16.256: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/https:proxy-service-4lr2b:tlsportname1/proxy/: tls baz (200; 9.349759ms)
Dec  5 20:50:16.256: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/https:proxy-service-4lr2b:tlsportname2/proxy/: tls qux (200; 9.689938ms)
Dec  5 20:50:16.256: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/proxy-service-4lr2b:portname1/proxy/: foo (200; 10.004477ms)
Dec  5 20:50:16.256: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/http:proxy-service-4lr2b:portname2/proxy/: bar (200; 10.154495ms)
Dec  5 20:50:16.257: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/http:proxy-service-4lr2b:portname1/proxy/: foo (200; 10.41418ms)
Dec  5 20:50:16.257: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/proxy-service-4lr2b:portname2/proxy/: bar (200; 10.52873ms)
Dec  5 20:50:16.261: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:462/proxy/: tls qux (200; 3.898835ms)
Dec  5 20:50:16.262: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:443/proxy/... (200; 5.488059ms)
Dec  5 20:50:16.263: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:162/proxy/: bar (200; 6.361107ms)
Dec  5 20:50:16.264: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:160/proxy/: foo (200; 6.547987ms)
Dec  5 20:50:16.264: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:460/proxy/: tls baz (200; 6.827641ms)
Dec  5 20:50:16.264: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:1080/proxy/rewri... (200; 7.068562ms)
Dec  5 20:50:16.264: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:1080/proxy/... (200; 7.003966ms)
Dec  5 20:50:16.264: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v/proxy/rewriteme"... (200; 7.454358ms)
Dec  5 20:50:16.265: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:160/proxy/: foo (200; 7.797975ms)
Dec  5 20:50:16.265: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:162/proxy/: bar (200; 7.886164ms)
Dec  5 20:50:16.265: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/http:proxy-service-4lr2b:portname1/proxy/: foo (200; 8.588121ms)
Dec  5 20:50:16.265: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/http:proxy-service-4lr2b:portname2/proxy/: bar (200; 8.507302ms)
Dec  5 20:50:16.266: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/https:proxy-service-4lr2b:tlsportname1/proxy/: tls baz (200; 9.1855ms)
Dec  5 20:50:16.266: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/https:proxy-service-4lr2b:tlsportname2/proxy/: tls qux (200; 9.357157ms)
Dec  5 20:50:16.266: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/proxy-service-4lr2b:portname2/proxy/: bar (200; 9.528214ms)
Dec  5 20:50:16.266: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/proxy-service-4lr2b:portname1/proxy/: foo (200; 9.686684ms)
Dec  5 20:50:16.273: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:1080/proxy/... (200; 5.86955ms)
Dec  5 20:50:16.273: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/https:proxy-service-4lr2b:tlsportname1/proxy/: tls baz (200; 6.287712ms)
Dec  5 20:50:16.276: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v/proxy/rewriteme"... (200; 9.128173ms)
Dec  5 20:50:16.276: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:1080/proxy/rewri... (200; 8.806217ms)
Dec  5 20:50:16.276: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:162/proxy/: bar (200; 9.002466ms)
Dec  5 20:50:16.276: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:162/proxy/: bar (200; 9.571049ms)
Dec  5 20:50:16.277: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:443/proxy/... (200; 9.771055ms)
Dec  5 20:50:16.278: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:462/proxy/: tls qux (200; 11.07558ms)
Dec  5 20:50:16.278: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/https:proxy-service-4lr2b:tlsportname2/proxy/: tls qux (200; 11.592417ms)
Dec  5 20:50:16.278: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:160/proxy/: foo (200; 11.2142ms)
Dec  5 20:50:16.279: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/proxy-service-4lr2b:portname2/proxy/: bar (200; 11.557622ms)
Dec  5 20:50:16.279: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/http:proxy-service-4lr2b:portname1/proxy/: foo (200; 11.666648ms)
Dec  5 20:50:16.279: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:460/proxy/: tls baz (200; 11.915773ms)
Dec  5 20:50:16.279: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/http:proxy-service-4lr2b:portname2/proxy/: bar (200; 12.15483ms)
Dec  5 20:50:16.280: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/proxy-service-4lr2b:portname1/proxy/: foo (200; 12.791641ms)
Dec  5 20:50:16.280: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:160/proxy/: foo (200; 12.991189ms)
Dec  5 20:50:16.284: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v/proxy/rewriteme"... (200; 4.098002ms)
Dec  5 20:50:16.285: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:160/proxy/: foo (200; 5.349171ms)
Dec  5 20:50:16.287: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:162/proxy/: bar (200; 6.64714ms)
Dec  5 20:50:16.287: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:1080/proxy/... (200; 7.073057ms)
Dec  5 20:50:16.287: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:160/proxy/: foo (200; 7.115809ms)
Dec  5 20:50:16.287: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:1080/proxy/rewri... (200; 7.023381ms)
Dec  5 20:50:16.287: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:462/proxy/: tls qux (200; 7.465268ms)
Dec  5 20:50:16.288: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:460/proxy/: tls baz (200; 7.977896ms)
Dec  5 20:50:16.289: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:162/proxy/: bar (200; 8.543842ms)
Dec  5 20:50:16.289: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:443/proxy/... (200; 8.416723ms)
Dec  5 20:50:16.289: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/proxy-service-4lr2b:portname1/proxy/: foo (200; 8.84657ms)
Dec  5 20:50:16.289: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/http:proxy-service-4lr2b:portname1/proxy/: foo (200; 9.349644ms)
Dec  5 20:50:16.290: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/https:proxy-service-4lr2b:tlsportname1/proxy/: tls baz (200; 9.504626ms)
Dec  5 20:50:16.290: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/http:proxy-service-4lr2b:portname2/proxy/: bar (200; 9.584715ms)
Dec  5 20:50:16.290: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/proxy-service-4lr2b:portname2/proxy/: bar (200; 9.726328ms)
Dec  5 20:50:16.290: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/https:proxy-service-4lr2b:tlsportname2/proxy/: tls qux (200; 10.026698ms)
Dec  5 20:50:16.296: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v/proxy/rewriteme"... (200; 6.189799ms)
Dec  5 20:50:16.297: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:460/proxy/: tls baz (200; 6.668172ms)
Dec  5 20:50:16.297: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:160/proxy/: foo (200; 7.069403ms)
Dec  5 20:50:16.297: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:1080/proxy/... (200; 7.013321ms)
Dec  5 20:50:16.298: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:462/proxy/: tls qux (200; 8.062915ms)
Dec  5 20:50:16.298: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:162/proxy/: bar (200; 8.047182ms)
Dec  5 20:50:16.298: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:160/proxy/: foo (200; 8.246363ms)
Dec  5 20:50:16.298: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:162/proxy/: bar (200; 8.19749ms)
Dec  5 20:50:16.299: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/proxy-service-4lr2b:portname1/proxy/: foo (200; 8.452293ms)
Dec  5 20:50:16.299: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:443/proxy/... (200; 8.86551ms)
Dec  5 20:50:16.299: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:1080/proxy/rewri... (200; 8.98956ms)
Dec  5 20:50:16.300: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/proxy-service-4lr2b:portname2/proxy/: bar (200; 9.325683ms)
Dec  5 20:50:16.300: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/http:proxy-service-4lr2b:portname2/proxy/: bar (200; 9.796758ms)
Dec  5 20:50:16.300: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/https:proxy-service-4lr2b:tlsportname1/proxy/: tls baz (200; 9.857251ms)
Dec  5 20:50:16.301: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/https:proxy-service-4lr2b:tlsportname2/proxy/: tls qux (200; 10.59518ms)
Dec  5 20:50:16.301: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/http:proxy-service-4lr2b:portname1/proxy/: foo (200; 10.525141ms)
Dec  5 20:50:16.306: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:1080/proxy/rewri... (200; 5.086439ms)
Dec  5 20:50:16.306: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:462/proxy/: tls qux (200; 4.968973ms)
Dec  5 20:50:16.306: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:460/proxy/: tls baz (200; 5.702274ms)
Dec  5 20:50:16.307: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:160/proxy/: foo (200; 5.854988ms)
Dec  5 20:50:16.307: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:162/proxy/: bar (200; 6.087236ms)
Dec  5 20:50:16.308: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:443/proxy/... (200; 7.567041ms)
Dec  5 20:50:16.309: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:160/proxy/: foo (200; 7.830519ms)
Dec  5 20:50:16.309: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v/proxy/rewriteme"... (200; 7.997708ms)
Dec  5 20:50:16.309: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/https:proxy-service-4lr2b:tlsportname2/proxy/: tls qux (200; 8.238281ms)
Dec  5 20:50:16.309: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:1080/proxy/... (200; 8.352038ms)
Dec  5 20:50:16.310: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:162/proxy/: bar (200; 8.688034ms)
Dec  5 20:50:16.310: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/proxy-service-4lr2b:portname2/proxy/: bar (200; 9.397018ms)
Dec  5 20:50:16.311: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/http:proxy-service-4lr2b:portname2/proxy/: bar (200; 9.792298ms)
Dec  5 20:50:16.311: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/http:proxy-service-4lr2b:portname1/proxy/: foo (200; 9.909006ms)
Dec  5 20:50:16.311: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/https:proxy-service-4lr2b:tlsportname1/proxy/: tls baz (200; 9.902876ms)
Dec  5 20:50:16.311: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/proxy-service-4lr2b:portname1/proxy/: foo (200; 9.972823ms)
Dec  5 20:50:16.315: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:462/proxy/: tls qux (200; 3.693314ms)
Dec  5 20:50:16.317: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:1080/proxy/... (200; 5.834795ms)
Dec  5 20:50:16.317: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:162/proxy/: bar (200; 6.032316ms)
Dec  5 20:50:16.318: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:1080/proxy/rewri... (200; 6.69891ms)
Dec  5 20:50:16.318: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v/proxy/rewriteme"... (200; 6.915176ms)
Dec  5 20:50:16.319: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:460/proxy/: tls baz (200; 7.580808ms)
Dec  5 20:50:16.319: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:160/proxy/: foo (200; 7.654676ms)
Dec  5 20:50:16.319: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:160/proxy/: foo (200; 7.952368ms)
Dec  5 20:50:16.319: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:443/proxy/... (200; 8.090705ms)
Dec  5 20:50:16.319: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:162/proxy/: bar (200; 8.095413ms)
Dec  5 20:50:16.319: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/proxy-service-4lr2b:portname2/proxy/: bar (200; 8.321975ms)
Dec  5 20:50:16.320: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/http:proxy-service-4lr2b:portname2/proxy/: bar (200; 8.617322ms)
Dec  5 20:50:16.320: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/https:proxy-service-4lr2b:tlsportname1/proxy/: tls baz (200; 8.981549ms)
Dec  5 20:50:16.321: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/proxy-service-4lr2b:portname1/proxy/: foo (200; 9.590891ms)
Dec  5 20:50:16.321: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/https:proxy-service-4lr2b:tlsportname2/proxy/: tls qux (200; 9.64925ms)
Dec  5 20:50:16.321: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/http:proxy-service-4lr2b:portname1/proxy/: foo (200; 9.837029ms)
Dec  5 20:50:16.329: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:460/proxy/: tls baz (200; 7.734938ms)
Dec  5 20:50:16.329: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:160/proxy/: foo (200; 7.947561ms)
Dec  5 20:50:16.329: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:162/proxy/: bar (200; 8.404932ms)
Dec  5 20:50:16.330: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v/proxy/rewriteme"... (200; 8.787403ms)
Dec  5 20:50:16.330: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:1080/proxy/... (200; 8.995855ms)
Dec  5 20:50:16.330: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/proxy-service-4lr2b:portname2/proxy/: bar (200; 9.646058ms)
Dec  5 20:50:16.330: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:443/proxy/... (200; 9.479462ms)
Dec  5 20:50:16.331: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:1080/proxy/rewri... (200; 9.930322ms)
Dec  5 20:50:16.331: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:462/proxy/: tls qux (200; 9.825419ms)
Dec  5 20:50:16.331: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:162/proxy/: bar (200; 9.893438ms)
Dec  5 20:50:16.331: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:160/proxy/: foo (200; 10.064323ms)
Dec  5 20:50:16.331: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/http:proxy-service-4lr2b:portname2/proxy/: bar (200; 10.618988ms)
Dec  5 20:50:16.332: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/https:proxy-service-4lr2b:tlsportname1/proxy/: tls baz (200; 10.63008ms)
Dec  5 20:50:16.332: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/proxy-service-4lr2b:portname1/proxy/: foo (200; 10.609149ms)
Dec  5 20:50:16.332: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/https:proxy-service-4lr2b:tlsportname2/proxy/: tls qux (200; 10.847599ms)
Dec  5 20:50:16.332: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/http:proxy-service-4lr2b:portname1/proxy/: foo (200; 10.919202ms)
Dec  5 20:50:16.337: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:160/proxy/: foo (200; 5.480165ms)
Dec  5 20:50:16.338: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v/proxy/rewriteme"... (200; 5.346419ms)
Dec  5 20:50:16.338: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:1080/proxy/rewri... (200; 5.423029ms)
Dec  5 20:50:16.338: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:162/proxy/: bar (200; 6.104694ms)
Dec  5 20:50:16.339: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:1080/proxy/... (200; 6.507869ms)
Dec  5 20:50:16.339: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:162/proxy/: bar (200; 7.247211ms)
Dec  5 20:50:16.340: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:462/proxy/: tls qux (200; 7.850254ms)
Dec  5 20:50:16.340: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/proxy-service-4lr2b:portname1/proxy/: foo (200; 7.933784ms)
Dec  5 20:50:16.340: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/https:proxy-service-4lr2b:tlsportname1/proxy/: tls baz (200; 8.18952ms)
Dec  5 20:50:16.340: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:460/proxy/: tls baz (200; 8.415265ms)
Dec  5 20:50:16.341: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:443/proxy/... (200; 8.75011ms)
Dec  5 20:50:16.341: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:160/proxy/: foo (200; 8.948216ms)
Dec  5 20:50:16.341: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/proxy-service-4lr2b:portname2/proxy/: bar (200; 8.915167ms)
Dec  5 20:50:16.341: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/http:proxy-service-4lr2b:portname2/proxy/: bar (200; 9.297743ms)
Dec  5 20:50:16.342: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/http:proxy-service-4lr2b:portname1/proxy/: foo (200; 9.616901ms)
Dec  5 20:50:16.342: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/https:proxy-service-4lr2b:tlsportname2/proxy/: tls qux (200; 10.255239ms)
Dec  5 20:50:16.347: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:160/proxy/: foo (200; 4.298909ms)
Dec  5 20:50:16.347: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:1080/proxy/... (200; 4.525819ms)
Dec  5 20:50:16.348: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:443/proxy/... (200; 5.337278ms)
Dec  5 20:50:16.348: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:160/proxy/: foo (200; 5.732267ms)
Dec  5 20:50:16.349: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:462/proxy/: tls qux (200; 6.738855ms)
Dec  5 20:50:16.349: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:1080/proxy/rewri... (200; 6.685365ms)
Dec  5 20:50:16.349: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:162/proxy/: bar (200; 6.855668ms)
Dec  5 20:50:16.349: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v/proxy/rewriteme"... (200; 6.711882ms)
Dec  5 20:50:16.350: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:162/proxy/: bar (200; 7.097627ms)
Dec  5 20:50:16.350: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:460/proxy/: tls baz (200; 7.45962ms)
Dec  5 20:50:16.351: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/http:proxy-service-4lr2b:portname1/proxy/: foo (200; 8.13148ms)
Dec  5 20:50:16.351: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/https:proxy-service-4lr2b:tlsportname2/proxy/: tls qux (200; 8.337764ms)
Dec  5 20:50:16.352: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/proxy-service-4lr2b:portname2/proxy/: bar (200; 9.170131ms)
Dec  5 20:50:16.352: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/https:proxy-service-4lr2b:tlsportname1/proxy/: tls baz (200; 9.496865ms)
Dec  5 20:50:16.352: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/http:proxy-service-4lr2b:portname2/proxy/: bar (200; 9.715415ms)
Dec  5 20:50:16.353: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/proxy-service-4lr2b:portname1/proxy/: foo (200; 9.97314ms)
Dec  5 20:50:16.356: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:462/proxy/: tls qux (200; 3.577965ms)
Dec  5 20:50:16.357: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:160/proxy/: foo (200; 4.085003ms)
Dec  5 20:50:16.358: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:160/proxy/: foo (200; 5.140827ms)
Dec  5 20:50:16.358: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:1080/proxy/rewri... (200; 5.270785ms)
Dec  5 20:50:16.360: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:1080/proxy/... (200; 6.989784ms)
Dec  5 20:50:16.360: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:443/proxy/... (200; 7.087066ms)
Dec  5 20:50:16.360: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/http:proxy-service-4lr2b:portname1/proxy/: foo (200; 7.291686ms)
Dec  5 20:50:16.360: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v/proxy/rewriteme"... (200; 7.282161ms)
Dec  5 20:50:16.361: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:162/proxy/: bar (200; 7.503511ms)
Dec  5 20:50:16.361: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:162/proxy/: bar (200; 7.593484ms)
Dec  5 20:50:16.361: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/https:proxy-service-4lr2b:tlsportname2/proxy/: tls qux (200; 8.239648ms)
Dec  5 20:50:16.361: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/https:proxy-service-4lr2b:tlsportname1/proxy/: tls baz (200; 8.241363ms)
Dec  5 20:50:16.361: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/proxy-service-4lr2b:portname2/proxy/: bar (200; 8.519735ms)
Dec  5 20:50:16.362: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:460/proxy/: tls baz (200; 8.896323ms)
Dec  5 20:50:16.362: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/proxy-service-4lr2b:portname1/proxy/: foo (200; 8.89775ms)
Dec  5 20:50:16.362: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/http:proxy-service-4lr2b:portname2/proxy/: bar (200; 8.668917ms)
Dec  5 20:50:16.383: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v/proxy/rewriteme"... (200; 21.053548ms)
Dec  5 20:50:16.396: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:1080/proxy/... (200; 34.17075ms)
Dec  5 20:50:16.396: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:160/proxy/: foo (200; 34.163106ms)
Dec  5 20:50:16.396: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:443/proxy/... (200; 34.354001ms)
Dec  5 20:50:16.396: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:460/proxy/: tls baz (200; 34.454287ms)
Dec  5 20:50:16.399: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:162/proxy/: bar (200; 37.1524ms)
Dec  5 20:50:16.399: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:160/proxy/: foo (200; 37.261434ms)
Dec  5 20:50:16.401: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:462/proxy/: tls qux (200; 38.617359ms)
Dec  5 20:50:16.401: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:1080/proxy/rewri... (200; 38.58813ms)
Dec  5 20:50:16.402: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/proxy-service-4lr2b:portname1/proxy/: foo (200; 40.339932ms)
Dec  5 20:50:16.405: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/proxy-service-4lr2b:portname2/proxy/: bar (200; 43.15453ms)
Dec  5 20:50:16.405: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:162/proxy/: bar (200; 43.495258ms)
Dec  5 20:50:16.406: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/https:proxy-service-4lr2b:tlsportname1/proxy/: tls baz (200; 43.979488ms)
Dec  5 20:50:16.407: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/https:proxy-service-4lr2b:tlsportname2/proxy/: tls qux (200; 45.537638ms)
Dec  5 20:50:16.407: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/http:proxy-service-4lr2b:portname2/proxy/: bar (200; 45.635917ms)
Dec  5 20:50:16.408: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/http:proxy-service-4lr2b:portname1/proxy/: foo (200; 45.993969ms)
Dec  5 20:50:16.422: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:443/proxy/... (200; 14.326189ms)
Dec  5 20:50:16.423: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:162/proxy/: bar (200; 14.798862ms)
Dec  5 20:50:16.427: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:1080/proxy/rewri... (200; 19.328899ms)
Dec  5 20:50:16.428: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:460/proxy/: tls baz (200; 20.10391ms)
Dec  5 20:50:16.429: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:160/proxy/: foo (200; 21.073276ms)
Dec  5 20:50:16.429: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:1080/proxy/... (200; 21.387629ms)
Dec  5 20:50:16.435: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:160/proxy/: foo (200; 26.716031ms)
Dec  5 20:50:16.436: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v/proxy/rewriteme"... (200; 28.213262ms)
Dec  5 20:50:16.436: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/http:proxy-service-4lr2b:portname1/proxy/: foo (200; 28.322571ms)
Dec  5 20:50:16.436: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:462/proxy/: tls qux (200; 28.375274ms)
Dec  5 20:50:16.436: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:162/proxy/: bar (200; 28.443254ms)
Dec  5 20:50:16.436: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/https:proxy-service-4lr2b:tlsportname1/proxy/: tls baz (200; 28.598139ms)
Dec  5 20:50:16.438: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/proxy-service-4lr2b:portname2/proxy/: bar (200; 30.114452ms)
Dec  5 20:50:16.438: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/https:proxy-service-4lr2b:tlsportname2/proxy/: tls qux (200; 30.186052ms)
Dec  5 20:50:16.438: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/proxy-service-4lr2b:portname1/proxy/: foo (200; 30.262236ms)
Dec  5 20:50:16.439: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/http:proxy-service-4lr2b:portname2/proxy/: bar (200; 30.57595ms)
Dec  5 20:50:16.459: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:443/proxy/... (200; 20.283965ms)
Dec  5 20:50:16.460: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:160/proxy/: foo (200; 21.600042ms)
Dec  5 20:50:16.462: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:462/proxy/: tls qux (200; 23.180458ms)
Dec  5 20:50:16.462: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:1080/proxy/... (200; 23.189945ms)
Dec  5 20:50:16.462: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v/proxy/rewriteme"... (200; 23.609953ms)
Dec  5 20:50:16.465: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:160/proxy/: foo (200; 26.12284ms)
Dec  5 20:50:16.465: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:162/proxy/: bar (200; 26.580567ms)
Dec  5 20:50:16.465: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/http:proxy-service-4lr2b-rtt4v:162/proxy/: bar (200; 26.56739ms)
Dec  5 20:50:16.465: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/https:proxy-service-4lr2b:tlsportname1/proxy/: tls baz (200; 26.780827ms)
Dec  5 20:50:16.466: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/https:proxy-service-4lr2b-rtt4v:460/proxy/: tls baz (200; 26.706738ms)
Dec  5 20:50:16.466: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bp4p2/pods/proxy-service-4lr2b-rtt4v:1080/proxy/rewri... (200; 26.711096ms)
Dec  5 20:50:16.466: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/proxy-service-4lr2b:portname1/proxy/: foo (200; 27.540529ms)
Dec  5 20:50:16.469: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/http:proxy-service-4lr2b:portname1/proxy/: foo (200; 30.25491ms)
Dec  5 20:50:16.469: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/proxy-service-4lr2b:portname2/proxy/: bar (200; 30.049905ms)
Dec  5 20:50:16.470: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/http:proxy-service-4lr2b:portname2/proxy/: bar (200; 30.764752ms)
Dec  5 20:50:16.470: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bp4p2/services/https:proxy-service-4lr2b:tlsportname2/proxy/: tls qux (200; 30.857681ms)
STEP: deleting ReplicationController proxy-service-4lr2b in namespace e2e-tests-proxy-bp4p2, will wait for the garbage collector to delete the pods
Dec  5 20:50:16.530: INFO: Deleting ReplicationController proxy-service-4lr2b took: 7.003517ms
Dec  5 20:50:16.630: INFO: Terminating ReplicationController proxy-service-4lr2b pods took: 100.205501ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:50:19.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-bp4p2" for this suite.
Dec  5 20:50:25.145: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:50:25.161: INFO: namespace: e2e-tests-proxy-bp4p2, resource: bindings, ignored listing per whitelist
Dec  5 20:50:25.238: INFO: namespace e2e-tests-proxy-bp4p2 deletion completed in 6.104192642s

• [SLOW TEST:13.191 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:50:25.238: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Dec  5 20:50:25.327: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-p9hvp,SelfLink:/api/v1/namespaces/e2e-tests-watch-p9hvp/configmaps/e2e-watch-test-label-changed,UID:63ea72c7-f8cf-11e8-b622-12e7eb78a7a2,ResourceVersion:19762,Generation:0,CreationTimestamp:2018-12-05 20:50:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  5 20:50:25.327: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-p9hvp,SelfLink:/api/v1/namespaces/e2e-tests-watch-p9hvp/configmaps/e2e-watch-test-label-changed,UID:63ea72c7-f8cf-11e8-b622-12e7eb78a7a2,ResourceVersion:19763,Generation:0,CreationTimestamp:2018-12-05 20:50:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec  5 20:50:25.327: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-p9hvp,SelfLink:/api/v1/namespaces/e2e-tests-watch-p9hvp/configmaps/e2e-watch-test-label-changed,UID:63ea72c7-f8cf-11e8-b622-12e7eb78a7a2,ResourceVersion:19764,Generation:0,CreationTimestamp:2018-12-05 20:50:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Dec  5 20:50:35.356: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-p9hvp,SelfLink:/api/v1/namespaces/e2e-tests-watch-p9hvp/configmaps/e2e-watch-test-label-changed,UID:63ea72c7-f8cf-11e8-b622-12e7eb78a7a2,ResourceVersion:19782,Generation:0,CreationTimestamp:2018-12-05 20:50:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  5 20:50:35.356: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-p9hvp,SelfLink:/api/v1/namespaces/e2e-tests-watch-p9hvp/configmaps/e2e-watch-test-label-changed,UID:63ea72c7-f8cf-11e8-b622-12e7eb78a7a2,ResourceVersion:19783,Generation:0,CreationTimestamp:2018-12-05 20:50:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Dec  5 20:50:35.356: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-p9hvp,SelfLink:/api/v1/namespaces/e2e-tests-watch-p9hvp/configmaps/e2e-watch-test-label-changed,UID:63ea72c7-f8cf-11e8-b622-12e7eb78a7a2,ResourceVersion:19784,Generation:0,CreationTimestamp:2018-12-05 20:50:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:50:35.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-p9hvp" for this suite.
Dec  5 20:50:41.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:50:41.398: INFO: namespace: e2e-tests-watch-p9hvp, resource: bindings, ignored listing per whitelist
Dec  5 20:50:41.497: INFO: namespace e2e-tests-watch-p9hvp deletion completed in 6.137986726s

• [SLOW TEST:16.259 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:50:41.497: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 20:50:41.612: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6da20ce9-f8cf-11e8-b559-c27407a18179" in namespace "e2e-tests-downward-api-mjk7c" to be "success or failure"
Dec  5 20:50:41.617: INFO: Pod "downwardapi-volume-6da20ce9-f8cf-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 4.151534ms
Dec  5 20:50:43.620: INFO: Pod "downwardapi-volume-6da20ce9-f8cf-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007841294s
Dec  5 20:50:45.735: INFO: Pod "downwardapi-volume-6da20ce9-f8cf-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.122185097s
STEP: Saw pod success
Dec  5 20:50:45.735: INFO: Pod "downwardapi-volume-6da20ce9-f8cf-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 20:50:45.739: INFO: Trying to get logs from node ip-172-31-2-231 pod downwardapi-volume-6da20ce9-f8cf-11e8-b559-c27407a18179 container client-container: <nil>
STEP: delete the pod
Dec  5 20:50:45.764: INFO: Waiting for pod downwardapi-volume-6da20ce9-f8cf-11e8-b559-c27407a18179 to disappear
Dec  5 20:50:45.767: INFO: Pod downwardapi-volume-6da20ce9-f8cf-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:50:45.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-mjk7c" for this suite.
Dec  5 20:50:51.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:50:51.867: INFO: namespace: e2e-tests-downward-api-mjk7c, resource: bindings, ignored listing per whitelist
Dec  5 20:50:51.887: INFO: namespace e2e-tests-downward-api-mjk7c deletion completed in 6.115504515s

• [SLOW TEST:10.390 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:50:51.887: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-73cc4169-f8cf-11e8-b559-c27407a18179
STEP: Creating configMap with name cm-test-opt-upd-73cc41b2-f8cf-11e8-b559-c27407a18179
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-73cc4169-f8cf-11e8-b559-c27407a18179
STEP: Updating configmap cm-test-opt-upd-73cc41b2-f8cf-11e8-b559-c27407a18179
STEP: Creating configMap with name cm-test-opt-create-73cc41ca-f8cf-11e8-b559-c27407a18179
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:52:10.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-j2ds6" for this suite.
Dec  5 20:52:32.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:52:32.816: INFO: namespace: e2e-tests-projected-j2ds6, resource: bindings, ignored listing per whitelist
Dec  5 20:52:32.820: INFO: namespace e2e-tests-projected-j2ds6 deletion completed in 22.110618885s

• [SLOW TEST:100.933 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:52:32.821: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-aff552d0-f8cf-11e8-b559-c27407a18179
Dec  5 20:52:32.889: INFO: Pod name my-hostname-basic-aff552d0-f8cf-11e8-b559-c27407a18179: Found 0 pods out of 1
Dec  5 20:52:37.894: INFO: Pod name my-hostname-basic-aff552d0-f8cf-11e8-b559-c27407a18179: Found 1 pods out of 1
Dec  5 20:52:37.894: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-aff552d0-f8cf-11e8-b559-c27407a18179" are running
Dec  5 20:52:37.897: INFO: Pod "my-hostname-basic-aff552d0-f8cf-11e8-b559-c27407a18179-qv684" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-05 20:52:33 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-05 20:52:35 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-05 20:52:35 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-05 20:52:32 +0000 UTC Reason: Message:}])
Dec  5 20:52:37.897: INFO: Trying to dial the pod
Dec  5 20:52:42.909: INFO: Controller my-hostname-basic-aff552d0-f8cf-11e8-b559-c27407a18179: Got expected result from replica 1 [my-hostname-basic-aff552d0-f8cf-11e8-b559-c27407a18179-qv684]: "my-hostname-basic-aff552d0-f8cf-11e8-b559-c27407a18179-qv684", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:52:42.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-bjrgt" for this suite.
Dec  5 20:52:48.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:52:48.935: INFO: namespace: e2e-tests-replication-controller-bjrgt, resource: bindings, ignored listing per whitelist
Dec  5 20:52:49.013: INFO: namespace e2e-tests-replication-controller-bjrgt deletion completed in 6.101047247s

• [SLOW TEST:16.193 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:52:49.013: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-b99b6bff-f8cf-11e8-b559-c27407a18179
STEP: Creating a pod to test consume configMaps
Dec  5 20:52:49.079: INFO: Waiting up to 5m0s for pod "pod-configmaps-b99c0466-f8cf-11e8-b559-c27407a18179" in namespace "e2e-tests-configmap-gph8w" to be "success or failure"
Dec  5 20:52:49.082: INFO: Pod "pod-configmaps-b99c0466-f8cf-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.821022ms
Dec  5 20:52:51.085: INFO: Pod "pod-configmaps-b99c0466-f8cf-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006344666s
STEP: Saw pod success
Dec  5 20:52:51.085: INFO: Pod "pod-configmaps-b99c0466-f8cf-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 20:52:51.088: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-configmaps-b99c0466-f8cf-11e8-b559-c27407a18179 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 20:52:51.105: INFO: Waiting for pod pod-configmaps-b99c0466-f8cf-11e8-b559-c27407a18179 to disappear
Dec  5 20:52:51.107: INFO: Pod pod-configmaps-b99c0466-f8cf-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:52:51.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-gph8w" for this suite.
Dec  5 20:52:57.121: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:52:57.204: INFO: namespace: e2e-tests-configmap-gph8w, resource: bindings, ignored listing per whitelist
Dec  5 20:52:57.212: INFO: namespace e2e-tests-configmap-gph8w deletion completed in 6.10130252s

• [SLOW TEST:8.198 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:52:57.212: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 20:52:57.265: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:53:01.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-g2k8g" for this suite.
Dec  5 20:53:43.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:53:43.368: INFO: namespace: e2e-tests-pods-g2k8g, resource: bindings, ignored listing per whitelist
Dec  5 20:53:43.412: INFO: namespace e2e-tests-pods-g2k8g deletion completed in 42.103514542s

• [SLOW TEST:46.200 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:53:43.412: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 20:53:43.473: INFO: Creating deployment "nginx-deployment"
Dec  5 20:53:43.479: INFO: Waiting for observed generation 1
Dec  5 20:53:45.489: INFO: Waiting for all required pods to come up
Dec  5 20:53:45.493: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Dec  5 20:53:49.503: INFO: Waiting for deployment "nginx-deployment" to complete
Dec  5 20:53:49.509: INFO: Updating deployment "nginx-deployment" with a non-existent image
Dec  5 20:53:49.516: INFO: Updating deployment nginx-deployment
Dec  5 20:53:49.516: INFO: Waiting for observed generation 2
Dec  5 20:53:51.523: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Dec  5 20:53:51.526: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Dec  5 20:53:51.529: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Dec  5 20:53:51.537: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Dec  5 20:53:51.537: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Dec  5 20:53:51.539: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Dec  5 20:53:51.543: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Dec  5 20:53:51.543: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Dec  5 20:53:51.550: INFO: Updating deployment nginx-deployment
Dec  5 20:53:51.550: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Dec  5 20:53:51.556: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Dec  5 20:53:51.562: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  5 20:53:51.580: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-m9g8z,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-m9g8z/deployments/nginx-deployment,UID:da078272-f8cf-11e8-b622-12e7eb78a7a2,ResourceVersion:20461,Generation:3,CreationTimestamp:2018-12-05 20:53:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[{Progressing True 2018-12-05 20:53:49 +0000 UTC 2018-12-05 20:53:43 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.} {Available False 2018-12-05 20:53:51 +0000 UTC 2018-12-05 20:53:51 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Dec  5 20:53:51.594: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-m9g8z,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-m9g8z/replicasets/nginx-deployment-65bbdb5f8,UID:dda18095-f8cf-11e8-b622-12e7eb78a7a2,ResourceVersion:20456,Generation:3,CreationTimestamp:2018-12-05 20:53:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment da078272-f8cf-11e8-b622-12e7eb78a7a2 0xc001b634b7 0xc001b634b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  5 20:53:51.594: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Dec  5 20:53:51.594: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-m9g8z,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-m9g8z/replicasets/nginx-deployment-555b55d965,UID:da081f87-f8cf-11e8-b622-12e7eb78a7a2,ResourceVersion:20454,Generation:3,CreationTimestamp:2018-12-05 20:53:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment da078272-f8cf-11e8-b622-12e7eb78a7a2 0xc001b632f7 0xc001b632f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Dec  5 20:53:51.611: INFO: Pod "nginx-deployment-555b55d965-4hr2f" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-4hr2f,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-m9g8z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-m9g8z/pods/nginx-deployment-555b55d965-4hr2f,UID:ded8856a-f8cf-11e8-b622-12e7eb78a7a2,ResourceVersion:20458,Generation:0,CreationTimestamp:2018-12-05 20:53:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 da081f87-f8cf-11e8-b622-12e7eb78a7a2 0xc001be4b57 0xc001be4b58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-29wv6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-29wv6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-29wv6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-2-231,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001be4c40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001be4c60}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 20:53:51.611: INFO: Pod "nginx-deployment-555b55d965-4ktv4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-4ktv4,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-m9g8z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-m9g8z/pods/nginx-deployment-555b55d965-4ktv4,UID:dedad12f-f8cf-11e8-b622-12e7eb78a7a2,ResourceVersion:20478,Generation:0,CreationTimestamp:2018-12-05 20:53:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 da081f87-f8cf-11e8-b622-12e7eb78a7a2 0xc001be4cc0 0xc001be4cc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-29wv6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-29wv6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-29wv6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-66-194,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001be4d30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001be4d60}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 20:53:51.611: INFO: Pod "nginx-deployment-555b55d965-4tbg5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-4tbg5,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-m9g8z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-m9g8z/pods/nginx-deployment-555b55d965-4tbg5,UID:da0b8edd-f8cf-11e8-b622-12e7eb78a7a2,ResourceVersion:20362,Generation:0,CreationTimestamp:2018-12-05 20:53:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 da081f87-f8cf-11e8-b622-12e7eb78a7a2 0xc001be4e80 0xc001be4e81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-29wv6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-29wv6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-29wv6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-2-231,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001be4ef0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001be4f10}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:43 +0000 UTC  }],Message:,Reason:,HostIP:172.31.2.231,PodIP:10.1.94.67,StartTime:2018-12-05 20:53:43 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-05 20:53:45 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd docker://0cc1a6b060b391c83bb92fcd0f73c70f67e1cf2442a709c3e175ea9ce9de79c0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 20:53:51.612: INFO: Pod "nginx-deployment-555b55d965-69ksd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-69ksd,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-m9g8z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-m9g8z/pods/nginx-deployment-555b55d965-69ksd,UID:dedd451a-f8cf-11e8-b622-12e7eb78a7a2,ResourceVersion:20476,Generation:0,CreationTimestamp:2018-12-05 20:53:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 da081f87-f8cf-11e8-b622-12e7eb78a7a2 0xc001be50c0 0xc001be50c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-29wv6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-29wv6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-29wv6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001be5120} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001be5140}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 20:53:51.612: INFO: Pod "nginx-deployment-555b55d965-9mtxs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-9mtxs,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-m9g8z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-m9g8z/pods/nginx-deployment-555b55d965-9mtxs,UID:dedd73ed-f8cf-11e8-b622-12e7eb78a7a2,ResourceVersion:20481,Generation:0,CreationTimestamp:2018-12-05 20:53:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 da081f87-f8cf-11e8-b622-12e7eb78a7a2 0xc001be5190 0xc001be5191}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-29wv6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-29wv6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-29wv6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001be51f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001be5210}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 20:53:51.612: INFO: Pod "nginx-deployment-555b55d965-dgnq7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-dgnq7,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-m9g8z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-m9g8z/pods/nginx-deployment-555b55d965-dgnq7,UID:ded9594d-f8cf-11e8-b622-12e7eb78a7a2,ResourceVersion:20468,Generation:0,CreationTimestamp:2018-12-05 20:53:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 da081f87-f8cf-11e8-b622-12e7eb78a7a2 0xc001be52c0 0xc001be52c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-29wv6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-29wv6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-29wv6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-2-231,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001be53a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001be5400}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 20:53:51.612: INFO: Pod "nginx-deployment-555b55d965-gbgt9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-gbgt9,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-m9g8z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-m9g8z/pods/nginx-deployment-555b55d965-gbgt9,UID:dedb84cc-f8cf-11e8-b622-12e7eb78a7a2,ResourceVersion:20489,Generation:0,CreationTimestamp:2018-12-05 20:53:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 da081f87-f8cf-11e8-b622-12e7eb78a7a2 0xc001be5490 0xc001be5491}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-29wv6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-29wv6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-29wv6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-2-231,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001be5500} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001be5520}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 20:53:51.612: INFO: Pod "nginx-deployment-555b55d965-gzd2b" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-gzd2b,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-m9g8z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-m9g8z/pods/nginx-deployment-555b55d965-gzd2b,UID:da0b7bfd-f8cf-11e8-b622-12e7eb78a7a2,ResourceVersion:20369,Generation:0,CreationTimestamp:2018-12-05 20:53:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 da081f87-f8cf-11e8-b622-12e7eb78a7a2 0xc001be5580 0xc001be5581}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-29wv6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-29wv6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-29wv6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-24-193,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001be5600} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001be5620}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:47 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:47 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:43 +0000 UTC  }],Message:,Reason:,HostIP:172.31.24.193,PodIP:10.1.41.210,StartTime:2018-12-05 20:53:43 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-05 20:53:45 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd docker://192fa5c3e4dca02b13f8e4c638d1078854ded1af940250b067c39a7fb389beba}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 20:53:51.612: INFO: Pod "nginx-deployment-555b55d965-h7glb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-h7glb,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-m9g8z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-m9g8z/pods/nginx-deployment-555b55d965-h7glb,UID:dedddcd6-f8cf-11e8-b622-12e7eb78a7a2,ResourceVersion:20485,Generation:0,CreationTimestamp:2018-12-05 20:53:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 da081f87-f8cf-11e8-b622-12e7eb78a7a2 0xc001be56e0 0xc001be56e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-29wv6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-29wv6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-29wv6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001be5790} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001be57b0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 20:53:51.612: INFO: Pod "nginx-deployment-555b55d965-jqlqk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-jqlqk,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-m9g8z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-m9g8z/pods/nginx-deployment-555b55d965-jqlqk,UID:dedd76be-f8cf-11e8-b622-12e7eb78a7a2,ResourceVersion:20482,Generation:0,CreationTimestamp:2018-12-05 20:53:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 da081f87-f8cf-11e8-b622-12e7eb78a7a2 0xc001be5800 0xc001be5801}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-29wv6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-29wv6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-29wv6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001be5860} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001be5880}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 20:53:51.612: INFO: Pod "nginx-deployment-555b55d965-jqs4n" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-jqs4n,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-m9g8z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-m9g8z/pods/nginx-deployment-555b55d965-jqs4n,UID:da09921b-f8cf-11e8-b622-12e7eb78a7a2,ResourceVersion:20322,Generation:0,CreationTimestamp:2018-12-05 20:53:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 da081f87-f8cf-11e8-b622-12e7eb78a7a2 0xc001be58d0 0xc001be58d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-29wv6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-29wv6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-29wv6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-24-193,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001be59b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001be59d0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:44 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:44 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:43 +0000 UTC  }],Message:,Reason:,HostIP:172.31.24.193,PodIP:10.1.41.208,StartTime:2018-12-05 20:53:43 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-05 20:53:44 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd docker://aa7d18838650b01cd7674281d58859fbbf200d7a9a5a58761822afa722675ece}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 20:53:51.613: INFO: Pod "nginx-deployment-555b55d965-l2rh6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-l2rh6,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-m9g8z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-m9g8z/pods/nginx-deployment-555b55d965-l2rh6,UID:da0b7744-f8cf-11e8-b622-12e7eb78a7a2,ResourceVersion:20347,Generation:0,CreationTimestamp:2018-12-05 20:53:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 da081f87-f8cf-11e8-b622-12e7eb78a7a2 0xc001be5a80 0xc001be5a81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-29wv6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-29wv6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-29wv6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-66-194,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001be5af0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001be5b10}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:43 +0000 UTC  }],Message:,Reason:,HostIP:172.31.66.194,PodIP:10.1.43.40,StartTime:2018-12-05 20:53:43 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-05 20:53:45 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd docker://82388d350fc1f3b786986c7b637131dba6d6785c8b11829a5d7344548084066e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 20:53:51.613: INFO: Pod "nginx-deployment-555b55d965-lzqzg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-lzqzg,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-m9g8z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-m9g8z/pods/nginx-deployment-555b55d965-lzqzg,UID:da0b5391-f8cf-11e8-b622-12e7eb78a7a2,ResourceVersion:20343,Generation:0,CreationTimestamp:2018-12-05 20:53:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 da081f87-f8cf-11e8-b622-12e7eb78a7a2 0xc001be5bc0 0xc001be5bc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-29wv6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-29wv6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-29wv6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-24-193,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001be5c30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001be5c50}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:43 +0000 UTC  }],Message:,Reason:,HostIP:172.31.24.193,PodIP:10.1.41.209,StartTime:2018-12-05 20:53:43 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-05 20:53:44 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd docker://f2e246325680114a709e28eca643df8272adb4996ed071295a019170c441d655}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 20:53:51.613: INFO: Pod "nginx-deployment-555b55d965-prt5v" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-prt5v,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-m9g8z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-m9g8z/pods/nginx-deployment-555b55d965-prt5v,UID:da0a4089-f8cf-11e8-b622-12e7eb78a7a2,ResourceVersion:20359,Generation:0,CreationTimestamp:2018-12-05 20:53:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 da081f87-f8cf-11e8-b622-12e7eb78a7a2 0xc001be5d60 0xc001be5d61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-29wv6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-29wv6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-29wv6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-2-231,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001be5dd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001be5df0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:43 +0000 UTC  }],Message:,Reason:,HostIP:172.31.2.231,PodIP:10.1.94.66,StartTime:2018-12-05 20:53:43 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-05 20:53:45 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd docker://8ba85303c79f5d4b9fcd38c47c66931b7bf3bce5e1decab366bd6397be09a5d8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 20:53:51.613: INFO: Pod "nginx-deployment-555b55d965-s79l7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-s79l7,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-m9g8z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-m9g8z/pods/nginx-deployment-555b55d965-s79l7,UID:dedb6862-f8cf-11e8-b622-12e7eb78a7a2,ResourceVersion:20488,Generation:0,CreationTimestamp:2018-12-05 20:53:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 da081f87-f8cf-11e8-b622-12e7eb78a7a2 0xc001be5ea0 0xc001be5ea1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-29wv6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-29wv6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-29wv6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-24-193,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001be5f10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001be5f30}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 20:53:51.613: INFO: Pod "nginx-deployment-555b55d965-t7q8v" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-t7q8v,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-m9g8z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-m9g8z/pods/nginx-deployment-555b55d965-t7q8v,UID:da10727d-f8cf-11e8-b622-12e7eb78a7a2,ResourceVersion:20350,Generation:0,CreationTimestamp:2018-12-05 20:53:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 da081f87-f8cf-11e8-b622-12e7eb78a7a2 0xc001be5f90 0xc001be5f91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-29wv6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-29wv6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-29wv6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-66-194,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c2c000} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c2c020}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:43 +0000 UTC  }],Message:,Reason:,HostIP:172.31.66.194,PodIP:10.1.43.42,StartTime:2018-12-05 20:53:43 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-05 20:53:45 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd docker://bb3fe0a7f91dbee34e260d251ada3b3b122486e8265cef933ff55f55dd2c0f06}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 20:53:51.613: INFO: Pod "nginx-deployment-555b55d965-tzxg2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-tzxg2,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-m9g8z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-m9g8z/pods/nginx-deployment-555b55d965-tzxg2,UID:deda8528-f8cf-11e8-b622-12e7eb78a7a2,ResourceVersion:20486,Generation:0,CreationTimestamp:2018-12-05 20:53:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 da081f87-f8cf-11e8-b622-12e7eb78a7a2 0xc001c2c0d0 0xc001c2c0d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-29wv6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-29wv6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-29wv6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-66-194,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c2c1d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c2c200}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 20:53:51.613: INFO: Pod "nginx-deployment-555b55d965-vrk8m" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-vrk8m,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-m9g8z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-m9g8z/pods/nginx-deployment-555b55d965-vrk8m,UID:ded93560-f8cf-11e8-b622-12e7eb78a7a2,ResourceVersion:20473,Generation:0,CreationTimestamp:2018-12-05 20:53:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 da081f87-f8cf-11e8-b622-12e7eb78a7a2 0xc001c2c390 0xc001c2c391}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-29wv6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-29wv6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-29wv6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-24-193,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c2c470} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c2c490}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 20:53:51.614: INFO: Pod "nginx-deployment-555b55d965-x64cj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-x64cj,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-m9g8z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-m9g8z/pods/nginx-deployment-555b55d965-x64cj,UID:dedcee45-f8cf-11e8-b622-12e7eb78a7a2,ResourceVersion:20475,Generation:0,CreationTimestamp:2018-12-05 20:53:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 da081f87-f8cf-11e8-b622-12e7eb78a7a2 0xc001c2c4f0 0xc001c2c4f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-29wv6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-29wv6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-29wv6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c2c690} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c2c6b0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 20:53:51.614: INFO: Pod "nginx-deployment-555b55d965-zwc82" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-zwc82,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-m9g8z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-m9g8z/pods/nginx-deployment-555b55d965-zwc82,UID:da0a5ef7-f8cf-11e8-b622-12e7eb78a7a2,ResourceVersion:20328,Generation:0,CreationTimestamp:2018-12-05 20:53:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 da081f87-f8cf-11e8-b622-12e7eb78a7a2 0xc001c2c700 0xc001c2c701}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-29wv6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-29wv6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-29wv6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-66-194,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c2c770} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c2c790}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:43 +0000 UTC  }],Message:,Reason:,HostIP:172.31.66.194,PodIP:10.1.43.39,StartTime:2018-12-05 20:53:43 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-05 20:53:44 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd docker://f901ccc4c87c330cbf02158412b955864a5878ab2c55680ae9e829c9da775478}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 20:53:51.614: INFO: Pod "nginx-deployment-65bbdb5f8-4thwn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-4thwn,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-m9g8z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-m9g8z/pods/nginx-deployment-65bbdb5f8-4thwn,UID:dedd858c-f8cf-11e8-b622-12e7eb78a7a2,ResourceVersion:20483,Generation:0,CreationTimestamp:2018-12-05 20:53:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 dda18095-f8cf-11e8-b622-12e7eb78a7a2 0xc001c2c960 0xc001c2c961}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-29wv6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-29wv6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-29wv6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c2c9d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c2c9f0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 20:53:51.614: INFO: Pod "nginx-deployment-65bbdb5f8-5brtp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-5brtp,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-m9g8z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-m9g8z/pods/nginx-deployment-65bbdb5f8-5brtp,UID:dedd8743-f8cf-11e8-b622-12e7eb78a7a2,ResourceVersion:20479,Generation:0,CreationTimestamp:2018-12-05 20:53:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 dda18095-f8cf-11e8-b622-12e7eb78a7a2 0xc001c2ca40 0xc001c2ca41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-29wv6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-29wv6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-29wv6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c2cab0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c2cad0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 20:53:51.614: INFO: Pod "nginx-deployment-65bbdb5f8-66wc5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-66wc5,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-m9g8z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-m9g8z/pods/nginx-deployment-65bbdb5f8-66wc5,UID:ddab1568-f8cf-11e8-b622-12e7eb78a7a2,ResourceVersion:20423,Generation:0,CreationTimestamp:2018-12-05 20:53:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 dda18095-f8cf-11e8-b622-12e7eb78a7a2 0xc001c2cb20 0xc001c2cb21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-29wv6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-29wv6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-29wv6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-24-193,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c2cba0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c2cbc0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:49 +0000 UTC  }],Message:,Reason:,HostIP:172.31.24.193,PodIP:,StartTime:2018-12-05 20:53:49 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 20:53:51.614: INFO: Pod "nginx-deployment-65bbdb5f8-8b597" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-8b597,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-m9g8z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-m9g8z/pods/nginx-deployment-65bbdb5f8-8b597,UID:dedd59f7-f8cf-11e8-b622-12e7eb78a7a2,ResourceVersion:20477,Generation:0,CreationTimestamp:2018-12-05 20:53:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 dda18095-f8cf-11e8-b622-12e7eb78a7a2 0xc001c2cc70 0xc001c2cc71}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-29wv6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-29wv6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-29wv6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c2cce0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c2cd00}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 20:53:51.614: INFO: Pod "nginx-deployment-65bbdb5f8-8clw8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-8clw8,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-m9g8z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-m9g8z/pods/nginx-deployment-65bbdb5f8-8clw8,UID:ded9df8d-f8cf-11e8-b622-12e7eb78a7a2,ResourceVersion:20474,Generation:0,CreationTimestamp:2018-12-05 20:53:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 dda18095-f8cf-11e8-b622-12e7eb78a7a2 0xc001c2cd50 0xc001c2cd51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-29wv6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-29wv6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-29wv6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-2-231,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c2cde0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c2ce00}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 20:53:51.614: INFO: Pod "nginx-deployment-65bbdb5f8-99c67" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-99c67,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-m9g8z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-m9g8z/pods/nginx-deployment-65bbdb5f8-99c67,UID:dedbce67-f8cf-11e8-b622-12e7eb78a7a2,ResourceVersion:20490,Generation:0,CreationTimestamp:2018-12-05 20:53:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 dda18095-f8cf-11e8-b622-12e7eb78a7a2 0xc001c2ce60 0xc001c2ce61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-29wv6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-29wv6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-29wv6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-24-193,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c2cee0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c2cf00}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 20:53:51.615: INFO: Pod "nginx-deployment-65bbdb5f8-9l9zk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-9l9zk,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-m9g8z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-m9g8z/pods/nginx-deployment-65bbdb5f8-9l9zk,UID:dda21b71-f8cf-11e8-b622-12e7eb78a7a2,ResourceVersion:20439,Generation:0,CreationTimestamp:2018-12-05 20:53:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 dda18095-f8cf-11e8-b622-12e7eb78a7a2 0xc001c2cf60 0xc001c2cf61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-29wv6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-29wv6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-29wv6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-24-193,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c2cfe0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c2d000}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:49 +0000 UTC  }],Message:,Reason:,HostIP:172.31.24.193,PodIP:10.1.41.211,StartTime:2018-12-05 20:53:49 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 20:53:51.615: INFO: Pod "nginx-deployment-65bbdb5f8-pfj7p" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-pfj7p,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-m9g8z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-m9g8z/pods/nginx-deployment-65bbdb5f8-pfj7p,UID:dedd6ffd-f8cf-11e8-b622-12e7eb78a7a2,ResourceVersion:20480,Generation:0,CreationTimestamp:2018-12-05 20:53:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 dda18095-f8cf-11e8-b622-12e7eb78a7a2 0xc001c2d0d0 0xc001c2d0d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-29wv6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-29wv6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-29wv6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c2d140} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c2d160}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 20:53:51.615: INFO: Pod "nginx-deployment-65bbdb5f8-plz9d" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-plz9d,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-m9g8z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-m9g8z/pods/nginx-deployment-65bbdb5f8-plz9d,UID:dda30e55-f8cf-11e8-b622-12e7eb78a7a2,ResourceVersion:20415,Generation:0,CreationTimestamp:2018-12-05 20:53:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 dda18095-f8cf-11e8-b622-12e7eb78a7a2 0xc001c2d1b0 0xc001c2d1b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-29wv6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-29wv6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-29wv6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-66-194,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c2d230} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c2d250}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:49 +0000 UTC  }],Message:,Reason:,HostIP:172.31.66.194,PodIP:,StartTime:2018-12-05 20:53:49 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 20:53:51.615: INFO: Pod "nginx-deployment-65bbdb5f8-ptpj5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-ptpj5,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-m9g8z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-m9g8z/pods/nginx-deployment-65bbdb5f8-ptpj5,UID:dda2d833-f8cf-11e8-b622-12e7eb78a7a2,ResourceVersion:20430,Generation:0,CreationTimestamp:2018-12-05 20:53:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 dda18095-f8cf-11e8-b622-12e7eb78a7a2 0xc001c2d300 0xc001c2d301}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-29wv6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-29wv6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-29wv6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-2-231,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c2d380} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c2d3a0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:49 +0000 UTC  }],Message:,Reason:,HostIP:172.31.2.231,PodIP:,StartTime:2018-12-05 20:53:49 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 20:53:51.615: INFO: Pod "nginx-deployment-65bbdb5f8-xg2qc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-xg2qc,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-m9g8z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-m9g8z/pods/nginx-deployment-65bbdb5f8-xg2qc,UID:dedba699-f8cf-11e8-b622-12e7eb78a7a2,ResourceVersion:20487,Generation:0,CreationTimestamp:2018-12-05 20:53:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 dda18095-f8cf-11e8-b622-12e7eb78a7a2 0xc001c2d450 0xc001c2d451}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-29wv6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-29wv6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-29wv6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-66-194,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c2d4d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c2d4f0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  5 20:53:51.615: INFO: Pod "nginx-deployment-65bbdb5f8-xn9j6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-xn9j6,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-m9g8z,SelfLink:/api/v1/namespaces/e2e-tests-deployment-m9g8z/pods/nginx-deployment-65bbdb5f8-xn9j6,UID:ddac2369-f8cf-11e8-b622-12e7eb78a7a2,ResourceVersion:20426,Generation:0,CreationTimestamp:2018-12-05 20:53:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 dda18095-f8cf-11e8-b622-12e7eb78a7a2 0xc001c2dd20 0xc001c2dd21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-29wv6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-29wv6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-29wv6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-66-194,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c2dda0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c2ddc0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:49 +0000 UTC  }],Message:,Reason:,HostIP:172.31.66.194,PodIP:,StartTime:2018-12-05 20:53:49 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 20:53:51.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-m9g8z" for this suite.
Dec  5 20:53:57.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 20:53:57.702: INFO: namespace: e2e-tests-deployment-m9g8z, resource: bindings, ignored listing per whitelist
Dec  5 20:53:57.760: INFO: namespace e2e-tests-deployment-m9g8z deletion completed in 6.124288984s

• [SLOW TEST:14.348 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 20:53:57.760: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-vb7xd
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-vb7xd
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-vb7xd
Dec  5 20:53:57.830: INFO: Found 0 stateful pods, waiting for 1
Dec  5 20:54:07.834: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Dec  5 20:54:07.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  5 20:54:08.248: INFO: stderr: ""
Dec  5 20:54:08.248: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  5 20:54:08.248: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  5 20:54:08.252: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec  5 20:54:18.256: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  5 20:54:18.256: INFO: Waiting for statefulset status.replicas updated to 0
Dec  5 20:54:18.277: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Dec  5 20:54:18.277: INFO: ss-0  ip-172-31-24-193  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:57 +0000 UTC  }]
Dec  5 20:54:18.277: INFO: 
Dec  5 20:54:18.277: INFO: StatefulSet ss has not reached scale 3, at 1
Dec  5 20:54:19.281: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.989202379s
Dec  5 20:54:20.285: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.985152639s
Dec  5 20:54:21.289: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.981218675s
Dec  5 20:54:22.293: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.977218832s
Dec  5 20:54:23.298: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.972854032s
Dec  5 20:54:24.302: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.968546941s
Dec  5 20:54:25.305: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.964590479s
Dec  5 20:54:26.309: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.961105705s
Dec  5 20:54:27.314: INFO: Verifying statefulset ss doesn't scale past 3 for another 956.776392ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-vb7xd
Dec  5 20:54:28.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 20:54:28.474: INFO: stderr: ""
Dec  5 20:54:28.474: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  5 20:54:28.474: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  5 20:54:28.475: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 20:54:28.638: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Dec  5 20:54:28.638: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  5 20:54:28.638: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  5 20:54:28.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 20:54:28.808: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Dec  5 20:54:28.808: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  5 20:54:28.808: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  5 20:54:28.811: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Dec  5 20:54:38.816: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 20:54:38.816: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 20:54:38.816: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Dec  5 20:54:38.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  5 20:54:38.987: INFO: stderr: ""
Dec  5 20:54:38.987: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  5 20:54:38.987: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  5 20:54:38.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  5 20:54:39.252: INFO: stderr: ""
Dec  5 20:54:39.252: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  5 20:54:39.252: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  5 20:54:39.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  5 20:54:39.490: INFO: stderr: ""
Dec  5 20:54:39.490: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  5 20:54:39.490: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  5 20:54:39.490: INFO: Waiting for statefulset status.replicas updated to 0
Dec  5 20:54:39.492: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Dec  5 20:54:49.500: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  5 20:54:49.500: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec  5 20:54:49.500: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec  5 20:54:49.512: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Dec  5 20:54:49.512: INFO: ss-0  ip-172-31-24-193  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:57 +0000 UTC  }]
Dec  5 20:54:49.512: INFO: ss-1  ip-172-31-66-194  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:18 +0000 UTC  }]
Dec  5 20:54:49.512: INFO: ss-2  ip-172-31-2-231   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:18 +0000 UTC  }]
Dec  5 20:54:49.512: INFO: 
Dec  5 20:54:49.512: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  5 20:54:50.518: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Dec  5 20:54:50.518: INFO: ss-0  ip-172-31-24-193  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:57 +0000 UTC  }]
Dec  5 20:54:50.518: INFO: ss-1  ip-172-31-66-194  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:18 +0000 UTC  }]
Dec  5 20:54:50.518: INFO: ss-2  ip-172-31-2-231   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:18 +0000 UTC  }]
Dec  5 20:54:50.518: INFO: 
Dec  5 20:54:50.518: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  5 20:54:51.522: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Dec  5 20:54:51.522: INFO: ss-0  ip-172-31-24-193  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:57 +0000 UTC  }]
Dec  5 20:54:51.522: INFO: ss-1  ip-172-31-66-194  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:18 +0000 UTC  }]
Dec  5 20:54:51.522: INFO: ss-2  ip-172-31-2-231   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:18 +0000 UTC  }]
Dec  5 20:54:51.522: INFO: 
Dec  5 20:54:51.522: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  5 20:54:52.527: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Dec  5 20:54:52.527: INFO: ss-0  ip-172-31-24-193  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:57 +0000 UTC  }]
Dec  5 20:54:52.528: INFO: ss-1  ip-172-31-66-194  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:18 +0000 UTC  }]
Dec  5 20:54:52.528: INFO: ss-2  ip-172-31-2-231   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:18 +0000 UTC  }]
Dec  5 20:54:52.528: INFO: 
Dec  5 20:54:52.528: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  5 20:54:53.531: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Dec  5 20:54:53.531: INFO: ss-0  ip-172-31-24-193  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:57 +0000 UTC  }]
Dec  5 20:54:53.531: INFO: ss-1  ip-172-31-66-194  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:18 +0000 UTC  }]
Dec  5 20:54:53.532: INFO: ss-2  ip-172-31-2-231   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:18 +0000 UTC  }]
Dec  5 20:54:53.532: INFO: 
Dec  5 20:54:53.532: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  5 20:54:54.535: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Dec  5 20:54:54.535: INFO: ss-0  ip-172-31-24-193  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:57 +0000 UTC  }]
Dec  5 20:54:54.535: INFO: ss-1  ip-172-31-66-194  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:18 +0000 UTC  }]
Dec  5 20:54:54.535: INFO: ss-2  ip-172-31-2-231   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:18 +0000 UTC  }]
Dec  5 20:54:54.535: INFO: 
Dec  5 20:54:54.535: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  5 20:54:55.539: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Dec  5 20:54:55.539: INFO: ss-0  ip-172-31-24-193  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:57 +0000 UTC  }]
Dec  5 20:54:55.539: INFO: ss-1  ip-172-31-66-194  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:18 +0000 UTC  }]
Dec  5 20:54:55.539: INFO: ss-2  ip-172-31-2-231   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:18 +0000 UTC  }]
Dec  5 20:54:55.539: INFO: 
Dec  5 20:54:55.539: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  5 20:54:56.543: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Dec  5 20:54:56.543: INFO: ss-0  ip-172-31-24-193  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:57 +0000 UTC  }]
Dec  5 20:54:56.543: INFO: ss-1  ip-172-31-66-194  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:18 +0000 UTC  }]
Dec  5 20:54:56.543: INFO: ss-2  ip-172-31-2-231   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:18 +0000 UTC  }]
Dec  5 20:54:56.543: INFO: 
Dec  5 20:54:56.543: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  5 20:54:57.547: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Dec  5 20:54:57.547: INFO: ss-0  ip-172-31-24-193  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:57 +0000 UTC  }]
Dec  5 20:54:57.547: INFO: ss-1  ip-172-31-66-194  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:18 +0000 UTC  }]
Dec  5 20:54:57.547: INFO: ss-2  ip-172-31-2-231   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:18 +0000 UTC  }]
Dec  5 20:54:57.547: INFO: 
Dec  5 20:54:57.547: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  5 20:54:58.551: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Dec  5 20:54:58.551: INFO: ss-0  ip-172-31-24-193  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:53:57 +0000 UTC  }]
Dec  5 20:54:58.551: INFO: ss-1  ip-172-31-66-194  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:18 +0000 UTC  }]
Dec  5 20:54:58.551: INFO: ss-2  ip-172-31-2-231   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 20:54:18 +0000 UTC  }]
Dec  5 20:54:58.551: INFO: 
Dec  5 20:54:58.551: INFO: StatefulSet ss has not reached scale 0, at 3
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-vb7xd
Dec  5 20:54:59.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 20:54:59.649: INFO: rc: 1
Dec  5 20:54:59.649: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc001d8b8f0 exit status 1 <nil> <nil> true [0xc000ae04a0 0xc000ae04b8 0xc000ae04d0] [0xc000ae04a0 0xc000ae04b8 0xc000ae04d0] [0xc000ae04b0 0xc000ae04c8] [0x92f8e0 0x92f8e0] 0xc00195b980 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Dec  5 20:55:09.649: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 20:55:09.705: INFO: rc: 1
Dec  5 20:55:09.705: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001d8bc80 exit status 1 <nil> <nil> true [0xc000ae04d8 0xc000ae04f0 0xc000ae0508] [0xc000ae04d8 0xc000ae04f0 0xc000ae0508] [0xc000ae04e8 0xc000ae0500] [0x92f8e0 0x92f8e0] 0xc001454120 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 20:55:19.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 20:55:19.805: INFO: rc: 1
Dec  5 20:55:19.805: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0014b8c30 exit status 1 <nil> <nil> true [0xc000fd5460 0xc000fd5478 0xc000fd5490] [0xc000fd5460 0xc000fd5478 0xc000fd5490] [0xc000fd5470 0xc000fd5488] [0x92f8e0 0x92f8e0] 0xc00170e4e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 20:55:29.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 20:55:29.910: INFO: rc: 1
Dec  5 20:55:29.910: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0005ded80 exit status 1 <nil> <nil> true [0xc0012c1088 0xc0012c10f8 0xc0012c11b8] [0xc0012c1088 0xc0012c10f8 0xc0012c11b8] [0xc0012c10e8 0xc0012c1170] [0x92f8e0 0x92f8e0] 0xc0016c2420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 20:55:39.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 20:55:40.031: INFO: rc: 1
Dec  5 20:55:40.031: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0027a3ce0 exit status 1 <nil> <nil> true [0xc000ae0510 0xc0018a9ac0 0xc0018a9ad8] [0xc000ae0510 0xc0018a9ac0 0xc0018a9ad8] [0xc0018a9ab8 0xc0018a9ad0] [0x92f8e0 0x92f8e0] 0xc0009b8780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 20:55:50.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 20:55:50.094: INFO: rc: 1
Dec  5 20:55:50.094: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0017d0540 exit status 1 <nil> <nil> true [0xc0000ca040 0xc00000e488 0xc00000e548] [0xc0000ca040 0xc00000e488 0xc00000e548] [0xc00000e3d8 0xc00000e4e8] [0x92f8e0 0x92f8e0] 0xc00260c480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 20:56:00.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 20:56:00.161: INFO: rc: 1
Dec  5 20:56:00.161: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0017d08d0 exit status 1 <nil> <nil> true [0xc00000e5a8 0xc00000e6a8 0xc00000e7c8] [0xc00000e5a8 0xc00000e6a8 0xc00000e7c8] [0xc00000e668 0xc00000e738] [0x92f8e0 0x92f8e0] 0xc00260c9c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 20:56:10.161: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 20:56:10.227: INFO: rc: 1
Dec  5 20:56:10.227: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0017d0cc0 exit status 1 <nil> <nil> true [0xc00000e8c8 0xc00000ea10 0xc00000eb78] [0xc00000e8c8 0xc00000ea10 0xc00000eb78] [0xc00000e980 0xc00000eaa8] [0x92f8e0 0x92f8e0] 0xc00260d080 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 20:56:20.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 20:56:20.286: INFO: rc: 1
Dec  5 20:56:20.286: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001f96390 exit status 1 <nil> <nil> true [0xc00017d3d0 0xc00017d540 0xc00017d5c8] [0xc00017d3d0 0xc00017d540 0xc00017d5c8] [0xc00017d530 0xc00017d590] [0x92f8e0 0x92f8e0] 0xc0024dc2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 20:56:30.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 20:56:30.350: INFO: rc: 1
Dec  5 20:56:30.350: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0018d03c0 exit status 1 <nil> <nil> true [0xc000fd4000 0xc000fd4050 0xc000fd40c0] [0xc000fd4000 0xc000fd4050 0xc000fd40c0] [0xc000fd4038 0xc000fd40a8] [0x92f8e0 0x92f8e0] 0xc00204e2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 20:56:40.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 20:56:40.447: INFO: rc: 1
Dec  5 20:56:40.447: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0018d0750 exit status 1 <nil> <nil> true [0xc000fd40d0 0xc000fd4110 0xc000fd4158] [0xc000fd40d0 0xc000fd4110 0xc000fd4158] [0xc000fd4108 0xc000fd4148] [0x92f8e0 0x92f8e0] 0xc00204e5a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 20:56:50.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 20:56:50.512: INFO: rc: 1
Dec  5 20:56:50.512: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001aa84b0 exit status 1 <nil> <nil> true [0xc000300180 0xc0003009c0 0xc000300a48] [0xc000300180 0xc0003009c0 0xc000300a48] [0xc000300528 0xc000300a10] [0x92f8e0 0x92f8e0] 0xc00217c2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 20:57:00.512: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 20:57:00.594: INFO: rc: 1
Dec  5 20:57:00.594: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001aa8930 exit status 1 <nil> <nil> true [0xc000300b30 0xc000300d78 0xc000300e00] [0xc000300b30 0xc000300d78 0xc000300e00] [0xc000300d18 0xc000300dd0] [0x92f8e0 0x92f8e0] 0xc00217c5a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 20:57:10.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 20:57:10.664: INFO: rc: 1
Dec  5 20:57:10.664: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001aa8cf0 exit status 1 <nil> <nil> true [0xc000300e58 0xc000301140 0xc0003013c8] [0xc000300e58 0xc000301140 0xc0003013c8] [0xc000301030 0xc000301330] [0x92f8e0 0x92f8e0] 0xc00217c900 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 20:57:20.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 20:57:20.729: INFO: rc: 1
Dec  5 20:57:20.729: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001f969c0 exit status 1 <nil> <nil> true [0xc00017d5e0 0xc00017d738 0xc00017da28] [0xc00017d5e0 0xc00017d738 0xc00017da28] [0xc00017d6a8 0xc00017d9e8] [0x92f8e0 0x92f8e0] 0xc0024dc840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 20:57:30.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 20:57:30.795: INFO: rc: 1
Dec  5 20:57:30.795: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001f96e40 exit status 1 <nil> <nil> true [0xc00017da78 0xc00017dad8 0xc00017db48] [0xc00017da78 0xc00017dad8 0xc00017db48] [0xc00017dab8 0xc00017db30] [0x92f8e0 0x92f8e0] 0xc0024dcea0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 20:57:40.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 20:57:40.858: INFO: rc: 1
Dec  5 20:57:40.858: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001f97230 exit status 1 <nil> <nil> true [0xc00017db68 0xc00017dc08 0xc00017dc58] [0xc00017db68 0xc00017dc08 0xc00017dc58] [0xc00017dbd8 0xc00017dc38] [0x92f8e0 0x92f8e0] 0xc0024dd920 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 20:57:50.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 20:57:50.931: INFO: rc: 1
Dec  5 20:57:50.931: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0018d0390 exit status 1 <nil> <nil> true [0xc0000ca040 0xc00000e488 0xc00000e548] [0xc0000ca040 0xc00000e488 0xc00000e548] [0xc00000e3d8 0xc00000e4e8] [0x92f8e0 0x92f8e0] 0xc00260c480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 20:58:00.931: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 20:58:00.992: INFO: rc: 1
Dec  5 20:58:00.992: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001f963c0 exit status 1 <nil> <nil> true [0xc000fd4000 0xc000fd4050 0xc000fd40c0] [0xc000fd4000 0xc000fd4050 0xc000fd40c0] [0xc000fd4038 0xc000fd40a8] [0x92f8e0 0x92f8e0] 0xc00204e2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 20:58:10.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 20:58:11.056: INFO: rc: 1
Dec  5 20:58:11.056: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001aa8480 exit status 1 <nil> <nil> true [0xc00017d3d0 0xc00017d540 0xc00017d5c8] [0xc00017d3d0 0xc00017d540 0xc00017d5c8] [0xc00017d530 0xc00017d590] [0x92f8e0 0x92f8e0] 0xc0024dc2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 20:58:21.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 20:58:21.126: INFO: rc: 1
Dec  5 20:58:21.126: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0018d07e0 exit status 1 <nil> <nil> true [0xc00000e5a8 0xc00000e6a8 0xc00000e7c8] [0xc00000e5a8 0xc00000e6a8 0xc00000e7c8] [0xc00000e668 0xc00000e738] [0x92f8e0 0x92f8e0] 0xc00260c9c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 20:58:31.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 20:58:31.197: INFO: rc: 1
Dec  5 20:58:31.197: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0017d05a0 exit status 1 <nil> <nil> true [0xc0003000f0 0xc000300528 0xc000300a10] [0xc0003000f0 0xc000300528 0xc000300a10] [0xc000300410 0xc0003009f8] [0x92f8e0 0x92f8e0] 0xc00217c2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 20:58:41.197: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 20:58:41.274: INFO: rc: 1
Dec  5 20:58:41.274: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001aa8960 exit status 1 <nil> <nil> true [0xc00017d5e0 0xc00017d738 0xc00017da28] [0xc00017d5e0 0xc00017d738 0xc00017da28] [0xc00017d6a8 0xc00017d9e8] [0x92f8e0 0x92f8e0] 0xc0024dc780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 20:58:51.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 20:58:51.349: INFO: rc: 1
Dec  5 20:58:51.349: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0018d0c90 exit status 1 <nil> <nil> true [0xc00000e8c8 0xc00000ea10 0xc00000eb78] [0xc00000e8c8 0xc00000ea10 0xc00000eb78] [0xc00000e980 0xc00000eaa8] [0x92f8e0 0x92f8e0] 0xc00260cfc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 20:59:01.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 20:59:01.412: INFO: rc: 1
Dec  5 20:59:01.412: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001aa8db0 exit status 1 <nil> <nil> true [0xc00017da78 0xc00017dad8 0xc00017db48] [0xc00017da78 0xc00017dad8 0xc00017db48] [0xc00017dab8 0xc00017db30] [0x92f8e0 0x92f8e0] 0xc0024dcd80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 20:59:11.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 20:59:11.489: INFO: rc: 1
Dec  5 20:59:11.489: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001aa9140 exit status 1 <nil> <nil> true [0xc00017dc88 0xc00017dca0 0xc00017dd20] [0xc00017dc88 0xc00017dca0 0xc00017dd20] [0xc00017dc98 0xc00017dcf8] [0x92f8e0 0x92f8e0] 0xc001d060c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 20:59:21.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 20:59:21.672: INFO: rc: 1
Dec  5 20:59:21.672: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0017d09c0 exit status 1 <nil> <nil> true [0xc000300a48 0xc000300d18 0xc000300dd0] [0xc000300a48 0xc000300d18 0xc000300dd0] [0xc000300b88 0xc000300dc0] [0x92f8e0 0x92f8e0] 0xc00217c5a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 20:59:31.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 20:59:31.737: INFO: rc: 1
Dec  5 20:59:31.737: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0017d0de0 exit status 1 <nil> <nil> true [0xc000300e00 0xc000301030 0xc000301330] [0xc000300e00 0xc000301030 0xc000301330] [0xc000300fd0 0xc000301170] [0x92f8e0 0x92f8e0] 0xc00217c900 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 20:59:41.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 20:59:41.807: INFO: rc: 1
Dec  5 20:59:41.807: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001f96390 exit status 1 <nil> <nil> true [0xc000fd4000 0xc000fd4050 0xc000fd40c0] [0xc000fd4000 0xc000fd4050 0xc000fd40c0] [0xc000fd4038 0xc000fd40a8] [0x92f8e0 0x92f8e0] 0xc0024dc2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 20:59:51.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 20:59:51.873: INFO: rc: 1
Dec  5 20:59:51.873: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001aa84b0 exit status 1 <nil> <nil> true [0xc00017d3d0 0xc00017d540 0xc00017d5c8] [0xc00017d3d0 0xc00017d540 0xc00017d5c8] [0xc00017d530 0xc00017d590] [0x92f8e0 0x92f8e0] 0xc00204e2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  5 21:00:01.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-100404934 exec --namespace=e2e-tests-statefulset-vb7xd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  5 21:00:01.996: INFO: rc: 1
Dec  5 21:00:01.997: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: 
Dec  5 21:00:01.997: INFO: Scaling statefulset ss to 0
Dec  5 21:00:02.014: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  5 21:00:02.021: INFO: Deleting all statefulset in ns e2e-tests-statefulset-vb7xd
Dec  5 21:00:02.034: INFO: Scaling statefulset ss to 0
Dec  5 21:00:02.051: INFO: Waiting for statefulset status.replicas updated to 0
Dec  5 21:00:02.057: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 21:00:02.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-vb7xd" for this suite.
Dec  5 21:00:08.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:00:08.202: INFO: namespace: e2e-tests-statefulset-vb7xd, resource: bindings, ignored listing per whitelist
Dec  5 21:00:08.233: INFO: namespace e2e-tests-statefulset-vb7xd deletion completed in 6.149293241s

• [SLOW TEST:370.474 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 21:00:08.234: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-bf686a2b-f8d0-11e8-b559-c27407a18179
STEP: Creating a pod to test consume configMaps
Dec  5 21:00:08.309: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-bf69414e-f8d0-11e8-b559-c27407a18179" in namespace "e2e-tests-projected-cskq6" to be "success or failure"
Dec  5 21:00:08.312: INFO: Pod "pod-projected-configmaps-bf69414e-f8d0-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.818785ms
Dec  5 21:00:10.316: INFO: Pod "pod-projected-configmaps-bf69414e-f8d0-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006572187s
Dec  5 21:00:12.320: INFO: Pod "pod-projected-configmaps-bf69414e-f8d0-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0108041s
STEP: Saw pod success
Dec  5 21:00:12.320: INFO: Pod "pod-projected-configmaps-bf69414e-f8d0-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 21:00:12.323: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-projected-configmaps-bf69414e-f8d0-11e8-b559-c27407a18179 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 21:00:12.345: INFO: Waiting for pod pod-projected-configmaps-bf69414e-f8d0-11e8-b559-c27407a18179 to disappear
Dec  5 21:00:12.348: INFO: Pod pod-projected-configmaps-bf69414e-f8d0-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 21:00:12.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cskq6" for this suite.
Dec  5 21:00:18.364: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:00:18.377: INFO: namespace: e2e-tests-projected-cskq6, resource: bindings, ignored listing per whitelist
Dec  5 21:00:18.455: INFO: namespace e2e-tests-projected-cskq6 deletion completed in 6.103651785s

• [SLOW TEST:10.221 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 21:00:18.455: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 21:00:18.522: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Dec  5 21:00:23.527: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  5 21:00:23.527: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  5 21:00:23.546: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-r5dt7,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-r5dt7/deployments/test-cleanup-deployment,UID:c87bacff-f8d0-11e8-b622-12e7eb78a7a2,ResourceVersion:21619,Generation:1,CreationTimestamp:2018-12-05 21:00:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Dec  5 21:00:23.551: INFO: New ReplicaSet "test-cleanup-deployment-7dbbfcf846" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-7dbbfcf846,GenerateName:,Namespace:e2e-tests-deployment-r5dt7,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-r5dt7/replicasets/test-cleanup-deployment-7dbbfcf846,UID:c87dd4ba-f8d0-11e8-b622-12e7eb78a7a2,ResourceVersion:21621,Generation:1,CreationTimestamp:2018-12-05 21:00:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment c87bacff-f8d0-11e8-b622-12e7eb78a7a2 0xc0021a6577 0xc0021a6578}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  5 21:00:23.551: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Dec  5 21:00:23.551: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-r5dt7,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-r5dt7/replicasets/test-cleanup-controller,UID:c57e403d-f8d0-11e8-b622-12e7eb78a7a2,ResourceVersion:21620,Generation:1,CreationTimestamp:2018-12-05 21:00:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment c87bacff-f8d0-11e8-b622-12e7eb78a7a2 0xc0021a63e7 0xc0021a63e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec  5 21:00:23.556: INFO: Pod "test-cleanup-controller-tnjl8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-tnjl8,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-r5dt7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r5dt7/pods/test-cleanup-controller-tnjl8,UID:c57f633d-f8d0-11e8-b622-12e7eb78a7a2,ResourceVersion:21613,Generation:0,CreationTimestamp:2018-12-05 21:00:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller c57e403d-f8d0-11e8-b622-12e7eb78a7a2 0xc0014962d7 0xc0014962d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lqqbg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lqqbg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lqqbg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-24-193,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0014965a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0014965c0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 21:00:18 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 21:00:20 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 21:00:20 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-05 21:00:18 +0000 UTC  }],Message:,Reason:,HostIP:172.31.24.193,PodIP:10.1.41.221,StartTime:2018-12-05 21:00:18 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-05 21:00:19 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd docker://69e7b4426eacfed4cc279267ce9cb94a641c9541931fa3d716319dbe55e94b38}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 21:00:23.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-r5dt7" for this suite.
Dec  5 21:00:29.590: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:00:29.664: INFO: namespace: e2e-tests-deployment-r5dt7, resource: bindings, ignored listing per whitelist
Dec  5 21:00:29.711: INFO: namespace e2e-tests-deployment-r5dt7 deletion completed in 6.150033218s

• [SLOW TEST:11.256 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 21:00:29.711: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-cc39c74e-f8d0-11e8-b559-c27407a18179
STEP: Creating secret with name s-test-opt-upd-cc39c79b-f8d0-11e8-b559-c27407a18179
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-cc39c74e-f8d0-11e8-b559-c27407a18179
STEP: Updating secret s-test-opt-upd-cc39c79b-f8d0-11e8-b559-c27407a18179
STEP: Creating secret with name s-test-opt-create-cc39c7bd-f8d0-11e8-b559-c27407a18179
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 21:01:40.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-p92sz" for this suite.
Dec  5 21:02:02.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:02:02.324: INFO: namespace: e2e-tests-projected-p92sz, resource: bindings, ignored listing per whitelist
Dec  5 21:02:02.467: INFO: namespace e2e-tests-projected-p92sz deletion completed in 22.225834967s

• [SLOW TEST:92.756 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 21:02:02.467: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Dec  5 21:02:02.628: INFO: Pod name pod-release: Found 0 pods out of 1
Dec  5 21:02:07.632: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 21:02:08.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-v52ng" for this suite.
Dec  5 21:02:14.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:02:14.736: INFO: namespace: e2e-tests-replication-controller-v52ng, resource: bindings, ignored listing per whitelist
Dec  5 21:02:14.764: INFO: namespace e2e-tests-replication-controller-v52ng deletion completed in 6.11199931s

• [SLOW TEST:12.296 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 21:02:14.764: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-0ad25ec6-f8d1-11e8-b559-c27407a18179
STEP: Creating a pod to test consume secrets
Dec  5 21:02:14.845: INFO: Waiting up to 5m0s for pod "pod-secrets-0ad2fb39-f8d1-11e8-b559-c27407a18179" in namespace "e2e-tests-secrets-9vj2n" to be "success or failure"
Dec  5 21:02:14.849: INFO: Pod "pod-secrets-0ad2fb39-f8d1-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 4.658447ms
Dec  5 21:02:16.856: INFO: Pod "pod-secrets-0ad2fb39-f8d1-11e8-b559-c27407a18179": Phase="Running", Reason="", readiness=true. Elapsed: 2.011497429s
Dec  5 21:02:18.860: INFO: Pod "pod-secrets-0ad2fb39-f8d1-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015312935s
STEP: Saw pod success
Dec  5 21:02:18.860: INFO: Pod "pod-secrets-0ad2fb39-f8d1-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 21:02:18.863: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-secrets-0ad2fb39-f8d1-11e8-b559-c27407a18179 container secret-volume-test: <nil>
STEP: delete the pod
Dec  5 21:02:18.879: INFO: Waiting for pod pod-secrets-0ad2fb39-f8d1-11e8-b559-c27407a18179 to disappear
Dec  5 21:02:18.882: INFO: Pod pod-secrets-0ad2fb39-f8d1-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 21:02:18.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-9vj2n" for this suite.
Dec  5 21:02:24.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:02:24.985: INFO: namespace: e2e-tests-secrets-9vj2n, resource: bindings, ignored listing per whitelist
Dec  5 21:02:25.010: INFO: namespace e2e-tests-secrets-9vj2n deletion completed in 6.125308505s

• [SLOW TEST:10.246 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 21:02:25.010: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  5 21:02:25.071: INFO: Waiting up to 5m0s for pod "downwardapi-volume-10ed0b55-f8d1-11e8-b559-c27407a18179" in namespace "e2e-tests-projected-q6kn5" to be "success or failure"
Dec  5 21:02:25.074: INFO: Pod "downwardapi-volume-10ed0b55-f8d1-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.781038ms
Dec  5 21:02:27.078: INFO: Pod "downwardapi-volume-10ed0b55-f8d1-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006507695s
Dec  5 21:02:29.082: INFO: Pod "downwardapi-volume-10ed0b55-f8d1-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010537191s
STEP: Saw pod success
Dec  5 21:02:29.082: INFO: Pod "downwardapi-volume-10ed0b55-f8d1-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 21:02:29.085: INFO: Trying to get logs from node ip-172-31-24-193 pod downwardapi-volume-10ed0b55-f8d1-11e8-b559-c27407a18179 container client-container: <nil>
STEP: delete the pod
Dec  5 21:02:29.103: INFO: Waiting for pod downwardapi-volume-10ed0b55-f8d1-11e8-b559-c27407a18179 to disappear
Dec  5 21:02:29.105: INFO: Pod downwardapi-volume-10ed0b55-f8d1-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 21:02:29.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-q6kn5" for this suite.
Dec  5 21:02:35.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:02:35.215: INFO: namespace: e2e-tests-projected-q6kn5, resource: bindings, ignored listing per whitelist
Dec  5 21:02:35.220: INFO: namespace e2e-tests-projected-q6kn5 deletion completed in 6.1106235s

• [SLOW TEST:10.210 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 21:02:35.220: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-17034eee-f8d1-11e8-b559-c27407a18179
STEP: Creating a pod to test consume configMaps
Dec  5 21:02:35.284: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1703db33-f8d1-11e8-b559-c27407a18179" in namespace "e2e-tests-projected-9h5wd" to be "success or failure"
Dec  5 21:02:35.289: INFO: Pod "pod-projected-configmaps-1703db33-f8d1-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 4.332188ms
Dec  5 21:02:37.293: INFO: Pod "pod-projected-configmaps-1703db33-f8d1-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008115477s
Dec  5 21:02:39.296: INFO: Pod "pod-projected-configmaps-1703db33-f8d1-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011762397s
STEP: Saw pod success
Dec  5 21:02:39.296: INFO: Pod "pod-projected-configmaps-1703db33-f8d1-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 21:02:39.299: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-projected-configmaps-1703db33-f8d1-11e8-b559-c27407a18179 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 21:02:39.318: INFO: Waiting for pod pod-projected-configmaps-1703db33-f8d1-11e8-b559-c27407a18179 to disappear
Dec  5 21:02:39.320: INFO: Pod pod-projected-configmaps-1703db33-f8d1-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 21:02:39.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9h5wd" for this suite.
Dec  5 21:02:45.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:02:45.348: INFO: namespace: e2e-tests-projected-9h5wd, resource: bindings, ignored listing per whitelist
Dec  5 21:02:45.426: INFO: namespace e2e-tests-projected-9h5wd deletion completed in 6.102341043s

• [SLOW TEST:10.206 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 21:02:45.426: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec  5 21:02:45.509: INFO: Number of nodes with available pods: 0
Dec  5 21:02:45.509: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 21:02:46.517: INFO: Number of nodes with available pods: 0
Dec  5 21:02:46.517: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 21:02:47.517: INFO: Number of nodes with available pods: 1
Dec  5 21:02:47.517: INFO: Node ip-172-31-24-193 is running more than one daemon pod
Dec  5 21:02:48.517: INFO: Number of nodes with available pods: 3
Dec  5 21:02:48.517: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Dec  5 21:02:48.536: INFO: Number of nodes with available pods: 2
Dec  5 21:02:48.536: INFO: Node ip-172-31-24-193 is running more than one daemon pod
Dec  5 21:02:49.543: INFO: Number of nodes with available pods: 2
Dec  5 21:02:49.543: INFO: Node ip-172-31-24-193 is running more than one daemon pod
Dec  5 21:02:50.543: INFO: Number of nodes with available pods: 2
Dec  5 21:02:50.543: INFO: Node ip-172-31-24-193 is running more than one daemon pod
Dec  5 21:02:51.544: INFO: Number of nodes with available pods: 3
Dec  5 21:02:51.544: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-ptq5p, will wait for the garbage collector to delete the pods
Dec  5 21:02:51.612: INFO: Deleting DaemonSet.extensions daemon-set took: 8.646133ms
Dec  5 21:02:51.712: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.326626ms
Dec  5 21:03:30.616: INFO: Number of nodes with available pods: 0
Dec  5 21:03:30.616: INFO: Number of running nodes: 0, number of available pods: 0
Dec  5 21:03:30.619: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-ptq5p/daemonsets","resourceVersion":"22208"},"items":null}

Dec  5 21:03:30.621: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-ptq5p/pods","resourceVersion":"22208"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 21:03:30.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-ptq5p" for this suite.
Dec  5 21:03:36.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:03:36.705: INFO: namespace: e2e-tests-daemonsets-ptq5p, resource: bindings, ignored listing per whitelist
Dec  5 21:03:36.743: INFO: namespace e2e-tests-daemonsets-ptq5p deletion completed in 6.10786037s

• [SLOW TEST:51.317 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 21:03:36.743: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-3baf69f6-f8d1-11e8-b559-c27407a18179
STEP: Creating a pod to test consume secrets
Dec  5 21:03:36.811: INFO: Waiting up to 5m0s for pod "pod-secrets-3bb011b2-f8d1-11e8-b559-c27407a18179" in namespace "e2e-tests-secrets-dv2dq" to be "success or failure"
Dec  5 21:03:36.814: INFO: Pod "pod-secrets-3bb011b2-f8d1-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 3.110011ms
Dec  5 21:03:38.818: INFO: Pod "pod-secrets-3bb011b2-f8d1-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00703155s
Dec  5 21:03:40.822: INFO: Pod "pod-secrets-3bb011b2-f8d1-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010918423s
STEP: Saw pod success
Dec  5 21:03:40.822: INFO: Pod "pod-secrets-3bb011b2-f8d1-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 21:03:40.824: INFO: Trying to get logs from node ip-172-31-24-193 pod pod-secrets-3bb011b2-f8d1-11e8-b559-c27407a18179 container secret-volume-test: <nil>
STEP: delete the pod
Dec  5 21:03:40.843: INFO: Waiting for pod pod-secrets-3bb011b2-f8d1-11e8-b559-c27407a18179 to disappear
Dec  5 21:03:40.846: INFO: Pod pod-secrets-3bb011b2-f8d1-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 21:03:40.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-dv2dq" for this suite.
Dec  5 21:03:46.867: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:03:47.051: INFO: namespace: e2e-tests-secrets-dv2dq, resource: bindings, ignored listing per whitelist
Dec  5 21:03:47.075: INFO: namespace e2e-tests-secrets-dv2dq deletion completed in 6.225954257s

• [SLOW TEST:10.332 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 21:03:47.076: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 21:03:47.191: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Dec  5 21:03:47.202: INFO: Number of nodes with available pods: 0
Dec  5 21:03:47.202: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Dec  5 21:03:47.220: INFO: Number of nodes with available pods: 0
Dec  5 21:03:47.220: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 21:03:48.223: INFO: Number of nodes with available pods: 0
Dec  5 21:03:48.223: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 21:03:49.223: INFO: Number of nodes with available pods: 1
Dec  5 21:03:49.223: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Dec  5 21:03:49.238: INFO: Number of nodes with available pods: 1
Dec  5 21:03:49.238: INFO: Number of running nodes: 0, number of available pods: 1
Dec  5 21:03:50.242: INFO: Number of nodes with available pods: 0
Dec  5 21:03:50.242: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Dec  5 21:03:50.251: INFO: Number of nodes with available pods: 0
Dec  5 21:03:50.251: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 21:03:51.255: INFO: Number of nodes with available pods: 0
Dec  5 21:03:51.255: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 21:03:52.255: INFO: Number of nodes with available pods: 0
Dec  5 21:03:52.255: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 21:03:53.255: INFO: Number of nodes with available pods: 0
Dec  5 21:03:53.255: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 21:03:54.255: INFO: Number of nodes with available pods: 0
Dec  5 21:03:54.255: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 21:03:55.255: INFO: Number of nodes with available pods: 0
Dec  5 21:03:55.255: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 21:03:56.257: INFO: Number of nodes with available pods: 0
Dec  5 21:03:56.257: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 21:03:57.255: INFO: Number of nodes with available pods: 0
Dec  5 21:03:57.255: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 21:03:58.255: INFO: Number of nodes with available pods: 0
Dec  5 21:03:58.255: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 21:03:59.255: INFO: Number of nodes with available pods: 0
Dec  5 21:03:59.255: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 21:04:00.255: INFO: Number of nodes with available pods: 0
Dec  5 21:04:00.255: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 21:04:01.255: INFO: Number of nodes with available pods: 0
Dec  5 21:04:01.255: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 21:04:02.257: INFO: Number of nodes with available pods: 0
Dec  5 21:04:02.257: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 21:04:03.256: INFO: Number of nodes with available pods: 0
Dec  5 21:04:03.256: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 21:04:04.255: INFO: Number of nodes with available pods: 0
Dec  5 21:04:04.255: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 21:04:05.257: INFO: Number of nodes with available pods: 0
Dec  5 21:04:05.257: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 21:04:06.258: INFO: Number of nodes with available pods: 0
Dec  5 21:04:06.258: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 21:04:07.255: INFO: Number of nodes with available pods: 0
Dec  5 21:04:07.255: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 21:04:08.255: INFO: Number of nodes with available pods: 0
Dec  5 21:04:08.255: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 21:04:09.255: INFO: Number of nodes with available pods: 0
Dec  5 21:04:09.255: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 21:04:10.255: INFO: Number of nodes with available pods: 0
Dec  5 21:04:10.255: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 21:04:11.255: INFO: Number of nodes with available pods: 0
Dec  5 21:04:11.255: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 21:04:12.255: INFO: Number of nodes with available pods: 0
Dec  5 21:04:12.255: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 21:04:13.255: INFO: Number of nodes with available pods: 0
Dec  5 21:04:13.255: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 21:04:14.255: INFO: Number of nodes with available pods: 0
Dec  5 21:04:14.255: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 21:04:15.255: INFO: Number of nodes with available pods: 0
Dec  5 21:04:15.255: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 21:04:16.255: INFO: Number of nodes with available pods: 0
Dec  5 21:04:16.255: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 21:04:17.255: INFO: Number of nodes with available pods: 0
Dec  5 21:04:17.255: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 21:04:18.255: INFO: Number of nodes with available pods: 0
Dec  5 21:04:18.255: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 21:04:19.255: INFO: Number of nodes with available pods: 0
Dec  5 21:04:19.255: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 21:04:20.255: INFO: Number of nodes with available pods: 0
Dec  5 21:04:20.255: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 21:04:21.255: INFO: Number of nodes with available pods: 0
Dec  5 21:04:21.255: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 21:04:22.257: INFO: Number of nodes with available pods: 0
Dec  5 21:04:22.257: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 21:04:23.255: INFO: Number of nodes with available pods: 0
Dec  5 21:04:23.255: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 21:04:24.255: INFO: Number of nodes with available pods: 0
Dec  5 21:04:24.255: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 21:04:25.256: INFO: Number of nodes with available pods: 0
Dec  5 21:04:25.256: INFO: Node ip-172-31-2-231 is running more than one daemon pod
Dec  5 21:04:26.255: INFO: Number of nodes with available pods: 1
Dec  5 21:04:26.255: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-774rf, will wait for the garbage collector to delete the pods
Dec  5 21:04:26.320: INFO: Deleting DaemonSet.extensions daemon-set took: 7.190669ms
Dec  5 21:04:26.420: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.211377ms
Dec  5 21:05:10.624: INFO: Number of nodes with available pods: 0
Dec  5 21:05:10.624: INFO: Number of running nodes: 0, number of available pods: 0
Dec  5 21:05:10.627: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-774rf/daemonsets","resourceVersion":"22478"},"items":null}

Dec  5 21:05:10.630: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-774rf/pods","resourceVersion":"22478"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 21:05:10.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-774rf" for this suite.
Dec  5 21:05:16.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:05:16.725: INFO: namespace: e2e-tests-daemonsets-774rf, resource: bindings, ignored listing per whitelist
Dec  5 21:05:16.762: INFO: namespace e2e-tests-daemonsets-774rf deletion completed in 6.110844709s

• [SLOW TEST:89.686 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 21:05:16.762: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  5 21:05:16.836: INFO: Waiting up to 5m0s for pod "downward-api-774d4ced-f8d1-11e8-b559-c27407a18179" in namespace "e2e-tests-downward-api-gjfv6" to be "success or failure"
Dec  5 21:05:16.847: INFO: Pod "downward-api-774d4ced-f8d1-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 10.802045ms
Dec  5 21:05:18.851: INFO: Pod "downward-api-774d4ced-f8d1-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014579846s
STEP: Saw pod success
Dec  5 21:05:18.851: INFO: Pod "downward-api-774d4ced-f8d1-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 21:05:18.853: INFO: Trying to get logs from node ip-172-31-24-193 pod downward-api-774d4ced-f8d1-11e8-b559-c27407a18179 container dapi-container: <nil>
STEP: delete the pod
Dec  5 21:05:18.877: INFO: Waiting for pod downward-api-774d4ced-f8d1-11e8-b559-c27407a18179 to disappear
Dec  5 21:05:18.880: INFO: Pod downward-api-774d4ced-f8d1-11e8-b559-c27407a18179 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 21:05:18.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-gjfv6" for this suite.
Dec  5 21:05:24.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:05:24.999: INFO: namespace: e2e-tests-downward-api-gjfv6, resource: bindings, ignored listing per whitelist
Dec  5 21:05:25.048: INFO: namespace e2e-tests-downward-api-gjfv6 deletion completed in 6.164047216s

• [SLOW TEST:8.286 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 21:05:25.048: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 21:05:25.121: INFO: (0) /api/v1/nodes/ip-172-31-2-231:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 7.580721ms)
Dec  5 21:05:25.125: INFO: (1) /api/v1/nodes/ip-172-31-2-231:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.039429ms)
Dec  5 21:05:25.129: INFO: (2) /api/v1/nodes/ip-172-31-2-231:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.728483ms)
Dec  5 21:05:25.133: INFO: (3) /api/v1/nodes/ip-172-31-2-231:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.912616ms)
Dec  5 21:05:25.137: INFO: (4) /api/v1/nodes/ip-172-31-2-231:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.193898ms)
Dec  5 21:05:25.141: INFO: (5) /api/v1/nodes/ip-172-31-2-231:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.998969ms)
Dec  5 21:05:25.145: INFO: (6) /api/v1/nodes/ip-172-31-2-231:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.689415ms)
Dec  5 21:05:25.148: INFO: (7) /api/v1/nodes/ip-172-31-2-231:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.642067ms)
Dec  5 21:05:25.152: INFO: (8) /api/v1/nodes/ip-172-31-2-231:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.485318ms)
Dec  5 21:05:25.156: INFO: (9) /api/v1/nodes/ip-172-31-2-231:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.780891ms)
Dec  5 21:05:25.159: INFO: (10) /api/v1/nodes/ip-172-31-2-231:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.875527ms)
Dec  5 21:05:25.163: INFO: (11) /api/v1/nodes/ip-172-31-2-231:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.825755ms)
Dec  5 21:05:25.167: INFO: (12) /api/v1/nodes/ip-172-31-2-231:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.565113ms)
Dec  5 21:05:25.171: INFO: (13) /api/v1/nodes/ip-172-31-2-231:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.084519ms)
Dec  5 21:05:25.174: INFO: (14) /api/v1/nodes/ip-172-31-2-231:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.445444ms)
Dec  5 21:05:25.178: INFO: (15) /api/v1/nodes/ip-172-31-2-231:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.715635ms)
Dec  5 21:05:25.182: INFO: (16) /api/v1/nodes/ip-172-31-2-231:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.246983ms)
Dec  5 21:05:25.187: INFO: (17) /api/v1/nodes/ip-172-31-2-231:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.652313ms)
Dec  5 21:05:25.191: INFO: (18) /api/v1/nodes/ip-172-31-2-231:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.673139ms)
Dec  5 21:05:25.195: INFO: (19) /api/v1/nodes/ip-172-31-2-231:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.768003ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 21:05:25.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-xgt55" for this suite.
Dec  5 21:05:31.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:05:31.259: INFO: namespace: e2e-tests-proxy-xgt55, resource: bindings, ignored listing per whitelist
Dec  5 21:05:31.319: INFO: namespace e2e-tests-proxy-xgt55 deletion completed in 6.121063228s

• [SLOW TEST:6.271 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  5 21:05:31.319: INFO: >>> kubeConfig: /tmp/kubeconfig-100404934
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  5 21:05:35.419: INFO: Waiting up to 5m0s for pod "client-envvars-82622d65-f8d1-11e8-b559-c27407a18179" in namespace "e2e-tests-pods-jw8bv" to be "success or failure"
Dec  5 21:05:35.427: INFO: Pod "client-envvars-82622d65-f8d1-11e8-b559-c27407a18179": Phase="Pending", Reason="", readiness=false. Elapsed: 7.65997ms
Dec  5 21:05:37.437: INFO: Pod "client-envvars-82622d65-f8d1-11e8-b559-c27407a18179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017968637s
STEP: Saw pod success
Dec  5 21:05:37.437: INFO: Pod "client-envvars-82622d65-f8d1-11e8-b559-c27407a18179" satisfied condition "success or failure"
Dec  5 21:05:37.440: INFO: Trying to get logs from node ip-172-31-24-193 pod client-envvars-82622d65-f8d1-11e8-b559-c27407a18179 container env3cont: <nil>
STEP: delete the pod
Dec  5 21:05:37.460: INFO: Waiting for pod client-envvars-82622d65-f8d1-11e8-b559-c27407a18179 to disappear
Dec  5 21:05:37.463: INFO: Pod client-envvars-82622d65-f8d1-11e8-b559-c27407a18179 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  5 21:05:37.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-jw8bv" for this suite.
Dec  5 21:06:15.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 21:06:15.683: INFO: namespace: e2e-tests-pods-jw8bv, resource: bindings, ignored listing per whitelist
Dec  5 21:06:15.703: INFO: namespace e2e-tests-pods-jw8bv deletion completed in 38.23686799s

• [SLOW TEST:44.384 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSDec  5 21:06:15.703: INFO: Running AfterSuite actions on all nodes
Dec  5 21:06:15.703: INFO: Running AfterSuite actions on node 1
Dec  5 21:06:15.703: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 5829.233 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h37m10.138756142s
Test Suite Passed
