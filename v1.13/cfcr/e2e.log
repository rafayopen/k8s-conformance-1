I0221 18:13:50.586170      18 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-043636783
I0221 18:13:50.586395      18 e2e.go:224] Starting e2e run "7014886c-3604-11e9-816d-1a333d676433" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1550772829 - Will randomize all specs
Will run 201 of 1946 specs

Feb 21 18:13:50.763: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
Feb 21 18:13:50.767: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Feb 21 18:13:50.788: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Feb 21 18:13:50.817: INFO: 5 / 5 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Feb 21 18:13:50.817: INFO: expected 5 pod replicas in namespace 'kube-system', 5 are Running and Ready.
Feb 21 18:13:50.817: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Feb 21 18:13:50.826: INFO: e2e test version: v1.13.0
Feb 21 18:13:50.828: INFO: kube-apiserver version: v1.13.3
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:13:50.828: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename kubectl
Feb 21 18:13:50.913: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Feb 21 18:13:50.933: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-hqflg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Feb 21 18:13:51.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 api-versions'
Feb 21 18:13:51.138: INFO: stderr: ""
Feb 21 18:13:51.138: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:13:51.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hqflg" for this suite.
Feb 21 18:13:57.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:13:57.257: INFO: namespace: e2e-tests-kubectl-hqflg, resource: bindings, ignored listing per whitelist
Feb 21 18:13:57.314: INFO: namespace e2e-tests-kubectl-hqflg deletion completed in 6.171541431s

• [SLOW TEST:6.486 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:13:57.315: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-jtkd8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 21 18:14:03.567: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 21 18:14:03.571: INFO: Pod pod-with-prestop-http-hook still exists
Feb 21 18:14:05.571: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 21 18:14:05.576: INFO: Pod pod-with-prestop-http-hook still exists
Feb 21 18:14:07.571: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 21 18:14:07.576: INFO: Pod pod-with-prestop-http-hook still exists
Feb 21 18:14:09.571: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 21 18:14:09.576: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:14:09.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-jtkd8" for this suite.
Feb 21 18:14:31.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:14:31.761: INFO: namespace: e2e-tests-container-lifecycle-hook-jtkd8, resource: bindings, ignored listing per whitelist
Feb 21 18:14:31.774: INFO: namespace e2e-tests-container-lifecycle-hook-jtkd8 deletion completed in 22.167339292s

• [SLOW TEST:34.459 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:14:31.774: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-dwtt7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-891c6b6e-3604-11e9-816d-1a333d676433
STEP: Creating a pod to test consume secrets
Feb 21 18:14:31.980: INFO: Waiting up to 5m0s for pod "pod-secrets-891d5ca8-3604-11e9-816d-1a333d676433" in namespace "e2e-tests-secrets-dwtt7" to be "success or failure"
Feb 21 18:14:31.984: INFO: Pod "pod-secrets-891d5ca8-3604-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 4.535545ms
Feb 21 18:14:33.997: INFO: Pod "pod-secrets-891d5ca8-3604-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017277503s
Feb 21 18:14:36.002: INFO: Pod "pod-secrets-891d5ca8-3604-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022555126s
STEP: Saw pod success
Feb 21 18:14:36.002: INFO: Pod "pod-secrets-891d5ca8-3604-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:14:36.007: INFO: Trying to get logs from node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c pod pod-secrets-891d5ca8-3604-11e9-816d-1a333d676433 container secret-volume-test: <nil>
STEP: delete the pod
Feb 21 18:14:36.036: INFO: Waiting for pod pod-secrets-891d5ca8-3604-11e9-816d-1a333d676433 to disappear
Feb 21 18:14:36.039: INFO: Pod pod-secrets-891d5ca8-3604-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:14:36.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-dwtt7" for this suite.
Feb 21 18:14:42.065: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:14:42.157: INFO: namespace: e2e-tests-secrets-dwtt7, resource: bindings, ignored listing per whitelist
Feb 21 18:14:42.199: INFO: namespace e2e-tests-secrets-dwtt7 deletion completed in 6.156428494s

• [SLOW TEST:10.425 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:14:42.199: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-9shxt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-9shxt/configmap-test-8f540e2e-3604-11e9-816d-1a333d676433
STEP: Creating a pod to test consume configMaps
Feb 21 18:14:42.408: INFO: Waiting up to 5m0s for pod "pod-configmaps-8f5509ee-3604-11e9-816d-1a333d676433" in namespace "e2e-tests-configmap-9shxt" to be "success or failure"
Feb 21 18:14:42.414: INFO: Pod "pod-configmaps-8f5509ee-3604-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 5.790198ms
Feb 21 18:14:44.425: INFO: Pod "pod-configmaps-8f5509ee-3604-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016335918s
Feb 21 18:14:46.429: INFO: Pod "pod-configmaps-8f5509ee-3604-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021096912s
STEP: Saw pod success
Feb 21 18:14:46.429: INFO: Pod "pod-configmaps-8f5509ee-3604-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:14:46.433: INFO: Trying to get logs from node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c pod pod-configmaps-8f5509ee-3604-11e9-816d-1a333d676433 container env-test: <nil>
STEP: delete the pod
Feb 21 18:14:46.473: INFO: Waiting for pod pod-configmaps-8f5509ee-3604-11e9-816d-1a333d676433 to disappear
Feb 21 18:14:46.477: INFO: Pod pod-configmaps-8f5509ee-3604-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:14:46.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9shxt" for this suite.
Feb 21 18:14:52.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:14:52.534: INFO: namespace: e2e-tests-configmap-9shxt, resource: bindings, ignored listing per whitelist
Feb 21 18:14:52.633: INFO: namespace e2e-tests-configmap-9shxt deletion completed in 6.152717564s

• [SLOW TEST:10.434 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:14:52.634: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-wrapper-w55dx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:14:56.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-w55dx" for this suite.
Feb 21 18:15:02.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:15:03.043: INFO: namespace: e2e-tests-emptydir-wrapper-w55dx, resource: bindings, ignored listing per whitelist
Feb 21 18:15:03.071: INFO: namespace e2e-tests-emptydir-wrapper-w55dx deletion completed in 6.169670618s

• [SLOW TEST:10.437 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:15:03.071: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-2fgr7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 21 18:15:03.263: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-2fgr7'
Feb 21 18:15:03.546: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 21 18:15:03.546: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Feb 21 18:15:05.573: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-2fgr7'
Feb 21 18:15:05.662: INFO: stderr: ""
Feb 21 18:15:05.662: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:15:05.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2fgr7" for this suite.
Feb 21 18:15:11.690: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:15:11.831: INFO: namespace: e2e-tests-kubectl-2fgr7, resource: bindings, ignored listing per whitelist
Feb 21 18:15:11.834: INFO: namespace e2e-tests-kubectl-2fgr7 deletion completed in 6.165936125s

• [SLOW TEST:8.763 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:15:11.834: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-895d2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Feb 21 18:15:12.029: INFO: Waiting up to 5m0s for pod "client-containers-a0fc83fc-3604-11e9-816d-1a333d676433" in namespace "e2e-tests-containers-895d2" to be "success or failure"
Feb 21 18:15:12.037: INFO: Pod "client-containers-a0fc83fc-3604-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 7.985571ms
Feb 21 18:15:14.042: INFO: Pod "client-containers-a0fc83fc-3604-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013134765s
Feb 21 18:15:16.055: INFO: Pod "client-containers-a0fc83fc-3604-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025811356s
STEP: Saw pod success
Feb 21 18:15:16.055: INFO: Pod "client-containers-a0fc83fc-3604-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:15:16.058: INFO: Trying to get logs from node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c pod client-containers-a0fc83fc-3604-11e9-816d-1a333d676433 container test-container: <nil>
STEP: delete the pod
Feb 21 18:15:16.084: INFO: Waiting for pod client-containers-a0fc83fc-3604-11e9-816d-1a333d676433 to disappear
Feb 21 18:15:16.088: INFO: Pod client-containers-a0fc83fc-3604-11e9-816d-1a333d676433 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:15:16.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-895d2" for this suite.
Feb 21 18:15:22.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:15:22.153: INFO: namespace: e2e-tests-containers-895d2, resource: bindings, ignored listing per whitelist
Feb 21 18:15:22.268: INFO: namespace e2e-tests-containers-895d2 deletion completed in 6.175844059s

• [SLOW TEST:10.434 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:15:22.268: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-rr2vx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 21 18:15:22.510: INFO: Number of nodes with available pods: 0
Feb 21 18:15:22.510: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:15:23.520: INFO: Number of nodes with available pods: 0
Feb 21 18:15:23.520: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:15:24.520: INFO: Number of nodes with available pods: 0
Feb 21 18:15:24.520: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:15:25.520: INFO: Number of nodes with available pods: 3
Feb 21 18:15:25.520: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Feb 21 18:15:25.548: INFO: Number of nodes with available pods: 2
Feb 21 18:15:25.548: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:15:26.565: INFO: Number of nodes with available pods: 2
Feb 21 18:15:26.565: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:15:27.559: INFO: Number of nodes with available pods: 2
Feb 21 18:15:27.559: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:15:28.558: INFO: Number of nodes with available pods: 2
Feb 21 18:15:28.558: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:15:29.557: INFO: Number of nodes with available pods: 2
Feb 21 18:15:29.557: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:15:30.557: INFO: Number of nodes with available pods: 2
Feb 21 18:15:30.557: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:15:31.557: INFO: Number of nodes with available pods: 2
Feb 21 18:15:31.557: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:15:32.557: INFO: Number of nodes with available pods: 2
Feb 21 18:15:32.557: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:15:33.558: INFO: Number of nodes with available pods: 2
Feb 21 18:15:33.558: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:15:34.558: INFO: Number of nodes with available pods: 2
Feb 21 18:15:34.558: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:15:35.558: INFO: Number of nodes with available pods: 2
Feb 21 18:15:35.558: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:15:36.558: INFO: Number of nodes with available pods: 2
Feb 21 18:15:36.558: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:15:37.564: INFO: Number of nodes with available pods: 2
Feb 21 18:15:37.564: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:15:38.557: INFO: Number of nodes with available pods: 2
Feb 21 18:15:38.557: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:15:39.557: INFO: Number of nodes with available pods: 2
Feb 21 18:15:39.557: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:15:40.561: INFO: Number of nodes with available pods: 2
Feb 21 18:15:40.561: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:15:41.558: INFO: Number of nodes with available pods: 2
Feb 21 18:15:41.558: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:15:42.556: INFO: Number of nodes with available pods: 2
Feb 21 18:15:42.557: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:15:43.557: INFO: Number of nodes with available pods: 2
Feb 21 18:15:43.557: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:15:44.557: INFO: Number of nodes with available pods: 2
Feb 21 18:15:44.557: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:15:45.556: INFO: Number of nodes with available pods: 2
Feb 21 18:15:45.556: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:15:46.557: INFO: Number of nodes with available pods: 2
Feb 21 18:15:46.557: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:15:47.557: INFO: Number of nodes with available pods: 2
Feb 21 18:15:47.557: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:15:48.565: INFO: Number of nodes with available pods: 2
Feb 21 18:15:48.565: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:15:49.557: INFO: Number of nodes with available pods: 2
Feb 21 18:15:49.557: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:15:50.557: INFO: Number of nodes with available pods: 2
Feb 21 18:15:50.557: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:15:51.558: INFO: Number of nodes with available pods: 2
Feb 21 18:15:51.558: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:15:52.557: INFO: Number of nodes with available pods: 2
Feb 21 18:15:52.557: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:15:53.557: INFO: Number of nodes with available pods: 2
Feb 21 18:15:53.557: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:15:54.557: INFO: Number of nodes with available pods: 2
Feb 21 18:15:54.557: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:15:55.557: INFO: Number of nodes with available pods: 2
Feb 21 18:15:55.557: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:15:56.557: INFO: Number of nodes with available pods: 2
Feb 21 18:15:56.557: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:15:57.558: INFO: Number of nodes with available pods: 2
Feb 21 18:15:57.558: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:15:58.560: INFO: Number of nodes with available pods: 2
Feb 21 18:15:58.560: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:15:59.565: INFO: Number of nodes with available pods: 2
Feb 21 18:15:59.565: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:16:00.557: INFO: Number of nodes with available pods: 2
Feb 21 18:16:00.558: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:16:01.557: INFO: Number of nodes with available pods: 2
Feb 21 18:16:01.557: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:16:02.558: INFO: Number of nodes with available pods: 3
Feb 21 18:16:02.558: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-rr2vx, will wait for the garbage collector to delete the pods
Feb 21 18:16:02.626: INFO: Deleting DaemonSet.extensions daemon-set took: 10.249917ms
Feb 21 18:16:02.726: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.350552ms
Feb 21 18:16:39.037: INFO: Number of nodes with available pods: 0
Feb 21 18:16:39.037: INFO: Number of running nodes: 0, number of available pods: 0
Feb 21 18:16:39.041: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-rr2vx/daemonsets","resourceVersion":"6086"},"items":null}

Feb 21 18:16:39.045: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-rr2vx/pods","resourceVersion":"6086"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:16:39.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-rr2vx" for this suite.
Feb 21 18:16:45.080: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:16:45.148: INFO: namespace: e2e-tests-daemonsets-rr2vx, resource: bindings, ignored listing per whitelist
Feb 21 18:16:45.203: INFO: namespace e2e-tests-daemonsets-rr2vx deletion completed in 6.139661712s

• [SLOW TEST:82.935 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:16:45.203: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-6gmk5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 21 18:16:45.405: INFO: (0) /api/v1/nodes/vm-899af0be-63fe-4e97-4fe5-b77e233eb87c/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 7.573234ms)
Feb 21 18:16:45.410: INFO: (1) /api/v1/nodes/vm-899af0be-63fe-4e97-4fe5-b77e233eb87c/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.512234ms)
Feb 21 18:16:45.415: INFO: (2) /api/v1/nodes/vm-899af0be-63fe-4e97-4fe5-b77e233eb87c/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.17826ms)
Feb 21 18:16:45.420: INFO: (3) /api/v1/nodes/vm-899af0be-63fe-4e97-4fe5-b77e233eb87c/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.993627ms)
Feb 21 18:16:45.425: INFO: (4) /api/v1/nodes/vm-899af0be-63fe-4e97-4fe5-b77e233eb87c/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.776511ms)
Feb 21 18:16:45.430: INFO: (5) /api/v1/nodes/vm-899af0be-63fe-4e97-4fe5-b77e233eb87c/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.028512ms)
Feb 21 18:16:45.435: INFO: (6) /api/v1/nodes/vm-899af0be-63fe-4e97-4fe5-b77e233eb87c/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.738483ms)
Feb 21 18:16:45.440: INFO: (7) /api/v1/nodes/vm-899af0be-63fe-4e97-4fe5-b77e233eb87c/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.558734ms)
Feb 21 18:16:45.445: INFO: (8) /api/v1/nodes/vm-899af0be-63fe-4e97-4fe5-b77e233eb87c/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.568265ms)
Feb 21 18:16:45.450: INFO: (9) /api/v1/nodes/vm-899af0be-63fe-4e97-4fe5-b77e233eb87c/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.601322ms)
Feb 21 18:16:45.455: INFO: (10) /api/v1/nodes/vm-899af0be-63fe-4e97-4fe5-b77e233eb87c/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.998668ms)
Feb 21 18:16:45.460: INFO: (11) /api/v1/nodes/vm-899af0be-63fe-4e97-4fe5-b77e233eb87c/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.926917ms)
Feb 21 18:16:45.465: INFO: (12) /api/v1/nodes/vm-899af0be-63fe-4e97-4fe5-b77e233eb87c/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.478029ms)
Feb 21 18:16:45.469: INFO: (13) /api/v1/nodes/vm-899af0be-63fe-4e97-4fe5-b77e233eb87c/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.2848ms)
Feb 21 18:16:45.474: INFO: (14) /api/v1/nodes/vm-899af0be-63fe-4e97-4fe5-b77e233eb87c/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.841509ms)
Feb 21 18:16:45.479: INFO: (15) /api/v1/nodes/vm-899af0be-63fe-4e97-4fe5-b77e233eb87c/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.612909ms)
Feb 21 18:16:45.484: INFO: (16) /api/v1/nodes/vm-899af0be-63fe-4e97-4fe5-b77e233eb87c/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.999819ms)
Feb 21 18:16:45.488: INFO: (17) /api/v1/nodes/vm-899af0be-63fe-4e97-4fe5-b77e233eb87c/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.734945ms)
Feb 21 18:16:45.493: INFO: (18) /api/v1/nodes/vm-899af0be-63fe-4e97-4fe5-b77e233eb87c/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.900946ms)
Feb 21 18:16:45.498: INFO: (19) /api/v1/nodes/vm-899af0be-63fe-4e97-4fe5-b77e233eb87c/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.539442ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:16:45.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-6gmk5" for this suite.
Feb 21 18:16:51.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:16:51.538: INFO: namespace: e2e-tests-proxy-6gmk5, resource: bindings, ignored listing per whitelist
Feb 21 18:16:51.649: INFO: namespace e2e-tests-proxy-6gmk5 deletion completed in 6.147069687s

• [SLOW TEST:6.446 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:16:51.649: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-hostpath-8xdz7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Feb 21 18:16:51.845: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-8xdz7" to be "success or failure"
Feb 21 18:16:51.850: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 5.309338ms
Feb 21 18:16:53.855: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010138577s
Feb 21 18:16:55.861: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01564268s
STEP: Saw pod success
Feb 21 18:16:55.861: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Feb 21 18:16:55.864: INFO: Trying to get logs from node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Feb 21 18:16:55.889: INFO: Waiting for pod pod-host-path-test to disappear
Feb 21 18:16:55.892: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:16:55.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-8xdz7" for this suite.
Feb 21 18:17:01.914: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:17:02.002: INFO: namespace: e2e-tests-hostpath-8xdz7, resource: bindings, ignored listing per whitelist
Feb 21 18:17:02.068: INFO: namespace e2e-tests-hostpath-8xdz7 deletion completed in 6.171455413s

• [SLOW TEST:10.418 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:17:02.068: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-x4282
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 21 18:17:02.279: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e2b1b8a5-3604-11e9-816d-1a333d676433" in namespace "e2e-tests-downward-api-x4282" to be "success or failure"
Feb 21 18:17:02.288: INFO: Pod "downwardapi-volume-e2b1b8a5-3604-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 9.141198ms
Feb 21 18:17:04.293: INFO: Pod "downwardapi-volume-e2b1b8a5-3604-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013807397s
Feb 21 18:17:06.298: INFO: Pod "downwardapi-volume-e2b1b8a5-3604-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018828411s
STEP: Saw pod success
Feb 21 18:17:06.298: INFO: Pod "downwardapi-volume-e2b1b8a5-3604-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:17:06.302: INFO: Trying to get logs from node vm-96433648-4a4e-4d7e-4d24-8065d4ab25dc pod downwardapi-volume-e2b1b8a5-3604-11e9-816d-1a333d676433 container client-container: <nil>
STEP: delete the pod
Feb 21 18:17:06.347: INFO: Waiting for pod downwardapi-volume-e2b1b8a5-3604-11e9-816d-1a333d676433 to disappear
Feb 21 18:17:06.351: INFO: Pod downwardapi-volume-e2b1b8a5-3604-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:17:06.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-x4282" for this suite.
Feb 21 18:17:12.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:17:12.384: INFO: namespace: e2e-tests-downward-api-x4282, resource: bindings, ignored listing per whitelist
Feb 21 18:17:12.509: INFO: namespace e2e-tests-downward-api-x4282 deletion completed in 6.153480554s

• [SLOW TEST:10.441 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:17:12.509: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-vldpk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-e8eab4cd-3604-11e9-816d-1a333d676433
STEP: Creating a pod to test consume configMaps
Feb 21 18:17:12.715: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e8ebd924-3604-11e9-816d-1a333d676433" in namespace "e2e-tests-projected-vldpk" to be "success or failure"
Feb 21 18:17:12.721: INFO: Pod "pod-projected-configmaps-e8ebd924-3604-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 5.692718ms
Feb 21 18:17:14.725: INFO: Pod "pod-projected-configmaps-e8ebd924-3604-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01020136s
STEP: Saw pod success
Feb 21 18:17:14.725: INFO: Pod "pod-projected-configmaps-e8ebd924-3604-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:17:14.729: INFO: Trying to get logs from node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c pod pod-projected-configmaps-e8ebd924-3604-11e9-816d-1a333d676433 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 21 18:17:14.755: INFO: Waiting for pod pod-projected-configmaps-e8ebd924-3604-11e9-816d-1a333d676433 to disappear
Feb 21 18:17:14.758: INFO: Pod pod-projected-configmaps-e8ebd924-3604-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:17:14.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vldpk" for this suite.
Feb 21 18:17:20.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:17:20.893: INFO: namespace: e2e-tests-projected-vldpk, resource: bindings, ignored listing per whitelist
Feb 21 18:17:20.916: INFO: namespace e2e-tests-projected-vldpk deletion completed in 6.153877451s

• [SLOW TEST:8.407 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:17:20.916: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-5wwhd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-edeccf55-3604-11e9-816d-1a333d676433
STEP: Creating a pod to test consume secrets
Feb 21 18:17:21.116: INFO: Waiting up to 5m0s for pod "pod-secrets-ededc8c8-3604-11e9-816d-1a333d676433" in namespace "e2e-tests-secrets-5wwhd" to be "success or failure"
Feb 21 18:17:21.121: INFO: Pod "pod-secrets-ededc8c8-3604-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 5.515863ms
Feb 21 18:17:23.127: INFO: Pod "pod-secrets-ededc8c8-3604-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010965293s
STEP: Saw pod success
Feb 21 18:17:23.127: INFO: Pod "pod-secrets-ededc8c8-3604-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:17:23.130: INFO: Trying to get logs from node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c pod pod-secrets-ededc8c8-3604-11e9-816d-1a333d676433 container secret-volume-test: <nil>
STEP: delete the pod
Feb 21 18:17:23.154: INFO: Waiting for pod pod-secrets-ededc8c8-3604-11e9-816d-1a333d676433 to disappear
Feb 21 18:17:23.157: INFO: Pod pod-secrets-ededc8c8-3604-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:17:23.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-5wwhd" for this suite.
Feb 21 18:17:29.180: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:17:29.210: INFO: namespace: e2e-tests-secrets-5wwhd, resource: bindings, ignored listing per whitelist
Feb 21 18:17:29.310: INFO: namespace e2e-tests-secrets-5wwhd deletion completed in 6.147977987s

• [SLOW TEST:8.394 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:17:29.310: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-22jjs
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Feb 21 18:17:38.540: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:17:39.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-22jjs" for this suite.
Feb 21 18:18:01.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:18:01.684: INFO: namespace: e2e-tests-replicaset-22jjs, resource: bindings, ignored listing per whitelist
Feb 21 18:18:01.755: INFO: namespace e2e-tests-replicaset-22jjs deletion completed in 22.190310748s

• [SLOW TEST:32.444 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:18:01.755: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-h7xwz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 21 18:18:01.956: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:18:07.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-h7xwz" for this suite.
Feb 21 18:18:13.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:18:13.225: INFO: namespace: e2e-tests-init-container-h7xwz, resource: bindings, ignored listing per whitelist
Feb 21 18:18:13.291: INFO: namespace e2e-tests-init-container-h7xwz deletion completed in 6.159460857s

• [SLOW TEST:11.536 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:18:13.292: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-events-mpgvl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Feb 21 18:18:15.510: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-0d259974-3605-11e9-816d-1a333d676433,GenerateName:,Namespace:e2e-tests-events-mpgvl,SelfLink:/api/v1/namespaces/e2e-tests-events-mpgvl/pods/send-events-0d259974-3605-11e9-816d-1a333d676433,UID:0d26602f-3605-11e9-bacd-42010a000102,ResourceVersion:6496,Generation:0,CreationTimestamp:2019-02-21 18:18:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 481514439,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-h7p47 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-h7p47,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-h7p47 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm-899af0be-63fe-4e97-4fe5-b77e233eb87c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001e87550} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001e87570}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 18:18:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 18:18:15 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 18:18:15 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 18:18:13 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.5,PodIP:10.200.20.14,StartTime:2019-02-21 18:18:13 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-02-21 18:18:14 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://dab6aa5910ebf25d23266fc301e199e2fc07c7011267628dc93089a07a7957ce}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Feb 21 18:18:17.523: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Feb 21 18:18:19.529: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:18:19.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-mpgvl" for this suite.
Feb 21 18:18:57.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:18:57.611: INFO: namespace: e2e-tests-events-mpgvl, resource: bindings, ignored listing per whitelist
Feb 21 18:18:57.694: INFO: namespace e2e-tests-events-mpgvl deletion completed in 38.153022301s

• [SLOW TEST:44.403 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:18:57.694: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-ckmlp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 21 18:18:57.893: INFO: Waiting up to 5m0s for pod "downwardapi-volume-279ca468-3605-11e9-816d-1a333d676433" in namespace "e2e-tests-projected-ckmlp" to be "success or failure"
Feb 21 18:18:57.899: INFO: Pod "downwardapi-volume-279ca468-3605-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 5.765982ms
Feb 21 18:18:59.903: INFO: Pod "downwardapi-volume-279ca468-3605-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0103603s
STEP: Saw pod success
Feb 21 18:18:59.903: INFO: Pod "downwardapi-volume-279ca468-3605-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:18:59.908: INFO: Trying to get logs from node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c pod downwardapi-volume-279ca468-3605-11e9-816d-1a333d676433 container client-container: <nil>
STEP: delete the pod
Feb 21 18:18:59.935: INFO: Waiting for pod downwardapi-volume-279ca468-3605-11e9-816d-1a333d676433 to disappear
Feb 21 18:18:59.939: INFO: Pod downwardapi-volume-279ca468-3605-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:18:59.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ckmlp" for this suite.
Feb 21 18:19:05.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:19:06.002: INFO: namespace: e2e-tests-projected-ckmlp, resource: bindings, ignored listing per whitelist
Feb 21 18:19:06.093: INFO: namespace e2e-tests-projected-ckmlp deletion completed in 6.149820224s

• [SLOW TEST:8.399 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:19:06.093: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-qtqfg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Feb 21 18:19:06.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 cluster-info'
Feb 21 18:19:06.355: INFO: stderr: ""
Feb 21 18:19:06.355: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.100.200.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.100.200.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:19:06.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qtqfg" for this suite.
Feb 21 18:19:12.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:19:12.408: INFO: namespace: e2e-tests-kubectl-qtqfg, resource: bindings, ignored listing per whitelist
Feb 21 18:19:12.523: INFO: namespace e2e-tests-kubectl-qtqfg deletion completed in 6.162863482s

• [SLOW TEST:6.429 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:19:12.523: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-custom-resource-definition-ldzdc
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 21 18:19:12.712: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:19:18.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-ldzdc" for this suite.
Feb 21 18:19:24.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:19:24.853: INFO: namespace: e2e-tests-custom-resource-definition-ldzdc, resource: bindings, ignored listing per whitelist
Feb 21 18:19:24.957: INFO: namespace e2e-tests-custom-resource-definition-ldzdc deletion completed in 6.158890749s

• [SLOW TEST:12.434 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:19:24.957: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-zvt44
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-zvt44
Feb 21 18:19:27.169: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-zvt44
STEP: checking the pod's current state and verifying that restartCount is present
Feb 21 18:19:27.173: INFO: Initial restart count of pod liveness-exec is 0
Feb 21 18:20:13.323: INFO: Restart count of pod e2e-tests-container-probe-zvt44/liveness-exec is now 1 (46.150092977s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:20:13.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-zvt44" for this suite.
Feb 21 18:20:19.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:20:19.480: INFO: namespace: e2e-tests-container-probe-zvt44, resource: bindings, ignored listing per whitelist
Feb 21 18:20:19.495: INFO: namespace e2e-tests-container-probe-zvt44 deletion completed in 6.152766166s

• [SLOW TEST:54.538 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:20:19.495: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-s26wq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-585e69b8-3605-11e9-816d-1a333d676433
STEP: Creating a pod to test consume secrets
Feb 21 18:20:19.701: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-585f5853-3605-11e9-816d-1a333d676433" in namespace "e2e-tests-projected-s26wq" to be "success or failure"
Feb 21 18:20:19.708: INFO: Pod "pod-projected-secrets-585f5853-3605-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 6.747952ms
Feb 21 18:20:21.713: INFO: Pod "pod-projected-secrets-585f5853-3605-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01115577s
Feb 21 18:20:23.728: INFO: Pod "pod-projected-secrets-585f5853-3605-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026679356s
STEP: Saw pod success
Feb 21 18:20:23.728: INFO: Pod "pod-projected-secrets-585f5853-3605-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:20:23.732: INFO: Trying to get logs from node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c pod pod-projected-secrets-585f5853-3605-11e9-816d-1a333d676433 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 21 18:20:23.766: INFO: Waiting for pod pod-projected-secrets-585f5853-3605-11e9-816d-1a333d676433 to disappear
Feb 21 18:20:23.770: INFO: Pod pod-projected-secrets-585f5853-3605-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:20:23.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-s26wq" for this suite.
Feb 21 18:20:29.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:20:29.863: INFO: namespace: e2e-tests-projected-s26wq, resource: bindings, ignored listing per whitelist
Feb 21 18:20:29.923: INFO: namespace e2e-tests-projected-s26wq deletion completed in 6.149215272s

• [SLOW TEST:10.428 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:20:29.924: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-sp45z
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 21 18:20:30.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-sp45z'
Feb 21 18:20:30.208: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 21 18:20:30.208: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Feb 21 18:20:30.220: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Feb 21 18:20:30.220: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Feb 21 18:20:30.230: INFO: scanned /root for discovery docs: <nil>
Feb 21 18:20:30.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-sp45z'
Feb 21 18:20:46.049: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 21 18:20:46.049: INFO: stdout: "Created e2e-test-nginx-rc-cb5b9ac350267af3ea2772a96d33b007\nScaling up e2e-test-nginx-rc-cb5b9ac350267af3ea2772a96d33b007 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-cb5b9ac350267af3ea2772a96d33b007 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-cb5b9ac350267af3ea2772a96d33b007 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Feb 21 18:20:46.050: INFO: stdout: "Created e2e-test-nginx-rc-cb5b9ac350267af3ea2772a96d33b007\nScaling up e2e-test-nginx-rc-cb5b9ac350267af3ea2772a96d33b007 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-cb5b9ac350267af3ea2772a96d33b007 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-cb5b9ac350267af3ea2772a96d33b007 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Feb 21 18:20:46.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-sp45z'
Feb 21 18:20:46.125: INFO: stderr: ""
Feb 21 18:20:46.125: INFO: stdout: "e2e-test-nginx-rc-cb5b9ac350267af3ea2772a96d33b007-m8vhk "
Feb 21 18:20:46.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods e2e-test-nginx-rc-cb5b9ac350267af3ea2772a96d33b007-m8vhk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sp45z'
Feb 21 18:20:46.201: INFO: stderr: ""
Feb 21 18:20:46.201: INFO: stdout: "true"
Feb 21 18:20:46.201: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods e2e-test-nginx-rc-cb5b9ac350267af3ea2772a96d33b007-m8vhk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sp45z'
Feb 21 18:20:46.280: INFO: stderr: ""
Feb 21 18:20:46.280: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Feb 21 18:20:46.280: INFO: e2e-test-nginx-rc-cb5b9ac350267af3ea2772a96d33b007-m8vhk is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Feb 21 18:20:46.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-sp45z'
Feb 21 18:20:46.367: INFO: stderr: ""
Feb 21 18:20:46.367: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:20:46.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-sp45z" for this suite.
Feb 21 18:21:08.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:21:08.506: INFO: namespace: e2e-tests-kubectl-sp45z, resource: bindings, ignored listing per whitelist
Feb 21 18:21:08.542: INFO: namespace e2e-tests-kubectl-sp45z deletion completed in 22.169816068s

• [SLOW TEST:38.618 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:21:08.542: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-kg7mr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 21 18:21:08.746: INFO: Waiting up to 5m0s for pod "pod-759aace0-3605-11e9-816d-1a333d676433" in namespace "e2e-tests-emptydir-kg7mr" to be "success or failure"
Feb 21 18:21:08.750: INFO: Pod "pod-759aace0-3605-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 3.680889ms
Feb 21 18:21:10.755: INFO: Pod "pod-759aace0-3605-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008492122s
Feb 21 18:21:12.760: INFO: Pod "pod-759aace0-3605-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013629703s
STEP: Saw pod success
Feb 21 18:21:12.760: INFO: Pod "pod-759aace0-3605-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:21:12.763: INFO: Trying to get logs from node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c pod pod-759aace0-3605-11e9-816d-1a333d676433 container test-container: <nil>
STEP: delete the pod
Feb 21 18:21:12.789: INFO: Waiting for pod pod-759aace0-3605-11e9-816d-1a333d676433 to disappear
Feb 21 18:21:12.793: INFO: Pod pod-759aace0-3605-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:21:12.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-kg7mr" for this suite.
Feb 21 18:21:18.825: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:21:18.872: INFO: namespace: e2e-tests-emptydir-kg7mr, resource: bindings, ignored listing per whitelist
Feb 21 18:21:18.974: INFO: namespace e2e-tests-emptydir-kg7mr deletion completed in 6.176694048s

• [SLOW TEST:10.433 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:21:18.975: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-k6f5s
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 21 18:21:19.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 version'
Feb 21 18:21:19.237: INFO: stderr: ""
Feb 21 18:21:19.237: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.3\", GitCommit:\"721bfa751924da8d1680787490c54b9179b1fed0\", GitTreeState:\"clean\", BuildDate:\"2019-02-01T20:00:57Z\", GoVersion:\"go1.11.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:21:19.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-k6f5s" for this suite.
Feb 21 18:21:25.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:21:25.380: INFO: namespace: e2e-tests-kubectl-k6f5s, resource: bindings, ignored listing per whitelist
Feb 21 18:21:25.388: INFO: namespace e2e-tests-kubectl-k6f5s deletion completed in 6.146249366s

• [SLOW TEST:6.414 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:21:25.388: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-jf45d
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 21 18:21:25.580: INFO: Waiting up to 5m0s for pod "pod-7fa3f612-3605-11e9-816d-1a333d676433" in namespace "e2e-tests-emptydir-jf45d" to be "success or failure"
Feb 21 18:21:25.585: INFO: Pod "pod-7fa3f612-3605-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 4.655211ms
Feb 21 18:21:27.589: INFO: Pod "pod-7fa3f612-3605-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009473321s
STEP: Saw pod success
Feb 21 18:21:27.590: INFO: Pod "pod-7fa3f612-3605-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:21:27.593: INFO: Trying to get logs from node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c pod pod-7fa3f612-3605-11e9-816d-1a333d676433 container test-container: <nil>
STEP: delete the pod
Feb 21 18:21:27.618: INFO: Waiting for pod pod-7fa3f612-3605-11e9-816d-1a333d676433 to disappear
Feb 21 18:21:27.621: INFO: Pod pod-7fa3f612-3605-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:21:27.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jf45d" for this suite.
Feb 21 18:21:33.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:21:33.759: INFO: namespace: e2e-tests-emptydir-jf45d, resource: bindings, ignored listing per whitelist
Feb 21 18:21:33.783: INFO: namespace e2e-tests-emptydir-jf45d deletion completed in 6.157095653s

• [SLOW TEST:8.394 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:21:33.783: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-tj58p
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 21 18:21:36.522: INFO: Successfully updated pod "labelsupdate84a63829-3605-11e9-816d-1a333d676433"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:21:38.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-tj58p" for this suite.
Feb 21 18:22:00.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:22:00.705: INFO: namespace: e2e-tests-downward-api-tj58p, resource: bindings, ignored listing per whitelist
Feb 21 18:22:00.705: INFO: namespace e2e-tests-downward-api-tj58p deletion completed in 22.157761331s

• [SLOW TEST:26.923 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:22:00.706: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-hd6gj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 21 18:22:00.905: INFO: Waiting up to 5m0s for pod "downwardapi-volume-94b21a92-3605-11e9-816d-1a333d676433" in namespace "e2e-tests-projected-hd6gj" to be "success or failure"
Feb 21 18:22:00.911: INFO: Pod "downwardapi-volume-94b21a92-3605-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 5.663238ms
Feb 21 18:22:02.923: INFO: Pod "downwardapi-volume-94b21a92-3605-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017987391s
Feb 21 18:22:04.928: INFO: Pod "downwardapi-volume-94b21a92-3605-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022990956s
STEP: Saw pod success
Feb 21 18:22:04.928: INFO: Pod "downwardapi-volume-94b21a92-3605-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:22:04.932: INFO: Trying to get logs from node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c pod downwardapi-volume-94b21a92-3605-11e9-816d-1a333d676433 container client-container: <nil>
STEP: delete the pod
Feb 21 18:22:04.962: INFO: Waiting for pod downwardapi-volume-94b21a92-3605-11e9-816d-1a333d676433 to disappear
Feb 21 18:22:04.965: INFO: Pod downwardapi-volume-94b21a92-3605-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:22:04.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hd6gj" for this suite.
Feb 21 18:22:10.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:22:11.080: INFO: namespace: e2e-tests-projected-hd6gj, resource: bindings, ignored listing per whitelist
Feb 21 18:22:11.120: INFO: namespace e2e-tests-projected-hd6gj deletion completed in 6.150436498s

• [SLOW TEST:10.414 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:22:11.120: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-jvt9h
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-jvt9h A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-jvt9h;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-jvt9h A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-jvt9h;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-jvt9h.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-jvt9h.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-jvt9h.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-jvt9h.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-jvt9h.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-jvt9h.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-jvt9h.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-jvt9h.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-jvt9h.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-jvt9h.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-jvt9h.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-jvt9h.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-jvt9h.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 87.200.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.200.87_udp@PTR;check="$$(dig +tcp +noall +answer +search 87.200.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.200.87_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-jvt9h A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-jvt9h;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-jvt9h A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-jvt9h;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-jvt9h.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-jvt9h.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-jvt9h.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-jvt9h.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-jvt9h.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-jvt9h.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-jvt9h.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-jvt9h.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-jvt9h.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-jvt9h.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-jvt9h.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-jvt9h.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-jvt9h.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 87.200.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.200.87_udp@PTR;check="$$(dig +tcp +noall +answer +search 87.200.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.200.87_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 21 18:22:23.365: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-jvt9h/dns-test-9aeaa63a-3605-11e9-816d-1a333d676433: the server could not find the requested resource (get pods dns-test-9aeaa63a-3605-11e9-816d-1a333d676433)
Feb 21 18:22:23.377: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-jvt9h/dns-test-9aeaa63a-3605-11e9-816d-1a333d676433: the server could not find the requested resource (get pods dns-test-9aeaa63a-3605-11e9-816d-1a333d676433)
Feb 21 18:22:23.382: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-jvt9h from pod e2e-tests-dns-jvt9h/dns-test-9aeaa63a-3605-11e9-816d-1a333d676433: the server could not find the requested resource (get pods dns-test-9aeaa63a-3605-11e9-816d-1a333d676433)
Feb 21 18:22:23.387: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-jvt9h from pod e2e-tests-dns-jvt9h/dns-test-9aeaa63a-3605-11e9-816d-1a333d676433: the server could not find the requested resource (get pods dns-test-9aeaa63a-3605-11e9-816d-1a333d676433)
Feb 21 18:22:23.391: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-jvt9h.svc from pod e2e-tests-dns-jvt9h/dns-test-9aeaa63a-3605-11e9-816d-1a333d676433: the server could not find the requested resource (get pods dns-test-9aeaa63a-3605-11e9-816d-1a333d676433)
Feb 21 18:22:23.396: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-jvt9h.svc from pod e2e-tests-dns-jvt9h/dns-test-9aeaa63a-3605-11e9-816d-1a333d676433: the server could not find the requested resource (get pods dns-test-9aeaa63a-3605-11e9-816d-1a333d676433)
Feb 21 18:22:23.401: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-jvt9h.svc from pod e2e-tests-dns-jvt9h/dns-test-9aeaa63a-3605-11e9-816d-1a333d676433: the server could not find the requested resource (get pods dns-test-9aeaa63a-3605-11e9-816d-1a333d676433)
Feb 21 18:22:23.406: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-jvt9h.svc from pod e2e-tests-dns-jvt9h/dns-test-9aeaa63a-3605-11e9-816d-1a333d676433: the server could not find the requested resource (get pods dns-test-9aeaa63a-3605-11e9-816d-1a333d676433)
Feb 21 18:22:23.445: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-jvt9h/dns-test-9aeaa63a-3605-11e9-816d-1a333d676433: the server could not find the requested resource (get pods dns-test-9aeaa63a-3605-11e9-816d-1a333d676433)
Feb 21 18:22:23.450: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-jvt9h/dns-test-9aeaa63a-3605-11e9-816d-1a333d676433: the server could not find the requested resource (get pods dns-test-9aeaa63a-3605-11e9-816d-1a333d676433)
Feb 21 18:22:23.455: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-jvt9h from pod e2e-tests-dns-jvt9h/dns-test-9aeaa63a-3605-11e9-816d-1a333d676433: the server could not find the requested resource (get pods dns-test-9aeaa63a-3605-11e9-816d-1a333d676433)
Feb 21 18:22:23.459: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-jvt9h from pod e2e-tests-dns-jvt9h/dns-test-9aeaa63a-3605-11e9-816d-1a333d676433: the server could not find the requested resource (get pods dns-test-9aeaa63a-3605-11e9-816d-1a333d676433)
Feb 21 18:22:23.464: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-jvt9h.svc from pod e2e-tests-dns-jvt9h/dns-test-9aeaa63a-3605-11e9-816d-1a333d676433: the server could not find the requested resource (get pods dns-test-9aeaa63a-3605-11e9-816d-1a333d676433)
Feb 21 18:22:23.469: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-jvt9h.svc from pod e2e-tests-dns-jvt9h/dns-test-9aeaa63a-3605-11e9-816d-1a333d676433: the server could not find the requested resource (get pods dns-test-9aeaa63a-3605-11e9-816d-1a333d676433)
Feb 21 18:22:23.473: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-jvt9h.svc from pod e2e-tests-dns-jvt9h/dns-test-9aeaa63a-3605-11e9-816d-1a333d676433: the server could not find the requested resource (get pods dns-test-9aeaa63a-3605-11e9-816d-1a333d676433)
Feb 21 18:22:23.478: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-jvt9h.svc from pod e2e-tests-dns-jvt9h/dns-test-9aeaa63a-3605-11e9-816d-1a333d676433: the server could not find the requested resource (get pods dns-test-9aeaa63a-3605-11e9-816d-1a333d676433)
Feb 21 18:22:23.508: INFO: Lookups using e2e-tests-dns-jvt9h/dns-test-9aeaa63a-3605-11e9-816d-1a333d676433 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-jvt9h wheezy_tcp@dns-test-service.e2e-tests-dns-jvt9h wheezy_udp@dns-test-service.e2e-tests-dns-jvt9h.svc wheezy_tcp@dns-test-service.e2e-tests-dns-jvt9h.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-jvt9h.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-jvt9h.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-jvt9h jessie_tcp@dns-test-service.e2e-tests-dns-jvt9h jessie_udp@dns-test-service.e2e-tests-dns-jvt9h.svc jessie_tcp@dns-test-service.e2e-tests-dns-jvt9h.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-jvt9h.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-jvt9h.svc]

Feb 21 18:22:28.643: INFO: DNS probes using e2e-tests-dns-jvt9h/dns-test-9aeaa63a-3605-11e9-816d-1a333d676433 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:22:28.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-jvt9h" for this suite.
Feb 21 18:22:34.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:22:34.755: INFO: namespace: e2e-tests-dns-jvt9h, resource: bindings, ignored listing per whitelist
Feb 21 18:22:34.867: INFO: namespace e2e-tests-dns-jvt9h deletion completed in 6.153719767s

• [SLOW TEST:23.748 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:22:34.868: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-xpzsv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secret-namespace-4j95x
STEP: Creating secret with name secret-test-a90f1eda-3605-11e9-816d-1a333d676433
STEP: Creating a pod to test consume secrets
Feb 21 18:22:35.222: INFO: Waiting up to 5m0s for pod "pod-secrets-a926a0db-3605-11e9-816d-1a333d676433" in namespace "e2e-tests-secrets-xpzsv" to be "success or failure"
Feb 21 18:22:35.228: INFO: Pod "pod-secrets-a926a0db-3605-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 5.937783ms
Feb 21 18:22:37.233: INFO: Pod "pod-secrets-a926a0db-3605-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010828027s
STEP: Saw pod success
Feb 21 18:22:37.233: INFO: Pod "pod-secrets-a926a0db-3605-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:22:37.237: INFO: Trying to get logs from node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c pod pod-secrets-a926a0db-3605-11e9-816d-1a333d676433 container secret-volume-test: <nil>
STEP: delete the pod
Feb 21 18:22:37.264: INFO: Waiting for pod pod-secrets-a926a0db-3605-11e9-816d-1a333d676433 to disappear
Feb 21 18:22:37.268: INFO: Pod pod-secrets-a926a0db-3605-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:22:37.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-xpzsv" for this suite.
Feb 21 18:22:43.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:22:43.412: INFO: namespace: e2e-tests-secrets-xpzsv, resource: bindings, ignored listing per whitelist
Feb 21 18:22:43.424: INFO: namespace e2e-tests-secrets-xpzsv deletion completed in 6.152369333s
STEP: Destroying namespace "e2e-tests-secret-namespace-4j95x" for this suite.
Feb 21 18:22:49.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:22:49.487: INFO: namespace: e2e-tests-secret-namespace-4j95x, resource: bindings, ignored listing per whitelist
Feb 21 18:22:49.577: INFO: namespace e2e-tests-secret-namespace-4j95x deletion completed in 6.152683316s

• [SLOW TEST:14.709 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:22:49.577: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-d5588
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Feb 21 18:22:49.772: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 create -f - --namespace=e2e-tests-kubectl-d5588'
Feb 21 18:22:49.992: INFO: stderr: ""
Feb 21 18:22:49.992: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 21 18:22:49.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-d5588'
Feb 21 18:22:50.072: INFO: stderr: ""
Feb 21 18:22:50.072: INFO: stdout: "update-demo-nautilus-shnp9 update-demo-nautilus-tbjlx "
Feb 21 18:22:50.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods update-demo-nautilus-shnp9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-d5588'
Feb 21 18:22:50.144: INFO: stderr: ""
Feb 21 18:22:50.144: INFO: stdout: ""
Feb 21 18:22:50.144: INFO: update-demo-nautilus-shnp9 is created but not running
Feb 21 18:22:55.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-d5588'
Feb 21 18:22:55.226: INFO: stderr: ""
Feb 21 18:22:55.226: INFO: stdout: "update-demo-nautilus-shnp9 update-demo-nautilus-tbjlx "
Feb 21 18:22:55.226: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods update-demo-nautilus-shnp9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-d5588'
Feb 21 18:22:55.303: INFO: stderr: ""
Feb 21 18:22:55.303: INFO: stdout: "true"
Feb 21 18:22:55.303: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods update-demo-nautilus-shnp9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-d5588'
Feb 21 18:22:55.374: INFO: stderr: ""
Feb 21 18:22:55.374: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 21 18:22:55.374: INFO: validating pod update-demo-nautilus-shnp9
Feb 21 18:22:55.382: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 21 18:22:55.382: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 21 18:22:55.382: INFO: update-demo-nautilus-shnp9 is verified up and running
Feb 21 18:22:55.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods update-demo-nautilus-tbjlx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-d5588'
Feb 21 18:22:55.465: INFO: stderr: ""
Feb 21 18:22:55.465: INFO: stdout: "true"
Feb 21 18:22:55.466: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods update-demo-nautilus-tbjlx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-d5588'
Feb 21 18:22:55.541: INFO: stderr: ""
Feb 21 18:22:55.541: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 21 18:22:55.541: INFO: validating pod update-demo-nautilus-tbjlx
Feb 21 18:22:55.549: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 21 18:22:55.550: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 21 18:22:55.550: INFO: update-demo-nautilus-tbjlx is verified up and running
STEP: rolling-update to new replication controller
Feb 21 18:22:55.551: INFO: scanned /root for discovery docs: <nil>
Feb 21 18:22:55.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-d5588'
Feb 21 18:23:18.040: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 21 18:23:18.040: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 21 18:23:18.040: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-d5588'
Feb 21 18:23:18.120: INFO: stderr: ""
Feb 21 18:23:18.120: INFO: stdout: "update-demo-kitten-28fdl update-demo-kitten-qcpsv "
Feb 21 18:23:18.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods update-demo-kitten-28fdl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-d5588'
Feb 21 18:23:18.196: INFO: stderr: ""
Feb 21 18:23:18.196: INFO: stdout: "true"
Feb 21 18:23:18.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods update-demo-kitten-28fdl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-d5588'
Feb 21 18:23:18.275: INFO: stderr: ""
Feb 21 18:23:18.275: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 21 18:23:18.275: INFO: validating pod update-demo-kitten-28fdl
Feb 21 18:23:18.282: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 21 18:23:18.282: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 21 18:23:18.282: INFO: update-demo-kitten-28fdl is verified up and running
Feb 21 18:23:18.282: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods update-demo-kitten-qcpsv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-d5588'
Feb 21 18:23:18.355: INFO: stderr: ""
Feb 21 18:23:18.356: INFO: stdout: "true"
Feb 21 18:23:18.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods update-demo-kitten-qcpsv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-d5588'
Feb 21 18:23:18.435: INFO: stderr: ""
Feb 21 18:23:18.435: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 21 18:23:18.435: INFO: validating pod update-demo-kitten-qcpsv
Feb 21 18:23:18.442: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 21 18:23:18.442: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 21 18:23:18.442: INFO: update-demo-kitten-qcpsv is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:23:18.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-d5588" for this suite.
Feb 21 18:23:40.475: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:23:40.514: INFO: namespace: e2e-tests-kubectl-d5588, resource: bindings, ignored listing per whitelist
Feb 21 18:23:40.634: INFO: namespace e2e-tests-kubectl-d5588 deletion completed in 22.186852671s

• [SLOW TEST:51.057 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:23:40.635: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-lxkql
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 21 18:23:40.853: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Feb 21 18:23:45.858: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 21 18:23:45.858: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 21 18:23:45.880: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-lxkql,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lxkql/deployments/test-cleanup-deployment,UID:d343332d-3605-11e9-bacd-42010a000102,ResourceVersion:7618,Generation:1,CreationTimestamp:2019-02-21 18:23:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Feb 21 18:23:45.888: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Feb 21 18:23:45.888: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Feb 21 18:23:45.889: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-lxkql,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lxkql/replicasets/test-cleanup-controller,UID:d044433b-3605-11e9-bacd-42010a000102,ResourceVersion:7619,Generation:1,CreationTimestamp:2019-02-21 18:23:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment d343332d-3605-11e9-bacd-42010a000102 0xc001d1d79f 0xc001d1d7b0}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 21 18:23:45.899: INFO: Pod "test-cleanup-controller-phqj9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-phqj9,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-lxkql,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lxkql/pods/test-cleanup-controller-phqj9,UID:d0472336-3605-11e9-8547-42010a000100,ResourceVersion:7612,Generation:0,CreationTimestamp:2019-02-21 18:23:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller d044433b-3605-11e9-bacd-42010a000102 0xc001d1de7f 0xc001d1de90}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fzpxj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fzpxj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fzpxj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d1def0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d1df10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 18:23:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 18:23:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 18:23:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 18:23:40 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.4,PodIP:10.200.10.19,StartTime:2019-02-21 18:23:40 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-21 18:23:42 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://6cf07c78eecde347d99d098c6fe8da28c9aa8317d6bac3b9e52345b0c7e6a35b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:23:45.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-lxkql" for this suite.
Feb 21 18:23:51.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:23:51.972: INFO: namespace: e2e-tests-deployment-lxkql, resource: bindings, ignored listing per whitelist
Feb 21 18:23:52.087: INFO: namespace e2e-tests-deployment-lxkql deletion completed in 6.179664555s

• [SLOW TEST:11.452 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:23:52.087: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-g9rwv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:23:56.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-g9rwv" for this suite.
Feb 21 18:24:34.353: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:24:34.462: INFO: namespace: e2e-tests-kubelet-test-g9rwv, resource: bindings, ignored listing per whitelist
Feb 21 18:24:34.476: INFO: namespace e2e-tests-kubelet-test-g9rwv deletion completed in 38.143520628s

• [SLOW TEST:42.389 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:24:34.476: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-26xlv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 21 18:24:34.707: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Feb 21 18:24:34.719: INFO: Number of nodes with available pods: 0
Feb 21 18:24:34.719: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Feb 21 18:24:34.741: INFO: Number of nodes with available pods: 0
Feb 21 18:24:34.741: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:24:35.746: INFO: Number of nodes with available pods: 0
Feb 21 18:24:35.746: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:24:36.752: INFO: Number of nodes with available pods: 0
Feb 21 18:24:36.752: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:24:37.746: INFO: Number of nodes with available pods: 1
Feb 21 18:24:37.746: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Feb 21 18:24:37.769: INFO: Number of nodes with available pods: 1
Feb 21 18:24:37.769: INFO: Number of running nodes: 0, number of available pods: 1
Feb 21 18:24:38.774: INFO: Number of nodes with available pods: 0
Feb 21 18:24:38.774: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Feb 21 18:24:38.788: INFO: Number of nodes with available pods: 0
Feb 21 18:24:38.788: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:24:39.793: INFO: Number of nodes with available pods: 0
Feb 21 18:24:39.793: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:24:40.793: INFO: Number of nodes with available pods: 0
Feb 21 18:24:40.793: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:24:41.792: INFO: Number of nodes with available pods: 0
Feb 21 18:24:41.793: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:24:42.793: INFO: Number of nodes with available pods: 0
Feb 21 18:24:42.793: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:24:43.792: INFO: Number of nodes with available pods: 0
Feb 21 18:24:43.792: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:24:44.792: INFO: Number of nodes with available pods: 0
Feb 21 18:24:44.793: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:24:45.792: INFO: Number of nodes with available pods: 0
Feb 21 18:24:45.792: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:24:46.800: INFO: Number of nodes with available pods: 0
Feb 21 18:24:46.800: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:24:47.792: INFO: Number of nodes with available pods: 0
Feb 21 18:24:47.792: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:24:48.792: INFO: Number of nodes with available pods: 0
Feb 21 18:24:48.793: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:24:49.793: INFO: Number of nodes with available pods: 0
Feb 21 18:24:49.793: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:24:50.793: INFO: Number of nodes with available pods: 0
Feb 21 18:24:50.793: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:24:51.792: INFO: Number of nodes with available pods: 0
Feb 21 18:24:51.792: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:24:52.793: INFO: Number of nodes with available pods: 0
Feb 21 18:24:52.793: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:24:53.793: INFO: Number of nodes with available pods: 0
Feb 21 18:24:53.793: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:24:54.793: INFO: Number of nodes with available pods: 0
Feb 21 18:24:54.793: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:24:55.793: INFO: Number of nodes with available pods: 0
Feb 21 18:24:55.793: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:24:56.793: INFO: Number of nodes with available pods: 0
Feb 21 18:24:56.793: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:24:57.801: INFO: Number of nodes with available pods: 0
Feb 21 18:24:57.801: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:24:58.793: INFO: Number of nodes with available pods: 0
Feb 21 18:24:58.793: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:24:59.792: INFO: Number of nodes with available pods: 0
Feb 21 18:24:59.792: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:25:00.794: INFO: Number of nodes with available pods: 0
Feb 21 18:25:00.794: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:25:01.792: INFO: Number of nodes with available pods: 0
Feb 21 18:25:01.792: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:25:02.793: INFO: Number of nodes with available pods: 0
Feb 21 18:25:02.793: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:25:03.792: INFO: Number of nodes with available pods: 0
Feb 21 18:25:03.792: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:25:04.793: INFO: Number of nodes with available pods: 0
Feb 21 18:25:04.793: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:25:05.793: INFO: Number of nodes with available pods: 0
Feb 21 18:25:05.793: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:25:06.793: INFO: Number of nodes with available pods: 0
Feb 21 18:25:06.793: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:25:07.793: INFO: Number of nodes with available pods: 0
Feb 21 18:25:07.793: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:25:08.800: INFO: Number of nodes with available pods: 0
Feb 21 18:25:08.800: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:25:09.793: INFO: Number of nodes with available pods: 0
Feb 21 18:25:09.793: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:25:10.793: INFO: Number of nodes with available pods: 0
Feb 21 18:25:10.793: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:25:11.794: INFO: Number of nodes with available pods: 0
Feb 21 18:25:11.794: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:25:12.792: INFO: Number of nodes with available pods: 0
Feb 21 18:25:12.792: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:25:13.793: INFO: Number of nodes with available pods: 0
Feb 21 18:25:13.793: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:25:14.793: INFO: Number of nodes with available pods: 0
Feb 21 18:25:14.793: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:25:15.793: INFO: Number of nodes with available pods: 0
Feb 21 18:25:15.793: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:25:16.793: INFO: Number of nodes with available pods: 0
Feb 21 18:25:16.793: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:25:17.793: INFO: Number of nodes with available pods: 1
Feb 21 18:25:17.793: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-26xlv, will wait for the garbage collector to delete the pods
Feb 21 18:25:17.865: INFO: Deleting DaemonSet.extensions daemon-set took: 11.386115ms
Feb 21 18:25:17.965: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.490076ms
Feb 21 18:25:51.576: INFO: Number of nodes with available pods: 0
Feb 21 18:25:51.576: INFO: Number of running nodes: 0, number of available pods: 0
Feb 21 18:25:51.579: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-26xlv/daemonsets","resourceVersion":"7942"},"items":null}

Feb 21 18:25:51.582: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-26xlv/pods","resourceVersion":"7942"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:25:51.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-26xlv" for this suite.
Feb 21 18:25:57.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:25:57.699: INFO: namespace: e2e-tests-daemonsets-26xlv, resource: bindings, ignored listing per whitelist
Feb 21 18:25:57.763: INFO: namespace e2e-tests-daemonsets-26xlv deletion completed in 6.155041823s

• [SLOW TEST:83.287 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:25:57.763: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-e2e-kubelet-etc-hosts-dhjwg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Feb 21 18:26:04.008: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dhjwg PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 21 18:26:04.008: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
Feb 21 18:26:04.105: INFO: Exec stderr: ""
Feb 21 18:26:04.105: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dhjwg PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 21 18:26:04.105: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
Feb 21 18:26:04.201: INFO: Exec stderr: ""
Feb 21 18:26:04.201: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dhjwg PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 21 18:26:04.201: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
Feb 21 18:26:04.295: INFO: Exec stderr: ""
Feb 21 18:26:04.295: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dhjwg PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 21 18:26:04.295: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
Feb 21 18:26:04.389: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Feb 21 18:26:04.390: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dhjwg PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 21 18:26:04.390: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
Feb 21 18:26:04.479: INFO: Exec stderr: ""
Feb 21 18:26:04.479: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dhjwg PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 21 18:26:04.479: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
Feb 21 18:26:04.564: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Feb 21 18:26:04.564: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dhjwg PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 21 18:26:04.564: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
Feb 21 18:26:04.651: INFO: Exec stderr: ""
Feb 21 18:26:04.651: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dhjwg PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 21 18:26:04.651: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
Feb 21 18:26:04.740: INFO: Exec stderr: ""
Feb 21 18:26:04.740: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dhjwg PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 21 18:26:04.740: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
Feb 21 18:26:04.820: INFO: Exec stderr: ""
Feb 21 18:26:04.820: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dhjwg PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 21 18:26:04.821: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
Feb 21 18:26:04.912: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:26:04.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-dhjwg" for this suite.
Feb 21 18:26:50.936: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:26:50.970: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-dhjwg, resource: bindings, ignored listing per whitelist
Feb 21 18:26:51.101: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-dhjwg deletion completed in 46.183503416s

• [SLOW TEST:53.338 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:26:51.101: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-m959c
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-m959c
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-m959c
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-m959c
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-m959c
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-m959c
Feb 21 18:26:53.350: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-m959c, name: ss-0, uid: 41db00ce-3606-11e9-8547-42010a000100, status phase: Pending. Waiting for statefulset controller to delete.
Feb 21 18:26:55.400: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-m959c, name: ss-0, uid: 41db00ce-3606-11e9-8547-42010a000100, status phase: Failed. Waiting for statefulset controller to delete.
Feb 21 18:26:55.413: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-m959c, name: ss-0, uid: 41db00ce-3606-11e9-8547-42010a000100, status phase: Failed. Waiting for statefulset controller to delete.
Feb 21 18:26:55.420: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-m959c
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-m959c
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-m959c and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 21 18:26:57.450: INFO: Deleting all statefulset in ns e2e-tests-statefulset-m959c
Feb 21 18:26:57.454: INFO: Scaling statefulset ss to 0
Feb 21 18:27:07.482: INFO: Waiting for statefulset status.replicas updated to 0
Feb 21 18:27:07.485: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:27:07.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-m959c" for this suite.
Feb 21 18:27:13.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:27:13.629: INFO: namespace: e2e-tests-statefulset-m959c, resource: bindings, ignored listing per whitelist
Feb 21 18:27:13.667: INFO: namespace e2e-tests-statefulset-m959c deletion completed in 6.160463133s

• [SLOW TEST:22.566 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:27:13.667: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-qs26w
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-4f3f2d28-3606-11e9-816d-1a333d676433
STEP: Creating a pod to test consume configMaps
Feb 21 18:27:13.893: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4f4043e6-3606-11e9-816d-1a333d676433" in namespace "e2e-tests-projected-qs26w" to be "success or failure"
Feb 21 18:27:13.898: INFO: Pod "pod-projected-configmaps-4f4043e6-3606-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 5.444273ms
Feb 21 18:27:15.903: INFO: Pod "pod-projected-configmaps-4f4043e6-3606-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010013588s
STEP: Saw pod success
Feb 21 18:27:15.903: INFO: Pod "pod-projected-configmaps-4f4043e6-3606-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:27:15.907: INFO: Trying to get logs from node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c pod pod-projected-configmaps-4f4043e6-3606-11e9-816d-1a333d676433 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 21 18:27:15.935: INFO: Waiting for pod pod-projected-configmaps-4f4043e6-3606-11e9-816d-1a333d676433 to disappear
Feb 21 18:27:15.938: INFO: Pod pod-projected-configmaps-4f4043e6-3606-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:27:15.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qs26w" for this suite.
Feb 21 18:27:21.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:27:21.992: INFO: namespace: e2e-tests-projected-qs26w, resource: bindings, ignored listing per whitelist
Feb 21 18:27:22.109: INFO: namespace e2e-tests-projected-qs26w deletion completed in 6.165808863s

• [SLOW TEST:8.442 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:27:22.109: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-pfmk5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 21 18:27:22.369: INFO: Waiting up to 5m0s for pod "pod-544db38d-3606-11e9-816d-1a333d676433" in namespace "e2e-tests-emptydir-pfmk5" to be "success or failure"
Feb 21 18:27:22.373: INFO: Pod "pod-544db38d-3606-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 4.386593ms
Feb 21 18:27:24.378: INFO: Pod "pod-544db38d-3606-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008925771s
Feb 21 18:27:26.382: INFO: Pod "pod-544db38d-3606-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013743232s
STEP: Saw pod success
Feb 21 18:27:26.383: INFO: Pod "pod-544db38d-3606-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:27:26.386: INFO: Trying to get logs from node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c pod pod-544db38d-3606-11e9-816d-1a333d676433 container test-container: <nil>
STEP: delete the pod
Feb 21 18:27:26.412: INFO: Waiting for pod pod-544db38d-3606-11e9-816d-1a333d676433 to disappear
Feb 21 18:27:26.416: INFO: Pod pod-544db38d-3606-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:27:26.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-pfmk5" for this suite.
Feb 21 18:27:32.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:27:32.558: INFO: namespace: e2e-tests-emptydir-pfmk5, resource: bindings, ignored listing per whitelist
Feb 21 18:27:32.573: INFO: namespace e2e-tests-emptydir-pfmk5 deletion completed in 6.152933339s

• [SLOW TEST:10.464 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:27:32.574: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-2njlf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-5a825da1-3606-11e9-816d-1a333d676433
STEP: Creating a pod to test consume secrets
Feb 21 18:27:32.788: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5a83518b-3606-11e9-816d-1a333d676433" in namespace "e2e-tests-projected-2njlf" to be "success or failure"
Feb 21 18:27:32.793: INFO: Pod "pod-projected-secrets-5a83518b-3606-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 5.004763ms
Feb 21 18:27:34.797: INFO: Pod "pod-projected-secrets-5a83518b-3606-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009678819s
STEP: Saw pod success
Feb 21 18:27:34.798: INFO: Pod "pod-projected-secrets-5a83518b-3606-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:27:34.801: INFO: Trying to get logs from node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c pod pod-projected-secrets-5a83518b-3606-11e9-816d-1a333d676433 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 21 18:27:34.829: INFO: Waiting for pod pod-projected-secrets-5a83518b-3606-11e9-816d-1a333d676433 to disappear
Feb 21 18:27:34.833: INFO: Pod pod-projected-secrets-5a83518b-3606-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:27:34.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2njlf" for this suite.
Feb 21 18:27:40.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:27:40.906: INFO: namespace: e2e-tests-projected-2njlf, resource: bindings, ignored listing per whitelist
Feb 21 18:27:40.989: INFO: namespace e2e-tests-projected-2njlf deletion completed in 6.151774957s

• [SLOW TEST:8.416 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:27:40.989: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-mszpn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Feb 21 18:27:41.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 create -f - --namespace=e2e-tests-kubectl-mszpn'
Feb 21 18:27:41.579: INFO: stderr: ""
Feb 21 18:27:41.579: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 21 18:27:42.584: INFO: Selector matched 1 pods for map[app:redis]
Feb 21 18:27:42.584: INFO: Found 0 / 1
Feb 21 18:27:43.584: INFO: Selector matched 1 pods for map[app:redis]
Feb 21 18:27:43.584: INFO: Found 0 / 1
Feb 21 18:27:44.584: INFO: Selector matched 1 pods for map[app:redis]
Feb 21 18:27:44.584: INFO: Found 1 / 1
Feb 21 18:27:44.584: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Feb 21 18:27:44.588: INFO: Selector matched 1 pods for map[app:redis]
Feb 21 18:27:44.588: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 21 18:27:44.588: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 patch pod redis-master-shskl --namespace=e2e-tests-kubectl-mszpn -p {"metadata":{"annotations":{"x":"y"}}}'
Feb 21 18:27:44.671: INFO: stderr: ""
Feb 21 18:27:44.671: INFO: stdout: "pod/redis-master-shskl patched\n"
STEP: checking annotations
Feb 21 18:27:44.675: INFO: Selector matched 1 pods for map[app:redis]
Feb 21 18:27:44.675: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:27:44.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mszpn" for this suite.
Feb 21 18:28:06.703: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:28:06.800: INFO: namespace: e2e-tests-kubectl-mszpn, resource: bindings, ignored listing per whitelist
Feb 21 18:28:06.852: INFO: namespace e2e-tests-kubectl-mszpn deletion completed in 22.172096337s

• [SLOW TEST:25.863 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:28:06.852: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-66hfr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-66hfr
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Feb 21 18:28:07.069: INFO: Found 0 stateful pods, waiting for 3
Feb 21 18:28:17.083: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 21 18:28:17.083: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 21 18:28:17.083: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb 21 18:28:17.118: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Feb 21 18:28:27.166: INFO: Updating stateful set ss2
Feb 21 18:28:27.174: INFO: Waiting for Pod e2e-tests-statefulset-66hfr/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Feb 21 18:28:37.262: INFO: Found 2 stateful pods, waiting for 3
Feb 21 18:28:47.277: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 21 18:28:47.277: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 21 18:28:47.277: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Feb 21 18:28:47.309: INFO: Updating stateful set ss2
Feb 21 18:28:47.319: INFO: Waiting for Pod e2e-tests-statefulset-66hfr/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 21 18:28:57.356: INFO: Updating stateful set ss2
Feb 21 18:28:57.365: INFO: Waiting for StatefulSet e2e-tests-statefulset-66hfr/ss2 to complete update
Feb 21 18:28:57.365: INFO: Waiting for Pod e2e-tests-statefulset-66hfr/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 21 18:29:07.384: INFO: Deleting all statefulset in ns e2e-tests-statefulset-66hfr
Feb 21 18:29:07.387: INFO: Scaling statefulset ss2 to 0
Feb 21 18:29:37.416: INFO: Waiting for statefulset status.replicas updated to 0
Feb 21 18:29:37.420: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:29:37.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-66hfr" for this suite.
Feb 21 18:29:43.466: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:29:43.581: INFO: namespace: e2e-tests-statefulset-66hfr, resource: bindings, ignored listing per whitelist
Feb 21 18:29:43.597: INFO: namespace e2e-tests-statefulset-66hfr deletion completed in 6.155887816s

• [SLOW TEST:96.745 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:29:43.598: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-ssbs8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Feb 21 18:29:43.799: INFO: Waiting up to 5m0s for pod "client-containers-a89a2aa8-3606-11e9-816d-1a333d676433" in namespace "e2e-tests-containers-ssbs8" to be "success or failure"
Feb 21 18:29:43.805: INFO: Pod "client-containers-a89a2aa8-3606-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 5.457643ms
Feb 21 18:29:45.809: INFO: Pod "client-containers-a89a2aa8-3606-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009815411s
Feb 21 18:29:47.820: INFO: Pod "client-containers-a89a2aa8-3606-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020829442s
STEP: Saw pod success
Feb 21 18:29:47.820: INFO: Pod "client-containers-a89a2aa8-3606-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:29:47.823: INFO: Trying to get logs from node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c pod client-containers-a89a2aa8-3606-11e9-816d-1a333d676433 container test-container: <nil>
STEP: delete the pod
Feb 21 18:29:47.850: INFO: Waiting for pod client-containers-a89a2aa8-3606-11e9-816d-1a333d676433 to disappear
Feb 21 18:29:47.853: INFO: Pod client-containers-a89a2aa8-3606-11e9-816d-1a333d676433 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:29:47.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-ssbs8" for this suite.
Feb 21 18:29:53.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:29:53.961: INFO: namespace: e2e-tests-containers-ssbs8, resource: bindings, ignored listing per whitelist
Feb 21 18:29:54.010: INFO: namespace e2e-tests-containers-ssbs8 deletion completed in 6.151649001s

• [SLOW TEST:10.412 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:29:54.010: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-2gc5n
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 21 18:29:54.213: INFO: Waiting up to 5m0s for pod "downwardapi-volume-aeceed49-3606-11e9-816d-1a333d676433" in namespace "e2e-tests-downward-api-2gc5n" to be "success or failure"
Feb 21 18:29:54.217: INFO: Pod "downwardapi-volume-aeceed49-3606-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 3.776888ms
Feb 21 18:29:56.222: INFO: Pod "downwardapi-volume-aeceed49-3606-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008801243s
STEP: Saw pod success
Feb 21 18:29:56.222: INFO: Pod "downwardapi-volume-aeceed49-3606-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:29:56.226: INFO: Trying to get logs from node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c pod downwardapi-volume-aeceed49-3606-11e9-816d-1a333d676433 container client-container: <nil>
STEP: delete the pod
Feb 21 18:29:56.251: INFO: Waiting for pod downwardapi-volume-aeceed49-3606-11e9-816d-1a333d676433 to disappear
Feb 21 18:29:56.254: INFO: Pod downwardapi-volume-aeceed49-3606-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:29:56.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2gc5n" for this suite.
Feb 21 18:30:02.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:30:02.354: INFO: namespace: e2e-tests-downward-api-2gc5n, resource: bindings, ignored listing per whitelist
Feb 21 18:30:02.456: INFO: namespace e2e-tests-downward-api-2gc5n deletion completed in 6.197260947s

• [SLOW TEST:8.446 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:30:02.456: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-4kgcq
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-b3da05fa-3606-11e9-816d-1a333d676433
STEP: Creating secret with name s-test-opt-upd-b3da0658-3606-11e9-816d-1a333d676433
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-b3da05fa-3606-11e9-816d-1a333d676433
STEP: Updating secret s-test-opt-upd-b3da0658-3606-11e9-816d-1a333d676433
STEP: Creating secret with name s-test-opt-create-b3da0684-3606-11e9-816d-1a333d676433
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:31:17.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4kgcq" for this suite.
Feb 21 18:31:39.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:31:39.382: INFO: namespace: e2e-tests-projected-4kgcq, resource: bindings, ignored listing per whitelist
Feb 21 18:31:39.411: INFO: namespace e2e-tests-projected-4kgcq deletion completed in 22.160190225s

• [SLOW TEST:96.955 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:31:39.412: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-sbm6b
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 21 18:31:41.668: INFO: Waiting up to 5m0s for pod "client-envvars-eeda7e32-3606-11e9-816d-1a333d676433" in namespace "e2e-tests-pods-sbm6b" to be "success or failure"
Feb 21 18:31:41.673: INFO: Pod "client-envvars-eeda7e32-3606-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 5.493495ms
Feb 21 18:31:43.678: INFO: Pod "client-envvars-eeda7e32-3606-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009695725s
Feb 21 18:31:45.682: INFO: Pod "client-envvars-eeda7e32-3606-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014547302s
STEP: Saw pod success
Feb 21 18:31:45.682: INFO: Pod "client-envvars-eeda7e32-3606-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:31:45.686: INFO: Trying to get logs from node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c pod client-envvars-eeda7e32-3606-11e9-816d-1a333d676433 container env3cont: <nil>
STEP: delete the pod
Feb 21 18:31:45.713: INFO: Waiting for pod client-envvars-eeda7e32-3606-11e9-816d-1a333d676433 to disappear
Feb 21 18:31:45.717: INFO: Pod client-envvars-eeda7e32-3606-11e9-816d-1a333d676433 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:31:45.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-sbm6b" for this suite.
Feb 21 18:32:27.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:32:27.823: INFO: namespace: e2e-tests-pods-sbm6b, resource: bindings, ignored listing per whitelist
Feb 21 18:32:27.883: INFO: namespace e2e-tests-pods-sbm6b deletion completed in 42.161039468s

• [SLOW TEST:48.471 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:32:27.883: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-d2m9r
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 21 18:32:28.085: INFO: Waiting up to 5m0s for pod "downward-api-0a864641-3607-11e9-816d-1a333d676433" in namespace "e2e-tests-downward-api-d2m9r" to be "success or failure"
Feb 21 18:32:28.091: INFO: Pod "downward-api-0a864641-3607-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 5.410321ms
Feb 21 18:32:30.096: INFO: Pod "downward-api-0a864641-3607-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01016495s
Feb 21 18:32:32.101: INFO: Pod "downward-api-0a864641-3607-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015256554s
STEP: Saw pod success
Feb 21 18:32:32.101: INFO: Pod "downward-api-0a864641-3607-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:32:32.105: INFO: Trying to get logs from node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c pod downward-api-0a864641-3607-11e9-816d-1a333d676433 container dapi-container: <nil>
STEP: delete the pod
Feb 21 18:32:32.132: INFO: Waiting for pod downward-api-0a864641-3607-11e9-816d-1a333d676433 to disappear
Feb 21 18:32:32.135: INFO: Pod downward-api-0a864641-3607-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:32:32.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-d2m9r" for this suite.
Feb 21 18:32:38.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:32:38.246: INFO: namespace: e2e-tests-downward-api-d2m9r, resource: bindings, ignored listing per whitelist
Feb 21 18:32:38.305: INFO: namespace e2e-tests-downward-api-d2m9r deletion completed in 6.166024735s

• [SLOW TEST:10.423 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:32:38.305: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-xp6ld
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 21 18:32:38.494: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:32:40.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-xp6ld" for this suite.
Feb 21 18:33:18.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:33:18.689: INFO: namespace: e2e-tests-pods-xp6ld, resource: bindings, ignored listing per whitelist
Feb 21 18:33:18.698: INFO: namespace e2e-tests-pods-xp6ld deletion completed in 38.157420025s

• [SLOW TEST:40.393 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:33:18.699: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-6khjm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-28d1282a-3607-11e9-816d-1a333d676433
STEP: Creating a pod to test consume configMaps
Feb 21 18:33:18.918: INFO: Waiting up to 5m0s for pod "pod-configmaps-28d23b29-3607-11e9-816d-1a333d676433" in namespace "e2e-tests-configmap-6khjm" to be "success or failure"
Feb 21 18:33:18.928: INFO: Pod "pod-configmaps-28d23b29-3607-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 10.282808ms
Feb 21 18:33:20.933: INFO: Pod "pod-configmaps-28d23b29-3607-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015054027s
STEP: Saw pod success
Feb 21 18:33:20.933: INFO: Pod "pod-configmaps-28d23b29-3607-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:33:20.936: INFO: Trying to get logs from node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c pod pod-configmaps-28d23b29-3607-11e9-816d-1a333d676433 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 21 18:33:20.960: INFO: Waiting for pod pod-configmaps-28d23b29-3607-11e9-816d-1a333d676433 to disappear
Feb 21 18:33:20.964: INFO: Pod pod-configmaps-28d23b29-3607-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:33:20.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-6khjm" for this suite.
Feb 21 18:33:26.987: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:33:27.143: INFO: namespace: e2e-tests-configmap-6khjm, resource: bindings, ignored listing per whitelist
Feb 21 18:33:27.143: INFO: namespace e2e-tests-configmap-6khjm deletion completed in 6.174764615s

• [SLOW TEST:8.445 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:33:27.144: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-9pjwq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-2dd916dd-3607-11e9-816d-1a333d676433
STEP: Creating a pod to test consume secrets
Feb 21 18:33:27.357: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2dd9ff21-3607-11e9-816d-1a333d676433" in namespace "e2e-tests-projected-9pjwq" to be "success or failure"
Feb 21 18:33:27.361: INFO: Pod "pod-projected-secrets-2dd9ff21-3607-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 4.196068ms
Feb 21 18:33:29.367: INFO: Pod "pod-projected-secrets-2dd9ff21-3607-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01011817s
STEP: Saw pod success
Feb 21 18:33:29.367: INFO: Pod "pod-projected-secrets-2dd9ff21-3607-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:33:29.371: INFO: Trying to get logs from node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c pod pod-projected-secrets-2dd9ff21-3607-11e9-816d-1a333d676433 container secret-volume-test: <nil>
STEP: delete the pod
Feb 21 18:33:29.398: INFO: Waiting for pod pod-projected-secrets-2dd9ff21-3607-11e9-816d-1a333d676433 to disappear
Feb 21 18:33:29.403: INFO: Pod pod-projected-secrets-2dd9ff21-3607-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:33:29.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9pjwq" for this suite.
Feb 21 18:33:35.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:33:35.515: INFO: namespace: e2e-tests-projected-9pjwq, resource: bindings, ignored listing per whitelist
Feb 21 18:33:35.576: INFO: namespace e2e-tests-projected-9pjwq deletion completed in 6.168659217s

• [SLOW TEST:8.433 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:33:35.577: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-fk656
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-32e0d2d9-3607-11e9-816d-1a333d676433
STEP: Creating a pod to test consume secrets
Feb 21 18:33:35.795: INFO: Waiting up to 5m0s for pod "pod-secrets-32e1c975-3607-11e9-816d-1a333d676433" in namespace "e2e-tests-secrets-fk656" to be "success or failure"
Feb 21 18:33:35.800: INFO: Pod "pod-secrets-32e1c975-3607-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 5.461424ms
Feb 21 18:33:37.805: INFO: Pod "pod-secrets-32e1c975-3607-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010049819s
Feb 21 18:33:39.810: INFO: Pod "pod-secrets-32e1c975-3607-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01506493s
STEP: Saw pod success
Feb 21 18:33:39.810: INFO: Pod "pod-secrets-32e1c975-3607-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:33:39.814: INFO: Trying to get logs from node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c pod pod-secrets-32e1c975-3607-11e9-816d-1a333d676433 container secret-volume-test: <nil>
STEP: delete the pod
Feb 21 18:33:39.840: INFO: Waiting for pod pod-secrets-32e1c975-3607-11e9-816d-1a333d676433 to disappear
Feb 21 18:33:39.844: INFO: Pod pod-secrets-32e1c975-3607-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:33:39.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-fk656" for this suite.
Feb 21 18:33:45.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:33:45.998: INFO: namespace: e2e-tests-secrets-fk656, resource: bindings, ignored listing per whitelist
Feb 21 18:33:46.015: INFO: namespace e2e-tests-secrets-fk656 deletion completed in 6.165528909s

• [SLOW TEST:10.438 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:33:46.015: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-5xptx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Feb 21 18:33:46.209: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-043636783 proxy --unix-socket=/tmp/kubectl-proxy-unix251751874/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:33:46.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5xptx" for this suite.
Feb 21 18:33:52.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:33:52.378: INFO: namespace: e2e-tests-kubectl-5xptx, resource: bindings, ignored listing per whitelist
Feb 21 18:33:52.414: INFO: namespace e2e-tests-kubectl-5xptx deletion completed in 6.13950596s

• [SLOW TEST:6.399 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:33:52.414: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-h6sx4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 21 18:33:52.595: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:33:57.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-h6sx4" for this suite.
Feb 21 18:34:19.094: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:34:19.160: INFO: namespace: e2e-tests-init-container-h6sx4, resource: bindings, ignored listing per whitelist
Feb 21 18:34:19.254: INFO: namespace e2e-tests-init-container-h6sx4 deletion completed in 22.188773311s

• [SLOW TEST:26.840 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:34:19.255: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-t7pfx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 21 18:34:19.489: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Feb 21 18:34:19.497: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-t7pfx/daemonsets","resourceVersion":"9654"},"items":null}

Feb 21 18:34:19.501: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-t7pfx/pods","resourceVersion":"9654"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:34:19.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-t7pfx" for this suite.
Feb 21 18:34:25.546: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:34:25.621: INFO: namespace: e2e-tests-daemonsets-t7pfx, resource: bindings, ignored listing per whitelist
Feb 21 18:34:25.700: INFO: namespace e2e-tests-daemonsets-t7pfx deletion completed in 6.175279402s

S [SKIPPING] [6.445 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Feb 21 18:34:19.489: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:34:25.700: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-nc8r5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-nc8r5
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 21 18:34:25.887: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 21 18:34:42.010: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.200.34.11:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-nc8r5 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 21 18:34:42.010: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
Feb 21 18:34:42.108: INFO: Found all expected endpoints: [netserver-0]
Feb 21 18:34:42.112: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.200.10.31:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-nc8r5 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 21 18:34:42.112: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
Feb 21 18:34:42.206: INFO: Found all expected endpoints: [netserver-1]
Feb 21 18:34:42.211: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.200.20.36:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-nc8r5 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 21 18:34:42.211: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
Feb 21 18:34:42.294: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:34:42.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-nc8r5" for this suite.
Feb 21 18:35:04.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:35:04.437: INFO: namespace: e2e-tests-pod-network-test-nc8r5, resource: bindings, ignored listing per whitelist
Feb 21 18:35:04.464: INFO: namespace e2e-tests-pod-network-test-nc8r5 deletion completed in 22.164824899s

• [SLOW TEST:38.764 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:35:04.465: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-4c5qb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 21 18:35:04.682: INFO: Waiting up to 5m0s for pod "downwardapi-volume-67dccca4-3607-11e9-816d-1a333d676433" in namespace "e2e-tests-downward-api-4c5qb" to be "success or failure"
Feb 21 18:35:04.686: INFO: Pod "downwardapi-volume-67dccca4-3607-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 3.487949ms
Feb 21 18:35:06.692: INFO: Pod "downwardapi-volume-67dccca4-3607-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010288215s
STEP: Saw pod success
Feb 21 18:35:06.692: INFO: Pod "downwardapi-volume-67dccca4-3607-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:35:06.696: INFO: Trying to get logs from node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c pod downwardapi-volume-67dccca4-3607-11e9-816d-1a333d676433 container client-container: <nil>
STEP: delete the pod
Feb 21 18:35:06.724: INFO: Waiting for pod downwardapi-volume-67dccca4-3607-11e9-816d-1a333d676433 to disappear
Feb 21 18:35:06.728: INFO: Pod downwardapi-volume-67dccca4-3607-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:35:06.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4c5qb" for this suite.
Feb 21 18:35:12.760: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:35:12.838: INFO: namespace: e2e-tests-downward-api-4c5qb, resource: bindings, ignored listing per whitelist
Feb 21 18:35:12.889: INFO: namespace e2e-tests-downward-api-4c5qb deletion completed in 6.156548618s

• [SLOW TEST:8.425 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:35:12.890: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-cq5bq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Feb 21 18:35:13.087: INFO: Waiting up to 5m0s for pod "client-containers-6cdf8901-3607-11e9-816d-1a333d676433" in namespace "e2e-tests-containers-cq5bq" to be "success or failure"
Feb 21 18:35:13.092: INFO: Pod "client-containers-6cdf8901-3607-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 5.27167ms
Feb 21 18:35:15.097: INFO: Pod "client-containers-6cdf8901-3607-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010134676s
STEP: Saw pod success
Feb 21 18:35:15.097: INFO: Pod "client-containers-6cdf8901-3607-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:35:15.100: INFO: Trying to get logs from node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c pod client-containers-6cdf8901-3607-11e9-816d-1a333d676433 container test-container: <nil>
STEP: delete the pod
Feb 21 18:35:15.126: INFO: Waiting for pod client-containers-6cdf8901-3607-11e9-816d-1a333d676433 to disappear
Feb 21 18:35:15.129: INFO: Pod client-containers-6cdf8901-3607-11e9-816d-1a333d676433 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:35:15.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-cq5bq" for this suite.
Feb 21 18:35:21.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:35:21.233: INFO: namespace: e2e-tests-containers-cq5bq, resource: bindings, ignored listing per whitelist
Feb 21 18:35:21.301: INFO: namespace e2e-tests-containers-cq5bq deletion completed in 6.167225846s

• [SLOW TEST:8.412 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:35:21.301: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-cnr9p
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-71e3c7e6-3607-11e9-816d-1a333d676433
STEP: Creating a pod to test consume secrets
Feb 21 18:35:21.509: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-71e4960b-3607-11e9-816d-1a333d676433" in namespace "e2e-tests-projected-cnr9p" to be "success or failure"
Feb 21 18:35:21.513: INFO: Pod "pod-projected-secrets-71e4960b-3607-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 4.058671ms
Feb 21 18:35:23.526: INFO: Pod "pod-projected-secrets-71e4960b-3607-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017454137s
STEP: Saw pod success
Feb 21 18:35:23.526: INFO: Pod "pod-projected-secrets-71e4960b-3607-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:35:23.530: INFO: Trying to get logs from node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c pod pod-projected-secrets-71e4960b-3607-11e9-816d-1a333d676433 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 21 18:35:23.555: INFO: Waiting for pod pod-projected-secrets-71e4960b-3607-11e9-816d-1a333d676433 to disappear
Feb 21 18:35:23.559: INFO: Pod pod-projected-secrets-71e4960b-3607-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:35:23.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cnr9p" for this suite.
Feb 21 18:35:29.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:35:29.659: INFO: namespace: e2e-tests-projected-cnr9p, resource: bindings, ignored listing per whitelist
Feb 21 18:35:29.724: INFO: namespace e2e-tests-projected-cnr9p deletion completed in 6.160390598s

• [SLOW TEST:8.423 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:35:29.725: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-4rhms
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Feb 21 18:35:29.908: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 21 18:35:29.917: INFO: Waiting for terminating namespaces to be deleted...
Feb 21 18:35:29.923: INFO: 
Logging pods the kubelet thinks is on node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c before test
Feb 21 18:35:29.929: INFO: coredns-54586579f6-8j2jr from kube-system started at 2019-02-21 17:44:33 +0000 UTC (1 container statuses recorded)
Feb 21 18:35:29.929: INFO: 	Container coredns ready: true, restart count 0
Feb 21 18:35:29.929: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-21 18:13:29 +0000 UTC (1 container statuses recorded)
Feb 21 18:35:29.929: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 21 18:35:29.929: INFO: sonobuoy-systemd-logs-daemon-set-8b397f221aec4f93-4wkfg from heptio-sonobuoy started at 2019-02-21 18:13:33 +0000 UTC (2 container statuses recorded)
Feb 21 18:35:29.929: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 21 18:35:29.929: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 21 18:35:29.929: INFO: 
Logging pods the kubelet thinks is on node vm-96433648-4a4e-4d7e-4d24-8065d4ab25dc before test
Feb 21 18:35:29.937: INFO: coredns-54586579f6-jqhrc from kube-system started at 2019-02-21 17:44:33 +0000 UTC (1 container statuses recorded)
Feb 21 18:35:29.937: INFO: 	Container coredns ready: true, restart count 0
Feb 21 18:35:29.937: INFO: metrics-server-5475446b7f-zdftv from kube-system started at 2019-02-21 17:44:35 +0000 UTC (1 container statuses recorded)
Feb 21 18:35:29.937: INFO: 	Container metrics-server ready: true, restart count 0
Feb 21 18:35:29.937: INFO: sonobuoy-e2e-job-820b1b08ea7846bb from heptio-sonobuoy started at 2019-02-21 18:13:32 +0000 UTC (2 container statuses recorded)
Feb 21 18:35:29.937: INFO: 	Container e2e ready: true, restart count 0
Feb 21 18:35:29.937: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 21 18:35:29.937: INFO: sonobuoy-systemd-logs-daemon-set-8b397f221aec4f93-wdlj7 from heptio-sonobuoy started at 2019-02-21 18:13:33 +0000 UTC (2 container statuses recorded)
Feb 21 18:35:29.937: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 21 18:35:29.937: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 21 18:35:29.937: INFO: 
Logging pods the kubelet thinks is on node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c before test
Feb 21 18:35:29.950: INFO: coredns-54586579f6-sj4gh from kube-system started at 2019-02-21 17:44:33 +0000 UTC (1 container statuses recorded)
Feb 21 18:35:29.950: INFO: 	Container coredns ready: true, restart count 0
Feb 21 18:35:29.950: INFO: kubernetes-dashboard-6c68548bc9-blr2b from kube-system started at 2019-02-21 17:44:38 +0000 UTC (1 container statuses recorded)
Feb 21 18:35:29.950: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Feb 21 18:35:29.950: INFO: sonobuoy-systemd-logs-daemon-set-8b397f221aec4f93-r7kz4 from heptio-sonobuoy started at 2019-02-21 18:13:33 +0000 UTC (2 container statuses recorded)
Feb 21 18:35:29.950: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 21 18:35:29.950: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.158574dad8072076], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:35:30.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-4rhms" for this suite.
Feb 21 18:35:37.007: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:35:37.074: INFO: namespace: e2e-tests-sched-pred-4rhms, resource: bindings, ignored listing per whitelist
Feb 21 18:35:37.134: INFO: namespace e2e-tests-sched-pred-4rhms deletion completed in 6.146875037s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.409 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:35:37.134: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-l6zzr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 21 18:35:37.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 version --client'
Feb 21 18:35:37.391: INFO: stderr: ""
Feb 21 18:35:37.391: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Feb 21 18:35:37.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 create -f - --namespace=e2e-tests-kubectl-l6zzr'
Feb 21 18:35:37.579: INFO: stderr: ""
Feb 21 18:35:37.579: INFO: stdout: "replicationcontroller/redis-master created\n"
Feb 21 18:35:37.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 create -f - --namespace=e2e-tests-kubectl-l6zzr'
Feb 21 18:35:37.806: INFO: stderr: ""
Feb 21 18:35:37.806: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 21 18:35:38.811: INFO: Selector matched 1 pods for map[app:redis]
Feb 21 18:35:38.811: INFO: Found 0 / 1
Feb 21 18:35:39.811: INFO: Selector matched 1 pods for map[app:redis]
Feb 21 18:35:39.811: INFO: Found 0 / 1
Feb 21 18:35:40.811: INFO: Selector matched 1 pods for map[app:redis]
Feb 21 18:35:40.811: INFO: Found 1 / 1
Feb 21 18:35:40.811: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 21 18:35:40.815: INFO: Selector matched 1 pods for map[app:redis]
Feb 21 18:35:40.815: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 21 18:35:40.815: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 describe pod redis-master-np84d --namespace=e2e-tests-kubectl-l6zzr'
Feb 21 18:35:40.912: INFO: stderr: ""
Feb 21 18:35:40.912: INFO: stdout: "Name:               redis-master-np84d\nNamespace:          e2e-tests-kubectl-l6zzr\nPriority:           0\nPriorityClassName:  <none>\nNode:               vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c/10.0.1.4\nStart Time:         Thu, 21 Feb 2019 18:35:37 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.200.10.33\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://58072b492ddfe104f368ee0fc47a002ba70e9f77d4250f7182f7335f6dbd1c68\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Thu, 21 Feb 2019 18:35:39 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-l7tvw (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-l7tvw:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-l7tvw\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                              Message\n  ----    ------     ----  ----                                              -------\n  Normal  Scheduled  3s    default-scheduler                                 Successfully assigned e2e-tests-kubectl-l6zzr/redis-master-np84d to vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c\n  Normal  Pulling    2s    kubelet, vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c  pulling image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\"\n  Normal  Pulled     1s    kubelet, vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c  Successfully pulled image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\"\n  Normal  Created    1s    kubelet, vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c  Created container\n  Normal  Started    1s    kubelet, vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c  Started container\n"
Feb 21 18:35:40.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 describe rc redis-master --namespace=e2e-tests-kubectl-l6zzr'
Feb 21 18:35:41.013: INFO: stderr: ""
Feb 21 18:35:41.013: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-l6zzr\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  4s    replication-controller  Created pod: redis-master-np84d\n"
Feb 21 18:35:41.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 describe service redis-master --namespace=e2e-tests-kubectl-l6zzr'
Feb 21 18:35:41.104: INFO: stderr: ""
Feb 21 18:35:41.104: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-l6zzr\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.100.200.12\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.200.10.33:6379\nSession Affinity:  None\nEvents:            <none>\n"
Feb 21 18:35:41.110: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 describe node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c'
Feb 21 18:35:41.214: INFO: stderr: ""
Feb 21 18:35:41.214: INFO: stdout: "Name:               vm-899af0be-63fe-4e97-4fe5-b77e233eb87c\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=n1-highmem-4\n                    beta.kubernetes.io/os=linux\n                    bosh.id=2df66475-a9d6-473d-9ed8-13e28364bff4\n                    bosh.zone=z3\n                    failure-domain.beta.kubernetes.io/region=us-west1\n                    failure-domain.beta.kubernetes.io/zone=us-west1-c\n                    kubernetes.io/hostname=vm-899af0be-63fe-4e97-4fe5-b77e233eb87c\n                    spec.ip=10.0.1.5\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Thu, 21 Feb 2019 17:29:05 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Mon, 01 Jan 0001 00:00:00 +0000   Thu, 21 Feb 2019 17:29:05 +0000   NetworkProvidedByFlannel     Status manually modified by CFCR kubelet post-start\n  MemoryPressure       False   Thu, 21 Feb 2019 18:35:32 +0000   Thu, 21 Feb 2019 17:29:05 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Thu, 21 Feb 2019 18:35:32 +0000   Thu, 21 Feb 2019 17:29:05 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Thu, 21 Feb 2019 18:35:32 +0000   Thu, 21 Feb 2019 17:29:05 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Thu, 21 Feb 2019 18:35:32 +0000   Thu, 21 Feb 2019 17:29:05 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:   10.0.1.5\n  ExternalIP:   35.197.47.134\n  InternalDNS:  vm-899af0be-63fe-4e97-4fe5-b77e233eb87c.c.cf-kubo-dev.internal\n  Hostname:     vm-899af0be-63fe-4e97-4fe5-b77e233eb87c\nCapacity:\n attachable-volumes-gce-pd:  64\n cpu:                        4\n ephemeral-storage:          2886304Ki\n hugepages-1Gi:              0\n hugepages-2Mi:              0\n memory:                     26747452Ki\n pods:                       110\nAllocatable:\n attachable-volumes-gce-pd:  64\n cpu:                        4\n ephemeral-storage:          2660017762\n hugepages-1Gi:              0\n hugepages-2Mi:              0\n memory:                     26645052Ki\n pods:                       110\nSystem Info:\n Machine ID:                 44e1bbe594e9f4948c40f45d0003b1c4\n System UUID:                4CD46C34-64E9-FD68-73F9-3AABC9BCA8FF\n Boot ID:                    f4df11e3-598c-45c2-846c-011a6acd88db\n Kernel Version:             4.15.0-43-generic\n OS Image:                   Ubuntu 16.04.5 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.2\n Kubelet Version:            v1.13.3\n Kube-Proxy Version:         v1.13.3\nProviderID:                  gce://cf-kubo-dev/us-west1-c/vm-899af0be-63fe-4e97-4fe5-b77e233eb87c\nNon-terminated Pods:         (3 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         22m\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-8b397f221aec4f93-4wkfg    0 (0%)        0 (0%)      0 (0%)           0 (0%)         22m\n  kube-system                coredns-54586579f6-8j2jr                                   100m (2%)     0 (0%)      70Mi (0%)        170Mi (0%)     51m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                   Requests   Limits\n  --------                   --------   ------\n  cpu                        100m (2%)  0 (0%)\n  memory                     70Mi (0%)  170Mi (0%)\n  ephemeral-storage          0 (0%)     0 (0%)\n  attachable-volumes-gce-pd  0          0\nEvents:                      <none>\n"
Feb 21 18:35:41.214: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 describe namespace e2e-tests-kubectl-l6zzr'
Feb 21 18:35:41.310: INFO: stderr: ""
Feb 21 18:35:41.310: INFO: stdout: "Name:         e2e-tests-kubectl-l6zzr\nLabels:       e2e-framework=kubectl\n              e2e-run=7014886c-3604-11e9-816d-1a333d676433\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:35:41.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-l6zzr" for this suite.
Feb 21 18:36:03.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:36:03.395: INFO: namespace: e2e-tests-kubectl-l6zzr, resource: bindings, ignored listing per whitelist
Feb 21 18:36:03.477: INFO: namespace e2e-tests-kubectl-l6zzr deletion completed in 22.162812428s

• [SLOW TEST:26.344 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:36:03.478: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-bwmt8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Feb 21 18:36:03.669: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 21 18:36:03.679: INFO: Waiting for terminating namespaces to be deleted...
Feb 21 18:36:03.684: INFO: 
Logging pods the kubelet thinks is on node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c before test
Feb 21 18:36:03.690: INFO: coredns-54586579f6-8j2jr from kube-system started at 2019-02-21 17:44:33 +0000 UTC (1 container statuses recorded)
Feb 21 18:36:03.690: INFO: 	Container coredns ready: true, restart count 0
Feb 21 18:36:03.690: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-21 18:13:29 +0000 UTC (1 container statuses recorded)
Feb 21 18:36:03.690: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 21 18:36:03.690: INFO: sonobuoy-systemd-logs-daemon-set-8b397f221aec4f93-4wkfg from heptio-sonobuoy started at 2019-02-21 18:13:33 +0000 UTC (2 container statuses recorded)
Feb 21 18:36:03.690: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 21 18:36:03.690: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 21 18:36:03.690: INFO: 
Logging pods the kubelet thinks is on node vm-96433648-4a4e-4d7e-4d24-8065d4ab25dc before test
Feb 21 18:36:03.697: INFO: sonobuoy-e2e-job-820b1b08ea7846bb from heptio-sonobuoy started at 2019-02-21 18:13:32 +0000 UTC (2 container statuses recorded)
Feb 21 18:36:03.697: INFO: 	Container e2e ready: true, restart count 0
Feb 21 18:36:03.697: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 21 18:36:03.697: INFO: sonobuoy-systemd-logs-daemon-set-8b397f221aec4f93-wdlj7 from heptio-sonobuoy started at 2019-02-21 18:13:33 +0000 UTC (2 container statuses recorded)
Feb 21 18:36:03.697: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 21 18:36:03.697: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 21 18:36:03.697: INFO: coredns-54586579f6-jqhrc from kube-system started at 2019-02-21 17:44:33 +0000 UTC (1 container statuses recorded)
Feb 21 18:36:03.697: INFO: 	Container coredns ready: true, restart count 0
Feb 21 18:36:03.697: INFO: metrics-server-5475446b7f-zdftv from kube-system started at 2019-02-21 17:44:35 +0000 UTC (1 container statuses recorded)
Feb 21 18:36:03.697: INFO: 	Container metrics-server ready: true, restart count 0
Feb 21 18:36:03.697: INFO: 
Logging pods the kubelet thinks is on node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c before test
Feb 21 18:36:03.704: INFO: coredns-54586579f6-sj4gh from kube-system started at 2019-02-21 17:44:33 +0000 UTC (1 container statuses recorded)
Feb 21 18:36:03.704: INFO: 	Container coredns ready: true, restart count 0
Feb 21 18:36:03.704: INFO: kubernetes-dashboard-6c68548bc9-blr2b from kube-system started at 2019-02-21 17:44:38 +0000 UTC (1 container statuses recorded)
Feb 21 18:36:03.704: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Feb 21 18:36:03.704: INFO: sonobuoy-systemd-logs-daemon-set-8b397f221aec4f93-r7kz4 from heptio-sonobuoy started at 2019-02-21 18:13:33 +0000 UTC (2 container statuses recorded)
Feb 21 18:36:03.704: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 21 18:36:03.704: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c
STEP: verifying the node has the label node vm-96433648-4a4e-4d7e-4d24-8065d4ab25dc
STEP: verifying the node has the label node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c
Feb 21 18:36:03.754: INFO: Pod sonobuoy requesting resource cpu=0m on Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c
Feb 21 18:36:03.754: INFO: Pod sonobuoy-e2e-job-820b1b08ea7846bb requesting resource cpu=0m on Node vm-96433648-4a4e-4d7e-4d24-8065d4ab25dc
Feb 21 18:36:03.754: INFO: Pod sonobuoy-systemd-logs-daemon-set-8b397f221aec4f93-4wkfg requesting resource cpu=0m on Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c
Feb 21 18:36:03.754: INFO: Pod sonobuoy-systemd-logs-daemon-set-8b397f221aec4f93-r7kz4 requesting resource cpu=0m on Node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c
Feb 21 18:36:03.754: INFO: Pod sonobuoy-systemd-logs-daemon-set-8b397f221aec4f93-wdlj7 requesting resource cpu=0m on Node vm-96433648-4a4e-4d7e-4d24-8065d4ab25dc
Feb 21 18:36:03.754: INFO: Pod coredns-54586579f6-8j2jr requesting resource cpu=100m on Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c
Feb 21 18:36:03.754: INFO: Pod coredns-54586579f6-jqhrc requesting resource cpu=100m on Node vm-96433648-4a4e-4d7e-4d24-8065d4ab25dc
Feb 21 18:36:03.754: INFO: Pod coredns-54586579f6-sj4gh requesting resource cpu=100m on Node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c
Feb 21 18:36:03.754: INFO: Pod kubernetes-dashboard-6c68548bc9-blr2b requesting resource cpu=50m on Node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c
Feb 21 18:36:03.754: INFO: Pod metrics-server-5475446b7f-zdftv requesting resource cpu=0m on Node vm-96433648-4a4e-4d7e-4d24-8065d4ab25dc
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8b145b6c-3607-11e9-816d-1a333d676433.158574e2b667791f], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-bwmt8/filler-pod-8b145b6c-3607-11e9-816d-1a333d676433 to vm-96433648-4a4e-4d7e-4d24-8065d4ab25dc]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8b145b6c-3607-11e9-816d-1a333d676433.158574e2edb33f7b], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8b145b6c-3607-11e9-816d-1a333d676433.158574e2f258d0c8], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8b145b6c-3607-11e9-816d-1a333d676433.158574e2fd26e9cf], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8b1640dd-3607-11e9-816d-1a333d676433.158574e2b70cb5fe], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-bwmt8/filler-pod-8b1640dd-3607-11e9-816d-1a333d676433 to vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8b1640dd-3607-11e9-816d-1a333d676433.158574e2ee4c1ecf], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8b1640dd-3607-11e9-816d-1a333d676433.158574e2f31c4ffc], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8b1640dd-3607-11e9-816d-1a333d676433.158574e2ffdb3c30], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8b179751-3607-11e9-816d-1a333d676433.158574e2b7bcad19], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-bwmt8/filler-pod-8b179751-3607-11e9-816d-1a333d676433 to vm-899af0be-63fe-4e97-4fe5-b77e233eb87c]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8b179751-3607-11e9-816d-1a333d676433.158574e2ef9e39e3], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8b179751-3607-11e9-816d-1a333d676433.158574e2f309bd5a], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8b179751-3607-11e9-816d-1a333d676433.158574e300aa2712], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.158574e3a899a8e9], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node vm-96433648-4a4e-4d7e-4d24-8065d4ab25dc
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:36:08.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-bwmt8" for this suite.
Feb 21 18:36:14.922: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:36:14.961: INFO: namespace: e2e-tests-sched-pred-bwmt8, resource: bindings, ignored listing per whitelist
Feb 21 18:36:15.059: INFO: namespace e2e-tests-sched-pred-bwmt8 deletion completed in 6.157978367s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:11.582 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:36:15.060: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-qmzfc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Feb 21 18:36:15.771: INFO: Waiting up to 5m0s for pod "pod-service-account-923c3391-3607-11e9-816d-1a333d676433-fxc4n" in namespace "e2e-tests-svcaccounts-qmzfc" to be "success or failure"
Feb 21 18:36:15.778: INFO: Pod "pod-service-account-923c3391-3607-11e9-816d-1a333d676433-fxc4n": Phase="Pending", Reason="", readiness=false. Elapsed: 6.135116ms
Feb 21 18:36:17.783: INFO: Pod "pod-service-account-923c3391-3607-11e9-816d-1a333d676433-fxc4n": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011257658s
Feb 21 18:36:19.795: INFO: Pod "pod-service-account-923c3391-3607-11e9-816d-1a333d676433-fxc4n": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023044585s
STEP: Saw pod success
Feb 21 18:36:19.795: INFO: Pod "pod-service-account-923c3391-3607-11e9-816d-1a333d676433-fxc4n" satisfied condition "success or failure"
Feb 21 18:36:19.798: INFO: Trying to get logs from node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c pod pod-service-account-923c3391-3607-11e9-816d-1a333d676433-fxc4n container token-test: <nil>
STEP: delete the pod
Feb 21 18:36:19.822: INFO: Waiting for pod pod-service-account-923c3391-3607-11e9-816d-1a333d676433-fxc4n to disappear
Feb 21 18:36:19.826: INFO: Pod pod-service-account-923c3391-3607-11e9-816d-1a333d676433-fxc4n no longer exists
STEP: Creating a pod to test consume service account root CA
Feb 21 18:36:19.836: INFO: Waiting up to 5m0s for pod "pod-service-account-923c3391-3607-11e9-816d-1a333d676433-bcn2z" in namespace "e2e-tests-svcaccounts-qmzfc" to be "success or failure"
Feb 21 18:36:19.841: INFO: Pod "pod-service-account-923c3391-3607-11e9-816d-1a333d676433-bcn2z": Phase="Pending", Reason="", readiness=false. Elapsed: 4.485748ms
Feb 21 18:36:21.845: INFO: Pod "pod-service-account-923c3391-3607-11e9-816d-1a333d676433-bcn2z": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009449865s
Feb 21 18:36:23.850: INFO: Pod "pod-service-account-923c3391-3607-11e9-816d-1a333d676433-bcn2z": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01409941s
STEP: Saw pod success
Feb 21 18:36:23.850: INFO: Pod "pod-service-account-923c3391-3607-11e9-816d-1a333d676433-bcn2z" satisfied condition "success or failure"
Feb 21 18:36:23.854: INFO: Trying to get logs from node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c pod pod-service-account-923c3391-3607-11e9-816d-1a333d676433-bcn2z container root-ca-test: <nil>
STEP: delete the pod
Feb 21 18:36:23.881: INFO: Waiting for pod pod-service-account-923c3391-3607-11e9-816d-1a333d676433-bcn2z to disappear
Feb 21 18:36:23.885: INFO: Pod pod-service-account-923c3391-3607-11e9-816d-1a333d676433-bcn2z no longer exists
STEP: Creating a pod to test consume service account namespace
Feb 21 18:36:23.892: INFO: Waiting up to 5m0s for pod "pod-service-account-923c3391-3607-11e9-816d-1a333d676433-gp7pq" in namespace "e2e-tests-svcaccounts-qmzfc" to be "success or failure"
Feb 21 18:36:23.898: INFO: Pod "pod-service-account-923c3391-3607-11e9-816d-1a333d676433-gp7pq": Phase="Pending", Reason="", readiness=false. Elapsed: 6.342288ms
Feb 21 18:36:25.903: INFO: Pod "pod-service-account-923c3391-3607-11e9-816d-1a333d676433-gp7pq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011399804s
Feb 21 18:36:27.908: INFO: Pod "pod-service-account-923c3391-3607-11e9-816d-1a333d676433-gp7pq": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016201761s
STEP: Saw pod success
Feb 21 18:36:27.908: INFO: Pod "pod-service-account-923c3391-3607-11e9-816d-1a333d676433-gp7pq" satisfied condition "success or failure"
Feb 21 18:36:27.912: INFO: Trying to get logs from node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c pod pod-service-account-923c3391-3607-11e9-816d-1a333d676433-gp7pq container namespace-test: <nil>
STEP: delete the pod
Feb 21 18:36:27.937: INFO: Waiting for pod pod-service-account-923c3391-3607-11e9-816d-1a333d676433-gp7pq to disappear
Feb 21 18:36:27.941: INFO: Pod pod-service-account-923c3391-3607-11e9-816d-1a333d676433-gp7pq no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:36:27.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-qmzfc" for this suite.
Feb 21 18:36:33.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:36:33.979: INFO: namespace: e2e-tests-svcaccounts-qmzfc, resource: bindings, ignored listing per whitelist
Feb 21 18:36:34.107: INFO: namespace e2e-tests-svcaccounts-qmzfc deletion completed in 6.161233187s

• [SLOW TEST:19.047 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:36:34.107: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-xh8dg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Feb 21 18:36:34.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 create -f - --namespace=e2e-tests-kubectl-xh8dg'
Feb 21 18:36:34.520: INFO: stderr: ""
Feb 21 18:36:34.520: INFO: stdout: "pod/pause created\n"
Feb 21 18:36:34.520: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Feb 21 18:36:34.520: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-xh8dg" to be "running and ready"
Feb 21 18:36:34.527: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 6.983374ms
Feb 21 18:36:36.531: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.011613709s
Feb 21 18:36:36.532: INFO: Pod "pause" satisfied condition "running and ready"
Feb 21 18:36:36.532: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Feb 21 18:36:36.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-xh8dg'
Feb 21 18:36:36.619: INFO: stderr: ""
Feb 21 18:36:36.619: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Feb 21 18:36:36.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pod pause -L testing-label --namespace=e2e-tests-kubectl-xh8dg'
Feb 21 18:36:36.692: INFO: stderr: ""
Feb 21 18:36:36.692: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Feb 21 18:36:36.693: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 label pods pause testing-label- --namespace=e2e-tests-kubectl-xh8dg'
Feb 21 18:36:36.774: INFO: stderr: ""
Feb 21 18:36:36.774: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Feb 21 18:36:36.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pod pause -L testing-label --namespace=e2e-tests-kubectl-xh8dg'
Feb 21 18:36:36.861: INFO: stderr: ""
Feb 21 18:36:36.861: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Feb 21 18:36:36.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-xh8dg'
Feb 21 18:36:36.948: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 21 18:36:36.948: INFO: stdout: "pod \"pause\" force deleted\n"
Feb 21 18:36:36.948: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-xh8dg'
Feb 21 18:36:37.028: INFO: stderr: "No resources found.\n"
Feb 21 18:36:37.028: INFO: stdout: ""
Feb 21 18:36:37.028: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods -l name=pause --namespace=e2e-tests-kubectl-xh8dg -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 21 18:36:37.102: INFO: stderr: ""
Feb 21 18:36:37.102: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:36:37.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xh8dg" for this suite.
Feb 21 18:36:43.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:36:43.180: INFO: namespace: e2e-tests-kubectl-xh8dg, resource: bindings, ignored listing per whitelist
Feb 21 18:36:43.268: INFO: namespace e2e-tests-kubectl-xh8dg deletion completed in 6.159563463s

• [SLOW TEST:9.161 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:36:43.268: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-wnckb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-6cggg
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Feb 21 18:36:45.628: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-wp9w8
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:37:09.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-wnckb" for this suite.
Feb 21 18:37:15.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:37:15.919: INFO: namespace: e2e-tests-namespaces-wnckb, resource: bindings, ignored listing per whitelist
Feb 21 18:37:15.977: INFO: namespace e2e-tests-namespaces-wnckb deletion completed in 6.176952159s
STEP: Destroying namespace "e2e-tests-nsdeletetest-6cggg" for this suite.
Feb 21 18:37:15.982: INFO: Namespace e2e-tests-nsdeletetest-6cggg was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-wp9w8" for this suite.
Feb 21 18:37:22.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:37:22.080: INFO: namespace: e2e-tests-nsdeletetest-wp9w8, resource: bindings, ignored listing per whitelist
Feb 21 18:37:22.147: INFO: namespace e2e-tests-nsdeletetest-wp9w8 deletion completed in 6.164814129s

• [SLOW TEST:38.879 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:37:22.147: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-wg6dh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 21 18:37:22.351: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b9eb9a23-3607-11e9-816d-1a333d676433" in namespace "e2e-tests-downward-api-wg6dh" to be "success or failure"
Feb 21 18:37:22.360: INFO: Pod "downwardapi-volume-b9eb9a23-3607-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 9.550315ms
Feb 21 18:37:24.373: INFO: Pod "downwardapi-volume-b9eb9a23-3607-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022380756s
STEP: Saw pod success
Feb 21 18:37:24.373: INFO: Pod "downwardapi-volume-b9eb9a23-3607-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:37:24.377: INFO: Trying to get logs from node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c pod downwardapi-volume-b9eb9a23-3607-11e9-816d-1a333d676433 container client-container: <nil>
STEP: delete the pod
Feb 21 18:37:24.400: INFO: Waiting for pod downwardapi-volume-b9eb9a23-3607-11e9-816d-1a333d676433 to disappear
Feb 21 18:37:24.404: INFO: Pod downwardapi-volume-b9eb9a23-3607-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:37:24.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-wg6dh" for this suite.
Feb 21 18:37:30.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:37:30.452: INFO: namespace: e2e-tests-downward-api-wg6dh, resource: bindings, ignored listing per whitelist
Feb 21 18:37:30.581: INFO: namespace e2e-tests-downward-api-wg6dh deletion completed in 6.172101937s

• [SLOW TEST:8.434 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:37:30.582: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-hlw7f
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-hlw7f/configmap-test-bef1932e-3607-11e9-816d-1a333d676433
STEP: Creating a pod to test consume configMaps
Feb 21 18:37:30.786: INFO: Waiting up to 5m0s for pod "pod-configmaps-bef2a744-3607-11e9-816d-1a333d676433" in namespace "e2e-tests-configmap-hlw7f" to be "success or failure"
Feb 21 18:37:30.791: INFO: Pod "pod-configmaps-bef2a744-3607-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 5.050182ms
Feb 21 18:37:32.796: INFO: Pod "pod-configmaps-bef2a744-3607-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009986594s
Feb 21 18:37:34.807: INFO: Pod "pod-configmaps-bef2a744-3607-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021020075s
STEP: Saw pod success
Feb 21 18:37:34.807: INFO: Pod "pod-configmaps-bef2a744-3607-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:37:34.810: INFO: Trying to get logs from node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c pod pod-configmaps-bef2a744-3607-11e9-816d-1a333d676433 container env-test: <nil>
STEP: delete the pod
Feb 21 18:37:34.836: INFO: Waiting for pod pod-configmaps-bef2a744-3607-11e9-816d-1a333d676433 to disappear
Feb 21 18:37:34.839: INFO: Pod pod-configmaps-bef2a744-3607-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:37:34.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-hlw7f" for this suite.
Feb 21 18:37:40.862: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:37:40.997: INFO: namespace: e2e-tests-configmap-hlw7f, resource: bindings, ignored listing per whitelist
Feb 21 18:37:41.000: INFO: namespace e2e-tests-configmap-hlw7f deletion completed in 6.156388447s

• [SLOW TEST:10.419 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:37:41.000: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-g4vvf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 21 18:37:41.206: INFO: (0) /api/v1/nodes/vm-899af0be-63fe-4e97-4fe5-b77e233eb87c:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 7.978086ms)
Feb 21 18:37:41.210: INFO: (1) /api/v1/nodes/vm-899af0be-63fe-4e97-4fe5-b77e233eb87c:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.591716ms)
Feb 21 18:37:41.215: INFO: (2) /api/v1/nodes/vm-899af0be-63fe-4e97-4fe5-b77e233eb87c:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.667357ms)
Feb 21 18:37:41.220: INFO: (3) /api/v1/nodes/vm-899af0be-63fe-4e97-4fe5-b77e233eb87c:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.825573ms)
Feb 21 18:37:41.225: INFO: (4) /api/v1/nodes/vm-899af0be-63fe-4e97-4fe5-b77e233eb87c:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.928501ms)
Feb 21 18:37:41.230: INFO: (5) /api/v1/nodes/vm-899af0be-63fe-4e97-4fe5-b77e233eb87c:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.025806ms)
Feb 21 18:37:41.234: INFO: (6) /api/v1/nodes/vm-899af0be-63fe-4e97-4fe5-b77e233eb87c:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.269179ms)
Feb 21 18:37:41.238: INFO: (7) /api/v1/nodes/vm-899af0be-63fe-4e97-4fe5-b77e233eb87c:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.144357ms)
Feb 21 18:37:41.243: INFO: (8) /api/v1/nodes/vm-899af0be-63fe-4e97-4fe5-b77e233eb87c:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.48479ms)
Feb 21 18:37:41.248: INFO: (9) /api/v1/nodes/vm-899af0be-63fe-4e97-4fe5-b77e233eb87c:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.722708ms)
Feb 21 18:37:41.252: INFO: (10) /api/v1/nodes/vm-899af0be-63fe-4e97-4fe5-b77e233eb87c:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.199034ms)
Feb 21 18:37:41.257: INFO: (11) /api/v1/nodes/vm-899af0be-63fe-4e97-4fe5-b77e233eb87c:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.666697ms)
Feb 21 18:37:41.261: INFO: (12) /api/v1/nodes/vm-899af0be-63fe-4e97-4fe5-b77e233eb87c:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.809254ms)
Feb 21 18:37:41.266: INFO: (13) /api/v1/nodes/vm-899af0be-63fe-4e97-4fe5-b77e233eb87c:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.816997ms)
Feb 21 18:37:41.271: INFO: (14) /api/v1/nodes/vm-899af0be-63fe-4e97-4fe5-b77e233eb87c:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.541145ms)
Feb 21 18:37:41.276: INFO: (15) /api/v1/nodes/vm-899af0be-63fe-4e97-4fe5-b77e233eb87c:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.751188ms)
Feb 21 18:37:41.280: INFO: (16) /api/v1/nodes/vm-899af0be-63fe-4e97-4fe5-b77e233eb87c:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.421763ms)
Feb 21 18:37:41.285: INFO: (17) /api/v1/nodes/vm-899af0be-63fe-4e97-4fe5-b77e233eb87c:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.62291ms)
Feb 21 18:37:41.290: INFO: (18) /api/v1/nodes/vm-899af0be-63fe-4e97-4fe5-b77e233eb87c:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.753904ms)
Feb 21 18:37:41.294: INFO: (19) /api/v1/nodes/vm-899af0be-63fe-4e97-4fe5-b77e233eb87c:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.138844ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:37:41.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-g4vvf" for this suite.
Feb 21 18:37:47.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:37:47.442: INFO: namespace: e2e-tests-proxy-g4vvf, resource: bindings, ignored listing per whitelist
Feb 21 18:37:47.444: INFO: namespace e2e-tests-proxy-g4vvf deletion completed in 6.145366551s

• [SLOW TEST:6.443 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:37:47.444: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-4lkrk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-c8fe8b83-3607-11e9-816d-1a333d676433
STEP: Creating a pod to test consume secrets
Feb 21 18:37:47.646: INFO: Waiting up to 5m0s for pod "pod-secrets-c8ff58ec-3607-11e9-816d-1a333d676433" in namespace "e2e-tests-secrets-4lkrk" to be "success or failure"
Feb 21 18:37:47.652: INFO: Pod "pod-secrets-c8ff58ec-3607-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 5.577841ms
Feb 21 18:37:49.656: INFO: Pod "pod-secrets-c8ff58ec-3607-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010121602s
STEP: Saw pod success
Feb 21 18:37:49.656: INFO: Pod "pod-secrets-c8ff58ec-3607-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:37:49.660: INFO: Trying to get logs from node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c pod pod-secrets-c8ff58ec-3607-11e9-816d-1a333d676433 container secret-env-test: <nil>
STEP: delete the pod
Feb 21 18:37:49.685: INFO: Waiting for pod pod-secrets-c8ff58ec-3607-11e9-816d-1a333d676433 to disappear
Feb 21 18:37:49.688: INFO: Pod pod-secrets-c8ff58ec-3607-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:37:49.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-4lkrk" for this suite.
Feb 21 18:37:55.719: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:37:55.782: INFO: namespace: e2e-tests-secrets-4lkrk, resource: bindings, ignored listing per whitelist
Feb 21 18:37:55.853: INFO: namespace e2e-tests-secrets-4lkrk deletion completed in 6.159870145s

• [SLOW TEST:8.409 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:37:55.853: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-qx76r
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 21 18:37:56.055: INFO: Waiting up to 5m0s for pod "pod-ce021271-3607-11e9-816d-1a333d676433" in namespace "e2e-tests-emptydir-qx76r" to be "success or failure"
Feb 21 18:37:56.058: INFO: Pod "pod-ce021271-3607-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 3.355652ms
Feb 21 18:37:58.063: INFO: Pod "pod-ce021271-3607-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007977259s
Feb 21 18:38:00.067: INFO: Pod "pod-ce021271-3607-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012376398s
STEP: Saw pod success
Feb 21 18:38:00.067: INFO: Pod "pod-ce021271-3607-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:38:00.071: INFO: Trying to get logs from node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c pod pod-ce021271-3607-11e9-816d-1a333d676433 container test-container: <nil>
STEP: delete the pod
Feb 21 18:38:00.099: INFO: Waiting for pod pod-ce021271-3607-11e9-816d-1a333d676433 to disappear
Feb 21 18:38:00.102: INFO: Pod pod-ce021271-3607-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:38:00.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-qx76r" for this suite.
Feb 21 18:38:06.134: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:38:06.276: INFO: namespace: e2e-tests-emptydir-qx76r, resource: bindings, ignored listing per whitelist
Feb 21 18:38:06.284: INFO: namespace e2e-tests-emptydir-qx76r deletion completed in 6.176644099s

• [SLOW TEST:10.431 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:38:06.284: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-fnc5r
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 21 18:38:06.474: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Feb 21 18:38:06.487: INFO: Pod name sample-pod: Found 0 pods out of 1
Feb 21 18:38:11.492: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 21 18:38:11.493: INFO: Creating deployment "test-rolling-update-deployment"
Feb 21 18:38:11.499: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Feb 21 18:38:11.508: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Feb 21 18:38:13.520: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Feb 21 18:38:13.525: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 21 18:38:13.539: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-fnc5r,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fnc5r/deployments/test-rolling-update-deployment,UID:d737cf83-3607-11e9-bacd-42010a000102,ResourceVersion:10688,Generation:1,CreationTimestamp:2019-02-21 18:38:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-21 18:38:11 +0000 UTC 2019-02-21 18:38:11 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-21 18:38:13 +0000 UTC 2019-02-21 18:38:11 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb 21 18:38:13.545: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-fnc5r,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fnc5r/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:d73b20ea-3607-11e9-8547-42010a000100,ResourceVersion:10679,Generation:1,CreationTimestamp:2019-02-21 18:38:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment d737cf83-3607-11e9-bacd-42010a000102 0xc002109a77 0xc002109a78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 21 18:38:13.545: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Feb 21 18:38:13.545: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-fnc5r,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fnc5r/replicasets/test-rolling-update-controller,UID:d43a00e6-3607-11e9-bacd-42010a000102,ResourceVersion:10687,Generation:2,CreationTimestamp:2019-02-21 18:38:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment d737cf83-3607-11e9-bacd-42010a000102 0xc0021099b7 0xc0021099b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 21 18:38:13.551: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-fbhhn" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-fbhhn,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-fnc5r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fnc5r/pods/test-rolling-update-deployment-68b55d7bc6-fbhhn,UID:d73c0228-3607-11e9-8547-42010a000100,ResourceVersion:10678,Generation:0,CreationTimestamp:2019-02-21 18:38:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 d73b20ea-3607-11e9-8547-42010a000100 0xc002130547 0xc002130548}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2nltx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2nltx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-2nltx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002130620} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021308f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 18:38:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 18:38:13 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 18:38:13 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 18:38:11 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.4,PodIP:10.200.10.42,StartTime:2019-02-21 18:38:11 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-21 18:38:12 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://d2512619f01f17bad988f71611c9c6a8a7e8ac4175c07f5b3e0bf8883babb421}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:38:13.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-fnc5r" for this suite.
Feb 21 18:38:19.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:38:19.623: INFO: namespace: e2e-tests-deployment-fnc5r, resource: bindings, ignored listing per whitelist
Feb 21 18:38:19.711: INFO: namespace e2e-tests-deployment-fnc5r deletion completed in 6.154262453s

• [SLOW TEST:13.427 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:38:19.711: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-gfqgr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Feb 21 18:38:19.896: INFO: namespace e2e-tests-kubectl-gfqgr
Feb 21 18:38:19.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 create -f - --namespace=e2e-tests-kubectl-gfqgr'
Feb 21 18:38:20.338: INFO: stderr: ""
Feb 21 18:38:20.338: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 21 18:38:21.343: INFO: Selector matched 1 pods for map[app:redis]
Feb 21 18:38:21.343: INFO: Found 0 / 1
Feb 21 18:38:22.343: INFO: Selector matched 1 pods for map[app:redis]
Feb 21 18:38:22.343: INFO: Found 0 / 1
Feb 21 18:38:23.343: INFO: Selector matched 1 pods for map[app:redis]
Feb 21 18:38:23.343: INFO: Found 1 / 1
Feb 21 18:38:23.343: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 21 18:38:23.346: INFO: Selector matched 1 pods for map[app:redis]
Feb 21 18:38:23.346: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 21 18:38:23.346: INFO: wait on redis-master startup in e2e-tests-kubectl-gfqgr 
Feb 21 18:38:23.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 logs redis-master-ql2kd redis-master --namespace=e2e-tests-kubectl-gfqgr'
Feb 21 18:38:23.455: INFO: stderr: ""
Feb 21 18:38:23.455: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 21 Feb 18:38:21.505 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 Feb 18:38:21.505 # Server started, Redis version 3.2.12\n1:M 21 Feb 18:38:21.505 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 Feb 18:38:21.505 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Feb 21 18:38:23.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-gfqgr'
Feb 21 18:38:23.555: INFO: stderr: ""
Feb 21 18:38:23.556: INFO: stdout: "service/rm2 exposed\n"
Feb 21 18:38:23.566: INFO: Service rm2 in namespace e2e-tests-kubectl-gfqgr found.
STEP: exposing service
Feb 21 18:38:25.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-gfqgr'
Feb 21 18:38:25.669: INFO: stderr: ""
Feb 21 18:38:25.669: INFO: stdout: "service/rm3 exposed\n"
Feb 21 18:38:25.674: INFO: Service rm3 in namespace e2e-tests-kubectl-gfqgr found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:38:27.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gfqgr" for this suite.
Feb 21 18:38:49.724: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:38:49.824: INFO: namespace: e2e-tests-kubectl-gfqgr, resource: bindings, ignored listing per whitelist
Feb 21 18:38:49.864: INFO: namespace e2e-tests-kubectl-gfqgr deletion completed in 22.16826165s

• [SLOW TEST:30.153 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:38:49.864: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-pnjzh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 21 18:38:50.068: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ee34339a-3607-11e9-816d-1a333d676433" in namespace "e2e-tests-downward-api-pnjzh" to be "success or failure"
Feb 21 18:38:50.074: INFO: Pod "downwardapi-volume-ee34339a-3607-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 6.065882ms
Feb 21 18:38:52.079: INFO: Pod "downwardapi-volume-ee34339a-3607-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011593251s
STEP: Saw pod success
Feb 21 18:38:52.080: INFO: Pod "downwardapi-volume-ee34339a-3607-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:38:52.084: INFO: Trying to get logs from node vm-96433648-4a4e-4d7e-4d24-8065d4ab25dc pod downwardapi-volume-ee34339a-3607-11e9-816d-1a333d676433 container client-container: <nil>
STEP: delete the pod
Feb 21 18:38:52.111: INFO: Waiting for pod downwardapi-volume-ee34339a-3607-11e9-816d-1a333d676433 to disappear
Feb 21 18:38:52.115: INFO: Pod downwardapi-volume-ee34339a-3607-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:38:52.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-pnjzh" for this suite.
Feb 21 18:38:58.143: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:38:58.202: INFO: namespace: e2e-tests-downward-api-pnjzh, resource: bindings, ignored listing per whitelist
Feb 21 18:38:58.284: INFO: namespace e2e-tests-downward-api-pnjzh deletion completed in 6.159459678s

• [SLOW TEST:8.419 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:38:58.284: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-rcpxq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 21 18:38:58.479: INFO: Waiting up to 5m0s for pod "pod-f33774bc-3607-11e9-816d-1a333d676433" in namespace "e2e-tests-emptydir-rcpxq" to be "success or failure"
Feb 21 18:38:58.485: INFO: Pod "pod-f33774bc-3607-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 5.890219ms
Feb 21 18:39:00.498: INFO: Pod "pod-f33774bc-3607-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01861868s
STEP: Saw pod success
Feb 21 18:39:00.498: INFO: Pod "pod-f33774bc-3607-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:39:00.501: INFO: Trying to get logs from node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c pod pod-f33774bc-3607-11e9-816d-1a333d676433 container test-container: <nil>
STEP: delete the pod
Feb 21 18:39:00.525: INFO: Waiting for pod pod-f33774bc-3607-11e9-816d-1a333d676433 to disappear
Feb 21 18:39:00.528: INFO: Pod pod-f33774bc-3607-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:39:00.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-rcpxq" for this suite.
Feb 21 18:39:06.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:39:06.664: INFO: namespace: e2e-tests-emptydir-rcpxq, resource: bindings, ignored listing per whitelist
Feb 21 18:39:06.719: INFO: namespace e2e-tests-emptydir-rcpxq deletion completed in 6.186372885s

• [SLOW TEST:8.435 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:39:06.719: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-5gpfn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-5gpfn
Feb 21 18:39:08.942: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-5gpfn
STEP: checking the pod's current state and verifying that restartCount is present
Feb 21 18:39:08.947: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:43:09.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-5gpfn" for this suite.
Feb 21 18:43:15.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:43:15.868: INFO: namespace: e2e-tests-container-probe-5gpfn, resource: bindings, ignored listing per whitelist
Feb 21 18:43:15.895: INFO: namespace e2e-tests-container-probe-5gpfn deletion completed in 6.163756494s

• [SLOW TEST:249.176 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:43:15.895: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-smsgx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Feb 21 18:43:16.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 create -f - --namespace=e2e-tests-kubectl-smsgx'
Feb 21 18:43:16.312: INFO: stderr: ""
Feb 21 18:43:16.312: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Feb 21 18:43:17.317: INFO: Selector matched 1 pods for map[app:redis]
Feb 21 18:43:17.317: INFO: Found 0 / 1
Feb 21 18:43:18.317: INFO: Selector matched 1 pods for map[app:redis]
Feb 21 18:43:18.317: INFO: Found 1 / 1
Feb 21 18:43:18.317: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 21 18:43:18.321: INFO: Selector matched 1 pods for map[app:redis]
Feb 21 18:43:18.321: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Feb 21 18:43:18.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 logs redis-master-nmt6x redis-master --namespace=e2e-tests-kubectl-smsgx'
Feb 21 18:43:18.414: INFO: stderr: ""
Feb 21 18:43:18.414: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 21 Feb 18:43:17.453 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 Feb 18:43:17.453 # Server started, Redis version 3.2.12\n1:M 21 Feb 18:43:17.453 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 Feb 18:43:17.453 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Feb 21 18:43:18.414: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 log redis-master-nmt6x redis-master --namespace=e2e-tests-kubectl-smsgx --tail=1'
Feb 21 18:43:18.522: INFO: stderr: ""
Feb 21 18:43:18.522: INFO: stdout: "1:M 21 Feb 18:43:17.453 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Feb 21 18:43:18.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 log redis-master-nmt6x redis-master --namespace=e2e-tests-kubectl-smsgx --limit-bytes=1'
Feb 21 18:43:18.608: INFO: stderr: ""
Feb 21 18:43:18.608: INFO: stdout: " "
STEP: exposing timestamps
Feb 21 18:43:18.608: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 log redis-master-nmt6x redis-master --namespace=e2e-tests-kubectl-smsgx --tail=1 --timestamps'
Feb 21 18:43:18.696: INFO: stderr: ""
Feb 21 18:43:18.696: INFO: stdout: "2019-02-21T18:43:17.45391387Z 1:M 21 Feb 18:43:17.453 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Feb 21 18:43:21.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 log redis-master-nmt6x redis-master --namespace=e2e-tests-kubectl-smsgx --since=1s'
Feb 21 18:43:21.286: INFO: stderr: ""
Feb 21 18:43:21.286: INFO: stdout: ""
Feb 21 18:43:21.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 log redis-master-nmt6x redis-master --namespace=e2e-tests-kubectl-smsgx --since=24h'
Feb 21 18:43:21.376: INFO: stderr: ""
Feb 21 18:43:21.376: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 21 Feb 18:43:17.453 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 Feb 18:43:17.453 # Server started, Redis version 3.2.12\n1:M 21 Feb 18:43:17.453 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 Feb 18:43:17.453 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Feb 21 18:43:21.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-smsgx'
Feb 21 18:43:21.461: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 21 18:43:21.461: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Feb 21 18:43:21.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-smsgx'
Feb 21 18:43:21.539: INFO: stderr: "No resources found.\n"
Feb 21 18:43:21.539: INFO: stdout: ""
Feb 21 18:43:21.540: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods -l name=nginx --namespace=e2e-tests-kubectl-smsgx -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 21 18:43:21.611: INFO: stderr: ""
Feb 21 18:43:21.611: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:43:21.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-smsgx" for this suite.
Feb 21 18:43:27.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:43:27.670: INFO: namespace: e2e-tests-kubectl-smsgx, resource: bindings, ignored listing per whitelist
Feb 21 18:43:27.786: INFO: namespace e2e-tests-kubectl-smsgx deletion completed in 6.167831312s

• [SLOW TEST:11.891 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:43:27.786: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-w2cfv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 21 18:43:27.983: INFO: Waiting up to 5m0s for pod "downwardapi-volume-93dacc47-3608-11e9-816d-1a333d676433" in namespace "e2e-tests-downward-api-w2cfv" to be "success or failure"
Feb 21 18:43:27.989: INFO: Pod "downwardapi-volume-93dacc47-3608-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 5.747752ms
Feb 21 18:43:29.994: INFO: Pod "downwardapi-volume-93dacc47-3608-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010885138s
STEP: Saw pod success
Feb 21 18:43:29.994: INFO: Pod "downwardapi-volume-93dacc47-3608-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:43:29.998: INFO: Trying to get logs from node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c pod downwardapi-volume-93dacc47-3608-11e9-816d-1a333d676433 container client-container: <nil>
STEP: delete the pod
Feb 21 18:43:30.030: INFO: Waiting for pod downwardapi-volume-93dacc47-3608-11e9-816d-1a333d676433 to disappear
Feb 21 18:43:30.034: INFO: Pod downwardapi-volume-93dacc47-3608-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:43:30.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-w2cfv" for this suite.
Feb 21 18:43:36.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:43:36.183: INFO: namespace: e2e-tests-downward-api-w2cfv, resource: bindings, ignored listing per whitelist
Feb 21 18:43:36.196: INFO: namespace e2e-tests-downward-api-w2cfv deletion completed in 6.156728225s

• [SLOW TEST:8.410 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:43:36.196: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-h2ct6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-98ddaeb1-3608-11e9-816d-1a333d676433
STEP: Creating a pod to test consume configMaps
Feb 21 18:43:36.399: INFO: Waiting up to 5m0s for pod "pod-configmaps-98deb246-3608-11e9-816d-1a333d676433" in namespace "e2e-tests-configmap-h2ct6" to be "success or failure"
Feb 21 18:43:36.405: INFO: Pod "pod-configmaps-98deb246-3608-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 6.115364ms
Feb 21 18:43:38.410: INFO: Pod "pod-configmaps-98deb246-3608-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010542167s
STEP: Saw pod success
Feb 21 18:43:38.410: INFO: Pod "pod-configmaps-98deb246-3608-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:43:38.413: INFO: Trying to get logs from node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c pod pod-configmaps-98deb246-3608-11e9-816d-1a333d676433 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 21 18:43:38.441: INFO: Waiting for pod pod-configmaps-98deb246-3608-11e9-816d-1a333d676433 to disappear
Feb 21 18:43:38.445: INFO: Pod pod-configmaps-98deb246-3608-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:43:38.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-h2ct6" for this suite.
Feb 21 18:43:44.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:43:44.487: INFO: namespace: e2e-tests-configmap-h2ct6, resource: bindings, ignored listing per whitelist
Feb 21 18:43:44.628: INFO: namespace e2e-tests-configmap-h2ct6 deletion completed in 6.178436558s

• [SLOW TEST:8.432 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:43:44.628: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-92klv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 21 18:43:44.814: INFO: Creating deployment "test-recreate-deployment"
Feb 21 18:43:44.822: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Feb 21 18:43:44.831: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Feb 21 18:43:46.840: INFO: Waiting deployment "test-recreate-deployment" to complete
Feb 21 18:43:46.844: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Feb 21 18:43:46.853: INFO: Updating deployment test-recreate-deployment
Feb 21 18:43:46.853: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 21 18:43:46.954: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-92klv,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-92klv/deployments/test-recreate-deployment,UID:9de49a4e-3608-11e9-bacd-42010a000102,ResourceVersion:11501,Generation:2,CreationTimestamp:2019-02-21 18:43:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-02-21 18:43:46 +0000 UTC 2019-02-21 18:43:46 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-02-21 18:43:46 +0000 UTC 2019-02-21 18:43:44 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Feb 21 18:43:46.959: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-92klv,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-92klv/replicasets/test-recreate-deployment-697fbf54bf,UID:9f227de3-3608-11e9-8547-42010a000100,ResourceVersion:11497,Generation:1,CreationTimestamp:2019-02-21 18:43:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 9de49a4e-3608-11e9-bacd-42010a000102 0xc001fbdb27 0xc001fbdb28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 21 18:43:46.959: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Feb 21 18:43:46.959: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-92klv,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-92klv/replicasets/test-recreate-deployment-5dfdcc846d,UID:9de6c3ca-3608-11e9-8547-42010a000100,ResourceVersion:11489,Generation:2,CreationTimestamp:2019-02-21 18:43:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 9de49a4e-3608-11e9-bacd-42010a000102 0xc001fbda67 0xc001fbda68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 21 18:43:46.963: INFO: Pod "test-recreate-deployment-697fbf54bf-qgw4v" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-qgw4v,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-92klv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-92klv/pods/test-recreate-deployment-697fbf54bf-qgw4v,UID:9f233256-3608-11e9-8547-42010a000100,ResourceVersion:11500,Generation:0,CreationTimestamp:2019-02-21 18:43:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf 9f227de3-3608-11e9-8547-42010a000100 0xc0024ea507 0xc0024ea508}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gmldw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gmldw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-gmldw true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm-899af0be-63fe-4e97-4fe5-b77e233eb87c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024ea570} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024ea590}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 18:43:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 18:43:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 18:43:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 18:43:46 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.5,PodIP:,StartTime:2019-02-21 18:43:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:43:46.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-92klv" for this suite.
Feb 21 18:43:52.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:43:52.999: INFO: namespace: e2e-tests-deployment-92klv, resource: bindings, ignored listing per whitelist
Feb 21 18:43:53.130: INFO: namespace e2e-tests-deployment-92klv deletion completed in 6.16269374s

• [SLOW TEST:8.503 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:43:53.131: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-fwc84
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 21 18:43:53.337: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a2f6fc6f-3608-11e9-816d-1a333d676433" in namespace "e2e-tests-projected-fwc84" to be "success or failure"
Feb 21 18:43:53.345: INFO: Pod "downwardapi-volume-a2f6fc6f-3608-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 7.560214ms
Feb 21 18:43:55.359: INFO: Pod "downwardapi-volume-a2f6fc6f-3608-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021103865s
STEP: Saw pod success
Feb 21 18:43:55.359: INFO: Pod "downwardapi-volume-a2f6fc6f-3608-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:43:55.363: INFO: Trying to get logs from node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c pod downwardapi-volume-a2f6fc6f-3608-11e9-816d-1a333d676433 container client-container: <nil>
STEP: delete the pod
Feb 21 18:43:55.392: INFO: Waiting for pod downwardapi-volume-a2f6fc6f-3608-11e9-816d-1a333d676433 to disappear
Feb 21 18:43:55.396: INFO: Pod downwardapi-volume-a2f6fc6f-3608-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:43:55.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fwc84" for this suite.
Feb 21 18:44:01.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:44:01.472: INFO: namespace: e2e-tests-projected-fwc84, resource: bindings, ignored listing per whitelist
Feb 21 18:44:01.577: INFO: namespace e2e-tests-projected-fwc84 deletion completed in 6.176992282s

• [SLOW TEST:8.446 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:44:01.577: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-bmlp7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 21 18:44:01.802: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a8028997-3608-11e9-816d-1a333d676433" in namespace "e2e-tests-projected-bmlp7" to be "success or failure"
Feb 21 18:44:01.809: INFO: Pod "downwardapi-volume-a8028997-3608-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 7.35631ms
Feb 21 18:44:03.814: INFO: Pod "downwardapi-volume-a8028997-3608-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012357489s
Feb 21 18:44:05.827: INFO: Pod "downwardapi-volume-a8028997-3608-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02555281s
STEP: Saw pod success
Feb 21 18:44:05.827: INFO: Pod "downwardapi-volume-a8028997-3608-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:44:05.831: INFO: Trying to get logs from node vm-96433648-4a4e-4d7e-4d24-8065d4ab25dc pod downwardapi-volume-a8028997-3608-11e9-816d-1a333d676433 container client-container: <nil>
STEP: delete the pod
Feb 21 18:44:05.860: INFO: Waiting for pod downwardapi-volume-a8028997-3608-11e9-816d-1a333d676433 to disappear
Feb 21 18:44:05.864: INFO: Pod downwardapi-volume-a8028997-3608-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:44:05.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bmlp7" for this suite.
Feb 21 18:44:11.888: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:44:11.990: INFO: namespace: e2e-tests-projected-bmlp7, resource: bindings, ignored listing per whitelist
Feb 21 18:44:12.032: INFO: namespace e2e-tests-projected-bmlp7 deletion completed in 6.162710242s

• [SLOW TEST:10.455 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:44:12.032: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-ng9v9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-ae3be74c-3608-11e9-816d-1a333d676433
STEP: Creating a pod to test consume configMaps
Feb 21 18:44:12.250: INFO: Waiting up to 5m0s for pod "pod-configmaps-ae3d2f59-3608-11e9-816d-1a333d676433" in namespace "e2e-tests-configmap-ng9v9" to be "success or failure"
Feb 21 18:44:12.256: INFO: Pod "pod-configmaps-ae3d2f59-3608-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 5.50557ms
Feb 21 18:44:14.264: INFO: Pod "pod-configmaps-ae3d2f59-3608-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013776026s
Feb 21 18:44:16.277: INFO: Pod "pod-configmaps-ae3d2f59-3608-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026721096s
STEP: Saw pod success
Feb 21 18:44:16.277: INFO: Pod "pod-configmaps-ae3d2f59-3608-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:44:16.281: INFO: Trying to get logs from node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c pod pod-configmaps-ae3d2f59-3608-11e9-816d-1a333d676433 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 21 18:44:16.312: INFO: Waiting for pod pod-configmaps-ae3d2f59-3608-11e9-816d-1a333d676433 to disappear
Feb 21 18:44:16.316: INFO: Pod pod-configmaps-ae3d2f59-3608-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:44:16.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-ng9v9" for this suite.
Feb 21 18:44:22.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:44:22.388: INFO: namespace: e2e-tests-configmap-ng9v9, resource: bindings, ignored listing per whitelist
Feb 21 18:44:22.513: INFO: namespace e2e-tests-configmap-ng9v9 deletion completed in 6.191407463s

• [SLOW TEST:10.480 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:44:22.513: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-2wqc9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 21 18:44:22.725: INFO: Waiting up to 5m0s for pod "pod-b47b6ba4-3608-11e9-816d-1a333d676433" in namespace "e2e-tests-emptydir-2wqc9" to be "success or failure"
Feb 21 18:44:22.733: INFO: Pod "pod-b47b6ba4-3608-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 7.533367ms
Feb 21 18:44:24.738: INFO: Pod "pod-b47b6ba4-3608-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013407739s
STEP: Saw pod success
Feb 21 18:44:24.738: INFO: Pod "pod-b47b6ba4-3608-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:44:24.743: INFO: Trying to get logs from node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c pod pod-b47b6ba4-3608-11e9-816d-1a333d676433 container test-container: <nil>
STEP: delete the pod
Feb 21 18:44:24.771: INFO: Waiting for pod pod-b47b6ba4-3608-11e9-816d-1a333d676433 to disappear
Feb 21 18:44:24.775: INFO: Pod pod-b47b6ba4-3608-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:44:24.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-2wqc9" for this suite.
Feb 21 18:44:30.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:44:30.915: INFO: namespace: e2e-tests-emptydir-2wqc9, resource: bindings, ignored listing per whitelist
Feb 21 18:44:30.943: INFO: namespace e2e-tests-emptydir-2wqc9 deletion completed in 6.162046754s

• [SLOW TEST:8.430 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:44:30.943: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-d2tcg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-b97fef80-3608-11e9-816d-1a333d676433
STEP: Creating secret with name secret-projected-all-test-volume-b97fef6a-3608-11e9-816d-1a333d676433
STEP: Creating a pod to test Check all projections for projected volume plugin
Feb 21 18:44:31.158: INFO: Waiting up to 5m0s for pod "projected-volume-b97fef40-3608-11e9-816d-1a333d676433" in namespace "e2e-tests-projected-d2tcg" to be "success or failure"
Feb 21 18:44:31.168: INFO: Pod "projected-volume-b97fef40-3608-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 9.411653ms
Feb 21 18:44:33.173: INFO: Pod "projected-volume-b97fef40-3608-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014191712s
STEP: Saw pod success
Feb 21 18:44:33.173: INFO: Pod "projected-volume-b97fef40-3608-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:44:33.177: INFO: Trying to get logs from node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c pod projected-volume-b97fef40-3608-11e9-816d-1a333d676433 container projected-all-volume-test: <nil>
STEP: delete the pod
Feb 21 18:44:33.205: INFO: Waiting for pod projected-volume-b97fef40-3608-11e9-816d-1a333d676433 to disappear
Feb 21 18:44:33.209: INFO: Pod projected-volume-b97fef40-3608-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:44:33.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-d2tcg" for this suite.
Feb 21 18:44:39.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:44:39.271: INFO: namespace: e2e-tests-projected-d2tcg, resource: bindings, ignored listing per whitelist
Feb 21 18:44:39.372: INFO: namespace e2e-tests-projected-d2tcg deletion completed in 6.158636641s

• [SLOW TEST:8.429 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:44:39.373: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-gtqvr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 21 18:44:39.565: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-gtqvr'
Feb 21 18:44:39.671: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 21 18:44:39.671: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Feb 21 18:44:39.686: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-x4qbx]
Feb 21 18:44:39.686: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-x4qbx" in namespace "e2e-tests-kubectl-gtqvr" to be "running and ready"
Feb 21 18:44:39.690: INFO: Pod "e2e-test-nginx-rc-x4qbx": Phase="Pending", Reason="", readiness=false. Elapsed: 3.808644ms
Feb 21 18:44:41.694: INFO: Pod "e2e-test-nginx-rc-x4qbx": Phase="Running", Reason="", readiness=true. Elapsed: 2.008433563s
Feb 21 18:44:41.695: INFO: Pod "e2e-test-nginx-rc-x4qbx" satisfied condition "running and ready"
Feb 21 18:44:41.695: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-x4qbx]
Feb 21 18:44:41.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-gtqvr'
Feb 21 18:44:41.804: INFO: stderr: ""
Feb 21 18:44:41.804: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Feb 21 18:44:41.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-gtqvr'
Feb 21 18:44:41.899: INFO: stderr: ""
Feb 21 18:44:41.899: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:44:41.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gtqvr" for this suite.
Feb 21 18:44:47.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:44:48.041: INFO: namespace: e2e-tests-kubectl-gtqvr, resource: bindings, ignored listing per whitelist
Feb 21 18:44:48.064: INFO: namespace e2e-tests-kubectl-gtqvr deletion completed in 6.159322548s

• [SLOW TEST:8.692 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:44:48.065: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-qwrsv
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-c3b4f1d5-3608-11e9-816d-1a333d676433
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-c3b4f1d5-3608-11e9-816d-1a333d676433
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:44:52.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-qwrsv" for this suite.
Feb 21 18:45:14.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:45:14.382: INFO: namespace: e2e-tests-configmap-qwrsv, resource: bindings, ignored listing per whitelist
Feb 21 18:45:14.487: INFO: namespace e2e-tests-configmap-qwrsv deletion completed in 22.147345259s

• [SLOW TEST:26.423 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:45:14.487: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-frt8n
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-d3759574-3608-11e9-816d-1a333d676433
STEP: Creating a pod to test consume configMaps
Feb 21 18:45:14.703: INFO: Waiting up to 5m0s for pod "pod-configmaps-d376b388-3608-11e9-816d-1a333d676433" in namespace "e2e-tests-configmap-frt8n" to be "success or failure"
Feb 21 18:45:14.708: INFO: Pod "pod-configmaps-d376b388-3608-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 5.248606ms
Feb 21 18:45:16.713: INFO: Pod "pod-configmaps-d376b388-3608-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009968057s
Feb 21 18:45:18.718: INFO: Pod "pod-configmaps-d376b388-3608-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014708849s
STEP: Saw pod success
Feb 21 18:45:18.718: INFO: Pod "pod-configmaps-d376b388-3608-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:45:18.721: INFO: Trying to get logs from node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c pod pod-configmaps-d376b388-3608-11e9-816d-1a333d676433 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 21 18:45:18.748: INFO: Waiting for pod pod-configmaps-d376b388-3608-11e9-816d-1a333d676433 to disappear
Feb 21 18:45:18.753: INFO: Pod pod-configmaps-d376b388-3608-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:45:18.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-frt8n" for this suite.
Feb 21 18:45:24.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:45:24.863: INFO: namespace: e2e-tests-configmap-frt8n, resource: bindings, ignored listing per whitelist
Feb 21 18:45:24.919: INFO: namespace e2e-tests-configmap-frt8n deletion completed in 6.160984865s

• [SLOW TEST:10.432 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:45:24.919: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-dpxvj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 21 18:45:25.162: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"d9b01336-3608-11e9-bacd-42010a000102", Controller:(*bool)(0xc002434e3e), BlockOwnerDeletion:(*bool)(0xc002434e3f)}}
Feb 21 18:45:25.168: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"d9ad86c1-3608-11e9-bacd-42010a000102", Controller:(*bool)(0xc00255bef6), BlockOwnerDeletion:(*bool)(0xc00255bef7)}}
Feb 21 18:45:25.176: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"d9aeb00d-3608-11e9-bacd-42010a000102", Controller:(*bool)(0xc00205ab3e), BlockOwnerDeletion:(*bool)(0xc00205ab3f)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:45:30.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-dpxvj" for this suite.
Feb 21 18:45:36.215: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:45:36.310: INFO: namespace: e2e-tests-gc-dpxvj, resource: bindings, ignored listing per whitelist
Feb 21 18:45:36.345: INFO: namespace e2e-tests-gc-dpxvj deletion completed in 6.150870425s

• [SLOW TEST:11.426 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:45:36.345: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-8c26n
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-e07bc372-3608-11e9-816d-1a333d676433
STEP: Creating a pod to test consume secrets
Feb 21 18:45:36.555: INFO: Waiting up to 5m0s for pod "pod-secrets-e07ca017-3608-11e9-816d-1a333d676433" in namespace "e2e-tests-secrets-8c26n" to be "success or failure"
Feb 21 18:45:36.559: INFO: Pod "pod-secrets-e07ca017-3608-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 3.843419ms
Feb 21 18:45:38.563: INFO: Pod "pod-secrets-e07ca017-3608-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008572007s
STEP: Saw pod success
Feb 21 18:45:38.563: INFO: Pod "pod-secrets-e07ca017-3608-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:45:38.567: INFO: Trying to get logs from node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c pod pod-secrets-e07ca017-3608-11e9-816d-1a333d676433 container secret-volume-test: <nil>
STEP: delete the pod
Feb 21 18:45:38.593: INFO: Waiting for pod pod-secrets-e07ca017-3608-11e9-816d-1a333d676433 to disappear
Feb 21 18:45:38.596: INFO: Pod pod-secrets-e07ca017-3608-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:45:38.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-8c26n" for this suite.
Feb 21 18:45:44.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:45:44.652: INFO: namespace: e2e-tests-secrets-8c26n, resource: bindings, ignored listing per whitelist
Feb 21 18:45:44.767: INFO: namespace e2e-tests-secrets-8c26n deletion completed in 6.165269858s

• [SLOW TEST:8.421 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:45:44.767: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-fh76t
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:45:50.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-fh76t" for this suite.
Feb 21 18:46:12.029: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:46:12.119: INFO: namespace: e2e-tests-replication-controller-fh76t, resource: bindings, ignored listing per whitelist
Feb 21 18:46:12.171: INFO: namespace e2e-tests-replication-controller-fh76t deletion completed in 22.162697258s

• [SLOW TEST:27.404 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:46:12.171: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-wkbhg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 21 18:46:14.901: INFO: Successfully updated pod "pod-update-activedeadlineseconds-f5d669ae-3608-11e9-816d-1a333d676433"
Feb 21 18:46:14.901: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-f5d669ae-3608-11e9-816d-1a333d676433" in namespace "e2e-tests-pods-wkbhg" to be "terminated due to deadline exceeded"
Feb 21 18:46:14.905: INFO: Pod "pod-update-activedeadlineseconds-f5d669ae-3608-11e9-816d-1a333d676433": Phase="Running", Reason="", readiness=true. Elapsed: 3.731253ms
Feb 21 18:46:16.917: INFO: Pod "pod-update-activedeadlineseconds-f5d669ae-3608-11e9-816d-1a333d676433": Phase="Running", Reason="", readiness=true. Elapsed: 2.016050533s
Feb 21 18:46:18.922: INFO: Pod "pod-update-activedeadlineseconds-f5d669ae-3608-11e9-816d-1a333d676433": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.021149764s
Feb 21 18:46:18.922: INFO: Pod "pod-update-activedeadlineseconds-f5d669ae-3608-11e9-816d-1a333d676433" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:46:18.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-wkbhg" for this suite.
Feb 21 18:46:24.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:46:25.032: INFO: namespace: e2e-tests-pods-wkbhg, resource: bindings, ignored listing per whitelist
Feb 21 18:46:25.091: INFO: namespace e2e-tests-pods-wkbhg deletion completed in 6.163604358s

• [SLOW TEST:12.920 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:46:25.091: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-7fwhk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-7fwhk
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-7fwhk to expose endpoints map[]
Feb 21 18:46:25.301: INFO: Get endpoints failed (4.997725ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Feb 21 18:46:26.306: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-7fwhk exposes endpoints map[] (1.010792324s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-7fwhk
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-7fwhk to expose endpoints map[pod1:[80]]
Feb 21 18:46:28.355: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-7fwhk exposes endpoints map[pod1:[80]] (2.036858065s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-7fwhk
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-7fwhk to expose endpoints map[pod1:[80] pod2:[80]]
Feb 21 18:46:30.403: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-7fwhk exposes endpoints map[pod1:[80] pod2:[80]] (2.042170282s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-7fwhk
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-7fwhk to expose endpoints map[pod2:[80]]
Feb 21 18:46:31.430: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-7fwhk exposes endpoints map[pod2:[80]] (1.01894442s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-7fwhk
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-7fwhk to expose endpoints map[]
Feb 21 18:46:31.446: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-7fwhk exposes endpoints map[] (6.583659ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:46:31.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-7fwhk" for this suite.
Feb 21 18:46:53.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:46:53.537: INFO: namespace: e2e-tests-services-7fwhk, resource: bindings, ignored listing per whitelist
Feb 21 18:46:53.636: INFO: namespace e2e-tests-services-7fwhk deletion completed in 22.153987261s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:28.545 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:46:53.637: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-bc52l
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 21 18:46:53.841: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0e8db4dc-3609-11e9-816d-1a333d676433" in namespace "e2e-tests-projected-bc52l" to be "success or failure"
Feb 21 18:46:53.846: INFO: Pod "downwardapi-volume-0e8db4dc-3609-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 5.249223ms
Feb 21 18:46:55.851: INFO: Pod "downwardapi-volume-0e8db4dc-3609-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010557056s
Feb 21 18:46:57.856: INFO: Pod "downwardapi-volume-0e8db4dc-3609-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01523297s
STEP: Saw pod success
Feb 21 18:46:57.856: INFO: Pod "downwardapi-volume-0e8db4dc-3609-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:46:57.859: INFO: Trying to get logs from node vm-96433648-4a4e-4d7e-4d24-8065d4ab25dc pod downwardapi-volume-0e8db4dc-3609-11e9-816d-1a333d676433 container client-container: <nil>
STEP: delete the pod
Feb 21 18:46:57.888: INFO: Waiting for pod downwardapi-volume-0e8db4dc-3609-11e9-816d-1a333d676433 to disappear
Feb 21 18:46:57.891: INFO: Pod downwardapi-volume-0e8db4dc-3609-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:46:57.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bc52l" for this suite.
Feb 21 18:47:03.916: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:47:04.038: INFO: namespace: e2e-tests-projected-bc52l, resource: bindings, ignored listing per whitelist
Feb 21 18:47:04.053: INFO: namespace e2e-tests-projected-bc52l deletion completed in 6.157376923s

• [SLOW TEST:10.417 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:47:04.054: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-9v8h5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 21 18:47:04.246: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:47:08.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-9v8h5" for this suite.
Feb 21 18:47:14.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:47:14.680: INFO: namespace: e2e-tests-init-container-9v8h5, resource: bindings, ignored listing per whitelist
Feb 21 18:47:14.725: INFO: namespace e2e-tests-init-container-9v8h5 deletion completed in 6.156388343s

• [SLOW TEST:10.671 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:47:14.725: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-fd9bf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 21 18:47:14.946: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Feb 21 18:47:14.963: INFO: Number of nodes with available pods: 0
Feb 21 18:47:14.963: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:47:15.978: INFO: Number of nodes with available pods: 0
Feb 21 18:47:15.978: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 18:47:16.973: INFO: Number of nodes with available pods: 3
Feb 21 18:47:16.973: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Feb 21 18:47:17.000: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:17.000: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:17.000: INFO: Wrong image for pod: daemon-set-xkm5t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:18.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:18.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:18.012: INFO: Wrong image for pod: daemon-set-xkm5t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:19.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:19.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:19.012: INFO: Wrong image for pod: daemon-set-xkm5t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:20.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:20.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:20.012: INFO: Wrong image for pod: daemon-set-xkm5t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:21.019: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:21.019: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:21.019: INFO: Wrong image for pod: daemon-set-xkm5t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:22.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:22.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:22.012: INFO: Wrong image for pod: daemon-set-xkm5t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:23.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:23.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:23.012: INFO: Wrong image for pod: daemon-set-xkm5t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:24.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:24.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:24.012: INFO: Wrong image for pod: daemon-set-xkm5t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:25.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:25.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:25.012: INFO: Wrong image for pod: daemon-set-xkm5t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:26.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:26.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:26.012: INFO: Wrong image for pod: daemon-set-xkm5t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:27.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:27.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:27.012: INFO: Wrong image for pod: daemon-set-xkm5t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:28.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:28.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:28.012: INFO: Wrong image for pod: daemon-set-xkm5t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:29.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:29.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:29.012: INFO: Wrong image for pod: daemon-set-xkm5t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:30.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:30.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:30.012: INFO: Wrong image for pod: daemon-set-xkm5t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:31.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:31.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:31.012: INFO: Wrong image for pod: daemon-set-xkm5t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:32.019: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:32.019: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:32.019: INFO: Wrong image for pod: daemon-set-xkm5t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:33.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:33.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:33.012: INFO: Wrong image for pod: daemon-set-xkm5t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:34.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:34.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:34.012: INFO: Wrong image for pod: daemon-set-xkm5t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:35.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:35.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:35.012: INFO: Wrong image for pod: daemon-set-xkm5t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:36.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:36.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:36.012: INFO: Wrong image for pod: daemon-set-xkm5t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:37.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:37.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:37.012: INFO: Wrong image for pod: daemon-set-xkm5t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:38.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:38.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:38.012: INFO: Wrong image for pod: daemon-set-xkm5t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:39.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:39.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:39.012: INFO: Wrong image for pod: daemon-set-xkm5t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:40.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:40.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:40.012: INFO: Wrong image for pod: daemon-set-xkm5t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:41.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:41.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:41.012: INFO: Wrong image for pod: daemon-set-xkm5t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:42.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:42.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:42.012: INFO: Wrong image for pod: daemon-set-xkm5t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:43.020: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:43.020: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:43.020: INFO: Wrong image for pod: daemon-set-xkm5t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:44.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:44.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:44.012: INFO: Wrong image for pod: daemon-set-xkm5t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:45.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:45.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:45.012: INFO: Wrong image for pod: daemon-set-xkm5t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:46.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:46.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:46.012: INFO: Wrong image for pod: daemon-set-xkm5t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:47.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:47.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:47.012: INFO: Wrong image for pod: daemon-set-xkm5t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:48.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:48.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:48.012: INFO: Wrong image for pod: daemon-set-xkm5t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:49.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:49.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:49.012: INFO: Wrong image for pod: daemon-set-xkm5t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:50.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:50.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:50.012: INFO: Wrong image for pod: daemon-set-xkm5t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:50.012: INFO: Pod daemon-set-xkm5t is not available
Feb 21 18:47:51.013: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:51.013: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:51.013: INFO: Wrong image for pod: daemon-set-xkm5t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:51.013: INFO: Pod daemon-set-xkm5t is not available
Feb 21 18:47:52.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:52.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:52.012: INFO: Wrong image for pod: daemon-set-xkm5t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:52.012: INFO: Pod daemon-set-xkm5t is not available
Feb 21 18:47:53.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:53.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:53.012: INFO: Wrong image for pod: daemon-set-xkm5t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:53.012: INFO: Pod daemon-set-xkm5t is not available
Feb 21 18:47:54.020: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:54.020: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:54.020: INFO: Wrong image for pod: daemon-set-xkm5t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:54.020: INFO: Pod daemon-set-xkm5t is not available
Feb 21 18:47:55.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:55.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:55.012: INFO: Pod daemon-set-dr7fj is not available
Feb 21 18:47:56.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:56.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:56.012: INFO: Pod daemon-set-dr7fj is not available
Feb 21 18:47:57.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:57.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:57.012: INFO: Pod daemon-set-dr7fj is not available
Feb 21 18:47:58.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:58.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:59.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:47:59.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:00.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:00.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:01.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:01.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:02.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:02.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:03.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:03.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:04.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:04.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:05.020: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:05.021: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:06.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:06.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:07.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:07.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:08.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:08.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:09.011: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:09.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:10.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:10.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:11.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:11.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:12.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:12.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:13.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:13.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:14.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:14.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:15.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:15.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:16.019: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:16.019: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:17.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:17.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:18.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:18.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:19.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:19.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:20.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:20.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:21.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:21.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:22.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:22.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:23.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:23.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:24.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:24.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:25.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:25.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:26.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:26.013: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:27.021: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:27.021: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:28.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:28.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:29.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:29.012: INFO: Pod daemon-set-6ldhw is not available
Feb 21 18:48:29.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:30.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:30.012: INFO: Pod daemon-set-6ldhw is not available
Feb 21 18:48:30.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:31.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:31.012: INFO: Pod daemon-set-6ldhw is not available
Feb 21 18:48:31.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:32.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:32.012: INFO: Pod daemon-set-6ldhw is not available
Feb 21 18:48:32.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:33.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:33.012: INFO: Pod daemon-set-6ldhw is not available
Feb 21 18:48:33.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:34.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:34.012: INFO: Pod daemon-set-6ldhw is not available
Feb 21 18:48:34.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:35.012: INFO: Wrong image for pod: daemon-set-6ldhw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:35.012: INFO: Pod daemon-set-6ldhw is not available
Feb 21 18:48:35.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:36.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:36.012: INFO: Pod daemon-set-pfqmc is not available
Feb 21 18:48:37.011: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:37.011: INFO: Pod daemon-set-pfqmc is not available
Feb 21 18:48:38.020: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:39.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:40.011: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:41.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:42.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:43.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:44.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:45.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:46.011: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:47.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:48.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:49.019: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:50.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:51.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:52.011: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:53.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:54.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:55.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:56.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:57.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:58.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:48:59.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:49:00.020: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:49:01.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:49:02.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:49:03.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:49:04.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:49:05.013: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:49:06.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:49:07.013: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:49:08.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:49:09.012: INFO: Wrong image for pod: daemon-set-6qp2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 21 18:49:09.013: INFO: Pod daemon-set-6qp2l is not available
Feb 21 18:49:10.013: INFO: Pod daemon-set-n59z9 is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Feb 21 18:49:10.036: INFO: Number of nodes with available pods: 2
Feb 21 18:49:10.036: INFO: Node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c is running more than one daemon pod
Feb 21 18:49:11.047: INFO: Number of nodes with available pods: 2
Feb 21 18:49:11.047: INFO: Node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c is running more than one daemon pod
Feb 21 18:49:12.047: INFO: Number of nodes with available pods: 3
Feb 21 18:49:12.047: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-fd9bf, will wait for the garbage collector to delete the pods
Feb 21 18:49:12.133: INFO: Deleting DaemonSet.extensions daemon-set took: 11.675169ms
Feb 21 18:49:12.233: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.395833ms
Feb 21 18:49:25.446: INFO: Number of nodes with available pods: 0
Feb 21 18:49:25.446: INFO: Number of running nodes: 0, number of available pods: 0
Feb 21 18:49:25.449: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-fd9bf/daemonsets","resourceVersion":"12669"},"items":null}

Feb 21 18:49:25.452: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-fd9bf/pods","resourceVersion":"12669"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:49:25.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-fd9bf" for this suite.
Feb 21 18:49:31.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:49:31.517: INFO: namespace: e2e-tests-daemonsets-fd9bf, resource: bindings, ignored listing per whitelist
Feb 21 18:49:31.651: INFO: namespace e2e-tests-daemonsets-fd9bf deletion completed in 6.179492582s

• [SLOW TEST:136.926 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:49:31.652: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-vnp2j
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-vnp2j
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-vnp2j to expose endpoints map[]
Feb 21 18:49:31.890: INFO: Get endpoints failed (9.123076ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Feb 21 18:49:32.896: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-vnp2j exposes endpoints map[] (1.014848739s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-vnp2j
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-vnp2j to expose endpoints map[pod1:[100]]
Feb 21 18:49:34.943: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-vnp2j exposes endpoints map[pod1:[100]] (2.036483318s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-vnp2j
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-vnp2j to expose endpoints map[pod1:[100] pod2:[101]]
Feb 21 18:49:37.003: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-vnp2j exposes endpoints map[pod1:[100] pod2:[101]] (2.052139722s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-vnp2j
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-vnp2j to expose endpoints map[pod2:[101]]
Feb 21 18:49:38.028: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-vnp2j exposes endpoints map[pod2:[101]] (1.016757782s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-vnp2j
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-vnp2j to expose endpoints map[]
Feb 21 18:49:38.043: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-vnp2j exposes endpoints map[] (5.769519ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:49:38.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-vnp2j" for this suite.
Feb 21 18:49:52.097: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:49:52.135: INFO: namespace: e2e-tests-services-vnp2j, resource: bindings, ignored listing per whitelist
Feb 21 18:49:52.247: INFO: namespace e2e-tests-services-vnp2j deletion completed in 14.169901187s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:20.596 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:49:52.247: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-58glz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-f9qdb in namespace e2e-tests-proxy-58glz
I0221 18:49:52.465446      18 runners.go:184] Created replication controller with name: proxy-service-f9qdb, namespace: e2e-tests-proxy-58glz, replica count: 1
I0221 18:49:53.516922      18 runners.go:184] proxy-service-f9qdb Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0221 18:49:54.517305      18 runners.go:184] proxy-service-f9qdb Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0221 18:49:55.517558      18 runners.go:184] proxy-service-f9qdb Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0221 18:49:56.517832      18 runners.go:184] proxy-service-f9qdb Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0221 18:49:57.518046      18 runners.go:184] proxy-service-f9qdb Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0221 18:49:58.518322      18 runners.go:184] proxy-service-f9qdb Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0221 18:49:59.518582      18 runners.go:184] proxy-service-f9qdb Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0221 18:50:00.518862      18 runners.go:184] proxy-service-f9qdb Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0221 18:50:01.519144      18 runners.go:184] proxy-service-f9qdb Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0221 18:50:02.519362      18 runners.go:184] proxy-service-f9qdb Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0221 18:50:03.519641      18 runners.go:184] proxy-service-f9qdb Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0221 18:50:04.519855      18 runners.go:184] proxy-service-f9qdb Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 21 18:50:04.531: INFO: setup took 12.089855356s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Feb 21 18:50:04.540: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp/proxy/rewriteme"... (200; 7.967719ms)
Feb 21 18:50:04.541: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:1080/proxy/rewri... (200; 8.804438ms)
Feb 21 18:50:04.541: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:162/proxy/: bar (200; 9.04395ms)
Feb 21 18:50:04.545: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-58glz/services/http:proxy-service-f9qdb:portname2/proxy/: bar (200; 12.803233ms)
Feb 21 18:50:04.546: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-58glz/services/proxy-service-f9qdb:portname2/proxy/: bar (200; 14.033802ms)
Feb 21 18:50:04.546: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:160/proxy/: foo (200; 14.487576ms)
Feb 21 18:50:04.546: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:160/proxy/: foo (200; 14.682747ms)
Feb 21 18:50:04.548: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:162/proxy/: bar (200; 16.299512ms)
Feb 21 18:50:04.548: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-58glz/services/http:proxy-service-f9qdb:portname1/proxy/: foo (200; 16.538845ms)
Feb 21 18:50:04.549: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-58glz/services/proxy-service-f9qdb:portname1/proxy/: foo (200; 16.971034ms)
Feb 21 18:50:04.549: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:443/proxy/... (200; 17.64675ms)
Feb 21 18:50:04.549: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:1080/proxy/... (200; 17.761613ms)
Feb 21 18:50:04.550: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:462/proxy/: tls qux (200; 18.143909ms)
Feb 21 18:50:04.551: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-58glz/services/https:proxy-service-f9qdb:tlsportname2/proxy/: tls qux (200; 18.999156ms)
Feb 21 18:50:04.551: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-58glz/services/https:proxy-service-f9qdb:tlsportname1/proxy/: tls baz (200; 19.46485ms)
Feb 21 18:50:04.555: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:460/proxy/: tls baz (200; 22.797684ms)
Feb 21 18:50:04.565: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:460/proxy/: tls baz (200; 9.953035ms)
Feb 21 18:50:04.565: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:1080/proxy/rewri... (200; 10.436581ms)
Feb 21 18:50:04.566: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp/proxy/rewriteme"... (200; 10.742865ms)
Feb 21 18:50:04.566: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:443/proxy/... (200; 11.28412ms)
Feb 21 18:50:04.566: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:1080/proxy/... (200; 11.416374ms)
Feb 21 18:50:04.567: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:160/proxy/: foo (200; 11.911743ms)
Feb 21 18:50:04.567: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:160/proxy/: foo (200; 11.638489ms)
Feb 21 18:50:04.567: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:162/proxy/: bar (200; 11.855572ms)
Feb 21 18:50:04.567: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:162/proxy/: bar (200; 11.629584ms)
Feb 21 18:50:04.567: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:462/proxy/: tls qux (200; 11.923645ms)
Feb 21 18:50:04.569: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-58glz/services/proxy-service-f9qdb:portname2/proxy/: bar (200; 14.589637ms)
Feb 21 18:50:04.571: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-58glz/services/https:proxy-service-f9qdb:tlsportname1/proxy/: tls baz (200; 16.518434ms)
Feb 21 18:50:04.572: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-58glz/services/https:proxy-service-f9qdb:tlsportname2/proxy/: tls qux (200; 16.869982ms)
Feb 21 18:50:04.572: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-58glz/services/http:proxy-service-f9qdb:portname2/proxy/: bar (200; 17.457919ms)
Feb 21 18:50:04.573: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-58glz/services/proxy-service-f9qdb:portname1/proxy/: foo (200; 18.399894ms)
Feb 21 18:50:04.574: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-58glz/services/http:proxy-service-f9qdb:portname1/proxy/: foo (200; 18.692224ms)
Feb 21 18:50:04.582: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:460/proxy/: tls baz (200; 8.236578ms)
Feb 21 18:50:04.585: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:462/proxy/: tls qux (200; 10.709033ms)
Feb 21 18:50:04.585: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:1080/proxy/... (200; 10.796861ms)
Feb 21 18:50:04.585: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:162/proxy/: bar (200; 11.064378ms)
Feb 21 18:50:04.585: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-58glz/services/https:proxy-service-f9qdb:tlsportname1/proxy/: tls baz (200; 11.17158ms)
Feb 21 18:50:04.585: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:162/proxy/: bar (200; 11.342767ms)
Feb 21 18:50:04.585: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:160/proxy/: foo (200; 11.644184ms)
Feb 21 18:50:04.585: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:443/proxy/... (200; 11.661388ms)
Feb 21 18:50:04.585: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:1080/proxy/rewri... (200; 11.693273ms)
Feb 21 18:50:04.586: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:160/proxy/: foo (200; 11.896328ms)
Feb 21 18:50:04.586: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp/proxy/rewriteme"... (200; 11.662586ms)
Feb 21 18:50:04.588: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-58glz/services/https:proxy-service-f9qdb:tlsportname2/proxy/: tls qux (200; 14.210671ms)
Feb 21 18:50:04.588: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-58glz/services/proxy-service-f9qdb:portname2/proxy/: bar (200; 14.094667ms)
Feb 21 18:50:04.588: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-58glz/services/http:proxy-service-f9qdb:portname2/proxy/: bar (200; 14.409512ms)
Feb 21 18:50:04.588: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-58glz/services/proxy-service-f9qdb:portname1/proxy/: foo (200; 14.420341ms)
Feb 21 18:50:04.588: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-58glz/services/http:proxy-service-f9qdb:portname1/proxy/: foo (200; 14.741634ms)
Feb 21 18:50:04.594: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp/proxy/rewriteme"... (200; 5.638947ms)
Feb 21 18:50:04.595: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:1080/proxy/... (200; 6.483756ms)
Feb 21 18:50:04.595: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:1080/proxy/rewri... (200; 6.504598ms)
Feb 21 18:50:04.596: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:162/proxy/: bar (200; 6.788212ms)
Feb 21 18:50:04.597: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:160/proxy/: foo (200; 8.330684ms)
Feb 21 18:50:04.598: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:160/proxy/: foo (200; 9.157219ms)
Feb 21 18:50:04.598: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:162/proxy/: bar (200; 9.264515ms)
Feb 21 18:50:04.598: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:462/proxy/: tls qux (200; 9.607126ms)
Feb 21 18:50:04.599: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-58glz/services/https:proxy-service-f9qdb:tlsportname2/proxy/: tls qux (200; 10.136732ms)
Feb 21 18:50:04.599: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-58glz/services/http:proxy-service-f9qdb:portname1/proxy/: foo (200; 10.341665ms)
Feb 21 18:50:04.599: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-58glz/services/http:proxy-service-f9qdb:portname2/proxy/: bar (200; 10.142134ms)
Feb 21 18:50:04.599: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:443/proxy/... (200; 10.258641ms)
Feb 21 18:50:04.599: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:460/proxy/: tls baz (200; 10.501539ms)
Feb 21 18:50:04.601: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-58glz/services/proxy-service-f9qdb:portname2/proxy/: bar (200; 11.76541ms)
Feb 21 18:50:04.602: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-58glz/services/proxy-service-f9qdb:portname1/proxy/: foo (200; 12.654058ms)
Feb 21 18:50:04.602: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-58glz/services/https:proxy-service-f9qdb:tlsportname1/proxy/: tls baz (200; 12.756386ms)
Feb 21 18:50:04.609: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:162/proxy/: bar (200; 6.936136ms)
Feb 21 18:50:04.609: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:160/proxy/: foo (200; 7.583665ms)
Feb 21 18:50:04.611: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:462/proxy/: tls qux (200; 8.63105ms)
Feb 21 18:50:04.611: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:1080/proxy/... (200; 9.50328ms)
Feb 21 18:50:04.611: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:1080/proxy/rewri... (200; 9.534433ms)
Feb 21 18:50:04.612: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-58glz/services/https:proxy-service-f9qdb:tlsportname1/proxy/: tls baz (200; 10.196135ms)
Feb 21 18:50:04.612: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:460/proxy/: tls baz (200; 9.96994ms)
Feb 21 18:50:04.612: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:160/proxy/: foo (200; 10.008886ms)
Feb 21 18:50:04.612: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-58glz/services/http:proxy-service-f9qdb:portname1/proxy/: foo (200; 9.948948ms)
Feb 21 18:50:04.612: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:443/proxy/... (200; 10.062531ms)
Feb 21 18:50:04.612: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:162/proxy/: bar (200; 9.997619ms)
Feb 21 18:50:04.612: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-58glz/services/https:proxy-service-f9qdb:tlsportname2/proxy/: tls qux (200; 10.720584ms)
Feb 21 18:50:04.612: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp/proxy/rewriteme"... (200; 10.572265ms)
Feb 21 18:50:04.613: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-58glz/services/proxy-service-f9qdb:portname2/proxy/: bar (200; 11.230562ms)
Feb 21 18:50:04.613: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-58glz/services/proxy-service-f9qdb:portname1/proxy/: foo (200; 11.418502ms)
Feb 21 18:50:04.613: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-58glz/services/http:proxy-service-f9qdb:portname2/proxy/: bar (200; 11.374318ms)
Feb 21 18:50:04.620: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:1080/proxy/rewri... (200; 6.795735ms)
Feb 21 18:50:04.623: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp/proxy/rewriteme"... (200; 8.968757ms)
Feb 21 18:50:04.623: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:443/proxy/... (200; 9.472433ms)
Feb 21 18:50:04.624: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:462/proxy/: tls qux (200; 10.331431ms)
Feb 21 18:50:04.624: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:160/proxy/: foo (200; 10.321979ms)
Feb 21 18:50:04.624: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:162/proxy/: bar (200; 10.429052ms)
Feb 21 18:50:04.625: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:460/proxy/: tls baz (200; 11.353174ms)
Feb 21 18:50:04.625: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:162/proxy/: bar (200; 11.380101ms)
Feb 21 18:50:04.625: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:1080/proxy/... (200; 11.399501ms)
Feb 21 18:50:04.625: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:160/proxy/: foo (200; 11.409171ms)
Feb 21 18:50:04.625: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-58glz/services/http:proxy-service-f9qdb:portname2/proxy/: bar (200; 11.568187ms)
Feb 21 18:50:04.628: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-58glz/services/https:proxy-service-f9qdb:tlsportname1/proxy/: tls baz (200; 14.398774ms)
Feb 21 18:50:04.629: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-58glz/services/proxy-service-f9qdb:portname1/proxy/: foo (200; 15.059238ms)
Feb 21 18:50:04.629: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-58glz/services/https:proxy-service-f9qdb:tlsportname2/proxy/: tls qux (200; 15.023018ms)
Feb 21 18:50:04.629: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-58glz/services/proxy-service-f9qdb:portname2/proxy/: bar (200; 15.13628ms)
Feb 21 18:50:04.629: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-58glz/services/http:proxy-service-f9qdb:portname1/proxy/: foo (200; 15.206447ms)
Feb 21 18:50:04.635: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:443/proxy/... (200; 5.468616ms)
Feb 21 18:50:04.636: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:1080/proxy/rewri... (200; 6.746367ms)
Feb 21 18:50:04.637: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp/proxy/rewriteme"... (200; 7.988478ms)
Feb 21 18:50:04.638: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:160/proxy/: foo (200; 8.367ms)
Feb 21 18:50:04.638: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:460/proxy/: tls baz (200; 9.257236ms)
Feb 21 18:50:04.639: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:162/proxy/: bar (200; 9.541777ms)
Feb 21 18:50:04.639: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:462/proxy/: tls qux (200; 10.038401ms)
Feb 21 18:50:04.639: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:162/proxy/: bar (200; 10.024262ms)
Feb 21 18:50:04.639: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:1080/proxy/... (200; 10.001354ms)
Feb 21 18:50:04.639: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:160/proxy/: foo (200; 10.192739ms)
Feb 21 18:50:04.640: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-58glz/services/https:proxy-service-f9qdb:tlsportname2/proxy/: tls qux (200; 10.934975ms)
Feb 21 18:50:04.641: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-58glz/services/https:proxy-service-f9qdb:tlsportname1/proxy/: tls baz (200; 11.327717ms)
Feb 21 18:50:04.641: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-58glz/services/http:proxy-service-f9qdb:portname1/proxy/: foo (200; 11.583327ms)
Feb 21 18:50:04.641: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-58glz/services/proxy-service-f9qdb:portname2/proxy/: bar (200; 11.638478ms)
Feb 21 18:50:04.641: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-58glz/services/proxy-service-f9qdb:portname1/proxy/: foo (200; 11.851371ms)
Feb 21 18:50:04.641: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-58glz/services/http:proxy-service-f9qdb:portname2/proxy/: bar (200; 11.869919ms)
Feb 21 18:50:04.647: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:162/proxy/: bar (200; 5.977657ms)
Feb 21 18:50:04.647: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:1080/proxy/rewri... (200; 6.301025ms)
Feb 21 18:50:04.648: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:162/proxy/: bar (200; 6.356219ms)
Feb 21 18:50:04.648: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:460/proxy/: tls baz (200; 6.688946ms)
Feb 21 18:50:04.649: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:1080/proxy/... (200; 7.205526ms)
Feb 21 18:50:04.649: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp/proxy/rewriteme"... (200; 7.666861ms)
Feb 21 18:50:04.649: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:443/proxy/... (200; 7.834277ms)
Feb 21 18:50:04.649: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:462/proxy/: tls qux (200; 7.696015ms)
Feb 21 18:50:04.650: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:160/proxy/: foo (200; 8.123724ms)
Feb 21 18:50:04.650: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-58glz/services/proxy-service-f9qdb:portname2/proxy/: bar (200; 8.982495ms)
Feb 21 18:50:04.650: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:160/proxy/: foo (200; 8.8527ms)
Feb 21 18:50:04.652: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-58glz/services/https:proxy-service-f9qdb:tlsportname1/proxy/: tls baz (200; 10.73716ms)
Feb 21 18:50:04.653: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-58glz/services/proxy-service-f9qdb:portname1/proxy/: foo (200; 11.302885ms)
Feb 21 18:50:04.653: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-58glz/services/http:proxy-service-f9qdb:portname2/proxy/: bar (200; 11.171638ms)
Feb 21 18:50:04.653: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-58glz/services/https:proxy-service-f9qdb:tlsportname2/proxy/: tls qux (200; 11.312864ms)
Feb 21 18:50:04.653: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-58glz/services/http:proxy-service-f9qdb:portname1/proxy/: foo (200; 11.418355ms)
Feb 21 18:50:04.658: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:160/proxy/: foo (200; 5.259215ms)
Feb 21 18:50:04.661: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:160/proxy/: foo (200; 7.304927ms)
Feb 21 18:50:04.661: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:1080/proxy/rewri... (200; 7.821016ms)
Feb 21 18:50:04.662: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:162/proxy/: bar (200; 8.970086ms)
Feb 21 18:50:04.663: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp/proxy/rewriteme"... (200; 9.990078ms)
Feb 21 18:50:04.663: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:1080/proxy/... (200; 10.196507ms)
Feb 21 18:50:04.664: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:462/proxy/: tls qux (200; 10.149539ms)
Feb 21 18:50:04.664: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-58glz/services/http:proxy-service-f9qdb:portname2/proxy/: bar (200; 10.439932ms)
Feb 21 18:50:04.664: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:460/proxy/: tls baz (200; 9.852264ms)
Feb 21 18:50:04.664: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:162/proxy/: bar (200; 10.284793ms)
Feb 21 18:50:04.664: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:443/proxy/... (200; 10.404426ms)
Feb 21 18:50:04.665: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-58glz/services/https:proxy-service-f9qdb:tlsportname1/proxy/: tls baz (200; 11.626147ms)
Feb 21 18:50:04.667: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-58glz/services/proxy-service-f9qdb:portname2/proxy/: bar (200; 13.112605ms)
Feb 21 18:50:04.667: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-58glz/services/https:proxy-service-f9qdb:tlsportname2/proxy/: tls qux (200; 13.178743ms)
Feb 21 18:50:04.667: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-58glz/services/proxy-service-f9qdb:portname1/proxy/: foo (200; 13.33272ms)
Feb 21 18:50:04.667: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-58glz/services/http:proxy-service-f9qdb:portname1/proxy/: foo (200; 13.952591ms)
Feb 21 18:50:04.675: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp/proxy/rewriteme"... (200; 7.470853ms)
Feb 21 18:50:04.675: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:1080/proxy/rewri... (200; 8.116818ms)
Feb 21 18:50:04.676: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:462/proxy/: tls qux (200; 8.372311ms)
Feb 21 18:50:04.676: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-58glz/services/proxy-service-f9qdb:portname1/proxy/: foo (200; 9.003996ms)
Feb 21 18:50:04.677: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:162/proxy/: bar (200; 9.00516ms)
Feb 21 18:50:04.678: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:162/proxy/: bar (200; 10.095794ms)
Feb 21 18:50:04.678: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:160/proxy/: foo (200; 10.3577ms)
Feb 21 18:50:04.679: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-58glz/services/https:proxy-service-f9qdb:tlsportname1/proxy/: tls baz (200; 10.981743ms)
Feb 21 18:50:04.679: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:443/proxy/... (200; 11.837269ms)
Feb 21 18:50:04.679: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:160/proxy/: foo (200; 11.539711ms)
Feb 21 18:50:04.679: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-58glz/services/https:proxy-service-f9qdb:tlsportname2/proxy/: tls qux (200; 11.793554ms)
Feb 21 18:50:04.679: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-58glz/services/http:proxy-service-f9qdb:portname2/proxy/: bar (200; 11.992436ms)
Feb 21 18:50:04.680: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:460/proxy/: tls baz (200; 12.506797ms)
Feb 21 18:50:04.680: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:1080/proxy/... (200; 12.089091ms)
Feb 21 18:50:04.680: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-58glz/services/proxy-service-f9qdb:portname2/proxy/: bar (200; 12.485349ms)
Feb 21 18:50:04.680: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-58glz/services/http:proxy-service-f9qdb:portname1/proxy/: foo (200; 12.327922ms)
Feb 21 18:50:04.685: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:460/proxy/: tls baz (200; 5.449206ms)
Feb 21 18:50:04.688: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:160/proxy/: foo (200; 7.462295ms)
Feb 21 18:50:04.688: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:1080/proxy/... (200; 8.086141ms)
Feb 21 18:50:04.690: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:162/proxy/: bar (200; 10.118154ms)
Feb 21 18:50:04.691: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:443/proxy/... (200; 10.122154ms)
Feb 21 18:50:04.691: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp/proxy/rewriteme"... (200; 10.824603ms)
Feb 21 18:50:04.692: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-58glz/services/http:proxy-service-f9qdb:portname1/proxy/: foo (200; 11.429323ms)
Feb 21 18:50:04.692: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-58glz/services/https:proxy-service-f9qdb:tlsportname2/proxy/: tls qux (200; 11.582641ms)
Feb 21 18:50:04.692: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:462/proxy/: tls qux (200; 11.274616ms)
Feb 21 18:50:04.692: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:1080/proxy/rewri... (200; 11.741593ms)
Feb 21 18:50:04.692: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:162/proxy/: bar (200; 11.631215ms)
Feb 21 18:50:04.692: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:160/proxy/: foo (200; 12.156268ms)
Feb 21 18:50:04.693: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-58glz/services/http:proxy-service-f9qdb:portname2/proxy/: bar (200; 12.450084ms)
Feb 21 18:50:04.694: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-58glz/services/https:proxy-service-f9qdb:tlsportname1/proxy/: tls baz (200; 13.633185ms)
Feb 21 18:50:04.694: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-58glz/services/proxy-service-f9qdb:portname2/proxy/: bar (200; 13.455408ms)
Feb 21 18:50:04.694: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-58glz/services/proxy-service-f9qdb:portname1/proxy/: foo (200; 13.429871ms)
Feb 21 18:50:04.699: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp/proxy/rewriteme"... (200; 4.946153ms)
Feb 21 18:50:04.700: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:443/proxy/... (200; 5.894352ms)
Feb 21 18:50:04.701: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:160/proxy/: foo (200; 6.507665ms)
Feb 21 18:50:04.701: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:162/proxy/: bar (200; 6.65964ms)
Feb 21 18:50:04.702: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:1080/proxy/... (200; 7.435746ms)
Feb 21 18:50:04.703: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-58glz/services/proxy-service-f9qdb:portname2/proxy/: bar (200; 8.419611ms)
Feb 21 18:50:04.703: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:162/proxy/: bar (200; 8.169698ms)
Feb 21 18:50:04.703: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:462/proxy/: tls qux (200; 8.353399ms)
Feb 21 18:50:04.703: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:160/proxy/: foo (200; 8.490493ms)
Feb 21 18:50:04.703: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:1080/proxy/rewri... (200; 8.765092ms)
Feb 21 18:50:04.703: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:460/proxy/: tls baz (200; 8.825089ms)
Feb 21 18:50:04.703: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-58glz/services/proxy-service-f9qdb:portname1/proxy/: foo (200; 9.080203ms)
Feb 21 18:50:04.705: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-58glz/services/https:proxy-service-f9qdb:tlsportname2/proxy/: tls qux (200; 10.910446ms)
Feb 21 18:50:04.706: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-58glz/services/http:proxy-service-f9qdb:portname1/proxy/: foo (200; 10.902546ms)
Feb 21 18:50:04.706: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-58glz/services/https:proxy-service-f9qdb:tlsportname1/proxy/: tls baz (200; 11.348647ms)
Feb 21 18:50:04.706: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-58glz/services/http:proxy-service-f9qdb:portname2/proxy/: bar (200; 11.387329ms)
Feb 21 18:50:04.713: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:443/proxy/... (200; 6.461798ms)
Feb 21 18:50:04.713: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:462/proxy/: tls qux (200; 6.384362ms)
Feb 21 18:50:04.714: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:162/proxy/: bar (200; 7.138792ms)
Feb 21 18:50:04.716: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:460/proxy/: tls baz (200; 9.347509ms)
Feb 21 18:50:04.716: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:160/proxy/: foo (200; 9.80243ms)
Feb 21 18:50:04.717: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:1080/proxy/... (200; 10.045776ms)
Feb 21 18:50:04.717: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:162/proxy/: bar (200; 10.166237ms)
Feb 21 18:50:04.717: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:1080/proxy/rewri... (200; 10.015464ms)
Feb 21 18:50:04.717: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:160/proxy/: foo (200; 10.755387ms)
Feb 21 18:50:04.717: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-58glz/services/http:proxy-service-f9qdb:portname2/proxy/: bar (200; 10.900476ms)
Feb 21 18:50:04.718: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp/proxy/rewriteme"... (200; 10.989216ms)
Feb 21 18:50:04.719: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-58glz/services/proxy-service-f9qdb:portname1/proxy/: foo (200; 12.3292ms)
Feb 21 18:50:04.719: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-58glz/services/https:proxy-service-f9qdb:tlsportname1/proxy/: tls baz (200; 12.647547ms)
Feb 21 18:50:04.719: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-58glz/services/http:proxy-service-f9qdb:portname1/proxy/: foo (200; 12.906877ms)
Feb 21 18:50:04.719: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-58glz/services/proxy-service-f9qdb:portname2/proxy/: bar (200; 12.719728ms)
Feb 21 18:50:04.720: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-58glz/services/https:proxy-service-f9qdb:tlsportname2/proxy/: tls qux (200; 13.3293ms)
Feb 21 18:50:04.725: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:462/proxy/: tls qux (200; 5.37626ms)
Feb 21 18:50:04.727: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:1080/proxy/... (200; 7.269769ms)
Feb 21 18:50:04.728: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:162/proxy/: bar (200; 7.482684ms)
Feb 21 18:50:04.728: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:160/proxy/: foo (200; 7.820363ms)
Feb 21 18:50:04.729: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:460/proxy/: tls baz (200; 8.913937ms)
Feb 21 18:50:04.730: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp/proxy/rewriteme"... (200; 9.555481ms)
Feb 21 18:50:04.730: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-58glz/services/https:proxy-service-f9qdb:tlsportname2/proxy/: tls qux (200; 9.965906ms)
Feb 21 18:50:04.730: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:160/proxy/: foo (200; 10.037462ms)
Feb 21 18:50:04.731: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:1080/proxy/rewri... (200; 10.322076ms)
Feb 21 18:50:04.731: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:162/proxy/: bar (200; 10.603344ms)
Feb 21 18:50:04.731: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-58glz/services/proxy-service-f9qdb:portname1/proxy/: foo (200; 11.458717ms)
Feb 21 18:50:04.731: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:443/proxy/... (200; 11.15435ms)
Feb 21 18:50:04.734: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-58glz/services/http:proxy-service-f9qdb:portname1/proxy/: foo (200; 13.743805ms)
Feb 21 18:50:04.734: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-58glz/services/proxy-service-f9qdb:portname2/proxy/: bar (200; 13.758056ms)
Feb 21 18:50:04.734: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-58glz/services/https:proxy-service-f9qdb:tlsportname1/proxy/: tls baz (200; 14.105257ms)
Feb 21 18:50:04.735: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-58glz/services/http:proxy-service-f9qdb:portname2/proxy/: bar (200; 15.162897ms)
Feb 21 18:50:04.742: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:1080/proxy/... (200; 6.33852ms)
Feb 21 18:50:04.742: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:160/proxy/: foo (200; 6.750356ms)
Feb 21 18:50:04.742: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:1080/proxy/rewri... (200; 6.411211ms)
Feb 21 18:50:04.743: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:160/proxy/: foo (200; 7.640963ms)
Feb 21 18:50:04.743: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:162/proxy/: bar (200; 7.488393ms)
Feb 21 18:50:04.743: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-58glz/services/http:proxy-service-f9qdb:portname1/proxy/: foo (200; 7.696499ms)
Feb 21 18:50:04.744: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:460/proxy/: tls baz (200; 7.583217ms)
Feb 21 18:50:04.744: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:162/proxy/: bar (200; 8.112931ms)
Feb 21 18:50:04.744: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:443/proxy/... (200; 8.387439ms)
Feb 21 18:50:04.744: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp/proxy/rewriteme"... (200; 8.271305ms)
Feb 21 18:50:04.744: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:462/proxy/: tls qux (200; 8.79244ms)
Feb 21 18:50:04.747: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-58glz/services/proxy-service-f9qdb:portname1/proxy/: foo (200; 10.916178ms)
Feb 21 18:50:04.748: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-58glz/services/http:proxy-service-f9qdb:portname2/proxy/: bar (200; 12.053649ms)
Feb 21 18:50:04.748: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-58glz/services/proxy-service-f9qdb:portname2/proxy/: bar (200; 11.990699ms)
Feb 21 18:50:04.748: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-58glz/services/https:proxy-service-f9qdb:tlsportname1/proxy/: tls baz (200; 12.411811ms)
Feb 21 18:50:04.748: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-58glz/services/https:proxy-service-f9qdb:tlsportname2/proxy/: tls qux (200; 12.154185ms)
Feb 21 18:50:04.754: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:460/proxy/: tls baz (200; 5.501653ms)
Feb 21 18:50:04.755: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:160/proxy/: foo (200; 6.080173ms)
Feb 21 18:50:04.755: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:162/proxy/: bar (200; 6.218902ms)
Feb 21 18:50:04.755: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp/proxy/rewriteme"... (200; 6.878879ms)
Feb 21 18:50:04.757: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-58glz/services/http:proxy-service-f9qdb:portname2/proxy/: bar (200; 8.12601ms)
Feb 21 18:50:04.757: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:160/proxy/: foo (200; 8.616307ms)
Feb 21 18:50:04.758: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:462/proxy/: tls qux (200; 9.113339ms)
Feb 21 18:50:04.758: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:1080/proxy/... (200; 9.10911ms)
Feb 21 18:50:04.758: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:162/proxy/: bar (200; 9.417076ms)
Feb 21 18:50:04.758: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:443/proxy/... (200; 9.471822ms)
Feb 21 18:50:04.759: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:1080/proxy/rewri... (200; 10.333504ms)
Feb 21 18:50:04.759: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-58glz/services/https:proxy-service-f9qdb:tlsportname2/proxy/: tls qux (200; 10.781633ms)
Feb 21 18:50:04.760: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-58glz/services/http:proxy-service-f9qdb:portname1/proxy/: foo (200; 11.233003ms)
Feb 21 18:50:04.760: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-58glz/services/proxy-service-f9qdb:portname1/proxy/: foo (200; 11.612904ms)
Feb 21 18:50:04.760: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-58glz/services/https:proxy-service-f9qdb:tlsportname1/proxy/: tls baz (200; 11.828789ms)
Feb 21 18:50:04.761: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-58glz/services/proxy-service-f9qdb:portname2/proxy/: bar (200; 11.93682ms)
Feb 21 18:50:04.777: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:460/proxy/: tls baz (200; 16.015675ms)
Feb 21 18:50:04.777: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:162/proxy/: bar (200; 15.841798ms)
Feb 21 18:50:04.780: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp/proxy/rewriteme"... (200; 19.154091ms)
Feb 21 18:50:04.789: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:160/proxy/: foo (200; 28.429405ms)
Feb 21 18:50:04.791: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:462/proxy/: tls qux (200; 29.849485ms)
Feb 21 18:50:04.792: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:160/proxy/: foo (200; 31.450642ms)
Feb 21 18:50:04.795: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-58glz/services/https:proxy-service-f9qdb:tlsportname2/proxy/: tls qux (200; 34.282872ms)
Feb 21 18:50:04.796: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-58glz/services/https:proxy-service-f9qdb:tlsportname1/proxy/: tls baz (200; 34.809672ms)
Feb 21 18:50:04.796: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:1080/proxy/rewri... (200; 34.884664ms)
Feb 21 18:50:04.796: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:1080/proxy/... (200; 34.880643ms)
Feb 21 18:50:04.796: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-58glz/services/http:proxy-service-f9qdb:portname1/proxy/: foo (200; 35.011642ms)
Feb 21 18:50:04.796: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:162/proxy/: bar (200; 34.907925ms)
Feb 21 18:50:04.796: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:443/proxy/... (200; 34.911574ms)
Feb 21 18:50:04.796: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-58glz/services/proxy-service-f9qdb:portname1/proxy/: foo (200; 35.294006ms)
Feb 21 18:50:04.798: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-58glz/services/http:proxy-service-f9qdb:portname2/proxy/: bar (200; 37.651921ms)
Feb 21 18:50:04.799: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-58glz/services/proxy-service-f9qdb:portname2/proxy/: bar (200; 38.215348ms)
Feb 21 18:50:04.815: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:162/proxy/: bar (200; 16.327151ms)
Feb 21 18:50:04.819: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:462/proxy/: tls qux (200; 19.424138ms)
Feb 21 18:50:04.819: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:1080/proxy/rewri... (200; 19.568787ms)
Feb 21 18:50:04.828: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-58glz/services/http:proxy-service-f9qdb:portname2/proxy/: bar (200; 29.073644ms)
Feb 21 18:50:04.828: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:162/proxy/: bar (200; 29.065962ms)
Feb 21 18:50:04.828: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:1080/proxy/... (200; 29.061096ms)
Feb 21 18:50:04.828: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-58glz/services/https:proxy-service-f9qdb:tlsportname2/proxy/: tls qux (200; 29.13245ms)
Feb 21 18:50:04.828: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:160/proxy/: foo (200; 28.990179ms)
Feb 21 18:50:04.831: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-58glz/services/https:proxy-service-f9qdb:tlsportname1/proxy/: tls baz (200; 31.883339ms)
Feb 21 18:50:04.831: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp/proxy/rewriteme"... (200; 31.830794ms)
Feb 21 18:50:04.832: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:460/proxy/: tls baz (200; 32.289218ms)
Feb 21 18:50:04.832: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-58glz/services/proxy-service-f9qdb:portname1/proxy/: foo (200; 32.916581ms)
Feb 21 18:50:04.833: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-58glz/services/proxy-service-f9qdb:portname2/proxy/: bar (200; 33.355045ms)
Feb 21 18:50:04.833: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-58glz/services/http:proxy-service-f9qdb:portname1/proxy/: foo (200; 33.771018ms)
Feb 21 18:50:04.833: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:160/proxy/: foo (200; 33.895762ms)
Feb 21 18:50:04.834: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:443/proxy/... (200; 34.59962ms)
Feb 21 18:50:04.846: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:162/proxy/: bar (200; 11.765083ms)
Feb 21 18:50:04.852: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:443/proxy/... (200; 17.468457ms)
Feb 21 18:50:04.853: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:160/proxy/: foo (200; 19.295344ms)
Feb 21 18:50:04.853: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:1080/proxy/... (200; 19.173446ms)
Feb 21 18:50:04.859: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp/proxy/rewriteme"... (200; 24.452623ms)
Feb 21 18:50:04.859: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:462/proxy/: tls qux (200; 24.587448ms)
Feb 21 18:50:04.859: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:1080/proxy/rewri... (200; 25.011018ms)
Feb 21 18:50:04.859: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:160/proxy/: foo (200; 25.09615ms)
Feb 21 18:50:04.860: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:460/proxy/: tls baz (200; 25.501431ms)
Feb 21 18:50:04.861: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:162/proxy/: bar (200; 27.073451ms)
Feb 21 18:50:04.867: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-58glz/services/http:proxy-service-f9qdb:portname2/proxy/: bar (200; 32.365616ms)
Feb 21 18:50:04.867: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-58glz/services/https:proxy-service-f9qdb:tlsportname1/proxy/: tls baz (200; 32.645547ms)
Feb 21 18:50:04.867: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-58glz/services/proxy-service-f9qdb:portname1/proxy/: foo (200; 33.074756ms)
Feb 21 18:50:04.868: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-58glz/services/https:proxy-service-f9qdb:tlsportname2/proxy/: tls qux (200; 33.967806ms)
Feb 21 18:50:04.870: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-58glz/services/proxy-service-f9qdb:portname2/proxy/: bar (200; 36.049807ms)
Feb 21 18:50:04.870: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-58glz/services/http:proxy-service-f9qdb:portname1/proxy/: foo (200; 35.877353ms)
Feb 21 18:50:04.894: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:1080/proxy/... (200; 23.59668ms)
Feb 21 18:50:04.898: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-58glz/services/http:proxy-service-f9qdb:portname2/proxy/: bar (200; 27.18443ms)
Feb 21 18:50:04.901: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-58glz/services/https:proxy-service-f9qdb:tlsportname1/proxy/: tls baz (200; 30.79179ms)
Feb 21 18:50:04.902: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-58glz/services/https:proxy-service-f9qdb:tlsportname2/proxy/: tls qux (200; 31.238662ms)
Feb 21 18:50:04.902: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-58glz/services/proxy-service-f9qdb:portname1/proxy/: foo (200; 31.187774ms)
Feb 21 18:50:04.902: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:160/proxy/: foo (200; 31.248563ms)
Feb 21 18:50:04.902: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:462/proxy/: tls qux (200; 31.149874ms)
Feb 21 18:50:04.902: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:443/proxy/... (200; 31.4357ms)
Feb 21 18:50:04.902: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/https:proxy-service-f9qdb-55dmp:460/proxy/: tls baz (200; 31.322206ms)
Feb 21 18:50:04.902: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:162/proxy/: bar (200; 31.377456ms)
Feb 21 18:50:04.902: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:1080/proxy/rewri... (200; 31.258333ms)
Feb 21 18:50:04.902: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp:160/proxy/: foo (200; 31.887415ms)
Feb 21 18:50:04.902: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-58glz/services/http:proxy-service-f9qdb:portname1/proxy/: foo (200; 31.825729ms)
Feb 21 18:50:04.902: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-58glz/pods/proxy-service-f9qdb-55dmp/proxy/rewriteme"... (200; 31.941868ms)
Feb 21 18:50:04.903: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-58glz/pods/http:proxy-service-f9qdb-55dmp:162/proxy/: bar (200; 32.11731ms)
Feb 21 18:50:04.903: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-58glz/services/proxy-service-f9qdb:portname2/proxy/: bar (200; 32.161523ms)
STEP: deleting ReplicationController proxy-service-f9qdb in namespace e2e-tests-proxy-58glz, will wait for the garbage collector to delete the pods
Feb 21 18:50:04.970: INFO: Deleting ReplicationController proxy-service-f9qdb took: 12.85566ms
Feb 21 18:50:05.071: INFO: Terminating ReplicationController proxy-service-f9qdb pods took: 100.485605ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:50:09.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-58glz" for this suite.
Feb 21 18:50:15.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:50:15.171: INFO: namespace: e2e-tests-proxy-58glz, resource: bindings, ignored listing per whitelist
Feb 21 18:50:15.241: INFO: namespace e2e-tests-proxy-58glz deletion completed in 6.163073738s

• [SLOW TEST:22.993 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:50:15.241: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-runtime-jlv4z
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:50:40.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-jlv4z" for this suite.
Feb 21 18:50:46.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:50:46.828: INFO: namespace: e2e-tests-container-runtime-jlv4z, resource: bindings, ignored listing per whitelist
Feb 21 18:50:46.918: INFO: namespace e2e-tests-container-runtime-jlv4z deletion completed in 6.162047319s

• [SLOW TEST:31.677 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:50:46.918: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-lttx7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 21 18:50:47.131: INFO: Waiting up to 5m0s for pod "pod-999aafae-3609-11e9-816d-1a333d676433" in namespace "e2e-tests-emptydir-lttx7" to be "success or failure"
Feb 21 18:50:47.136: INFO: Pod "pod-999aafae-3609-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 4.893868ms
Feb 21 18:50:49.141: INFO: Pod "pod-999aafae-3609-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009560138s
STEP: Saw pod success
Feb 21 18:50:49.141: INFO: Pod "pod-999aafae-3609-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:50:49.144: INFO: Trying to get logs from node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c pod pod-999aafae-3609-11e9-816d-1a333d676433 container test-container: <nil>
STEP: delete the pod
Feb 21 18:50:49.172: INFO: Waiting for pod pod-999aafae-3609-11e9-816d-1a333d676433 to disappear
Feb 21 18:50:49.175: INFO: Pod pod-999aafae-3609-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:50:49.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-lttx7" for this suite.
Feb 21 18:50:55.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:50:55.291: INFO: namespace: e2e-tests-emptydir-lttx7, resource: bindings, ignored listing per whitelist
Feb 21 18:50:55.347: INFO: namespace e2e-tests-emptydir-lttx7 deletion completed in 6.16788385s

• [SLOW TEST:8.430 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:50:55.348: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-swf72
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 21 18:50:55.530: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:50:59.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-swf72" for this suite.
Feb 21 18:51:49.672: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:51:49.766: INFO: namespace: e2e-tests-pods-swf72, resource: bindings, ignored listing per whitelist
Feb 21 18:51:49.797: INFO: namespace e2e-tests-pods-swf72 deletion completed in 50.145205757s

• [SLOW TEST:54.449 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:51:49.797: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-95ghz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Feb 21 18:51:54.018: INFO: Pod pod-hostip-bf132c10-3609-11e9-816d-1a333d676433 has hostIP: 10.0.1.5
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:51:54.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-95ghz" for this suite.
Feb 21 18:52:16.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:52:16.149: INFO: namespace: e2e-tests-pods-95ghz, resource: bindings, ignored listing per whitelist
Feb 21 18:52:16.188: INFO: namespace e2e-tests-pods-95ghz deletion completed in 22.166289269s

• [SLOW TEST:26.392 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:52:16.189: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-m4j8f
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-jmlxj
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-pcddn
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:52:22.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-m4j8f" for this suite.
Feb 21 18:52:28.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:52:28.834: INFO: namespace: e2e-tests-namespaces-m4j8f, resource: bindings, ignored listing per whitelist
Feb 21 18:52:28.857: INFO: namespace e2e-tests-namespaces-m4j8f deletion completed in 6.14579102s
STEP: Destroying namespace "e2e-tests-nsdeletetest-jmlxj" for this suite.
Feb 21 18:52:28.861: INFO: Namespace e2e-tests-nsdeletetest-jmlxj was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-pcddn" for this suite.
Feb 21 18:52:34.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:52:34.894: INFO: namespace: e2e-tests-nsdeletetest-pcddn, resource: bindings, ignored listing per whitelist
Feb 21 18:52:35.011: INFO: namespace e2e-tests-nsdeletetest-pcddn deletion completed in 6.150498284s

• [SLOW TEST:18.823 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:52:35.012: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-7h9d8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 21 18:52:35.212: INFO: Waiting up to 5m0s for pod "downward-api-da06dc74-3609-11e9-816d-1a333d676433" in namespace "e2e-tests-downward-api-7h9d8" to be "success or failure"
Feb 21 18:52:35.216: INFO: Pod "downward-api-da06dc74-3609-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 4.123182ms
Feb 21 18:52:37.228: INFO: Pod "downward-api-da06dc74-3609-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016344661s
STEP: Saw pod success
Feb 21 18:52:37.228: INFO: Pod "downward-api-da06dc74-3609-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:52:37.232: INFO: Trying to get logs from node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c pod downward-api-da06dc74-3609-11e9-816d-1a333d676433 container dapi-container: <nil>
STEP: delete the pod
Feb 21 18:52:37.257: INFO: Waiting for pod downward-api-da06dc74-3609-11e9-816d-1a333d676433 to disappear
Feb 21 18:52:37.261: INFO: Pod downward-api-da06dc74-3609-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:52:37.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7h9d8" for this suite.
Feb 21 18:52:43.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:52:43.390: INFO: namespace: e2e-tests-downward-api-7h9d8, resource: bindings, ignored listing per whitelist
Feb 21 18:52:43.429: INFO: namespace e2e-tests-downward-api-7h9d8 deletion completed in 6.163590887s

• [SLOW TEST:8.417 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:52:43.429: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-pznzf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Feb 21 18:52:43.621: INFO: Waiting up to 5m0s for pod "var-expansion-df0a50ac-3609-11e9-816d-1a333d676433" in namespace "e2e-tests-var-expansion-pznzf" to be "success or failure"
Feb 21 18:52:43.625: INFO: Pod "var-expansion-df0a50ac-3609-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 3.67581ms
Feb 21 18:52:45.630: INFO: Pod "var-expansion-df0a50ac-3609-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008230957s
Feb 21 18:52:47.643: INFO: Pod "var-expansion-df0a50ac-3609-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022111674s
STEP: Saw pod success
Feb 21 18:52:47.644: INFO: Pod "var-expansion-df0a50ac-3609-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:52:47.647: INFO: Trying to get logs from node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c pod var-expansion-df0a50ac-3609-11e9-816d-1a333d676433 container dapi-container: <nil>
STEP: delete the pod
Feb 21 18:52:47.672: INFO: Waiting for pod var-expansion-df0a50ac-3609-11e9-816d-1a333d676433 to disappear
Feb 21 18:52:47.675: INFO: Pod var-expansion-df0a50ac-3609-11e9-816d-1a333d676433 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:52:47.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-pznzf" for this suite.
Feb 21 18:52:53.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:52:53.788: INFO: namespace: e2e-tests-var-expansion-pznzf, resource: bindings, ignored listing per whitelist
Feb 21 18:52:53.866: INFO: namespace e2e-tests-var-expansion-pznzf deletion completed in 6.187203683s

• [SLOW TEST:10.437 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:52:53.867: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-hcnj8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 21 18:52:54.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-hcnj8'
Feb 21 18:52:54.332: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 21 18:52:54.332: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Feb 21 18:52:58.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-hcnj8'
Feb 21 18:52:58.431: INFO: stderr: ""
Feb 21 18:52:58.431: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:52:58.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hcnj8" for this suite.
Feb 21 18:53:20.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:53:20.488: INFO: namespace: e2e-tests-kubectl-hcnj8, resource: bindings, ignored listing per whitelist
Feb 21 18:53:20.605: INFO: namespace e2e-tests-kubectl-hcnj8 deletion completed in 22.158797755s

• [SLOW TEST:26.738 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:53:20.605: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-ftqpc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Feb 21 18:53:20.794: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-043636783 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:53:20.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ftqpc" for this suite.
Feb 21 18:53:26.888: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:53:27.019: INFO: namespace: e2e-tests-kubectl-ftqpc, resource: bindings, ignored listing per whitelist
Feb 21 18:53:27.022: INFO: namespace e2e-tests-kubectl-ftqpc deletion completed in 6.153320224s

• [SLOW TEST:6.418 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:53:27.023: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-wqzwb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0221 18:53:28.270951      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 21 18:53:28.271: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:53:28.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-wqzwb" for this suite.
Feb 21 18:53:34.296: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:53:34.385: INFO: namespace: e2e-tests-gc-wqzwb, resource: bindings, ignored listing per whitelist
Feb 21 18:53:34.465: INFO: namespace e2e-tests-gc-wqzwb deletion completed in 6.189756455s

• [SLOW TEST:7.442 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:53:34.465: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-fqp4m
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Feb 21 18:53:36.716: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-fd7aa83e-3609-11e9-816d-1a333d676433", GenerateName:"", Namespace:"e2e-tests-pods-fqp4m", SelfLink:"/api/v1/namespaces/e2e-tests-pods-fqp4m/pods/pod-submit-remove-fd7aa83e-3609-11e9-816d-1a333d676433", UID:"fd7ca328-3609-11e9-bacd-42010a000102", ResourceVersion:"13590", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63686372014, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"679049969"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-78gdq", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001170cc0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-78gdq", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001c63dc8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0019ca600), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001c63e60)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001c63e80)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001c63e88), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001c63e8c)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686372014, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686372016, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686372016, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686372014, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.1.4", PodIP:"10.200.10.61", StartTime:(*v1.Time)(0xc0015f6440), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc0015f6460), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632", ContainerID:"docker://dc6418ed8dfb96ab7b50bc49a6f79d966d19920bdcaa40278e106ebea2801b8e"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:53:49.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-fqp4m" for this suite.
Feb 21 18:53:55.044: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:53:55.153: INFO: namespace: e2e-tests-pods-fqp4m, resource: bindings, ignored listing per whitelist
Feb 21 18:53:55.182: INFO: namespace e2e-tests-pods-fqp4m deletion completed in 6.15774969s

• [SLOW TEST:20.717 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:53:55.183: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-h4wkv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-09cfcd88-360a-11e9-816d-1a333d676433
STEP: Creating a pod to test consume secrets
Feb 21 18:53:55.384: INFO: Waiting up to 5m0s for pod "pod-secrets-09d09de3-360a-11e9-816d-1a333d676433" in namespace "e2e-tests-secrets-h4wkv" to be "success or failure"
Feb 21 18:53:55.389: INFO: Pod "pod-secrets-09d09de3-360a-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 4.189156ms
Feb 21 18:53:57.393: INFO: Pod "pod-secrets-09d09de3-360a-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008873236s
STEP: Saw pod success
Feb 21 18:53:57.394: INFO: Pod "pod-secrets-09d09de3-360a-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:53:57.397: INFO: Trying to get logs from node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c pod pod-secrets-09d09de3-360a-11e9-816d-1a333d676433 container secret-volume-test: <nil>
STEP: delete the pod
Feb 21 18:53:57.423: INFO: Waiting for pod pod-secrets-09d09de3-360a-11e9-816d-1a333d676433 to disappear
Feb 21 18:53:57.426: INFO: Pod pod-secrets-09d09de3-360a-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:53:57.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-h4wkv" for this suite.
Feb 21 18:54:03.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:54:03.463: INFO: namespace: e2e-tests-secrets-h4wkv, resource: bindings, ignored listing per whitelist
Feb 21 18:54:03.596: INFO: namespace e2e-tests-secrets-h4wkv deletion completed in 6.165889101s

• [SLOW TEST:8.413 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:54:03.596: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-hfxk7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-hfxk7
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 21 18:54:03.779: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 21 18:54:27.923: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.34.19:8080/dial?request=hostName&protocol=udp&host=10.200.10.62&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-hfxk7 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 21 18:54:27.923: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
Feb 21 18:54:28.027: INFO: Waiting for endpoints: map[]
Feb 21 18:54:28.031: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.34.19:8080/dial?request=hostName&protocol=udp&host=10.200.34.18&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-hfxk7 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 21 18:54:28.031: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
Feb 21 18:54:28.138: INFO: Waiting for endpoints: map[]
Feb 21 18:54:28.142: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.34.19:8080/dial?request=hostName&protocol=udp&host=10.200.20.68&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-hfxk7 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 21 18:54:28.143: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
Feb 21 18:54:28.241: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:54:28.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-hfxk7" for this suite.
Feb 21 18:54:50.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:54:50.298: INFO: namespace: e2e-tests-pod-network-test-hfxk7, resource: bindings, ignored listing per whitelist
Feb 21 18:54:50.407: INFO: namespace e2e-tests-pod-network-test-hfxk7 deletion completed in 22.159637218s

• [SLOW TEST:46.811 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:54:50.407: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-gjt89
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Feb 21 18:54:50.608: INFO: Waiting up to 5m0s for pod "pod-2abae216-360a-11e9-816d-1a333d676433" in namespace "e2e-tests-emptydir-gjt89" to be "success or failure"
Feb 21 18:54:50.614: INFO: Pod "pod-2abae216-360a-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 5.621003ms
Feb 21 18:54:52.625: INFO: Pod "pod-2abae216-360a-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017169557s
STEP: Saw pod success
Feb 21 18:54:52.625: INFO: Pod "pod-2abae216-360a-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:54:52.629: INFO: Trying to get logs from node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c pod pod-2abae216-360a-11e9-816d-1a333d676433 container test-container: <nil>
STEP: delete the pod
Feb 21 18:54:52.657: INFO: Waiting for pod pod-2abae216-360a-11e9-816d-1a333d676433 to disappear
Feb 21 18:54:52.660: INFO: Pod pod-2abae216-360a-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:54:52.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-gjt89" for this suite.
Feb 21 18:54:58.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:54:58.815: INFO: namespace: e2e-tests-emptydir-gjt89, resource: bindings, ignored listing per whitelist
Feb 21 18:54:58.829: INFO: namespace e2e-tests-emptydir-gjt89 deletion completed in 6.16466367s

• [SLOW TEST:8.422 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:54:58.829: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-nz6h5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-2fc0d76f-360a-11e9-816d-1a333d676433
STEP: Creating a pod to test consume configMaps
Feb 21 18:54:59.044: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2fc1f183-360a-11e9-816d-1a333d676433" in namespace "e2e-tests-projected-nz6h5" to be "success or failure"
Feb 21 18:54:59.050: INFO: Pod "pod-projected-configmaps-2fc1f183-360a-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 5.726301ms
Feb 21 18:55:01.056: INFO: Pod "pod-projected-configmaps-2fc1f183-360a-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011003908s
Feb 21 18:55:03.068: INFO: Pod "pod-projected-configmaps-2fc1f183-360a-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023966732s
STEP: Saw pod success
Feb 21 18:55:03.069: INFO: Pod "pod-projected-configmaps-2fc1f183-360a-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:55:03.073: INFO: Trying to get logs from node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c pod pod-projected-configmaps-2fc1f183-360a-11e9-816d-1a333d676433 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 21 18:55:03.098: INFO: Waiting for pod pod-projected-configmaps-2fc1f183-360a-11e9-816d-1a333d676433 to disappear
Feb 21 18:55:03.103: INFO: Pod pod-projected-configmaps-2fc1f183-360a-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:55:03.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nz6h5" for this suite.
Feb 21 18:55:09.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:55:09.155: INFO: namespace: e2e-tests-projected-nz6h5, resource: bindings, ignored listing per whitelist
Feb 21 18:55:09.257: INFO: namespace e2e-tests-projected-nz6h5 deletion completed in 6.149196635s

• [SLOW TEST:10.428 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:55:09.257: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-mqnx9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 21 18:55:09.449: INFO: PodSpec: initContainers in spec.initContainers
Feb 21 18:55:53.008: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-35f789e4-360a-11e9-816d-1a333d676433", GenerateName:"", Namespace:"e2e-tests-init-container-mqnx9", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-mqnx9/pods/pod-init-35f789e4-360a-11e9-816d-1a333d676433", UID:"35f866d9-360a-11e9-bacd-42010a000102", ResourceVersion:"14021", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63686372109, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"time":"449883389", "name":"foo"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-jctw4", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0014ab600), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-jctw4", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-jctw4", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-jctw4", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0018c2178), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0019f9560), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0018c2220)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0018c2240)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0018c2248), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0018c224c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686372109, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686372109, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686372109, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686372109, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.1.4", PodIP:"10.200.10.64", StartTime:(*v1.Time)(0xc000e56ae0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0018d7500)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0018d7570)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://a91f4ca6aabeb249d1ceaaeaa0c02ce804dc3c10747db02809bdf2469fa1d5bf"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc000e56b20), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc000e56b00), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:55:53.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-mqnx9" for this suite.
Feb 21 18:56:15.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:56:15.110: INFO: namespace: e2e-tests-init-container-mqnx9, resource: bindings, ignored listing per whitelist
Feb 21 18:56:15.201: INFO: namespace e2e-tests-init-container-mqnx9 deletion completed in 22.179788122s

• [SLOW TEST:65.944 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:56:15.201: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-nddss
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-k25x
STEP: Creating a pod to test atomic-volume-subpath
Feb 21 18:56:15.428: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-k25x" in namespace "e2e-tests-subpath-nddss" to be "success or failure"
Feb 21 18:56:15.438: INFO: Pod "pod-subpath-test-configmap-k25x": Phase="Pending", Reason="", readiness=false. Elapsed: 10.031332ms
Feb 21 18:56:17.443: INFO: Pod "pod-subpath-test-configmap-k25x": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014915127s
Feb 21 18:56:19.448: INFO: Pod "pod-subpath-test-configmap-k25x": Phase="Running", Reason="", readiness=false. Elapsed: 4.0197138s
Feb 21 18:56:21.453: INFO: Pod "pod-subpath-test-configmap-k25x": Phase="Running", Reason="", readiness=false. Elapsed: 6.024816526s
Feb 21 18:56:23.458: INFO: Pod "pod-subpath-test-configmap-k25x": Phase="Running", Reason="", readiness=false. Elapsed: 8.029661461s
Feb 21 18:56:25.470: INFO: Pod "pod-subpath-test-configmap-k25x": Phase="Running", Reason="", readiness=false. Elapsed: 10.041655006s
Feb 21 18:56:27.475: INFO: Pod "pod-subpath-test-configmap-k25x": Phase="Running", Reason="", readiness=false. Elapsed: 12.046796205s
Feb 21 18:56:29.484: INFO: Pod "pod-subpath-test-configmap-k25x": Phase="Running", Reason="", readiness=false. Elapsed: 14.055658609s
Feb 21 18:56:31.488: INFO: Pod "pod-subpath-test-configmap-k25x": Phase="Running", Reason="", readiness=false. Elapsed: 16.060165107s
Feb 21 18:56:33.493: INFO: Pod "pod-subpath-test-configmap-k25x": Phase="Running", Reason="", readiness=false. Elapsed: 18.065090189s
Feb 21 18:56:35.504: INFO: Pod "pod-subpath-test-configmap-k25x": Phase="Running", Reason="", readiness=false. Elapsed: 20.076154309s
Feb 21 18:56:37.509: INFO: Pod "pod-subpath-test-configmap-k25x": Phase="Running", Reason="", readiness=false. Elapsed: 22.08074841s
Feb 21 18:56:39.514: INFO: Pod "pod-subpath-test-configmap-k25x": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.085553344s
STEP: Saw pod success
Feb 21 18:56:39.514: INFO: Pod "pod-subpath-test-configmap-k25x" satisfied condition "success or failure"
Feb 21 18:56:39.517: INFO: Trying to get logs from node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c pod pod-subpath-test-configmap-k25x container test-container-subpath-configmap-k25x: <nil>
STEP: delete the pod
Feb 21 18:56:39.547: INFO: Waiting for pod pod-subpath-test-configmap-k25x to disappear
Feb 21 18:56:39.550: INFO: Pod pod-subpath-test-configmap-k25x no longer exists
STEP: Deleting pod pod-subpath-test-configmap-k25x
Feb 21 18:56:39.550: INFO: Deleting pod "pod-subpath-test-configmap-k25x" in namespace "e2e-tests-subpath-nddss"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:56:39.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-nddss" for this suite.
Feb 21 18:56:45.582: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:56:45.697: INFO: namespace: e2e-tests-subpath-nddss, resource: bindings, ignored listing per whitelist
Feb 21 18:56:45.711: INFO: namespace e2e-tests-subpath-nddss deletion completed in 6.153187731s

• [SLOW TEST:30.510 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:56:45.711: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-v7b5l
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-6f76bf16-360a-11e9-816d-1a333d676433
STEP: Creating configMap with name cm-test-opt-upd-6f76bf56-360a-11e9-816d-1a333d676433
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-6f76bf16-360a-11e9-816d-1a333d676433
STEP: Updating configmap cm-test-opt-upd-6f76bf56-360a-11e9-816d-1a333d676433
STEP: Creating configMap with name cm-test-opt-create-6f76bf6c-360a-11e9-816d-1a333d676433
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:57:52.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-v7b5l" for this suite.
Feb 21 18:58:14.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:58:14.599: INFO: namespace: e2e-tests-projected-v7b5l, resource: bindings, ignored listing per whitelist
Feb 21 18:58:14.614: INFO: namespace e2e-tests-projected-v7b5l deletion completed in 22.161955313s

• [SLOW TEST:88.903 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:58:14.614: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-l9nrj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Feb 21 18:58:15.340: INFO: created pod pod-service-account-defaultsa
Feb 21 18:58:15.341: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Feb 21 18:58:15.350: INFO: created pod pod-service-account-mountsa
Feb 21 18:58:15.350: INFO: pod pod-service-account-mountsa service account token volume mount: true
Feb 21 18:58:15.359: INFO: created pod pod-service-account-nomountsa
Feb 21 18:58:15.359: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Feb 21 18:58:15.369: INFO: created pod pod-service-account-defaultsa-mountspec
Feb 21 18:58:15.369: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Feb 21 18:58:15.383: INFO: created pod pod-service-account-mountsa-mountspec
Feb 21 18:58:15.383: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Feb 21 18:58:15.389: INFO: created pod pod-service-account-nomountsa-mountspec
Feb 21 18:58:15.389: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Feb 21 18:58:15.400: INFO: created pod pod-service-account-defaultsa-nomountspec
Feb 21 18:58:15.401: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Feb 21 18:58:15.409: INFO: created pod pod-service-account-mountsa-nomountspec
Feb 21 18:58:15.409: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Feb 21 18:58:15.417: INFO: created pod pod-service-account-nomountsa-nomountspec
Feb 21 18:58:15.417: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:58:15.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-l9nrj" for this suite.
Feb 21 18:58:21.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:58:21.478: INFO: namespace: e2e-tests-svcaccounts-l9nrj, resource: bindings, ignored listing per whitelist
Feb 21 18:58:21.589: INFO: namespace e2e-tests-svcaccounts-l9nrj deletion completed in 6.164065993s

• [SLOW TEST:6.975 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:58:21.589: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-hzgtj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 21 18:58:24.323: INFO: Successfully updated pod "labelsupdatea899608b-360a-11e9-816d-1a333d676433"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:58:26.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hzgtj" for this suite.
Feb 21 18:58:48.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:58:48.402: INFO: namespace: e2e-tests-projected-hzgtj, resource: bindings, ignored listing per whitelist
Feb 21 18:58:48.496: INFO: namespace e2e-tests-projected-hzgtj deletion completed in 22.143905245s

• [SLOW TEST:26.907 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:58:48.496: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-99phb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-b8a76632-360a-11e9-816d-1a333d676433
STEP: Creating a pod to test consume configMaps
Feb 21 18:58:48.725: INFO: Waiting up to 5m0s for pod "pod-configmaps-b8a87087-360a-11e9-816d-1a333d676433" in namespace "e2e-tests-configmap-99phb" to be "success or failure"
Feb 21 18:58:48.729: INFO: Pod "pod-configmaps-b8a87087-360a-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 4.352943ms
Feb 21 18:58:50.734: INFO: Pod "pod-configmaps-b8a87087-360a-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009050815s
Feb 21 18:58:52.745: INFO: Pod "pod-configmaps-b8a87087-360a-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020487967s
STEP: Saw pod success
Feb 21 18:58:52.745: INFO: Pod "pod-configmaps-b8a87087-360a-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:58:52.749: INFO: Trying to get logs from node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c pod pod-configmaps-b8a87087-360a-11e9-816d-1a333d676433 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 21 18:58:52.775: INFO: Waiting for pod pod-configmaps-b8a87087-360a-11e9-816d-1a333d676433 to disappear
Feb 21 18:58:52.778: INFO: Pod pod-configmaps-b8a87087-360a-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:58:52.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-99phb" for this suite.
Feb 21 18:58:58.801: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:58:58.885: INFO: namespace: e2e-tests-configmap-99phb, resource: bindings, ignored listing per whitelist
Feb 21 18:58:58.935: INFO: namespace e2e-tests-configmap-99phb deletion completed in 6.152263726s

• [SLOW TEST:10.440 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:58:58.935: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-ttz2k
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:58:59.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-ttz2k" for this suite.
Feb 21 18:59:21.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:59:21.249: INFO: namespace: e2e-tests-pods-ttz2k, resource: bindings, ignored listing per whitelist
Feb 21 18:59:21.305: INFO: namespace e2e-tests-pods-ttz2k deletion completed in 22.152619813s

• [SLOW TEST:22.369 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:59:21.305: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-lhsz8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-cc32093f-360a-11e9-816d-1a333d676433
STEP: Creating a pod to test consume configMaps
Feb 21 18:59:21.507: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-cc32f03c-360a-11e9-816d-1a333d676433" in namespace "e2e-tests-projected-lhsz8" to be "success or failure"
Feb 21 18:59:21.511: INFO: Pod "pod-projected-configmaps-cc32f03c-360a-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 3.552894ms
Feb 21 18:59:23.515: INFO: Pod "pod-projected-configmaps-cc32f03c-360a-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007949597s
STEP: Saw pod success
Feb 21 18:59:23.515: INFO: Pod "pod-projected-configmaps-cc32f03c-360a-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:59:23.518: INFO: Trying to get logs from node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c pod pod-projected-configmaps-cc32f03c-360a-11e9-816d-1a333d676433 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 21 18:59:23.544: INFO: Waiting for pod pod-projected-configmaps-cc32f03c-360a-11e9-816d-1a333d676433 to disappear
Feb 21 18:59:23.547: INFO: Pod pod-projected-configmaps-cc32f03c-360a-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:59:23.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-lhsz8" for this suite.
Feb 21 18:59:29.573: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:59:29.629: INFO: namespace: e2e-tests-projected-lhsz8, resource: bindings, ignored listing per whitelist
Feb 21 18:59:29.728: INFO: namespace e2e-tests-projected-lhsz8 deletion completed in 6.175456982s

• [SLOW TEST:8.423 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:59:29.728: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-c7pbf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-d1381534-360a-11e9-816d-1a333d676433
STEP: Creating a pod to test consume configMaps
Feb 21 18:59:29.939: INFO: Waiting up to 5m0s for pod "pod-configmaps-d13948ed-360a-11e9-816d-1a333d676433" in namespace "e2e-tests-configmap-c7pbf" to be "success or failure"
Feb 21 18:59:29.943: INFO: Pod "pod-configmaps-d13948ed-360a-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 4.146184ms
Feb 21 18:59:31.948: INFO: Pod "pod-configmaps-d13948ed-360a-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008872143s
STEP: Saw pod success
Feb 21 18:59:31.948: INFO: Pod "pod-configmaps-d13948ed-360a-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:59:31.952: INFO: Trying to get logs from node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c pod pod-configmaps-d13948ed-360a-11e9-816d-1a333d676433 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 21 18:59:31.983: INFO: Waiting for pod pod-configmaps-d13948ed-360a-11e9-816d-1a333d676433 to disappear
Feb 21 18:59:31.986: INFO: Pod pod-configmaps-d13948ed-360a-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:59:31.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-c7pbf" for this suite.
Feb 21 18:59:38.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:59:38.131: INFO: namespace: e2e-tests-configmap-c7pbf, resource: bindings, ignored listing per whitelist
Feb 21 18:59:38.141: INFO: namespace e2e-tests-configmap-c7pbf deletion completed in 6.150634713s

• [SLOW TEST:8.413 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:59:38.141: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-dvq5w
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 21 18:59:38.339: INFO: Waiting up to 5m0s for pod "pod-d63b6531-360a-11e9-816d-1a333d676433" in namespace "e2e-tests-emptydir-dvq5w" to be "success or failure"
Feb 21 18:59:38.345: INFO: Pod "pod-d63b6531-360a-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 5.751193ms
Feb 21 18:59:40.350: INFO: Pod "pod-d63b6531-360a-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010431622s
Feb 21 18:59:42.354: INFO: Pod "pod-d63b6531-360a-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015191915s
STEP: Saw pod success
Feb 21 18:59:42.354: INFO: Pod "pod-d63b6531-360a-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 18:59:42.358: INFO: Trying to get logs from node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c pod pod-d63b6531-360a-11e9-816d-1a333d676433 container test-container: <nil>
STEP: delete the pod
Feb 21 18:59:42.382: INFO: Waiting for pod pod-d63b6531-360a-11e9-816d-1a333d676433 to disappear
Feb 21 18:59:42.386: INFO: Pod pod-d63b6531-360a-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:59:42.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-dvq5w" for this suite.
Feb 21 18:59:48.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 18:59:48.512: INFO: namespace: e2e-tests-emptydir-dvq5w, resource: bindings, ignored listing per whitelist
Feb 21 18:59:48.563: INFO: namespace e2e-tests-emptydir-dvq5w deletion completed in 6.172873811s

• [SLOW TEST:10.422 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 18:59:48.563: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-z89db
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0221 18:59:54.808930      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 21 18:59:54.808: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 18:59:54.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-z89db" for this suite.
Feb 21 19:00:00.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:00:00.845: INFO: namespace: e2e-tests-gc-z89db, resource: bindings, ignored listing per whitelist
Feb 21 19:00:00.969: INFO: namespace e2e-tests-gc-z89db deletion completed in 6.155486183s

• [SLOW TEST:12.406 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:00:00.969: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-g52n7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 21 19:00:01.174: INFO: Pod name rollover-pod: Found 0 pods out of 1
Feb 21 19:00:06.179: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 21 19:00:06.179: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Feb 21 19:00:08.193: INFO: Creating deployment "test-rollover-deployment"
Feb 21 19:00:08.204: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Feb 21 19:00:10.213: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Feb 21 19:00:10.223: INFO: Ensure that both replica sets have 1 created replica
Feb 21 19:00:10.234: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Feb 21 19:00:10.247: INFO: Updating deployment test-rollover-deployment
Feb 21 19:00:10.247: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Feb 21 19:00:12.270: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Feb 21 19:00:12.280: INFO: Make sure deployment "test-rollover-deployment" is complete
Feb 21 19:00:12.290: INFO: all replica sets need to contain the pod-template-hash label
Feb 21 19:00:12.290: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686372408, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686372408, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686372410, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686372408, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 21 19:00:14.301: INFO: all replica sets need to contain the pod-template-hash label
Feb 21 19:00:14.301: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686372408, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686372408, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686372412, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686372408, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 21 19:00:16.301: INFO: all replica sets need to contain the pod-template-hash label
Feb 21 19:00:16.301: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686372408, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686372408, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686372412, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686372408, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 21 19:00:18.307: INFO: all replica sets need to contain the pod-template-hash label
Feb 21 19:00:18.307: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686372408, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686372408, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686372412, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686372408, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 21 19:00:20.301: INFO: all replica sets need to contain the pod-template-hash label
Feb 21 19:00:20.301: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686372408, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686372408, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686372412, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686372408, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 21 19:00:22.300: INFO: all replica sets need to contain the pod-template-hash label
Feb 21 19:00:22.300: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686372408, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686372408, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686372412, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686372408, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 21 19:00:24.300: INFO: 
Feb 21 19:00:24.300: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 21 19:00:24.313: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-g52n7,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-g52n7/deployments/test-rollover-deployment,UID:e80863d5-360a-11e9-bacd-42010a000102,ResourceVersion:15111,Generation:2,CreationTimestamp:2019-02-21 19:00:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-21 19:00:08 +0000 UTC 2019-02-21 19:00:08 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-21 19:00:22 +0000 UTC 2019-02-21 19:00:08 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb 21 19:00:24.319: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-g52n7,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-g52n7/replicasets/test-rollover-deployment-6b7f9d6597,UID:e941686d-360a-11e9-8547-42010a000100,ResourceVersion:15102,Generation:2,CreationTimestamp:2019-02-21 19:00:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment e80863d5-360a-11e9-bacd-42010a000102 0xc001a22da7 0xc001a22da8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 21 19:00:24.319: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Feb 21 19:00:24.319: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-g52n7,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-g52n7/replicasets/test-rollover-controller,UID:e3d6e469-360a-11e9-bacd-42010a000102,ResourceVersion:15110,Generation:2,CreationTimestamp:2019-02-21 19:00:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment e80863d5-360a-11e9-bacd-42010a000102 0xc001a22997 0xc001a22998}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 21 19:00:24.319: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-g52n7,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-g52n7/replicasets/test-rollover-deployment-6586df867b,UID:e80b8cad-360a-11e9-8547-42010a000100,ResourceVersion:15074,Generation:2,CreationTimestamp:2019-02-21 19:00:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment e80863d5-360a-11e9-bacd-42010a000102 0xc001a22ca7 0xc001a22ca8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 21 19:00:24.324: INFO: Pod "test-rollover-deployment-6b7f9d6597-k9lvv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-k9lvv,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-g52n7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g52n7/pods/test-rollover-deployment-6b7f9d6597-k9lvv,UID:e948fb0d-360a-11e9-8547-42010a000100,ResourceVersion:15083,Generation:0,CreationTimestamp:2019-02-21 19:00:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 e941686d-360a-11e9-8547-42010a000100 0xc0019341f7 0xc0019341f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nk7wh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nk7wh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-nk7wh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm-899af0be-63fe-4e97-4fe5-b77e233eb87c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001934290} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0019342b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:00:10 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:00:12 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:00:12 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:00:10 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.5,PodIP:10.200.20.81,StartTime:2019-02-21 19:00:10 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-21 19:00:11 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://262f12098bca82852996f492fcba1504da05d80ac9c8bc6be51a29f301d115e0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:00:24.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-g52n7" for this suite.
Feb 21 19:00:30.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:00:30.477: INFO: namespace: e2e-tests-deployment-g52n7, resource: bindings, ignored listing per whitelist
Feb 21 19:00:30.481: INFO: namespace e2e-tests-deployment-g52n7 deletion completed in 6.150755533s

• [SLOW TEST:29.512 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:00:30.481: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-gzszj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-gzszj
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Feb 21 19:00:30.699: INFO: Found 0 stateful pods, waiting for 3
Feb 21 19:00:40.712: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 21 19:00:40.712: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 21 19:00:40.712: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Feb 21 19:00:40.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 exec --namespace=e2e-tests-statefulset-gzszj ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 21 19:00:40.905: INFO: stderr: ""
Feb 21 19:00:40.905: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 21 19:00:40.905: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb 21 19:00:50.957: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Feb 21 19:01:00.990: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 exec --namespace=e2e-tests-statefulset-gzszj ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 21 19:01:01.163: INFO: stderr: ""
Feb 21 19:01:01.163: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 21 19:01:01.163: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 21 19:01:11.198: INFO: Waiting for StatefulSet e2e-tests-statefulset-gzszj/ss2 to complete update
Feb 21 19:01:11.198: INFO: Waiting for Pod e2e-tests-statefulset-gzszj/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 21 19:01:11.198: INFO: Waiting for Pod e2e-tests-statefulset-gzszj/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 21 19:01:11.198: INFO: Waiting for Pod e2e-tests-statefulset-gzszj/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 21 19:01:21.216: INFO: Waiting for StatefulSet e2e-tests-statefulset-gzszj/ss2 to complete update
Feb 21 19:01:21.216: INFO: Waiting for Pod e2e-tests-statefulset-gzszj/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Feb 21 19:01:31.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 exec --namespace=e2e-tests-statefulset-gzszj ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 21 19:01:31.397: INFO: stderr: ""
Feb 21 19:01:31.397: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 21 19:01:31.397: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 21 19:01:41.441: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Feb 21 19:01:51.471: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 exec --namespace=e2e-tests-statefulset-gzszj ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 21 19:01:51.643: INFO: stderr: ""
Feb 21 19:01:51.643: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 21 19:01:51.644: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 21 19:02:01.676: INFO: Waiting for StatefulSet e2e-tests-statefulset-gzszj/ss2 to complete update
Feb 21 19:02:01.676: INFO: Waiting for Pod e2e-tests-statefulset-gzszj/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 21 19:02:01.676: INFO: Waiting for Pod e2e-tests-statefulset-gzszj/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 21 19:02:01.676: INFO: Waiting for Pod e2e-tests-statefulset-gzszj/ss2-2 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 21 19:02:11.692: INFO: Waiting for StatefulSet e2e-tests-statefulset-gzszj/ss2 to complete update
Feb 21 19:02:11.692: INFO: Waiting for Pod e2e-tests-statefulset-gzszj/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 21 19:02:11.692: INFO: Waiting for Pod e2e-tests-statefulset-gzszj/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 21 19:02:21.685: INFO: Waiting for StatefulSet e2e-tests-statefulset-gzszj/ss2 to complete update
Feb 21 19:02:21.685: INFO: Waiting for Pod e2e-tests-statefulset-gzszj/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 21 19:02:31.692: INFO: Deleting all statefulset in ns e2e-tests-statefulset-gzszj
Feb 21 19:02:31.695: INFO: Scaling statefulset ss2 to 0
Feb 21 19:02:51.713: INFO: Waiting for statefulset status.replicas updated to 0
Feb 21 19:02:51.717: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:02:51.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-gzszj" for this suite.
Feb 21 19:02:57.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:02:57.899: INFO: namespace: e2e-tests-statefulset-gzszj, resource: bindings, ignored listing per whitelist
Feb 21 19:02:57.906: INFO: namespace e2e-tests-statefulset-gzszj deletion completed in 6.152767505s

• [SLOW TEST:147.425 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:02:57.906: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-vc29z
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 21 19:02:58.105: INFO: Waiting up to 5m0s for pod "pod-4d4d28da-360b-11e9-816d-1a333d676433" in namespace "e2e-tests-emptydir-vc29z" to be "success or failure"
Feb 21 19:02:58.110: INFO: Pod "pod-4d4d28da-360b-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 5.811648ms
Feb 21 19:03:00.115: INFO: Pod "pod-4d4d28da-360b-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010286665s
Feb 21 19:03:02.127: INFO: Pod "pod-4d4d28da-360b-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022389252s
STEP: Saw pod success
Feb 21 19:03:02.127: INFO: Pod "pod-4d4d28da-360b-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 19:03:02.131: INFO: Trying to get logs from node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c pod pod-4d4d28da-360b-11e9-816d-1a333d676433 container test-container: <nil>
STEP: delete the pod
Feb 21 19:03:02.157: INFO: Waiting for pod pod-4d4d28da-360b-11e9-816d-1a333d676433 to disappear
Feb 21 19:03:02.161: INFO: Pod pod-4d4d28da-360b-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:03:02.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-vc29z" for this suite.
Feb 21 19:03:08.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:03:08.204: INFO: namespace: e2e-tests-emptydir-vc29z, resource: bindings, ignored listing per whitelist
Feb 21 19:03:08.348: INFO: namespace e2e-tests-emptydir-vc29z deletion completed in 6.18276024s

• [SLOW TEST:10.442 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:03:08.349: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-97w4f
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-53871bbf-360b-11e9-816d-1a333d676433
STEP: Creating a pod to test consume configMaps
Feb 21 19:03:08.565: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5388f658-360b-11e9-816d-1a333d676433" in namespace "e2e-tests-projected-97w4f" to be "success or failure"
Feb 21 19:03:08.572: INFO: Pod "pod-projected-configmaps-5388f658-360b-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 6.319468ms
Feb 21 19:03:10.576: INFO: Pod "pod-projected-configmaps-5388f658-360b-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010898082s
STEP: Saw pod success
Feb 21 19:03:10.576: INFO: Pod "pod-projected-configmaps-5388f658-360b-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 19:03:10.580: INFO: Trying to get logs from node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c pod pod-projected-configmaps-5388f658-360b-11e9-816d-1a333d676433 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 21 19:03:10.609: INFO: Waiting for pod pod-projected-configmaps-5388f658-360b-11e9-816d-1a333d676433 to disappear
Feb 21 19:03:10.613: INFO: Pod pod-projected-configmaps-5388f658-360b-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:03:10.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-97w4f" for this suite.
Feb 21 19:03:16.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:03:16.770: INFO: namespace: e2e-tests-projected-97w4f, resource: bindings, ignored listing per whitelist
Feb 21 19:03:16.796: INFO: namespace e2e-tests-projected-97w4f deletion completed in 6.178414152s

• [SLOW TEST:8.448 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:03:16.796: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-6s44h
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:04:17.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-6s44h" for this suite.
Feb 21 19:04:39.027: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:04:39.151: INFO: namespace: e2e-tests-container-probe-6s44h, resource: bindings, ignored listing per whitelist
Feb 21 19:04:39.158: INFO: namespace e2e-tests-container-probe-6s44h deletion completed in 22.149446236s

• [SLOW TEST:82.362 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:04:39.159: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-g5fsc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Feb 21 19:04:39.359: INFO: Waiting up to 5m0s for pod "client-containers-89a76302-360b-11e9-816d-1a333d676433" in namespace "e2e-tests-containers-g5fsc" to be "success or failure"
Feb 21 19:04:39.366: INFO: Pod "client-containers-89a76302-360b-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 6.336577ms
Feb 21 19:04:41.371: INFO: Pod "client-containers-89a76302-360b-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011246354s
Feb 21 19:04:43.375: INFO: Pod "client-containers-89a76302-360b-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015976023s
STEP: Saw pod success
Feb 21 19:04:43.375: INFO: Pod "client-containers-89a76302-360b-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 19:04:43.379: INFO: Trying to get logs from node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c pod client-containers-89a76302-360b-11e9-816d-1a333d676433 container test-container: <nil>
STEP: delete the pod
Feb 21 19:04:43.408: INFO: Waiting for pod client-containers-89a76302-360b-11e9-816d-1a333d676433 to disappear
Feb 21 19:04:43.411: INFO: Pod client-containers-89a76302-360b-11e9-816d-1a333d676433 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:04:43.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-g5fsc" for this suite.
Feb 21 19:04:49.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:04:49.460: INFO: namespace: e2e-tests-containers-g5fsc, resource: bindings, ignored listing per whitelist
Feb 21 19:04:49.573: INFO: namespace e2e-tests-containers-g5fsc deletion completed in 6.157282958s

• [SLOW TEST:10.415 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:04:49.573: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-9mc26
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Feb 21 19:04:49.765: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Feb 21 19:04:49.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 create -f - --namespace=e2e-tests-kubectl-9mc26'
Feb 21 19:04:50.309: INFO: stderr: ""
Feb 21 19:04:50.309: INFO: stdout: "service/redis-slave created\n"
Feb 21 19:04:50.309: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Feb 21 19:04:50.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 create -f - --namespace=e2e-tests-kubectl-9mc26'
Feb 21 19:04:50.584: INFO: stderr: ""
Feb 21 19:04:50.584: INFO: stdout: "service/redis-master created\n"
Feb 21 19:04:50.584: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Feb 21 19:04:50.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 create -f - --namespace=e2e-tests-kubectl-9mc26'
Feb 21 19:04:50.789: INFO: stderr: ""
Feb 21 19:04:50.789: INFO: stdout: "service/frontend created\n"
Feb 21 19:04:50.789: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Feb 21 19:04:50.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 create -f - --namespace=e2e-tests-kubectl-9mc26'
Feb 21 19:04:51.008: INFO: stderr: ""
Feb 21 19:04:51.008: INFO: stdout: "deployment.extensions/frontend created\n"
Feb 21 19:04:51.008: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Feb 21 19:04:51.008: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 create -f - --namespace=e2e-tests-kubectl-9mc26'
Feb 21 19:04:51.263: INFO: stderr: ""
Feb 21 19:04:51.263: INFO: stdout: "deployment.extensions/redis-master created\n"
Feb 21 19:04:51.263: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Feb 21 19:04:51.263: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 create -f - --namespace=e2e-tests-kubectl-9mc26'
Feb 21 19:04:51.463: INFO: stderr: ""
Feb 21 19:04:51.463: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Feb 21 19:04:51.463: INFO: Waiting for all frontend pods to be Running.
Feb 21 19:05:06.514: INFO: Waiting for frontend to serve content.
Feb 21 19:05:06.547: INFO: Trying to add a new entry to the guestbook.
Feb 21 19:05:06.567: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Feb 21 19:05:06.587: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-9mc26'
Feb 21 19:05:06.688: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 21 19:05:06.688: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Feb 21 19:05:06.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-9mc26'
Feb 21 19:05:06.790: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 21 19:05:06.790: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 21 19:05:06.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-9mc26'
Feb 21 19:05:06.896: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 21 19:05:06.896: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 21 19:05:06.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-9mc26'
Feb 21 19:05:06.987: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 21 19:05:06.987: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 21 19:05:06.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-9mc26'
Feb 21 19:05:07.091: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 21 19:05:07.091: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 21 19:05:07.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-9mc26'
Feb 21 19:05:07.210: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 21 19:05:07.210: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:05:07.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9mc26" for this suite.
Feb 21 19:05:51.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:05:51.354: INFO: namespace: e2e-tests-kubectl-9mc26, resource: bindings, ignored listing per whitelist
Feb 21 19:05:51.411: INFO: namespace e2e-tests-kubectl-9mc26 deletion completed in 44.19554232s

• [SLOW TEST:61.838 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:05:51.412: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-lgm4n
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 21 19:05:51.614: INFO: Waiting up to 5m0s for pod "downward-api-b4b85fa2-360b-11e9-816d-1a333d676433" in namespace "e2e-tests-downward-api-lgm4n" to be "success or failure"
Feb 21 19:05:51.619: INFO: Pod "downward-api-b4b85fa2-360b-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 5.031025ms
Feb 21 19:05:53.623: INFO: Pod "downward-api-b4b85fa2-360b-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009661226s
STEP: Saw pod success
Feb 21 19:05:53.623: INFO: Pod "downward-api-b4b85fa2-360b-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 19:05:53.627: INFO: Trying to get logs from node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c pod downward-api-b4b85fa2-360b-11e9-816d-1a333d676433 container dapi-container: <nil>
STEP: delete the pod
Feb 21 19:05:53.655: INFO: Waiting for pod downward-api-b4b85fa2-360b-11e9-816d-1a333d676433 to disappear
Feb 21 19:05:53.659: INFO: Pod downward-api-b4b85fa2-360b-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:05:53.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-lgm4n" for this suite.
Feb 21 19:05:59.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:05:59.745: INFO: namespace: e2e-tests-downward-api-lgm4n, resource: bindings, ignored listing per whitelist
Feb 21 19:05:59.808: INFO: namespace e2e-tests-downward-api-lgm4n deletion completed in 6.144119214s

• [SLOW TEST:8.396 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:05:59.808: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-62rvs
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-62rvs.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-62rvs.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-62rvs.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-62rvs.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-62rvs.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-62rvs.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 21 19:06:04.119: INFO: DNS probes using e2e-tests-dns-62rvs/dns-test-b9b82e5f-360b-11e9-816d-1a333d676433 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:06:04.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-62rvs" for this suite.
Feb 21 19:06:10.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:06:10.182: INFO: namespace: e2e-tests-dns-62rvs, resource: bindings, ignored listing per whitelist
Feb 21 19:06:10.295: INFO: namespace e2e-tests-dns-62rvs deletion completed in 6.152275007s

• [SLOW TEST:10.487 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:06:10.295: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-m7jjl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 21 19:06:10.496: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bff96abf-360b-11e9-816d-1a333d676433" in namespace "e2e-tests-projected-m7jjl" to be "success or failure"
Feb 21 19:06:10.502: INFO: Pod "downwardapi-volume-bff96abf-360b-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 5.587017ms
Feb 21 19:06:12.514: INFO: Pod "downwardapi-volume-bff96abf-360b-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018163396s
Feb 21 19:06:14.519: INFO: Pod "downwardapi-volume-bff96abf-360b-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022535971s
STEP: Saw pod success
Feb 21 19:06:14.519: INFO: Pod "downwardapi-volume-bff96abf-360b-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 19:06:14.522: INFO: Trying to get logs from node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c pod downwardapi-volume-bff96abf-360b-11e9-816d-1a333d676433 container client-container: <nil>
STEP: delete the pod
Feb 21 19:06:14.549: INFO: Waiting for pod downwardapi-volume-bff96abf-360b-11e9-816d-1a333d676433 to disappear
Feb 21 19:06:14.552: INFO: Pod downwardapi-volume-bff96abf-360b-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:06:14.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-m7jjl" for this suite.
Feb 21 19:06:20.576: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:06:20.679: INFO: namespace: e2e-tests-projected-m7jjl, resource: bindings, ignored listing per whitelist
Feb 21 19:06:20.706: INFO: namespace e2e-tests-projected-m7jjl deletion completed in 6.149125595s

• [SLOW TEST:10.412 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:06:20.707: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-xgpbn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Feb 21 19:06:20.906: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 --namespace=e2e-tests-kubectl-xgpbn run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Feb 21 19:06:23.082: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Feb 21 19:06:23.082: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:06:25.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xgpbn" for this suite.
Feb 21 19:06:39.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:06:39.197: INFO: namespace: e2e-tests-kubectl-xgpbn, resource: bindings, ignored listing per whitelist
Feb 21 19:06:39.230: INFO: namespace e2e-tests-kubectl-xgpbn deletion completed in 14.134172512s

• [SLOW TEST:18.524 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:06:39.231: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-wxk9f
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Feb 21 19:06:39.448: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-wxk9f,SelfLink:/api/v1/namespaces/e2e-tests-watch-wxk9f/configmaps/e2e-watch-test-resource-version,UID:d137fda7-360b-11e9-bacd-42010a000102,ResourceVersion:16532,Generation:0,CreationTimestamp:2019-02-21 19:06:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 21 19:06:39.449: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-wxk9f,SelfLink:/api/v1/namespaces/e2e-tests-watch-wxk9f/configmaps/e2e-watch-test-resource-version,UID:d137fda7-360b-11e9-bacd-42010a000102,ResourceVersion:16533,Generation:0,CreationTimestamp:2019-02-21 19:06:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:06:39.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-wxk9f" for this suite.
Feb 21 19:06:45.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:06:45.525: INFO: namespace: e2e-tests-watch-wxk9f, resource: bindings, ignored listing per whitelist
Feb 21 19:06:45.606: INFO: namespace e2e-tests-watch-wxk9f deletion completed in 6.153157669s

• [SLOW TEST:6.376 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:06:45.607: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-s82f8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-d5053ef8-360b-11e9-816d-1a333d676433
Feb 21 19:06:45.805: INFO: Pod name my-hostname-basic-d5053ef8-360b-11e9-816d-1a333d676433: Found 0 pods out of 1
Feb 21 19:06:50.810: INFO: Pod name my-hostname-basic-d5053ef8-360b-11e9-816d-1a333d676433: Found 1 pods out of 1
Feb 21 19:06:50.810: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-d5053ef8-360b-11e9-816d-1a333d676433" are running
Feb 21 19:06:50.814: INFO: Pod "my-hostname-basic-d5053ef8-360b-11e9-816d-1a333d676433-vt59m" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-21 19:06:45 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-21 19:06:47 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-21 19:06:47 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-21 19:06:45 +0000 UTC Reason: Message:}])
Feb 21 19:06:50.814: INFO: Trying to dial the pod
Feb 21 19:06:55.837: INFO: Controller my-hostname-basic-d5053ef8-360b-11e9-816d-1a333d676433: Got expected result from replica 1 [my-hostname-basic-d5053ef8-360b-11e9-816d-1a333d676433-vt59m]: "my-hostname-basic-d5053ef8-360b-11e9-816d-1a333d676433-vt59m", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:06:55.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-s82f8" for this suite.
Feb 21 19:07:01.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:07:01.936: INFO: namespace: e2e-tests-replication-controller-s82f8, resource: bindings, ignored listing per whitelist
Feb 21 19:07:02.018: INFO: namespace e2e-tests-replication-controller-s82f8 deletion completed in 6.174844385s

• [SLOW TEST:16.411 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:07:02.018: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-cr2jt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-l5ln
STEP: Creating a pod to test atomic-volume-subpath
Feb 21 19:07:02.231: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-l5ln" in namespace "e2e-tests-subpath-cr2jt" to be "success or failure"
Feb 21 19:07:02.237: INFO: Pod "pod-subpath-test-projected-l5ln": Phase="Pending", Reason="", readiness=false. Elapsed: 5.520339ms
Feb 21 19:07:04.242: INFO: Pod "pod-subpath-test-projected-l5ln": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010532051s
Feb 21 19:07:06.257: INFO: Pod "pod-subpath-test-projected-l5ln": Phase="Running", Reason="", readiness=false. Elapsed: 4.025222058s
Feb 21 19:07:08.262: INFO: Pod "pod-subpath-test-projected-l5ln": Phase="Running", Reason="", readiness=false. Elapsed: 6.030215624s
Feb 21 19:07:10.267: INFO: Pod "pod-subpath-test-projected-l5ln": Phase="Running", Reason="", readiness=false. Elapsed: 8.035106139s
Feb 21 19:07:12.272: INFO: Pod "pod-subpath-test-projected-l5ln": Phase="Running", Reason="", readiness=false. Elapsed: 10.040386425s
Feb 21 19:07:14.277: INFO: Pod "pod-subpath-test-projected-l5ln": Phase="Running", Reason="", readiness=false. Elapsed: 12.045556082s
Feb 21 19:07:16.290: INFO: Pod "pod-subpath-test-projected-l5ln": Phase="Running", Reason="", readiness=false. Elapsed: 14.058141689s
Feb 21 19:07:18.294: INFO: Pod "pod-subpath-test-projected-l5ln": Phase="Running", Reason="", readiness=false. Elapsed: 16.062812232s
Feb 21 19:07:20.299: INFO: Pod "pod-subpath-test-projected-l5ln": Phase="Running", Reason="", readiness=false. Elapsed: 18.067934445s
Feb 21 19:07:22.304: INFO: Pod "pod-subpath-test-projected-l5ln": Phase="Running", Reason="", readiness=false. Elapsed: 20.072648798s
Feb 21 19:07:24.310: INFO: Pod "pod-subpath-test-projected-l5ln": Phase="Running", Reason="", readiness=false. Elapsed: 22.078393411s
Feb 21 19:07:26.321: INFO: Pod "pod-subpath-test-projected-l5ln": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.090039194s
STEP: Saw pod success
Feb 21 19:07:26.322: INFO: Pod "pod-subpath-test-projected-l5ln" satisfied condition "success or failure"
Feb 21 19:07:26.326: INFO: Trying to get logs from node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c pod pod-subpath-test-projected-l5ln container test-container-subpath-projected-l5ln: <nil>
STEP: delete the pod
Feb 21 19:07:26.352: INFO: Waiting for pod pod-subpath-test-projected-l5ln to disappear
Feb 21 19:07:26.355: INFO: Pod pod-subpath-test-projected-l5ln no longer exists
STEP: Deleting pod pod-subpath-test-projected-l5ln
Feb 21 19:07:26.355: INFO: Deleting pod "pod-subpath-test-projected-l5ln" in namespace "e2e-tests-subpath-cr2jt"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:07:26.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-cr2jt" for this suite.
Feb 21 19:07:32.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:07:32.421: INFO: namespace: e2e-tests-subpath-cr2jt, resource: bindings, ignored listing per whitelist
Feb 21 19:07:32.510: INFO: namespace e2e-tests-subpath-cr2jt deletion completed in 6.147403186s

• [SLOW TEST:30.493 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:07:32.511: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-w7fpg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 21 19:07:32.718: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f0fafe43-360b-11e9-816d-1a333d676433" in namespace "e2e-tests-downward-api-w7fpg" to be "success or failure"
Feb 21 19:07:32.722: INFO: Pod "downwardapi-volume-f0fafe43-360b-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 3.799835ms
Feb 21 19:07:34.727: INFO: Pod "downwardapi-volume-f0fafe43-360b-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008869844s
STEP: Saw pod success
Feb 21 19:07:34.727: INFO: Pod "downwardapi-volume-f0fafe43-360b-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 19:07:34.730: INFO: Trying to get logs from node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c pod downwardapi-volume-f0fafe43-360b-11e9-816d-1a333d676433 container client-container: <nil>
STEP: delete the pod
Feb 21 19:07:34.757: INFO: Waiting for pod downwardapi-volume-f0fafe43-360b-11e9-816d-1a333d676433 to disappear
Feb 21 19:07:34.760: INFO: Pod downwardapi-volume-f0fafe43-360b-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:07:34.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-w7fpg" for this suite.
Feb 21 19:07:40.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:07:40.818: INFO: namespace: e2e-tests-downward-api-w7fpg, resource: bindings, ignored listing per whitelist
Feb 21 19:07:40.922: INFO: namespace e2e-tests-downward-api-w7fpg deletion completed in 6.157114365s

• [SLOW TEST:8.412 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:07:40.922: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-cdv97
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-nqnh
STEP: Creating a pod to test atomic-volume-subpath
Feb 21 19:07:41.133: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-nqnh" in namespace "e2e-tests-subpath-cdv97" to be "success or failure"
Feb 21 19:07:41.139: INFO: Pod "pod-subpath-test-configmap-nqnh": Phase="Pending", Reason="", readiness=false. Elapsed: 6.195012ms
Feb 21 19:07:43.144: INFO: Pod "pod-subpath-test-configmap-nqnh": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010913755s
Feb 21 19:07:45.149: INFO: Pod "pod-subpath-test-configmap-nqnh": Phase="Running", Reason="", readiness=false. Elapsed: 4.015777904s
Feb 21 19:07:47.161: INFO: Pod "pod-subpath-test-configmap-nqnh": Phase="Running", Reason="", readiness=false. Elapsed: 6.028105412s
Feb 21 19:07:49.166: INFO: Pod "pod-subpath-test-configmap-nqnh": Phase="Running", Reason="", readiness=false. Elapsed: 8.032925696s
Feb 21 19:07:51.170: INFO: Pod "pod-subpath-test-configmap-nqnh": Phase="Running", Reason="", readiness=false. Elapsed: 10.037611972s
Feb 21 19:07:53.175: INFO: Pod "pod-subpath-test-configmap-nqnh": Phase="Running", Reason="", readiness=false. Elapsed: 12.042753066s
Feb 21 19:07:55.180: INFO: Pod "pod-subpath-test-configmap-nqnh": Phase="Running", Reason="", readiness=false. Elapsed: 14.047362286s
Feb 21 19:07:57.192: INFO: Pod "pod-subpath-test-configmap-nqnh": Phase="Running", Reason="", readiness=false. Elapsed: 16.058933818s
Feb 21 19:07:59.197: INFO: Pod "pod-subpath-test-configmap-nqnh": Phase="Running", Reason="", readiness=false. Elapsed: 18.064181019s
Feb 21 19:08:01.202: INFO: Pod "pod-subpath-test-configmap-nqnh": Phase="Running", Reason="", readiness=false. Elapsed: 20.069580351s
Feb 21 19:08:03.207: INFO: Pod "pod-subpath-test-configmap-nqnh": Phase="Running", Reason="", readiness=false. Elapsed: 22.074069573s
Feb 21 19:08:05.211: INFO: Pod "pod-subpath-test-configmap-nqnh": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.078584266s
STEP: Saw pod success
Feb 21 19:08:05.211: INFO: Pod "pod-subpath-test-configmap-nqnh" satisfied condition "success or failure"
Feb 21 19:08:05.215: INFO: Trying to get logs from node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c pod pod-subpath-test-configmap-nqnh container test-container-subpath-configmap-nqnh: <nil>
STEP: delete the pod
Feb 21 19:08:05.243: INFO: Waiting for pod pod-subpath-test-configmap-nqnh to disappear
Feb 21 19:08:05.246: INFO: Pod pod-subpath-test-configmap-nqnh no longer exists
STEP: Deleting pod pod-subpath-test-configmap-nqnh
Feb 21 19:08:05.246: INFO: Deleting pod "pod-subpath-test-configmap-nqnh" in namespace "e2e-tests-subpath-cdv97"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:08:05.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-cdv97" for this suite.
Feb 21 19:08:11.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:08:11.316: INFO: namespace: e2e-tests-subpath-cdv97, resource: bindings, ignored listing per whitelist
Feb 21 19:08:11.403: INFO: namespace e2e-tests-subpath-cdv97 deletion completed in 6.149253914s

• [SLOW TEST:30.481 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:08:11.403: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-6zhfd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-0828fb45-360c-11e9-816d-1a333d676433
STEP: Creating a pod to test consume configMaps
Feb 21 19:08:11.611: INFO: Waiting up to 5m0s for pod "pod-configmaps-082a2908-360c-11e9-816d-1a333d676433" in namespace "e2e-tests-configmap-6zhfd" to be "success or failure"
Feb 21 19:08:11.615: INFO: Pod "pod-configmaps-082a2908-360c-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 4.555273ms
Feb 21 19:08:13.622: INFO: Pod "pod-configmaps-082a2908-360c-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01072746s
STEP: Saw pod success
Feb 21 19:08:13.622: INFO: Pod "pod-configmaps-082a2908-360c-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 19:08:13.626: INFO: Trying to get logs from node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c pod pod-configmaps-082a2908-360c-11e9-816d-1a333d676433 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 21 19:08:13.651: INFO: Waiting for pod pod-configmaps-082a2908-360c-11e9-816d-1a333d676433 to disappear
Feb 21 19:08:13.655: INFO: Pod pod-configmaps-082a2908-360c-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:08:13.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-6zhfd" for this suite.
Feb 21 19:08:19.679: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:08:19.728: INFO: namespace: e2e-tests-configmap-6zhfd, resource: bindings, ignored listing per whitelist
Feb 21 19:08:19.832: INFO: namespace e2e-tests-configmap-6zhfd deletion completed in 6.172405474s

• [SLOW TEST:8.429 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:08:19.832: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-nlrhz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-nlrhz
Feb 21 19:08:24.048: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-nlrhz
STEP: checking the pod's current state and verifying that restartCount is present
Feb 21 19:08:24.052: INFO: Initial restart count of pod liveness-http is 0
Feb 21 19:08:38.103: INFO: Restart count of pod e2e-tests-container-probe-nlrhz/liveness-http is now 1 (14.050882039s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:08:38.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-nlrhz" for this suite.
Feb 21 19:08:44.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:08:44.185: INFO: namespace: e2e-tests-container-probe-nlrhz, resource: bindings, ignored listing per whitelist
Feb 21 19:08:44.274: INFO: namespace e2e-tests-container-probe-nlrhz deletion completed in 6.14838051s

• [SLOW TEST:24.442 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:08:44.275: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-jjdtk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:08:46.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-jjdtk" for this suite.
Feb 21 19:09:24.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:09:24.666: INFO: namespace: e2e-tests-kubelet-test-jjdtk, resource: bindings, ignored listing per whitelist
Feb 21 19:09:24.687: INFO: namespace e2e-tests-kubelet-test-jjdtk deletion completed in 38.180946257s

• [SLOW TEST:40.413 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:09:24.687: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-676tk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Feb 21 19:09:24.878: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 21 19:09:24.887: INFO: Waiting for terminating namespaces to be deleted...
Feb 21 19:09:24.891: INFO: 
Logging pods the kubelet thinks is on node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c before test
Feb 21 19:09:24.898: INFO: coredns-54586579f6-8j2jr from kube-system started at 2019-02-21 17:44:33 +0000 UTC (1 container statuses recorded)
Feb 21 19:09:24.898: INFO: 	Container coredns ready: true, restart count 0
Feb 21 19:09:24.898: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-21 18:13:29 +0000 UTC (1 container statuses recorded)
Feb 21 19:09:24.898: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 21 19:09:24.898: INFO: sonobuoy-systemd-logs-daemon-set-8b397f221aec4f93-4wkfg from heptio-sonobuoy started at 2019-02-21 18:13:33 +0000 UTC (2 container statuses recorded)
Feb 21 19:09:24.898: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 21 19:09:24.898: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 21 19:09:24.898: INFO: 
Logging pods the kubelet thinks is on node vm-96433648-4a4e-4d7e-4d24-8065d4ab25dc before test
Feb 21 19:09:24.906: INFO: coredns-54586579f6-jqhrc from kube-system started at 2019-02-21 17:44:33 +0000 UTC (1 container statuses recorded)
Feb 21 19:09:24.906: INFO: 	Container coredns ready: true, restart count 0
Feb 21 19:09:24.906: INFO: metrics-server-5475446b7f-zdftv from kube-system started at 2019-02-21 17:44:35 +0000 UTC (1 container statuses recorded)
Feb 21 19:09:24.906: INFO: 	Container metrics-server ready: true, restart count 0
Feb 21 19:09:24.906: INFO: sonobuoy-e2e-job-820b1b08ea7846bb from heptio-sonobuoy started at 2019-02-21 18:13:32 +0000 UTC (2 container statuses recorded)
Feb 21 19:09:24.906: INFO: 	Container e2e ready: true, restart count 0
Feb 21 19:09:24.906: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 21 19:09:24.906: INFO: sonobuoy-systemd-logs-daemon-set-8b397f221aec4f93-wdlj7 from heptio-sonobuoy started at 2019-02-21 18:13:33 +0000 UTC (2 container statuses recorded)
Feb 21 19:09:24.906: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 21 19:09:24.906: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 21 19:09:24.906: INFO: 
Logging pods the kubelet thinks is on node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c before test
Feb 21 19:09:24.914: INFO: coredns-54586579f6-sj4gh from kube-system started at 2019-02-21 17:44:33 +0000 UTC (1 container statuses recorded)
Feb 21 19:09:24.914: INFO: 	Container coredns ready: true, restart count 0
Feb 21 19:09:24.914: INFO: kubernetes-dashboard-6c68548bc9-blr2b from kube-system started at 2019-02-21 17:44:38 +0000 UTC (1 container statuses recorded)
Feb 21 19:09:24.914: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Feb 21 19:09:24.914: INFO: sonobuoy-systemd-logs-daemon-set-8b397f221aec4f93-r7kz4 from heptio-sonobuoy started at 2019-02-21 18:13:33 +0000 UTC (2 container statuses recorded)
Feb 21 19:09:24.914: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 21 19:09:24.914: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-3514d5bc-360c-11e9-816d-1a333d676433 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-3514d5bc-360c-11e9-816d-1a333d676433 off the node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c
STEP: verifying the node doesn't have the label kubernetes.io/e2e-3514d5bc-360c-11e9-816d-1a333d676433
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:09:29.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-676tk" for this suite.
Feb 21 19:09:37.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:09:37.089: INFO: namespace: e2e-tests-sched-pred-676tk, resource: bindings, ignored listing per whitelist
Feb 21 19:09:37.161: INFO: namespace e2e-tests-sched-pred-676tk deletion completed in 8.151013038s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:12.474 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:09:37.162: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-9cm4p
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-3b4b2287-360c-11e9-816d-1a333d676433
STEP: Creating a pod to test consume configMaps
Feb 21 19:09:37.401: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3b4c39af-360c-11e9-816d-1a333d676433" in namespace "e2e-tests-projected-9cm4p" to be "success or failure"
Feb 21 19:09:37.406: INFO: Pod "pod-projected-configmaps-3b4c39af-360c-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 5.054042ms
Feb 21 19:09:39.410: INFO: Pod "pod-projected-configmaps-3b4c39af-360c-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009375308s
STEP: Saw pod success
Feb 21 19:09:39.410: INFO: Pod "pod-projected-configmaps-3b4c39af-360c-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 19:09:39.413: INFO: Trying to get logs from node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c pod pod-projected-configmaps-3b4c39af-360c-11e9-816d-1a333d676433 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 21 19:09:39.438: INFO: Waiting for pod pod-projected-configmaps-3b4c39af-360c-11e9-816d-1a333d676433 to disappear
Feb 21 19:09:39.441: INFO: Pod pod-projected-configmaps-3b4c39af-360c-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:09:39.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9cm4p" for this suite.
Feb 21 19:09:45.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:09:45.524: INFO: namespace: e2e-tests-projected-9cm4p, resource: bindings, ignored listing per whitelist
Feb 21 19:09:45.601: INFO: namespace e2e-tests-projected-9cm4p deletion completed in 6.155186977s

• [SLOW TEST:8.439 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:09:45.601: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-dlhjt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 21 19:09:45.791: INFO: Waiting up to 5m0s for pod "downwardapi-volume-404d0154-360c-11e9-816d-1a333d676433" in namespace "e2e-tests-projected-dlhjt" to be "success or failure"
Feb 21 19:09:45.796: INFO: Pod "downwardapi-volume-404d0154-360c-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 4.686705ms
Feb 21 19:09:47.800: INFO: Pod "downwardapi-volume-404d0154-360c-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00939854s
STEP: Saw pod success
Feb 21 19:09:47.800: INFO: Pod "downwardapi-volume-404d0154-360c-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 19:09:47.804: INFO: Trying to get logs from node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c pod downwardapi-volume-404d0154-360c-11e9-816d-1a333d676433 container client-container: <nil>
STEP: delete the pod
Feb 21 19:09:47.833: INFO: Waiting for pod downwardapi-volume-404d0154-360c-11e9-816d-1a333d676433 to disappear
Feb 21 19:09:47.837: INFO: Pod downwardapi-volume-404d0154-360c-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:09:47.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dlhjt" for this suite.
Feb 21 19:09:53.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:09:53.939: INFO: namespace: e2e-tests-projected-dlhjt, resource: bindings, ignored listing per whitelist
Feb 21 19:09:54.019: INFO: namespace e2e-tests-projected-dlhjt deletion completed in 6.175916484s

• [SLOW TEST:8.418 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:09:54.019: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-mbfhb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0221 19:10:04.341422      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 21 19:10:04.341: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:10:04.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-mbfhb" for this suite.
Feb 21 19:10:10.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:10:10.421: INFO: namespace: e2e-tests-gc-mbfhb, resource: bindings, ignored listing per whitelist
Feb 21 19:10:10.540: INFO: namespace e2e-tests-gc-mbfhb deletion completed in 6.193972144s

• [SLOW TEST:16.521 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:10:10.540: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-wjmf5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-4f2e2963-360c-11e9-816d-1a333d676433
STEP: Creating a pod to test consume configMaps
Feb 21 19:10:10.764: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4f2f4240-360c-11e9-816d-1a333d676433" in namespace "e2e-tests-projected-wjmf5" to be "success or failure"
Feb 21 19:10:10.771: INFO: Pod "pod-projected-configmaps-4f2f4240-360c-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 6.897852ms
Feb 21 19:10:12.776: INFO: Pod "pod-projected-configmaps-4f2f4240-360c-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012455575s
Feb 21 19:10:14.781: INFO: Pod "pod-projected-configmaps-4f2f4240-360c-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017469128s
STEP: Saw pod success
Feb 21 19:10:14.781: INFO: Pod "pod-projected-configmaps-4f2f4240-360c-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 19:10:14.785: INFO: Trying to get logs from node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c pod pod-projected-configmaps-4f2f4240-360c-11e9-816d-1a333d676433 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 21 19:10:14.815: INFO: Waiting for pod pod-projected-configmaps-4f2f4240-360c-11e9-816d-1a333d676433 to disappear
Feb 21 19:10:14.819: INFO: Pod pod-projected-configmaps-4f2f4240-360c-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:10:14.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wjmf5" for this suite.
Feb 21 19:10:20.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:10:20.903: INFO: namespace: e2e-tests-projected-wjmf5, resource: bindings, ignored listing per whitelist
Feb 21 19:10:21.002: INFO: namespace e2e-tests-projected-wjmf5 deletion completed in 6.176905469s

• [SLOW TEST:10.462 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:10:21.002: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-4fll6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 21 19:10:21.203: INFO: Waiting up to 5m0s for pod "pod-5568859e-360c-11e9-816d-1a333d676433" in namespace "e2e-tests-emptydir-4fll6" to be "success or failure"
Feb 21 19:10:21.208: INFO: Pod "pod-5568859e-360c-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 5.390033ms
Feb 21 19:10:23.213: INFO: Pod "pod-5568859e-360c-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010385978s
Feb 21 19:10:25.218: INFO: Pod "pod-5568859e-360c-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015062157s
STEP: Saw pod success
Feb 21 19:10:25.218: INFO: Pod "pod-5568859e-360c-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 19:10:25.222: INFO: Trying to get logs from node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c pod pod-5568859e-360c-11e9-816d-1a333d676433 container test-container: <nil>
STEP: delete the pod
Feb 21 19:10:25.248: INFO: Waiting for pod pod-5568859e-360c-11e9-816d-1a333d676433 to disappear
Feb 21 19:10:25.251: INFO: Pod pod-5568859e-360c-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:10:25.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-4fll6" for this suite.
Feb 21 19:10:31.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:10:31.429: INFO: namespace: e2e-tests-emptydir-4fll6, resource: bindings, ignored listing per whitelist
Feb 21 19:10:31.434: INFO: namespace e2e-tests-emptydir-4fll6 deletion completed in 6.177417659s

• [SLOW TEST:10.432 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:10:31.434: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-2znbd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:10:31.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-2znbd" for this suite.
Feb 21 19:10:37.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:10:37.821: INFO: namespace: e2e-tests-services-2znbd, resource: bindings, ignored listing per whitelist
Feb 21 19:10:37.843: INFO: namespace e2e-tests-services-2znbd deletion completed in 6.19599611s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:6.409 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:10:37.843: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-pvhm2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 21 19:10:38.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-pvhm2'
Feb 21 19:10:38.136: INFO: stderr: ""
Feb 21 19:10:38.136: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Feb 21 19:10:38.143: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-pvhm2'
Feb 21 19:10:49.017: INFO: stderr: ""
Feb 21 19:10:49.017: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:10:49.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pvhm2" for this suite.
Feb 21 19:10:55.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:10:55.060: INFO: namespace: e2e-tests-kubectl-pvhm2, resource: bindings, ignored listing per whitelist
Feb 21 19:10:55.190: INFO: namespace e2e-tests-kubectl-pvhm2 deletion completed in 6.159170811s

• [SLOW TEST:17.346 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:10:55.190: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-wpkrw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Feb 21 19:10:55.401: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-wpkrw,SelfLink:/api/v1/namespaces/e2e-tests-watch-wpkrw/configmaps/e2e-watch-test-configmap-a,UID:69cace5f-360c-11e9-bacd-42010a000102,ResourceVersion:17599,Generation:0,CreationTimestamp:2019-02-21 19:10:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 21 19:10:55.401: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-wpkrw,SelfLink:/api/v1/namespaces/e2e-tests-watch-wpkrw/configmaps/e2e-watch-test-configmap-a,UID:69cace5f-360c-11e9-bacd-42010a000102,ResourceVersion:17599,Generation:0,CreationTimestamp:2019-02-21 19:10:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Feb 21 19:11:05.420: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-wpkrw,SelfLink:/api/v1/namespaces/e2e-tests-watch-wpkrw/configmaps/e2e-watch-test-configmap-a,UID:69cace5f-360c-11e9-bacd-42010a000102,ResourceVersion:17616,Generation:0,CreationTimestamp:2019-02-21 19:10:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 21 19:11:05.421: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-wpkrw,SelfLink:/api/v1/namespaces/e2e-tests-watch-wpkrw/configmaps/e2e-watch-test-configmap-a,UID:69cace5f-360c-11e9-bacd-42010a000102,ResourceVersion:17616,Generation:0,CreationTimestamp:2019-02-21 19:10:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Feb 21 19:11:15.440: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-wpkrw,SelfLink:/api/v1/namespaces/e2e-tests-watch-wpkrw/configmaps/e2e-watch-test-configmap-a,UID:69cace5f-360c-11e9-bacd-42010a000102,ResourceVersion:17633,Generation:0,CreationTimestamp:2019-02-21 19:10:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 21 19:11:15.440: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-wpkrw,SelfLink:/api/v1/namespaces/e2e-tests-watch-wpkrw/configmaps/e2e-watch-test-configmap-a,UID:69cace5f-360c-11e9-bacd-42010a000102,ResourceVersion:17633,Generation:0,CreationTimestamp:2019-02-21 19:10:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Feb 21 19:11:25.460: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-wpkrw,SelfLink:/api/v1/namespaces/e2e-tests-watch-wpkrw/configmaps/e2e-watch-test-configmap-a,UID:69cace5f-360c-11e9-bacd-42010a000102,ResourceVersion:17650,Generation:0,CreationTimestamp:2019-02-21 19:10:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 21 19:11:25.460: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-wpkrw,SelfLink:/api/v1/namespaces/e2e-tests-watch-wpkrw/configmaps/e2e-watch-test-configmap-a,UID:69cace5f-360c-11e9-bacd-42010a000102,ResourceVersion:17650,Generation:0,CreationTimestamp:2019-02-21 19:10:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Feb 21 19:11:35.477: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-wpkrw,SelfLink:/api/v1/namespaces/e2e-tests-watch-wpkrw/configmaps/e2e-watch-test-configmap-b,UID:81ae26bf-360c-11e9-bacd-42010a000102,ResourceVersion:17667,Generation:0,CreationTimestamp:2019-02-21 19:11:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 21 19:11:35.478: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-wpkrw,SelfLink:/api/v1/namespaces/e2e-tests-watch-wpkrw/configmaps/e2e-watch-test-configmap-b,UID:81ae26bf-360c-11e9-bacd-42010a000102,ResourceVersion:17667,Generation:0,CreationTimestamp:2019-02-21 19:11:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Feb 21 19:11:45.496: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-wpkrw,SelfLink:/api/v1/namespaces/e2e-tests-watch-wpkrw/configmaps/e2e-watch-test-configmap-b,UID:81ae26bf-360c-11e9-bacd-42010a000102,ResourceVersion:17684,Generation:0,CreationTimestamp:2019-02-21 19:11:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 21 19:11:45.496: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-wpkrw,SelfLink:/api/v1/namespaces/e2e-tests-watch-wpkrw/configmaps/e2e-watch-test-configmap-b,UID:81ae26bf-360c-11e9-bacd-42010a000102,ResourceVersion:17684,Generation:0,CreationTimestamp:2019-02-21 19:11:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:11:55.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-wpkrw" for this suite.
Feb 21 19:12:01.527: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:12:01.598: INFO: namespace: e2e-tests-watch-wpkrw, resource: bindings, ignored listing per whitelist
Feb 21 19:12:01.663: INFO: namespace e2e-tests-watch-wpkrw deletion completed in 6.154469154s

• [SLOW TEST:66.474 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:12:01.663: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-xd9kh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-tc9f
STEP: Creating a pod to test atomic-volume-subpath
Feb 21 19:12:01.881: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-tc9f" in namespace "e2e-tests-subpath-xd9kh" to be "success or failure"
Feb 21 19:12:01.886: INFO: Pod "pod-subpath-test-secret-tc9f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.689678ms
Feb 21 19:12:03.891: INFO: Pod "pod-subpath-test-secret-tc9f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010787234s
Feb 21 19:12:05.903: INFO: Pod "pod-subpath-test-secret-tc9f": Phase="Running", Reason="", readiness=false. Elapsed: 4.022644623s
Feb 21 19:12:07.908: INFO: Pod "pod-subpath-test-secret-tc9f": Phase="Running", Reason="", readiness=false. Elapsed: 6.027741373s
Feb 21 19:12:09.913: INFO: Pod "pod-subpath-test-secret-tc9f": Phase="Running", Reason="", readiness=false. Elapsed: 8.032226764s
Feb 21 19:12:11.918: INFO: Pod "pod-subpath-test-secret-tc9f": Phase="Running", Reason="", readiness=false. Elapsed: 10.037155272s
Feb 21 19:12:13.922: INFO: Pod "pod-subpath-test-secret-tc9f": Phase="Running", Reason="", readiness=false. Elapsed: 12.041826789s
Feb 21 19:12:15.935: INFO: Pod "pod-subpath-test-secret-tc9f": Phase="Running", Reason="", readiness=false. Elapsed: 14.05476013s
Feb 21 19:12:17.940: INFO: Pod "pod-subpath-test-secret-tc9f": Phase="Running", Reason="", readiness=false. Elapsed: 16.05967479s
Feb 21 19:12:19.945: INFO: Pod "pod-subpath-test-secret-tc9f": Phase="Running", Reason="", readiness=false. Elapsed: 18.064468341s
Feb 21 19:12:21.951: INFO: Pod "pod-subpath-test-secret-tc9f": Phase="Running", Reason="", readiness=false. Elapsed: 20.070277935s
Feb 21 19:12:23.956: INFO: Pod "pod-subpath-test-secret-tc9f": Phase="Running", Reason="", readiness=false. Elapsed: 22.075400789s
Feb 21 19:12:25.969: INFO: Pod "pod-subpath-test-secret-tc9f": Phase="Running", Reason="", readiness=false. Elapsed: 24.088259132s
Feb 21 19:12:27.978: INFO: Pod "pod-subpath-test-secret-tc9f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.096907263s
STEP: Saw pod success
Feb 21 19:12:27.978: INFO: Pod "pod-subpath-test-secret-tc9f" satisfied condition "success or failure"
Feb 21 19:12:27.981: INFO: Trying to get logs from node vm-96433648-4a4e-4d7e-4d24-8065d4ab25dc pod pod-subpath-test-secret-tc9f container test-container-subpath-secret-tc9f: <nil>
STEP: delete the pod
Feb 21 19:12:28.008: INFO: Waiting for pod pod-subpath-test-secret-tc9f to disappear
Feb 21 19:12:28.012: INFO: Pod pod-subpath-test-secret-tc9f no longer exists
STEP: Deleting pod pod-subpath-test-secret-tc9f
Feb 21 19:12:28.012: INFO: Deleting pod "pod-subpath-test-secret-tc9f" in namespace "e2e-tests-subpath-xd9kh"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:12:28.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-xd9kh" for this suite.
Feb 21 19:12:34.040: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:12:34.168: INFO: namespace: e2e-tests-subpath-xd9kh, resource: bindings, ignored listing per whitelist
Feb 21 19:12:34.175: INFO: namespace e2e-tests-subpath-xd9kh deletion completed in 6.154732396s

• [SLOW TEST:32.511 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:12:34.175: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-z7nxc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-z7nxc
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-z7nxc
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-z7nxc
Feb 21 19:12:34.395: INFO: Found 0 stateful pods, waiting for 1
Feb 21 19:12:44.408: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Feb 21 19:12:44.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 exec --namespace=e2e-tests-statefulset-z7nxc ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 21 19:12:44.591: INFO: stderr: ""
Feb 21 19:12:44.591: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 21 19:12:44.591: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 21 19:12:44.596: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 21 19:12:54.608: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 21 19:12:54.608: INFO: Waiting for statefulset status.replicas updated to 0
Feb 21 19:12:54.626: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999644s
Feb 21 19:12:55.631: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.995042454s
Feb 21 19:12:56.636: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.990026982s
Feb 21 19:12:57.641: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.985125095s
Feb 21 19:12:58.646: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.980432861s
Feb 21 19:12:59.651: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.974972119s
Feb 21 19:13:00.656: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.970149982s
Feb 21 19:13:01.661: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.965328023s
Feb 21 19:13:02.667: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.959901495s
Feb 21 19:13:03.672: INFO: Verifying statefulset ss doesn't scale past 1 for another 954.070062ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-z7nxc
Feb 21 19:13:04.685: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 exec --namespace=e2e-tests-statefulset-z7nxc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 21 19:13:04.853: INFO: stderr: ""
Feb 21 19:13:04.853: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 21 19:13:04.853: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 21 19:13:04.857: INFO: Found 1 stateful pods, waiting for 3
Feb 21 19:13:14.871: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 21 19:13:14.871: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 21 19:13:14.871: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Feb 21 19:13:14.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 exec --namespace=e2e-tests-statefulset-z7nxc ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 21 19:13:15.066: INFO: stderr: ""
Feb 21 19:13:15.066: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 21 19:13:15.066: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 21 19:13:15.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 exec --namespace=e2e-tests-statefulset-z7nxc ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 21 19:13:15.231: INFO: stderr: ""
Feb 21 19:13:15.231: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 21 19:13:15.231: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 21 19:13:15.231: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 exec --namespace=e2e-tests-statefulset-z7nxc ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 21 19:13:15.404: INFO: stderr: ""
Feb 21 19:13:15.404: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 21 19:13:15.404: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 21 19:13:15.404: INFO: Waiting for statefulset status.replicas updated to 0
Feb 21 19:13:15.408: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Feb 21 19:13:25.423: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 21 19:13:25.423: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 21 19:13:25.423: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 21 19:13:25.437: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999177s
Feb 21 19:13:26.442: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996039377s
Feb 21 19:13:27.447: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.990865818s
Feb 21 19:13:28.453: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.985491974s
Feb 21 19:13:29.458: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.980204551s
Feb 21 19:13:30.464: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.974512454s
Feb 21 19:13:31.470: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.968875721s
Feb 21 19:13:32.475: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.963246398s
Feb 21 19:13:33.481: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.957581728s
Feb 21 19:13:34.486: INFO: Verifying statefulset ss doesn't scale past 3 for another 952.206417ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-z7nxc
Feb 21 19:13:35.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 exec --namespace=e2e-tests-statefulset-z7nxc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 21 19:13:35.673: INFO: stderr: ""
Feb 21 19:13:35.673: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 21 19:13:35.673: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 21 19:13:35.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 exec --namespace=e2e-tests-statefulset-z7nxc ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 21 19:13:35.836: INFO: stderr: ""
Feb 21 19:13:35.836: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 21 19:13:35.836: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 21 19:13:35.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 exec --namespace=e2e-tests-statefulset-z7nxc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 21 19:13:36.039: INFO: stderr: ""
Feb 21 19:13:36.039: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 21 19:13:36.039: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 21 19:13:36.039: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 21 19:14:06.067: INFO: Deleting all statefulset in ns e2e-tests-statefulset-z7nxc
Feb 21 19:14:06.070: INFO: Scaling statefulset ss to 0
Feb 21 19:14:06.082: INFO: Waiting for statefulset status.replicas updated to 0
Feb 21 19:14:06.085: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:14:06.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-z7nxc" for this suite.
Feb 21 19:14:12.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:14:12.169: INFO: namespace: e2e-tests-statefulset-z7nxc, resource: bindings, ignored listing per whitelist
Feb 21 19:14:12.274: INFO: namespace e2e-tests-statefulset-z7nxc deletion completed in 6.166704688s

• [SLOW TEST:98.099 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:14:12.274: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-jxt9x
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 21 19:14:15.025: INFO: Successfully updated pod "annotationupdatedf42bc7a-360c-11e9-816d-1a333d676433"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:14:19.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jxt9x" for this suite.
Feb 21 19:14:41.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:14:41.167: INFO: namespace: e2e-tests-projected-jxt9x, resource: bindings, ignored listing per whitelist
Feb 21 19:14:41.218: INFO: namespace e2e-tests-projected-jxt9x deletion completed in 22.145377775s

• [SLOW TEST:28.944 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:14:41.218: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-fpc5v
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-f082761f-360c-11e9-816d-1a333d676433
STEP: Creating a pod to test consume secrets
Feb 21 19:14:41.431: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f08357b0-360c-11e9-816d-1a333d676433" in namespace "e2e-tests-projected-fpc5v" to be "success or failure"
Feb 21 19:14:41.439: INFO: Pod "pod-projected-secrets-f08357b0-360c-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 8.136871ms
Feb 21 19:14:43.444: INFO: Pod "pod-projected-secrets-f08357b0-360c-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013031625s
STEP: Saw pod success
Feb 21 19:14:43.444: INFO: Pod "pod-projected-secrets-f08357b0-360c-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 19:14:43.448: INFO: Trying to get logs from node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c pod pod-projected-secrets-f08357b0-360c-11e9-816d-1a333d676433 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 21 19:14:43.473: INFO: Waiting for pod pod-projected-secrets-f08357b0-360c-11e9-816d-1a333d676433 to disappear
Feb 21 19:14:43.477: INFO: Pod pod-projected-secrets-f08357b0-360c-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:14:43.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fpc5v" for this suite.
Feb 21 19:14:49.508: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:14:49.581: INFO: namespace: e2e-tests-projected-fpc5v, resource: bindings, ignored listing per whitelist
Feb 21 19:14:49.651: INFO: namespace e2e-tests-projected-fpc5v deletion completed in 6.170033571s

• [SLOW TEST:8.433 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:14:49.652: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-ghfz4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 21 19:14:49.848: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f58835ce-360c-11e9-816d-1a333d676433" in namespace "e2e-tests-downward-api-ghfz4" to be "success or failure"
Feb 21 19:14:49.851: INFO: Pod "downwardapi-volume-f58835ce-360c-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 3.804473ms
Feb 21 19:14:51.856: INFO: Pod "downwardapi-volume-f58835ce-360c-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00855685s
STEP: Saw pod success
Feb 21 19:14:51.856: INFO: Pod "downwardapi-volume-f58835ce-360c-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 19:14:51.860: INFO: Trying to get logs from node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c pod downwardapi-volume-f58835ce-360c-11e9-816d-1a333d676433 container client-container: <nil>
STEP: delete the pod
Feb 21 19:14:51.883: INFO: Waiting for pod downwardapi-volume-f58835ce-360c-11e9-816d-1a333d676433 to disappear
Feb 21 19:14:51.886: INFO: Pod downwardapi-volume-f58835ce-360c-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:14:51.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-ghfz4" for this suite.
Feb 21 19:14:57.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:14:57.999: INFO: namespace: e2e-tests-downward-api-ghfz4, resource: bindings, ignored listing per whitelist
Feb 21 19:14:58.067: INFO: namespace e2e-tests-downward-api-ghfz4 deletion completed in 6.17510958s

• [SLOW TEST:8.415 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:14:58.067: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-q5kmg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 21 19:15:02.831: INFO: Successfully updated pod "annotationupdatefa8f51ae-360c-11e9-816d-1a333d676433"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:15:04.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-q5kmg" for this suite.
Feb 21 19:15:26.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:15:26.919: INFO: namespace: e2e-tests-downward-api-q5kmg, resource: bindings, ignored listing per whitelist
Feb 21 19:15:27.041: INFO: namespace e2e-tests-downward-api-q5kmg deletion completed in 22.179821785s

• [SLOW TEST:28.974 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:15:27.041: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-5hbgt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Feb 21 19:15:27.290: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-5hbgt,SelfLink:/api/v1/namespaces/e2e-tests-watch-5hbgt/configmaps/e2e-watch-test-label-changed,UID:0bd4ca72-360d-11e9-bacd-42010a000102,ResourceVersion:18456,Generation:0,CreationTimestamp:2019-02-21 19:15:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 21 19:15:27.290: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-5hbgt,SelfLink:/api/v1/namespaces/e2e-tests-watch-5hbgt/configmaps/e2e-watch-test-label-changed,UID:0bd4ca72-360d-11e9-bacd-42010a000102,ResourceVersion:18457,Generation:0,CreationTimestamp:2019-02-21 19:15:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 21 19:15:27.290: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-5hbgt,SelfLink:/api/v1/namespaces/e2e-tests-watch-5hbgt/configmaps/e2e-watch-test-label-changed,UID:0bd4ca72-360d-11e9-bacd-42010a000102,ResourceVersion:18458,Generation:0,CreationTimestamp:2019-02-21 19:15:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Feb 21 19:15:37.346: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-5hbgt,SelfLink:/api/v1/namespaces/e2e-tests-watch-5hbgt/configmaps/e2e-watch-test-label-changed,UID:0bd4ca72-360d-11e9-bacd-42010a000102,ResourceVersion:18476,Generation:0,CreationTimestamp:2019-02-21 19:15:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 21 19:15:37.346: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-5hbgt,SelfLink:/api/v1/namespaces/e2e-tests-watch-5hbgt/configmaps/e2e-watch-test-label-changed,UID:0bd4ca72-360d-11e9-bacd-42010a000102,ResourceVersion:18477,Generation:0,CreationTimestamp:2019-02-21 19:15:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Feb 21 19:15:37.346: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-5hbgt,SelfLink:/api/v1/namespaces/e2e-tests-watch-5hbgt/configmaps/e2e-watch-test-label-changed,UID:0bd4ca72-360d-11e9-bacd-42010a000102,ResourceVersion:18478,Generation:0,CreationTimestamp:2019-02-21 19:15:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:15:37.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-5hbgt" for this suite.
Feb 21 19:15:43.372: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:15:43.502: INFO: namespace: e2e-tests-watch-5hbgt, resource: bindings, ignored listing per whitelist
Feb 21 19:15:43.506: INFO: namespace e2e-tests-watch-5hbgt deletion completed in 6.15409219s

• [SLOW TEST:16.465 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:15:43.506: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-cn6mw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:15:45.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-cn6mw" for this suite.
Feb 21 19:16:27.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:16:27.812: INFO: namespace: e2e-tests-kubelet-test-cn6mw, resource: bindings, ignored listing per whitelist
Feb 21 19:16:27.902: INFO: namespace e2e-tests-kubelet-test-cn6mw deletion completed in 42.156987353s

• [SLOW TEST:44.396 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:16:27.902: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-zxcsp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Feb 21 19:16:28.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 create -f - --namespace=e2e-tests-kubectl-zxcsp'
Feb 21 19:16:28.493: INFO: stderr: ""
Feb 21 19:16:28.493: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 21 19:16:28.493: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zxcsp'
Feb 21 19:16:28.573: INFO: stderr: ""
Feb 21 19:16:28.573: INFO: stdout: "update-demo-nautilus-6kjgd update-demo-nautilus-gc4w4 "
Feb 21 19:16:28.573: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods update-demo-nautilus-6kjgd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zxcsp'
Feb 21 19:16:28.647: INFO: stderr: ""
Feb 21 19:16:28.647: INFO: stdout: ""
Feb 21 19:16:28.647: INFO: update-demo-nautilus-6kjgd is created but not running
Feb 21 19:16:33.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zxcsp'
Feb 21 19:16:33.735: INFO: stderr: ""
Feb 21 19:16:33.736: INFO: stdout: "update-demo-nautilus-6kjgd update-demo-nautilus-gc4w4 "
Feb 21 19:16:33.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods update-demo-nautilus-6kjgd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zxcsp'
Feb 21 19:16:33.817: INFO: stderr: ""
Feb 21 19:16:33.817: INFO: stdout: "true"
Feb 21 19:16:33.817: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods update-demo-nautilus-6kjgd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zxcsp'
Feb 21 19:16:33.897: INFO: stderr: ""
Feb 21 19:16:33.897: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 21 19:16:33.897: INFO: validating pod update-demo-nautilus-6kjgd
Feb 21 19:16:33.904: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 21 19:16:33.904: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 21 19:16:33.904: INFO: update-demo-nautilus-6kjgd is verified up and running
Feb 21 19:16:33.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods update-demo-nautilus-gc4w4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zxcsp'
Feb 21 19:16:33.983: INFO: stderr: ""
Feb 21 19:16:33.983: INFO: stdout: "true"
Feb 21 19:16:33.983: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods update-demo-nautilus-gc4w4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zxcsp'
Feb 21 19:16:34.060: INFO: stderr: ""
Feb 21 19:16:34.060: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 21 19:16:34.060: INFO: validating pod update-demo-nautilus-gc4w4
Feb 21 19:16:34.067: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 21 19:16:34.067: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 21 19:16:34.067: INFO: update-demo-nautilus-gc4w4 is verified up and running
STEP: using delete to clean up resources
Feb 21 19:16:34.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-zxcsp'
Feb 21 19:16:34.145: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 21 19:16:34.145: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 21 19:16:34.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-zxcsp'
Feb 21 19:16:34.222: INFO: stderr: "No resources found.\n"
Feb 21 19:16:34.222: INFO: stdout: ""
Feb 21 19:16:34.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods -l name=update-demo --namespace=e2e-tests-kubectl-zxcsp -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 21 19:16:34.300: INFO: stderr: ""
Feb 21 19:16:34.300: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:16:34.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zxcsp" for this suite.
Feb 21 19:16:40.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:16:40.364: INFO: namespace: e2e-tests-kubectl-zxcsp, resource: bindings, ignored listing per whitelist
Feb 21 19:16:40.472: INFO: namespace e2e-tests-kubectl-zxcsp deletion completed in 6.16700283s

• [SLOW TEST:12.570 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:16:40.472: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-7lpsz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 21 19:16:40.672: INFO: Waiting up to 5m0s for pod "pod-3796bf84-360d-11e9-816d-1a333d676433" in namespace "e2e-tests-emptydir-7lpsz" to be "success or failure"
Feb 21 19:16:40.681: INFO: Pod "pod-3796bf84-360d-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 9.611296ms
Feb 21 19:16:42.686: INFO: Pod "pod-3796bf84-360d-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014278435s
STEP: Saw pod success
Feb 21 19:16:42.686: INFO: Pod "pod-3796bf84-360d-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 19:16:42.689: INFO: Trying to get logs from node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c pod pod-3796bf84-360d-11e9-816d-1a333d676433 container test-container: <nil>
STEP: delete the pod
Feb 21 19:16:42.714: INFO: Waiting for pod pod-3796bf84-360d-11e9-816d-1a333d676433 to disappear
Feb 21 19:16:42.718: INFO: Pod pod-3796bf84-360d-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:16:42.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-7lpsz" for this suite.
Feb 21 19:16:48.742: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:16:48.805: INFO: namespace: e2e-tests-emptydir-7lpsz, resource: bindings, ignored listing per whitelist
Feb 21 19:16:48.876: INFO: namespace e2e-tests-emptydir-7lpsz deletion completed in 6.153239185s

• [SLOW TEST:8.404 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:16:48.876: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-2tqrs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 21 19:16:49.073: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3c98a1c3-360d-11e9-816d-1a333d676433" in namespace "e2e-tests-projected-2tqrs" to be "success or failure"
Feb 21 19:16:49.080: INFO: Pod "downwardapi-volume-3c98a1c3-360d-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 6.961514ms
Feb 21 19:16:51.085: INFO: Pod "downwardapi-volume-3c98a1c3-360d-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011680161s
STEP: Saw pod success
Feb 21 19:16:51.085: INFO: Pod "downwardapi-volume-3c98a1c3-360d-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 19:16:51.088: INFO: Trying to get logs from node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c pod downwardapi-volume-3c98a1c3-360d-11e9-816d-1a333d676433 container client-container: <nil>
STEP: delete the pod
Feb 21 19:16:51.114: INFO: Waiting for pod downwardapi-volume-3c98a1c3-360d-11e9-816d-1a333d676433 to disappear
Feb 21 19:16:51.117: INFO: Pod downwardapi-volume-3c98a1c3-360d-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:16:51.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2tqrs" for this suite.
Feb 21 19:16:57.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:16:57.196: INFO: namespace: e2e-tests-projected-2tqrs, resource: bindings, ignored listing per whitelist
Feb 21 19:16:57.275: INFO: namespace e2e-tests-projected-2tqrs deletion completed in 6.152090475s

• [SLOW TEST:8.399 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:16:57.275: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-g8sgv
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-419b63cd-360d-11e9-816d-1a333d676433
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:17:01.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-g8sgv" for this suite.
Feb 21 19:17:23.551: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:17:23.569: INFO: namespace: e2e-tests-configmap-g8sgv, resource: bindings, ignored listing per whitelist
Feb 21 19:17:23.691: INFO: namespace e2e-tests-configmap-g8sgv deletion completed in 22.159725897s

• [SLOW TEST:26.416 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:17:23.691: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-bp8gw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-bp8gw
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 21 19:17:23.882: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 21 19:17:46.004: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.200.34.37 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-bp8gw PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 21 19:17:46.004: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
Feb 21 19:17:47.089: INFO: Found all expected endpoints: [netserver-0]
Feb 21 19:17:47.093: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.200.20.110 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-bp8gw PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 21 19:17:47.093: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
Feb 21 19:17:48.183: INFO: Found all expected endpoints: [netserver-1]
Feb 21 19:17:48.194: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.200.10.100 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-bp8gw PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 21 19:17:48.194: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
Feb 21 19:17:49.282: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:17:49.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-bp8gw" for this suite.
Feb 21 19:18:11.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:18:11.329: INFO: namespace: e2e-tests-pod-network-test-bp8gw, resource: bindings, ignored listing per whitelist
Feb 21 19:18:11.458: INFO: namespace e2e-tests-pod-network-test-bp8gw deletion completed in 22.170636771s

• [SLOW TEST:47.767 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:18:11.459: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-8gdkq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Feb 21 19:18:11.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 create -f - --namespace=e2e-tests-kubectl-8gdkq'
Feb 21 19:18:11.829: INFO: stderr: ""
Feb 21 19:18:11.830: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 21 19:18:11.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-8gdkq'
Feb 21 19:18:11.906: INFO: stderr: ""
Feb 21 19:18:11.906: INFO: stdout: "update-demo-nautilus-n4m89 update-demo-nautilus-znrv4 "
Feb 21 19:18:11.906: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods update-demo-nautilus-n4m89 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8gdkq'
Feb 21 19:18:11.985: INFO: stderr: ""
Feb 21 19:18:11.985: INFO: stdout: ""
Feb 21 19:18:11.985: INFO: update-demo-nautilus-n4m89 is created but not running
Feb 21 19:18:16.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-8gdkq'
Feb 21 19:18:17.061: INFO: stderr: ""
Feb 21 19:18:17.061: INFO: stdout: "update-demo-nautilus-n4m89 update-demo-nautilus-znrv4 "
Feb 21 19:18:17.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods update-demo-nautilus-n4m89 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8gdkq'
Feb 21 19:18:17.136: INFO: stderr: ""
Feb 21 19:18:17.136: INFO: stdout: "true"
Feb 21 19:18:17.136: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods update-demo-nautilus-n4m89 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8gdkq'
Feb 21 19:18:17.210: INFO: stderr: ""
Feb 21 19:18:17.210: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 21 19:18:17.210: INFO: validating pod update-demo-nautilus-n4m89
Feb 21 19:18:17.218: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 21 19:18:17.218: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 21 19:18:17.218: INFO: update-demo-nautilus-n4m89 is verified up and running
Feb 21 19:18:17.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods update-demo-nautilus-znrv4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8gdkq'
Feb 21 19:18:17.288: INFO: stderr: ""
Feb 21 19:18:17.288: INFO: stdout: "true"
Feb 21 19:18:17.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods update-demo-nautilus-znrv4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8gdkq'
Feb 21 19:18:17.360: INFO: stderr: ""
Feb 21 19:18:17.360: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 21 19:18:17.360: INFO: validating pod update-demo-nautilus-znrv4
Feb 21 19:18:17.367: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 21 19:18:17.367: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 21 19:18:17.367: INFO: update-demo-nautilus-znrv4 is verified up and running
STEP: scaling down the replication controller
Feb 21 19:18:17.369: INFO: scanned /root for discovery docs: <nil>
Feb 21 19:18:17.369: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-8gdkq'
Feb 21 19:18:18.472: INFO: stderr: ""
Feb 21 19:18:18.472: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 21 19:18:18.472: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-8gdkq'
Feb 21 19:18:18.551: INFO: stderr: ""
Feb 21 19:18:18.551: INFO: stdout: "update-demo-nautilus-n4m89 update-demo-nautilus-znrv4 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 21 19:18:23.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-8gdkq'
Feb 21 19:18:23.641: INFO: stderr: ""
Feb 21 19:18:23.641: INFO: stdout: "update-demo-nautilus-n4m89 update-demo-nautilus-znrv4 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 21 19:18:28.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-8gdkq'
Feb 21 19:18:28.722: INFO: stderr: ""
Feb 21 19:18:28.722: INFO: stdout: "update-demo-nautilus-n4m89 update-demo-nautilus-znrv4 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 21 19:18:33.722: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-8gdkq'
Feb 21 19:18:33.808: INFO: stderr: ""
Feb 21 19:18:33.808: INFO: stdout: "update-demo-nautilus-znrv4 "
Feb 21 19:18:33.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods update-demo-nautilus-znrv4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8gdkq'
Feb 21 19:18:33.886: INFO: stderr: ""
Feb 21 19:18:33.886: INFO: stdout: "true"
Feb 21 19:18:33.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods update-demo-nautilus-znrv4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8gdkq'
Feb 21 19:18:33.962: INFO: stderr: ""
Feb 21 19:18:33.962: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 21 19:18:33.962: INFO: validating pod update-demo-nautilus-znrv4
Feb 21 19:18:33.969: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 21 19:18:33.969: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 21 19:18:33.969: INFO: update-demo-nautilus-znrv4 is verified up and running
STEP: scaling up the replication controller
Feb 21 19:18:33.970: INFO: scanned /root for discovery docs: <nil>
Feb 21 19:18:33.970: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-8gdkq'
Feb 21 19:18:35.086: INFO: stderr: ""
Feb 21 19:18:35.086: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 21 19:18:35.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-8gdkq'
Feb 21 19:18:35.162: INFO: stderr: ""
Feb 21 19:18:35.162: INFO: stdout: "update-demo-nautilus-xtbqc update-demo-nautilus-znrv4 "
Feb 21 19:18:35.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods update-demo-nautilus-xtbqc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8gdkq'
Feb 21 19:18:35.244: INFO: stderr: ""
Feb 21 19:18:35.244: INFO: stdout: ""
Feb 21 19:18:35.244: INFO: update-demo-nautilus-xtbqc is created but not running
Feb 21 19:18:40.244: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-8gdkq'
Feb 21 19:18:40.328: INFO: stderr: ""
Feb 21 19:18:40.328: INFO: stdout: "update-demo-nautilus-xtbqc update-demo-nautilus-znrv4 "
Feb 21 19:18:40.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods update-demo-nautilus-xtbqc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8gdkq'
Feb 21 19:18:40.405: INFO: stderr: ""
Feb 21 19:18:40.405: INFO: stdout: "true"
Feb 21 19:18:40.405: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods update-demo-nautilus-xtbqc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8gdkq'
Feb 21 19:18:40.485: INFO: stderr: ""
Feb 21 19:18:40.485: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 21 19:18:40.485: INFO: validating pod update-demo-nautilus-xtbqc
Feb 21 19:18:40.493: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 21 19:18:40.493: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 21 19:18:40.493: INFO: update-demo-nautilus-xtbqc is verified up and running
Feb 21 19:18:40.493: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods update-demo-nautilus-znrv4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8gdkq'
Feb 21 19:18:40.569: INFO: stderr: ""
Feb 21 19:18:40.569: INFO: stdout: "true"
Feb 21 19:18:40.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods update-demo-nautilus-znrv4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8gdkq'
Feb 21 19:18:40.644: INFO: stderr: ""
Feb 21 19:18:40.644: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 21 19:18:40.644: INFO: validating pod update-demo-nautilus-znrv4
Feb 21 19:18:40.651: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 21 19:18:40.651: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 21 19:18:40.651: INFO: update-demo-nautilus-znrv4 is verified up and running
STEP: using delete to clean up resources
Feb 21 19:18:40.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-8gdkq'
Feb 21 19:18:40.732: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 21 19:18:40.732: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 21 19:18:40.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-8gdkq'
Feb 21 19:18:40.817: INFO: stderr: "No resources found.\n"
Feb 21 19:18:40.817: INFO: stdout: ""
Feb 21 19:18:40.817: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pods -l name=update-demo --namespace=e2e-tests-kubectl-8gdkq -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 21 19:18:40.900: INFO: stderr: ""
Feb 21 19:18:40.900: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:18:40.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8gdkq" for this suite.
Feb 21 19:18:46.925: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:18:46.950: INFO: namespace: e2e-tests-kubectl-8gdkq, resource: bindings, ignored listing per whitelist
Feb 21 19:18:47.064: INFO: namespace e2e-tests-kubectl-8gdkq deletion completed in 6.158257961s

• [SLOW TEST:35.605 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:18:47.064: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-9pptf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0221 19:19:27.318937      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 21 19:19:27.318: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:19:27.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-9pptf" for this suite.
Feb 21 19:19:33.342: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:19:33.380: INFO: namespace: e2e-tests-gc-9pptf, resource: bindings, ignored listing per whitelist
Feb 21 19:19:33.490: INFO: namespace e2e-tests-gc-9pptf deletion completed in 6.167043933s

• [SLOW TEST:46.426 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:19:33.491: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-wrapper-8zblw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Feb 21 19:19:34.056: INFO: Pod name wrapped-volume-race-9eed5067-360d-11e9-816d-1a333d676433: Found 0 pods out of 5
Feb 21 19:19:39.072: INFO: Pod name wrapped-volume-race-9eed5067-360d-11e9-816d-1a333d676433: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-9eed5067-360d-11e9-816d-1a333d676433 in namespace e2e-tests-emptydir-wrapper-8zblw, will wait for the garbage collector to delete the pods
Feb 21 19:19:49.184: INFO: Deleting ReplicationController wrapped-volume-race-9eed5067-360d-11e9-816d-1a333d676433 took: 21.263004ms
Feb 21 19:19:49.285: INFO: Terminating ReplicationController wrapped-volume-race-9eed5067-360d-11e9-816d-1a333d676433 pods took: 100.376227ms
STEP: Creating RC which spawns configmap-volume pods
Feb 21 19:20:36.520: INFO: Pod name wrapped-volume-race-c426b539-360d-11e9-816d-1a333d676433: Found 0 pods out of 5
Feb 21 19:20:41.531: INFO: Pod name wrapped-volume-race-c426b539-360d-11e9-816d-1a333d676433: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-c426b539-360d-11e9-816d-1a333d676433 in namespace e2e-tests-emptydir-wrapper-8zblw, will wait for the garbage collector to delete the pods
Feb 21 19:20:53.635: INFO: Deleting ReplicationController wrapped-volume-race-c426b539-360d-11e9-816d-1a333d676433 took: 14.162863ms
Feb 21 19:20:53.736: INFO: Terminating ReplicationController wrapped-volume-race-c426b539-360d-11e9-816d-1a333d676433 pods took: 100.519874ms
STEP: Creating RC which spawns configmap-volume pods
Feb 21 19:21:35.466: INFO: Pod name wrapped-volume-race-e749e627-360d-11e9-816d-1a333d676433: Found 0 pods out of 5
Feb 21 19:21:40.475: INFO: Pod name wrapped-volume-race-e749e627-360d-11e9-816d-1a333d676433: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-e749e627-360d-11e9-816d-1a333d676433 in namespace e2e-tests-emptydir-wrapper-8zblw, will wait for the garbage collector to delete the pods
Feb 21 19:21:50.569: INFO: Deleting ReplicationController wrapped-volume-race-e749e627-360d-11e9-816d-1a333d676433 took: 11.273996ms
Feb 21 19:21:50.670: INFO: Terminating ReplicationController wrapped-volume-race-e749e627-360d-11e9-816d-1a333d676433 pods took: 100.416209ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:22:36.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-8zblw" for this suite.
Feb 21 19:22:44.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:22:44.154: INFO: namespace: e2e-tests-emptydir-wrapper-8zblw, resource: bindings, ignored listing per whitelist
Feb 21 19:22:44.192: INFO: namespace e2e-tests-emptydir-wrapper-8zblw deletion completed in 8.154260653s

• [SLOW TEST:190.701 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:22:44.192: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-6qmvr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-6qmvr
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 21 19:22:44.387: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 21 19:23:08.523: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.20.132:8080/dial?request=hostName&protocol=http&host=10.200.10.107&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-6qmvr PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 21 19:23:08.523: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
Feb 21 19:23:08.628: INFO: Waiting for endpoints: map[]
Feb 21 19:23:08.632: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.20.132:8080/dial?request=hostName&protocol=http&host=10.200.34.41&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-6qmvr PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 21 19:23:08.632: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
Feb 21 19:23:08.735: INFO: Waiting for endpoints: map[]
Feb 21 19:23:08.739: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.20.132:8080/dial?request=hostName&protocol=http&host=10.200.20.131&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-6qmvr PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 21 19:23:08.739: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
Feb 21 19:23:08.835: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:23:08.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-6qmvr" for this suite.
Feb 21 19:23:30.869: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:23:30.893: INFO: namespace: e2e-tests-pod-network-test-6qmvr, resource: bindings, ignored listing per whitelist
Feb 21 19:23:31.001: INFO: namespace e2e-tests-pod-network-test-6qmvr deletion completed in 22.159086403s

• [SLOW TEST:46.809 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:23:31.001: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-q6rgq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 21 19:23:31.233: INFO: Number of nodes with available pods: 0
Feb 21 19:23:31.233: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 19:23:32.247: INFO: Number of nodes with available pods: 0
Feb 21 19:23:32.247: INFO: Node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c is running more than one daemon pod
Feb 21 19:23:33.243: INFO: Number of nodes with available pods: 3
Feb 21 19:23:33.243: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Feb 21 19:23:33.273: INFO: Number of nodes with available pods: 2
Feb 21 19:23:33.273: INFO: Node vm-96433648-4a4e-4d7e-4d24-8065d4ab25dc is running more than one daemon pod
Feb 21 19:23:34.284: INFO: Number of nodes with available pods: 2
Feb 21 19:23:34.284: INFO: Node vm-96433648-4a4e-4d7e-4d24-8065d4ab25dc is running more than one daemon pod
Feb 21 19:23:35.284: INFO: Number of nodes with available pods: 3
Feb 21 19:23:35.284: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-q6rgq, will wait for the garbage collector to delete the pods
Feb 21 19:23:35.353: INFO: Deleting DaemonSet.extensions daemon-set took: 8.80792ms
Feb 21 19:23:35.453: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.252816ms
Feb 21 19:24:15.465: INFO: Number of nodes with available pods: 0
Feb 21 19:24:15.465: INFO: Number of running nodes: 0, number of available pods: 0
Feb 21 19:24:15.469: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-q6rgq/daemonsets","resourceVersion":"20864"},"items":null}

Feb 21 19:24:15.473: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-q6rgq/pods","resourceVersion":"20864"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:24:15.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-q6rgq" for this suite.
Feb 21 19:24:21.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:24:21.639: INFO: namespace: e2e-tests-daemonsets-q6rgq, resource: bindings, ignored listing per whitelist
Feb 21 19:24:21.642: INFO: namespace e2e-tests-daemonsets-q6rgq deletion completed in 6.148243047s

• [SLOW TEST:50.641 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:24:21.642: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-xqbq5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-rvqj
STEP: Creating a pod to test atomic-volume-subpath
Feb 21 19:24:21.855: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-rvqj" in namespace "e2e-tests-subpath-xqbq5" to be "success or failure"
Feb 21 19:24:21.860: INFO: Pod "pod-subpath-test-downwardapi-rvqj": Phase="Pending", Reason="", readiness=false. Elapsed: 4.523164ms
Feb 21 19:24:23.865: INFO: Pod "pod-subpath-test-downwardapi-rvqj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009668818s
Feb 21 19:24:25.877: INFO: Pod "pod-subpath-test-downwardapi-rvqj": Phase="Running", Reason="", readiness=false. Elapsed: 4.021443183s
Feb 21 19:24:27.881: INFO: Pod "pod-subpath-test-downwardapi-rvqj": Phase="Running", Reason="", readiness=false. Elapsed: 6.025968379s
Feb 21 19:24:29.886: INFO: Pod "pod-subpath-test-downwardapi-rvqj": Phase="Running", Reason="", readiness=false. Elapsed: 8.030488869s
Feb 21 19:24:31.891: INFO: Pod "pod-subpath-test-downwardapi-rvqj": Phase="Running", Reason="", readiness=false. Elapsed: 10.035735323s
Feb 21 19:24:33.896: INFO: Pod "pod-subpath-test-downwardapi-rvqj": Phase="Running", Reason="", readiness=false. Elapsed: 12.04113074s
Feb 21 19:24:35.908: INFO: Pod "pod-subpath-test-downwardapi-rvqj": Phase="Running", Reason="", readiness=false. Elapsed: 14.052638059s
Feb 21 19:24:37.913: INFO: Pod "pod-subpath-test-downwardapi-rvqj": Phase="Running", Reason="", readiness=false. Elapsed: 16.057447832s
Feb 21 19:24:39.918: INFO: Pod "pod-subpath-test-downwardapi-rvqj": Phase="Running", Reason="", readiness=false. Elapsed: 18.062486242s
Feb 21 19:24:41.922: INFO: Pod "pod-subpath-test-downwardapi-rvqj": Phase="Running", Reason="", readiness=false. Elapsed: 20.067000185s
Feb 21 19:24:43.927: INFO: Pod "pod-subpath-test-downwardapi-rvqj": Phase="Running", Reason="", readiness=false. Elapsed: 22.071639947s
Feb 21 19:24:45.939: INFO: Pod "pod-subpath-test-downwardapi-rvqj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.083723944s
STEP: Saw pod success
Feb 21 19:24:45.939: INFO: Pod "pod-subpath-test-downwardapi-rvqj" satisfied condition "success or failure"
Feb 21 19:24:45.943: INFO: Trying to get logs from node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c pod pod-subpath-test-downwardapi-rvqj container test-container-subpath-downwardapi-rvqj: <nil>
STEP: delete the pod
Feb 21 19:24:45.970: INFO: Waiting for pod pod-subpath-test-downwardapi-rvqj to disappear
Feb 21 19:24:45.973: INFO: Pod pod-subpath-test-downwardapi-rvqj no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-rvqj
Feb 21 19:24:45.973: INFO: Deleting pod "pod-subpath-test-downwardapi-rvqj" in namespace "e2e-tests-subpath-xqbq5"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:24:45.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-xqbq5" for this suite.
Feb 21 19:24:51.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:24:52.055: INFO: namespace: e2e-tests-subpath-xqbq5, resource: bindings, ignored listing per whitelist
Feb 21 19:24:52.130: INFO: namespace e2e-tests-subpath-xqbq5 deletion completed in 6.149573299s

• [SLOW TEST:30.488 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:24:52.130: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-qcz4w
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 21 19:24:52.330: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5ca3dd13-360e-11e9-816d-1a333d676433" in namespace "e2e-tests-downward-api-qcz4w" to be "success or failure"
Feb 21 19:24:52.335: INFO: Pod "downwardapi-volume-5ca3dd13-360e-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 4.969238ms
Feb 21 19:24:54.340: INFO: Pod "downwardapi-volume-5ca3dd13-360e-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009650246s
STEP: Saw pod success
Feb 21 19:24:54.340: INFO: Pod "downwardapi-volume-5ca3dd13-360e-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 19:24:54.344: INFO: Trying to get logs from node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c pod downwardapi-volume-5ca3dd13-360e-11e9-816d-1a333d676433 container client-container: <nil>
STEP: delete the pod
Feb 21 19:24:54.368: INFO: Waiting for pod downwardapi-volume-5ca3dd13-360e-11e9-816d-1a333d676433 to disappear
Feb 21 19:24:54.372: INFO: Pod downwardapi-volume-5ca3dd13-360e-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:24:54.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-qcz4w" for this suite.
Feb 21 19:25:00.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:25:00.500: INFO: namespace: e2e-tests-downward-api-qcz4w, resource: bindings, ignored listing per whitelist
Feb 21 19:25:00.531: INFO: namespace e2e-tests-downward-api-qcz4w deletion completed in 6.15404598s

• [SLOW TEST:8.401 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:25:00.531: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-54s56
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 21 19:25:08.783: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 21 19:25:08.787: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 21 19:25:10.787: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 21 19:25:10.792: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 21 19:25:12.787: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 21 19:25:12.792: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 21 19:25:14.787: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 21 19:25:14.793: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 21 19:25:16.787: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 21 19:25:16.799: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 21 19:25:18.787: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 21 19:25:18.792: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 21 19:25:20.787: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 21 19:25:20.793: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 21 19:25:22.787: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 21 19:25:22.792: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 21 19:25:24.787: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 21 19:25:24.793: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 21 19:25:26.787: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 21 19:25:26.792: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 21 19:25:28.787: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 21 19:25:28.800: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 21 19:25:30.787: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 21 19:25:30.792: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 21 19:25:32.787: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 21 19:25:32.792: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 21 19:25:34.787: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 21 19:25:34.792: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 21 19:25:36.787: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 21 19:25:36.792: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:25:36.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-54s56" for this suite.
Feb 21 19:25:58.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:25:58.892: INFO: namespace: e2e-tests-container-lifecycle-hook-54s56, resource: bindings, ignored listing per whitelist
Feb 21 19:25:58.957: INFO: namespace e2e-tests-container-lifecycle-hook-54s56 deletion completed in 22.160432292s

• [SLOW TEST:58.427 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:25:58.958: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-8t8pz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 21 19:25:59.160: INFO: Waiting up to 5m0s for pod "downward-api-847934fc-360e-11e9-816d-1a333d676433" in namespace "e2e-tests-downward-api-8t8pz" to be "success or failure"
Feb 21 19:25:59.167: INFO: Pod "downward-api-847934fc-360e-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 6.234588ms
Feb 21 19:26:01.179: INFO: Pod "downward-api-847934fc-360e-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018957723s
STEP: Saw pod success
Feb 21 19:26:01.180: INFO: Pod "downward-api-847934fc-360e-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 19:26:01.183: INFO: Trying to get logs from node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c pod downward-api-847934fc-360e-11e9-816d-1a333d676433 container dapi-container: <nil>
STEP: delete the pod
Feb 21 19:26:01.208: INFO: Waiting for pod downward-api-847934fc-360e-11e9-816d-1a333d676433 to disappear
Feb 21 19:26:01.211: INFO: Pod downward-api-847934fc-360e-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:26:01.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-8t8pz" for this suite.
Feb 21 19:26:07.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:26:07.286: INFO: namespace: e2e-tests-downward-api-8t8pz, resource: bindings, ignored listing per whitelist
Feb 21 19:26:07.377: INFO: namespace e2e-tests-downward-api-8t8pz deletion completed in 6.161282508s

• [SLOW TEST:8.419 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:26:07.377: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-8nfk5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-897dcd41-360e-11e9-816d-1a333d676433
STEP: Creating a pod to test consume secrets
Feb 21 19:26:07.587: INFO: Waiting up to 5m0s for pod "pod-secrets-897f2279-360e-11e9-816d-1a333d676433" in namespace "e2e-tests-secrets-8nfk5" to be "success or failure"
Feb 21 19:26:07.593: INFO: Pod "pod-secrets-897f2279-360e-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 6.195224ms
Feb 21 19:26:09.598: INFO: Pod "pod-secrets-897f2279-360e-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011100399s
STEP: Saw pod success
Feb 21 19:26:09.598: INFO: Pod "pod-secrets-897f2279-360e-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 19:26:09.602: INFO: Trying to get logs from node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c pod pod-secrets-897f2279-360e-11e9-816d-1a333d676433 container secret-volume-test: <nil>
STEP: delete the pod
Feb 21 19:26:09.624: INFO: Waiting for pod pod-secrets-897f2279-360e-11e9-816d-1a333d676433 to disappear
Feb 21 19:26:09.629: INFO: Pod pod-secrets-897f2279-360e-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:26:09.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-8nfk5" for this suite.
Feb 21 19:26:15.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:26:15.698: INFO: namespace: e2e-tests-secrets-8nfk5, resource: bindings, ignored listing per whitelist
Feb 21 19:26:15.788: INFO: namespace e2e-tests-secrets-8nfk5 deletion completed in 6.154907999s

• [SLOW TEST:8.411 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:26:15.789: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-m2749
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Feb 21 19:26:15.993: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-m2749,SelfLink:/api/v1/namespaces/e2e-tests-watch-m2749/configmaps/e2e-watch-test-watch-closed,UID:8e8107d4-360e-11e9-bacd-42010a000102,ResourceVersion:21269,Generation:0,CreationTimestamp:2019-02-21 19:26:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 21 19:26:15.993: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-m2749,SelfLink:/api/v1/namespaces/e2e-tests-watch-m2749/configmaps/e2e-watch-test-watch-closed,UID:8e8107d4-360e-11e9-bacd-42010a000102,ResourceVersion:21270,Generation:0,CreationTimestamp:2019-02-21 19:26:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Feb 21 19:26:16.018: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-m2749,SelfLink:/api/v1/namespaces/e2e-tests-watch-m2749/configmaps/e2e-watch-test-watch-closed,UID:8e8107d4-360e-11e9-bacd-42010a000102,ResourceVersion:21271,Generation:0,CreationTimestamp:2019-02-21 19:26:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 21 19:26:16.018: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-m2749,SelfLink:/api/v1/namespaces/e2e-tests-watch-m2749/configmaps/e2e-watch-test-watch-closed,UID:8e8107d4-360e-11e9-bacd-42010a000102,ResourceVersion:21272,Generation:0,CreationTimestamp:2019-02-21 19:26:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:26:16.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-m2749" for this suite.
Feb 21 19:26:22.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:26:22.100: INFO: namespace: e2e-tests-watch-m2749, resource: bindings, ignored listing per whitelist
Feb 21 19:26:22.179: INFO: namespace e2e-tests-watch-m2749 deletion completed in 6.156007222s

• [SLOW TEST:6.390 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:26:22.179: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-cvk9p
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 21 19:26:22.364: INFO: Creating ReplicaSet my-hostname-basic-924faa7d-360e-11e9-816d-1a333d676433
Feb 21 19:26:22.376: INFO: Pod name my-hostname-basic-924faa7d-360e-11e9-816d-1a333d676433: Found 0 pods out of 1
Feb 21 19:26:27.381: INFO: Pod name my-hostname-basic-924faa7d-360e-11e9-816d-1a333d676433: Found 1 pods out of 1
Feb 21 19:26:27.381: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-924faa7d-360e-11e9-816d-1a333d676433" is running
Feb 21 19:26:27.385: INFO: Pod "my-hostname-basic-924faa7d-360e-11e9-816d-1a333d676433-g6nzb" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-21 19:26:22 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-21 19:26:24 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-21 19:26:24 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-21 19:26:22 +0000 UTC Reason: Message:}])
Feb 21 19:26:27.385: INFO: Trying to dial the pod
Feb 21 19:26:32.408: INFO: Controller my-hostname-basic-924faa7d-360e-11e9-816d-1a333d676433: Got expected result from replica 1 [my-hostname-basic-924faa7d-360e-11e9-816d-1a333d676433-g6nzb]: "my-hostname-basic-924faa7d-360e-11e9-816d-1a333d676433-g6nzb", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:26:32.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-cvk9p" for this suite.
Feb 21 19:26:38.431: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:26:38.475: INFO: namespace: e2e-tests-replicaset-cvk9p, resource: bindings, ignored listing per whitelist
Feb 21 19:26:38.559: INFO: namespace e2e-tests-replicaset-cvk9p deletion completed in 6.145648214s

• [SLOW TEST:16.380 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:26:38.559: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-bzslz
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Feb 21 19:26:38.752: INFO: Waiting up to 5m0s for pod "pod-9c12e56f-360e-11e9-816d-1a333d676433" in namespace "e2e-tests-emptydir-bzslz" to be "success or failure"
Feb 21 19:26:38.760: INFO: Pod "pod-9c12e56f-360e-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 7.284777ms
Feb 21 19:26:40.764: INFO: Pod "pod-9c12e56f-360e-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011601528s
STEP: Saw pod success
Feb 21 19:26:40.764: INFO: Pod "pod-9c12e56f-360e-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 19:26:40.768: INFO: Trying to get logs from node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c pod pod-9c12e56f-360e-11e9-816d-1a333d676433 container test-container: <nil>
STEP: delete the pod
Feb 21 19:26:40.791: INFO: Waiting for pod pod-9c12e56f-360e-11e9-816d-1a333d676433 to disappear
Feb 21 19:26:40.794: INFO: Pod pod-9c12e56f-360e-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:26:40.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-bzslz" for this suite.
Feb 21 19:26:46.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:26:46.889: INFO: namespace: e2e-tests-emptydir-bzslz, resource: bindings, ignored listing per whitelist
Feb 21 19:26:46.938: INFO: namespace e2e-tests-emptydir-bzslz deletion completed in 6.138841186s

• [SLOW TEST:8.379 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:26:46.938: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-prestop-7grwd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-7grwd
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-7grwd
STEP: Deleting pre-stop pod
Feb 21 19:26:58.180: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:26:58.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-7grwd" for this suite.
Feb 21 19:27:36.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:27:36.244: INFO: namespace: e2e-tests-prestop-7grwd, resource: bindings, ignored listing per whitelist
Feb 21 19:27:36.342: INFO: namespace e2e-tests-prestop-7grwd deletion completed in 38.147745422s

• [SLOW TEST:49.404 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:27:36.343: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-8sfzv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Feb 21 19:27:36.545: INFO: Waiting up to 5m0s for pod "var-expansion-be84b54d-360e-11e9-816d-1a333d676433" in namespace "e2e-tests-var-expansion-8sfzv" to be "success or failure"
Feb 21 19:27:36.549: INFO: Pod "var-expansion-be84b54d-360e-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 3.822164ms
Feb 21 19:27:38.561: INFO: Pod "var-expansion-be84b54d-360e-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015858608s
STEP: Saw pod success
Feb 21 19:27:38.561: INFO: Pod "var-expansion-be84b54d-360e-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 19:27:38.565: INFO: Trying to get logs from node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c pod var-expansion-be84b54d-360e-11e9-816d-1a333d676433 container dapi-container: <nil>
STEP: delete the pod
Feb 21 19:27:38.592: INFO: Waiting for pod var-expansion-be84b54d-360e-11e9-816d-1a333d676433 to disappear
Feb 21 19:27:38.595: INFO: Pod var-expansion-be84b54d-360e-11e9-816d-1a333d676433 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:27:38.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-8sfzv" for this suite.
Feb 21 19:27:44.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:27:44.628: INFO: namespace: e2e-tests-var-expansion-8sfzv, resource: bindings, ignored listing per whitelist
Feb 21 19:27:44.754: INFO: namespace e2e-tests-var-expansion-8sfzv deletion completed in 6.153384852s

• [SLOW TEST:8.411 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:27:44.754: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-j92b9
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-c3880fcb-360e-11e9-816d-1a333d676433
STEP: Creating secret with name s-test-opt-upd-c388101c-360e-11e9-816d-1a333d676433
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-c3880fcb-360e-11e9-816d-1a333d676433
STEP: Updating secret s-test-opt-upd-c388101c-360e-11e9-816d-1a333d676433
STEP: Creating secret with name s-test-opt-create-c3881039-360e-11e9-816d-1a333d676433
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:29:09.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-j92b9" for this suite.
Feb 21 19:29:31.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:29:31.815: INFO: namespace: e2e-tests-secrets-j92b9, resource: bindings, ignored listing per whitelist
Feb 21 19:29:31.819: INFO: namespace e2e-tests-secrets-j92b9 deletion completed in 22.16289049s

• [SLOW TEST:107.066 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:29:31.820: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-z26bg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 21 19:29:40.066: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 21 19:29:40.070: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 21 19:29:42.071: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 21 19:29:42.083: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 21 19:29:44.071: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 21 19:29:44.075: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 21 19:29:46.071: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 21 19:29:46.075: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 21 19:29:48.071: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 21 19:29:48.075: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 21 19:29:50.071: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 21 19:29:50.075: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 21 19:29:52.071: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 21 19:29:52.075: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 21 19:29:54.071: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 21 19:29:54.083: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 21 19:29:56.071: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 21 19:29:56.076: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 21 19:29:58.071: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 21 19:29:58.076: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 21 19:30:00.071: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 21 19:30:00.075: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 21 19:30:02.071: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 21 19:30:02.076: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 21 19:30:04.071: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 21 19:30:04.075: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 21 19:30:06.071: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 21 19:30:06.083: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:30:06.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-z26bg" for this suite.
Feb 21 19:30:28.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:30:28.233: INFO: namespace: e2e-tests-container-lifecycle-hook-z26bg, resource: bindings, ignored listing per whitelist
Feb 21 19:30:28.250: INFO: namespace e2e-tests-container-lifecycle-hook-z26bg deletion completed in 22.151015118s

• [SLOW TEST:56.431 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:30:28.251: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-gk2zp
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-25016c2e-360f-11e9-816d-1a333d676433
STEP: Creating configMap with name cm-test-opt-upd-25016c6b-360f-11e9-816d-1a333d676433
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-25016c2e-360f-11e9-816d-1a333d676433
STEP: Updating configmap cm-test-opt-upd-25016c6b-360f-11e9-816d-1a333d676433
STEP: Creating configMap with name cm-test-opt-create-25016c7e-360f-11e9-816d-1a333d676433
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:30:32.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-gk2zp" for this suite.
Feb 21 19:30:54.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:30:54.770: INFO: namespace: e2e-tests-configmap-gk2zp, resource: bindings, ignored listing per whitelist
Feb 21 19:30:54.786: INFO: namespace e2e-tests-configmap-gk2zp deletion completed in 22.160754651s

• [SLOW TEST:26.535 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:30:54.786: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-nnqf5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0221 19:31:05.033736      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 21 19:31:05.033: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:31:05.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-nnqf5" for this suite.
Feb 21 19:31:11.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:31:11.155: INFO: namespace: e2e-tests-gc-nnqf5, resource: bindings, ignored listing per whitelist
Feb 21 19:31:11.186: INFO: namespace e2e-tests-gc-nnqf5 deletion completed in 6.14841844s

• [SLOW TEST:16.400 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:31:11.186: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-d5lsb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-3e935b58-360f-11e9-816d-1a333d676433
STEP: Creating a pod to test consume secrets
Feb 21 19:31:11.391: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3e9429ed-360f-11e9-816d-1a333d676433" in namespace "e2e-tests-projected-d5lsb" to be "success or failure"
Feb 21 19:31:11.395: INFO: Pod "pod-projected-secrets-3e9429ed-360f-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 4.169851ms
Feb 21 19:31:13.400: INFO: Pod "pod-projected-secrets-3e9429ed-360f-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008710782s
STEP: Saw pod success
Feb 21 19:31:13.400: INFO: Pod "pod-projected-secrets-3e9429ed-360f-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 19:31:13.404: INFO: Trying to get logs from node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c pod pod-projected-secrets-3e9429ed-360f-11e9-816d-1a333d676433 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 21 19:31:13.430: INFO: Waiting for pod pod-projected-secrets-3e9429ed-360f-11e9-816d-1a333d676433 to disappear
Feb 21 19:31:13.433: INFO: Pod pod-projected-secrets-3e9429ed-360f-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:31:13.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-d5lsb" for this suite.
Feb 21 19:31:19.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:31:19.558: INFO: namespace: e2e-tests-projected-d5lsb, resource: bindings, ignored listing per whitelist
Feb 21 19:31:19.598: INFO: namespace e2e-tests-projected-d5lsb deletion completed in 6.160555662s

• [SLOW TEST:8.412 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:31:19.598: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-wvdbt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 21 19:31:19.808: INFO: Waiting up to 5m0s for pod "downwardapi-volume-43983d11-360f-11e9-816d-1a333d676433" in namespace "e2e-tests-projected-wvdbt" to be "success or failure"
Feb 21 19:31:19.814: INFO: Pod "downwardapi-volume-43983d11-360f-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 5.829012ms
Feb 21 19:31:21.819: INFO: Pod "downwardapi-volume-43983d11-360f-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011039768s
STEP: Saw pod success
Feb 21 19:31:21.819: INFO: Pod "downwardapi-volume-43983d11-360f-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 19:31:21.824: INFO: Trying to get logs from node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c pod downwardapi-volume-43983d11-360f-11e9-816d-1a333d676433 container client-container: <nil>
STEP: delete the pod
Feb 21 19:31:21.853: INFO: Waiting for pod downwardapi-volume-43983d11-360f-11e9-816d-1a333d676433 to disappear
Feb 21 19:31:21.857: INFO: Pod downwardapi-volume-43983d11-360f-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:31:21.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wvdbt" for this suite.
Feb 21 19:31:27.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:31:27.915: INFO: namespace: e2e-tests-projected-wvdbt, resource: bindings, ignored listing per whitelist
Feb 21 19:31:27.997: INFO: namespace e2e-tests-projected-wvdbt deletion completed in 6.134844199s

• [SLOW TEST:8.398 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:31:27.997: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-kr5gz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 21 19:31:28.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-kr5gz'
Feb 21 19:31:28.461: INFO: stderr: ""
Feb 21 19:31:28.461: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Feb 21 19:31:33.512: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-kr5gz -o json'
Feb 21 19:31:33.584: INFO: stderr: ""
Feb 21 19:31:33.584: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-02-21T19:31:28Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-kr5gz\",\n        \"resourceVersion\": \"22172\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-kr5gz/pods/e2e-test-nginx-pod\",\n        \"uid\": \"48c02a21-360f-11e9-8547-42010a000100\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-w9889\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"vm-899af0be-63fe-4e97-4fe5-b77e233eb87c\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-w9889\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-w9889\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-21T19:31:28Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-21T19:31:30Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-21T19:31:30Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-21T19:31:28Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://a1390e0b63a8477d7f34dec10b6a1409a0d977e680ed3ac416f4a432a94621f4\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-02-21T19:31:29Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.0.1.5\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.200.20.144\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-02-21T19:31:28Z\"\n    }\n}\n"
STEP: replace the image in the pod
Feb 21 19:31:33.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 replace -f - --namespace=e2e-tests-kubectl-kr5gz'
Feb 21 19:31:33.765: INFO: stderr: ""
Feb 21 19:31:33.765: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Feb 21 19:31:33.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-kr5gz'
Feb 21 19:31:35.454: INFO: stderr: ""
Feb 21 19:31:35.454: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:31:35.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kr5gz" for this suite.
Feb 21 19:31:41.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:31:41.572: INFO: namespace: e2e-tests-kubectl-kr5gz, resource: bindings, ignored listing per whitelist
Feb 21 19:31:41.593: INFO: namespace e2e-tests-kubectl-kr5gz deletion completed in 6.133978293s

• [SLOW TEST:13.596 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:31:41.593: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-cwvzk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0221 19:32:12.345232      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 21 19:32:12.345: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:32:12.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-cwvzk" for this suite.
Feb 21 19:32:18.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:32:18.470: INFO: namespace: e2e-tests-gc-cwvzk, resource: bindings, ignored listing per whitelist
Feb 21 19:32:18.503: INFO: namespace e2e-tests-gc-cwvzk deletion completed in 6.153586243s

• [SLOW TEST:36.910 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:32:18.503: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-xj56l
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-xj56l
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-xj56l
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-xj56l
Feb 21 19:32:18.718: INFO: Found 0 stateful pods, waiting for 1
Feb 21 19:32:28.730: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Feb 21 19:32:28.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 exec --namespace=e2e-tests-statefulset-xj56l ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 21 19:32:28.914: INFO: stderr: ""
Feb 21 19:32:28.914: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 21 19:32:28.914: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 21 19:32:28.919: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 21 19:32:38.932: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 21 19:32:38.932: INFO: Waiting for statefulset status.replicas updated to 0
Feb 21 19:32:38.956: INFO: POD   NODE                                     PHASE    GRACE  CONDITIONS
Feb 21 19:32:38.956: INFO: ss-0  vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:18 +0000 UTC  }]
Feb 21 19:32:38.956: INFO: ss-1                                           Pending         []
Feb 21 19:32:38.956: INFO: 
Feb 21 19:32:38.956: INFO: StatefulSet ss has not reached scale 3, at 2
Feb 21 19:32:39.962: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.992435329s
Feb 21 19:32:40.968: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.986917536s
Feb 21 19:32:41.973: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.981291149s
Feb 21 19:32:42.979: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.975859298s
Feb 21 19:32:43.984: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.970200679s
Feb 21 19:32:44.989: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.965163841s
Feb 21 19:32:45.995: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.959649548s
Feb 21 19:32:47.000: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.954598451s
Feb 21 19:32:48.005: INFO: Verifying statefulset ss doesn't scale past 3 for another 949.346717ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-xj56l
Feb 21 19:32:49.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 exec --namespace=e2e-tests-statefulset-xj56l ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 21 19:32:49.196: INFO: stderr: ""
Feb 21 19:32:49.196: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 21 19:32:49.196: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 21 19:32:49.197: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 exec --namespace=e2e-tests-statefulset-xj56l ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 21 19:32:49.380: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Feb 21 19:32:49.380: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 21 19:32:49.380: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 21 19:32:49.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 exec --namespace=e2e-tests-statefulset-xj56l ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 21 19:32:49.543: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Feb 21 19:32:49.543: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 21 19:32:49.543: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 21 19:32:49.547: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 21 19:32:49.547: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 21 19:32:49.547: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Feb 21 19:32:49.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 exec --namespace=e2e-tests-statefulset-xj56l ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 21 19:32:49.714: INFO: stderr: ""
Feb 21 19:32:49.714: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 21 19:32:49.714: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 21 19:32:49.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 exec --namespace=e2e-tests-statefulset-xj56l ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 21 19:32:49.886: INFO: stderr: ""
Feb 21 19:32:49.886: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 21 19:32:49.886: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 21 19:32:49.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 exec --namespace=e2e-tests-statefulset-xj56l ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 21 19:32:50.042: INFO: stderr: ""
Feb 21 19:32:50.042: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 21 19:32:50.042: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 21 19:32:50.042: INFO: Waiting for statefulset status.replicas updated to 0
Feb 21 19:32:50.047: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Feb 21 19:33:00.063: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 21 19:33:00.063: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 21 19:33:00.063: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 21 19:33:00.080: INFO: POD   NODE                                     PHASE    GRACE  CONDITIONS
Feb 21 19:33:00.080: INFO: ss-0  vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:18 +0000 UTC  }]
Feb 21 19:33:00.081: INFO: ss-1  vm-899af0be-63fe-4e97-4fe5-b77e233eb87c  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:38 +0000 UTC  }]
Feb 21 19:33:00.081: INFO: ss-2  vm-96433648-4a4e-4d7e-4d24-8065d4ab25dc  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:38 +0000 UTC  }]
Feb 21 19:33:00.081: INFO: 
Feb 21 19:33:00.081: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 21 19:33:01.086: INFO: POD   NODE                                     PHASE    GRACE  CONDITIONS
Feb 21 19:33:01.086: INFO: ss-0  vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:18 +0000 UTC  }]
Feb 21 19:33:01.086: INFO: ss-1  vm-899af0be-63fe-4e97-4fe5-b77e233eb87c  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:38 +0000 UTC  }]
Feb 21 19:33:01.086: INFO: ss-2  vm-96433648-4a4e-4d7e-4d24-8065d4ab25dc  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:38 +0000 UTC  }]
Feb 21 19:33:01.086: INFO: 
Feb 21 19:33:01.086: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 21 19:33:02.091: INFO: POD   NODE                                     PHASE    GRACE  CONDITIONS
Feb 21 19:33:02.091: INFO: ss-0  vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:18 +0000 UTC  }]
Feb 21 19:33:02.091: INFO: ss-1  vm-899af0be-63fe-4e97-4fe5-b77e233eb87c  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:38 +0000 UTC  }]
Feb 21 19:33:02.091: INFO: ss-2  vm-96433648-4a4e-4d7e-4d24-8065d4ab25dc  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:38 +0000 UTC  }]
Feb 21 19:33:02.091: INFO: 
Feb 21 19:33:02.091: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 21 19:33:03.097: INFO: POD   NODE                                     PHASE    GRACE  CONDITIONS
Feb 21 19:33:03.097: INFO: ss-0  vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:18 +0000 UTC  }]
Feb 21 19:33:03.097: INFO: ss-1  vm-899af0be-63fe-4e97-4fe5-b77e233eb87c  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:38 +0000 UTC  }]
Feb 21 19:33:03.097: INFO: ss-2  vm-96433648-4a4e-4d7e-4d24-8065d4ab25dc  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:38 +0000 UTC  }]
Feb 21 19:33:03.097: INFO: 
Feb 21 19:33:03.097: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 21 19:33:04.102: INFO: POD   NODE                                     PHASE    GRACE  CONDITIONS
Feb 21 19:33:04.102: INFO: ss-0  vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:18 +0000 UTC  }]
Feb 21 19:33:04.103: INFO: ss-1  vm-899af0be-63fe-4e97-4fe5-b77e233eb87c  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:38 +0000 UTC  }]
Feb 21 19:33:04.103: INFO: ss-2  vm-96433648-4a4e-4d7e-4d24-8065d4ab25dc  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:38 +0000 UTC  }]
Feb 21 19:33:04.103: INFO: 
Feb 21 19:33:04.103: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 21 19:33:05.108: INFO: POD   NODE                                     PHASE    GRACE  CONDITIONS
Feb 21 19:33:05.108: INFO: ss-0  vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:18 +0000 UTC  }]
Feb 21 19:33:05.108: INFO: ss-1  vm-899af0be-63fe-4e97-4fe5-b77e233eb87c  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:38 +0000 UTC  }]
Feb 21 19:33:05.108: INFO: 
Feb 21 19:33:05.108: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 21 19:33:06.113: INFO: POD   NODE                                     PHASE    GRACE  CONDITIONS
Feb 21 19:33:06.113: INFO: ss-0  vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:18 +0000 UTC  }]
Feb 21 19:33:06.113: INFO: 
Feb 21 19:33:06.113: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 21 19:33:07.118: INFO: POD   NODE                                     PHASE    GRACE  CONDITIONS
Feb 21 19:33:07.118: INFO: ss-0  vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:18 +0000 UTC  }]
Feb 21 19:33:07.118: INFO: 
Feb 21 19:33:07.118: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 21 19:33:08.123: INFO: POD   NODE                                     PHASE    GRACE  CONDITIONS
Feb 21 19:33:08.123: INFO: ss-0  vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:32:18 +0000 UTC  }]
Feb 21 19:33:08.123: INFO: 
Feb 21 19:33:08.123: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 21 19:33:09.127: INFO: Verifying statefulset ss doesn't scale past 0 for another 952.457381ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-xj56l
Feb 21 19:33:10.140: INFO: Scaling statefulset ss to 0
Feb 21 19:33:10.151: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 21 19:33:10.154: INFO: Deleting all statefulset in ns e2e-tests-statefulset-xj56l
Feb 21 19:33:10.157: INFO: Scaling statefulset ss to 0
Feb 21 19:33:10.168: INFO: Waiting for statefulset status.replicas updated to 0
Feb 21 19:33:10.171: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:33:10.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-xj56l" for this suite.
Feb 21 19:33:16.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:33:16.235: INFO: namespace: e2e-tests-statefulset-xj56l, resource: bindings, ignored listing per whitelist
Feb 21 19:33:16.354: INFO: namespace e2e-tests-statefulset-xj56l deletion completed in 6.159878267s

• [SLOW TEST:57.851 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:33:16.355: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-s8rch
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 21 19:33:19.091: INFO: Successfully updated pod "pod-update-892fd99a-360f-11e9-816d-1a333d676433"
STEP: verifying the updated pod is in kubernetes
Feb 21 19:33:19.098: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:33:19.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-s8rch" for this suite.
Feb 21 19:33:41.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:33:41.155: INFO: namespace: e2e-tests-pods-s8rch, resource: bindings, ignored listing per whitelist
Feb 21 19:33:41.245: INFO: namespace e2e-tests-pods-s8rch deletion completed in 22.14211766s

• [SLOW TEST:24.891 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:33:41.246: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-mc5jc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 21 19:33:41.437: INFO: Waiting up to 5m0s for pod "pod-98033d21-360f-11e9-816d-1a333d676433" in namespace "e2e-tests-emptydir-mc5jc" to be "success or failure"
Feb 21 19:33:41.443: INFO: Pod "pod-98033d21-360f-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 5.23699ms
Feb 21 19:33:43.454: INFO: Pod "pod-98033d21-360f-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017182855s
STEP: Saw pod success
Feb 21 19:33:43.455: INFO: Pod "pod-98033d21-360f-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 19:33:43.458: INFO: Trying to get logs from node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c pod pod-98033d21-360f-11e9-816d-1a333d676433 container test-container: <nil>
STEP: delete the pod
Feb 21 19:33:43.481: INFO: Waiting for pod pod-98033d21-360f-11e9-816d-1a333d676433 to disappear
Feb 21 19:33:43.484: INFO: Pod pod-98033d21-360f-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:33:43.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-mc5jc" for this suite.
Feb 21 19:33:49.511: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:33:49.612: INFO: namespace: e2e-tests-emptydir-mc5jc, resource: bindings, ignored listing per whitelist
Feb 21 19:33:49.633: INFO: namespace e2e-tests-emptydir-mc5jc deletion completed in 6.143646298s

• [SLOW TEST:8.387 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:33:49.633: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-cvtfd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 21 19:33:49.810: INFO: Creating deployment "nginx-deployment"
Feb 21 19:33:49.817: INFO: Waiting for observed generation 1
Feb 21 19:33:51.824: INFO: Waiting for all required pods to come up
Feb 21 19:33:51.831: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Feb 21 19:33:53.851: INFO: Waiting for deployment "nginx-deployment" to complete
Feb 21 19:33:53.859: INFO: Updating deployment "nginx-deployment" with a non-existent image
Feb 21 19:33:53.871: INFO: Updating deployment nginx-deployment
Feb 21 19:33:53.871: INFO: Waiting for observed generation 2
Feb 21 19:33:55.879: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Feb 21 19:33:55.884: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Feb 21 19:33:55.889: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb 21 19:33:55.902: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Feb 21 19:33:55.902: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Feb 21 19:33:55.906: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb 21 19:33:55.915: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Feb 21 19:33:55.915: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Feb 21 19:33:55.925: INFO: Updating deployment nginx-deployment
Feb 21 19:33:55.925: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Feb 21 19:33:55.950: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Feb 21 19:33:55.981: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 21 19:33:58.002: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-cvtfd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-cvtfd/deployments/nginx-deployment,UID:9d02a357-360f-11e9-bacd-42010a000102,ResourceVersion:23079,Generation:3,CreationTimestamp:2019-02-21 19:33:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:11,UnavailableReplicas:22,Conditions:[{Available False 2019-02-21 19:33:55 +0000 UTC 2019-02-21 19:33:55 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-02-21 19:33:57 +0000 UTC 2019-02-21 19:33:49 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.}],ReadyReplicas:11,CollisionCount:nil,},}

Feb 21 19:33:58.008: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-cvtfd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-cvtfd/replicasets/nginx-deployment-65bbdb5f8,UID:9f6e360c-360f-11e9-8547-42010a000100,ResourceVersion:22982,Generation:3,CreationTimestamp:2019-02-21 19:33:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 9d02a357-360f-11e9-bacd-42010a000102 0xc00252bd07 0xc00252bd08}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 21 19:33:58.008: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Feb 21 19:33:58.008: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-cvtfd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-cvtfd/replicasets/nginx-deployment-555b55d965,UID:9d046a30-360f-11e9-8547-42010a000100,ResourceVersion:23077,Generation:3,CreationTimestamp:2019-02-21 19:33:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 9d02a357-360f-11e9-bacd-42010a000102 0xc00252bc47 0xc00252bc48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:11,AvailableReplicas:11,Conditions:[],},}
Feb 21 19:33:58.017: INFO: Pod "nginx-deployment-555b55d965-492c8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-492c8,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-cvtfd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cvtfd/pods/nginx-deployment-555b55d965-492c8,UID:a0b69d21-360f-11e9-8547-42010a000100,ResourceVersion:23037,Generation:0,CreationTimestamp:2019-02-21 19:33:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 9d046a30-360f-11e9-8547-42010a000100 0xc0026a98a7 0xc0026a98a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cthj5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cthj5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-cthj5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0026a9950} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0026a9970}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.4,PodIP:,StartTime:2019-02-21 19:33:56 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 21 19:33:58.017: INFO: Pod "nginx-deployment-555b55d965-5cftd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-5cftd,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-cvtfd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cvtfd/pods/nginx-deployment-555b55d965-5cftd,UID:9d0786bd-360f-11e9-8547-42010a000100,ResourceVersion:22804,Generation:0,CreationTimestamp:2019-02-21 19:33:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 9d046a30-360f-11e9-8547-42010a000100 0xc0026a9a20 0xc0026a9a21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cthj5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cthj5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-cthj5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm-899af0be-63fe-4e97-4fe5-b77e233eb87c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0026a9a80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0026a9aa0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:49 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:52 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:52 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:49 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.5,PodIP:10.200.20.148,StartTime:2019-02-21 19:33:49 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-21 19:33:51 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://69d8e23903343df624c3b2f3d26dabdebd4efeb5bad5e48bf78a1f182b947908}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 21 19:33:58.017: INFO: Pod "nginx-deployment-555b55d965-6qrkd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-6qrkd,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-cvtfd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cvtfd/pods/nginx-deployment-555b55d965-6qrkd,UID:a0a86f8d-360f-11e9-8547-42010a000100,ResourceVersion:22923,Generation:0,CreationTimestamp:2019-02-21 19:33:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 9d046a30-360f-11e9-8547-42010a000100 0xc0026a9bd0 0xc0026a9bd1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cthj5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cthj5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-cthj5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm-899af0be-63fe-4e97-4fe5-b77e233eb87c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0026a9c30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0026a9c50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:55 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.5,PodIP:,StartTime:2019-02-21 19:33:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 21 19:33:58.018: INFO: Pod "nginx-deployment-555b55d965-785q5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-785q5,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-cvtfd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cvtfd/pods/nginx-deployment-555b55d965-785q5,UID:9d0f0a2a-360f-11e9-8547-42010a000100,ResourceVersion:22807,Generation:0,CreationTimestamp:2019-02-21 19:33:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 9d046a30-360f-11e9-8547-42010a000100 0xc0026a9d00 0xc0026a9d01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cthj5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cthj5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-cthj5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm-899af0be-63fe-4e97-4fe5-b77e233eb87c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0026a9d80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0026a9e50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:49 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:52 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:52 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:49 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.5,PodIP:10.200.20.150,StartTime:2019-02-21 19:33:49 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-21 19:33:51 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://8a9a6577092e8d7adc6a5b73d134228846c6b338509030f99b758d79236ae1f1}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 21 19:33:58.018: INFO: Pod "nginx-deployment-555b55d965-9kvlx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-9kvlx,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-cvtfd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cvtfd/pods/nginx-deployment-555b55d965-9kvlx,UID:9d0eea24-360f-11e9-8547-42010a000100,ResourceVersion:22824,Generation:0,CreationTimestamp:2019-02-21 19:33:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 9d046a30-360f-11e9-8547-42010a000100 0xc0026a9f10 0xc0026a9f11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cthj5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cthj5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-cthj5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm-96433648-4a4e-4d7e-4d24-8065d4ab25dc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0026a9f70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0026a9fb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:49 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:52 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:52 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:49 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.3,PodIP:10.200.34.49,StartTime:2019-02-21 19:33:49 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-21 19:33:51 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://9c7a411c500950b28d4940970f9640cd3b38910396a7445c478a7ee56ac87c21}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 21 19:33:58.018: INFO: Pod "nginx-deployment-555b55d965-c2dh9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-c2dh9,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-cvtfd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cvtfd/pods/nginx-deployment-555b55d965-c2dh9,UID:a0ad4228-360f-11e9-8547-42010a000100,ResourceVersion:22949,Generation:0,CreationTimestamp:2019-02-21 19:33:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 9d046a30-360f-11e9-8547-42010a000100 0xc002708070 0xc002708071}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cthj5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cthj5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-cthj5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm-96433648-4a4e-4d7e-4d24-8065d4ab25dc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027080d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027080f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:55 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.3,PodIP:,StartTime:2019-02-21 19:33:56 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 21 19:33:58.018: INFO: Pod "nginx-deployment-555b55d965-c62w6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-c62w6,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-cvtfd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cvtfd/pods/nginx-deployment-555b55d965-c62w6,UID:a0b45ffb-360f-11e9-8547-42010a000100,ResourceVersion:23010,Generation:0,CreationTimestamp:2019-02-21 19:33:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 9d046a30-360f-11e9-8547-42010a000100 0xc0027081a0 0xc0027081a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cthj5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cthj5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-cthj5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm-899af0be-63fe-4e97-4fe5-b77e233eb87c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002708200} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002708220}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.5,PodIP:,StartTime:2019-02-21 19:33:56 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 21 19:33:58.018: INFO: Pod "nginx-deployment-555b55d965-f8z45" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-f8z45,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-cvtfd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cvtfd/pods/nginx-deployment-555b55d965-f8z45,UID:a0adc651-360f-11e9-8547-42010a000100,ResourceVersion:23056,Generation:0,CreationTimestamp:2019-02-21 19:33:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 9d046a30-360f-11e9-8547-42010a000100 0xc0027082d0 0xc0027082d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cthj5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cthj5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-cthj5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002708330} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002708350}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:55 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.4,PodIP:10.200.10.126,StartTime:2019-02-21 19:33:56 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-21 19:33:57 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://7dad8b0c7582c510a9b1cec7f4b8478afcc2cbb791f6c58c603622554c5ac24c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 21 19:33:58.018: INFO: Pod "nginx-deployment-555b55d965-g8827" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-g8827,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-cvtfd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cvtfd/pods/nginx-deployment-555b55d965-g8827,UID:a0b33127-360f-11e9-8547-42010a000100,ResourceVersion:23018,Generation:0,CreationTimestamp:2019-02-21 19:33:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 9d046a30-360f-11e9-8547-42010a000100 0xc0027084c0 0xc0027084c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cthj5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cthj5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-cthj5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm-96433648-4a4e-4d7e-4d24-8065d4ab25dc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002708520} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002708540}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.3,PodIP:,StartTime:2019-02-21 19:33:56 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 21 19:33:58.018: INFO: Pod "nginx-deployment-555b55d965-hkck5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-hkck5,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-cvtfd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cvtfd/pods/nginx-deployment-555b55d965-hkck5,UID:a0a9b0ea-360f-11e9-8547-42010a000100,ResourceVersion:22940,Generation:0,CreationTimestamp:2019-02-21 19:33:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 9d046a30-360f-11e9-8547-42010a000100 0xc0027085f0 0xc0027085f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cthj5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cthj5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-cthj5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm-899af0be-63fe-4e97-4fe5-b77e233eb87c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002708650} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002708670}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:55 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.5,PodIP:,StartTime:2019-02-21 19:33:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 21 19:33:58.018: INFO: Pod "nginx-deployment-555b55d965-htsw8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-htsw8,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-cvtfd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cvtfd/pods/nginx-deployment-555b55d965-htsw8,UID:9d0aac62-360f-11e9-8547-42010a000100,ResourceVersion:22810,Generation:0,CreationTimestamp:2019-02-21 19:33:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 9d046a30-360f-11e9-8547-42010a000100 0xc002708720 0xc002708721}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cthj5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cthj5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-cthj5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002708780} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027087a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:49 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:52 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:52 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:49 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.4,PodIP:10.200.10.121,StartTime:2019-02-21 19:33:49 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-21 19:33:51 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://937c8dca6bc56937c7c162d7250d57001b4b9cc42245adc590b1d7390460fc93}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 21 19:33:58.018: INFO: Pod "nginx-deployment-555b55d965-kghmx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-kghmx,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-cvtfd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cvtfd/pods/nginx-deployment-555b55d965-kghmx,UID:9d0871b3-360f-11e9-8547-42010a000100,ResourceVersion:22789,Generation:0,CreationTimestamp:2019-02-21 19:33:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 9d046a30-360f-11e9-8547-42010a000100 0xc002708860 0xc002708861}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cthj5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cthj5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-cthj5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027088d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002708970}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:49 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:51 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:51 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:49 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.4,PodIP:10.200.10.119,StartTime:2019-02-21 19:33:49 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-21 19:33:51 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://d4680fcedb86326a5b5f1562be27384b112eeb797bec30fe7633771a2023c604}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 21 19:33:58.019: INFO: Pod "nginx-deployment-555b55d965-n8kxc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-n8kxc,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-cvtfd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cvtfd/pods/nginx-deployment-555b55d965-n8kxc,UID:a0b69471-360f-11e9-8547-42010a000100,ResourceVersion:23036,Generation:0,CreationTimestamp:2019-02-21 19:33:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 9d046a30-360f-11e9-8547-42010a000100 0xc002708a30 0xc002708a31}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cthj5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cthj5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-cthj5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm-899af0be-63fe-4e97-4fe5-b77e233eb87c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002708a90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002708ba0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.5,PodIP:,StartTime:2019-02-21 19:33:56 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 21 19:33:58.019: INFO: Pod "nginx-deployment-555b55d965-pfmk2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-pfmk2,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-cvtfd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cvtfd/pods/nginx-deployment-555b55d965-pfmk2,UID:9d0a9c0b-360f-11e9-8547-42010a000100,ResourceVersion:22815,Generation:0,CreationTimestamp:2019-02-21 19:33:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 9d046a30-360f-11e9-8547-42010a000100 0xc002708c70 0xc002708c71}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cthj5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cthj5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-cthj5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm-96433648-4a4e-4d7e-4d24-8065d4ab25dc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002708cd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002708cf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:49 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:52 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:52 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:49 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.3,PodIP:10.200.34.48,StartTime:2019-02-21 19:33:49 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-21 19:33:51 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://61c959aa7fe9fb1040ab9148b2552272502bdee2da89d944f6301488e858236d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 21 19:33:58.019: INFO: Pod "nginx-deployment-555b55d965-rbbxv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-rbbxv,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-cvtfd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cvtfd/pods/nginx-deployment-555b55d965-rbbxv,UID:a0a999e1-360f-11e9-8547-42010a000100,ResourceVersion:23076,Generation:0,CreationTimestamp:2019-02-21 19:33:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 9d046a30-360f-11e9-8547-42010a000100 0xc002708dc0 0xc002708dc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cthj5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cthj5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-cthj5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002708e90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002708eb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:55 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:55 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.4,PodIP:10.200.10.124,StartTime:2019-02-21 19:33:55 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-21 19:33:57 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://a24c1837a8ebcc9b14f404f067346527de7bcb50703a66ff70198e3cedce496b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 21 19:33:58.019: INFO: Pod "nginx-deployment-555b55d965-s4l6g" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-s4l6g,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-cvtfd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cvtfd/pods/nginx-deployment-555b55d965-s4l6g,UID:9d0918a4-360f-11e9-8547-42010a000100,ResourceVersion:22819,Generation:0,CreationTimestamp:2019-02-21 19:33:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 9d046a30-360f-11e9-8547-42010a000100 0xc002708fa0 0xc002708fa1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cthj5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cthj5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-cthj5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm-96433648-4a4e-4d7e-4d24-8065d4ab25dc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002709000} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002709020}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:49 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:52 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:52 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:49 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.3,PodIP:10.200.34.47,StartTime:2019-02-21 19:33:49 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-21 19:33:50 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://cea4caf517ac849b516e647adda759a631a98ebe09fa6c647176c150e5253f5b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 21 19:33:58.019: INFO: Pod "nginx-deployment-555b55d965-shtj7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-shtj7,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-cvtfd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cvtfd/pods/nginx-deployment-555b55d965-shtj7,UID:a0b5cf97-360f-11e9-8547-42010a000100,ResourceVersion:23022,Generation:0,CreationTimestamp:2019-02-21 19:33:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 9d046a30-360f-11e9-8547-42010a000100 0xc0027093e0 0xc0027093e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cthj5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cthj5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-cthj5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002709450} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002709470}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.4,PodIP:,StartTime:2019-02-21 19:33:56 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 21 19:33:58.019: INFO: Pod "nginx-deployment-555b55d965-t4nlb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-t4nlb,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-cvtfd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cvtfd/pods/nginx-deployment-555b55d965-t4nlb,UID:a0ade24b-360f-11e9-8547-42010a000100,ResourceVersion:23065,Generation:0,CreationTimestamp:2019-02-21 19:33:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 9d046a30-360f-11e9-8547-42010a000100 0xc002709520 0xc002709521}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cthj5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cthj5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-cthj5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm-96433648-4a4e-4d7e-4d24-8065d4ab25dc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002709610} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002709630}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:55 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.3,PodIP:10.200.34.54,StartTime:2019-02-21 19:33:56 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-21 19:33:57 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://aaefbf1b9fd5fc1d902450048ddf0688c29189a27048dbb373e9ed2e0813c594}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 21 19:33:58.019: INFO: Pod "nginx-deployment-555b55d965-wmrlq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-wmrlq,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-cvtfd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cvtfd/pods/nginx-deployment-555b55d965-wmrlq,UID:a0ad6a4f-360f-11e9-8547-42010a000100,ResourceVersion:22964,Generation:0,CreationTimestamp:2019-02-21 19:33:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 9d046a30-360f-11e9-8547-42010a000100 0xc002709960 0xc002709961}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cthj5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cthj5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-cthj5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm-899af0be-63fe-4e97-4fe5-b77e233eb87c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002709ab0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002709ad0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:55 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.5,PodIP:,StartTime:2019-02-21 19:33:56 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 21 19:33:58.019: INFO: Pod "nginx-deployment-555b55d965-xtkrr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-xtkrr,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-cvtfd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cvtfd/pods/nginx-deployment-555b55d965-xtkrr,UID:9d0abc57-360f-11e9-8547-42010a000100,ResourceVersion:22813,Generation:0,CreationTimestamp:2019-02-21 19:33:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 9d046a30-360f-11e9-8547-42010a000100 0xc002709c00 0xc002709c01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cthj5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cthj5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-cthj5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002709ce0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002709d00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:49 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:52 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:52 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:49 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.4,PodIP:10.200.10.120,StartTime:2019-02-21 19:33:49 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-21 19:33:51 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://e592d02db860af83432b84c2c9d17b9ad741c305a4045373d13c51bfa0e5930f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 21 19:33:58.019: INFO: Pod "nginx-deployment-65bbdb5f8-4h88r" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-4h88r,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-cvtfd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cvtfd/pods/nginx-deployment-65bbdb5f8-4h88r,UID:9f774690-360f-11e9-8547-42010a000100,ResourceVersion:22959,Generation:0,CreationTimestamp:2019-02-21 19:33:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 9f6e360c-360f-11e9-8547-42010a000100 0xc0021c0060 0xc0021c0061}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cthj5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cthj5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-cthj5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021c00d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021c00f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:53 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.4,PodIP:10.200.10.123,StartTime:2019-02-21 19:33:53 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 21 19:33:58.019: INFO: Pod "nginx-deployment-65bbdb5f8-548z8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-548z8,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-cvtfd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cvtfd/pods/nginx-deployment-65bbdb5f8-548z8,UID:9f70efdc-360f-11e9-8547-42010a000100,ResourceVersion:22972,Generation:0,CreationTimestamp:2019-02-21 19:33:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 9f6e360c-360f-11e9-8547-42010a000100 0xc0021c01d0 0xc0021c01d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cthj5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cthj5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-cthj5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021c0240} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021c0260}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:53 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.4,PodIP:10.200.10.122,StartTime:2019-02-21 19:33:53 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 21 19:33:58.020: INFO: Pod "nginx-deployment-65bbdb5f8-8dqzm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-8dqzm,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-cvtfd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cvtfd/pods/nginx-deployment-65bbdb5f8-8dqzm,UID:9f6f54c7-360f-11e9-8547-42010a000100,ResourceVersion:23075,Generation:0,CreationTimestamp:2019-02-21 19:33:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 9f6e360c-360f-11e9-8547-42010a000100 0xc0021c0340 0xc0021c0341}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cthj5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cthj5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-cthj5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm-899af0be-63fe-4e97-4fe5-b77e233eb87c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021c03b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021c03d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:53 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.5,PodIP:10.200.20.151,StartTime:2019-02-21 19:33:53 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 21 19:33:58.020: INFO: Pod "nginx-deployment-65bbdb5f8-dwssl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-dwssl,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-cvtfd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cvtfd/pods/nginx-deployment-65bbdb5f8-dwssl,UID:a0b62ca2-360f-11e9-8547-42010a000100,ResourceVersion:23021,Generation:0,CreationTimestamp:2019-02-21 19:33:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 9f6e360c-360f-11e9-8547-42010a000100 0xc0021c04b0 0xc0021c04b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cthj5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cthj5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-cthj5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm-899af0be-63fe-4e97-4fe5-b77e233eb87c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021c0520} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021c0540}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.5,PodIP:,StartTime:2019-02-21 19:33:56 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 21 19:33:58.020: INFO: Pod "nginx-deployment-65bbdb5f8-fssb2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-fssb2,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-cvtfd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cvtfd/pods/nginx-deployment-65bbdb5f8-fssb2,UID:9f79c2fe-360f-11e9-8547-42010a000100,ResourceVersion:23049,Generation:0,CreationTimestamp:2019-02-21 19:33:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 9f6e360c-360f-11e9-8547-42010a000100 0xc0021c0600 0xc0021c0601}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cthj5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cthj5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-cthj5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm-899af0be-63fe-4e97-4fe5-b77e233eb87c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021c0670} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021c0690}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:53 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.5,PodIP:10.200.20.152,StartTime:2019-02-21 19:33:53 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 21 19:33:58.020: INFO: Pod "nginx-deployment-65bbdb5f8-g2d97" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-g2d97,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-cvtfd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cvtfd/pods/nginx-deployment-65bbdb5f8-g2d97,UID:9f70e2e4-360f-11e9-8547-42010a000100,ResourceVersion:23072,Generation:0,CreationTimestamp:2019-02-21 19:33:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 9f6e360c-360f-11e9-8547-42010a000100 0xc0021c0770 0xc0021c0771}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cthj5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cthj5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-cthj5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm-96433648-4a4e-4d7e-4d24-8065d4ab25dc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021c07e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021c0800}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:53 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.3,PodIP:10.200.34.51,StartTime:2019-02-21 19:33:53 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ImagePullBackOff,Message:Back-off pulling image "nginx:404",} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 21 19:33:58.020: INFO: Pod "nginx-deployment-65bbdb5f8-g6p6b" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-g6p6b,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-cvtfd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cvtfd/pods/nginx-deployment-65bbdb5f8-g6p6b,UID:a0afd5dd-360f-11e9-8547-42010a000100,ResourceVersion:23003,Generation:0,CreationTimestamp:2019-02-21 19:33:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 9f6e360c-360f-11e9-8547-42010a000100 0xc0021c08e0 0xc0021c08e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cthj5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cthj5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-cthj5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm-96433648-4a4e-4d7e-4d24-8065d4ab25dc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021c0950} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021c0970}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.3,PodIP:,StartTime:2019-02-21 19:33:56 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 21 19:33:58.020: INFO: Pod "nginx-deployment-65bbdb5f8-glr7m" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-glr7m,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-cvtfd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cvtfd/pods/nginx-deployment-65bbdb5f8-glr7m,UID:a0a9f91f-360f-11e9-8547-42010a000100,ResourceVersion:23069,Generation:0,CreationTimestamp:2019-02-21 19:33:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 9f6e360c-360f-11e9-8547-42010a000100 0xc0021c0a30 0xc0021c0a31}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cthj5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cthj5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-cthj5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm-96433648-4a4e-4d7e-4d24-8065d4ab25dc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021c0aa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021c0ac0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:55 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.3,PodIP:10.200.34.52,StartTime:2019-02-21 19:33:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 21 19:33:58.020: INFO: Pod "nginx-deployment-65bbdb5f8-jfjbt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-jfjbt,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-cvtfd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cvtfd/pods/nginx-deployment-65bbdb5f8-jfjbt,UID:a0ad151c-360f-11e9-8547-42010a000100,ResourceVersion:22952,Generation:0,CreationTimestamp:2019-02-21 19:33:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 9f6e360c-360f-11e9-8547-42010a000100 0xc0021c0ba0 0xc0021c0ba1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cthj5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cthj5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-cthj5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm-899af0be-63fe-4e97-4fe5-b77e233eb87c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021c0c10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021c0c30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:55 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.5,PodIP:,StartTime:2019-02-21 19:33:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 21 19:33:58.020: INFO: Pod "nginx-deployment-65bbdb5f8-jgq95" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-jgq95,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-cvtfd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cvtfd/pods/nginx-deployment-65bbdb5f8-jgq95,UID:a0affdf6-360f-11e9-8547-42010a000100,ResourceVersion:22976,Generation:0,CreationTimestamp:2019-02-21 19:33:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 9f6e360c-360f-11e9-8547-42010a000100 0xc0021c0cf0 0xc0021c0cf1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cthj5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cthj5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-cthj5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm-899af0be-63fe-4e97-4fe5-b77e233eb87c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021c0d60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021c0d80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.5,PodIP:,StartTime:2019-02-21 19:33:56 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 21 19:33:58.020: INFO: Pod "nginx-deployment-65bbdb5f8-mnwg7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-mnwg7,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-cvtfd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cvtfd/pods/nginx-deployment-65bbdb5f8-mnwg7,UID:a0aff203-360f-11e9-8547-42010a000100,ResourceVersion:23011,Generation:0,CreationTimestamp:2019-02-21 19:33:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 9f6e360c-360f-11e9-8547-42010a000100 0xc0021c0e40 0xc0021c0e41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cthj5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cthj5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-cthj5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021c0eb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021c0ed0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.4,PodIP:,StartTime:2019-02-21 19:33:56 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 21 19:33:58.021: INFO: Pod "nginx-deployment-65bbdb5f8-svl8r" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-svl8r,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-cvtfd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cvtfd/pods/nginx-deployment-65bbdb5f8-svl8r,UID:a0ad0034-360f-11e9-8547-42010a000100,ResourceVersion:22984,Generation:0,CreationTimestamp:2019-02-21 19:33:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 9f6e360c-360f-11e9-8547-42010a000100 0xc0021c0f90 0xc0021c0f91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cthj5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cthj5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-cthj5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021c1000} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021c1020}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:55 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.4,PodIP:,StartTime:2019-02-21 19:33:56 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 21 19:33:58.021: INFO: Pod "nginx-deployment-65bbdb5f8-zxwgl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-zxwgl,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-cvtfd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cvtfd/pods/nginx-deployment-65bbdb5f8-zxwgl,UID:a0b008af-360f-11e9-8547-42010a000100,ResourceVersion:22981,Generation:0,CreationTimestamp:2019-02-21 19:33:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 9f6e360c-360f-11e9-8547-42010a000100 0xc0021c10e0 0xc0021c10e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cthj5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cthj5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-cthj5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm-96433648-4a4e-4d7e-4d24-8065d4ab25dc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021c1150} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021c1170}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-21 19:33:56 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.3,PodIP:,StartTime:2019-02-21 19:33:56 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:33:58.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-cvtfd" for this suite.
Feb 21 19:34:06.044: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:34:06.091: INFO: namespace: e2e-tests-deployment-cvtfd, resource: bindings, ignored listing per whitelist
Feb 21 19:34:06.173: INFO: namespace e2e-tests-deployment-cvtfd deletion completed in 8.147516891s

• [SLOW TEST:16.540 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:34:06.173: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-tdcvw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:34:06.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-tdcvw" for this suite.
Feb 21 19:34:12.424: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:34:12.484: INFO: namespace: e2e-tests-kubelet-test-tdcvw, resource: bindings, ignored listing per whitelist
Feb 21 19:34:12.544: INFO: namespace e2e-tests-kubelet-test-tdcvw deletion completed in 6.140038614s

• [SLOW TEST:6.371 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:34:12.544: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-h7slx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Feb 21 19:34:12.739: INFO: Pod name pod-release: Found 0 pods out of 1
Feb 21 19:34:17.753: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:34:18.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-h7slx" for this suite.
Feb 21 19:34:24.801: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:34:24.921: INFO: namespace: e2e-tests-replication-controller-h7slx, resource: bindings, ignored listing per whitelist
Feb 21 19:34:24.934: INFO: namespace e2e-tests-replication-controller-h7slx deletion completed in 6.153857575s

• [SLOW TEST:12.390 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:34:24.934: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-ncddv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 21 19:34:31.188: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 21 19:34:31.192: INFO: Pod pod-with-poststart-http-hook still exists
Feb 21 19:34:33.192: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 21 19:34:33.197: INFO: Pod pod-with-poststart-http-hook still exists
Feb 21 19:34:35.192: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 21 19:34:35.196: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:34:35.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-ncddv" for this suite.
Feb 21 19:34:51.228: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:34:51.349: INFO: namespace: e2e-tests-container-lifecycle-hook-ncddv, resource: bindings, ignored listing per whitelist
Feb 21 19:34:51.362: INFO: namespace e2e-tests-container-lifecycle-hook-ncddv deletion completed in 16.160929762s

• [SLOW TEST:26.428 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:34:51.362: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svc-latency-d59z2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-d59z2
I0221 19:34:51.558484      18 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-d59z2, replica count: 1
I0221 19:34:52.609109      18 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0221 19:34:53.609367      18 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 21 19:34:53.725: INFO: Created: latency-svc-7v6d4
Feb 21 19:34:53.734: INFO: Got endpoints: latency-svc-7v6d4 [25.209076ms]
Feb 21 19:34:53.748: INFO: Created: latency-svc-62nms
Feb 21 19:34:53.753: INFO: Got endpoints: latency-svc-62nms [17.358478ms]
Feb 21 19:34:53.759: INFO: Created: latency-svc-xjdqm
Feb 21 19:34:53.763: INFO: Got endpoints: latency-svc-xjdqm [27.205268ms]
Feb 21 19:34:53.768: INFO: Created: latency-svc-kd695
Feb 21 19:34:53.772: INFO: Got endpoints: latency-svc-kd695 [36.328207ms]
Feb 21 19:34:53.778: INFO: Created: latency-svc-lrlzd
Feb 21 19:34:53.784: INFO: Got endpoints: latency-svc-lrlzd [48.018495ms]
Feb 21 19:34:53.789: INFO: Created: latency-svc-nqmml
Feb 21 19:34:53.794: INFO: Got endpoints: latency-svc-nqmml [22.188614ms]
Feb 21 19:34:53.800: INFO: Created: latency-svc-v8ft7
Feb 21 19:34:53.806: INFO: Got endpoints: latency-svc-v8ft7 [71.036973ms]
Feb 21 19:34:53.813: INFO: Created: latency-svc-vwhw4
Feb 21 19:34:53.818: INFO: Got endpoints: latency-svc-vwhw4 [82.564851ms]
Feb 21 19:34:53.824: INFO: Created: latency-svc-st55n
Feb 21 19:34:53.827: INFO: Got endpoints: latency-svc-st55n [91.911537ms]
Feb 21 19:34:53.840: INFO: Created: latency-svc-4drw9
Feb 21 19:34:53.848: INFO: Got endpoints: latency-svc-4drw9 [112.605938ms]
Feb 21 19:34:53.853: INFO: Created: latency-svc-cxzvp
Feb 21 19:34:53.856: INFO: Got endpoints: latency-svc-cxzvp [120.799443ms]
Feb 21 19:34:53.862: INFO: Created: latency-svc-gbq9z
Feb 21 19:34:53.867: INFO: Got endpoints: latency-svc-gbq9z [131.522956ms]
Feb 21 19:34:53.872: INFO: Created: latency-svc-xdqgr
Feb 21 19:34:53.879: INFO: Got endpoints: latency-svc-xdqgr [142.938172ms]
Feb 21 19:34:53.885: INFO: Created: latency-svc-rp4hl
Feb 21 19:34:53.888: INFO: Got endpoints: latency-svc-rp4hl [152.33605ms]
Feb 21 19:34:53.895: INFO: Created: latency-svc-j8qns
Feb 21 19:34:53.899: INFO: Got endpoints: latency-svc-j8qns [163.202811ms]
Feb 21 19:34:53.904: INFO: Created: latency-svc-rss8q
Feb 21 19:34:53.909: INFO: Got endpoints: latency-svc-rss8q [172.945548ms]
Feb 21 19:34:53.914: INFO: Created: latency-svc-fgkq7
Feb 21 19:34:53.918: INFO: Got endpoints: latency-svc-fgkq7 [182.357576ms]
Feb 21 19:34:53.922: INFO: Created: latency-svc-md5xl
Feb 21 19:34:53.928: INFO: Got endpoints: latency-svc-md5xl [175.03117ms]
Feb 21 19:34:53.933: INFO: Created: latency-svc-qzm6c
Feb 21 19:34:53.937: INFO: Got endpoints: latency-svc-qzm6c [174.48602ms]
Feb 21 19:34:53.941: INFO: Created: latency-svc-4sxrc
Feb 21 19:34:53.946: INFO: Got endpoints: latency-svc-4sxrc [162.366697ms]
Feb 21 19:34:53.953: INFO: Created: latency-svc-g6k6v
Feb 21 19:34:53.956: INFO: Got endpoints: latency-svc-g6k6v [162.260268ms]
Feb 21 19:34:53.961: INFO: Created: latency-svc-rhpdf
Feb 21 19:34:53.967: INFO: Got endpoints: latency-svc-rhpdf [160.013116ms]
Feb 21 19:34:53.972: INFO: Created: latency-svc-xl56h
Feb 21 19:34:53.977: INFO: Got endpoints: latency-svc-xl56h [159.14141ms]
Feb 21 19:34:53.983: INFO: Created: latency-svc-2fcrp
Feb 21 19:34:53.988: INFO: Got endpoints: latency-svc-2fcrp [160.103272ms]
Feb 21 19:34:53.992: INFO: Created: latency-svc-vfvvl
Feb 21 19:34:53.997: INFO: Got endpoints: latency-svc-vfvvl [148.746671ms]
Feb 21 19:34:54.005: INFO: Created: latency-svc-627n4
Feb 21 19:34:54.008: INFO: Got endpoints: latency-svc-627n4 [151.212894ms]
Feb 21 19:34:54.013: INFO: Created: latency-svc-trpvq
Feb 21 19:34:54.019: INFO: Got endpoints: latency-svc-trpvq [151.825628ms]
Feb 21 19:34:54.024: INFO: Created: latency-svc-2s4d6
Feb 21 19:34:54.028: INFO: Got endpoints: latency-svc-2s4d6 [149.175308ms]
Feb 21 19:34:54.033: INFO: Created: latency-svc-zm6ts
Feb 21 19:34:54.038: INFO: Got endpoints: latency-svc-zm6ts [150.491102ms]
Feb 21 19:34:54.044: INFO: Created: latency-svc-86dm4
Feb 21 19:34:54.050: INFO: Got endpoints: latency-svc-86dm4 [151.077751ms]
Feb 21 19:34:54.054: INFO: Created: latency-svc-srxp8
Feb 21 19:34:54.057: INFO: Got endpoints: latency-svc-srxp8 [147.908939ms]
Feb 21 19:34:54.064: INFO: Created: latency-svc-zhgrf
Feb 21 19:34:54.072: INFO: Got endpoints: latency-svc-zhgrf [153.508205ms]
Feb 21 19:34:54.076: INFO: Created: latency-svc-w98vn
Feb 21 19:34:54.081: INFO: Got endpoints: latency-svc-w98vn [152.979425ms]
Feb 21 19:34:54.087: INFO: Created: latency-svc-b2fg9
Feb 21 19:34:54.090: INFO: Got endpoints: latency-svc-b2fg9 [152.847518ms]
Feb 21 19:34:54.097: INFO: Created: latency-svc-bmw75
Feb 21 19:34:54.101: INFO: Got endpoints: latency-svc-bmw75 [154.822117ms]
Feb 21 19:34:54.107: INFO: Created: latency-svc-4m6t4
Feb 21 19:34:54.111: INFO: Got endpoints: latency-svc-4m6t4 [154.66582ms]
Feb 21 19:34:54.117: INFO: Created: latency-svc-2hws5
Feb 21 19:34:54.120: INFO: Got endpoints: latency-svc-2hws5 [153.157443ms]
Feb 21 19:34:54.126: INFO: Created: latency-svc-6prw8
Feb 21 19:34:54.131: INFO: Got endpoints: latency-svc-6prw8 [153.404057ms]
Feb 21 19:34:54.136: INFO: Created: latency-svc-7bjtx
Feb 21 19:34:54.146: INFO: Created: latency-svc-jpvcv
Feb 21 19:34:54.154: INFO: Created: latency-svc-9b4hg
Feb 21 19:34:54.163: INFO: Created: latency-svc-ptkq5
Feb 21 19:34:54.172: INFO: Created: latency-svc-nkzzc
Feb 21 19:34:54.182: INFO: Got endpoints: latency-svc-7bjtx [194.86189ms]
Feb 21 19:34:54.184: INFO: Created: latency-svc-z97ld
Feb 21 19:34:54.192: INFO: Created: latency-svc-nkwff
Feb 21 19:34:54.203: INFO: Created: latency-svc-h72jn
Feb 21 19:34:54.214: INFO: Created: latency-svc-kf5kn
Feb 21 19:34:54.219: INFO: Created: latency-svc-7tg9b
Feb 21 19:34:54.230: INFO: Got endpoints: latency-svc-jpvcv [232.956895ms]
Feb 21 19:34:54.230: INFO: Created: latency-svc-gghnk
Feb 21 19:34:54.242: INFO: Created: latency-svc-cm6g5
Feb 21 19:34:54.255: INFO: Created: latency-svc-t2bzf
Feb 21 19:34:54.266: INFO: Created: latency-svc-km5qk
Feb 21 19:34:54.275: INFO: Created: latency-svc-rvcs2
Feb 21 19:34:54.281: INFO: Got endpoints: latency-svc-9b4hg [273.746178ms]
Feb 21 19:34:54.287: INFO: Created: latency-svc-ms4kd
Feb 21 19:34:54.296: INFO: Created: latency-svc-8nk8j
Feb 21 19:34:54.305: INFO: Created: latency-svc-fknc5
Feb 21 19:34:54.332: INFO: Got endpoints: latency-svc-ptkq5 [312.584118ms]
Feb 21 19:34:54.346: INFO: Created: latency-svc-fbmq4
Feb 21 19:34:54.380: INFO: Got endpoints: latency-svc-nkzzc [351.767151ms]
Feb 21 19:34:54.394: INFO: Created: latency-svc-b6dsf
Feb 21 19:34:54.430: INFO: Got endpoints: latency-svc-z97ld [392.077135ms]
Feb 21 19:34:54.445: INFO: Created: latency-svc-7z76b
Feb 21 19:34:54.482: INFO: Got endpoints: latency-svc-nkwff [431.993959ms]
Feb 21 19:34:54.497: INFO: Created: latency-svc-2x2tn
Feb 21 19:34:54.532: INFO: Got endpoints: latency-svc-h72jn [475.348826ms]
Feb 21 19:34:54.555: INFO: Created: latency-svc-m7mmz
Feb 21 19:34:54.580: INFO: Got endpoints: latency-svc-kf5kn [508.440925ms]
Feb 21 19:34:54.593: INFO: Created: latency-svc-82pvg
Feb 21 19:34:54.630: INFO: Got endpoints: latency-svc-7tg9b [549.509101ms]
Feb 21 19:34:54.643: INFO: Created: latency-svc-54z6g
Feb 21 19:34:54.680: INFO: Got endpoints: latency-svc-gghnk [590.300717ms]
Feb 21 19:34:54.694: INFO: Created: latency-svc-qkbvd
Feb 21 19:34:54.730: INFO: Got endpoints: latency-svc-cm6g5 [628.425371ms]
Feb 21 19:34:54.745: INFO: Created: latency-svc-4wqxh
Feb 21 19:34:54.780: INFO: Got endpoints: latency-svc-t2bzf [669.147322ms]
Feb 21 19:34:54.795: INFO: Created: latency-svc-sc5f7
Feb 21 19:34:54.831: INFO: Got endpoints: latency-svc-km5qk [711.086312ms]
Feb 21 19:34:54.846: INFO: Created: latency-svc-b2bpt
Feb 21 19:34:54.880: INFO: Got endpoints: latency-svc-rvcs2 [749.730661ms]
Feb 21 19:34:54.896: INFO: Created: latency-svc-8rkpn
Feb 21 19:34:54.930: INFO: Got endpoints: latency-svc-ms4kd [747.439391ms]
Feb 21 19:34:54.944: INFO: Created: latency-svc-wbnbv
Feb 21 19:34:54.980: INFO: Got endpoints: latency-svc-8nk8j [749.578161ms]
Feb 21 19:34:54.994: INFO: Created: latency-svc-dhslz
Feb 21 19:34:55.031: INFO: Got endpoints: latency-svc-fknc5 [749.525693ms]
Feb 21 19:34:55.046: INFO: Created: latency-svc-zcp6t
Feb 21 19:34:55.081: INFO: Got endpoints: latency-svc-fbmq4 [749.085353ms]
Feb 21 19:34:55.095: INFO: Created: latency-svc-dgmmx
Feb 21 19:34:55.130: INFO: Got endpoints: latency-svc-b6dsf [750.280615ms]
Feb 21 19:34:55.144: INFO: Created: latency-svc-sttbs
Feb 21 19:34:55.181: INFO: Got endpoints: latency-svc-7z76b [750.344712ms]
Feb 21 19:34:55.194: INFO: Created: latency-svc-878n9
Feb 21 19:34:55.230: INFO: Got endpoints: latency-svc-2x2tn [748.381789ms]
Feb 21 19:34:55.244: INFO: Created: latency-svc-hgfxq
Feb 21 19:34:55.279: INFO: Got endpoints: latency-svc-m7mmz [747.113359ms]
Feb 21 19:34:55.294: INFO: Created: latency-svc-w9495
Feb 21 19:34:55.332: INFO: Got endpoints: latency-svc-82pvg [751.992194ms]
Feb 21 19:34:55.347: INFO: Created: latency-svc-s9vxf
Feb 21 19:34:55.380: INFO: Got endpoints: latency-svc-54z6g [749.574331ms]
Feb 21 19:34:55.395: INFO: Created: latency-svc-zb7z7
Feb 21 19:34:55.430: INFO: Got endpoints: latency-svc-qkbvd [749.242317ms]
Feb 21 19:34:55.445: INFO: Created: latency-svc-9bcjf
Feb 21 19:34:55.480: INFO: Got endpoints: latency-svc-4wqxh [749.841952ms]
Feb 21 19:34:55.496: INFO: Created: latency-svc-f9xbh
Feb 21 19:34:55.529: INFO: Got endpoints: latency-svc-sc5f7 [749.048693ms]
Feb 21 19:34:55.544: INFO: Created: latency-svc-5k2sr
Feb 21 19:34:55.580: INFO: Got endpoints: latency-svc-b2bpt [749.257499ms]
Feb 21 19:34:55.595: INFO: Created: latency-svc-wzg72
Feb 21 19:34:55.629: INFO: Got endpoints: latency-svc-8rkpn [748.629871ms]
Feb 21 19:34:55.644: INFO: Created: latency-svc-j7q8r
Feb 21 19:34:55.680: INFO: Got endpoints: latency-svc-wbnbv [749.828125ms]
Feb 21 19:34:55.694: INFO: Created: latency-svc-hskkr
Feb 21 19:34:55.730: INFO: Got endpoints: latency-svc-dhslz [750.230892ms]
Feb 21 19:34:55.744: INFO: Created: latency-svc-fmjbt
Feb 21 19:34:55.781: INFO: Got endpoints: latency-svc-zcp6t [749.921084ms]
Feb 21 19:34:55.795: INFO: Created: latency-svc-fplvq
Feb 21 19:34:55.832: INFO: Got endpoints: latency-svc-dgmmx [751.417136ms]
Feb 21 19:34:55.846: INFO: Created: latency-svc-z5lfn
Feb 21 19:34:55.880: INFO: Got endpoints: latency-svc-sttbs [749.777941ms]
Feb 21 19:34:55.893: INFO: Created: latency-svc-h9d7m
Feb 21 19:34:55.931: INFO: Got endpoints: latency-svc-878n9 [750.17985ms]
Feb 21 19:34:55.944: INFO: Created: latency-svc-vxsf8
Feb 21 19:34:55.980: INFO: Got endpoints: latency-svc-hgfxq [749.238323ms]
Feb 21 19:34:55.993: INFO: Created: latency-svc-bn5hc
Feb 21 19:34:56.029: INFO: Got endpoints: latency-svc-w9495 [750.068578ms]
Feb 21 19:34:56.045: INFO: Created: latency-svc-wsh4k
Feb 21 19:34:56.080: INFO: Got endpoints: latency-svc-s9vxf [747.966102ms]
Feb 21 19:34:56.093: INFO: Created: latency-svc-bbmtg
Feb 21 19:34:56.129: INFO: Got endpoints: latency-svc-zb7z7 [749.242096ms]
Feb 21 19:34:56.147: INFO: Created: latency-svc-4rdxx
Feb 21 19:34:56.181: INFO: Got endpoints: latency-svc-9bcjf [750.956633ms]
Feb 21 19:34:56.193: INFO: Created: latency-svc-kph7x
Feb 21 19:34:56.230: INFO: Got endpoints: latency-svc-f9xbh [749.731676ms]
Feb 21 19:34:56.244: INFO: Created: latency-svc-dftwn
Feb 21 19:34:56.280: INFO: Got endpoints: latency-svc-5k2sr [750.453002ms]
Feb 21 19:34:56.292: INFO: Created: latency-svc-d6r5p
Feb 21 19:34:56.331: INFO: Got endpoints: latency-svc-wzg72 [750.329339ms]
Feb 21 19:34:56.344: INFO: Created: latency-svc-w2mhn
Feb 21 19:34:56.381: INFO: Got endpoints: latency-svc-j7q8r [752.072132ms]
Feb 21 19:34:56.395: INFO: Created: latency-svc-t9jj8
Feb 21 19:34:56.429: INFO: Got endpoints: latency-svc-hskkr [749.561717ms]
Feb 21 19:34:56.446: INFO: Created: latency-svc-75n6h
Feb 21 19:34:56.480: INFO: Got endpoints: latency-svc-fmjbt [750.205027ms]
Feb 21 19:34:56.494: INFO: Created: latency-svc-qchx9
Feb 21 19:34:56.529: INFO: Got endpoints: latency-svc-fplvq [748.172839ms]
Feb 21 19:34:56.544: INFO: Created: latency-svc-74ncj
Feb 21 19:34:56.582: INFO: Got endpoints: latency-svc-z5lfn [749.907628ms]
Feb 21 19:34:56.596: INFO: Created: latency-svc-mb7px
Feb 21 19:34:56.630: INFO: Got endpoints: latency-svc-h9d7m [750.611514ms]
Feb 21 19:34:56.644: INFO: Created: latency-svc-f4ztr
Feb 21 19:34:56.681: INFO: Got endpoints: latency-svc-vxsf8 [750.017256ms]
Feb 21 19:34:56.696: INFO: Created: latency-svc-wnhtr
Feb 21 19:34:56.730: INFO: Got endpoints: latency-svc-bn5hc [750.554218ms]
Feb 21 19:34:56.745: INFO: Created: latency-svc-r5pbc
Feb 21 19:34:56.780: INFO: Got endpoints: latency-svc-wsh4k [750.251649ms]
Feb 21 19:34:56.796: INFO: Created: latency-svc-rv9fq
Feb 21 19:34:56.831: INFO: Got endpoints: latency-svc-bbmtg [750.970072ms]
Feb 21 19:34:56.846: INFO: Created: latency-svc-8k5b2
Feb 21 19:34:56.880: INFO: Got endpoints: latency-svc-4rdxx [750.905626ms]
Feb 21 19:34:56.895: INFO: Created: latency-svc-r4nq9
Feb 21 19:34:56.929: INFO: Got endpoints: latency-svc-kph7x [748.383043ms]
Feb 21 19:34:56.942: INFO: Created: latency-svc-zhvv8
Feb 21 19:34:56.979: INFO: Got endpoints: latency-svc-dftwn [749.726075ms]
Feb 21 19:34:56.994: INFO: Created: latency-svc-mn6sj
Feb 21 19:34:57.030: INFO: Got endpoints: latency-svc-d6r5p [749.653133ms]
Feb 21 19:34:57.042: INFO: Created: latency-svc-dz4tb
Feb 21 19:34:57.080: INFO: Got endpoints: latency-svc-w2mhn [748.90833ms]
Feb 21 19:34:57.094: INFO: Created: latency-svc-qhh5p
Feb 21 19:34:57.131: INFO: Got endpoints: latency-svc-t9jj8 [749.677609ms]
Feb 21 19:34:57.146: INFO: Created: latency-svc-f78ht
Feb 21 19:34:57.180: INFO: Got endpoints: latency-svc-75n6h [750.079753ms]
Feb 21 19:34:57.193: INFO: Created: latency-svc-w658q
Feb 21 19:34:57.231: INFO: Got endpoints: latency-svc-qchx9 [750.720216ms]
Feb 21 19:34:57.245: INFO: Created: latency-svc-9dmf8
Feb 21 19:34:57.279: INFO: Got endpoints: latency-svc-74ncj [749.497855ms]
Feb 21 19:34:57.292: INFO: Created: latency-svc-b46dd
Feb 21 19:34:57.331: INFO: Got endpoints: latency-svc-mb7px [748.141643ms]
Feb 21 19:34:57.344: INFO: Created: latency-svc-gkg8w
Feb 21 19:34:57.380: INFO: Got endpoints: latency-svc-f4ztr [749.554295ms]
Feb 21 19:34:57.393: INFO: Created: latency-svc-ms2hp
Feb 21 19:34:57.431: INFO: Got endpoints: latency-svc-wnhtr [749.346203ms]
Feb 21 19:34:57.448: INFO: Created: latency-svc-6l2w7
Feb 21 19:34:57.479: INFO: Got endpoints: latency-svc-r5pbc [748.975251ms]
Feb 21 19:34:57.494: INFO: Created: latency-svc-gjqfg
Feb 21 19:34:57.530: INFO: Got endpoints: latency-svc-rv9fq [749.891863ms]
Feb 21 19:34:57.545: INFO: Created: latency-svc-nbggv
Feb 21 19:34:57.579: INFO: Got endpoints: latency-svc-8k5b2 [747.743457ms]
Feb 21 19:34:57.593: INFO: Created: latency-svc-gc2b2
Feb 21 19:34:57.629: INFO: Got endpoints: latency-svc-r4nq9 [749.193727ms]
Feb 21 19:34:57.644: INFO: Created: latency-svc-mvntm
Feb 21 19:34:57.680: INFO: Got endpoints: latency-svc-zhvv8 [750.612772ms]
Feb 21 19:34:57.693: INFO: Created: latency-svc-96bw9
Feb 21 19:34:57.729: INFO: Got endpoints: latency-svc-mn6sj [749.79748ms]
Feb 21 19:34:57.745: INFO: Created: latency-svc-8pdqs
Feb 21 19:34:57.781: INFO: Got endpoints: latency-svc-dz4tb [751.445362ms]
Feb 21 19:34:57.795: INFO: Created: latency-svc-dl498
Feb 21 19:34:57.830: INFO: Got endpoints: latency-svc-qhh5p [750.316677ms]
Feb 21 19:34:57.844: INFO: Created: latency-svc-zvt45
Feb 21 19:34:57.880: INFO: Got endpoints: latency-svc-f78ht [748.771315ms]
Feb 21 19:34:57.894: INFO: Created: latency-svc-4rrzz
Feb 21 19:34:57.929: INFO: Got endpoints: latency-svc-w658q [749.721189ms]
Feb 21 19:34:57.942: INFO: Created: latency-svc-xwm29
Feb 21 19:34:57.981: INFO: Got endpoints: latency-svc-9dmf8 [750.281983ms]
Feb 21 19:34:57.994: INFO: Created: latency-svc-8mjkm
Feb 21 19:34:58.029: INFO: Got endpoints: latency-svc-b46dd [750.323241ms]
Feb 21 19:34:58.042: INFO: Created: latency-svc-z746b
Feb 21 19:34:58.081: INFO: Got endpoints: latency-svc-gkg8w [750.462213ms]
Feb 21 19:34:58.098: INFO: Created: latency-svc-n4nx5
Feb 21 19:34:58.130: INFO: Got endpoints: latency-svc-ms2hp [750.210401ms]
Feb 21 19:34:58.144: INFO: Created: latency-svc-slvng
Feb 21 19:34:58.180: INFO: Got endpoints: latency-svc-6l2w7 [748.86515ms]
Feb 21 19:34:58.197: INFO: Created: latency-svc-5k6tg
Feb 21 19:34:58.229: INFO: Got endpoints: latency-svc-gjqfg [749.451546ms]
Feb 21 19:34:58.252: INFO: Created: latency-svc-x8rrq
Feb 21 19:34:58.279: INFO: Got endpoints: latency-svc-nbggv [749.629043ms]
Feb 21 19:34:58.294: INFO: Created: latency-svc-kjjcz
Feb 21 19:34:58.330: INFO: Got endpoints: latency-svc-gc2b2 [751.202646ms]
Feb 21 19:34:58.344: INFO: Created: latency-svc-2wxlt
Feb 21 19:34:58.380: INFO: Got endpoints: latency-svc-mvntm [750.152439ms]
Feb 21 19:34:58.397: INFO: Created: latency-svc-mwdw8
Feb 21 19:34:58.430: INFO: Got endpoints: latency-svc-96bw9 [749.836304ms]
Feb 21 19:34:58.444: INFO: Created: latency-svc-wxlm4
Feb 21 19:34:58.479: INFO: Got endpoints: latency-svc-8pdqs [749.814555ms]
Feb 21 19:34:58.494: INFO: Created: latency-svc-vxn72
Feb 21 19:34:58.530: INFO: Got endpoints: latency-svc-dl498 [748.314911ms]
Feb 21 19:34:58.549: INFO: Created: latency-svc-5hrz9
Feb 21 19:34:58.580: INFO: Got endpoints: latency-svc-zvt45 [749.878594ms]
Feb 21 19:34:58.595: INFO: Created: latency-svc-78dhq
Feb 21 19:34:58.630: INFO: Got endpoints: latency-svc-4rrzz [749.806979ms]
Feb 21 19:34:58.645: INFO: Created: latency-svc-mlm8c
Feb 21 19:34:58.680: INFO: Got endpoints: latency-svc-xwm29 [750.175346ms]
Feb 21 19:34:58.693: INFO: Created: latency-svc-zr49q
Feb 21 19:34:58.732: INFO: Got endpoints: latency-svc-8mjkm [750.877839ms]
Feb 21 19:34:58.748: INFO: Created: latency-svc-6qfsn
Feb 21 19:34:58.780: INFO: Got endpoints: latency-svc-z746b [750.646251ms]
Feb 21 19:34:58.794: INFO: Created: latency-svc-pcj2t
Feb 21 19:34:58.831: INFO: Got endpoints: latency-svc-n4nx5 [750.146935ms]
Feb 21 19:34:58.845: INFO: Created: latency-svc-pp55z
Feb 21 19:34:58.881: INFO: Got endpoints: latency-svc-slvng [750.353883ms]
Feb 21 19:34:58.895: INFO: Created: latency-svc-gqf6t
Feb 21 19:34:58.930: INFO: Got endpoints: latency-svc-5k6tg [749.846804ms]
Feb 21 19:34:58.943: INFO: Created: latency-svc-2c6cx
Feb 21 19:34:58.981: INFO: Got endpoints: latency-svc-x8rrq [751.528282ms]
Feb 21 19:34:58.997: INFO: Created: latency-svc-4j29k
Feb 21 19:34:59.029: INFO: Got endpoints: latency-svc-kjjcz [749.645889ms]
Feb 21 19:34:59.043: INFO: Created: latency-svc-r9dj6
Feb 21 19:34:59.079: INFO: Got endpoints: latency-svc-2wxlt [748.775097ms]
Feb 21 19:34:59.100: INFO: Created: latency-svc-qggvf
Feb 21 19:34:59.130: INFO: Got endpoints: latency-svc-mwdw8 [749.923052ms]
Feb 21 19:34:59.144: INFO: Created: latency-svc-z6n4c
Feb 21 19:34:59.179: INFO: Got endpoints: latency-svc-wxlm4 [749.615627ms]
Feb 21 19:34:59.196: INFO: Created: latency-svc-nxbh4
Feb 21 19:34:59.231: INFO: Got endpoints: latency-svc-vxn72 [751.529738ms]
Feb 21 19:34:59.244: INFO: Created: latency-svc-2wgpl
Feb 21 19:34:59.279: INFO: Got endpoints: latency-svc-5hrz9 [749.489027ms]
Feb 21 19:34:59.293: INFO: Created: latency-svc-85mtt
Feb 21 19:34:59.332: INFO: Got endpoints: latency-svc-78dhq [751.595728ms]
Feb 21 19:34:59.346: INFO: Created: latency-svc-rptqs
Feb 21 19:34:59.380: INFO: Got endpoints: latency-svc-mlm8c [750.242727ms]
Feb 21 19:34:59.394: INFO: Created: latency-svc-xfdtf
Feb 21 19:34:59.431: INFO: Got endpoints: latency-svc-zr49q [750.923055ms]
Feb 21 19:34:59.444: INFO: Created: latency-svc-g9vn7
Feb 21 19:34:59.479: INFO: Got endpoints: latency-svc-6qfsn [747.143736ms]
Feb 21 19:34:59.494: INFO: Created: latency-svc-dk8dr
Feb 21 19:34:59.530: INFO: Got endpoints: latency-svc-pcj2t [750.290051ms]
Feb 21 19:34:59.547: INFO: Created: latency-svc-d4zxw
Feb 21 19:34:59.580: INFO: Got endpoints: latency-svc-pp55z [748.162205ms]
Feb 21 19:34:59.593: INFO: Created: latency-svc-vgv7g
Feb 21 19:34:59.633: INFO: Got endpoints: latency-svc-gqf6t [751.795216ms]
Feb 21 19:34:59.648: INFO: Created: latency-svc-r8rkk
Feb 21 19:34:59.679: INFO: Got endpoints: latency-svc-2c6cx [749.752915ms]
Feb 21 19:34:59.693: INFO: Created: latency-svc-4ss6p
Feb 21 19:34:59.730: INFO: Got endpoints: latency-svc-4j29k [749.079626ms]
Feb 21 19:34:59.747: INFO: Created: latency-svc-v8n7c
Feb 21 19:34:59.779: INFO: Got endpoints: latency-svc-r9dj6 [749.614342ms]
Feb 21 19:34:59.793: INFO: Created: latency-svc-dwrjj
Feb 21 19:34:59.830: INFO: Got endpoints: latency-svc-qggvf [750.626583ms]
Feb 21 19:34:59.846: INFO: Created: latency-svc-6xd4h
Feb 21 19:34:59.880: INFO: Got endpoints: latency-svc-z6n4c [750.136587ms]
Feb 21 19:34:59.894: INFO: Created: latency-svc-cz7g5
Feb 21 19:34:59.931: INFO: Got endpoints: latency-svc-nxbh4 [751.351982ms]
Feb 21 19:34:59.945: INFO: Created: latency-svc-ztm88
Feb 21 19:34:59.983: INFO: Got endpoints: latency-svc-2wgpl [752.569422ms]
Feb 21 19:34:59.998: INFO: Created: latency-svc-k277f
Feb 21 19:35:00.030: INFO: Got endpoints: latency-svc-85mtt [751.270467ms]
Feb 21 19:35:00.046: INFO: Created: latency-svc-m6k79
Feb 21 19:35:00.080: INFO: Got endpoints: latency-svc-rptqs [748.024357ms]
Feb 21 19:35:00.095: INFO: Created: latency-svc-8qn24
Feb 21 19:35:00.129: INFO: Got endpoints: latency-svc-xfdtf [749.061208ms]
Feb 21 19:35:00.144: INFO: Created: latency-svc-pkxt6
Feb 21 19:35:00.181: INFO: Got endpoints: latency-svc-g9vn7 [750.41523ms]
Feb 21 19:35:00.195: INFO: Created: latency-svc-d4rrh
Feb 21 19:35:00.231: INFO: Got endpoints: latency-svc-dk8dr [751.309729ms]
Feb 21 19:35:00.245: INFO: Created: latency-svc-wjlsx
Feb 21 19:35:00.279: INFO: Got endpoints: latency-svc-d4zxw [749.064091ms]
Feb 21 19:35:00.294: INFO: Created: latency-svc-52rlz
Feb 21 19:35:00.332: INFO: Got endpoints: latency-svc-vgv7g [751.872019ms]
Feb 21 19:35:00.349: INFO: Created: latency-svc-v9q6t
Feb 21 19:35:00.380: INFO: Got endpoints: latency-svc-r8rkk [746.92304ms]
Feb 21 19:35:00.394: INFO: Created: latency-svc-bkmrx
Feb 21 19:35:00.429: INFO: Got endpoints: latency-svc-4ss6p [749.65343ms]
Feb 21 19:35:00.443: INFO: Created: latency-svc-nnmsk
Feb 21 19:35:00.480: INFO: Got endpoints: latency-svc-v8n7c [749.686385ms]
Feb 21 19:35:00.494: INFO: Created: latency-svc-6vgrp
Feb 21 19:35:00.530: INFO: Got endpoints: latency-svc-dwrjj [751.390999ms]
Feb 21 19:35:00.544: INFO: Created: latency-svc-j4fzk
Feb 21 19:35:00.580: INFO: Got endpoints: latency-svc-6xd4h [750.540406ms]
Feb 21 19:35:00.596: INFO: Created: latency-svc-m9txf
Feb 21 19:35:00.631: INFO: Got endpoints: latency-svc-cz7g5 [751.182132ms]
Feb 21 19:35:00.645: INFO: Created: latency-svc-gqphz
Feb 21 19:35:00.680: INFO: Got endpoints: latency-svc-ztm88 [749.397373ms]
Feb 21 19:35:00.695: INFO: Created: latency-svc-lbj5s
Feb 21 19:35:00.733: INFO: Got endpoints: latency-svc-k277f [749.17619ms]
Feb 21 19:35:00.747: INFO: Created: latency-svc-9fvhv
Feb 21 19:35:00.780: INFO: Got endpoints: latency-svc-m6k79 [749.782347ms]
Feb 21 19:35:00.796: INFO: Created: latency-svc-z9bkk
Feb 21 19:35:00.830: INFO: Got endpoints: latency-svc-8qn24 [749.861632ms]
Feb 21 19:35:00.845: INFO: Created: latency-svc-qwmzq
Feb 21 19:35:00.881: INFO: Got endpoints: latency-svc-pkxt6 [751.341671ms]
Feb 21 19:35:00.895: INFO: Created: latency-svc-v7rxf
Feb 21 19:35:00.930: INFO: Got endpoints: latency-svc-d4rrh [748.871092ms]
Feb 21 19:35:00.946: INFO: Created: latency-svc-fp9kn
Feb 21 19:35:00.980: INFO: Got endpoints: latency-svc-wjlsx [749.110029ms]
Feb 21 19:35:00.995: INFO: Created: latency-svc-xg7v6
Feb 21 19:35:01.031: INFO: Got endpoints: latency-svc-52rlz [751.420437ms]
Feb 21 19:35:01.047: INFO: Created: latency-svc-9h6ck
Feb 21 19:35:01.081: INFO: Got endpoints: latency-svc-v9q6t [748.940673ms]
Feb 21 19:35:01.096: INFO: Created: latency-svc-q8s87
Feb 21 19:35:01.130: INFO: Got endpoints: latency-svc-bkmrx [749.93703ms]
Feb 21 19:35:01.143: INFO: Created: latency-svc-2nb8s
Feb 21 19:35:01.180: INFO: Got endpoints: latency-svc-nnmsk [751.262629ms]
Feb 21 19:35:01.195: INFO: Created: latency-svc-c7kb2
Feb 21 19:35:01.230: INFO: Got endpoints: latency-svc-6vgrp [750.803032ms]
Feb 21 19:35:01.255: INFO: Created: latency-svc-vkmz9
Feb 21 19:35:01.280: INFO: Got endpoints: latency-svc-j4fzk [749.463704ms]
Feb 21 19:35:01.294: INFO: Created: latency-svc-79xnb
Feb 21 19:35:01.331: INFO: Got endpoints: latency-svc-m9txf [750.575034ms]
Feb 21 19:35:01.345: INFO: Created: latency-svc-5l8lv
Feb 21 19:35:01.380: INFO: Got endpoints: latency-svc-gqphz [748.565203ms]
Feb 21 19:35:01.395: INFO: Created: latency-svc-2tc5j
Feb 21 19:35:01.430: INFO: Got endpoints: latency-svc-lbj5s [749.415665ms]
Feb 21 19:35:01.443: INFO: Created: latency-svc-t9n9l
Feb 21 19:35:01.479: INFO: Got endpoints: latency-svc-9fvhv [746.390853ms]
Feb 21 19:35:01.496: INFO: Created: latency-svc-4k6wh
Feb 21 19:35:01.530: INFO: Got endpoints: latency-svc-z9bkk [749.144181ms]
Feb 21 19:35:01.545: INFO: Created: latency-svc-k789q
Feb 21 19:35:01.581: INFO: Got endpoints: latency-svc-qwmzq [751.331959ms]
Feb 21 19:35:01.632: INFO: Got endpoints: latency-svc-v7rxf [750.889947ms]
Feb 21 19:35:01.681: INFO: Got endpoints: latency-svc-fp9kn [750.535896ms]
Feb 21 19:35:01.730: INFO: Got endpoints: latency-svc-xg7v6 [749.801953ms]
Feb 21 19:35:01.780: INFO: Got endpoints: latency-svc-9h6ck [749.029828ms]
Feb 21 19:35:01.830: INFO: Got endpoints: latency-svc-q8s87 [749.431548ms]
Feb 21 19:35:01.881: INFO: Got endpoints: latency-svc-2nb8s [751.446338ms]
Feb 21 19:35:01.930: INFO: Got endpoints: latency-svc-c7kb2 [749.08596ms]
Feb 21 19:35:01.980: INFO: Got endpoints: latency-svc-vkmz9 [749.89096ms]
Feb 21 19:35:02.032: INFO: Got endpoints: latency-svc-79xnb [751.654194ms]
Feb 21 19:35:02.080: INFO: Got endpoints: latency-svc-5l8lv [749.069892ms]
Feb 21 19:35:02.132: INFO: Got endpoints: latency-svc-2tc5j [752.101701ms]
Feb 21 19:35:02.180: INFO: Got endpoints: latency-svc-t9n9l [749.616067ms]
Feb 21 19:35:02.229: INFO: Got endpoints: latency-svc-4k6wh [750.166471ms]
Feb 21 19:35:02.280: INFO: Got endpoints: latency-svc-k789q [750.361602ms]
Feb 21 19:35:02.280: INFO: Latencies: [17.358478ms 22.188614ms 27.205268ms 36.328207ms 48.018495ms 71.036973ms 82.564851ms 91.911537ms 112.605938ms 120.799443ms 131.522956ms 142.938172ms 147.908939ms 148.746671ms 149.175308ms 150.491102ms 151.077751ms 151.212894ms 151.825628ms 152.33605ms 152.847518ms 152.979425ms 153.157443ms 153.404057ms 153.508205ms 154.66582ms 154.822117ms 159.14141ms 160.013116ms 160.103272ms 162.260268ms 162.366697ms 163.202811ms 172.945548ms 174.48602ms 175.03117ms 182.357576ms 194.86189ms 232.956895ms 273.746178ms 312.584118ms 351.767151ms 392.077135ms 431.993959ms 475.348826ms 508.440925ms 549.509101ms 590.300717ms 628.425371ms 669.147322ms 711.086312ms 746.390853ms 746.92304ms 747.113359ms 747.143736ms 747.439391ms 747.743457ms 747.966102ms 748.024357ms 748.141643ms 748.162205ms 748.172839ms 748.314911ms 748.381789ms 748.383043ms 748.565203ms 748.629871ms 748.771315ms 748.775097ms 748.86515ms 748.871092ms 748.90833ms 748.940673ms 748.975251ms 749.029828ms 749.048693ms 749.061208ms 749.064091ms 749.069892ms 749.079626ms 749.085353ms 749.08596ms 749.110029ms 749.144181ms 749.17619ms 749.193727ms 749.238323ms 749.242096ms 749.242317ms 749.257499ms 749.346203ms 749.397373ms 749.415665ms 749.431548ms 749.451546ms 749.463704ms 749.489027ms 749.497855ms 749.525693ms 749.554295ms 749.561717ms 749.574331ms 749.578161ms 749.614342ms 749.615627ms 749.616067ms 749.629043ms 749.645889ms 749.653133ms 749.65343ms 749.677609ms 749.686385ms 749.721189ms 749.726075ms 749.730661ms 749.731676ms 749.752915ms 749.777941ms 749.782347ms 749.79748ms 749.801953ms 749.806979ms 749.814555ms 749.828125ms 749.836304ms 749.841952ms 749.846804ms 749.861632ms 749.878594ms 749.89096ms 749.891863ms 749.907628ms 749.921084ms 749.923052ms 749.93703ms 750.017256ms 750.068578ms 750.079753ms 750.136587ms 750.146935ms 750.152439ms 750.166471ms 750.175346ms 750.17985ms 750.205027ms 750.210401ms 750.230892ms 750.242727ms 750.251649ms 750.280615ms 750.281983ms 750.290051ms 750.316677ms 750.323241ms 750.329339ms 750.344712ms 750.353883ms 750.361602ms 750.41523ms 750.453002ms 750.462213ms 750.535896ms 750.540406ms 750.554218ms 750.575034ms 750.611514ms 750.612772ms 750.626583ms 750.646251ms 750.720216ms 750.803032ms 750.877839ms 750.889947ms 750.905626ms 750.923055ms 750.956633ms 750.970072ms 751.182132ms 751.202646ms 751.262629ms 751.270467ms 751.309729ms 751.331959ms 751.341671ms 751.351982ms 751.390999ms 751.417136ms 751.420437ms 751.445362ms 751.446338ms 751.528282ms 751.529738ms 751.595728ms 751.654194ms 751.795216ms 751.872019ms 751.992194ms 752.072132ms 752.101701ms 752.569422ms]
Feb 21 19:35:02.280: INFO: 50 %ile: 749.561717ms
Feb 21 19:35:02.280: INFO: 90 %ile: 751.270467ms
Feb 21 19:35:02.280: INFO: 99 %ile: 752.101701ms
Feb 21 19:35:02.280: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:35:02.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-d59z2" for this suite.
Feb 21 19:35:16.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:35:16.435: INFO: namespace: e2e-tests-svc-latency-d59z2, resource: bindings, ignored listing per whitelist
Feb 21 19:35:16.436: INFO: namespace e2e-tests-svc-latency-d59z2 deletion completed in 14.150180787s

• [SLOW TEST:25.074 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:35:16.436: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-n78n2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-n78n2
Feb 21 19:35:18.644: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-n78n2
STEP: checking the pod's current state and verifying that restartCount is present
Feb 21 19:35:18.647: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:39:19.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-n78n2" for this suite.
Feb 21 19:39:25.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:39:25.527: INFO: namespace: e2e-tests-container-probe-n78n2, resource: bindings, ignored listing per whitelist
Feb 21 19:39:25.617: INFO: namespace e2e-tests-container-probe-n78n2 deletion completed in 6.191872935s

• [SLOW TEST:249.181 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:39:25.617: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-fzmqp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 21 19:39:49.849: INFO: Container started at 2019-02-21 19:39:26 +0000 UTC, pod became ready at 2019-02-21 19:39:47 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:39:49.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-fzmqp" for this suite.
Feb 21 19:40:11.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:40:11.917: INFO: namespace: e2e-tests-container-probe-fzmqp, resource: bindings, ignored listing per whitelist
Feb 21 19:40:11.998: INFO: namespace e2e-tests-container-probe-fzmqp deletion completed in 22.143013968s

• [SLOW TEST:46.381 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:40:11.998: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-w2pg6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Feb 21 19:40:12.194: INFO: Waiting up to 5m0s for pod "var-expansion-80ec1b11-3610-11e9-816d-1a333d676433" in namespace "e2e-tests-var-expansion-w2pg6" to be "success or failure"
Feb 21 19:40:12.198: INFO: Pod "var-expansion-80ec1b11-3610-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 3.798608ms
Feb 21 19:40:14.203: INFO: Pod "var-expansion-80ec1b11-3610-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008748681s
STEP: Saw pod success
Feb 21 19:40:14.203: INFO: Pod "var-expansion-80ec1b11-3610-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 19:40:14.207: INFO: Trying to get logs from node vm-899af0be-63fe-4e97-4fe5-b77e233eb87c pod var-expansion-80ec1b11-3610-11e9-816d-1a333d676433 container dapi-container: <nil>
STEP: delete the pod
Feb 21 19:40:14.235: INFO: Waiting for pod var-expansion-80ec1b11-3610-11e9-816d-1a333d676433 to disappear
Feb 21 19:40:14.238: INFO: Pod var-expansion-80ec1b11-3610-11e9-816d-1a333d676433 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:40:14.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-w2pg6" for this suite.
Feb 21 19:40:20.277: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:40:20.388: INFO: namespace: e2e-tests-var-expansion-w2pg6, resource: bindings, ignored listing per whitelist
Feb 21 19:40:20.412: INFO: namespace e2e-tests-var-expansion-w2pg6 deletion completed in 6.162862329s

• [SLOW TEST:8.414 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:40:20.412: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-jxl92
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-85f09b97-3610-11e9-816d-1a333d676433
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-85f09b97-3610-11e9-816d-1a333d676433
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:41:51.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jxl92" for this suite.
Feb 21 19:42:13.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:42:13.307: INFO: namespace: e2e-tests-projected-jxl92, resource: bindings, ignored listing per whitelist
Feb 21 19:42:13.390: INFO: namespace e2e-tests-projected-jxl92 deletion completed in 22.164651972s

• [SLOW TEST:112.977 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:42:13.390: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-r78k2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 21 19:42:13.596: INFO: Waiting up to 5m0s for pod "downward-api-c9489861-3610-11e9-816d-1a333d676433" in namespace "e2e-tests-downward-api-r78k2" to be "success or failure"
Feb 21 19:42:13.602: INFO: Pod "downward-api-c9489861-3610-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 5.755682ms
Feb 21 19:42:15.607: INFO: Pod "downward-api-c9489861-3610-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010319754s
Feb 21 19:42:17.611: INFO: Pod "downward-api-c9489861-3610-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014810769s
STEP: Saw pod success
Feb 21 19:42:17.611: INFO: Pod "downward-api-c9489861-3610-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 19:42:17.615: INFO: Trying to get logs from node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c pod downward-api-c9489861-3610-11e9-816d-1a333d676433 container dapi-container: <nil>
STEP: delete the pod
Feb 21 19:42:17.644: INFO: Waiting for pod downward-api-c9489861-3610-11e9-816d-1a333d676433 to disappear
Feb 21 19:42:17.647: INFO: Pod downward-api-c9489861-3610-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:42:17.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-r78k2" for this suite.
Feb 21 19:42:23.670: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:42:23.695: INFO: namespace: e2e-tests-downward-api-r78k2, resource: bindings, ignored listing per whitelist
Feb 21 19:42:23.810: INFO: namespace e2e-tests-downward-api-r78k2 deletion completed in 6.157926445s

• [SLOW TEST:10.420 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:42:23.810: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-4nh9t
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 21 19:42:24.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-4nh9t'
Feb 21 19:42:24.311: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 21 19:42:24.311: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Feb 21 19:42:24.317: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-043636783 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-4nh9t'
Feb 21 19:42:24.410: INFO: stderr: ""
Feb 21 19:42:24.410: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:42:24.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4nh9t" for this suite.
Feb 21 19:42:46.442: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:42:46.527: INFO: namespace: e2e-tests-kubectl-4nh9t, resource: bindings, ignored listing per whitelist
Feb 21 19:42:46.583: INFO: namespace e2e-tests-kubectl-4nh9t deletion completed in 22.168053482s

• [SLOW TEST:22.773 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:42:46.583: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-pd5fw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-pd5fw/secret-test-dd1082ef-3610-11e9-816d-1a333d676433
STEP: Creating a pod to test consume secrets
Feb 21 19:42:46.789: INFO: Waiting up to 5m0s for pod "pod-configmaps-dd117538-3610-11e9-816d-1a333d676433" in namespace "e2e-tests-secrets-pd5fw" to be "success or failure"
Feb 21 19:42:46.795: INFO: Pod "pod-configmaps-dd117538-3610-11e9-816d-1a333d676433": Phase="Pending", Reason="", readiness=false. Elapsed: 5.527542ms
Feb 21 19:42:48.799: INFO: Pod "pod-configmaps-dd117538-3610-11e9-816d-1a333d676433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01010828s
STEP: Saw pod success
Feb 21 19:42:48.799: INFO: Pod "pod-configmaps-dd117538-3610-11e9-816d-1a333d676433" satisfied condition "success or failure"
Feb 21 19:42:48.803: INFO: Trying to get logs from node vm-eb2db67a-c1df-4a88-7a11-61c28fd8881c pod pod-configmaps-dd117538-3610-11e9-816d-1a333d676433 container env-test: <nil>
STEP: delete the pod
Feb 21 19:42:48.832: INFO: Waiting for pod pod-configmaps-dd117538-3610-11e9-816d-1a333d676433 to disappear
Feb 21 19:42:48.835: INFO: Pod pod-configmaps-dd117538-3610-11e9-816d-1a333d676433 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:42:48.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-pd5fw" for this suite.
Feb 21 19:42:54.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:42:54.929: INFO: namespace: e2e-tests-secrets-pd5fw, resource: bindings, ignored listing per whitelist
Feb 21 19:42:55.009: INFO: namespace e2e-tests-secrets-pd5fw deletion completed in 6.169288289s

• [SLOW TEST:8.426 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:42:55.010: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-kjl5x
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:42:59.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-kjl5x" for this suite.
Feb 21 19:43:05.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:43:05.260: INFO: namespace: e2e-tests-kubelet-test-kjl5x, resource: bindings, ignored listing per whitelist
Feb 21 19:43:05.379: INFO: namespace e2e-tests-kubelet-test-kjl5x deletion completed in 6.155422502s

• [SLOW TEST:10.369 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 21 19:43:05.379: INFO: >>> kubeConfig: /tmp/kubeconfig-043636783
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-s44hh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-s44hh
Feb 21 19:43:07.590: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-s44hh
STEP: checking the pod's current state and verifying that restartCount is present
Feb 21 19:43:07.593: INFO: Initial restart count of pod liveness-http is 0
Feb 21 19:43:19.632: INFO: Restart count of pod e2e-tests-container-probe-s44hh/liveness-http is now 1 (12.039060823s elapsed)
Feb 21 19:43:39.693: INFO: Restart count of pod e2e-tests-container-probe-s44hh/liveness-http is now 2 (32.100020002s elapsed)
Feb 21 19:43:59.756: INFO: Restart count of pod e2e-tests-container-probe-s44hh/liveness-http is now 3 (52.162801201s elapsed)
Feb 21 19:44:19.826: INFO: Restart count of pod e2e-tests-container-probe-s44hh/liveness-http is now 4 (1m12.233351726s elapsed)
Feb 21 19:45:22.029: INFO: Restart count of pod e2e-tests-container-probe-s44hh/liveness-http is now 5 (2m14.436278327s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 21 19:45:22.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-s44hh" for this suite.
Feb 21 19:45:28.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 21 19:45:28.157: INFO: namespace: e2e-tests-container-probe-s44hh, resource: bindings, ignored listing per whitelist
Feb 21 19:45:28.200: INFO: namespace e2e-tests-container-probe-s44hh deletion completed in 6.150619319s

• [SLOW TEST:142.821 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSFeb 21 19:45:28.200: INFO: Running AfterSuite actions on all nodes
Feb 21 19:45:28.200: INFO: Running AfterSuite actions on node 1
Feb 21 19:45:28.200: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 5497.438 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h31m38.31557778s
Test Suite Passed
